// AUTO GENERATED FILE, DO NOT EDIT.
//
// Generated by `package:ffigen`.
import 'dart:ffi' as ffi;

/// Bindings for SDL
class DartSdl {
  /// Holds the symbol lookup function.
  final ffi.Pointer<T> Function<T extends ffi.NativeType>(String symbolName)
      _lookup;

  /// The symbols are looked up in [dynamicLibrary].
  DartSdl(ffi.DynamicLibrary dynamicLibrary) : _lookup = dynamicLibrary.lookup;

  /// The symbols are looked up with [lookup].
  DartSdl.fromLookup(
      ffi.Pointer<T> Function<T extends ffi.NativeType>(String symbolName)
          lookup)
      : _lookup = lookup;

  /// Get the name of the platform.
  ///
  /// Here are the names returned for some (but not all) supported platforms:
  ///
  /// - "Windows"
  /// - "Mac OS X"
  /// - "Linux"
  /// - "iOS"
  /// - "Android"
  ///
  /// \returns the name of the platform. If the correct platform name is not
  /// available, returns a string beginning with the text "Unknown".
  ///
  /// \since This function is available since SDL 2.0.0.
  ffi.Pointer<ffi.Int8> SDL_GetPlatform() {
    return _SDL_GetPlatform();
  }

  late final _SDL_GetPlatformPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Int8> Function()>>(
          'SDL_GetPlatform');
  late final _SDL_GetPlatform =
      _SDL_GetPlatformPtr.asFunction<ffi.Pointer<ffi.Int8> Function()>();

  void __va_start(
    ffi.Pointer<va_list> arg0,
  ) {
    return ___va_start(
      arg0,
    );
  }

  late final ___va_startPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<va_list>)>>(
          '__va_start');
  late final ___va_start =
      ___va_startPtr.asFunction<void Function(ffi.Pointer<va_list>)>();

  void __security_init_cookie() {
    return ___security_init_cookie();
  }

  late final ___security_init_cookiePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>(
          '__security_init_cookie');
  late final ___security_init_cookie =
      ___security_init_cookiePtr.asFunction<void Function()>();

  void __security_check_cookie(
    int _StackCookie,
  ) {
    return ___security_check_cookie(
      _StackCookie,
    );
  }

  late final ___security_check_cookiePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(uintptr_t)>>(
          '__security_check_cookie');
  late final ___security_check_cookie =
      ___security_check_cookiePtr.asFunction<void Function(int)>();

  void __report_gsfailure(
    int _StackCookie,
  ) {
    return ___report_gsfailure(
      _StackCookie,
    );
  }

  late final ___report_gsfailurePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(uintptr_t)>>(
          '__report_gsfailure');
  late final ___report_gsfailure =
      ___report_gsfailurePtr.asFunction<void Function(int)>();

  late final ffi.Pointer<uintptr_t> ___security_cookie =
      _lookup<uintptr_t>('__security_cookie');

  int get __security_cookie => ___security_cookie.value;

  set __security_cookie(int value) => ___security_cookie.value = value;

  void _invalid_parameter_noinfo() {
    return __invalid_parameter_noinfo();
  }

  late final __invalid_parameter_noinfoPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>(
          '_invalid_parameter_noinfo');
  late final __invalid_parameter_noinfo =
      __invalid_parameter_noinfoPtr.asFunction<void Function()>();

  void _invalid_parameter_noinfo_noreturn() {
    return __invalid_parameter_noinfo_noreturn();
  }

  late final __invalid_parameter_noinfo_noreturnPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>(
          '_invalid_parameter_noinfo_noreturn');
  late final __invalid_parameter_noinfo_noreturn =
      __invalid_parameter_noinfo_noreturnPtr.asFunction<void Function()>();

  void _invoke_watson(
    ffi.Pointer<wchar_t> _Expression,
    ffi.Pointer<wchar_t> _FunctionName,
    ffi.Pointer<wchar_t> _FileName,
    int _LineNo,
    int _Reserved,
  ) {
    return __invoke_watson(
      _Expression,
      _FunctionName,
      _FileName,
      _LineNo,
      _Reserved,
    );
  }

  late final __invoke_watsonPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<wchar_t>, ffi.Pointer<wchar_t>,
              ffi.Pointer<wchar_t>, ffi.Uint32, uintptr_t)>>('_invoke_watson');
  late final __invoke_watson = __invoke_watsonPtr.asFunction<
      void Function(ffi.Pointer<wchar_t>, ffi.Pointer<wchar_t>,
          ffi.Pointer<wchar_t>, int, int)>();

  ffi.Pointer<ffi.Int32> _errno() {
    return __errno();
  }

  late final __errnoPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Int32> Function()>>('_errno');
  late final __errno =
      __errnoPtr.asFunction<ffi.Pointer<ffi.Int32> Function()>();

  int _set_errno(
    int _Value,
  ) {
    return __set_errno(
      _Value,
    );
  }

  late final __set_errnoPtr =
      _lookup<ffi.NativeFunction<errno_t Function(ffi.Int32)>>('_set_errno');
  late final __set_errno = __set_errnoPtr.asFunction<int Function(int)>();

  int _get_errno(
    ffi.Pointer<ffi.Int32> _Value,
  ) {
    return __get_errno(
      _Value,
    );
  }

  late final __get_errnoPtr =
      _lookup<ffi.NativeFunction<errno_t Function(ffi.Pointer<ffi.Int32>)>>(
          '_get_errno');
  late final __get_errno =
      __get_errnoPtr.asFunction<int Function(ffi.Pointer<ffi.Int32>)>();

  int __threadid() {
    return ___threadid();
  }

  late final ___threadidPtr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function()>>('__threadid');
  late final ___threadid = ___threadidPtr.asFunction<int Function()>();

  int __threadhandle() {
    return ___threadhandle();
  }

  late final ___threadhandlePtr =
      _lookup<ffi.NativeFunction<uintptr_t Function()>>('__threadhandle');
  late final ___threadhandle = ___threadhandlePtr.asFunction<int Function()>();

  ffi.Pointer<ffi.Void> SDL_malloc(
    int size,
  ) {
    return _SDL_malloc(
      size,
    );
  }

  late final _SDL_mallocPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Void> Function(size_t)>>(
          'SDL_malloc');
  late final _SDL_malloc =
      _SDL_mallocPtr.asFunction<ffi.Pointer<ffi.Void> Function(int)>();

  ffi.Pointer<ffi.Void> SDL_calloc(
    int nmemb,
    int size,
  ) {
    return _SDL_calloc(
      nmemb,
      size,
    );
  }

  late final _SDL_callocPtr = _lookup<
          ffi.NativeFunction<ffi.Pointer<ffi.Void> Function(size_t, size_t)>>(
      'SDL_calloc');
  late final _SDL_calloc =
      _SDL_callocPtr.asFunction<ffi.Pointer<ffi.Void> Function(int, int)>();

  ffi.Pointer<ffi.Void> SDL_realloc(
    ffi.Pointer<ffi.Void> mem,
    int size,
  ) {
    return _SDL_realloc(
      mem,
      size,
    );
  }

  late final _SDL_reallocPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Void> Function(
              ffi.Pointer<ffi.Void>, size_t)>>('SDL_realloc');
  late final _SDL_realloc = _SDL_reallocPtr.asFunction<
      ffi.Pointer<ffi.Void> Function(ffi.Pointer<ffi.Void>, int)>();

  void SDL_free(
    ffi.Pointer<ffi.Void> mem,
  ) {
    return _SDL_free(
      mem,
    );
  }

  late final _SDL_freePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ffi.Void>)>>(
          'SDL_free');
  late final _SDL_free =
      _SDL_freePtr.asFunction<void Function(ffi.Pointer<ffi.Void>)>();

  /// Get the current set of SDL memory functions
  ///
  /// \since This function is available since SDL 2.0.7.
  void SDL_GetMemoryFunctions(
    ffi.Pointer<SDL_malloc_func> malloc_func,
    ffi.Pointer<SDL_calloc_func> calloc_func,
    ffi.Pointer<SDL_realloc_func> realloc_func,
    ffi.Pointer<SDL_free_func> free_func,
  ) {
    return _SDL_GetMemoryFunctions(
      malloc_func,
      calloc_func,
      realloc_func,
      free_func,
    );
  }

  late final _SDL_GetMemoryFunctionsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<SDL_malloc_func>,
              ffi.Pointer<SDL_calloc_func>,
              ffi.Pointer<SDL_realloc_func>,
              ffi.Pointer<SDL_free_func>)>>('SDL_GetMemoryFunctions');
  late final _SDL_GetMemoryFunctions = _SDL_GetMemoryFunctionsPtr.asFunction<
      void Function(ffi.Pointer<SDL_malloc_func>, ffi.Pointer<SDL_calloc_func>,
          ffi.Pointer<SDL_realloc_func>, ffi.Pointer<SDL_free_func>)>();

  /// Replace SDL's memory allocation functions with a custom set
  ///
  /// \since This function is available since SDL 2.0.7.
  int SDL_SetMemoryFunctions(
    SDL_malloc_func malloc_func,
    SDL_calloc_func calloc_func,
    SDL_realloc_func realloc_func,
    SDL_free_func free_func,
  ) {
    return _SDL_SetMemoryFunctions(
      malloc_func,
      calloc_func,
      realloc_func,
      free_func,
    );
  }

  late final _SDL_SetMemoryFunctionsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(SDL_malloc_func, SDL_calloc_func, SDL_realloc_func,
              SDL_free_func)>>('SDL_SetMemoryFunctions');
  late final _SDL_SetMemoryFunctions = _SDL_SetMemoryFunctionsPtr.asFunction<
      int Function(
          SDL_malloc_func, SDL_calloc_func, SDL_realloc_func, SDL_free_func)>();

  /// Get the number of outstanding (unfreed) allocations
  ///
  /// \since This function is available since SDL 2.0.7.
  int SDL_GetNumAllocations() {
    return _SDL_GetNumAllocations();
  }

  late final _SDL_GetNumAllocationsPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function()>>(
          'SDL_GetNumAllocations');
  late final _SDL_GetNumAllocations =
      _SDL_GetNumAllocationsPtr.asFunction<int Function()>();

  ffi.Pointer<ffi.Int8> SDL_getenv(
    ffi.Pointer<ffi.Int8> name,
  ) {
    return _SDL_getenv(
      name,
    );
  }

  late final _SDL_getenvPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Int8> Function(ffi.Pointer<ffi.Int8>)>>('SDL_getenv');
  late final _SDL_getenv = _SDL_getenvPtr.asFunction<
      ffi.Pointer<ffi.Int8> Function(ffi.Pointer<ffi.Int8>)>();

  int SDL_setenv(
    ffi.Pointer<ffi.Int8> name,
    ffi.Pointer<ffi.Int8> value,
    int overwrite,
  ) {
    return _SDL_setenv(
      name,
      value,
      overwrite,
    );
  }

  late final _SDL_setenvPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Int8>,
              ffi.Int32)>>('SDL_setenv');
  late final _SDL_setenv = _SDL_setenvPtr.asFunction<
      int Function(ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Int8>, int)>();

  void SDL_qsort(
    ffi.Pointer<ffi.Void> base,
    int nmemb,
    int size,
    ffi.Pointer<
            ffi.NativeFunction<
                ffi.Int32 Function(
                    ffi.Pointer<ffi.Void>, ffi.Pointer<ffi.Void>)>>
        compare,
  ) {
    return _SDL_qsort(
      base,
      nmemb,
      size,
      compare,
    );
  }

  late final _SDL_qsortPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<ffi.Void>,
              size_t,
              size_t,
              ffi.Pointer<
                  ffi.NativeFunction<
                      ffi.Int32 Function(ffi.Pointer<ffi.Void>,
                          ffi.Pointer<ffi.Void>)>>)>>('SDL_qsort');
  late final _SDL_qsort = _SDL_qsortPtr.asFunction<
      void Function(
          ffi.Pointer<ffi.Void>,
          int,
          int,
          ffi.Pointer<
              ffi.NativeFunction<
                  ffi.Int32 Function(
                      ffi.Pointer<ffi.Void>, ffi.Pointer<ffi.Void>)>>)>();

  int SDL_abs(
    int x,
  ) {
    return _SDL_abs(
      x,
    );
  }

  late final _SDL_absPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Int32)>>('SDL_abs');
  late final _SDL_abs = _SDL_absPtr.asFunction<int Function(int)>();

  int SDL_isalpha(
    int x,
  ) {
    return _SDL_isalpha(
      x,
    );
  }

  late final _SDL_isalphaPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Int32)>>('SDL_isalpha');
  late final _SDL_isalpha = _SDL_isalphaPtr.asFunction<int Function(int)>();

  int SDL_isalnum(
    int x,
  ) {
    return _SDL_isalnum(
      x,
    );
  }

  late final _SDL_isalnumPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Int32)>>('SDL_isalnum');
  late final _SDL_isalnum = _SDL_isalnumPtr.asFunction<int Function(int)>();

  int SDL_isblank(
    int x,
  ) {
    return _SDL_isblank(
      x,
    );
  }

  late final _SDL_isblankPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Int32)>>('SDL_isblank');
  late final _SDL_isblank = _SDL_isblankPtr.asFunction<int Function(int)>();

  int SDL_iscntrl(
    int x,
  ) {
    return _SDL_iscntrl(
      x,
    );
  }

  late final _SDL_iscntrlPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Int32)>>('SDL_iscntrl');
  late final _SDL_iscntrl = _SDL_iscntrlPtr.asFunction<int Function(int)>();

  int SDL_isdigit(
    int x,
  ) {
    return _SDL_isdigit(
      x,
    );
  }

  late final _SDL_isdigitPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Int32)>>('SDL_isdigit');
  late final _SDL_isdigit = _SDL_isdigitPtr.asFunction<int Function(int)>();

  int SDL_isxdigit(
    int x,
  ) {
    return _SDL_isxdigit(
      x,
    );
  }

  late final _SDL_isxdigitPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Int32)>>(
          'SDL_isxdigit');
  late final _SDL_isxdigit = _SDL_isxdigitPtr.asFunction<int Function(int)>();

  int SDL_ispunct(
    int x,
  ) {
    return _SDL_ispunct(
      x,
    );
  }

  late final _SDL_ispunctPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Int32)>>('SDL_ispunct');
  late final _SDL_ispunct = _SDL_ispunctPtr.asFunction<int Function(int)>();

  int SDL_isspace(
    int x,
  ) {
    return _SDL_isspace(
      x,
    );
  }

  late final _SDL_isspacePtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Int32)>>('SDL_isspace');
  late final _SDL_isspace = _SDL_isspacePtr.asFunction<int Function(int)>();

  int SDL_isupper(
    int x,
  ) {
    return _SDL_isupper(
      x,
    );
  }

  late final _SDL_isupperPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Int32)>>('SDL_isupper');
  late final _SDL_isupper = _SDL_isupperPtr.asFunction<int Function(int)>();

  int SDL_islower(
    int x,
  ) {
    return _SDL_islower(
      x,
    );
  }

  late final _SDL_islowerPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Int32)>>('SDL_islower');
  late final _SDL_islower = _SDL_islowerPtr.asFunction<int Function(int)>();

  int SDL_isprint(
    int x,
  ) {
    return _SDL_isprint(
      x,
    );
  }

  late final _SDL_isprintPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Int32)>>('SDL_isprint');
  late final _SDL_isprint = _SDL_isprintPtr.asFunction<int Function(int)>();

  int SDL_isgraph(
    int x,
  ) {
    return _SDL_isgraph(
      x,
    );
  }

  late final _SDL_isgraphPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Int32)>>('SDL_isgraph');
  late final _SDL_isgraph = _SDL_isgraphPtr.asFunction<int Function(int)>();

  int SDL_toupper(
    int x,
  ) {
    return _SDL_toupper(
      x,
    );
  }

  late final _SDL_toupperPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Int32)>>('SDL_toupper');
  late final _SDL_toupper = _SDL_toupperPtr.asFunction<int Function(int)>();

  int SDL_tolower(
    int x,
  ) {
    return _SDL_tolower(
      x,
    );
  }

  late final _SDL_tolowerPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Int32)>>('SDL_tolower');
  late final _SDL_tolower = _SDL_tolowerPtr.asFunction<int Function(int)>();

  int SDL_crc32(
    int crc,
    ffi.Pointer<ffi.Void> data,
    int len,
  ) {
    return _SDL_crc32(
      crc,
      data,
      len,
    );
  }

  late final _SDL_crc32Ptr = _lookup<
      ffi.NativeFunction<
          Uint32 Function(Uint32, ffi.Pointer<ffi.Void>, size_t)>>('SDL_crc32');
  late final _SDL_crc32 =
      _SDL_crc32Ptr.asFunction<int Function(int, ffi.Pointer<ffi.Void>, int)>();

  ffi.Pointer<ffi.Void> SDL_memset(
    ffi.Pointer<ffi.Void> dst,
    int c,
    int len,
  ) {
    return _SDL_memset(
      dst,
      c,
      len,
    );
  }

  late final _SDL_memsetPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Void> Function(
              ffi.Pointer<ffi.Void>, ffi.Int32, size_t)>>('SDL_memset');
  late final _SDL_memset = _SDL_memsetPtr.asFunction<
      ffi.Pointer<ffi.Void> Function(ffi.Pointer<ffi.Void>, int, int)>();

  ffi.Pointer<ffi.Void> SDL_memcpy(
    ffi.Pointer<ffi.Void> dst,
    ffi.Pointer<ffi.Void> src,
    int len,
  ) {
    return _SDL_memcpy(
      dst,
      src,
      len,
    );
  }

  late final _SDL_memcpyPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Void> Function(ffi.Pointer<ffi.Void>,
              ffi.Pointer<ffi.Void>, size_t)>>('SDL_memcpy');
  late final _SDL_memcpy = _SDL_memcpyPtr.asFunction<
      ffi.Pointer<ffi.Void> Function(
          ffi.Pointer<ffi.Void>, ffi.Pointer<ffi.Void>, int)>();

  ffi.Pointer<ffi.Void> SDL_memmove(
    ffi.Pointer<ffi.Void> dst,
    ffi.Pointer<ffi.Void> src,
    int len,
  ) {
    return _SDL_memmove(
      dst,
      src,
      len,
    );
  }

  late final _SDL_memmovePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Void> Function(ffi.Pointer<ffi.Void>,
              ffi.Pointer<ffi.Void>, size_t)>>('SDL_memmove');
  late final _SDL_memmove = _SDL_memmovePtr.asFunction<
      ffi.Pointer<ffi.Void> Function(
          ffi.Pointer<ffi.Void>, ffi.Pointer<ffi.Void>, int)>();

  int SDL_memcmp(
    ffi.Pointer<ffi.Void> s1,
    ffi.Pointer<ffi.Void> s2,
    int len,
  ) {
    return _SDL_memcmp(
      s1,
      s2,
      len,
    );
  }

  late final _SDL_memcmpPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<ffi.Void>, ffi.Pointer<ffi.Void>,
              size_t)>>('SDL_memcmp');
  late final _SDL_memcmp = _SDL_memcmpPtr.asFunction<
      int Function(ffi.Pointer<ffi.Void>, ffi.Pointer<ffi.Void>, int)>();

  int SDL_wcslen(
    ffi.Pointer<wchar_t> wstr,
  ) {
    return _SDL_wcslen(
      wstr,
    );
  }

  late final _SDL_wcslenPtr =
      _lookup<ffi.NativeFunction<size_t Function(ffi.Pointer<wchar_t>)>>(
          'SDL_wcslen');
  late final _SDL_wcslen =
      _SDL_wcslenPtr.asFunction<int Function(ffi.Pointer<wchar_t>)>();

  int SDL_wcslcpy(
    ffi.Pointer<wchar_t> dst,
    ffi.Pointer<wchar_t> src,
    int maxlen,
  ) {
    return _SDL_wcslcpy(
      dst,
      src,
      maxlen,
    );
  }

  late final _SDL_wcslcpyPtr = _lookup<
      ffi.NativeFunction<
          size_t Function(ffi.Pointer<wchar_t>, ffi.Pointer<wchar_t>,
              size_t)>>('SDL_wcslcpy');
  late final _SDL_wcslcpy = _SDL_wcslcpyPtr.asFunction<
      int Function(ffi.Pointer<wchar_t>, ffi.Pointer<wchar_t>, int)>();

  int SDL_wcslcat(
    ffi.Pointer<wchar_t> dst,
    ffi.Pointer<wchar_t> src,
    int maxlen,
  ) {
    return _SDL_wcslcat(
      dst,
      src,
      maxlen,
    );
  }

  late final _SDL_wcslcatPtr = _lookup<
      ffi.NativeFunction<
          size_t Function(ffi.Pointer<wchar_t>, ffi.Pointer<wchar_t>,
              size_t)>>('SDL_wcslcat');
  late final _SDL_wcslcat = _SDL_wcslcatPtr.asFunction<
      int Function(ffi.Pointer<wchar_t>, ffi.Pointer<wchar_t>, int)>();

  ffi.Pointer<wchar_t> SDL_wcsdup(
    ffi.Pointer<wchar_t> wstr,
  ) {
    return _SDL_wcsdup(
      wstr,
    );
  }

  late final _SDL_wcsdupPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<wchar_t> Function(ffi.Pointer<wchar_t>)>>('SDL_wcsdup');
  late final _SDL_wcsdup = _SDL_wcsdupPtr.asFunction<
      ffi.Pointer<wchar_t> Function(ffi.Pointer<wchar_t>)>();

  ffi.Pointer<wchar_t> SDL_wcsstr(
    ffi.Pointer<wchar_t> haystack,
    ffi.Pointer<wchar_t> needle,
  ) {
    return _SDL_wcsstr(
      haystack,
      needle,
    );
  }

  late final _SDL_wcsstrPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<wchar_t> Function(
              ffi.Pointer<wchar_t>, ffi.Pointer<wchar_t>)>>('SDL_wcsstr');
  late final _SDL_wcsstr = _SDL_wcsstrPtr.asFunction<
      ffi.Pointer<wchar_t> Function(
          ffi.Pointer<wchar_t>, ffi.Pointer<wchar_t>)>();

  int SDL_wcscmp(
    ffi.Pointer<wchar_t> str1,
    ffi.Pointer<wchar_t> str2,
  ) {
    return _SDL_wcscmp(
      str1,
      str2,
    );
  }

  late final _SDL_wcscmpPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<wchar_t>, ffi.Pointer<wchar_t>)>>('SDL_wcscmp');
  late final _SDL_wcscmp = _SDL_wcscmpPtr.asFunction<
      int Function(ffi.Pointer<wchar_t>, ffi.Pointer<wchar_t>)>();

  int SDL_wcsncmp(
    ffi.Pointer<wchar_t> str1,
    ffi.Pointer<wchar_t> str2,
    int maxlen,
  ) {
    return _SDL_wcsncmp(
      str1,
      str2,
      maxlen,
    );
  }

  late final _SDL_wcsncmpPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<wchar_t>, ffi.Pointer<wchar_t>,
              size_t)>>('SDL_wcsncmp');
  late final _SDL_wcsncmp = _SDL_wcsncmpPtr.asFunction<
      int Function(ffi.Pointer<wchar_t>, ffi.Pointer<wchar_t>, int)>();

  int SDL_wcscasecmp(
    ffi.Pointer<wchar_t> str1,
    ffi.Pointer<wchar_t> str2,
  ) {
    return _SDL_wcscasecmp(
      str1,
      str2,
    );
  }

  late final _SDL_wcscasecmpPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<wchar_t>, ffi.Pointer<wchar_t>)>>('SDL_wcscasecmp');
  late final _SDL_wcscasecmp = _SDL_wcscasecmpPtr.asFunction<
      int Function(ffi.Pointer<wchar_t>, ffi.Pointer<wchar_t>)>();

  int SDL_wcsncasecmp(
    ffi.Pointer<wchar_t> str1,
    ffi.Pointer<wchar_t> str2,
    int len,
  ) {
    return _SDL_wcsncasecmp(
      str1,
      str2,
      len,
    );
  }

  late final _SDL_wcsncasecmpPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<wchar_t>, ffi.Pointer<wchar_t>,
              size_t)>>('SDL_wcsncasecmp');
  late final _SDL_wcsncasecmp = _SDL_wcsncasecmpPtr.asFunction<
      int Function(ffi.Pointer<wchar_t>, ffi.Pointer<wchar_t>, int)>();

  int SDL_strlen(
    ffi.Pointer<ffi.Int8> str,
  ) {
    return _SDL_strlen(
      str,
    );
  }

  late final _SDL_strlenPtr =
      _lookup<ffi.NativeFunction<size_t Function(ffi.Pointer<ffi.Int8>)>>(
          'SDL_strlen');
  late final _SDL_strlen =
      _SDL_strlenPtr.asFunction<int Function(ffi.Pointer<ffi.Int8>)>();

  int SDL_strlcpy(
    ffi.Pointer<ffi.Int8> dst,
    ffi.Pointer<ffi.Int8> src,
    int maxlen,
  ) {
    return _SDL_strlcpy(
      dst,
      src,
      maxlen,
    );
  }

  late final _SDL_strlcpyPtr = _lookup<
      ffi.NativeFunction<
          size_t Function(ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Int8>,
              size_t)>>('SDL_strlcpy');
  late final _SDL_strlcpy = _SDL_strlcpyPtr.asFunction<
      int Function(ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Int8>, int)>();

  int SDL_utf8strlcpy(
    ffi.Pointer<ffi.Int8> dst,
    ffi.Pointer<ffi.Int8> src,
    int dst_bytes,
  ) {
    return _SDL_utf8strlcpy(
      dst,
      src,
      dst_bytes,
    );
  }

  late final _SDL_utf8strlcpyPtr = _lookup<
      ffi.NativeFunction<
          size_t Function(ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Int8>,
              size_t)>>('SDL_utf8strlcpy');
  late final _SDL_utf8strlcpy = _SDL_utf8strlcpyPtr.asFunction<
      int Function(ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Int8>, int)>();

  int SDL_strlcat(
    ffi.Pointer<ffi.Int8> dst,
    ffi.Pointer<ffi.Int8> src,
    int maxlen,
  ) {
    return _SDL_strlcat(
      dst,
      src,
      maxlen,
    );
  }

  late final _SDL_strlcatPtr = _lookup<
      ffi.NativeFunction<
          size_t Function(ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Int8>,
              size_t)>>('SDL_strlcat');
  late final _SDL_strlcat = _SDL_strlcatPtr.asFunction<
      int Function(ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Int8>, int)>();

  ffi.Pointer<ffi.Int8> SDL_strdup(
    ffi.Pointer<ffi.Int8> str,
  ) {
    return _SDL_strdup(
      str,
    );
  }

  late final _SDL_strdupPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Int8> Function(ffi.Pointer<ffi.Int8>)>>('SDL_strdup');
  late final _SDL_strdup = _SDL_strdupPtr.asFunction<
      ffi.Pointer<ffi.Int8> Function(ffi.Pointer<ffi.Int8>)>();

  ffi.Pointer<ffi.Int8> SDL_strrev(
    ffi.Pointer<ffi.Int8> str,
  ) {
    return _SDL_strrev(
      str,
    );
  }

  late final _SDL_strrevPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Int8> Function(ffi.Pointer<ffi.Int8>)>>('SDL_strrev');
  late final _SDL_strrev = _SDL_strrevPtr.asFunction<
      ffi.Pointer<ffi.Int8> Function(ffi.Pointer<ffi.Int8>)>();

  ffi.Pointer<ffi.Int8> SDL_strupr(
    ffi.Pointer<ffi.Int8> str,
  ) {
    return _SDL_strupr(
      str,
    );
  }

  late final _SDL_struprPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Int8> Function(ffi.Pointer<ffi.Int8>)>>('SDL_strupr');
  late final _SDL_strupr = _SDL_struprPtr.asFunction<
      ffi.Pointer<ffi.Int8> Function(ffi.Pointer<ffi.Int8>)>();

  ffi.Pointer<ffi.Int8> SDL_strlwr(
    ffi.Pointer<ffi.Int8> str,
  ) {
    return _SDL_strlwr(
      str,
    );
  }

  late final _SDL_strlwrPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Int8> Function(ffi.Pointer<ffi.Int8>)>>('SDL_strlwr');
  late final _SDL_strlwr = _SDL_strlwrPtr.asFunction<
      ffi.Pointer<ffi.Int8> Function(ffi.Pointer<ffi.Int8>)>();

  ffi.Pointer<ffi.Int8> SDL_strchr(
    ffi.Pointer<ffi.Int8> str,
    int c,
  ) {
    return _SDL_strchr(
      str,
      c,
    );
  }

  late final _SDL_strchrPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Int8> Function(
              ffi.Pointer<ffi.Int8>, ffi.Int32)>>('SDL_strchr');
  late final _SDL_strchr = _SDL_strchrPtr.asFunction<
      ffi.Pointer<ffi.Int8> Function(ffi.Pointer<ffi.Int8>, int)>();

  ffi.Pointer<ffi.Int8> SDL_strrchr(
    ffi.Pointer<ffi.Int8> str,
    int c,
  ) {
    return _SDL_strrchr(
      str,
      c,
    );
  }

  late final _SDL_strrchrPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Int8> Function(
              ffi.Pointer<ffi.Int8>, ffi.Int32)>>('SDL_strrchr');
  late final _SDL_strrchr = _SDL_strrchrPtr.asFunction<
      ffi.Pointer<ffi.Int8> Function(ffi.Pointer<ffi.Int8>, int)>();

  ffi.Pointer<ffi.Int8> SDL_strstr(
    ffi.Pointer<ffi.Int8> haystack,
    ffi.Pointer<ffi.Int8> needle,
  ) {
    return _SDL_strstr(
      haystack,
      needle,
    );
  }

  late final _SDL_strstrPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Int8> Function(
              ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Int8>)>>('SDL_strstr');
  late final _SDL_strstr = _SDL_strstrPtr.asFunction<
      ffi.Pointer<ffi.Int8> Function(
          ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Int8>)>();

  ffi.Pointer<ffi.Int8> SDL_strtokr(
    ffi.Pointer<ffi.Int8> s1,
    ffi.Pointer<ffi.Int8> s2,
    ffi.Pointer<ffi.Pointer<ffi.Int8>> saveptr,
  ) {
    return _SDL_strtokr(
      s1,
      s2,
      saveptr,
    );
  }

  late final _SDL_strtokrPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Int8> Function(
              ffi.Pointer<ffi.Int8>,
              ffi.Pointer<ffi.Int8>,
              ffi.Pointer<ffi.Pointer<ffi.Int8>>)>>('SDL_strtokr');
  late final _SDL_strtokr = _SDL_strtokrPtr.asFunction<
      ffi.Pointer<ffi.Int8> Function(ffi.Pointer<ffi.Int8>,
          ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Pointer<ffi.Int8>>)>();

  int SDL_utf8strlen(
    ffi.Pointer<ffi.Int8> str,
  ) {
    return _SDL_utf8strlen(
      str,
    );
  }

  late final _SDL_utf8strlenPtr =
      _lookup<ffi.NativeFunction<size_t Function(ffi.Pointer<ffi.Int8>)>>(
          'SDL_utf8strlen');
  late final _SDL_utf8strlen =
      _SDL_utf8strlenPtr.asFunction<int Function(ffi.Pointer<ffi.Int8>)>();

  ffi.Pointer<ffi.Int8> SDL_itoa(
    int value,
    ffi.Pointer<ffi.Int8> str,
    int radix,
  ) {
    return _SDL_itoa(
      value,
      str,
      radix,
    );
  }

  late final _SDL_itoaPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Int8> Function(
              ffi.Int32, ffi.Pointer<ffi.Int8>, ffi.Int32)>>('SDL_itoa');
  late final _SDL_itoa = _SDL_itoaPtr.asFunction<
      ffi.Pointer<ffi.Int8> Function(int, ffi.Pointer<ffi.Int8>, int)>();

  ffi.Pointer<ffi.Int8> SDL_uitoa(
    int value,
    ffi.Pointer<ffi.Int8> str,
    int radix,
  ) {
    return _SDL_uitoa(
      value,
      str,
      radix,
    );
  }

  late final _SDL_uitoaPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Int8> Function(
              ffi.Uint32, ffi.Pointer<ffi.Int8>, ffi.Int32)>>('SDL_uitoa');
  late final _SDL_uitoa = _SDL_uitoaPtr.asFunction<
      ffi.Pointer<ffi.Int8> Function(int, ffi.Pointer<ffi.Int8>, int)>();

  ffi.Pointer<ffi.Int8> SDL_ltoa(
    int value,
    ffi.Pointer<ffi.Int8> str,
    int radix,
  ) {
    return _SDL_ltoa(
      value,
      str,
      radix,
    );
  }

  late final _SDL_ltoaPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Int8> Function(
              ffi.Int64, ffi.Pointer<ffi.Int8>, ffi.Int32)>>('SDL_ltoa');
  late final _SDL_ltoa = _SDL_ltoaPtr.asFunction<
      ffi.Pointer<ffi.Int8> Function(int, ffi.Pointer<ffi.Int8>, int)>();

  ffi.Pointer<ffi.Int8> SDL_ultoa(
    int value,
    ffi.Pointer<ffi.Int8> str,
    int radix,
  ) {
    return _SDL_ultoa(
      value,
      str,
      radix,
    );
  }

  late final _SDL_ultoaPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Int8> Function(
              ffi.Uint64, ffi.Pointer<ffi.Int8>, ffi.Int32)>>('SDL_ultoa');
  late final _SDL_ultoa = _SDL_ultoaPtr.asFunction<
      ffi.Pointer<ffi.Int8> Function(int, ffi.Pointer<ffi.Int8>, int)>();

  ffi.Pointer<ffi.Int8> SDL_lltoa(
    int value,
    ffi.Pointer<ffi.Int8> str,
    int radix,
  ) {
    return _SDL_lltoa(
      value,
      str,
      radix,
    );
  }

  late final _SDL_lltoaPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Int8> Function(
              Sint64, ffi.Pointer<ffi.Int8>, ffi.Int32)>>('SDL_lltoa');
  late final _SDL_lltoa = _SDL_lltoaPtr.asFunction<
      ffi.Pointer<ffi.Int8> Function(int, ffi.Pointer<ffi.Int8>, int)>();

  ffi.Pointer<ffi.Int8> SDL_ulltoa(
    int value,
    ffi.Pointer<ffi.Int8> str,
    int radix,
  ) {
    return _SDL_ulltoa(
      value,
      str,
      radix,
    );
  }

  late final _SDL_ulltoaPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Int8> Function(
              Uint64, ffi.Pointer<ffi.Int8>, ffi.Int32)>>('SDL_ulltoa');
  late final _SDL_ulltoa = _SDL_ulltoaPtr.asFunction<
      ffi.Pointer<ffi.Int8> Function(int, ffi.Pointer<ffi.Int8>, int)>();

  int SDL_atoi(
    ffi.Pointer<ffi.Int8> str,
  ) {
    return _SDL_atoi(
      str,
    );
  }

  late final _SDL_atoiPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<ffi.Int8>)>>(
          'SDL_atoi');
  late final _SDL_atoi =
      _SDL_atoiPtr.asFunction<int Function(ffi.Pointer<ffi.Int8>)>();

  double SDL_atof(
    ffi.Pointer<ffi.Int8> str,
  ) {
    return _SDL_atof(
      str,
    );
  }

  late final _SDL_atofPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Pointer<ffi.Int8>)>>(
          'SDL_atof');
  late final _SDL_atof =
      _SDL_atofPtr.asFunction<double Function(ffi.Pointer<ffi.Int8>)>();

  int SDL_strtol(
    ffi.Pointer<ffi.Int8> str,
    ffi.Pointer<ffi.Pointer<ffi.Int8>> endp,
    int base,
  ) {
    return _SDL_strtol(
      str,
      endp,
      base,
    );
  }

  late final _SDL_strtolPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int64 Function(ffi.Pointer<ffi.Int8>,
              ffi.Pointer<ffi.Pointer<ffi.Int8>>, ffi.Int32)>>('SDL_strtol');
  late final _SDL_strtol = _SDL_strtolPtr.asFunction<
      int Function(
          ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Pointer<ffi.Int8>>, int)>();

  int SDL_strtoul(
    ffi.Pointer<ffi.Int8> str,
    ffi.Pointer<ffi.Pointer<ffi.Int8>> endp,
    int base,
  ) {
    return _SDL_strtoul(
      str,
      endp,
      base,
    );
  }

  late final _SDL_strtoulPtr = _lookup<
      ffi.NativeFunction<
          ffi.Uint64 Function(ffi.Pointer<ffi.Int8>,
              ffi.Pointer<ffi.Pointer<ffi.Int8>>, ffi.Int32)>>('SDL_strtoul');
  late final _SDL_strtoul = _SDL_strtoulPtr.asFunction<
      int Function(
          ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Pointer<ffi.Int8>>, int)>();

  int SDL_strtoll(
    ffi.Pointer<ffi.Int8> str,
    ffi.Pointer<ffi.Pointer<ffi.Int8>> endp,
    int base,
  ) {
    return _SDL_strtoll(
      str,
      endp,
      base,
    );
  }

  late final _SDL_strtollPtr = _lookup<
      ffi.NativeFunction<
          Sint64 Function(ffi.Pointer<ffi.Int8>,
              ffi.Pointer<ffi.Pointer<ffi.Int8>>, ffi.Int32)>>('SDL_strtoll');
  late final _SDL_strtoll = _SDL_strtollPtr.asFunction<
      int Function(
          ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Pointer<ffi.Int8>>, int)>();

  int SDL_strtoull(
    ffi.Pointer<ffi.Int8> str,
    ffi.Pointer<ffi.Pointer<ffi.Int8>> endp,
    int base,
  ) {
    return _SDL_strtoull(
      str,
      endp,
      base,
    );
  }

  late final _SDL_strtoullPtr = _lookup<
      ffi.NativeFunction<
          Uint64 Function(ffi.Pointer<ffi.Int8>,
              ffi.Pointer<ffi.Pointer<ffi.Int8>>, ffi.Int32)>>('SDL_strtoull');
  late final _SDL_strtoull = _SDL_strtoullPtr.asFunction<
      int Function(
          ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Pointer<ffi.Int8>>, int)>();

  double SDL_strtod(
    ffi.Pointer<ffi.Int8> str,
    ffi.Pointer<ffi.Pointer<ffi.Int8>> endp,
  ) {
    return _SDL_strtod(
      str,
      endp,
    );
  }

  late final _SDL_strtodPtr = _lookup<
      ffi.NativeFunction<
          ffi.Double Function(ffi.Pointer<ffi.Int8>,
              ffi.Pointer<ffi.Pointer<ffi.Int8>>)>>('SDL_strtod');
  late final _SDL_strtod = _SDL_strtodPtr.asFunction<
      double Function(
          ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Pointer<ffi.Int8>>)>();

  int SDL_strcmp(
    ffi.Pointer<ffi.Int8> str1,
    ffi.Pointer<ffi.Int8> str2,
  ) {
    return _SDL_strcmp(
      str1,
      str2,
    );
  }

  late final _SDL_strcmpPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Int8>)>>('SDL_strcmp');
  late final _SDL_strcmp = _SDL_strcmpPtr.asFunction<
      int Function(ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Int8>)>();

  int SDL_strncmp(
    ffi.Pointer<ffi.Int8> str1,
    ffi.Pointer<ffi.Int8> str2,
    int maxlen,
  ) {
    return _SDL_strncmp(
      str1,
      str2,
      maxlen,
    );
  }

  late final _SDL_strncmpPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Int8>,
              size_t)>>('SDL_strncmp');
  late final _SDL_strncmp = _SDL_strncmpPtr.asFunction<
      int Function(ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Int8>, int)>();

  int SDL_strcasecmp(
    ffi.Pointer<ffi.Int8> str1,
    ffi.Pointer<ffi.Int8> str2,
  ) {
    return _SDL_strcasecmp(
      str1,
      str2,
    );
  }

  late final _SDL_strcasecmpPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Int8>)>>('SDL_strcasecmp');
  late final _SDL_strcasecmp = _SDL_strcasecmpPtr.asFunction<
      int Function(ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Int8>)>();

  int SDL_strncasecmp(
    ffi.Pointer<ffi.Int8> str1,
    ffi.Pointer<ffi.Int8> str2,
    int len,
  ) {
    return _SDL_strncasecmp(
      str1,
      str2,
      len,
    );
  }

  late final _SDL_strncasecmpPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Int8>,
              size_t)>>('SDL_strncasecmp');
  late final _SDL_strncasecmp = _SDL_strncasecmpPtr.asFunction<
      int Function(ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Int8>, int)>();

  int SDL_sscanf(
    ffi.Pointer<ffi.Int8> text,
    ffi.Pointer<ffi.Int8> fmt,
  ) {
    return _SDL_sscanf(
      text,
      fmt,
    );
  }

  late final _SDL_sscanfPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Int8>)>>('SDL_sscanf');
  late final _SDL_sscanf = _SDL_sscanfPtr.asFunction<
      int Function(ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Int8>)>();

  int SDL_vsscanf(
    ffi.Pointer<ffi.Int8> text,
    ffi.Pointer<ffi.Int8> fmt,
    va_list ap,
  ) {
    return _SDL_vsscanf(
      text,
      fmt,
      ap,
    );
  }

  late final _SDL_vsscanfPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Int8>,
              va_list)>>('SDL_vsscanf');
  late final _SDL_vsscanf = _SDL_vsscanfPtr.asFunction<
      int Function(ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Int8>, va_list)>();

  int SDL_snprintf(
    ffi.Pointer<ffi.Int8> text,
    int maxlen,
    ffi.Pointer<ffi.Int8> fmt,
  ) {
    return _SDL_snprintf(
      text,
      maxlen,
      fmt,
    );
  }

  late final _SDL_snprintfPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<ffi.Int8>, size_t,
              ffi.Pointer<ffi.Int8>)>>('SDL_snprintf');
  late final _SDL_snprintf = _SDL_snprintfPtr.asFunction<
      int Function(ffi.Pointer<ffi.Int8>, int, ffi.Pointer<ffi.Int8>)>();

  int SDL_vsnprintf(
    ffi.Pointer<ffi.Int8> text,
    int maxlen,
    ffi.Pointer<ffi.Int8> fmt,
    va_list ap,
  ) {
    return _SDL_vsnprintf(
      text,
      maxlen,
      fmt,
      ap,
    );
  }

  late final _SDL_vsnprintfPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<ffi.Int8>, size_t,
              ffi.Pointer<ffi.Int8>, va_list)>>('SDL_vsnprintf');
  late final _SDL_vsnprintf = _SDL_vsnprintfPtr.asFunction<
      int Function(
          ffi.Pointer<ffi.Int8>, int, ffi.Pointer<ffi.Int8>, va_list)>();

  int SDL_asprintf(
    ffi.Pointer<ffi.Pointer<ffi.Int8>> strp,
    ffi.Pointer<ffi.Int8> fmt,
  ) {
    return _SDL_asprintf(
      strp,
      fmt,
    );
  }

  late final _SDL_asprintfPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<ffi.Pointer<ffi.Int8>>,
              ffi.Pointer<ffi.Int8>)>>('SDL_asprintf');
  late final _SDL_asprintf = _SDL_asprintfPtr.asFunction<
      int Function(
          ffi.Pointer<ffi.Pointer<ffi.Int8>>, ffi.Pointer<ffi.Int8>)>();

  int SDL_vasprintf(
    ffi.Pointer<ffi.Pointer<ffi.Int8>> strp,
    ffi.Pointer<ffi.Int8> fmt,
    va_list ap,
  ) {
    return _SDL_vasprintf(
      strp,
      fmt,
      ap,
    );
  }

  late final _SDL_vasprintfPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<ffi.Pointer<ffi.Int8>>,
              ffi.Pointer<ffi.Int8>, va_list)>>('SDL_vasprintf');
  late final _SDL_vasprintf = _SDL_vasprintfPtr.asFunction<
      int Function(ffi.Pointer<ffi.Pointer<ffi.Int8>>, ffi.Pointer<ffi.Int8>,
          va_list)>();

  /// Use this function to compute arc cosine of `x`.
  ///
  /// The definition of `y = acos(x)` is `x = cos(y)`.
  ///
  /// Domain: `-1 <= x <= 1`
  ///
  /// Range: `0 <= y <= Pi`
  ///
  /// \param x floating point value, in radians.
  /// \returns arc cosine of `x`.
  ///
  /// \since This function is available since SDL 2.0.2.
  double SDL_acos(
    double x,
  ) {
    return _SDL_acos(
      x,
    );
  }

  late final _SDL_acosPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double)>>('SDL_acos');
  late final _SDL_acos = _SDL_acosPtr.asFunction<double Function(double)>();

  double SDL_acosf(
    double x,
  ) {
    return _SDL_acosf(
      x,
    );
  }

  late final _SDL_acosfPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float)>>('SDL_acosf');
  late final _SDL_acosf = _SDL_acosfPtr.asFunction<double Function(double)>();

  double SDL_asin(
    double x,
  ) {
    return _SDL_asin(
      x,
    );
  }

  late final _SDL_asinPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double)>>('SDL_asin');
  late final _SDL_asin = _SDL_asinPtr.asFunction<double Function(double)>();

  double SDL_asinf(
    double x,
  ) {
    return _SDL_asinf(
      x,
    );
  }

  late final _SDL_asinfPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float)>>('SDL_asinf');
  late final _SDL_asinf = _SDL_asinfPtr.asFunction<double Function(double)>();

  double SDL_atan(
    double x,
  ) {
    return _SDL_atan(
      x,
    );
  }

  late final _SDL_atanPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double)>>('SDL_atan');
  late final _SDL_atan = _SDL_atanPtr.asFunction<double Function(double)>();

  double SDL_atanf(
    double x,
  ) {
    return _SDL_atanf(
      x,
    );
  }

  late final _SDL_atanfPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float)>>('SDL_atanf');
  late final _SDL_atanf = _SDL_atanfPtr.asFunction<double Function(double)>();

  double SDL_atan2(
    double y,
    double x,
  ) {
    return _SDL_atan2(
      y,
      x,
    );
  }

  late final _SDL_atan2Ptr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double, ffi.Double)>>(
          'SDL_atan2');
  late final _SDL_atan2 =
      _SDL_atan2Ptr.asFunction<double Function(double, double)>();

  double SDL_atan2f(
    double y,
    double x,
  ) {
    return _SDL_atan2f(
      y,
      x,
    );
  }

  late final _SDL_atan2fPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float, ffi.Float)>>(
          'SDL_atan2f');
  late final _SDL_atan2f =
      _SDL_atan2fPtr.asFunction<double Function(double, double)>();

  double SDL_ceil(
    double x,
  ) {
    return _SDL_ceil(
      x,
    );
  }

  late final _SDL_ceilPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double)>>('SDL_ceil');
  late final _SDL_ceil = _SDL_ceilPtr.asFunction<double Function(double)>();

  double SDL_ceilf(
    double x,
  ) {
    return _SDL_ceilf(
      x,
    );
  }

  late final _SDL_ceilfPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float)>>('SDL_ceilf');
  late final _SDL_ceilf = _SDL_ceilfPtr.asFunction<double Function(double)>();

  double SDL_copysign(
    double x,
    double y,
  ) {
    return _SDL_copysign(
      x,
      y,
    );
  }

  late final _SDL_copysignPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double, ffi.Double)>>(
          'SDL_copysign');
  late final _SDL_copysign =
      _SDL_copysignPtr.asFunction<double Function(double, double)>();

  double SDL_copysignf(
    double x,
    double y,
  ) {
    return _SDL_copysignf(
      x,
      y,
    );
  }

  late final _SDL_copysignfPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float, ffi.Float)>>(
          'SDL_copysignf');
  late final _SDL_copysignf =
      _SDL_copysignfPtr.asFunction<double Function(double, double)>();

  double SDL_cos(
    double x,
  ) {
    return _SDL_cos(
      x,
    );
  }

  late final _SDL_cosPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double)>>('SDL_cos');
  late final _SDL_cos = _SDL_cosPtr.asFunction<double Function(double)>();

  double SDL_cosf(
    double x,
  ) {
    return _SDL_cosf(
      x,
    );
  }

  late final _SDL_cosfPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float)>>('SDL_cosf');
  late final _SDL_cosf = _SDL_cosfPtr.asFunction<double Function(double)>();

  double SDL_exp(
    double x,
  ) {
    return _SDL_exp(
      x,
    );
  }

  late final _SDL_expPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double)>>('SDL_exp');
  late final _SDL_exp = _SDL_expPtr.asFunction<double Function(double)>();

  double SDL_expf(
    double x,
  ) {
    return _SDL_expf(
      x,
    );
  }

  late final _SDL_expfPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float)>>('SDL_expf');
  late final _SDL_expf = _SDL_expfPtr.asFunction<double Function(double)>();

  double SDL_fabs(
    double x,
  ) {
    return _SDL_fabs(
      x,
    );
  }

  late final _SDL_fabsPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double)>>('SDL_fabs');
  late final _SDL_fabs = _SDL_fabsPtr.asFunction<double Function(double)>();

  double SDL_fabsf(
    double x,
  ) {
    return _SDL_fabsf(
      x,
    );
  }

  late final _SDL_fabsfPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float)>>('SDL_fabsf');
  late final _SDL_fabsf = _SDL_fabsfPtr.asFunction<double Function(double)>();

  double SDL_floor(
    double x,
  ) {
    return _SDL_floor(
      x,
    );
  }

  late final _SDL_floorPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double)>>('SDL_floor');
  late final _SDL_floor = _SDL_floorPtr.asFunction<double Function(double)>();

  double SDL_floorf(
    double x,
  ) {
    return _SDL_floorf(
      x,
    );
  }

  late final _SDL_floorfPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float)>>('SDL_floorf');
  late final _SDL_floorf = _SDL_floorfPtr.asFunction<double Function(double)>();

  double SDL_trunc(
    double x,
  ) {
    return _SDL_trunc(
      x,
    );
  }

  late final _SDL_truncPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double)>>('SDL_trunc');
  late final _SDL_trunc = _SDL_truncPtr.asFunction<double Function(double)>();

  double SDL_truncf(
    double x,
  ) {
    return _SDL_truncf(
      x,
    );
  }

  late final _SDL_truncfPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float)>>('SDL_truncf');
  late final _SDL_truncf = _SDL_truncfPtr.asFunction<double Function(double)>();

  double SDL_fmod(
    double x,
    double y,
  ) {
    return _SDL_fmod(
      x,
      y,
    );
  }

  late final _SDL_fmodPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double, ffi.Double)>>(
          'SDL_fmod');
  late final _SDL_fmod =
      _SDL_fmodPtr.asFunction<double Function(double, double)>();

  double SDL_fmodf(
    double x,
    double y,
  ) {
    return _SDL_fmodf(
      x,
      y,
    );
  }

  late final _SDL_fmodfPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float, ffi.Float)>>(
          'SDL_fmodf');
  late final _SDL_fmodf =
      _SDL_fmodfPtr.asFunction<double Function(double, double)>();

  double SDL_log(
    double x,
  ) {
    return _SDL_log(
      x,
    );
  }

  late final _SDL_logPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double)>>('SDL_log');
  late final _SDL_log = _SDL_logPtr.asFunction<double Function(double)>();

  double SDL_logf(
    double x,
  ) {
    return _SDL_logf(
      x,
    );
  }

  late final _SDL_logfPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float)>>('SDL_logf');
  late final _SDL_logf = _SDL_logfPtr.asFunction<double Function(double)>();

  double SDL_log10(
    double x,
  ) {
    return _SDL_log10(
      x,
    );
  }

  late final _SDL_log10Ptr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double)>>('SDL_log10');
  late final _SDL_log10 = _SDL_log10Ptr.asFunction<double Function(double)>();

  double SDL_log10f(
    double x,
  ) {
    return _SDL_log10f(
      x,
    );
  }

  late final _SDL_log10fPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float)>>('SDL_log10f');
  late final _SDL_log10f = _SDL_log10fPtr.asFunction<double Function(double)>();

  double SDL_pow(
    double x,
    double y,
  ) {
    return _SDL_pow(
      x,
      y,
    );
  }

  late final _SDL_powPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double, ffi.Double)>>(
          'SDL_pow');
  late final _SDL_pow =
      _SDL_powPtr.asFunction<double Function(double, double)>();

  double SDL_powf(
    double x,
    double y,
  ) {
    return _SDL_powf(
      x,
      y,
    );
  }

  late final _SDL_powfPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float, ffi.Float)>>(
          'SDL_powf');
  late final _SDL_powf =
      _SDL_powfPtr.asFunction<double Function(double, double)>();

  double SDL_round(
    double x,
  ) {
    return _SDL_round(
      x,
    );
  }

  late final _SDL_roundPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double)>>('SDL_round');
  late final _SDL_round = _SDL_roundPtr.asFunction<double Function(double)>();

  double SDL_roundf(
    double x,
  ) {
    return _SDL_roundf(
      x,
    );
  }

  late final _SDL_roundfPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float)>>('SDL_roundf');
  late final _SDL_roundf = _SDL_roundfPtr.asFunction<double Function(double)>();

  int SDL_lround(
    double x,
  ) {
    return _SDL_lround(
      x,
    );
  }

  late final _SDL_lroundPtr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(ffi.Double)>>('SDL_lround');
  late final _SDL_lround = _SDL_lroundPtr.asFunction<int Function(double)>();

  int SDL_lroundf(
    double x,
  ) {
    return _SDL_lroundf(
      x,
    );
  }

  late final _SDL_lroundfPtr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(ffi.Float)>>('SDL_lroundf');
  late final _SDL_lroundf = _SDL_lroundfPtr.asFunction<int Function(double)>();

  double SDL_scalbn(
    double x,
    int n,
  ) {
    return _SDL_scalbn(
      x,
      n,
    );
  }

  late final _SDL_scalbnPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double, ffi.Int32)>>(
          'SDL_scalbn');
  late final _SDL_scalbn =
      _SDL_scalbnPtr.asFunction<double Function(double, int)>();

  double SDL_scalbnf(
    double x,
    int n,
  ) {
    return _SDL_scalbnf(
      x,
      n,
    );
  }

  late final _SDL_scalbnfPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float, ffi.Int32)>>(
          'SDL_scalbnf');
  late final _SDL_scalbnf =
      _SDL_scalbnfPtr.asFunction<double Function(double, int)>();

  double SDL_sin(
    double x,
  ) {
    return _SDL_sin(
      x,
    );
  }

  late final _SDL_sinPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double)>>('SDL_sin');
  late final _SDL_sin = _SDL_sinPtr.asFunction<double Function(double)>();

  double SDL_sinf(
    double x,
  ) {
    return _SDL_sinf(
      x,
    );
  }

  late final _SDL_sinfPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float)>>('SDL_sinf');
  late final _SDL_sinf = _SDL_sinfPtr.asFunction<double Function(double)>();

  double SDL_sqrt(
    double x,
  ) {
    return _SDL_sqrt(
      x,
    );
  }

  late final _SDL_sqrtPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double)>>('SDL_sqrt');
  late final _SDL_sqrt = _SDL_sqrtPtr.asFunction<double Function(double)>();

  double SDL_sqrtf(
    double x,
  ) {
    return _SDL_sqrtf(
      x,
    );
  }

  late final _SDL_sqrtfPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float)>>('SDL_sqrtf');
  late final _SDL_sqrtf = _SDL_sqrtfPtr.asFunction<double Function(double)>();

  double SDL_tan(
    double x,
  ) {
    return _SDL_tan(
      x,
    );
  }

  late final _SDL_tanPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double)>>('SDL_tan');
  late final _SDL_tan = _SDL_tanPtr.asFunction<double Function(double)>();

  double SDL_tanf(
    double x,
  ) {
    return _SDL_tanf(
      x,
    );
  }

  late final _SDL_tanfPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float)>>('SDL_tanf');
  late final _SDL_tanf = _SDL_tanfPtr.asFunction<double Function(double)>();

  SDL_iconv_t1 SDL_iconv_open(
    ffi.Pointer<ffi.Int8> tocode,
    ffi.Pointer<ffi.Int8> fromcode,
  ) {
    return _SDL_iconv_open(
      tocode,
      fromcode,
    );
  }

  late final _SDL_iconv_openPtr = _lookup<
      ffi.NativeFunction<
          SDL_iconv_t1 Function(
              ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Int8>)>>('SDL_iconv_open');
  late final _SDL_iconv_open = _SDL_iconv_openPtr.asFunction<
      SDL_iconv_t1 Function(ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Int8>)>();

  int SDL_iconv_close(
    SDL_iconv_t1 cd,
  ) {
    return _SDL_iconv_close(
      cd,
    );
  }

  late final _SDL_iconv_closePtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(SDL_iconv_t1)>>(
          'SDL_iconv_close');
  late final _SDL_iconv_close =
      _SDL_iconv_closePtr.asFunction<int Function(SDL_iconv_t1)>();

  int SDL_iconv(
    SDL_iconv_t1 cd,
    ffi.Pointer<ffi.Pointer<ffi.Int8>> inbuf,
    ffi.Pointer<size_t> inbytesleft,
    ffi.Pointer<ffi.Pointer<ffi.Int8>> outbuf,
    ffi.Pointer<size_t> outbytesleft,
  ) {
    return _SDL_iconv(
      cd,
      inbuf,
      inbytesleft,
      outbuf,
      outbytesleft,
    );
  }

  late final _SDL_iconvPtr = _lookup<
      ffi.NativeFunction<
          size_t Function(
              SDL_iconv_t1,
              ffi.Pointer<ffi.Pointer<ffi.Int8>>,
              ffi.Pointer<size_t>,
              ffi.Pointer<ffi.Pointer<ffi.Int8>>,
              ffi.Pointer<size_t>)>>('SDL_iconv');
  late final _SDL_iconv = _SDL_iconvPtr.asFunction<
      int Function(
          SDL_iconv_t1,
          ffi.Pointer<ffi.Pointer<ffi.Int8>>,
          ffi.Pointer<size_t>,
          ffi.Pointer<ffi.Pointer<ffi.Int8>>,
          ffi.Pointer<size_t>)>();

  /// This function converts a string between encodings in one pass, returning a
  /// string that must be freed with SDL_free() or NULL on error.
  ///
  /// \since This function is available since SDL 2.0.0.
  ffi.Pointer<ffi.Int8> SDL_iconv_string(
    ffi.Pointer<ffi.Int8> tocode,
    ffi.Pointer<ffi.Int8> fromcode,
    ffi.Pointer<ffi.Int8> inbuf,
    int inbytesleft,
  ) {
    return _SDL_iconv_string(
      tocode,
      fromcode,
      inbuf,
      inbytesleft,
    );
  }

  late final _SDL_iconv_stringPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Int8> Function(
              ffi.Pointer<ffi.Int8>,
              ffi.Pointer<ffi.Int8>,
              ffi.Pointer<ffi.Int8>,
              size_t)>>('SDL_iconv_string');
  late final _SDL_iconv_string = _SDL_iconv_stringPtr.asFunction<
      ffi.Pointer<ffi.Int8> Function(ffi.Pointer<ffi.Int8>,
          ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Int8>, int)>();

  int SDL_main(
    int argc,
    ffi.Pointer<ffi.Pointer<ffi.Int8>> argv,
  ) {
    return _SDL_main(
      argc,
      argv,
    );
  }

  late final _SDL_mainPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Int32, ffi.Pointer<ffi.Pointer<ffi.Int8>>)>>('SDL_main');
  late final _SDL_main = _SDL_mainPtr.asFunction<
      int Function(int, ffi.Pointer<ffi.Pointer<ffi.Int8>>)>();

  /// Circumvent failure of SDL_Init() when not using SDL_main() as an entry
  /// point.
  ///
  /// This function is defined in SDL_main.h, along with the preprocessor rule to
  /// redefine main() as SDL_main(). Thus to ensure that your main() function
  /// will not be changed it is necessary to define SDL_MAIN_HANDLED before
  /// including SDL.h.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_Init
  void SDL_SetMainReady() {
    return _SDL_SetMainReady();
  }

  late final _SDL_SetMainReadyPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('SDL_SetMainReady');
  late final _SDL_SetMainReady =
      _SDL_SetMainReadyPtr.asFunction<void Function()>();

  /// Register a win32 window class for SDL's use.
  ///
  /// This can be called to set the application window class at startup. It is
  /// safe to call this multiple times, as long as every call is eventually
  /// paired with a call to SDL_UnregisterApp, but a second registration attempt
  /// while a previous registration is still active will be ignored, other than
  /// to increment a counter.
  ///
  /// Most applications do not need to, and should not, call this directly; SDL
  /// will call it when initializing the video subsystem.
  ///
  /// \param name the window class name, in UTF-8 encoding. If NULL, SDL
  /// currently uses "SDL_app" but this isn't guaranteed.
  /// \param style the value to use in WNDCLASSEX::style. If `name` is NULL, SDL
  /// currently uses `(CS_BYTEALIGNCLIENT | CS_OWNDC)` regardless of
  /// what is specified here.
  /// \param hInst the HINSTANCE to use in WNDCLASSEX::hInstance. If zero, SDL
  /// will use `GetModuleHandle(NULL)` instead.
  /// \returns 0 on success, -1 on error. SDL_GetError() may have details.
  ///
  /// \since This function is available since SDL 2.0.2.
  int SDL_RegisterApp(
    ffi.Pointer<ffi.Int8> name,
    int style,
    ffi.Pointer<ffi.Void> hInst,
  ) {
    return _SDL_RegisterApp(
      name,
      style,
      hInst,
    );
  }

  late final _SDL_RegisterAppPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<ffi.Int8>, Uint32,
              ffi.Pointer<ffi.Void>)>>('SDL_RegisterApp');
  late final _SDL_RegisterApp = _SDL_RegisterAppPtr.asFunction<
      int Function(ffi.Pointer<ffi.Int8>, int, ffi.Pointer<ffi.Void>)>();

  /// Deregister the win32 window class from an SDL_RegisterApp call.
  ///
  /// This can be called to undo the effects of SDL_RegisterApp.
  ///
  /// Most applications do not need to, and should not, call this directly; SDL
  /// will call it when deinitializing the video subsystem.
  ///
  /// It is safe to call this multiple times, as long as every call is eventually
  /// paired with a prior call to SDL_RegisterApp. The window class will only be
  /// deregistered when the registration counter in SDL_RegisterApp decrements to
  /// zero through calls to this function.
  ///
  /// \since This function is available since SDL 2.0.2.
  void SDL_UnregisterApp() {
    return _SDL_UnregisterApp();
  }

  late final _SDL_UnregisterAppPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('SDL_UnregisterApp');
  late final _SDL_UnregisterApp =
      _SDL_UnregisterAppPtr.asFunction<void Function()>();

  void __debugbreak() {
    return ___debugbreak();
  }

  late final ___debugbreakPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('__debugbreak');
  late final ___debugbreak = ___debugbreakPtr.asFunction<void Function()>();

  int SDL_ReportAssertion(
    ffi.Pointer<SDL_AssertData> arg0,
    ffi.Pointer<ffi.Int8> arg1,
    ffi.Pointer<ffi.Int8> arg2,
    int arg3,
  ) {
    return _SDL_ReportAssertion(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final _SDL_ReportAssertionPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_AssertData>, ffi.Pointer<ffi.Int8>,
              ffi.Pointer<ffi.Int8>, ffi.Int32)>>('SDL_ReportAssertion');
  late final _SDL_ReportAssertion = _SDL_ReportAssertionPtr.asFunction<
      int Function(ffi.Pointer<SDL_AssertData>, ffi.Pointer<ffi.Int8>,
          ffi.Pointer<ffi.Int8>, int)>();

  /// Set an application-defined assertion handler.
  ///
  /// This function allows an application to show its own assertion UI and/or
  /// force the response to an assertion failure. If the application doesn't
  /// provide this, SDL will try to do the right thing, popping up a
  /// system-specific GUI dialog, and probably minimizing any fullscreen windows.
  ///
  /// This callback may fire from any thread, but it runs wrapped in a mutex, so
  /// it will only fire from one thread at a time.
  ///
  /// This callback is NOT reset to SDL's internal handler upon SDL_Quit()!
  ///
  /// \param handler the SDL_AssertionHandler function to call when an assertion
  /// fails or NULL for the default handler
  /// \param userdata a pointer that is passed to `handler`
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetAssertionHandler
  void SDL_SetAssertionHandler(
    SDL_AssertionHandler handler,
    ffi.Pointer<ffi.Void> userdata,
  ) {
    return _SDL_SetAssertionHandler(
      handler,
      userdata,
    );
  }

  late final _SDL_SetAssertionHandlerPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(SDL_AssertionHandler,
              ffi.Pointer<ffi.Void>)>>('SDL_SetAssertionHandler');
  late final _SDL_SetAssertionHandler = _SDL_SetAssertionHandlerPtr.asFunction<
      void Function(SDL_AssertionHandler, ffi.Pointer<ffi.Void>)>();

  /// Get the default assertion handler.
  ///
  /// This returns the function pointer that is called by default when an
  /// assertion is triggered. This is an internal function provided by SDL, that
  /// is used for assertions when SDL_SetAssertionHandler() hasn't been used to
  /// provide a different function.
  ///
  /// \returns the default SDL_AssertionHandler that is called when an assert
  /// triggers.
  ///
  /// \since This function is available since SDL 2.0.2.
  ///
  /// \sa SDL_GetAssertionHandler
  SDL_AssertionHandler SDL_GetDefaultAssertionHandler() {
    return _SDL_GetDefaultAssertionHandler();
  }

  late final _SDL_GetDefaultAssertionHandlerPtr =
      _lookup<ffi.NativeFunction<SDL_AssertionHandler Function()>>(
          'SDL_GetDefaultAssertionHandler');
  late final _SDL_GetDefaultAssertionHandler =
      _SDL_GetDefaultAssertionHandlerPtr.asFunction<
          SDL_AssertionHandler Function()>();

  /// Get the current assertion handler.
  ///
  /// This returns the function pointer that is called when an assertion is
  /// triggered. This is either the value last passed to
  /// SDL_SetAssertionHandler(), or if no application-specified function is set,
  /// is equivalent to calling SDL_GetDefaultAssertionHandler().
  ///
  /// The parameter `puserdata` is a pointer to a void*, which will store the
  /// "userdata" pointer that was passed to SDL_SetAssertionHandler(). This value
  /// will always be NULL for the default handler. If you don't care about this
  /// data, it is safe to pass a NULL pointer to this function to ignore it.
  ///
  /// \param puserdata pointer which is filled with the "userdata" pointer that
  /// was passed to SDL_SetAssertionHandler()
  /// \returns the SDL_AssertionHandler that is called when an assert triggers.
  ///
  /// \since This function is available since SDL 2.0.2.
  ///
  /// \sa SDL_SetAssertionHandler
  SDL_AssertionHandler SDL_GetAssertionHandler(
    ffi.Pointer<ffi.Pointer<ffi.Void>> puserdata,
  ) {
    return _SDL_GetAssertionHandler(
      puserdata,
    );
  }

  late final _SDL_GetAssertionHandlerPtr = _lookup<
      ffi.NativeFunction<
          SDL_AssertionHandler Function(
              ffi.Pointer<ffi.Pointer<ffi.Void>>)>>('SDL_GetAssertionHandler');
  late final _SDL_GetAssertionHandler = _SDL_GetAssertionHandlerPtr.asFunction<
      SDL_AssertionHandler Function(ffi.Pointer<ffi.Pointer<ffi.Void>>)>();

  /// Get a list of all assertion failures.
  ///
  /// This function gets all assertions triggered since the last call to
  /// SDL_ResetAssertionReport(), or the start of the program.
  ///
  /// The proper way to examine this data looks something like this:
  ///
  /// ```c
  /// const SDL_AssertData *item = SDL_GetAssertionReport();
  /// while (item) {
  /// printf("'%s', %s (%s:%d), triggered %u times, always ignore: %s.\\n",
  /// item->condition, item->function, item->filename,
  /// item->linenum, item->trigger_count,
  /// item->always_ignore ? "yes" : "no");
  /// item = item->next;
  /// }
  /// ```
  ///
  /// \returns a list of all failed assertions or NULL if the list is empty. This
  /// memory should not be modified or freed by the application.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_ResetAssertionReport
  ffi.Pointer<SDL_AssertData> SDL_GetAssertionReport() {
    return _SDL_GetAssertionReport();
  }

  late final _SDL_GetAssertionReportPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<SDL_AssertData> Function()>>(
          'SDL_GetAssertionReport');
  late final _SDL_GetAssertionReport = _SDL_GetAssertionReportPtr.asFunction<
      ffi.Pointer<SDL_AssertData> Function()>();

  /// Clear the list of all assertion failures.
  ///
  /// This function will clear the list of all assertions triggered up to that
  /// point. Immediately following this call, SDL_GetAssertionReport will return
  /// no items. In addition, any previously-triggered assertions will be reset to
  /// a trigger_count of zero, and their always_ignore state will be false.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetAssertionReport
  void SDL_ResetAssertionReport() {
    return _SDL_ResetAssertionReport();
  }

  late final _SDL_ResetAssertionReportPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>(
          'SDL_ResetAssertionReport');
  late final _SDL_ResetAssertionReport =
      _SDL_ResetAssertionReportPtr.asFunction<void Function()>();

  /// Try to lock a spin lock by setting it to a non-zero value.
  ///
  /// ***Please note that spinlocks are dangerous if you don't know what you're
  /// doing. Please be careful using any sort of spinlock!***
  ///
  /// \param lock a pointer to a lock variable
  /// \returns SDL_TRUE if the lock succeeded, SDL_FALSE if the lock is already
  /// held.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_AtomicLock
  /// \sa SDL_AtomicUnlock
  int SDL_AtomicTryLock(
    ffi.Pointer<SDL_SpinLock> lock,
  ) {
    return _SDL_AtomicTryLock(
      lock,
    );
  }

  late final _SDL_AtomicTryLockPtr = _lookup<
          ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<SDL_SpinLock>)>>(
      'SDL_AtomicTryLock');
  late final _SDL_AtomicTryLock = _SDL_AtomicTryLockPtr.asFunction<
      int Function(ffi.Pointer<SDL_SpinLock>)>();

  /// Lock a spin lock by setting it to a non-zero value.
  ///
  /// ***Please note that spinlocks are dangerous if you don't know what you're
  /// doing. Please be careful using any sort of spinlock!***
  ///
  /// \param lock a pointer to a lock variable
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_AtomicTryLock
  /// \sa SDL_AtomicUnlock
  void SDL_AtomicLock(
    ffi.Pointer<SDL_SpinLock> lock,
  ) {
    return _SDL_AtomicLock(
      lock,
    );
  }

  late final _SDL_AtomicLockPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<SDL_SpinLock>)>>(
          'SDL_AtomicLock');
  late final _SDL_AtomicLock =
      _SDL_AtomicLockPtr.asFunction<void Function(ffi.Pointer<SDL_SpinLock>)>();

  /// Unlock a spin lock by setting it to 0.
  ///
  /// Always returns immediately.
  ///
  /// ***Please note that spinlocks are dangerous if you don't know what you're
  /// doing. Please be careful using any sort of spinlock!***
  ///
  /// \param lock a pointer to a lock variable
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_AtomicLock
  /// \sa SDL_AtomicTryLock
  void SDL_AtomicUnlock(
    ffi.Pointer<SDL_SpinLock> lock,
  ) {
    return _SDL_AtomicUnlock(
      lock,
    );
  }

  late final _SDL_AtomicUnlockPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<SDL_SpinLock>)>>(
          'SDL_AtomicUnlock');
  late final _SDL_AtomicUnlock = _SDL_AtomicUnlockPtr.asFunction<
      void Function(ffi.Pointer<SDL_SpinLock>)>();

  /// Memory barriers are designed to prevent reads and writes from being
  /// reordered by the compiler and being seen out of order on multi-core CPUs.
  ///
  /// A typical pattern would be for thread A to write some data and a flag, and
  /// for thread B to read the flag and get the data. In this case you would
  /// insert a release barrier between writing the data and the flag,
  /// guaranteeing that the data write completes no later than the flag is
  /// written, and you would insert an acquire barrier between reading the flag
  /// and reading the data, to ensure that all the reads associated with the flag
  /// have completed.
  ///
  /// In this pattern you should always see a release barrier paired with an
  /// acquire barrier and you should gate the data reads/writes with a single
  /// flag variable.
  ///
  /// For more information on these semantics, take a look at the blog post:
  /// http://preshing.com/20120913/acquire-and-release-semantics
  ///
  /// \since This function is available since SDL 2.0.6.
  void SDL_MemoryBarrierReleaseFunction() {
    return _SDL_MemoryBarrierReleaseFunction();
  }

  late final _SDL_MemoryBarrierReleaseFunctionPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>(
          'SDL_MemoryBarrierReleaseFunction');
  late final _SDL_MemoryBarrierReleaseFunction =
      _SDL_MemoryBarrierReleaseFunctionPtr.asFunction<void Function()>();

  void SDL_MemoryBarrierAcquireFunction() {
    return _SDL_MemoryBarrierAcquireFunction();
  }

  late final _SDL_MemoryBarrierAcquireFunctionPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>(
          'SDL_MemoryBarrierAcquireFunction');
  late final _SDL_MemoryBarrierAcquireFunction =
      _SDL_MemoryBarrierAcquireFunctionPtr.asFunction<void Function()>();

  /// Set an atomic variable to a new value if it is currently an old value.
  ///
  /// ***Note: If you don't know what this function is for, you shouldn't use
  /// it!***
  ///
  /// \param a a pointer to an SDL_atomic_t variable to be modified
  /// \param oldval the old value
  /// \param newval the new value
  /// \returns SDL_TRUE if the atomic variable was set, SDL_FALSE otherwise.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_AtomicCASPtr
  /// \sa SDL_AtomicGet
  /// \sa SDL_AtomicSet
  int SDL_AtomicCAS(
    ffi.Pointer<SDL_atomic_t> a,
    int oldval,
    int newval,
  ) {
    return _SDL_AtomicCAS(
      a,
      oldval,
      newval,
    );
  }

  late final _SDL_AtomicCASPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_atomic_t>, ffi.Int32,
              ffi.Int32)>>('SDL_AtomicCAS');
  late final _SDL_AtomicCAS = _SDL_AtomicCASPtr.asFunction<
      int Function(ffi.Pointer<SDL_atomic_t>, int, int)>();

  /// Set an atomic variable to a value.
  ///
  /// This function also acts as a full memory barrier.
  ///
  /// ***Note: If you don't know what this function is for, you shouldn't use
  /// it!***
  ///
  /// \param a a pointer to an SDL_atomic_t variable to be modified
  /// \param v the desired value
  /// \returns the previous value of the atomic variable.
  ///
  /// \since This function is available since SDL 2.0.2.
  ///
  /// \sa SDL_AtomicGet
  int SDL_AtomicSet(
    ffi.Pointer<SDL_atomic_t> a,
    int v,
  ) {
    return _SDL_AtomicSet(
      a,
      v,
    );
  }

  late final _SDL_AtomicSetPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<SDL_atomic_t>, ffi.Int32)>>('SDL_AtomicSet');
  late final _SDL_AtomicSet = _SDL_AtomicSetPtr.asFunction<
      int Function(ffi.Pointer<SDL_atomic_t>, int)>();

  /// Get the value of an atomic variable.
  ///
  /// ***Note: If you don't know what this function is for, you shouldn't use
  /// it!***
  ///
  /// \param a a pointer to an SDL_atomic_t variable
  /// \returns the current value of an atomic variable.
  ///
  /// \since This function is available since SDL 2.0.2.
  ///
  /// \sa SDL_AtomicSet
  int SDL_AtomicGet(
    ffi.Pointer<SDL_atomic_t> a,
  ) {
    return _SDL_AtomicGet(
      a,
    );
  }

  late final _SDL_AtomicGetPtr = _lookup<
          ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<SDL_atomic_t>)>>(
      'SDL_AtomicGet');
  late final _SDL_AtomicGet =
      _SDL_AtomicGetPtr.asFunction<int Function(ffi.Pointer<SDL_atomic_t>)>();

  /// Add to an atomic variable.
  ///
  /// This function also acts as a full memory barrier.
  ///
  /// ***Note: If you don't know what this function is for, you shouldn't use
  /// it!***
  ///
  /// \param a a pointer to an SDL_atomic_t variable to be modified
  /// \param v the desired value to add
  /// \returns the previous value of the atomic variable.
  ///
  /// \since This function is available since SDL 2.0.2.
  ///
  /// \sa SDL_AtomicDecRef
  /// \sa SDL_AtomicIncRef
  int SDL_AtomicAdd(
    ffi.Pointer<SDL_atomic_t> a,
    int v,
  ) {
    return _SDL_AtomicAdd(
      a,
      v,
    );
  }

  late final _SDL_AtomicAddPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<SDL_atomic_t>, ffi.Int32)>>('SDL_AtomicAdd');
  late final _SDL_AtomicAdd = _SDL_AtomicAddPtr.asFunction<
      int Function(ffi.Pointer<SDL_atomic_t>, int)>();

  /// Set a pointer to a new value if it is currently an old value.
  ///
  /// ***Note: If you don't know what this function is for, you shouldn't use
  /// it!***
  ///
  /// \param a a pointer to a pointer
  /// \param oldval the old pointer value
  /// \param newval the new pointer value
  /// \returns SDL_TRUE if the pointer was set, SDL_FALSE otherwise.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_AtomicCAS
  /// \sa SDL_AtomicGetPtr
  /// \sa SDL_AtomicSetPtr
  int SDL_AtomicCASPtr(
    ffi.Pointer<ffi.Pointer<ffi.Void>> a,
    ffi.Pointer<ffi.Void> oldval,
    ffi.Pointer<ffi.Void> newval,
  ) {
    return _SDL_AtomicCASPtr1(
      a,
      oldval,
      newval,
    );
  }

  late final _SDL_AtomicCASPtrPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<ffi.Pointer<ffi.Void>>,
              ffi.Pointer<ffi.Void>,
              ffi.Pointer<ffi.Void>)>>('SDL_AtomicCASPtr');
  late final _SDL_AtomicCASPtr1 = _SDL_AtomicCASPtrPtr.asFunction<
      int Function(ffi.Pointer<ffi.Pointer<ffi.Void>>, ffi.Pointer<ffi.Void>,
          ffi.Pointer<ffi.Void>)>();

  /// Set a pointer to a value atomically.
  ///
  /// ***Note: If you don't know what this function is for, you shouldn't use
  /// it!***
  ///
  /// \param a a pointer to a pointer
  /// \param v the desired pointer value
  /// \returns the previous value of the pointer.
  ///
  /// \since This function is available since SDL 2.0.2.
  ///
  /// \sa SDL_AtomicCASPtr
  /// \sa SDL_AtomicGetPtr
  ffi.Pointer<ffi.Void> SDL_AtomicSetPtr(
    ffi.Pointer<ffi.Pointer<ffi.Void>> a,
    ffi.Pointer<ffi.Void> v,
  ) {
    return _SDL_AtomicSetPtr1(
      a,
      v,
    );
  }

  late final _SDL_AtomicSetPtrPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Void> Function(ffi.Pointer<ffi.Pointer<ffi.Void>>,
              ffi.Pointer<ffi.Void>)>>('SDL_AtomicSetPtr');
  late final _SDL_AtomicSetPtr1 = _SDL_AtomicSetPtrPtr.asFunction<
      ffi.Pointer<ffi.Void> Function(
          ffi.Pointer<ffi.Pointer<ffi.Void>>, ffi.Pointer<ffi.Void>)>();

  /// Get the value of a pointer atomically.
  ///
  /// ***Note: If you don't know what this function is for, you shouldn't use
  /// it!***
  ///
  /// \param a a pointer to a pointer
  /// \returns the current value of a pointer.
  ///
  /// \since This function is available since SDL 2.0.2.
  ///
  /// \sa SDL_AtomicCASPtr
  /// \sa SDL_AtomicSetPtr
  ffi.Pointer<ffi.Void> SDL_AtomicGetPtr(
    ffi.Pointer<ffi.Pointer<ffi.Void>> a,
  ) {
    return _SDL_AtomicGetPtr1(
      a,
    );
  }

  late final _SDL_AtomicGetPtrPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Void> Function(
              ffi.Pointer<ffi.Pointer<ffi.Void>>)>>('SDL_AtomicGetPtr');
  late final _SDL_AtomicGetPtr1 = _SDL_AtomicGetPtrPtr.asFunction<
      ffi.Pointer<ffi.Void> Function(ffi.Pointer<ffi.Pointer<ffi.Void>>)>();

  /// Set the SDL error message for the current thread.
  ///
  /// Calling this function will replace any previous error message that was set.
  ///
  /// This function always returns -1, since SDL frequently uses -1 to signify an
  /// failing result, leading to this idiom:
  ///
  /// ```c
  /// if (error_code) {
  /// return SDL_SetError("This operation has failed: %d", error_code);
  /// }
  /// ```
  ///
  /// \param fmt a printf()-style message format string
  /// \param ... additional parameters matching % tokens in the `fmt` string, if
  /// any
  /// \returns always -1.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_ClearError
  /// \sa SDL_GetError
  int SDL_SetError(
    ffi.Pointer<ffi.Int8> fmt,
  ) {
    return _SDL_SetError(
      fmt,
    );
  }

  late final _SDL_SetErrorPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<ffi.Int8>)>>(
          'SDL_SetError');
  late final _SDL_SetError =
      _SDL_SetErrorPtr.asFunction<int Function(ffi.Pointer<ffi.Int8>)>();

  /// Retrieve a message about the last error that occurred on the current
  /// thread.
  ///
  /// It is possible for multiple errors to occur before calling SDL_GetError().
  /// Only the last error is returned.
  ///
  /// The message is only applicable when an SDL function has signaled an error.
  /// You must check the return values of SDL function calls to determine when to
  /// appropriately call SDL_GetError(). You should *not* use the results of
  /// SDL_GetError() to decide if an error has occurred! Sometimes SDL will set
  /// an error string even when reporting success.
  ///
  /// SDL will *not* clear the error string for successful API calls. You *must*
  /// check return values for failure cases before you can assume the error
  /// string applies.
  ///
  /// Error strings are set per-thread, so an error set in a different thread
  /// will not interfere with the current thread's operation.
  ///
  /// The returned string is internally allocated and must not be freed by the
  /// application.
  ///
  /// \returns a message with information about the specific error that occurred,
  /// or an empty string if there hasn't been an error message set since
  /// the last call to SDL_ClearError(). The message is only applicable
  /// when an SDL function has signaled an error. You must check the
  /// return values of SDL function calls to determine when to
  /// appropriately call SDL_GetError().
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_ClearError
  /// \sa SDL_SetError
  ffi.Pointer<ffi.Int8> SDL_GetError() {
    return _SDL_GetError();
  }

  late final _SDL_GetErrorPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Int8> Function()>>(
          'SDL_GetError');
  late final _SDL_GetError =
      _SDL_GetErrorPtr.asFunction<ffi.Pointer<ffi.Int8> Function()>();

  /// Get the last error message that was set for the current thread.
  ///
  /// This allows the caller to copy the error string into a provided buffer, but
  /// otherwise operates exactly the same as SDL_GetError().
  ///
  /// \param errstr A buffer to fill with the last error message that was set for
  /// the current thread
  /// \param maxlen The size of the buffer pointed to by the errstr parameter
  /// \returns the pointer passed in as the `errstr` parameter.
  ///
  /// \since This function is available since SDL 2.0.14.
  ///
  /// \sa SDL_GetError
  ffi.Pointer<ffi.Int8> SDL_GetErrorMsg(
    ffi.Pointer<ffi.Int8> errstr,
    int maxlen,
  ) {
    return _SDL_GetErrorMsg(
      errstr,
      maxlen,
    );
  }

  late final _SDL_GetErrorMsgPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Int8> Function(
              ffi.Pointer<ffi.Int8>, ffi.Int32)>>('SDL_GetErrorMsg');
  late final _SDL_GetErrorMsg = _SDL_GetErrorMsgPtr.asFunction<
      ffi.Pointer<ffi.Int8> Function(ffi.Pointer<ffi.Int8>, int)>();

  /// Clear any previous error message for this thread.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetError
  /// \sa SDL_SetError
  void SDL_ClearError() {
    return _SDL_ClearError();
  }

  late final _SDL_ClearErrorPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('SDL_ClearError');
  late final _SDL_ClearError = _SDL_ClearErrorPtr.asFunction<void Function()>();

  int SDL_Error(
    int code,
  ) {
    return _SDL_Error(
      code,
    );
  }

  late final _SDL_ErrorPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Int32)>>('SDL_Error');
  late final _SDL_Error = _SDL_ErrorPtr.asFunction<int Function(int)>();

  int _BitScanForward(
    ffi.Pointer<ffi.Uint64> _Index,
    int _Mask,
  ) {
    return __BitScanForward(
      _Index,
      _Mask,
    );
  }

  late final __BitScanForwardPtr = _lookup<
      ffi.NativeFunction<
          ffi.Uint8 Function(
              ffi.Pointer<ffi.Uint64>, ffi.Uint64)>>('_BitScanForward');
  late final __BitScanForward = __BitScanForwardPtr
      .asFunction<int Function(ffi.Pointer<ffi.Uint64>, int)>();

  int _BitScanForward64(
    ffi.Pointer<ffi.Uint64> _Index,
    int _Mask,
  ) {
    return __BitScanForward64(
      _Index,
      _Mask,
    );
  }

  late final __BitScanForward64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Uint8 Function(
              ffi.Pointer<ffi.Uint64>, ffi.Uint64)>>('_BitScanForward64');
  late final __BitScanForward64 = __BitScanForward64Ptr
      .asFunction<int Function(ffi.Pointer<ffi.Uint64>, int)>();

  int _BitScanReverse(
    ffi.Pointer<ffi.Uint64> _Index,
    int _Mask,
  ) {
    return __BitScanReverse(
      _Index,
      _Mask,
    );
  }

  late final __BitScanReversePtr = _lookup<
      ffi.NativeFunction<
          ffi.Uint8 Function(
              ffi.Pointer<ffi.Uint64>, ffi.Uint64)>>('_BitScanReverse');
  late final __BitScanReverse = __BitScanReversePtr
      .asFunction<int Function(ffi.Pointer<ffi.Uint64>, int)>();

  int _BitScanReverse64(
    ffi.Pointer<ffi.Uint64> _Index,
    int _Mask,
  ) {
    return __BitScanReverse64(
      _Index,
      _Mask,
    );
  }

  late final __BitScanReverse64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Uint8 Function(
              ffi.Pointer<ffi.Uint64>, ffi.Uint64)>>('_BitScanReverse64');
  late final __BitScanReverse64 = __BitScanReverse64Ptr
      .asFunction<int Function(ffi.Pointer<ffi.Uint64>, int)>();

  int _bittest(
    ffi.Pointer<ffi.Int64> arg0,
    int arg1,
  ) {
    return __bittest(
      arg0,
      arg1,
    );
  }

  late final __bittestPtr = _lookup<
      ffi.NativeFunction<
          ffi.Uint8 Function(ffi.Pointer<ffi.Int64>, ffi.Int64)>>('_bittest');
  late final __bittest =
      __bittestPtr.asFunction<int Function(ffi.Pointer<ffi.Int64>, int)>();

  int _InterlockedAnd(
    ffi.Pointer<ffi.Int64> _Value,
    int _Mask,
  ) {
    return __InterlockedAnd(
      _Value,
      _Mask,
    );
  }

  late final __InterlockedAndPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int64 Function(
              ffi.Pointer<ffi.Int64>, ffi.Int64)>>('_InterlockedAnd');
  late final __InterlockedAnd = __InterlockedAndPtr
      .asFunction<int Function(ffi.Pointer<ffi.Int64>, int)>();

  int _InterlockedAnd16(
    ffi.Pointer<ffi.Int16> _Value,
    int _Mask,
  ) {
    return __InterlockedAnd16(
      _Value,
      _Mask,
    );
  }

  late final __InterlockedAnd16Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Int16 Function(
              ffi.Pointer<ffi.Int16>, ffi.Int16)>>('_InterlockedAnd16');
  late final __InterlockedAnd16 = __InterlockedAnd16Ptr
      .asFunction<int Function(ffi.Pointer<ffi.Int16>, int)>();

  int _InterlockedAnd64(
    ffi.Pointer<ffi.Int64> _Value,
    int _Mask,
  ) {
    return __InterlockedAnd64(
      _Value,
      _Mask,
    );
  }

  late final __InterlockedAnd64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Int64 Function(
              ffi.Pointer<ffi.Int64>, ffi.Int64)>>('_InterlockedAnd64');
  late final __InterlockedAnd64 = __InterlockedAnd64Ptr
      .asFunction<int Function(ffi.Pointer<ffi.Int64>, int)>();

  int _interlockedand64(
    ffi.Pointer<ffi.Int64> _Value,
    int _Mask,
  ) {
    return __interlockedand64(
      _Value,
      _Mask,
    );
  }

  late final __interlockedand64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Int64 Function(
              ffi.Pointer<ffi.Int64>, ffi.Int64)>>('_interlockedand64');
  late final __interlockedand64 = __interlockedand64Ptr
      .asFunction<int Function(ffi.Pointer<ffi.Int64>, int)>();

  int _InterlockedAnd8(
    ffi.Pointer<ffi.Int8> _Value,
    int _Mask,
  ) {
    return __InterlockedAnd8(
      _Value,
      _Mask,
    );
  }

  late final __InterlockedAnd8Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Int8 Function(
              ffi.Pointer<ffi.Int8>, ffi.Int8)>>('_InterlockedAnd8');
  late final __InterlockedAnd8 = __InterlockedAnd8Ptr
      .asFunction<int Function(ffi.Pointer<ffi.Int8>, int)>();

  int _InterlockedCompareExchange(
    ffi.Pointer<ffi.Int64> _Destination,
    int _Exchange,
    int _Comparand,
  ) {
    return __InterlockedCompareExchange(
      _Destination,
      _Exchange,
      _Comparand,
    );
  }

  late final __InterlockedCompareExchangePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int64 Function(ffi.Pointer<ffi.Int64>, ffi.Int64,
              ffi.Int64)>>('_InterlockedCompareExchange');
  late final __InterlockedCompareExchange = __InterlockedCompareExchangePtr
      .asFunction<int Function(ffi.Pointer<ffi.Int64>, int, int)>();

  int _InterlockedCompareExchange16(
    ffi.Pointer<ffi.Int16> _Destination,
    int _Exchange,
    int _Comparand,
  ) {
    return __InterlockedCompareExchange16(
      _Destination,
      _Exchange,
      _Comparand,
    );
  }

  late final __InterlockedCompareExchange16Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Int16 Function(ffi.Pointer<ffi.Int16>, ffi.Int16,
              ffi.Int16)>>('_InterlockedCompareExchange16');
  late final __InterlockedCompareExchange16 = __InterlockedCompareExchange16Ptr
      .asFunction<int Function(ffi.Pointer<ffi.Int16>, int, int)>();

  int _InterlockedCompareExchange64(
    ffi.Pointer<ffi.Int64> _Destination,
    int _Exchange,
    int _Comparand,
  ) {
    return __InterlockedCompareExchange64(
      _Destination,
      _Exchange,
      _Comparand,
    );
  }

  late final __InterlockedCompareExchange64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Int64 Function(ffi.Pointer<ffi.Int64>, ffi.Int64,
              ffi.Int64)>>('_InterlockedCompareExchange64');
  late final __InterlockedCompareExchange64 = __InterlockedCompareExchange64Ptr
      .asFunction<int Function(ffi.Pointer<ffi.Int64>, int, int)>();

  int _InterlockedCompareExchange8(
    ffi.Pointer<ffi.Int8> _Destination,
    int _Exchange,
    int _Comparand,
  ) {
    return __InterlockedCompareExchange8(
      _Destination,
      _Exchange,
      _Comparand,
    );
  }

  late final __InterlockedCompareExchange8Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Int8 Function(ffi.Pointer<ffi.Int8>, ffi.Int8,
              ffi.Int8)>>('_InterlockedCompareExchange8');
  late final __InterlockedCompareExchange8 = __InterlockedCompareExchange8Ptr
      .asFunction<int Function(ffi.Pointer<ffi.Int8>, int, int)>();

  int _InterlockedCompareExchange128(
    ffi.Pointer<ffi.Int64> _Destination,
    int _ExchangeHigh,
    int _ExchangeLow,
    ffi.Pointer<ffi.Int64> _ComparandResult,
  ) {
    return __InterlockedCompareExchange128(
      _Destination,
      _ExchangeHigh,
      _ExchangeLow,
      _ComparandResult,
    );
  }

  late final __InterlockedCompareExchange128Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Uint8 Function(ffi.Pointer<ffi.Int64>, ffi.Int64, ffi.Int64,
              ffi.Pointer<ffi.Int64>)>>('_InterlockedCompareExchange128');
  late final __InterlockedCompareExchange128 =
      __InterlockedCompareExchange128Ptr.asFunction<
          int Function(
              ffi.Pointer<ffi.Int64>, int, int, ffi.Pointer<ffi.Int64>)>();

  int _InterlockedDecrement(
    ffi.Pointer<ffi.Int64> _Addend,
  ) {
    return __InterlockedDecrement(
      _Addend,
    );
  }

  late final __InterlockedDecrementPtr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(ffi.Pointer<ffi.Int64>)>>(
          '_InterlockedDecrement');
  late final __InterlockedDecrement = __InterlockedDecrementPtr
      .asFunction<int Function(ffi.Pointer<ffi.Int64>)>();

  int _InterlockedDecrement16(
    ffi.Pointer<ffi.Int16> _Addend,
  ) {
    return __InterlockedDecrement16(
      _Addend,
    );
  }

  late final __InterlockedDecrement16Ptr =
      _lookup<ffi.NativeFunction<ffi.Int16 Function(ffi.Pointer<ffi.Int16>)>>(
          '_InterlockedDecrement16');
  late final __InterlockedDecrement16 = __InterlockedDecrement16Ptr
      .asFunction<int Function(ffi.Pointer<ffi.Int16>)>();

  int _InterlockedDecrement64(
    ffi.Pointer<ffi.Int64> _Addend,
  ) {
    return __InterlockedDecrement64(
      _Addend,
    );
  }

  late final __InterlockedDecrement64Ptr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(ffi.Pointer<ffi.Int64>)>>(
          '_InterlockedDecrement64');
  late final __InterlockedDecrement64 = __InterlockedDecrement64Ptr
      .asFunction<int Function(ffi.Pointer<ffi.Int64>)>();

  int _interlockeddecrement64(
    ffi.Pointer<ffi.Int64> _Addend,
  ) {
    return __interlockeddecrement64(
      _Addend,
    );
  }

  late final __interlockeddecrement64Ptr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(ffi.Pointer<ffi.Int64>)>>(
          '_interlockeddecrement64');
  late final __interlockeddecrement64 = __interlockeddecrement64Ptr
      .asFunction<int Function(ffi.Pointer<ffi.Int64>)>();

  int _InterlockedExchange(
    ffi.Pointer<ffi.Int64> _Target,
    int _Value,
  ) {
    return __InterlockedExchange(
      _Target,
      _Value,
    );
  }

  late final __InterlockedExchangePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int64 Function(
              ffi.Pointer<ffi.Int64>, ffi.Int64)>>('_InterlockedExchange');
  late final __InterlockedExchange = __InterlockedExchangePtr
      .asFunction<int Function(ffi.Pointer<ffi.Int64>, int)>();

  int _InterlockedExchange16(
    ffi.Pointer<ffi.Int16> _Target,
    int _Value,
  ) {
    return __InterlockedExchange16(
      _Target,
      _Value,
    );
  }

  late final __InterlockedExchange16Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Int16 Function(
              ffi.Pointer<ffi.Int16>, ffi.Int16)>>('_InterlockedExchange16');
  late final __InterlockedExchange16 = __InterlockedExchange16Ptr
      .asFunction<int Function(ffi.Pointer<ffi.Int16>, int)>();

  int _InterlockedExchange64(
    ffi.Pointer<ffi.Int64> _Target,
    int _Value,
  ) {
    return __InterlockedExchange64(
      _Target,
      _Value,
    );
  }

  late final __InterlockedExchange64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Int64 Function(
              ffi.Pointer<ffi.Int64>, ffi.Int64)>>('_InterlockedExchange64');
  late final __InterlockedExchange64 = __InterlockedExchange64Ptr
      .asFunction<int Function(ffi.Pointer<ffi.Int64>, int)>();

  int _interlockedexchange64(
    ffi.Pointer<ffi.Int64> _Target,
    int _Value,
  ) {
    return __interlockedexchange64(
      _Target,
      _Value,
    );
  }

  late final __interlockedexchange64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Int64 Function(
              ffi.Pointer<ffi.Int64>, ffi.Int64)>>('_interlockedexchange64');
  late final __interlockedexchange64 = __interlockedexchange64Ptr
      .asFunction<int Function(ffi.Pointer<ffi.Int64>, int)>();

  int _InterlockedExchange8(
    ffi.Pointer<ffi.Int8> _Target,
    int _Value,
  ) {
    return __InterlockedExchange8(
      _Target,
      _Value,
    );
  }

  late final __InterlockedExchange8Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Int8 Function(
              ffi.Pointer<ffi.Int8>, ffi.Int8)>>('_InterlockedExchange8');
  late final __InterlockedExchange8 = __InterlockedExchange8Ptr
      .asFunction<int Function(ffi.Pointer<ffi.Int8>, int)>();

  int _InterlockedExchangeAdd(
    ffi.Pointer<ffi.Int64> _Addend,
    int _Value,
  ) {
    return __InterlockedExchangeAdd(
      _Addend,
      _Value,
    );
  }

  late final __InterlockedExchangeAddPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int64 Function(
              ffi.Pointer<ffi.Int64>, ffi.Int64)>>('_InterlockedExchangeAdd');
  late final __InterlockedExchangeAdd = __InterlockedExchangeAddPtr
      .asFunction<int Function(ffi.Pointer<ffi.Int64>, int)>();

  int _InterlockedExchangeAdd16(
    ffi.Pointer<ffi.Int16> _Addend,
    int _Value,
  ) {
    return __InterlockedExchangeAdd16(
      _Addend,
      _Value,
    );
  }

  late final __InterlockedExchangeAdd16Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Int16 Function(
              ffi.Pointer<ffi.Int16>, ffi.Int16)>>('_InterlockedExchangeAdd16');
  late final __InterlockedExchangeAdd16 = __InterlockedExchangeAdd16Ptr
      .asFunction<int Function(ffi.Pointer<ffi.Int16>, int)>();

  int _InterlockedExchangeAdd64(
    ffi.Pointer<ffi.Int64> _Addend,
    int _Value,
  ) {
    return __InterlockedExchangeAdd64(
      _Addend,
      _Value,
    );
  }

  late final __InterlockedExchangeAdd64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Int64 Function(
              ffi.Pointer<ffi.Int64>, ffi.Int64)>>('_InterlockedExchangeAdd64');
  late final __InterlockedExchangeAdd64 = __InterlockedExchangeAdd64Ptr
      .asFunction<int Function(ffi.Pointer<ffi.Int64>, int)>();

  int _interlockedexchangeadd64(
    ffi.Pointer<ffi.Int64> _Addend,
    int _Value,
  ) {
    return __interlockedexchangeadd64(
      _Addend,
      _Value,
    );
  }

  late final __interlockedexchangeadd64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Int64 Function(
              ffi.Pointer<ffi.Int64>, ffi.Int64)>>('_interlockedexchangeadd64');
  late final __interlockedexchangeadd64 = __interlockedexchangeadd64Ptr
      .asFunction<int Function(ffi.Pointer<ffi.Int64>, int)>();

  int _InterlockedExchangeAdd8(
    ffi.Pointer<ffi.Int8> _Addend,
    int _Value,
  ) {
    return __InterlockedExchangeAdd8(
      _Addend,
      _Value,
    );
  }

  late final __InterlockedExchangeAdd8Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Int8 Function(
              ffi.Pointer<ffi.Int8>, ffi.Int8)>>('_InterlockedExchangeAdd8');
  late final __InterlockedExchangeAdd8 = __InterlockedExchangeAdd8Ptr
      .asFunction<int Function(ffi.Pointer<ffi.Int8>, int)>();

  int _InterlockedIncrement(
    ffi.Pointer<ffi.Int64> _Addend,
  ) {
    return __InterlockedIncrement(
      _Addend,
    );
  }

  late final __InterlockedIncrementPtr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(ffi.Pointer<ffi.Int64>)>>(
          '_InterlockedIncrement');
  late final __InterlockedIncrement = __InterlockedIncrementPtr
      .asFunction<int Function(ffi.Pointer<ffi.Int64>)>();

  int _InterlockedIncrement16(
    ffi.Pointer<ffi.Int16> _Addend,
  ) {
    return __InterlockedIncrement16(
      _Addend,
    );
  }

  late final __InterlockedIncrement16Ptr =
      _lookup<ffi.NativeFunction<ffi.Int16 Function(ffi.Pointer<ffi.Int16>)>>(
          '_InterlockedIncrement16');
  late final __InterlockedIncrement16 = __InterlockedIncrement16Ptr
      .asFunction<int Function(ffi.Pointer<ffi.Int16>)>();

  int _InterlockedIncrement64(
    ffi.Pointer<ffi.Int64> _Addend,
  ) {
    return __InterlockedIncrement64(
      _Addend,
    );
  }

  late final __InterlockedIncrement64Ptr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(ffi.Pointer<ffi.Int64>)>>(
          '_InterlockedIncrement64');
  late final __InterlockedIncrement64 = __InterlockedIncrement64Ptr
      .asFunction<int Function(ffi.Pointer<ffi.Int64>)>();

  int _interlockedincrement64(
    ffi.Pointer<ffi.Int64> _Addend,
  ) {
    return __interlockedincrement64(
      _Addend,
    );
  }

  late final __interlockedincrement64Ptr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(ffi.Pointer<ffi.Int64>)>>(
          '_interlockedincrement64');
  late final __interlockedincrement64 = __interlockedincrement64Ptr
      .asFunction<int Function(ffi.Pointer<ffi.Int64>)>();

  int _InterlockedOr(
    ffi.Pointer<ffi.Int64> _Value,
    int _Mask,
  ) {
    return __InterlockedOr(
      _Value,
      _Mask,
    );
  }

  late final __InterlockedOrPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int64 Function(
              ffi.Pointer<ffi.Int64>, ffi.Int64)>>('_InterlockedOr');
  late final __InterlockedOr = __InterlockedOrPtr
      .asFunction<int Function(ffi.Pointer<ffi.Int64>, int)>();

  int _InterlockedOr16(
    ffi.Pointer<ffi.Int16> _Value,
    int _Mask,
  ) {
    return __InterlockedOr16(
      _Value,
      _Mask,
    );
  }

  late final __InterlockedOr16Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Int16 Function(
              ffi.Pointer<ffi.Int16>, ffi.Int16)>>('_InterlockedOr16');
  late final __InterlockedOr16 = __InterlockedOr16Ptr
      .asFunction<int Function(ffi.Pointer<ffi.Int16>, int)>();

  int _InterlockedOr64(
    ffi.Pointer<ffi.Int64> _Value,
    int _Mask,
  ) {
    return __InterlockedOr64(
      _Value,
      _Mask,
    );
  }

  late final __InterlockedOr64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Int64 Function(
              ffi.Pointer<ffi.Int64>, ffi.Int64)>>('_InterlockedOr64');
  late final __InterlockedOr64 = __InterlockedOr64Ptr
      .asFunction<int Function(ffi.Pointer<ffi.Int64>, int)>();

  int _interlockedor64(
    ffi.Pointer<ffi.Int64> _Value,
    int _Mask,
  ) {
    return __interlockedor64(
      _Value,
      _Mask,
    );
  }

  late final __interlockedor64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Int64 Function(
              ffi.Pointer<ffi.Int64>, ffi.Int64)>>('_interlockedor64');
  late final __interlockedor64 = __interlockedor64Ptr
      .asFunction<int Function(ffi.Pointer<ffi.Int64>, int)>();

  int _InterlockedOr8(
    ffi.Pointer<ffi.Int8> _Value,
    int _Mask,
  ) {
    return __InterlockedOr8(
      _Value,
      _Mask,
    );
  }

  late final __InterlockedOr8Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Int8 Function(
              ffi.Pointer<ffi.Int8>, ffi.Int8)>>('_InterlockedOr8');
  late final __InterlockedOr8 = __InterlockedOr8Ptr
      .asFunction<int Function(ffi.Pointer<ffi.Int8>, int)>();

  int _InterlockedXor(
    ffi.Pointer<ffi.Int64> _Value,
    int _Mask,
  ) {
    return __InterlockedXor(
      _Value,
      _Mask,
    );
  }

  late final __InterlockedXorPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int64 Function(
              ffi.Pointer<ffi.Int64>, ffi.Int64)>>('_InterlockedXor');
  late final __InterlockedXor = __InterlockedXorPtr
      .asFunction<int Function(ffi.Pointer<ffi.Int64>, int)>();

  int _InterlockedXor16(
    ffi.Pointer<ffi.Int16> _Value,
    int _Mask,
  ) {
    return __InterlockedXor16(
      _Value,
      _Mask,
    );
  }

  late final __InterlockedXor16Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Int16 Function(
              ffi.Pointer<ffi.Int16>, ffi.Int16)>>('_InterlockedXor16');
  late final __InterlockedXor16 = __InterlockedXor16Ptr
      .asFunction<int Function(ffi.Pointer<ffi.Int16>, int)>();

  int _InterlockedXor64(
    ffi.Pointer<ffi.Int64> _Value,
    int _Mask,
  ) {
    return __InterlockedXor64(
      _Value,
      _Mask,
    );
  }

  late final __InterlockedXor64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Int64 Function(
              ffi.Pointer<ffi.Int64>, ffi.Int64)>>('_InterlockedXor64');
  late final __InterlockedXor64 = __InterlockedXor64Ptr
      .asFunction<int Function(ffi.Pointer<ffi.Int64>, int)>();

  int _interlockedxor64(
    ffi.Pointer<ffi.Int64> _Value,
    int _Mask,
  ) {
    return __interlockedxor64(
      _Value,
      _Mask,
    );
  }

  late final __interlockedxor64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Int64 Function(
              ffi.Pointer<ffi.Int64>, ffi.Int64)>>('_interlockedxor64');
  late final __interlockedxor64 = __interlockedxor64Ptr
      .asFunction<int Function(ffi.Pointer<ffi.Int64>, int)>();

  int _InterlockedXor8(
    ffi.Pointer<ffi.Int8> _Value,
    int _Mask,
  ) {
    return __InterlockedXor8(
      _Value,
      _Mask,
    );
  }

  late final __InterlockedXor8Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Int8 Function(
              ffi.Pointer<ffi.Int8>, ffi.Int8)>>('_InterlockedXor8');
  late final __InterlockedXor8 = __InterlockedXor8Ptr
      .asFunction<int Function(ffi.Pointer<ffi.Int8>, int)>();

  void _ReadWriteBarrier() {
    return __ReadWriteBarrier();
  }

  late final __ReadWriteBarrierPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('_ReadWriteBarrier');
  late final __ReadWriteBarrier =
      __ReadWriteBarrierPtr.asFunction<void Function()>();

  int __iso_volatile_load16(
    ffi.Pointer<ffi.Int16> arg0,
  ) {
    return ___iso_volatile_load16(
      arg0,
    );
  }

  late final ___iso_volatile_load16Ptr =
      _lookup<ffi.NativeFunction<ffi.Int16 Function(ffi.Pointer<ffi.Int16>)>>(
          '__iso_volatile_load16');
  late final ___iso_volatile_load16 = ___iso_volatile_load16Ptr
      .asFunction<int Function(ffi.Pointer<ffi.Int16>)>();

  int __iso_volatile_load32(
    ffi.Pointer<ffi.Int32> arg0,
  ) {
    return ___iso_volatile_load32(
      arg0,
    );
  }

  late final ___iso_volatile_load32Ptr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<ffi.Int32>)>>(
          '__iso_volatile_load32');
  late final ___iso_volatile_load32 = ___iso_volatile_load32Ptr
      .asFunction<int Function(ffi.Pointer<ffi.Int32>)>();

  int __iso_volatile_load64(
    ffi.Pointer<ffi.Int64> arg0,
  ) {
    return ___iso_volatile_load64(
      arg0,
    );
  }

  late final ___iso_volatile_load64Ptr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(ffi.Pointer<ffi.Int64>)>>(
          '__iso_volatile_load64');
  late final ___iso_volatile_load64 = ___iso_volatile_load64Ptr
      .asFunction<int Function(ffi.Pointer<ffi.Int64>)>();

  int __iso_volatile_load8(
    ffi.Pointer<ffi.Int8> arg0,
  ) {
    return ___iso_volatile_load8(
      arg0,
    );
  }

  late final ___iso_volatile_load8Ptr =
      _lookup<ffi.NativeFunction<ffi.Int8 Function(ffi.Pointer<ffi.Int8>)>>(
          '__iso_volatile_load8');
  late final ___iso_volatile_load8 = ___iso_volatile_load8Ptr
      .asFunction<int Function(ffi.Pointer<ffi.Int8>)>();

  void __iso_volatile_store16(
    ffi.Pointer<ffi.Int16> arg0,
    int arg1,
  ) {
    return ___iso_volatile_store16(
      arg0,
      arg1,
    );
  }

  late final ___iso_volatile_store16Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<ffi.Int16>, ffi.Int16)>>('__iso_volatile_store16');
  late final ___iso_volatile_store16 = ___iso_volatile_store16Ptr
      .asFunction<void Function(ffi.Pointer<ffi.Int16>, int)>();

  void __iso_volatile_store32(
    ffi.Pointer<ffi.Int32> arg0,
    int arg1,
  ) {
    return ___iso_volatile_store32(
      arg0,
      arg1,
    );
  }

  late final ___iso_volatile_store32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<ffi.Int32>, ffi.Int32)>>('__iso_volatile_store32');
  late final ___iso_volatile_store32 = ___iso_volatile_store32Ptr
      .asFunction<void Function(ffi.Pointer<ffi.Int32>, int)>();

  void __iso_volatile_store64(
    ffi.Pointer<ffi.Int64> arg0,
    int arg1,
  ) {
    return ___iso_volatile_store64(
      arg0,
      arg1,
    );
  }

  late final ___iso_volatile_store64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<ffi.Int64>, ffi.Int64)>>('__iso_volatile_store64');
  late final ___iso_volatile_store64 = ___iso_volatile_store64Ptr
      .asFunction<void Function(ffi.Pointer<ffi.Int64>, int)>();

  void __iso_volatile_store8(
    ffi.Pointer<ffi.Int8> arg0,
    int arg1,
  ) {
    return ___iso_volatile_store8(
      arg0,
      arg1,
    );
  }

  late final ___iso_volatile_store8Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<ffi.Int8>, ffi.Int8)>>('__iso_volatile_store8');
  late final ___iso_volatile_store8 = ___iso_volatile_store8Ptr
      .asFunction<void Function(ffi.Pointer<ffi.Int8>, int)>();

  int _interlockedbittestandset(
    ffi.Pointer<ffi.Int64> arg0,
    int arg1,
  ) {
    return __interlockedbittestandset(
      arg0,
      arg1,
    );
  }

  late final __interlockedbittestandsetPtr = _lookup<
      ffi.NativeFunction<
          ffi.Uint8 Function(
              ffi.Pointer<ffi.Int64>, ffi.Int64)>>('_interlockedbittestandset');
  late final __interlockedbittestandset = __interlockedbittestandsetPtr
      .asFunction<int Function(ffi.Pointer<ffi.Int64>, int)>();

  void _mm_pause() {
    return __mm_pause();
  }

  late final __mm_pausePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('_mm_pause');
  late final __mm_pause = __mm_pausePtr.asFunction<void Function()>();

  int __lzcnt(
    int arg0,
  ) {
    return ___lzcnt(
      arg0,
    );
  }

  late final ___lzcntPtr =
      _lookup<ffi.NativeFunction<ffi.Uint32 Function(ffi.Uint32)>>('__lzcnt');
  late final ___lzcnt = ___lzcntPtr.asFunction<int Function(int)>();

  int __lzcnt16(
    int arg0,
  ) {
    return ___lzcnt16(
      arg0,
    );
  }

  late final ___lzcnt16Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint16 Function(ffi.Uint16)>>('__lzcnt16');
  late final ___lzcnt16 = ___lzcnt16Ptr.asFunction<int Function(int)>();

  int __lzcnt64(
    int arg0,
  ) {
    return ___lzcnt64(
      arg0,
    );
  }

  late final ___lzcnt64Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function(ffi.Uint64)>>('__lzcnt64');
  late final ___lzcnt64 = ___lzcnt64Ptr.asFunction<int Function(int)>();

  int __popcnt(
    int arg0,
  ) {
    return ___popcnt(
      arg0,
    );
  }

  late final ___popcntPtr =
      _lookup<ffi.NativeFunction<ffi.Uint32 Function(ffi.Uint32)>>('__popcnt');
  late final ___popcnt = ___popcntPtr.asFunction<int Function(int)>();

  int __popcnt16(
    int arg0,
  ) {
    return ___popcnt16(
      arg0,
    );
  }

  late final ___popcnt16Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint16 Function(ffi.Uint16)>>(
          '__popcnt16');
  late final ___popcnt16 = ___popcnt16Ptr.asFunction<int Function(int)>();

  int __popcnt64(
    int arg0,
  ) {
    return ___popcnt64(
      arg0,
    );
  }

  late final ___popcnt64Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function(ffi.Uint64)>>(
          '__popcnt64');
  late final ___popcnt64 = ___popcnt64Ptr.asFunction<int Function(int)>();

  int __shiftright128(
    int _LowPart,
    int _HighPart,
    int _Shift,
  ) {
    return ___shiftright128(
      _LowPart,
      _HighPart,
      _Shift,
    );
  }

  late final ___shiftright128Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Uint64 Function(
              ffi.Uint64, ffi.Uint64, ffi.Uint8)>>('__shiftright128');
  late final ___shiftright128 =
      ___shiftright128Ptr.asFunction<int Function(int, int, int)>();

  int _umul128(
    int _Multiplier,
    int _Multiplicand,
    ffi.Pointer<ffi.Uint64> _HighProduct,
  ) {
    return __umul128(
      _Multiplier,
      _Multiplicand,
      _HighProduct,
    );
  }

  late final __umul128Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Uint64 Function(
              ffi.Uint64, ffi.Uint64, ffi.Pointer<ffi.Uint64>)>>('_umul128');
  late final __umul128 = __umul128Ptr
      .asFunction<int Function(int, int, ffi.Pointer<ffi.Uint64>)>();

  double __ceil(
    double arg0,
  ) {
    return ___ceil(
      arg0,
    );
  }

  late final ___ceilPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double)>>('__ceil');
  late final ___ceil = ___ceilPtr.asFunction<double Function(double)>();

  double __ceilf(
    double arg0,
  ) {
    return ___ceilf(
      arg0,
    );
  }

  late final ___ceilfPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float)>>('__ceilf');
  late final ___ceilf = ___ceilfPtr.asFunction<double Function(double)>();

  double __floor(
    double arg0,
  ) {
    return ___floor(
      arg0,
    );
  }

  late final ___floorPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double)>>('__floor');
  late final ___floor = ___floorPtr.asFunction<double Function(double)>();

  double __floorf(
    double arg0,
  ) {
    return ___floorf(
      arg0,
    );
  }

  late final ___floorfPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float)>>('__floorf');
  late final ___floorf = ___floorfPtr.asFunction<double Function(double)>();

  double __round(
    double arg0,
  ) {
    return ___round(
      arg0,
    );
  }

  late final ___roundPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double)>>('__round');
  late final ___round = ___roundPtr.asFunction<double Function(double)>();

  double __roundf(
    double arg0,
  ) {
    return ___roundf(
      arg0,
    );
  }

  late final ___roundfPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float)>>('__roundf');
  late final ___roundf = ___roundfPtr.asFunction<double Function(double)>();

  double __trunc(
    double arg0,
  ) {
    return ___trunc(
      arg0,
    );
  }

  late final ___truncPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double)>>('__trunc');
  late final ___trunc = ___truncPtr.asFunction<double Function(double)>();

  double __truncf(
    double arg0,
  ) {
    return ___truncf(
      arg0,
    );
  }

  late final ___truncfPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float)>>('__truncf');
  late final ___truncf = ___truncfPtr.asFunction<double Function(double)>();

  double __copysign(
    double arg0,
    double arg1,
  ) {
    return ___copysign(
      arg0,
      arg1,
    );
  }

  late final ___copysignPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double, ffi.Double)>>(
          '__copysign');
  late final ___copysign =
      ___copysignPtr.asFunction<double Function(double, double)>();

  double __copysignf(
    double arg0,
    double arg1,
  ) {
    return ___copysignf(
      arg0,
      arg1,
    );
  }

  late final ___copysignfPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float, ffi.Float)>>(
          '__copysignf');
  late final ___copysignf =
      ___copysignfPtr.asFunction<double Function(double, double)>();

  int __signbitvalue(
    double arg0,
  ) {
    return ___signbitvalue(
      arg0,
    );
  }

  late final ___signbitvaluePtr =
      _lookup<ffi.NativeFunction<ffi.Uint32 Function(ffi.Double)>>(
          '__signbitvalue');
  late final ___signbitvalue =
      ___signbitvaluePtr.asFunction<int Function(double)>();

  int __signbitvaluef(
    double arg0,
  ) {
    return ___signbitvaluef(
      arg0,
    );
  }

  late final ___signbitvaluefPtr =
      _lookup<ffi.NativeFunction<ffi.Uint32 Function(ffi.Float)>>(
          '__signbitvaluef');
  late final ___signbitvaluef =
      ___signbitvaluefPtr.asFunction<int Function(double)>();

  int _cvt_ftoi_sat(
    double a,
  ) {
    return __cvt_ftoi_sat(
      a,
    );
  }

  late final __cvt_ftoi_satPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Float)>>(
          '_cvt_ftoi_sat');
  late final __cvt_ftoi_sat =
      __cvt_ftoi_satPtr.asFunction<int Function(double)>();

  int _cvt_ftoui_sat(
    double a,
  ) {
    return __cvt_ftoui_sat(
      a,
    );
  }

  late final __cvt_ftoui_satPtr =
      _lookup<ffi.NativeFunction<ffi.Uint32 Function(ffi.Float)>>(
          '_cvt_ftoui_sat');
  late final __cvt_ftoui_sat =
      __cvt_ftoui_satPtr.asFunction<int Function(double)>();

  int _cvt_ftoll_sat(
    double a,
  ) {
    return __cvt_ftoll_sat(
      a,
    );
  }

  late final __cvt_ftoll_satPtr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(ffi.Float)>>(
          '_cvt_ftoll_sat');
  late final __cvt_ftoll_sat =
      __cvt_ftoll_satPtr.asFunction<int Function(double)>();

  int _cvt_ftoull_sat(
    double a,
  ) {
    return __cvt_ftoull_sat(
      a,
    );
  }

  late final __cvt_ftoull_satPtr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function(ffi.Float)>>(
          '_cvt_ftoull_sat');
  late final __cvt_ftoull_sat =
      __cvt_ftoull_satPtr.asFunction<int Function(double)>();

  int _cvt_ftoi_sent(
    double a,
  ) {
    return __cvt_ftoi_sent(
      a,
    );
  }

  late final __cvt_ftoi_sentPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Float)>>(
          '_cvt_ftoi_sent');
  late final __cvt_ftoi_sent =
      __cvt_ftoi_sentPtr.asFunction<int Function(double)>();

  int _cvt_ftoui_sent(
    double a,
  ) {
    return __cvt_ftoui_sent(
      a,
    );
  }

  late final __cvt_ftoui_sentPtr =
      _lookup<ffi.NativeFunction<ffi.Uint32 Function(ffi.Float)>>(
          '_cvt_ftoui_sent');
  late final __cvt_ftoui_sent =
      __cvt_ftoui_sentPtr.asFunction<int Function(double)>();

  int _cvt_ftoll_sent(
    double a,
  ) {
    return __cvt_ftoll_sent(
      a,
    );
  }

  late final __cvt_ftoll_sentPtr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(ffi.Float)>>(
          '_cvt_ftoll_sent');
  late final __cvt_ftoll_sent =
      __cvt_ftoll_sentPtr.asFunction<int Function(double)>();

  int _cvt_ftoull_sent(
    double a,
  ) {
    return __cvt_ftoull_sent(
      a,
    );
  }

  late final __cvt_ftoull_sentPtr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function(ffi.Float)>>(
          '_cvt_ftoull_sent');
  late final __cvt_ftoull_sent =
      __cvt_ftoull_sentPtr.asFunction<int Function(double)>();

  int _cvt_dtoi_sat(
    double a,
  ) {
    return __cvt_dtoi_sat(
      a,
    );
  }

  late final __cvt_dtoi_satPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Double)>>(
          '_cvt_dtoi_sat');
  late final __cvt_dtoi_sat =
      __cvt_dtoi_satPtr.asFunction<int Function(double)>();

  int _cvt_dtoui_sat(
    double a,
  ) {
    return __cvt_dtoui_sat(
      a,
    );
  }

  late final __cvt_dtoui_satPtr =
      _lookup<ffi.NativeFunction<ffi.Uint32 Function(ffi.Double)>>(
          '_cvt_dtoui_sat');
  late final __cvt_dtoui_sat =
      __cvt_dtoui_satPtr.asFunction<int Function(double)>();

  int _cvt_dtoll_sat(
    double a,
  ) {
    return __cvt_dtoll_sat(
      a,
    );
  }

  late final __cvt_dtoll_satPtr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(ffi.Double)>>(
          '_cvt_dtoll_sat');
  late final __cvt_dtoll_sat =
      __cvt_dtoll_satPtr.asFunction<int Function(double)>();

  int _cvt_dtoull_sat(
    double a,
  ) {
    return __cvt_dtoull_sat(
      a,
    );
  }

  late final __cvt_dtoull_satPtr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function(ffi.Double)>>(
          '_cvt_dtoull_sat');
  late final __cvt_dtoull_sat =
      __cvt_dtoull_satPtr.asFunction<int Function(double)>();

  int _cvt_dtoi_sent(
    double a,
  ) {
    return __cvt_dtoi_sent(
      a,
    );
  }

  late final __cvt_dtoi_sentPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Double)>>(
          '_cvt_dtoi_sent');
  late final __cvt_dtoi_sent =
      __cvt_dtoi_sentPtr.asFunction<int Function(double)>();

  int _cvt_dtoui_sent(
    double a,
  ) {
    return __cvt_dtoui_sent(
      a,
    );
  }

  late final __cvt_dtoui_sentPtr =
      _lookup<ffi.NativeFunction<ffi.Uint32 Function(ffi.Double)>>(
          '_cvt_dtoui_sent');
  late final __cvt_dtoui_sent =
      __cvt_dtoui_sentPtr.asFunction<int Function(double)>();

  int _cvt_dtoll_sent(
    double a,
  ) {
    return __cvt_dtoll_sent(
      a,
    );
  }

  late final __cvt_dtoll_sentPtr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(ffi.Double)>>(
          '_cvt_dtoll_sent');
  late final __cvt_dtoll_sent =
      __cvt_dtoll_sentPtr.asFunction<int Function(double)>();

  int _cvt_dtoull_sent(
    double a,
  ) {
    return __cvt_dtoull_sent(
      a,
    );
  }

  late final __cvt_dtoull_sentPtr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function(ffi.Double)>>(
          '_cvt_dtoull_sent');
  late final __cvt_dtoull_sent =
      __cvt_dtoull_sentPtr.asFunction<int Function(double)>();

  int _setjmp(
    ffi.Pointer<_JBTYPE> _Buf,
  ) {
    return __setjmp(
      _Buf,
    );
  }

  late final __setjmpPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<_JBTYPE>)>>(
          '_setjmp');
  late final __setjmp =
      __setjmpPtr.asFunction<int Function(ffi.Pointer<_JBTYPE>)>();

  void longjmp(
    ffi.Pointer<_JBTYPE> _Buf,
    int _Value,
  ) {
    return _longjmp(
      _Buf,
      _Value,
    );
  }

  late final _longjmpPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<_JBTYPE>, ffi.Int32)>>('longjmp');
  late final _longjmp =
      _longjmpPtr.asFunction<void Function(ffi.Pointer<_JBTYPE>, int)>();

  ffi.Pointer<ffi.Void> _calloc_base(
    int _Count,
    int _Size,
  ) {
    return __calloc_base(
      _Count,
      _Size,
    );
  }

  late final __calloc_basePtr = _lookup<
          ffi.NativeFunction<ffi.Pointer<ffi.Void> Function(size_t, size_t)>>(
      '_calloc_base');
  late final __calloc_base =
      __calloc_basePtr.asFunction<ffi.Pointer<ffi.Void> Function(int, int)>();

  ffi.Pointer<ffi.Void> calloc(
    int _Count,
    int _Size,
  ) {
    return _calloc(
      _Count,
      _Size,
    );
  }

  late final _callocPtr = _lookup<
          ffi.NativeFunction<ffi.Pointer<ffi.Void> Function(size_t, size_t)>>(
      'calloc');
  late final _calloc =
      _callocPtr.asFunction<ffi.Pointer<ffi.Void> Function(int, int)>();

  int _callnewh(
    int _Size,
  ) {
    return __callnewh(
      _Size,
    );
  }

  late final __callnewhPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(size_t)>>('_callnewh');
  late final __callnewh = __callnewhPtr.asFunction<int Function(int)>();

  ffi.Pointer<ffi.Void> _expand(
    ffi.Pointer<ffi.Void> _Block,
    int _Size,
  ) {
    return __expand(
      _Block,
      _Size,
    );
  }

  late final __expandPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Void> Function(
              ffi.Pointer<ffi.Void>, size_t)>>('_expand');
  late final __expand = __expandPtr
      .asFunction<ffi.Pointer<ffi.Void> Function(ffi.Pointer<ffi.Void>, int)>();

  void _free_base(
    ffi.Pointer<ffi.Void> _Block,
  ) {
    return __free_base(
      _Block,
    );
  }

  late final __free_basePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ffi.Void>)>>(
          '_free_base');
  late final __free_base =
      __free_basePtr.asFunction<void Function(ffi.Pointer<ffi.Void>)>();

  void free(
    ffi.Pointer<ffi.Void> _Block,
  ) {
    return _free(
      _Block,
    );
  }

  late final _freePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ffi.Void>)>>(
          'free');
  late final _free =
      _freePtr.asFunction<void Function(ffi.Pointer<ffi.Void>)>();

  ffi.Pointer<ffi.Void> _malloc_base(
    int _Size,
  ) {
    return __malloc_base(
      _Size,
    );
  }

  late final __malloc_basePtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Void> Function(size_t)>>(
          '_malloc_base');
  late final __malloc_base =
      __malloc_basePtr.asFunction<ffi.Pointer<ffi.Void> Function(int)>();

  ffi.Pointer<ffi.Void> malloc(
    int _Size,
  ) {
    return _malloc(
      _Size,
    );
  }

  late final _mallocPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Void> Function(size_t)>>(
          'malloc');
  late final _malloc =
      _mallocPtr.asFunction<ffi.Pointer<ffi.Void> Function(int)>();

  int _msize_base(
    ffi.Pointer<ffi.Void> _Block,
  ) {
    return __msize_base(
      _Block,
    );
  }

  late final __msize_basePtr =
      _lookup<ffi.NativeFunction<size_t Function(ffi.Pointer<ffi.Void>)>>(
          '_msize_base');
  late final __msize_base =
      __msize_basePtr.asFunction<int Function(ffi.Pointer<ffi.Void>)>();

  int _msize(
    ffi.Pointer<ffi.Void> _Block,
  ) {
    return __msize(
      _Block,
    );
  }

  late final __msizePtr =
      _lookup<ffi.NativeFunction<size_t Function(ffi.Pointer<ffi.Void>)>>(
          '_msize');
  late final __msize =
      __msizePtr.asFunction<int Function(ffi.Pointer<ffi.Void>)>();

  ffi.Pointer<ffi.Void> _realloc_base(
    ffi.Pointer<ffi.Void> _Block,
    int _Size,
  ) {
    return __realloc_base(
      _Block,
      _Size,
    );
  }

  late final __realloc_basePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Void> Function(
              ffi.Pointer<ffi.Void>, size_t)>>('_realloc_base');
  late final __realloc_base = __realloc_basePtr
      .asFunction<ffi.Pointer<ffi.Void> Function(ffi.Pointer<ffi.Void>, int)>();

  ffi.Pointer<ffi.Void> realloc(
    ffi.Pointer<ffi.Void> _Block,
    int _Size,
  ) {
    return _realloc(
      _Block,
      _Size,
    );
  }

  late final _reallocPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Void> Function(
              ffi.Pointer<ffi.Void>, size_t)>>('realloc');
  late final _realloc = _reallocPtr
      .asFunction<ffi.Pointer<ffi.Void> Function(ffi.Pointer<ffi.Void>, int)>();

  ffi.Pointer<ffi.Void> _recalloc_base(
    ffi.Pointer<ffi.Void> _Block,
    int _Count,
    int _Size,
  ) {
    return __recalloc_base(
      _Block,
      _Count,
      _Size,
    );
  }

  late final __recalloc_basePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Void> Function(
              ffi.Pointer<ffi.Void>, size_t, size_t)>>('_recalloc_base');
  late final __recalloc_base = __recalloc_basePtr.asFunction<
      ffi.Pointer<ffi.Void> Function(ffi.Pointer<ffi.Void>, int, int)>();

  ffi.Pointer<ffi.Void> _recalloc(
    ffi.Pointer<ffi.Void> _Block,
    int _Count,
    int _Size,
  ) {
    return __recalloc(
      _Block,
      _Count,
      _Size,
    );
  }

  late final __recallocPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Void> Function(
              ffi.Pointer<ffi.Void>, size_t, size_t)>>('_recalloc');
  late final __recalloc = __recallocPtr.asFunction<
      ffi.Pointer<ffi.Void> Function(ffi.Pointer<ffi.Void>, int, int)>();

  void _aligned_free(
    ffi.Pointer<ffi.Void> _Block,
  ) {
    return __aligned_free(
      _Block,
    );
  }

  late final __aligned_freePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ffi.Void>)>>(
          '_aligned_free');
  late final __aligned_free =
      __aligned_freePtr.asFunction<void Function(ffi.Pointer<ffi.Void>)>();

  ffi.Pointer<ffi.Void> _aligned_malloc(
    int _Size,
    int _Alignment,
  ) {
    return __aligned_malloc(
      _Size,
      _Alignment,
    );
  }

  late final __aligned_mallocPtr = _lookup<
          ffi.NativeFunction<ffi.Pointer<ffi.Void> Function(size_t, size_t)>>(
      '_aligned_malloc');
  late final __aligned_malloc = __aligned_mallocPtr
      .asFunction<ffi.Pointer<ffi.Void> Function(int, int)>();

  ffi.Pointer<ffi.Void> _aligned_offset_malloc(
    int _Size,
    int _Alignment,
    int _Offset,
  ) {
    return __aligned_offset_malloc(
      _Size,
      _Alignment,
      _Offset,
    );
  }

  late final __aligned_offset_mallocPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Void> Function(
              size_t, size_t, size_t)>>('_aligned_offset_malloc');
  late final __aligned_offset_malloc = __aligned_offset_mallocPtr
      .asFunction<ffi.Pointer<ffi.Void> Function(int, int, int)>();

  int _aligned_msize(
    ffi.Pointer<ffi.Void> _Block,
    int _Alignment,
    int _Offset,
  ) {
    return __aligned_msize(
      _Block,
      _Alignment,
      _Offset,
    );
  }

  late final __aligned_msizePtr = _lookup<
      ffi.NativeFunction<
          size_t Function(
              ffi.Pointer<ffi.Void>, size_t, size_t)>>('_aligned_msize');
  late final __aligned_msize = __aligned_msizePtr
      .asFunction<int Function(ffi.Pointer<ffi.Void>, int, int)>();

  ffi.Pointer<ffi.Void> _aligned_offset_realloc(
    ffi.Pointer<ffi.Void> _Block,
    int _Size,
    int _Alignment,
    int _Offset,
  ) {
    return __aligned_offset_realloc(
      _Block,
      _Size,
      _Alignment,
      _Offset,
    );
  }

  late final __aligned_offset_reallocPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Void> Function(ffi.Pointer<ffi.Void>, size_t, size_t,
              size_t)>>('_aligned_offset_realloc');
  late final __aligned_offset_realloc = __aligned_offset_reallocPtr.asFunction<
      ffi.Pointer<ffi.Void> Function(ffi.Pointer<ffi.Void>, int, int, int)>();

  ffi.Pointer<ffi.Void> _aligned_offset_recalloc(
    ffi.Pointer<ffi.Void> _Block,
    int _Count,
    int _Size,
    int _Alignment,
    int _Offset,
  ) {
    return __aligned_offset_recalloc(
      _Block,
      _Count,
      _Size,
      _Alignment,
      _Offset,
    );
  }

  late final __aligned_offset_recallocPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Void> Function(ffi.Pointer<ffi.Void>, size_t, size_t,
              size_t, size_t)>>('_aligned_offset_recalloc');
  late final __aligned_offset_recalloc =
      __aligned_offset_recallocPtr.asFunction<
          ffi.Pointer<ffi.Void> Function(
              ffi.Pointer<ffi.Void>, int, int, int, int)>();

  ffi.Pointer<ffi.Void> _aligned_realloc(
    ffi.Pointer<ffi.Void> _Block,
    int _Size,
    int _Alignment,
  ) {
    return __aligned_realloc(
      _Block,
      _Size,
      _Alignment,
    );
  }

  late final __aligned_reallocPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Void> Function(
              ffi.Pointer<ffi.Void>, size_t, size_t)>>('_aligned_realloc');
  late final __aligned_realloc = __aligned_reallocPtr.asFunction<
      ffi.Pointer<ffi.Void> Function(ffi.Pointer<ffi.Void>, int, int)>();

  ffi.Pointer<ffi.Void> _aligned_recalloc(
    ffi.Pointer<ffi.Void> _Block,
    int _Count,
    int _Size,
    int _Alignment,
  ) {
    return __aligned_recalloc(
      _Block,
      _Count,
      _Size,
      _Alignment,
    );
  }

  late final __aligned_recallocPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Void> Function(ffi.Pointer<ffi.Void>, size_t, size_t,
              size_t)>>('_aligned_recalloc');
  late final __aligned_recalloc = __aligned_recallocPtr.asFunction<
      ffi.Pointer<ffi.Void> Function(ffi.Pointer<ffi.Void>, int, int, int)>();

  ffi.Pointer<ffi.Void> _alloca(
    int _Size,
  ) {
    return __alloca(
      _Size,
    );
  }

  late final __allocaPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Void> Function(size_t)>>(
          '_alloca');
  late final __alloca =
      __allocaPtr.asFunction<ffi.Pointer<ffi.Void> Function(int)>();

  int _get_heap_handle() {
    return __get_heap_handle();
  }

  late final __get_heap_handlePtr =
      _lookup<ffi.NativeFunction<ffi.IntPtr Function()>>('_get_heap_handle');
  late final __get_heap_handle =
      __get_heap_handlePtr.asFunction<int Function()>();

  int _heapmin() {
    return __heapmin();
  }

  late final __heapminPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function()>>('_heapmin');
  late final __heapmin = __heapminPtr.asFunction<int Function()>();

  int _heapwalk(
    ffi.Pointer<_HEAPINFO> _EntryInfo,
  ) {
    return __heapwalk(
      _EntryInfo,
    );
  }

  late final __heapwalkPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<_HEAPINFO>)>>(
          '_heapwalk');
  late final __heapwalk =
      __heapwalkPtr.asFunction<int Function(ffi.Pointer<_HEAPINFO>)>();

  int _heapchk() {
    return __heapchk();
  }

  late final __heapchkPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function()>>('_heapchk');
  late final __heapchk = __heapchkPtr.asFunction<int Function()>();

  int _resetstkoflw() {
    return __resetstkoflw();
  }

  late final __resetstkoflwPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function()>>('_resetstkoflw');
  late final __resetstkoflw = __resetstkoflwPtr.asFunction<int Function()>();

  __m128 _mm_add_ss(
    __m128 _A,
    __m128 _B,
  ) {
    return __mm_add_ss(
      _A,
      _B,
    );
  }

  late final __mm_add_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128)>>(
          '_mm_add_ss');
  late final __mm_add_ss =
      __mm_add_ssPtr.asFunction<__m128 Function(__m128, __m128)>();

  __m128 _mm_add_ps(
    __m128 _A,
    __m128 _B,
  ) {
    return __mm_add_ps(
      _A,
      _B,
    );
  }

  late final __mm_add_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128)>>(
          '_mm_add_ps');
  late final __mm_add_ps =
      __mm_add_psPtr.asFunction<__m128 Function(__m128, __m128)>();

  __m128 _mm_sub_ss(
    __m128 _A,
    __m128 _B,
  ) {
    return __mm_sub_ss(
      _A,
      _B,
    );
  }

  late final __mm_sub_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128)>>(
          '_mm_sub_ss');
  late final __mm_sub_ss =
      __mm_sub_ssPtr.asFunction<__m128 Function(__m128, __m128)>();

  __m128 _mm_sub_ps(
    __m128 _A,
    __m128 _B,
  ) {
    return __mm_sub_ps(
      _A,
      _B,
    );
  }

  late final __mm_sub_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128)>>(
          '_mm_sub_ps');
  late final __mm_sub_ps =
      __mm_sub_psPtr.asFunction<__m128 Function(__m128, __m128)>();

  __m128 _mm_mul_ss(
    __m128 _A,
    __m128 _B,
  ) {
    return __mm_mul_ss(
      _A,
      _B,
    );
  }

  late final __mm_mul_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128)>>(
          '_mm_mul_ss');
  late final __mm_mul_ss =
      __mm_mul_ssPtr.asFunction<__m128 Function(__m128, __m128)>();

  __m128 _mm_mul_ps(
    __m128 _A,
    __m128 _B,
  ) {
    return __mm_mul_ps(
      _A,
      _B,
    );
  }

  late final __mm_mul_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128)>>(
          '_mm_mul_ps');
  late final __mm_mul_ps =
      __mm_mul_psPtr.asFunction<__m128 Function(__m128, __m128)>();

  __m128 _mm_div_ss(
    __m128 _A,
    __m128 _B,
  ) {
    return __mm_div_ss(
      _A,
      _B,
    );
  }

  late final __mm_div_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128)>>(
          '_mm_div_ss');
  late final __mm_div_ss =
      __mm_div_ssPtr.asFunction<__m128 Function(__m128, __m128)>();

  __m128 _mm_div_ps(
    __m128 _A,
    __m128 _B,
  ) {
    return __mm_div_ps(
      _A,
      _B,
    );
  }

  late final __mm_div_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128)>>(
          '_mm_div_ps');
  late final __mm_div_ps =
      __mm_div_psPtr.asFunction<__m128 Function(__m128, __m128)>();

  __m128 _mm_sqrt_ss(
    __m128 _A,
  ) {
    return __mm_sqrt_ss(
      _A,
    );
  }

  late final __mm_sqrt_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128)>>('_mm_sqrt_ss');
  late final __mm_sqrt_ss =
      __mm_sqrt_ssPtr.asFunction<__m128 Function(__m128)>();

  __m128 _mm_sqrt_ps(
    __m128 _A,
  ) {
    return __mm_sqrt_ps(
      _A,
    );
  }

  late final __mm_sqrt_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128)>>('_mm_sqrt_ps');
  late final __mm_sqrt_ps =
      __mm_sqrt_psPtr.asFunction<__m128 Function(__m128)>();

  __m128 _mm_rcp_ss(
    __m128 _A,
  ) {
    return __mm_rcp_ss(
      _A,
    );
  }

  late final __mm_rcp_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128)>>('_mm_rcp_ss');
  late final __mm_rcp_ss = __mm_rcp_ssPtr.asFunction<__m128 Function(__m128)>();

  __m128 _mm_rcp_ps(
    __m128 _A,
  ) {
    return __mm_rcp_ps(
      _A,
    );
  }

  late final __mm_rcp_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128)>>('_mm_rcp_ps');
  late final __mm_rcp_ps = __mm_rcp_psPtr.asFunction<__m128 Function(__m128)>();

  __m128 _mm_rsqrt_ss(
    __m128 _A,
  ) {
    return __mm_rsqrt_ss(
      _A,
    );
  }

  late final __mm_rsqrt_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128)>>('_mm_rsqrt_ss');
  late final __mm_rsqrt_ss =
      __mm_rsqrt_ssPtr.asFunction<__m128 Function(__m128)>();

  __m128 _mm_rsqrt_ps(
    __m128 _A,
  ) {
    return __mm_rsqrt_ps(
      _A,
    );
  }

  late final __mm_rsqrt_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128)>>('_mm_rsqrt_ps');
  late final __mm_rsqrt_ps =
      __mm_rsqrt_psPtr.asFunction<__m128 Function(__m128)>();

  __m128 _mm_min_ss(
    __m128 _A,
    __m128 _B,
  ) {
    return __mm_min_ss(
      _A,
      _B,
    );
  }

  late final __mm_min_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128)>>(
          '_mm_min_ss');
  late final __mm_min_ss =
      __mm_min_ssPtr.asFunction<__m128 Function(__m128, __m128)>();

  __m128 _mm_min_ps(
    __m128 _A,
    __m128 _B,
  ) {
    return __mm_min_ps(
      _A,
      _B,
    );
  }

  late final __mm_min_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128)>>(
          '_mm_min_ps');
  late final __mm_min_ps =
      __mm_min_psPtr.asFunction<__m128 Function(__m128, __m128)>();

  __m128 _mm_max_ss(
    __m128 _A,
    __m128 _B,
  ) {
    return __mm_max_ss(
      _A,
      _B,
    );
  }

  late final __mm_max_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128)>>(
          '_mm_max_ss');
  late final __mm_max_ss =
      __mm_max_ssPtr.asFunction<__m128 Function(__m128, __m128)>();

  __m128 _mm_max_ps(
    __m128 _A,
    __m128 _B,
  ) {
    return __mm_max_ps(
      _A,
      _B,
    );
  }

  late final __mm_max_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128)>>(
          '_mm_max_ps');
  late final __mm_max_ps =
      __mm_max_psPtr.asFunction<__m128 Function(__m128, __m128)>();

  __m128 _mm_and_ps(
    __m128 _A,
    __m128 _B,
  ) {
    return __mm_and_ps(
      _A,
      _B,
    );
  }

  late final __mm_and_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128)>>(
          '_mm_and_ps');
  late final __mm_and_ps =
      __mm_and_psPtr.asFunction<__m128 Function(__m128, __m128)>();

  __m128 _mm_andnot_ps(
    __m128 _A,
    __m128 _B,
  ) {
    return __mm_andnot_ps(
      _A,
      _B,
    );
  }

  late final __mm_andnot_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128)>>(
          '_mm_andnot_ps');
  late final __mm_andnot_ps =
      __mm_andnot_psPtr.asFunction<__m128 Function(__m128, __m128)>();

  __m128 _mm_or_ps(
    __m128 _A,
    __m128 _B,
  ) {
    return __mm_or_ps(
      _A,
      _B,
    );
  }

  late final __mm_or_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128)>>('_mm_or_ps');
  late final __mm_or_ps =
      __mm_or_psPtr.asFunction<__m128 Function(__m128, __m128)>();

  __m128 _mm_xor_ps(
    __m128 _A,
    __m128 _B,
  ) {
    return __mm_xor_ps(
      _A,
      _B,
    );
  }

  late final __mm_xor_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128)>>(
          '_mm_xor_ps');
  late final __mm_xor_ps =
      __mm_xor_psPtr.asFunction<__m128 Function(__m128, __m128)>();

  __m128 _mm_cmpeq_ss(
    __m128 _A,
    __m128 _B,
  ) {
    return __mm_cmpeq_ss(
      _A,
      _B,
    );
  }

  late final __mm_cmpeq_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128)>>(
          '_mm_cmpeq_ss');
  late final __mm_cmpeq_ss =
      __mm_cmpeq_ssPtr.asFunction<__m128 Function(__m128, __m128)>();

  __m128 _mm_cmpeq_ps(
    __m128 _A,
    __m128 _B,
  ) {
    return __mm_cmpeq_ps(
      _A,
      _B,
    );
  }

  late final __mm_cmpeq_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128)>>(
          '_mm_cmpeq_ps');
  late final __mm_cmpeq_ps =
      __mm_cmpeq_psPtr.asFunction<__m128 Function(__m128, __m128)>();

  __m128 _mm_cmplt_ss(
    __m128 _A,
    __m128 _B,
  ) {
    return __mm_cmplt_ss(
      _A,
      _B,
    );
  }

  late final __mm_cmplt_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128)>>(
          '_mm_cmplt_ss');
  late final __mm_cmplt_ss =
      __mm_cmplt_ssPtr.asFunction<__m128 Function(__m128, __m128)>();

  __m128 _mm_cmplt_ps(
    __m128 _A,
    __m128 _B,
  ) {
    return __mm_cmplt_ps(
      _A,
      _B,
    );
  }

  late final __mm_cmplt_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128)>>(
          '_mm_cmplt_ps');
  late final __mm_cmplt_ps =
      __mm_cmplt_psPtr.asFunction<__m128 Function(__m128, __m128)>();

  __m128 _mm_cmple_ss(
    __m128 _A,
    __m128 _B,
  ) {
    return __mm_cmple_ss(
      _A,
      _B,
    );
  }

  late final __mm_cmple_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128)>>(
          '_mm_cmple_ss');
  late final __mm_cmple_ss =
      __mm_cmple_ssPtr.asFunction<__m128 Function(__m128, __m128)>();

  __m128 _mm_cmple_ps(
    __m128 _A,
    __m128 _B,
  ) {
    return __mm_cmple_ps(
      _A,
      _B,
    );
  }

  late final __mm_cmple_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128)>>(
          '_mm_cmple_ps');
  late final __mm_cmple_ps =
      __mm_cmple_psPtr.asFunction<__m128 Function(__m128, __m128)>();

  __m128 _mm_cmpgt_ss(
    __m128 _A,
    __m128 _B,
  ) {
    return __mm_cmpgt_ss(
      _A,
      _B,
    );
  }

  late final __mm_cmpgt_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128)>>(
          '_mm_cmpgt_ss');
  late final __mm_cmpgt_ss =
      __mm_cmpgt_ssPtr.asFunction<__m128 Function(__m128, __m128)>();

  __m128 _mm_cmpgt_ps(
    __m128 _A,
    __m128 _B,
  ) {
    return __mm_cmpgt_ps(
      _A,
      _B,
    );
  }

  late final __mm_cmpgt_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128)>>(
          '_mm_cmpgt_ps');
  late final __mm_cmpgt_ps =
      __mm_cmpgt_psPtr.asFunction<__m128 Function(__m128, __m128)>();

  __m128 _mm_cmpge_ss(
    __m128 _A,
    __m128 _B,
  ) {
    return __mm_cmpge_ss(
      _A,
      _B,
    );
  }

  late final __mm_cmpge_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128)>>(
          '_mm_cmpge_ss');
  late final __mm_cmpge_ss =
      __mm_cmpge_ssPtr.asFunction<__m128 Function(__m128, __m128)>();

  __m128 _mm_cmpge_ps(
    __m128 _A,
    __m128 _B,
  ) {
    return __mm_cmpge_ps(
      _A,
      _B,
    );
  }

  late final __mm_cmpge_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128)>>(
          '_mm_cmpge_ps');
  late final __mm_cmpge_ps =
      __mm_cmpge_psPtr.asFunction<__m128 Function(__m128, __m128)>();

  __m128 _mm_cmpneq_ss(
    __m128 _A,
    __m128 _B,
  ) {
    return __mm_cmpneq_ss(
      _A,
      _B,
    );
  }

  late final __mm_cmpneq_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128)>>(
          '_mm_cmpneq_ss');
  late final __mm_cmpneq_ss =
      __mm_cmpneq_ssPtr.asFunction<__m128 Function(__m128, __m128)>();

  __m128 _mm_cmpneq_ps(
    __m128 _A,
    __m128 _B,
  ) {
    return __mm_cmpneq_ps(
      _A,
      _B,
    );
  }

  late final __mm_cmpneq_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128)>>(
          '_mm_cmpneq_ps');
  late final __mm_cmpneq_ps =
      __mm_cmpneq_psPtr.asFunction<__m128 Function(__m128, __m128)>();

  __m128 _mm_cmpnlt_ss(
    __m128 _A,
    __m128 _B,
  ) {
    return __mm_cmpnlt_ss(
      _A,
      _B,
    );
  }

  late final __mm_cmpnlt_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128)>>(
          '_mm_cmpnlt_ss');
  late final __mm_cmpnlt_ss =
      __mm_cmpnlt_ssPtr.asFunction<__m128 Function(__m128, __m128)>();

  __m128 _mm_cmpnlt_ps(
    __m128 _A,
    __m128 _B,
  ) {
    return __mm_cmpnlt_ps(
      _A,
      _B,
    );
  }

  late final __mm_cmpnlt_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128)>>(
          '_mm_cmpnlt_ps');
  late final __mm_cmpnlt_ps =
      __mm_cmpnlt_psPtr.asFunction<__m128 Function(__m128, __m128)>();

  __m128 _mm_cmpnle_ss(
    __m128 _A,
    __m128 _B,
  ) {
    return __mm_cmpnle_ss(
      _A,
      _B,
    );
  }

  late final __mm_cmpnle_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128)>>(
          '_mm_cmpnle_ss');
  late final __mm_cmpnle_ss =
      __mm_cmpnle_ssPtr.asFunction<__m128 Function(__m128, __m128)>();

  __m128 _mm_cmpnle_ps(
    __m128 _A,
    __m128 _B,
  ) {
    return __mm_cmpnle_ps(
      _A,
      _B,
    );
  }

  late final __mm_cmpnle_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128)>>(
          '_mm_cmpnle_ps');
  late final __mm_cmpnle_ps =
      __mm_cmpnle_psPtr.asFunction<__m128 Function(__m128, __m128)>();

  __m128 _mm_cmpngt_ss(
    __m128 _A,
    __m128 _B,
  ) {
    return __mm_cmpngt_ss(
      _A,
      _B,
    );
  }

  late final __mm_cmpngt_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128)>>(
          '_mm_cmpngt_ss');
  late final __mm_cmpngt_ss =
      __mm_cmpngt_ssPtr.asFunction<__m128 Function(__m128, __m128)>();

  __m128 _mm_cmpngt_ps(
    __m128 _A,
    __m128 _B,
  ) {
    return __mm_cmpngt_ps(
      _A,
      _B,
    );
  }

  late final __mm_cmpngt_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128)>>(
          '_mm_cmpngt_ps');
  late final __mm_cmpngt_ps =
      __mm_cmpngt_psPtr.asFunction<__m128 Function(__m128, __m128)>();

  __m128 _mm_cmpnge_ss(
    __m128 _A,
    __m128 _B,
  ) {
    return __mm_cmpnge_ss(
      _A,
      _B,
    );
  }

  late final __mm_cmpnge_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128)>>(
          '_mm_cmpnge_ss');
  late final __mm_cmpnge_ss =
      __mm_cmpnge_ssPtr.asFunction<__m128 Function(__m128, __m128)>();

  __m128 _mm_cmpnge_ps(
    __m128 _A,
    __m128 _B,
  ) {
    return __mm_cmpnge_ps(
      _A,
      _B,
    );
  }

  late final __mm_cmpnge_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128)>>(
          '_mm_cmpnge_ps');
  late final __mm_cmpnge_ps =
      __mm_cmpnge_psPtr.asFunction<__m128 Function(__m128, __m128)>();

  __m128 _mm_cmpord_ss(
    __m128 _A,
    __m128 _B,
  ) {
    return __mm_cmpord_ss(
      _A,
      _B,
    );
  }

  late final __mm_cmpord_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128)>>(
          '_mm_cmpord_ss');
  late final __mm_cmpord_ss =
      __mm_cmpord_ssPtr.asFunction<__m128 Function(__m128, __m128)>();

  __m128 _mm_cmpord_ps(
    __m128 _A,
    __m128 _B,
  ) {
    return __mm_cmpord_ps(
      _A,
      _B,
    );
  }

  late final __mm_cmpord_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128)>>(
          '_mm_cmpord_ps');
  late final __mm_cmpord_ps =
      __mm_cmpord_psPtr.asFunction<__m128 Function(__m128, __m128)>();

  __m128 _mm_cmpunord_ss(
    __m128 _A,
    __m128 _B,
  ) {
    return __mm_cmpunord_ss(
      _A,
      _B,
    );
  }

  late final __mm_cmpunord_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128)>>(
          '_mm_cmpunord_ss');
  late final __mm_cmpunord_ss =
      __mm_cmpunord_ssPtr.asFunction<__m128 Function(__m128, __m128)>();

  __m128 _mm_cmpunord_ps(
    __m128 _A,
    __m128 _B,
  ) {
    return __mm_cmpunord_ps(
      _A,
      _B,
    );
  }

  late final __mm_cmpunord_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128)>>(
          '_mm_cmpunord_ps');
  late final __mm_cmpunord_ps =
      __mm_cmpunord_psPtr.asFunction<__m128 Function(__m128, __m128)>();

  int _mm_comieq_ss(
    __m128 _A,
    __m128 _B,
  ) {
    return __mm_comieq_ss(
      _A,
      _B,
    );
  }

  late final __mm_comieq_ssPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(__m128, __m128)>>(
          '_mm_comieq_ss');
  late final __mm_comieq_ss =
      __mm_comieq_ssPtr.asFunction<int Function(__m128, __m128)>();

  int _mm_comilt_ss(
    __m128 _A,
    __m128 _B,
  ) {
    return __mm_comilt_ss(
      _A,
      _B,
    );
  }

  late final __mm_comilt_ssPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(__m128, __m128)>>(
          '_mm_comilt_ss');
  late final __mm_comilt_ss =
      __mm_comilt_ssPtr.asFunction<int Function(__m128, __m128)>();

  int _mm_comile_ss(
    __m128 _A,
    __m128 _B,
  ) {
    return __mm_comile_ss(
      _A,
      _B,
    );
  }

  late final __mm_comile_ssPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(__m128, __m128)>>(
          '_mm_comile_ss');
  late final __mm_comile_ss =
      __mm_comile_ssPtr.asFunction<int Function(__m128, __m128)>();

  int _mm_comigt_ss(
    __m128 _A,
    __m128 _B,
  ) {
    return __mm_comigt_ss(
      _A,
      _B,
    );
  }

  late final __mm_comigt_ssPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(__m128, __m128)>>(
          '_mm_comigt_ss');
  late final __mm_comigt_ss =
      __mm_comigt_ssPtr.asFunction<int Function(__m128, __m128)>();

  int _mm_comige_ss(
    __m128 _A,
    __m128 _B,
  ) {
    return __mm_comige_ss(
      _A,
      _B,
    );
  }

  late final __mm_comige_ssPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(__m128, __m128)>>(
          '_mm_comige_ss');
  late final __mm_comige_ss =
      __mm_comige_ssPtr.asFunction<int Function(__m128, __m128)>();

  int _mm_comineq_ss(
    __m128 _A,
    __m128 _B,
  ) {
    return __mm_comineq_ss(
      _A,
      _B,
    );
  }

  late final __mm_comineq_ssPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(__m128, __m128)>>(
          '_mm_comineq_ss');
  late final __mm_comineq_ss =
      __mm_comineq_ssPtr.asFunction<int Function(__m128, __m128)>();

  int _mm_ucomieq_ss(
    __m128 _A,
    __m128 _B,
  ) {
    return __mm_ucomieq_ss(
      _A,
      _B,
    );
  }

  late final __mm_ucomieq_ssPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(__m128, __m128)>>(
          '_mm_ucomieq_ss');
  late final __mm_ucomieq_ss =
      __mm_ucomieq_ssPtr.asFunction<int Function(__m128, __m128)>();

  int _mm_ucomilt_ss(
    __m128 _A,
    __m128 _B,
  ) {
    return __mm_ucomilt_ss(
      _A,
      _B,
    );
  }

  late final __mm_ucomilt_ssPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(__m128, __m128)>>(
          '_mm_ucomilt_ss');
  late final __mm_ucomilt_ss =
      __mm_ucomilt_ssPtr.asFunction<int Function(__m128, __m128)>();

  int _mm_ucomile_ss(
    __m128 _A,
    __m128 _B,
  ) {
    return __mm_ucomile_ss(
      _A,
      _B,
    );
  }

  late final __mm_ucomile_ssPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(__m128, __m128)>>(
          '_mm_ucomile_ss');
  late final __mm_ucomile_ss =
      __mm_ucomile_ssPtr.asFunction<int Function(__m128, __m128)>();

  int _mm_ucomigt_ss(
    __m128 _A,
    __m128 _B,
  ) {
    return __mm_ucomigt_ss(
      _A,
      _B,
    );
  }

  late final __mm_ucomigt_ssPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(__m128, __m128)>>(
          '_mm_ucomigt_ss');
  late final __mm_ucomigt_ss =
      __mm_ucomigt_ssPtr.asFunction<int Function(__m128, __m128)>();

  int _mm_ucomige_ss(
    __m128 _A,
    __m128 _B,
  ) {
    return __mm_ucomige_ss(
      _A,
      _B,
    );
  }

  late final __mm_ucomige_ssPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(__m128, __m128)>>(
          '_mm_ucomige_ss');
  late final __mm_ucomige_ss =
      __mm_ucomige_ssPtr.asFunction<int Function(__m128, __m128)>();

  int _mm_ucomineq_ss(
    __m128 _A,
    __m128 _B,
  ) {
    return __mm_ucomineq_ss(
      _A,
      _B,
    );
  }

  late final __mm_ucomineq_ssPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(__m128, __m128)>>(
          '_mm_ucomineq_ss');
  late final __mm_ucomineq_ss =
      __mm_ucomineq_ssPtr.asFunction<int Function(__m128, __m128)>();

  int _mm_cvt_ss2si(
    __m128 _A,
  ) {
    return __mm_cvt_ss2si(
      _A,
    );
  }

  late final __mm_cvt_ss2siPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(__m128)>>('_mm_cvt_ss2si');
  late final __mm_cvt_ss2si =
      __mm_cvt_ss2siPtr.asFunction<int Function(__m128)>();

  int _mm_cvtt_ss2si(
    __m128 _A,
  ) {
    return __mm_cvtt_ss2si(
      _A,
    );
  }

  late final __mm_cvtt_ss2siPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(__m128)>>('_mm_cvtt_ss2si');
  late final __mm_cvtt_ss2si =
      __mm_cvtt_ss2siPtr.asFunction<int Function(__m128)>();

  __m128 _mm_cvt_si2ss(
    __m128 arg0,
    int arg1,
  ) {
    return __mm_cvt_si2ss(
      arg0,
      arg1,
    );
  }

  late final __mm_cvt_si2ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, ffi.Int32)>>(
          '_mm_cvt_si2ss');
  late final __mm_cvt_si2ss =
      __mm_cvt_si2ssPtr.asFunction<__m128 Function(__m128, int)>();

  double _mm_cvtss_f32(
    __m128 _A,
  ) {
    return __mm_cvtss_f32(
      _A,
    );
  }

  late final __mm_cvtss_f32Ptr =
      _lookup<ffi.NativeFunction<ffi.Float Function(__m128)>>('_mm_cvtss_f32');
  late final __mm_cvtss_f32 =
      __mm_cvtss_f32Ptr.asFunction<double Function(__m128)>();

  int _mm_cvtss_si64(
    __m128 _A,
  ) {
    return __mm_cvtss_si64(
      _A,
    );
  }

  late final __mm_cvtss_si64Ptr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(__m128)>>('_mm_cvtss_si64');
  late final __mm_cvtss_si64 =
      __mm_cvtss_si64Ptr.asFunction<int Function(__m128)>();

  int _mm_cvttss_si64(
    __m128 _A,
  ) {
    return __mm_cvttss_si64(
      _A,
    );
  }

  late final __mm_cvttss_si64Ptr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(__m128)>>(
          '_mm_cvttss_si64');
  late final __mm_cvttss_si64 =
      __mm_cvttss_si64Ptr.asFunction<int Function(__m128)>();

  __m128 _mm_cvtsi64_ss(
    __m128 _A,
    int _B,
  ) {
    return __mm_cvtsi64_ss(
      _A,
      _B,
    );
  }

  late final __mm_cvtsi64_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, ffi.Int64)>>(
          '_mm_cvtsi64_ss');
  late final __mm_cvtsi64_ss =
      __mm_cvtsi64_ssPtr.asFunction<__m128 Function(__m128, int)>();

  __m128 _mm_shuffle_ps(
    __m128 _A,
    __m128 _B,
    int _Imm8,
  ) {
    return __mm_shuffle_ps(
      _A,
      _B,
      _Imm8,
    );
  }

  late final __mm_shuffle_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128, ffi.Uint32)>>(
          '_mm_shuffle_ps');
  late final __mm_shuffle_ps =
      __mm_shuffle_psPtr.asFunction<__m128 Function(__m128, __m128, int)>();

  __m128 _mm_unpackhi_ps(
    __m128 _A,
    __m128 _B,
  ) {
    return __mm_unpackhi_ps(
      _A,
      _B,
    );
  }

  late final __mm_unpackhi_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128)>>(
          '_mm_unpackhi_ps');
  late final __mm_unpackhi_ps =
      __mm_unpackhi_psPtr.asFunction<__m128 Function(__m128, __m128)>();

  __m128 _mm_unpacklo_ps(
    __m128 _A,
    __m128 _B,
  ) {
    return __mm_unpacklo_ps(
      _A,
      _B,
    );
  }

  late final __mm_unpacklo_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128)>>(
          '_mm_unpacklo_ps');
  late final __mm_unpacklo_ps =
      __mm_unpacklo_psPtr.asFunction<__m128 Function(__m128, __m128)>();

  __m128 _mm_loadh_pi(
    __m128 arg0,
    ffi.Pointer<__m64> arg1,
  ) {
    return __mm_loadh_pi(
      arg0,
      arg1,
    );
  }

  late final __mm_loadh_piPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, ffi.Pointer<__m64>)>>(
          '_mm_loadh_pi');
  late final __mm_loadh_pi = __mm_loadh_piPtr
      .asFunction<__m128 Function(__m128, ffi.Pointer<__m64>)>();

  __m128 _mm_movehl_ps(
    __m128 arg0,
    __m128 arg1,
  ) {
    return __mm_movehl_ps(
      arg0,
      arg1,
    );
  }

  late final __mm_movehl_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128)>>(
          '_mm_movehl_ps');
  late final __mm_movehl_ps =
      __mm_movehl_psPtr.asFunction<__m128 Function(__m128, __m128)>();

  __m128 _mm_movelh_ps(
    __m128 arg0,
    __m128 arg1,
  ) {
    return __mm_movelh_ps(
      arg0,
      arg1,
    );
  }

  late final __mm_movelh_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128)>>(
          '_mm_movelh_ps');
  late final __mm_movelh_ps =
      __mm_movelh_psPtr.asFunction<__m128 Function(__m128, __m128)>();

  void _mm_storeh_pi(
    ffi.Pointer<__m64> arg0,
    __m128 arg1,
  ) {
    return __mm_storeh_pi(
      arg0,
      arg1,
    );
  }

  late final __mm_storeh_piPtr = _lookup<
          ffi.NativeFunction<ffi.Void Function(ffi.Pointer<__m64>, __m128)>>(
      '_mm_storeh_pi');
  late final __mm_storeh_pi =
      __mm_storeh_piPtr.asFunction<void Function(ffi.Pointer<__m64>, __m128)>();

  __m128 _mm_loadl_pi(
    __m128 arg0,
    ffi.Pointer<__m64> arg1,
  ) {
    return __mm_loadl_pi(
      arg0,
      arg1,
    );
  }

  late final __mm_loadl_piPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, ffi.Pointer<__m64>)>>(
          '_mm_loadl_pi');
  late final __mm_loadl_pi = __mm_loadl_piPtr
      .asFunction<__m128 Function(__m128, ffi.Pointer<__m64>)>();

  void _mm_storel_pi(
    ffi.Pointer<__m64> arg0,
    __m128 arg1,
  ) {
    return __mm_storel_pi(
      arg0,
      arg1,
    );
  }

  late final __mm_storel_piPtr = _lookup<
          ffi.NativeFunction<ffi.Void Function(ffi.Pointer<__m64>, __m128)>>(
      '_mm_storel_pi');
  late final __mm_storel_pi =
      __mm_storel_piPtr.asFunction<void Function(ffi.Pointer<__m64>, __m128)>();

  int _mm_movemask_ps(
    __m128 _A,
  ) {
    return __mm_movemask_ps(
      _A,
    );
  }

  late final __mm_movemask_psPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(__m128)>>(
          '_mm_movemask_ps');
  late final __mm_movemask_ps =
      __mm_movemask_psPtr.asFunction<int Function(__m128)>();

  __m128 _mm_set_ss(
    double _A,
  ) {
    return __mm_set_ss(
      _A,
    );
  }

  late final __mm_set_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(ffi.Float)>>('_mm_set_ss');
  late final __mm_set_ss = __mm_set_ssPtr.asFunction<__m128 Function(double)>();

  __m128 _mm_set_ps1(
    double _A,
  ) {
    return __mm_set_ps1(
      _A,
    );
  }

  late final __mm_set_ps1Ptr =
      _lookup<ffi.NativeFunction<__m128 Function(ffi.Float)>>('_mm_set_ps1');
  late final __mm_set_ps1 =
      __mm_set_ps1Ptr.asFunction<__m128 Function(double)>();

  __m128 _mm_set_ps(
    double _A,
    double _B,
    double _C,
    double _D,
  ) {
    return __mm_set_ps(
      _A,
      _B,
      _C,
      _D,
    );
  }

  late final __mm_set_psPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              ffi.Float, ffi.Float, ffi.Float, ffi.Float)>>('_mm_set_ps');
  late final __mm_set_ps = __mm_set_psPtr
      .asFunction<__m128 Function(double, double, double, double)>();

  __m128 _mm_setr_ps(
    double _A,
    double _B,
    double _C,
    double _D,
  ) {
    return __mm_setr_ps(
      _A,
      _B,
      _C,
      _D,
    );
  }

  late final __mm_setr_psPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              ffi.Float, ffi.Float, ffi.Float, ffi.Float)>>('_mm_setr_ps');
  late final __mm_setr_ps = __mm_setr_psPtr
      .asFunction<__m128 Function(double, double, double, double)>();

  __m128 _mm_setzero_ps() {
    return __mm_setzero_ps();
  }

  late final __mm_setzero_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function()>>('_mm_setzero_ps');
  late final __mm_setzero_ps =
      __mm_setzero_psPtr.asFunction<__m128 Function()>();

  __m128 _mm_load_ss(
    ffi.Pointer<ffi.Float> _A,
  ) {
    return __mm_load_ss(
      _A,
    );
  }

  late final __mm_load_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(ffi.Pointer<ffi.Float>)>>(
          '_mm_load_ss');
  late final __mm_load_ss =
      __mm_load_ssPtr.asFunction<__m128 Function(ffi.Pointer<ffi.Float>)>();

  __m128 _mm_load_ps1(
    ffi.Pointer<ffi.Float> _A,
  ) {
    return __mm_load_ps1(
      _A,
    );
  }

  late final __mm_load_ps1Ptr =
      _lookup<ffi.NativeFunction<__m128 Function(ffi.Pointer<ffi.Float>)>>(
          '_mm_load_ps1');
  late final __mm_load_ps1 =
      __mm_load_ps1Ptr.asFunction<__m128 Function(ffi.Pointer<ffi.Float>)>();

  __m128 _mm_load_ps(
    ffi.Pointer<ffi.Float> _A,
  ) {
    return __mm_load_ps(
      _A,
    );
  }

  late final __mm_load_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(ffi.Pointer<ffi.Float>)>>(
          '_mm_load_ps');
  late final __mm_load_ps =
      __mm_load_psPtr.asFunction<__m128 Function(ffi.Pointer<ffi.Float>)>();

  __m128 _mm_loadr_ps(
    ffi.Pointer<ffi.Float> _A,
  ) {
    return __mm_loadr_ps(
      _A,
    );
  }

  late final __mm_loadr_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(ffi.Pointer<ffi.Float>)>>(
          '_mm_loadr_ps');
  late final __mm_loadr_ps =
      __mm_loadr_psPtr.asFunction<__m128 Function(ffi.Pointer<ffi.Float>)>();

  __m128 _mm_loadu_ps(
    ffi.Pointer<ffi.Float> _A,
  ) {
    return __mm_loadu_ps(
      _A,
    );
  }

  late final __mm_loadu_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(ffi.Pointer<ffi.Float>)>>(
          '_mm_loadu_ps');
  late final __mm_loadu_ps =
      __mm_loadu_psPtr.asFunction<__m128 Function(ffi.Pointer<ffi.Float>)>();

  void _mm_store_ss(
    ffi.Pointer<ffi.Float> _V,
    __m128 _A,
  ) {
    return __mm_store_ss(
      _V,
      _A,
    );
  }

  late final __mm_store_ssPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Float>, __m128)>>('_mm_store_ss');
  late final __mm_store_ss = __mm_store_ssPtr
      .asFunction<void Function(ffi.Pointer<ffi.Float>, __m128)>();

  void _mm_store_ps1(
    ffi.Pointer<ffi.Float> _V,
    __m128 _A,
  ) {
    return __mm_store_ps1(
      _V,
      _A,
    );
  }

  late final __mm_store_ps1Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Float>, __m128)>>('_mm_store_ps1');
  late final __mm_store_ps1 = __mm_store_ps1Ptr
      .asFunction<void Function(ffi.Pointer<ffi.Float>, __m128)>();

  void _mm_store_ps(
    ffi.Pointer<ffi.Float> _V,
    __m128 _A,
  ) {
    return __mm_store_ps(
      _V,
      _A,
    );
  }

  late final __mm_store_psPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Float>, __m128)>>('_mm_store_ps');
  late final __mm_store_ps = __mm_store_psPtr
      .asFunction<void Function(ffi.Pointer<ffi.Float>, __m128)>();

  void _mm_storer_ps(
    ffi.Pointer<ffi.Float> _V,
    __m128 _A,
  ) {
    return __mm_storer_ps(
      _V,
      _A,
    );
  }

  late final __mm_storer_psPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Float>, __m128)>>('_mm_storer_ps');
  late final __mm_storer_ps = __mm_storer_psPtr
      .asFunction<void Function(ffi.Pointer<ffi.Float>, __m128)>();

  void _mm_storeu_ps(
    ffi.Pointer<ffi.Float> _V,
    __m128 _A,
  ) {
    return __mm_storeu_ps(
      _V,
      _A,
    );
  }

  late final __mm_storeu_psPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Float>, __m128)>>('_mm_storeu_ps');
  late final __mm_storeu_ps = __mm_storeu_psPtr
      .asFunction<void Function(ffi.Pointer<ffi.Float>, __m128)>();

  void _mm_prefetch(
    ffi.Pointer<ffi.Int8> _A,
    int _Sel,
  ) {
    return __mm_prefetch(
      _A,
      _Sel,
    );
  }

  late final __mm_prefetchPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Int8>, ffi.Int32)>>('_mm_prefetch');
  late final __mm_prefetch =
      __mm_prefetchPtr.asFunction<void Function(ffi.Pointer<ffi.Int8>, int)>();

  void _mm_stream_ps(
    ffi.Pointer<ffi.Float> arg0,
    __m128 arg1,
  ) {
    return __mm_stream_ps(
      arg0,
      arg1,
    );
  }

  late final __mm_stream_psPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Float>, __m128)>>('_mm_stream_ps');
  late final __mm_stream_ps = __mm_stream_psPtr
      .asFunction<void Function(ffi.Pointer<ffi.Float>, __m128)>();

  __m128 _mm_move_ss(
    __m128 _A,
    __m128 _B,
  ) {
    return __mm_move_ss(
      _A,
      _B,
    );
  }

  late final __mm_move_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128)>>(
          '_mm_move_ss');
  late final __mm_move_ss =
      __mm_move_ssPtr.asFunction<__m128 Function(__m128, __m128)>();

  void _mm_sfence() {
    return __mm_sfence();
  }

  late final __mm_sfencePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('_mm_sfence');
  late final __mm_sfence = __mm_sfencePtr.asFunction<void Function()>();

  int _mm_getcsr() {
    return __mm_getcsr();
  }

  late final __mm_getcsrPtr =
      _lookup<ffi.NativeFunction<ffi.Uint32 Function()>>('_mm_getcsr');
  late final __mm_getcsr = __mm_getcsrPtr.asFunction<int Function()>();

  void _mm_setcsr(
    int arg0,
  ) {
    return __mm_setcsr(
      arg0,
    );
  }

  late final __mm_setcsrPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Uint32)>>('_mm_setcsr');
  late final __mm_setcsr = __mm_setcsrPtr.asFunction<void Function(int)>();

  _m128d _mm_add_sd(
    _m128d _A,
    _m128d _B,
  ) {
    return __mm_add_sd(
      _A,
      _B,
    );
  }

  late final __mm_add_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d)>>(
          '_mm_add_sd');
  late final __mm_add_sd =
      __mm_add_sdPtr.asFunction<_m128d Function(_m128d, _m128d)>();

  _m128d _mm_add_pd(
    _m128d _A,
    _m128d _B,
  ) {
    return __mm_add_pd(
      _A,
      _B,
    );
  }

  late final __mm_add_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d)>>(
          '_mm_add_pd');
  late final __mm_add_pd =
      __mm_add_pdPtr.asFunction<_m128d Function(_m128d, _m128d)>();

  _m128d _mm_sub_sd(
    _m128d _A,
    _m128d _B,
  ) {
    return __mm_sub_sd(
      _A,
      _B,
    );
  }

  late final __mm_sub_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d)>>(
          '_mm_sub_sd');
  late final __mm_sub_sd =
      __mm_sub_sdPtr.asFunction<_m128d Function(_m128d, _m128d)>();

  _m128d _mm_sub_pd(
    _m128d _A,
    _m128d _B,
  ) {
    return __mm_sub_pd(
      _A,
      _B,
    );
  }

  late final __mm_sub_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d)>>(
          '_mm_sub_pd');
  late final __mm_sub_pd =
      __mm_sub_pdPtr.asFunction<_m128d Function(_m128d, _m128d)>();

  _m128d _mm_mul_sd(
    _m128d _A,
    _m128d _B,
  ) {
    return __mm_mul_sd(
      _A,
      _B,
    );
  }

  late final __mm_mul_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d)>>(
          '_mm_mul_sd');
  late final __mm_mul_sd =
      __mm_mul_sdPtr.asFunction<_m128d Function(_m128d, _m128d)>();

  _m128d _mm_mul_pd(
    _m128d _A,
    _m128d _B,
  ) {
    return __mm_mul_pd(
      _A,
      _B,
    );
  }

  late final __mm_mul_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d)>>(
          '_mm_mul_pd');
  late final __mm_mul_pd =
      __mm_mul_pdPtr.asFunction<_m128d Function(_m128d, _m128d)>();

  _m128d _mm_sqrt_sd(
    _m128d _A,
    _m128d _B,
  ) {
    return __mm_sqrt_sd(
      _A,
      _B,
    );
  }

  late final __mm_sqrt_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d)>>(
          '_mm_sqrt_sd');
  late final __mm_sqrt_sd =
      __mm_sqrt_sdPtr.asFunction<_m128d Function(_m128d, _m128d)>();

  _m128d _mm_sqrt_pd(
    _m128d _A,
  ) {
    return __mm_sqrt_pd(
      _A,
    );
  }

  late final __mm_sqrt_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d)>>('_mm_sqrt_pd');
  late final __mm_sqrt_pd =
      __mm_sqrt_pdPtr.asFunction<_m128d Function(_m128d)>();

  _m128d _mm_div_sd(
    _m128d _A,
    _m128d _B,
  ) {
    return __mm_div_sd(
      _A,
      _B,
    );
  }

  late final __mm_div_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d)>>(
          '_mm_div_sd');
  late final __mm_div_sd =
      __mm_div_sdPtr.asFunction<_m128d Function(_m128d, _m128d)>();

  _m128d _mm_div_pd(
    _m128d _A,
    _m128d _B,
  ) {
    return __mm_div_pd(
      _A,
      _B,
    );
  }

  late final __mm_div_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d)>>(
          '_mm_div_pd');
  late final __mm_div_pd =
      __mm_div_pdPtr.asFunction<_m128d Function(_m128d, _m128d)>();

  _m128d _mm_min_sd(
    _m128d _A,
    _m128d _B,
  ) {
    return __mm_min_sd(
      _A,
      _B,
    );
  }

  late final __mm_min_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d)>>(
          '_mm_min_sd');
  late final __mm_min_sd =
      __mm_min_sdPtr.asFunction<_m128d Function(_m128d, _m128d)>();

  _m128d _mm_min_pd(
    _m128d _A,
    _m128d _B,
  ) {
    return __mm_min_pd(
      _A,
      _B,
    );
  }

  late final __mm_min_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d)>>(
          '_mm_min_pd');
  late final __mm_min_pd =
      __mm_min_pdPtr.asFunction<_m128d Function(_m128d, _m128d)>();

  _m128d _mm_max_sd(
    _m128d _A,
    _m128d _B,
  ) {
    return __mm_max_sd(
      _A,
      _B,
    );
  }

  late final __mm_max_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d)>>(
          '_mm_max_sd');
  late final __mm_max_sd =
      __mm_max_sdPtr.asFunction<_m128d Function(_m128d, _m128d)>();

  _m128d _mm_max_pd(
    _m128d _A,
    _m128d _B,
  ) {
    return __mm_max_pd(
      _A,
      _B,
    );
  }

  late final __mm_max_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d)>>(
          '_mm_max_pd');
  late final __mm_max_pd =
      __mm_max_pdPtr.asFunction<_m128d Function(_m128d, _m128d)>();

  _m128d _mm_and_pd(
    _m128d _A,
    _m128d _B,
  ) {
    return __mm_and_pd(
      _A,
      _B,
    );
  }

  late final __mm_and_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d)>>(
          '_mm_and_pd');
  late final __mm_and_pd =
      __mm_and_pdPtr.asFunction<_m128d Function(_m128d, _m128d)>();

  _m128d _mm_andnot_pd(
    _m128d _A,
    _m128d _B,
  ) {
    return __mm_andnot_pd(
      _A,
      _B,
    );
  }

  late final __mm_andnot_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d)>>(
          '_mm_andnot_pd');
  late final __mm_andnot_pd =
      __mm_andnot_pdPtr.asFunction<_m128d Function(_m128d, _m128d)>();

  _m128d _mm_or_pd(
    _m128d _A,
    _m128d _B,
  ) {
    return __mm_or_pd(
      _A,
      _B,
    );
  }

  late final __mm_or_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d)>>('_mm_or_pd');
  late final __mm_or_pd =
      __mm_or_pdPtr.asFunction<_m128d Function(_m128d, _m128d)>();

  _m128d _mm_xor_pd(
    _m128d _A,
    _m128d _B,
  ) {
    return __mm_xor_pd(
      _A,
      _B,
    );
  }

  late final __mm_xor_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d)>>(
          '_mm_xor_pd');
  late final __mm_xor_pd =
      __mm_xor_pdPtr.asFunction<_m128d Function(_m128d, _m128d)>();

  _m128d _mm_cmpeq_sd(
    _m128d _A,
    _m128d _B,
  ) {
    return __mm_cmpeq_sd(
      _A,
      _B,
    );
  }

  late final __mm_cmpeq_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d)>>(
          '_mm_cmpeq_sd');
  late final __mm_cmpeq_sd =
      __mm_cmpeq_sdPtr.asFunction<_m128d Function(_m128d, _m128d)>();

  _m128d _mm_cmpeq_pd(
    _m128d _A,
    _m128d _B,
  ) {
    return __mm_cmpeq_pd(
      _A,
      _B,
    );
  }

  late final __mm_cmpeq_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d)>>(
          '_mm_cmpeq_pd');
  late final __mm_cmpeq_pd =
      __mm_cmpeq_pdPtr.asFunction<_m128d Function(_m128d, _m128d)>();

  _m128d _mm_cmplt_sd(
    _m128d _A,
    _m128d _B,
  ) {
    return __mm_cmplt_sd(
      _A,
      _B,
    );
  }

  late final __mm_cmplt_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d)>>(
          '_mm_cmplt_sd');
  late final __mm_cmplt_sd =
      __mm_cmplt_sdPtr.asFunction<_m128d Function(_m128d, _m128d)>();

  _m128d _mm_cmplt_pd(
    _m128d _A,
    _m128d _B,
  ) {
    return __mm_cmplt_pd(
      _A,
      _B,
    );
  }

  late final __mm_cmplt_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d)>>(
          '_mm_cmplt_pd');
  late final __mm_cmplt_pd =
      __mm_cmplt_pdPtr.asFunction<_m128d Function(_m128d, _m128d)>();

  _m128d _mm_cmple_sd(
    _m128d _A,
    _m128d _B,
  ) {
    return __mm_cmple_sd(
      _A,
      _B,
    );
  }

  late final __mm_cmple_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d)>>(
          '_mm_cmple_sd');
  late final __mm_cmple_sd =
      __mm_cmple_sdPtr.asFunction<_m128d Function(_m128d, _m128d)>();

  _m128d _mm_cmple_pd(
    _m128d _A,
    _m128d _B,
  ) {
    return __mm_cmple_pd(
      _A,
      _B,
    );
  }

  late final __mm_cmple_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d)>>(
          '_mm_cmple_pd');
  late final __mm_cmple_pd =
      __mm_cmple_pdPtr.asFunction<_m128d Function(_m128d, _m128d)>();

  _m128d _mm_cmpgt_sd(
    _m128d _A,
    _m128d _B,
  ) {
    return __mm_cmpgt_sd(
      _A,
      _B,
    );
  }

  late final __mm_cmpgt_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d)>>(
          '_mm_cmpgt_sd');
  late final __mm_cmpgt_sd =
      __mm_cmpgt_sdPtr.asFunction<_m128d Function(_m128d, _m128d)>();

  _m128d _mm_cmpgt_pd(
    _m128d _A,
    _m128d _B,
  ) {
    return __mm_cmpgt_pd(
      _A,
      _B,
    );
  }

  late final __mm_cmpgt_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d)>>(
          '_mm_cmpgt_pd');
  late final __mm_cmpgt_pd =
      __mm_cmpgt_pdPtr.asFunction<_m128d Function(_m128d, _m128d)>();

  _m128d _mm_cmpge_sd(
    _m128d _A,
    _m128d _B,
  ) {
    return __mm_cmpge_sd(
      _A,
      _B,
    );
  }

  late final __mm_cmpge_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d)>>(
          '_mm_cmpge_sd');
  late final __mm_cmpge_sd =
      __mm_cmpge_sdPtr.asFunction<_m128d Function(_m128d, _m128d)>();

  _m128d _mm_cmpge_pd(
    _m128d _A,
    _m128d _B,
  ) {
    return __mm_cmpge_pd(
      _A,
      _B,
    );
  }

  late final __mm_cmpge_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d)>>(
          '_mm_cmpge_pd');
  late final __mm_cmpge_pd =
      __mm_cmpge_pdPtr.asFunction<_m128d Function(_m128d, _m128d)>();

  _m128d _mm_cmpneq_sd(
    _m128d _A,
    _m128d _B,
  ) {
    return __mm_cmpneq_sd(
      _A,
      _B,
    );
  }

  late final __mm_cmpneq_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d)>>(
          '_mm_cmpneq_sd');
  late final __mm_cmpneq_sd =
      __mm_cmpneq_sdPtr.asFunction<_m128d Function(_m128d, _m128d)>();

  _m128d _mm_cmpneq_pd(
    _m128d _A,
    _m128d _B,
  ) {
    return __mm_cmpneq_pd(
      _A,
      _B,
    );
  }

  late final __mm_cmpneq_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d)>>(
          '_mm_cmpneq_pd');
  late final __mm_cmpneq_pd =
      __mm_cmpneq_pdPtr.asFunction<_m128d Function(_m128d, _m128d)>();

  _m128d _mm_cmpnlt_sd(
    _m128d _A,
    _m128d _B,
  ) {
    return __mm_cmpnlt_sd(
      _A,
      _B,
    );
  }

  late final __mm_cmpnlt_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d)>>(
          '_mm_cmpnlt_sd');
  late final __mm_cmpnlt_sd =
      __mm_cmpnlt_sdPtr.asFunction<_m128d Function(_m128d, _m128d)>();

  _m128d _mm_cmpnlt_pd(
    _m128d _A,
    _m128d _B,
  ) {
    return __mm_cmpnlt_pd(
      _A,
      _B,
    );
  }

  late final __mm_cmpnlt_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d)>>(
          '_mm_cmpnlt_pd');
  late final __mm_cmpnlt_pd =
      __mm_cmpnlt_pdPtr.asFunction<_m128d Function(_m128d, _m128d)>();

  _m128d _mm_cmpnle_sd(
    _m128d _A,
    _m128d _B,
  ) {
    return __mm_cmpnle_sd(
      _A,
      _B,
    );
  }

  late final __mm_cmpnle_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d)>>(
          '_mm_cmpnle_sd');
  late final __mm_cmpnle_sd =
      __mm_cmpnle_sdPtr.asFunction<_m128d Function(_m128d, _m128d)>();

  _m128d _mm_cmpnle_pd(
    _m128d _A,
    _m128d _B,
  ) {
    return __mm_cmpnle_pd(
      _A,
      _B,
    );
  }

  late final __mm_cmpnle_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d)>>(
          '_mm_cmpnle_pd');
  late final __mm_cmpnle_pd =
      __mm_cmpnle_pdPtr.asFunction<_m128d Function(_m128d, _m128d)>();

  _m128d _mm_cmpngt_sd(
    _m128d _A,
    _m128d _B,
  ) {
    return __mm_cmpngt_sd(
      _A,
      _B,
    );
  }

  late final __mm_cmpngt_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d)>>(
          '_mm_cmpngt_sd');
  late final __mm_cmpngt_sd =
      __mm_cmpngt_sdPtr.asFunction<_m128d Function(_m128d, _m128d)>();

  _m128d _mm_cmpngt_pd(
    _m128d _A,
    _m128d _B,
  ) {
    return __mm_cmpngt_pd(
      _A,
      _B,
    );
  }

  late final __mm_cmpngt_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d)>>(
          '_mm_cmpngt_pd');
  late final __mm_cmpngt_pd =
      __mm_cmpngt_pdPtr.asFunction<_m128d Function(_m128d, _m128d)>();

  _m128d _mm_cmpnge_sd(
    _m128d _A,
    _m128d _B,
  ) {
    return __mm_cmpnge_sd(
      _A,
      _B,
    );
  }

  late final __mm_cmpnge_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d)>>(
          '_mm_cmpnge_sd');
  late final __mm_cmpnge_sd =
      __mm_cmpnge_sdPtr.asFunction<_m128d Function(_m128d, _m128d)>();

  _m128d _mm_cmpnge_pd(
    _m128d _A,
    _m128d _B,
  ) {
    return __mm_cmpnge_pd(
      _A,
      _B,
    );
  }

  late final __mm_cmpnge_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d)>>(
          '_mm_cmpnge_pd');
  late final __mm_cmpnge_pd =
      __mm_cmpnge_pdPtr.asFunction<_m128d Function(_m128d, _m128d)>();

  _m128d _mm_cmpord_pd(
    _m128d _A,
    _m128d _B,
  ) {
    return __mm_cmpord_pd(
      _A,
      _B,
    );
  }

  late final __mm_cmpord_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d)>>(
          '_mm_cmpord_pd');
  late final __mm_cmpord_pd =
      __mm_cmpord_pdPtr.asFunction<_m128d Function(_m128d, _m128d)>();

  _m128d _mm_cmpord_sd(
    _m128d _A,
    _m128d _B,
  ) {
    return __mm_cmpord_sd(
      _A,
      _B,
    );
  }

  late final __mm_cmpord_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d)>>(
          '_mm_cmpord_sd');
  late final __mm_cmpord_sd =
      __mm_cmpord_sdPtr.asFunction<_m128d Function(_m128d, _m128d)>();

  _m128d _mm_cmpunord_pd(
    _m128d _A,
    _m128d _B,
  ) {
    return __mm_cmpunord_pd(
      _A,
      _B,
    );
  }

  late final __mm_cmpunord_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d)>>(
          '_mm_cmpunord_pd');
  late final __mm_cmpunord_pd =
      __mm_cmpunord_pdPtr.asFunction<_m128d Function(_m128d, _m128d)>();

  _m128d _mm_cmpunord_sd(
    _m128d _A,
    _m128d _B,
  ) {
    return __mm_cmpunord_sd(
      _A,
      _B,
    );
  }

  late final __mm_cmpunord_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d)>>(
          '_mm_cmpunord_sd');
  late final __mm_cmpunord_sd =
      __mm_cmpunord_sdPtr.asFunction<_m128d Function(_m128d, _m128d)>();

  int _mm_comieq_sd(
    _m128d _A,
    _m128d _B,
  ) {
    return __mm_comieq_sd(
      _A,
      _B,
    );
  }

  late final __mm_comieq_sdPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(_m128d, _m128d)>>(
          '_mm_comieq_sd');
  late final __mm_comieq_sd =
      __mm_comieq_sdPtr.asFunction<int Function(_m128d, _m128d)>();

  int _mm_comilt_sd(
    _m128d _A,
    _m128d _B,
  ) {
    return __mm_comilt_sd(
      _A,
      _B,
    );
  }

  late final __mm_comilt_sdPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(_m128d, _m128d)>>(
          '_mm_comilt_sd');
  late final __mm_comilt_sd =
      __mm_comilt_sdPtr.asFunction<int Function(_m128d, _m128d)>();

  int _mm_comile_sd(
    _m128d _A,
    _m128d _B,
  ) {
    return __mm_comile_sd(
      _A,
      _B,
    );
  }

  late final __mm_comile_sdPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(_m128d, _m128d)>>(
          '_mm_comile_sd');
  late final __mm_comile_sd =
      __mm_comile_sdPtr.asFunction<int Function(_m128d, _m128d)>();

  int _mm_comigt_sd(
    _m128d _A,
    _m128d _B,
  ) {
    return __mm_comigt_sd(
      _A,
      _B,
    );
  }

  late final __mm_comigt_sdPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(_m128d, _m128d)>>(
          '_mm_comigt_sd');
  late final __mm_comigt_sd =
      __mm_comigt_sdPtr.asFunction<int Function(_m128d, _m128d)>();

  int _mm_comige_sd(
    _m128d _A,
    _m128d _B,
  ) {
    return __mm_comige_sd(
      _A,
      _B,
    );
  }

  late final __mm_comige_sdPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(_m128d, _m128d)>>(
          '_mm_comige_sd');
  late final __mm_comige_sd =
      __mm_comige_sdPtr.asFunction<int Function(_m128d, _m128d)>();

  int _mm_comineq_sd(
    _m128d _A,
    _m128d _B,
  ) {
    return __mm_comineq_sd(
      _A,
      _B,
    );
  }

  late final __mm_comineq_sdPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(_m128d, _m128d)>>(
          '_mm_comineq_sd');
  late final __mm_comineq_sd =
      __mm_comineq_sdPtr.asFunction<int Function(_m128d, _m128d)>();

  int _mm_ucomieq_sd(
    _m128d _A,
    _m128d _B,
  ) {
    return __mm_ucomieq_sd(
      _A,
      _B,
    );
  }

  late final __mm_ucomieq_sdPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(_m128d, _m128d)>>(
          '_mm_ucomieq_sd');
  late final __mm_ucomieq_sd =
      __mm_ucomieq_sdPtr.asFunction<int Function(_m128d, _m128d)>();

  int _mm_ucomilt_sd(
    _m128d _A,
    _m128d _B,
  ) {
    return __mm_ucomilt_sd(
      _A,
      _B,
    );
  }

  late final __mm_ucomilt_sdPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(_m128d, _m128d)>>(
          '_mm_ucomilt_sd');
  late final __mm_ucomilt_sd =
      __mm_ucomilt_sdPtr.asFunction<int Function(_m128d, _m128d)>();

  int _mm_ucomile_sd(
    _m128d _A,
    _m128d _B,
  ) {
    return __mm_ucomile_sd(
      _A,
      _B,
    );
  }

  late final __mm_ucomile_sdPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(_m128d, _m128d)>>(
          '_mm_ucomile_sd');
  late final __mm_ucomile_sd =
      __mm_ucomile_sdPtr.asFunction<int Function(_m128d, _m128d)>();

  int _mm_ucomigt_sd(
    _m128d _A,
    _m128d _B,
  ) {
    return __mm_ucomigt_sd(
      _A,
      _B,
    );
  }

  late final __mm_ucomigt_sdPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(_m128d, _m128d)>>(
          '_mm_ucomigt_sd');
  late final __mm_ucomigt_sd =
      __mm_ucomigt_sdPtr.asFunction<int Function(_m128d, _m128d)>();

  int _mm_ucomige_sd(
    _m128d _A,
    _m128d _B,
  ) {
    return __mm_ucomige_sd(
      _A,
      _B,
    );
  }

  late final __mm_ucomige_sdPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(_m128d, _m128d)>>(
          '_mm_ucomige_sd');
  late final __mm_ucomige_sd =
      __mm_ucomige_sdPtr.asFunction<int Function(_m128d, _m128d)>();

  int _mm_ucomineq_sd(
    _m128d _A,
    _m128d _B,
  ) {
    return __mm_ucomineq_sd(
      _A,
      _B,
    );
  }

  late final __mm_ucomineq_sdPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(_m128d, _m128d)>>(
          '_mm_ucomineq_sd');
  late final __mm_ucomineq_sd =
      __mm_ucomineq_sdPtr.asFunction<int Function(_m128d, _m128d)>();

  _m128d _mm_cvtepi32_pd(
    __m128i _A,
  ) {
    return __mm_cvtepi32_pd(
      _A,
    );
  }

  late final __mm_cvtepi32_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(__m128i)>>('_mm_cvtepi32_pd');
  late final __mm_cvtepi32_pd =
      __mm_cvtepi32_pdPtr.asFunction<_m128d Function(__m128i)>();

  __m128i _mm_cvtpd_epi32(
    _m128d _A,
  ) {
    return __mm_cvtpd_epi32(
      _A,
    );
  }

  late final __mm_cvtpd_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(_m128d)>>('_mm_cvtpd_epi32');
  late final __mm_cvtpd_epi32 =
      __mm_cvtpd_epi32Ptr.asFunction<__m128i Function(_m128d)>();

  __m128i _mm_cvttpd_epi32(
    _m128d _A,
  ) {
    return __mm_cvttpd_epi32(
      _A,
    );
  }

  late final __mm_cvttpd_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(_m128d)>>('_mm_cvttpd_epi32');
  late final __mm_cvttpd_epi32 =
      __mm_cvttpd_epi32Ptr.asFunction<__m128i Function(_m128d)>();

  __m128 _mm_cvtepi32_ps(
    __m128i _A,
  ) {
    return __mm_cvtepi32_ps(
      _A,
    );
  }

  late final __mm_cvtepi32_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128i)>>('_mm_cvtepi32_ps');
  late final __mm_cvtepi32_ps =
      __mm_cvtepi32_psPtr.asFunction<__m128 Function(__m128i)>();

  __m128i _mm_cvtps_epi32(
    __m128 _A,
  ) {
    return __mm_cvtps_epi32(
      _A,
    );
  }

  late final __mm_cvtps_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128)>>('_mm_cvtps_epi32');
  late final __mm_cvtps_epi32 =
      __mm_cvtps_epi32Ptr.asFunction<__m128i Function(__m128)>();

  __m128i _mm_cvttps_epi32(
    __m128 _A,
  ) {
    return __mm_cvttps_epi32(
      _A,
    );
  }

  late final __mm_cvttps_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128)>>('_mm_cvttps_epi32');
  late final __mm_cvttps_epi32 =
      __mm_cvttps_epi32Ptr.asFunction<__m128i Function(__m128)>();

  __m128 _mm_cvtpd_ps(
    _m128d _A,
  ) {
    return __mm_cvtpd_ps(
      _A,
    );
  }

  late final __mm_cvtpd_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(_m128d)>>('_mm_cvtpd_ps');
  late final __mm_cvtpd_ps =
      __mm_cvtpd_psPtr.asFunction<__m128 Function(_m128d)>();

  _m128d _mm_cvtps_pd(
    __m128 _A,
  ) {
    return __mm_cvtps_pd(
      _A,
    );
  }

  late final __mm_cvtps_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(__m128)>>('_mm_cvtps_pd');
  late final __mm_cvtps_pd =
      __mm_cvtps_pdPtr.asFunction<_m128d Function(__m128)>();

  __m128 _mm_cvtsd_ss(
    __m128 _A,
    _m128d _B,
  ) {
    return __mm_cvtsd_ss(
      _A,
      _B,
    );
  }

  late final __mm_cvtsd_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, _m128d)>>(
          '_mm_cvtsd_ss');
  late final __mm_cvtsd_ss =
      __mm_cvtsd_ssPtr.asFunction<__m128 Function(__m128, _m128d)>();

  _m128d _mm_cvtss_sd(
    _m128d _A,
    __m128 _B,
  ) {
    return __mm_cvtss_sd(
      _A,
      _B,
    );
  }

  late final __mm_cvtss_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, __m128)>>(
          '_mm_cvtss_sd');
  late final __mm_cvtss_sd =
      __mm_cvtss_sdPtr.asFunction<_m128d Function(_m128d, __m128)>();

  int _mm_cvtsd_si32(
    _m128d _A,
  ) {
    return __mm_cvtsd_si32(
      _A,
    );
  }

  late final __mm_cvtsd_si32Ptr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(_m128d)>>('_mm_cvtsd_si32');
  late final __mm_cvtsd_si32 =
      __mm_cvtsd_si32Ptr.asFunction<int Function(_m128d)>();

  int _mm_cvttsd_si32(
    _m128d _A,
  ) {
    return __mm_cvttsd_si32(
      _A,
    );
  }

  late final __mm_cvttsd_si32Ptr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(_m128d)>>(
          '_mm_cvttsd_si32');
  late final __mm_cvttsd_si32 =
      __mm_cvttsd_si32Ptr.asFunction<int Function(_m128d)>();

  _m128d _mm_cvtsi32_sd(
    _m128d _A,
    int _B,
  ) {
    return __mm_cvtsi32_sd(
      _A,
      _B,
    );
  }

  late final __mm_cvtsi32_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, ffi.Int32)>>(
          '_mm_cvtsi32_sd');
  late final __mm_cvtsi32_sd =
      __mm_cvtsi32_sdPtr.asFunction<_m128d Function(_m128d, int)>();

  _m128d _mm_unpackhi_pd(
    _m128d _A,
    _m128d _B,
  ) {
    return __mm_unpackhi_pd(
      _A,
      _B,
    );
  }

  late final __mm_unpackhi_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d)>>(
          '_mm_unpackhi_pd');
  late final __mm_unpackhi_pd =
      __mm_unpackhi_pdPtr.asFunction<_m128d Function(_m128d, _m128d)>();

  _m128d _mm_unpacklo_pd(
    _m128d _A,
    _m128d _B,
  ) {
    return __mm_unpacklo_pd(
      _A,
      _B,
    );
  }

  late final __mm_unpacklo_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d)>>(
          '_mm_unpacklo_pd');
  late final __mm_unpacklo_pd =
      __mm_unpacklo_pdPtr.asFunction<_m128d Function(_m128d, _m128d)>();

  int _mm_movemask_pd(
    _m128d _A,
  ) {
    return __mm_movemask_pd(
      _A,
    );
  }

  late final __mm_movemask_pdPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(_m128d)>>(
          '_mm_movemask_pd');
  late final __mm_movemask_pd =
      __mm_movemask_pdPtr.asFunction<int Function(_m128d)>();

  _m128d _mm_shuffle_pd(
    _m128d _A,
    _m128d _B,
    int _I,
  ) {
    return __mm_shuffle_pd(
      _A,
      _B,
      _I,
    );
  }

  late final __mm_shuffle_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d, ffi.Int32)>>(
          '_mm_shuffle_pd');
  late final __mm_shuffle_pd =
      __mm_shuffle_pdPtr.asFunction<_m128d Function(_m128d, _m128d, int)>();

  _m128d _mm_load_pd(
    ffi.Pointer<ffi.Double> _Dp,
  ) {
    return __mm_load_pd(
      _Dp,
    );
  }

  late final __mm_load_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(ffi.Pointer<ffi.Double>)>>(
          '_mm_load_pd');
  late final __mm_load_pd =
      __mm_load_pdPtr.asFunction<_m128d Function(ffi.Pointer<ffi.Double>)>();

  _m128d _mm_load1_pd(
    ffi.Pointer<ffi.Double> _Dp,
  ) {
    return __mm_load1_pd(
      _Dp,
    );
  }

  late final __mm_load1_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(ffi.Pointer<ffi.Double>)>>(
          '_mm_load1_pd');
  late final __mm_load1_pd =
      __mm_load1_pdPtr.asFunction<_m128d Function(ffi.Pointer<ffi.Double>)>();

  _m128d _mm_loadr_pd(
    ffi.Pointer<ffi.Double> _Dp,
  ) {
    return __mm_loadr_pd(
      _Dp,
    );
  }

  late final __mm_loadr_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(ffi.Pointer<ffi.Double>)>>(
          '_mm_loadr_pd');
  late final __mm_loadr_pd =
      __mm_loadr_pdPtr.asFunction<_m128d Function(ffi.Pointer<ffi.Double>)>();

  _m128d _mm_loadu_pd(
    ffi.Pointer<ffi.Double> _Dp,
  ) {
    return __mm_loadu_pd(
      _Dp,
    );
  }

  late final __mm_loadu_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(ffi.Pointer<ffi.Double>)>>(
          '_mm_loadu_pd');
  late final __mm_loadu_pd =
      __mm_loadu_pdPtr.asFunction<_m128d Function(ffi.Pointer<ffi.Double>)>();

  _m128d _mm_load_sd(
    ffi.Pointer<ffi.Double> _Dp,
  ) {
    return __mm_load_sd(
      _Dp,
    );
  }

  late final __mm_load_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(ffi.Pointer<ffi.Double>)>>(
          '_mm_load_sd');
  late final __mm_load_sd =
      __mm_load_sdPtr.asFunction<_m128d Function(ffi.Pointer<ffi.Double>)>();

  _m128d _mm_loadh_pd(
    _m128d _A,
    ffi.Pointer<ffi.Double> _Dp,
  ) {
    return __mm_loadh_pd(
      _A,
      _Dp,
    );
  }

  late final __mm_loadh_pdPtr = _lookup<
          ffi.NativeFunction<_m128d Function(_m128d, ffi.Pointer<ffi.Double>)>>(
      '_mm_loadh_pd');
  late final __mm_loadh_pd = __mm_loadh_pdPtr
      .asFunction<_m128d Function(_m128d, ffi.Pointer<ffi.Double>)>();

  _m128d _mm_loadl_pd(
    _m128d _A,
    ffi.Pointer<ffi.Double> _Dp,
  ) {
    return __mm_loadl_pd(
      _A,
      _Dp,
    );
  }

  late final __mm_loadl_pdPtr = _lookup<
          ffi.NativeFunction<_m128d Function(_m128d, ffi.Pointer<ffi.Double>)>>(
      '_mm_loadl_pd');
  late final __mm_loadl_pd = __mm_loadl_pdPtr
      .asFunction<_m128d Function(_m128d, ffi.Pointer<ffi.Double>)>();

  _m128d _mm_set_sd(
    double _W,
  ) {
    return __mm_set_sd(
      _W,
    );
  }

  late final __mm_set_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(ffi.Double)>>('_mm_set_sd');
  late final __mm_set_sd = __mm_set_sdPtr.asFunction<_m128d Function(double)>();

  _m128d _mm_set1_pd(
    double _A,
  ) {
    return __mm_set1_pd(
      _A,
    );
  }

  late final __mm_set1_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(ffi.Double)>>('_mm_set1_pd');
  late final __mm_set1_pd =
      __mm_set1_pdPtr.asFunction<_m128d Function(double)>();

  _m128d _mm_set_pd(
    double _Z,
    double _Y,
  ) {
    return __mm_set_pd(
      _Z,
      _Y,
    );
  }

  late final __mm_set_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(ffi.Double, ffi.Double)>>(
          '_mm_set_pd');
  late final __mm_set_pd =
      __mm_set_pdPtr.asFunction<_m128d Function(double, double)>();

  _m128d _mm_setr_pd(
    double _Y,
    double _Z,
  ) {
    return __mm_setr_pd(
      _Y,
      _Z,
    );
  }

  late final __mm_setr_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(ffi.Double, ffi.Double)>>(
          '_mm_setr_pd');
  late final __mm_setr_pd =
      __mm_setr_pdPtr.asFunction<_m128d Function(double, double)>();

  _m128d _mm_setzero_pd() {
    return __mm_setzero_pd();
  }

  late final __mm_setzero_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function()>>('_mm_setzero_pd');
  late final __mm_setzero_pd =
      __mm_setzero_pdPtr.asFunction<_m128d Function()>();

  _m128d _mm_move_sd(
    _m128d _A,
    _m128d _B,
  ) {
    return __mm_move_sd(
      _A,
      _B,
    );
  }

  late final __mm_move_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d)>>(
          '_mm_move_sd');
  late final __mm_move_sd =
      __mm_move_sdPtr.asFunction<_m128d Function(_m128d, _m128d)>();

  void _mm_store_sd(
    ffi.Pointer<ffi.Double> _Dp,
    _m128d _A,
  ) {
    return __mm_store_sd(
      _Dp,
      _A,
    );
  }

  late final __mm_store_sdPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Double>, _m128d)>>('_mm_store_sd');
  late final __mm_store_sd = __mm_store_sdPtr
      .asFunction<void Function(ffi.Pointer<ffi.Double>, _m128d)>();

  void _mm_store1_pd(
    ffi.Pointer<ffi.Double> _Dp,
    _m128d _A,
  ) {
    return __mm_store1_pd(
      _Dp,
      _A,
    );
  }

  late final __mm_store1_pdPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Double>, _m128d)>>('_mm_store1_pd');
  late final __mm_store1_pd = __mm_store1_pdPtr
      .asFunction<void Function(ffi.Pointer<ffi.Double>, _m128d)>();

  void _mm_store_pd(
    ffi.Pointer<ffi.Double> _Dp,
    _m128d _A,
  ) {
    return __mm_store_pd(
      _Dp,
      _A,
    );
  }

  late final __mm_store_pdPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Double>, _m128d)>>('_mm_store_pd');
  late final __mm_store_pd = __mm_store_pdPtr
      .asFunction<void Function(ffi.Pointer<ffi.Double>, _m128d)>();

  void _mm_storeu_pd(
    ffi.Pointer<ffi.Double> _Dp,
    _m128d _A,
  ) {
    return __mm_storeu_pd(
      _Dp,
      _A,
    );
  }

  late final __mm_storeu_pdPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Double>, _m128d)>>('_mm_storeu_pd');
  late final __mm_storeu_pd = __mm_storeu_pdPtr
      .asFunction<void Function(ffi.Pointer<ffi.Double>, _m128d)>();

  void _mm_storer_pd(
    ffi.Pointer<ffi.Double> _Dp,
    _m128d _A,
  ) {
    return __mm_storer_pd(
      _Dp,
      _A,
    );
  }

  late final __mm_storer_pdPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Double>, _m128d)>>('_mm_storer_pd');
  late final __mm_storer_pd = __mm_storer_pdPtr
      .asFunction<void Function(ffi.Pointer<ffi.Double>, _m128d)>();

  void _mm_storeh_pd(
    ffi.Pointer<ffi.Double> _Dp,
    _m128d _A,
  ) {
    return __mm_storeh_pd(
      _Dp,
      _A,
    );
  }

  late final __mm_storeh_pdPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Double>, _m128d)>>('_mm_storeh_pd');
  late final __mm_storeh_pd = __mm_storeh_pdPtr
      .asFunction<void Function(ffi.Pointer<ffi.Double>, _m128d)>();

  void _mm_storel_pd(
    ffi.Pointer<ffi.Double> _Dp,
    _m128d _A,
  ) {
    return __mm_storel_pd(
      _Dp,
      _A,
    );
  }

  late final __mm_storel_pdPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Double>, _m128d)>>('_mm_storel_pd');
  late final __mm_storel_pd = __mm_storel_pdPtr
      .asFunction<void Function(ffi.Pointer<ffi.Double>, _m128d)>();

  __m128i _mm_add_epi8(
    __m128i _A,
    __m128i _B,
  ) {
    return __mm_add_epi8(
      _A,
      _B,
    );
  }

  late final __mm_add_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_add_epi8');
  late final __mm_add_epi8 =
      __mm_add_epi8Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_add_epi16(
    __m128i _A,
    __m128i _B,
  ) {
    return __mm_add_epi16(
      _A,
      _B,
    );
  }

  late final __mm_add_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_add_epi16');
  late final __mm_add_epi16 =
      __mm_add_epi16Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_add_epi32(
    __m128i _A,
    __m128i _B,
  ) {
    return __mm_add_epi32(
      _A,
      _B,
    );
  }

  late final __mm_add_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_add_epi32');
  late final __mm_add_epi32 =
      __mm_add_epi32Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_add_epi64(
    __m128i _A,
    __m128i _B,
  ) {
    return __mm_add_epi64(
      _A,
      _B,
    );
  }

  late final __mm_add_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_add_epi64');
  late final __mm_add_epi64 =
      __mm_add_epi64Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_adds_epi8(
    __m128i _A,
    __m128i _B,
  ) {
    return __mm_adds_epi8(
      _A,
      _B,
    );
  }

  late final __mm_adds_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_adds_epi8');
  late final __mm_adds_epi8 =
      __mm_adds_epi8Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_adds_epi16(
    __m128i _A,
    __m128i _B,
  ) {
    return __mm_adds_epi16(
      _A,
      _B,
    );
  }

  late final __mm_adds_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_adds_epi16');
  late final __mm_adds_epi16 =
      __mm_adds_epi16Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_adds_epu8(
    __m128i _A,
    __m128i _B,
  ) {
    return __mm_adds_epu8(
      _A,
      _B,
    );
  }

  late final __mm_adds_epu8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_adds_epu8');
  late final __mm_adds_epu8 =
      __mm_adds_epu8Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_adds_epu16(
    __m128i _A,
    __m128i _B,
  ) {
    return __mm_adds_epu16(
      _A,
      _B,
    );
  }

  late final __mm_adds_epu16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_adds_epu16');
  late final __mm_adds_epu16 =
      __mm_adds_epu16Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_avg_epu8(
    __m128i _A,
    __m128i _B,
  ) {
    return __mm_avg_epu8(
      _A,
      _B,
    );
  }

  late final __mm_avg_epu8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_avg_epu8');
  late final __mm_avg_epu8 =
      __mm_avg_epu8Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_avg_epu16(
    __m128i _A,
    __m128i _B,
  ) {
    return __mm_avg_epu16(
      _A,
      _B,
    );
  }

  late final __mm_avg_epu16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_avg_epu16');
  late final __mm_avg_epu16 =
      __mm_avg_epu16Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_madd_epi16(
    __m128i _A,
    __m128i _B,
  ) {
    return __mm_madd_epi16(
      _A,
      _B,
    );
  }

  late final __mm_madd_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_madd_epi16');
  late final __mm_madd_epi16 =
      __mm_madd_epi16Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_max_epi16(
    __m128i _A,
    __m128i _B,
  ) {
    return __mm_max_epi16(
      _A,
      _B,
    );
  }

  late final __mm_max_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_max_epi16');
  late final __mm_max_epi16 =
      __mm_max_epi16Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_max_epu8(
    __m128i _A,
    __m128i _B,
  ) {
    return __mm_max_epu8(
      _A,
      _B,
    );
  }

  late final __mm_max_epu8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_max_epu8');
  late final __mm_max_epu8 =
      __mm_max_epu8Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_min_epi16(
    __m128i _A,
    __m128i _B,
  ) {
    return __mm_min_epi16(
      _A,
      _B,
    );
  }

  late final __mm_min_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_min_epi16');
  late final __mm_min_epi16 =
      __mm_min_epi16Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_min_epu8(
    __m128i _A,
    __m128i _B,
  ) {
    return __mm_min_epu8(
      _A,
      _B,
    );
  }

  late final __mm_min_epu8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_min_epu8');
  late final __mm_min_epu8 =
      __mm_min_epu8Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_mulhi_epi16(
    __m128i _A,
    __m128i _B,
  ) {
    return __mm_mulhi_epi16(
      _A,
      _B,
    );
  }

  late final __mm_mulhi_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_mulhi_epi16');
  late final __mm_mulhi_epi16 =
      __mm_mulhi_epi16Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_mulhi_epu16(
    __m128i _A,
    __m128i _B,
  ) {
    return __mm_mulhi_epu16(
      _A,
      _B,
    );
  }

  late final __mm_mulhi_epu16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_mulhi_epu16');
  late final __mm_mulhi_epu16 =
      __mm_mulhi_epu16Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_mullo_epi16(
    __m128i _A,
    __m128i _B,
  ) {
    return __mm_mullo_epi16(
      _A,
      _B,
    );
  }

  late final __mm_mullo_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_mullo_epi16');
  late final __mm_mullo_epi16 =
      __mm_mullo_epi16Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_mul_epu32(
    __m128i _A,
    __m128i _B,
  ) {
    return __mm_mul_epu32(
      _A,
      _B,
    );
  }

  late final __mm_mul_epu32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_mul_epu32');
  late final __mm_mul_epu32 =
      __mm_mul_epu32Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_sad_epu8(
    __m128i _A,
    __m128i _B,
  ) {
    return __mm_sad_epu8(
      _A,
      _B,
    );
  }

  late final __mm_sad_epu8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_sad_epu8');
  late final __mm_sad_epu8 =
      __mm_sad_epu8Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_sub_epi8(
    __m128i _A,
    __m128i _B,
  ) {
    return __mm_sub_epi8(
      _A,
      _B,
    );
  }

  late final __mm_sub_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_sub_epi8');
  late final __mm_sub_epi8 =
      __mm_sub_epi8Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_sub_epi16(
    __m128i _A,
    __m128i _B,
  ) {
    return __mm_sub_epi16(
      _A,
      _B,
    );
  }

  late final __mm_sub_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_sub_epi16');
  late final __mm_sub_epi16 =
      __mm_sub_epi16Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_sub_epi32(
    __m128i _A,
    __m128i _B,
  ) {
    return __mm_sub_epi32(
      _A,
      _B,
    );
  }

  late final __mm_sub_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_sub_epi32');
  late final __mm_sub_epi32 =
      __mm_sub_epi32Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_sub_epi64(
    __m128i _A,
    __m128i _B,
  ) {
    return __mm_sub_epi64(
      _A,
      _B,
    );
  }

  late final __mm_sub_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_sub_epi64');
  late final __mm_sub_epi64 =
      __mm_sub_epi64Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_subs_epi8(
    __m128i _A,
    __m128i _B,
  ) {
    return __mm_subs_epi8(
      _A,
      _B,
    );
  }

  late final __mm_subs_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_subs_epi8');
  late final __mm_subs_epi8 =
      __mm_subs_epi8Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_subs_epi16(
    __m128i _A,
    __m128i _B,
  ) {
    return __mm_subs_epi16(
      _A,
      _B,
    );
  }

  late final __mm_subs_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_subs_epi16');
  late final __mm_subs_epi16 =
      __mm_subs_epi16Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_subs_epu8(
    __m128i _A,
    __m128i _B,
  ) {
    return __mm_subs_epu8(
      _A,
      _B,
    );
  }

  late final __mm_subs_epu8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_subs_epu8');
  late final __mm_subs_epu8 =
      __mm_subs_epu8Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_subs_epu16(
    __m128i _A,
    __m128i _B,
  ) {
    return __mm_subs_epu16(
      _A,
      _B,
    );
  }

  late final __mm_subs_epu16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_subs_epu16');
  late final __mm_subs_epu16 =
      __mm_subs_epu16Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_and_si128(
    __m128i _A,
    __m128i _B,
  ) {
    return __mm_and_si128(
      _A,
      _B,
    );
  }

  late final __mm_and_si128Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_and_si128');
  late final __mm_and_si128 =
      __mm_and_si128Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_andnot_si128(
    __m128i _A,
    __m128i _B,
  ) {
    return __mm_andnot_si128(
      _A,
      _B,
    );
  }

  late final __mm_andnot_si128Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_andnot_si128');
  late final __mm_andnot_si128 =
      __mm_andnot_si128Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_or_si128(
    __m128i _A,
    __m128i _B,
  ) {
    return __mm_or_si128(
      _A,
      _B,
    );
  }

  late final __mm_or_si128Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_or_si128');
  late final __mm_or_si128 =
      __mm_or_si128Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_xor_si128(
    __m128i _A,
    __m128i _B,
  ) {
    return __mm_xor_si128(
      _A,
      _B,
    );
  }

  late final __mm_xor_si128Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_xor_si128');
  late final __mm_xor_si128 =
      __mm_xor_si128Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_slli_si128(
    __m128i _A,
    int _Imm,
  ) {
    return __mm_slli_si128(
      _A,
      _Imm,
    );
  }

  late final __mm_slli_si128Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, ffi.Int32)>>(
          '_mm_slli_si128');
  late final __mm_slli_si128 =
      __mm_slli_si128Ptr.asFunction<__m128i Function(__m128i, int)>();

  __m128i _mm_slli_epi16(
    __m128i _A,
    int _Count,
  ) {
    return __mm_slli_epi16(
      _A,
      _Count,
    );
  }

  late final __mm_slli_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, ffi.Int32)>>(
          '_mm_slli_epi16');
  late final __mm_slli_epi16 =
      __mm_slli_epi16Ptr.asFunction<__m128i Function(__m128i, int)>();

  __m128i _mm_sll_epi16(
    __m128i _A,
    __m128i _Count,
  ) {
    return __mm_sll_epi16(
      _A,
      _Count,
    );
  }

  late final __mm_sll_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_sll_epi16');
  late final __mm_sll_epi16 =
      __mm_sll_epi16Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_slli_epi32(
    __m128i _A,
    int _Count,
  ) {
    return __mm_slli_epi32(
      _A,
      _Count,
    );
  }

  late final __mm_slli_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, ffi.Int32)>>(
          '_mm_slli_epi32');
  late final __mm_slli_epi32 =
      __mm_slli_epi32Ptr.asFunction<__m128i Function(__m128i, int)>();

  __m128i _mm_sll_epi32(
    __m128i _A,
    __m128i _Count,
  ) {
    return __mm_sll_epi32(
      _A,
      _Count,
    );
  }

  late final __mm_sll_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_sll_epi32');
  late final __mm_sll_epi32 =
      __mm_sll_epi32Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_slli_epi64(
    __m128i _A,
    int _Count,
  ) {
    return __mm_slli_epi64(
      _A,
      _Count,
    );
  }

  late final __mm_slli_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, ffi.Int32)>>(
          '_mm_slli_epi64');
  late final __mm_slli_epi64 =
      __mm_slli_epi64Ptr.asFunction<__m128i Function(__m128i, int)>();

  __m128i _mm_sll_epi64(
    __m128i _A,
    __m128i _Count,
  ) {
    return __mm_sll_epi64(
      _A,
      _Count,
    );
  }

  late final __mm_sll_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_sll_epi64');
  late final __mm_sll_epi64 =
      __mm_sll_epi64Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_srai_epi16(
    __m128i _A,
    int _Count,
  ) {
    return __mm_srai_epi16(
      _A,
      _Count,
    );
  }

  late final __mm_srai_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, ffi.Int32)>>(
          '_mm_srai_epi16');
  late final __mm_srai_epi16 =
      __mm_srai_epi16Ptr.asFunction<__m128i Function(__m128i, int)>();

  __m128i _mm_sra_epi16(
    __m128i _A,
    __m128i _Count,
  ) {
    return __mm_sra_epi16(
      _A,
      _Count,
    );
  }

  late final __mm_sra_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_sra_epi16');
  late final __mm_sra_epi16 =
      __mm_sra_epi16Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_srai_epi32(
    __m128i _A,
    int _Count,
  ) {
    return __mm_srai_epi32(
      _A,
      _Count,
    );
  }

  late final __mm_srai_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, ffi.Int32)>>(
          '_mm_srai_epi32');
  late final __mm_srai_epi32 =
      __mm_srai_epi32Ptr.asFunction<__m128i Function(__m128i, int)>();

  __m128i _mm_sra_epi32(
    __m128i _A,
    __m128i _Count,
  ) {
    return __mm_sra_epi32(
      _A,
      _Count,
    );
  }

  late final __mm_sra_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_sra_epi32');
  late final __mm_sra_epi32 =
      __mm_sra_epi32Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_srli_si128(
    __m128i _A,
    int _Imm,
  ) {
    return __mm_srli_si128(
      _A,
      _Imm,
    );
  }

  late final __mm_srli_si128Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, ffi.Int32)>>(
          '_mm_srli_si128');
  late final __mm_srli_si128 =
      __mm_srli_si128Ptr.asFunction<__m128i Function(__m128i, int)>();

  __m128i _mm_srli_epi16(
    __m128i _A,
    int _Count,
  ) {
    return __mm_srli_epi16(
      _A,
      _Count,
    );
  }

  late final __mm_srli_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, ffi.Int32)>>(
          '_mm_srli_epi16');
  late final __mm_srli_epi16 =
      __mm_srli_epi16Ptr.asFunction<__m128i Function(__m128i, int)>();

  __m128i _mm_srl_epi16(
    __m128i _A,
    __m128i _Count,
  ) {
    return __mm_srl_epi16(
      _A,
      _Count,
    );
  }

  late final __mm_srl_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_srl_epi16');
  late final __mm_srl_epi16 =
      __mm_srl_epi16Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_srli_epi32(
    __m128i _A,
    int _Count,
  ) {
    return __mm_srli_epi32(
      _A,
      _Count,
    );
  }

  late final __mm_srli_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, ffi.Int32)>>(
          '_mm_srli_epi32');
  late final __mm_srli_epi32 =
      __mm_srli_epi32Ptr.asFunction<__m128i Function(__m128i, int)>();

  __m128i _mm_srl_epi32(
    __m128i _A,
    __m128i _Count,
  ) {
    return __mm_srl_epi32(
      _A,
      _Count,
    );
  }

  late final __mm_srl_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_srl_epi32');
  late final __mm_srl_epi32 =
      __mm_srl_epi32Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_srli_epi64(
    __m128i _A,
    int _Count,
  ) {
    return __mm_srli_epi64(
      _A,
      _Count,
    );
  }

  late final __mm_srli_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, ffi.Int32)>>(
          '_mm_srli_epi64');
  late final __mm_srli_epi64 =
      __mm_srli_epi64Ptr.asFunction<__m128i Function(__m128i, int)>();

  __m128i _mm_srl_epi64(
    __m128i _A,
    __m128i _Count,
  ) {
    return __mm_srl_epi64(
      _A,
      _Count,
    );
  }

  late final __mm_srl_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_srl_epi64');
  late final __mm_srl_epi64 =
      __mm_srl_epi64Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_cmpeq_epi8(
    __m128i _A,
    __m128i _B,
  ) {
    return __mm_cmpeq_epi8(
      _A,
      _B,
    );
  }

  late final __mm_cmpeq_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_cmpeq_epi8');
  late final __mm_cmpeq_epi8 =
      __mm_cmpeq_epi8Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_cmpeq_epi16(
    __m128i _A,
    __m128i _B,
  ) {
    return __mm_cmpeq_epi16(
      _A,
      _B,
    );
  }

  late final __mm_cmpeq_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_cmpeq_epi16');
  late final __mm_cmpeq_epi16 =
      __mm_cmpeq_epi16Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_cmpeq_epi32(
    __m128i _A,
    __m128i _B,
  ) {
    return __mm_cmpeq_epi32(
      _A,
      _B,
    );
  }

  late final __mm_cmpeq_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_cmpeq_epi32');
  late final __mm_cmpeq_epi32 =
      __mm_cmpeq_epi32Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_cmpgt_epi8(
    __m128i _A,
    __m128i _B,
  ) {
    return __mm_cmpgt_epi8(
      _A,
      _B,
    );
  }

  late final __mm_cmpgt_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_cmpgt_epi8');
  late final __mm_cmpgt_epi8 =
      __mm_cmpgt_epi8Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_cmpgt_epi16(
    __m128i _A,
    __m128i _B,
  ) {
    return __mm_cmpgt_epi16(
      _A,
      _B,
    );
  }

  late final __mm_cmpgt_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_cmpgt_epi16');
  late final __mm_cmpgt_epi16 =
      __mm_cmpgt_epi16Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_cmpgt_epi32(
    __m128i _A,
    __m128i _B,
  ) {
    return __mm_cmpgt_epi32(
      _A,
      _B,
    );
  }

  late final __mm_cmpgt_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_cmpgt_epi32');
  late final __mm_cmpgt_epi32 =
      __mm_cmpgt_epi32Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_cmplt_epi8(
    __m128i _A,
    __m128i _B,
  ) {
    return __mm_cmplt_epi8(
      _A,
      _B,
    );
  }

  late final __mm_cmplt_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_cmplt_epi8');
  late final __mm_cmplt_epi8 =
      __mm_cmplt_epi8Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_cmplt_epi16(
    __m128i _A,
    __m128i _B,
  ) {
    return __mm_cmplt_epi16(
      _A,
      _B,
    );
  }

  late final __mm_cmplt_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_cmplt_epi16');
  late final __mm_cmplt_epi16 =
      __mm_cmplt_epi16Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_cmplt_epi32(
    __m128i _A,
    __m128i _B,
  ) {
    return __mm_cmplt_epi32(
      _A,
      _B,
    );
  }

  late final __mm_cmplt_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_cmplt_epi32');
  late final __mm_cmplt_epi32 =
      __mm_cmplt_epi32Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_cvtsi32_si128(
    int _A,
  ) {
    return __mm_cvtsi32_si128(
      _A,
    );
  }

  late final __mm_cvtsi32_si128Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(ffi.Int32)>>(
          '_mm_cvtsi32_si128');
  late final __mm_cvtsi32_si128 =
      __mm_cvtsi32_si128Ptr.asFunction<__m128i Function(int)>();

  int _mm_cvtsi128_si32(
    __m128i _A,
  ) {
    return __mm_cvtsi128_si32(
      _A,
    );
  }

  late final __mm_cvtsi128_si32Ptr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(__m128i)>>(
          '_mm_cvtsi128_si32');
  late final __mm_cvtsi128_si32 =
      __mm_cvtsi128_si32Ptr.asFunction<int Function(__m128i)>();

  __m128i _mm_packs_epi16(
    __m128i _A,
    __m128i _B,
  ) {
    return __mm_packs_epi16(
      _A,
      _B,
    );
  }

  late final __mm_packs_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_packs_epi16');
  late final __mm_packs_epi16 =
      __mm_packs_epi16Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_packs_epi32(
    __m128i _A,
    __m128i _B,
  ) {
    return __mm_packs_epi32(
      _A,
      _B,
    );
  }

  late final __mm_packs_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_packs_epi32');
  late final __mm_packs_epi32 =
      __mm_packs_epi32Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_packus_epi16(
    __m128i _A,
    __m128i _B,
  ) {
    return __mm_packus_epi16(
      _A,
      _B,
    );
  }

  late final __mm_packus_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_packus_epi16');
  late final __mm_packus_epi16 =
      __mm_packus_epi16Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  int _mm_extract_epi16(
    __m128i _A,
    int _Imm,
  ) {
    return __mm_extract_epi16(
      _A,
      _Imm,
    );
  }

  late final __mm_extract_epi16Ptr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(__m128i, ffi.Int32)>>(
          '_mm_extract_epi16');
  late final __mm_extract_epi16 =
      __mm_extract_epi16Ptr.asFunction<int Function(__m128i, int)>();

  __m128i _mm_insert_epi16(
    __m128i _A,
    int _B,
    int _Imm,
  ) {
    return __mm_insert_epi16(
      _A,
      _B,
      _Imm,
    );
  }

  late final __mm_insert_epi16Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__m128i, ffi.Int32, ffi.Int32)>>(
      '_mm_insert_epi16');
  late final __mm_insert_epi16 =
      __mm_insert_epi16Ptr.asFunction<__m128i Function(__m128i, int, int)>();

  int _mm_movemask_epi8(
    __m128i _A,
  ) {
    return __mm_movemask_epi8(
      _A,
    );
  }

  late final __mm_movemask_epi8Ptr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(__m128i)>>(
          '_mm_movemask_epi8');
  late final __mm_movemask_epi8 =
      __mm_movemask_epi8Ptr.asFunction<int Function(__m128i)>();

  __m128i _mm_shuffle_epi32(
    __m128i _A,
    int _Imm,
  ) {
    return __mm_shuffle_epi32(
      _A,
      _Imm,
    );
  }

  late final __mm_shuffle_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, ffi.Int32)>>(
          '_mm_shuffle_epi32');
  late final __mm_shuffle_epi32 =
      __mm_shuffle_epi32Ptr.asFunction<__m128i Function(__m128i, int)>();

  __m128i _mm_shufflehi_epi16(
    __m128i _A,
    int _Imm,
  ) {
    return __mm_shufflehi_epi16(
      _A,
      _Imm,
    );
  }

  late final __mm_shufflehi_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, ffi.Int32)>>(
          '_mm_shufflehi_epi16');
  late final __mm_shufflehi_epi16 =
      __mm_shufflehi_epi16Ptr.asFunction<__m128i Function(__m128i, int)>();

  __m128i _mm_shufflelo_epi16(
    __m128i _A,
    int _Imm,
  ) {
    return __mm_shufflelo_epi16(
      _A,
      _Imm,
    );
  }

  late final __mm_shufflelo_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, ffi.Int32)>>(
          '_mm_shufflelo_epi16');
  late final __mm_shufflelo_epi16 =
      __mm_shufflelo_epi16Ptr.asFunction<__m128i Function(__m128i, int)>();

  __m128i _mm_unpackhi_epi8(
    __m128i _A,
    __m128i _B,
  ) {
    return __mm_unpackhi_epi8(
      _A,
      _B,
    );
  }

  late final __mm_unpackhi_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_unpackhi_epi8');
  late final __mm_unpackhi_epi8 =
      __mm_unpackhi_epi8Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_unpackhi_epi16(
    __m128i _A,
    __m128i _B,
  ) {
    return __mm_unpackhi_epi16(
      _A,
      _B,
    );
  }

  late final __mm_unpackhi_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_unpackhi_epi16');
  late final __mm_unpackhi_epi16 =
      __mm_unpackhi_epi16Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_unpackhi_epi32(
    __m128i _A,
    __m128i _B,
  ) {
    return __mm_unpackhi_epi32(
      _A,
      _B,
    );
  }

  late final __mm_unpackhi_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_unpackhi_epi32');
  late final __mm_unpackhi_epi32 =
      __mm_unpackhi_epi32Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_unpackhi_epi64(
    __m128i _A,
    __m128i _B,
  ) {
    return __mm_unpackhi_epi64(
      _A,
      _B,
    );
  }

  late final __mm_unpackhi_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_unpackhi_epi64');
  late final __mm_unpackhi_epi64 =
      __mm_unpackhi_epi64Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_unpacklo_epi8(
    __m128i _A,
    __m128i _B,
  ) {
    return __mm_unpacklo_epi8(
      _A,
      _B,
    );
  }

  late final __mm_unpacklo_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_unpacklo_epi8');
  late final __mm_unpacklo_epi8 =
      __mm_unpacklo_epi8Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_unpacklo_epi16(
    __m128i _A,
    __m128i _B,
  ) {
    return __mm_unpacklo_epi16(
      _A,
      _B,
    );
  }

  late final __mm_unpacklo_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_unpacklo_epi16');
  late final __mm_unpacklo_epi16 =
      __mm_unpacklo_epi16Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_unpacklo_epi32(
    __m128i _A,
    __m128i _B,
  ) {
    return __mm_unpacklo_epi32(
      _A,
      _B,
    );
  }

  late final __mm_unpacklo_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_unpacklo_epi32');
  late final __mm_unpacklo_epi32 =
      __mm_unpacklo_epi32Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_unpacklo_epi64(
    __m128i _A,
    __m128i _B,
  ) {
    return __mm_unpacklo_epi64(
      _A,
      _B,
    );
  }

  late final __mm_unpacklo_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_unpacklo_epi64');
  late final __mm_unpacklo_epi64 =
      __mm_unpacklo_epi64Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_load_si128(
    ffi.Pointer<__m128i> _P,
  ) {
    return __mm_load_si128(
      _P,
    );
  }

  late final __mm_load_si128Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(ffi.Pointer<__m128i>)>>(
          '_mm_load_si128');
  late final __mm_load_si128 =
      __mm_load_si128Ptr.asFunction<__m128i Function(ffi.Pointer<__m128i>)>();

  __m128i _mm_loadu_si128(
    ffi.Pointer<__m128i> _P,
  ) {
    return __mm_loadu_si128(
      _P,
    );
  }

  late final __mm_loadu_si128Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(ffi.Pointer<__m128i>)>>(
          '_mm_loadu_si128');
  late final __mm_loadu_si128 =
      __mm_loadu_si128Ptr.asFunction<__m128i Function(ffi.Pointer<__m128i>)>();

  __m128i _mm_loadl_epi64(
    ffi.Pointer<__m128i> _P,
  ) {
    return __mm_loadl_epi64(
      _P,
    );
  }

  late final __mm_loadl_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(ffi.Pointer<__m128i>)>>(
          '_mm_loadl_epi64');
  late final __mm_loadl_epi64 =
      __mm_loadl_epi64Ptr.asFunction<__m128i Function(ffi.Pointer<__m128i>)>();

  __m128i _mm_set_epi64x(
    int _I1,
    int _I0,
  ) {
    return __mm_set_epi64x(
      _I1,
      _I0,
    );
  }

  late final __mm_set_epi64xPtr =
      _lookup<ffi.NativeFunction<__m128i Function(ffi.Int64, ffi.Int64)>>(
          '_mm_set_epi64x');
  late final __mm_set_epi64x =
      __mm_set_epi64xPtr.asFunction<__m128i Function(int, int)>();

  __m128i _mm_set_epi32(
    int _I3,
    int _I2,
    int _I1,
    int _I0,
  ) {
    return __mm_set_epi32(
      _I3,
      _I2,
      _I1,
      _I0,
    );
  }

  late final __mm_set_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              ffi.Int32, ffi.Int32, ffi.Int32, ffi.Int32)>>('_mm_set_epi32');
  late final __mm_set_epi32 =
      __mm_set_epi32Ptr.asFunction<__m128i Function(int, int, int, int)>();

  __m128i _mm_set_epi16(
    int _W7,
    int _W6,
    int _W5,
    int _W4,
    int _W3,
    int _W2,
    int _W1,
    int _W0,
  ) {
    return __mm_set_epi16(
      _W7,
      _W6,
      _W5,
      _W4,
      _W3,
      _W2,
      _W1,
      _W0,
    );
  }

  late final __mm_set_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(ffi.Int16, ffi.Int16, ffi.Int16, ffi.Int16,
              ffi.Int16, ffi.Int16, ffi.Int16, ffi.Int16)>>('_mm_set_epi16');
  late final __mm_set_epi16 = __mm_set_epi16Ptr
      .asFunction<__m128i Function(int, int, int, int, int, int, int, int)>();

  __m128i _mm_set_epi8(
    int _B15,
    int _B14,
    int _B13,
    int _B12,
    int _B11,
    int _B10,
    int _B9,
    int _B8,
    int _B7,
    int _B6,
    int _B5,
    int _B4,
    int _B3,
    int _B2,
    int _B1,
    int _B0,
  ) {
    return __mm_set_epi8(
      _B15,
      _B14,
      _B13,
      _B12,
      _B11,
      _B10,
      _B9,
      _B8,
      _B7,
      _B6,
      _B5,
      _B4,
      _B3,
      _B2,
      _B1,
      _B0,
    );
  }

  late final __mm_set_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8)>>('_mm_set_epi8');
  late final __mm_set_epi8 = __mm_set_epi8Ptr.asFunction<
      __m128i Function(int, int, int, int, int, int, int, int, int, int, int,
          int, int, int, int, int)>();

  __m128i _mm_set1_epi64x(
    int i,
  ) {
    return __mm_set1_epi64x(
      i,
    );
  }

  late final __mm_set1_epi64xPtr =
      _lookup<ffi.NativeFunction<__m128i Function(ffi.Int64)>>(
          '_mm_set1_epi64x');
  late final __mm_set1_epi64x =
      __mm_set1_epi64xPtr.asFunction<__m128i Function(int)>();

  __m128i _mm_set1_epi32(
    int _I,
  ) {
    return __mm_set1_epi32(
      _I,
    );
  }

  late final __mm_set1_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(ffi.Int32)>>(
          '_mm_set1_epi32');
  late final __mm_set1_epi32 =
      __mm_set1_epi32Ptr.asFunction<__m128i Function(int)>();

  __m128i _mm_set1_epi16(
    int _W,
  ) {
    return __mm_set1_epi16(
      _W,
    );
  }

  late final __mm_set1_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(ffi.Int16)>>(
          '_mm_set1_epi16');
  late final __mm_set1_epi16 =
      __mm_set1_epi16Ptr.asFunction<__m128i Function(int)>();

  __m128i _mm_set1_epi8(
    int _B,
  ) {
    return __mm_set1_epi8(
      _B,
    );
  }

  late final __mm_set1_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(ffi.Int8)>>('_mm_set1_epi8');
  late final __mm_set1_epi8 =
      __mm_set1_epi8Ptr.asFunction<__m128i Function(int)>();

  __m128i _mm_setl_epi64(
    __m128i _Q,
  ) {
    return __mm_setl_epi64(
      _Q,
    );
  }

  late final __mm_setl_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i)>>('_mm_setl_epi64');
  late final __mm_setl_epi64 =
      __mm_setl_epi64Ptr.asFunction<__m128i Function(__m128i)>();

  __m128i _mm_setr_epi32(
    int _I0,
    int _I1,
    int _I2,
    int _I3,
  ) {
    return __mm_setr_epi32(
      _I0,
      _I1,
      _I2,
      _I3,
    );
  }

  late final __mm_setr_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              ffi.Int32, ffi.Int32, ffi.Int32, ffi.Int32)>>('_mm_setr_epi32');
  late final __mm_setr_epi32 =
      __mm_setr_epi32Ptr.asFunction<__m128i Function(int, int, int, int)>();

  __m128i _mm_setr_epi16(
    int _W0,
    int _W1,
    int _W2,
    int _W3,
    int _W4,
    int _W5,
    int _W6,
    int _W7,
  ) {
    return __mm_setr_epi16(
      _W0,
      _W1,
      _W2,
      _W3,
      _W4,
      _W5,
      _W6,
      _W7,
    );
  }

  late final __mm_setr_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(ffi.Int16, ffi.Int16, ffi.Int16, ffi.Int16,
              ffi.Int16, ffi.Int16, ffi.Int16, ffi.Int16)>>('_mm_setr_epi16');
  late final __mm_setr_epi16 = __mm_setr_epi16Ptr
      .asFunction<__m128i Function(int, int, int, int, int, int, int, int)>();

  __m128i _mm_setr_epi8(
    int _B15,
    int _B14,
    int _B13,
    int _B12,
    int _B11,
    int _B10,
    int _B9,
    int _B8,
    int _B7,
    int _B6,
    int _B5,
    int _B4,
    int _B3,
    int _B2,
    int _B1,
    int _B0,
  ) {
    return __mm_setr_epi8(
      _B15,
      _B14,
      _B13,
      _B12,
      _B11,
      _B10,
      _B9,
      _B8,
      _B7,
      _B6,
      _B5,
      _B4,
      _B3,
      _B2,
      _B1,
      _B0,
    );
  }

  late final __mm_setr_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8)>>('_mm_setr_epi8');
  late final __mm_setr_epi8 = __mm_setr_epi8Ptr.asFunction<
      __m128i Function(int, int, int, int, int, int, int, int, int, int, int,
          int, int, int, int, int)>();

  __m128i _mm_setzero_si128() {
    return __mm_setzero_si128();
  }

  late final __mm_setzero_si128Ptr =
      _lookup<ffi.NativeFunction<__m128i Function()>>('_mm_setzero_si128');
  late final __mm_setzero_si128 =
      __mm_setzero_si128Ptr.asFunction<__m128i Function()>();

  void _mm_store_si128(
    ffi.Pointer<__m128i> _P,
    __m128i _B,
  ) {
    return __mm_store_si128(
      _P,
      _B,
    );
  }

  late final __mm_store_si128Ptr = _lookup<
          ffi.NativeFunction<ffi.Void Function(ffi.Pointer<__m128i>, __m128i)>>(
      '_mm_store_si128');
  late final __mm_store_si128 = __mm_store_si128Ptr
      .asFunction<void Function(ffi.Pointer<__m128i>, __m128i)>();

  void _mm_storeu_si128(
    ffi.Pointer<__m128i> _P,
    __m128i _B,
  ) {
    return __mm_storeu_si128(
      _P,
      _B,
    );
  }

  late final __mm_storeu_si128Ptr = _lookup<
          ffi.NativeFunction<ffi.Void Function(ffi.Pointer<__m128i>, __m128i)>>(
      '_mm_storeu_si128');
  late final __mm_storeu_si128 = __mm_storeu_si128Ptr
      .asFunction<void Function(ffi.Pointer<__m128i>, __m128i)>();

  void _mm_storel_epi64(
    ffi.Pointer<__m128i> _P,
    __m128i _Q,
  ) {
    return __mm_storel_epi64(
      _P,
      _Q,
    );
  }

  late final __mm_storel_epi64Ptr = _lookup<
          ffi.NativeFunction<ffi.Void Function(ffi.Pointer<__m128i>, __m128i)>>(
      '_mm_storel_epi64');
  late final __mm_storel_epi64 = __mm_storel_epi64Ptr
      .asFunction<void Function(ffi.Pointer<__m128i>, __m128i)>();

  void _mm_maskmoveu_si128(
    __m128i _D,
    __m128i _N,
    ffi.Pointer<ffi.Int8> _P,
  ) {
    return __mm_maskmoveu_si128(
      _D,
      _N,
      _P,
    );
  }

  late final __mm_maskmoveu_si128Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              __m128i, __m128i, ffi.Pointer<ffi.Int8>)>>('_mm_maskmoveu_si128');
  late final __mm_maskmoveu_si128 = __mm_maskmoveu_si128Ptr
      .asFunction<void Function(__m128i, __m128i, ffi.Pointer<ffi.Int8>)>();

  __m128i _mm_move_epi64(
    __m128i _Q,
  ) {
    return __mm_move_epi64(
      _Q,
    );
  }

  late final __mm_move_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i)>>('_mm_move_epi64');
  late final __mm_move_epi64 =
      __mm_move_epi64Ptr.asFunction<__m128i Function(__m128i)>();

  void _mm_stream_pd(
    ffi.Pointer<ffi.Double> _Dp,
    _m128d _A,
  ) {
    return __mm_stream_pd(
      _Dp,
      _A,
    );
  }

  late final __mm_stream_pdPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Double>, _m128d)>>('_mm_stream_pd');
  late final __mm_stream_pd = __mm_stream_pdPtr
      .asFunction<void Function(ffi.Pointer<ffi.Double>, _m128d)>();

  void _mm_stream_si128(
    ffi.Pointer<__m128i> _P,
    __m128i _A,
  ) {
    return __mm_stream_si128(
      _P,
      _A,
    );
  }

  late final __mm_stream_si128Ptr = _lookup<
          ffi.NativeFunction<ffi.Void Function(ffi.Pointer<__m128i>, __m128i)>>(
      '_mm_stream_si128');
  late final __mm_stream_si128 = __mm_stream_si128Ptr
      .asFunction<void Function(ffi.Pointer<__m128i>, __m128i)>();

  void _mm_clflush(
    ffi.Pointer<ffi.Void> _P,
  ) {
    return __mm_clflush(
      _P,
    );
  }

  late final __mm_clflushPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ffi.Void>)>>(
          '_mm_clflush');
  late final __mm_clflush =
      __mm_clflushPtr.asFunction<void Function(ffi.Pointer<ffi.Void>)>();

  void _mm_lfence() {
    return __mm_lfence();
  }

  late final __mm_lfencePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('_mm_lfence');
  late final __mm_lfence = __mm_lfencePtr.asFunction<void Function()>();

  void _mm_mfence() {
    return __mm_mfence();
  }

  late final __mm_mfencePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('_mm_mfence');
  late final __mm_mfence = __mm_mfencePtr.asFunction<void Function()>();

  void _mm_stream_si32(
    ffi.Pointer<ffi.Int32> _P,
    int _I,
  ) {
    return __mm_stream_si32(
      _P,
      _I,
    );
  }

  late final __mm_stream_si32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<ffi.Int32>, ffi.Int32)>>('_mm_stream_si32');
  late final __mm_stream_si32 = __mm_stream_si32Ptr
      .asFunction<void Function(ffi.Pointer<ffi.Int32>, int)>();

  double _mm_cvtsd_f64(
    _m128d _A,
  ) {
    return __mm_cvtsd_f64(
      _A,
    );
  }

  late final __mm_cvtsd_f64Ptr =
      _lookup<ffi.NativeFunction<ffi.Double Function(_m128d)>>('_mm_cvtsd_f64');
  late final __mm_cvtsd_f64 =
      __mm_cvtsd_f64Ptr.asFunction<double Function(_m128d)>();

  __m128 _mm_castpd_ps(
    _m128d arg0,
  ) {
    return __mm_castpd_ps(
      arg0,
    );
  }

  late final __mm_castpd_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(_m128d)>>('_mm_castpd_ps');
  late final __mm_castpd_ps =
      __mm_castpd_psPtr.asFunction<__m128 Function(_m128d)>();

  __m128i _mm_castpd_si128(
    _m128d arg0,
  ) {
    return __mm_castpd_si128(
      arg0,
    );
  }

  late final __mm_castpd_si128Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(_m128d)>>('_mm_castpd_si128');
  late final __mm_castpd_si128 =
      __mm_castpd_si128Ptr.asFunction<__m128i Function(_m128d)>();

  _m128d _mm_castps_pd(
    __m128 arg0,
  ) {
    return __mm_castps_pd(
      arg0,
    );
  }

  late final __mm_castps_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(__m128)>>('_mm_castps_pd');
  late final __mm_castps_pd =
      __mm_castps_pdPtr.asFunction<_m128d Function(__m128)>();

  __m128i _mm_castps_si128(
    __m128 arg0,
  ) {
    return __mm_castps_si128(
      arg0,
    );
  }

  late final __mm_castps_si128Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128)>>('_mm_castps_si128');
  late final __mm_castps_si128 =
      __mm_castps_si128Ptr.asFunction<__m128i Function(__m128)>();

  __m128 _mm_castsi128_ps(
    __m128i arg0,
  ) {
    return __mm_castsi128_ps(
      arg0,
    );
  }

  late final __mm_castsi128_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128i)>>('_mm_castsi128_ps');
  late final __mm_castsi128_ps =
      __mm_castsi128_psPtr.asFunction<__m128 Function(__m128i)>();

  _m128d _mm_castsi128_pd(
    __m128i arg0,
  ) {
    return __mm_castsi128_pd(
      arg0,
    );
  }

  late final __mm_castsi128_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(__m128i)>>('_mm_castsi128_pd');
  late final __mm_castsi128_pd =
      __mm_castsi128_pdPtr.asFunction<_m128d Function(__m128i)>();

  int _mm_cvtsd_si64(
    _m128d arg0,
  ) {
    return __mm_cvtsd_si64(
      arg0,
    );
  }

  late final __mm_cvtsd_si64Ptr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(_m128d)>>('_mm_cvtsd_si64');
  late final __mm_cvtsd_si64 =
      __mm_cvtsd_si64Ptr.asFunction<int Function(_m128d)>();

  int _mm_cvttsd_si64(
    _m128d arg0,
  ) {
    return __mm_cvttsd_si64(
      arg0,
    );
  }

  late final __mm_cvttsd_si64Ptr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(_m128d)>>(
          '_mm_cvttsd_si64');
  late final __mm_cvttsd_si64 =
      __mm_cvttsd_si64Ptr.asFunction<int Function(_m128d)>();

  _m128d _mm_cvtsi64_sd(
    _m128d arg0,
    int arg1,
  ) {
    return __mm_cvtsi64_sd(
      arg0,
      arg1,
    );
  }

  late final __mm_cvtsi64_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, ffi.Int64)>>(
          '_mm_cvtsi64_sd');
  late final __mm_cvtsi64_sd =
      __mm_cvtsi64_sdPtr.asFunction<_m128d Function(_m128d, int)>();

  __m128i _mm_cvtsi64_si128(
    int arg0,
  ) {
    return __mm_cvtsi64_si128(
      arg0,
    );
  }

  late final __mm_cvtsi64_si128Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(ffi.Int64)>>(
          '_mm_cvtsi64_si128');
  late final __mm_cvtsi64_si128 =
      __mm_cvtsi64_si128Ptr.asFunction<__m128i Function(int)>();

  int _mm_cvtsi128_si64(
    __m128i arg0,
  ) {
    return __mm_cvtsi128_si64(
      arg0,
    );
  }

  late final __mm_cvtsi128_si64Ptr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(__m128i)>>(
          '_mm_cvtsi128_si64');
  late final __mm_cvtsi128_si64 =
      __mm_cvtsi128_si64Ptr.asFunction<int Function(__m128i)>();

  __m128 _mm_addsub_ps(
    __m128 arg0,
    __m128 arg1,
  ) {
    return __mm_addsub_ps(
      arg0,
      arg1,
    );
  }

  late final __mm_addsub_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128)>>(
          '_mm_addsub_ps');
  late final __mm_addsub_ps =
      __mm_addsub_psPtr.asFunction<__m128 Function(__m128, __m128)>();

  __m128 _mm_hadd_ps(
    __m128 arg0,
    __m128 arg1,
  ) {
    return __mm_hadd_ps(
      arg0,
      arg1,
    );
  }

  late final __mm_hadd_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128)>>(
          '_mm_hadd_ps');
  late final __mm_hadd_ps =
      __mm_hadd_psPtr.asFunction<__m128 Function(__m128, __m128)>();

  __m128 _mm_hsub_ps(
    __m128 arg0,
    __m128 arg1,
  ) {
    return __mm_hsub_ps(
      arg0,
      arg1,
    );
  }

  late final __mm_hsub_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128)>>(
          '_mm_hsub_ps');
  late final __mm_hsub_ps =
      __mm_hsub_psPtr.asFunction<__m128 Function(__m128, __m128)>();

  __m128 _mm_movehdup_ps(
    __m128 arg0,
  ) {
    return __mm_movehdup_ps(
      arg0,
    );
  }

  late final __mm_movehdup_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128)>>('_mm_movehdup_ps');
  late final __mm_movehdup_ps =
      __mm_movehdup_psPtr.asFunction<__m128 Function(__m128)>();

  __m128 _mm_moveldup_ps(
    __m128 arg0,
  ) {
    return __mm_moveldup_ps(
      arg0,
    );
  }

  late final __mm_moveldup_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128)>>('_mm_moveldup_ps');
  late final __mm_moveldup_ps =
      __mm_moveldup_psPtr.asFunction<__m128 Function(__m128)>();

  _m128d _mm_addsub_pd(
    _m128d arg0,
    _m128d arg1,
  ) {
    return __mm_addsub_pd(
      arg0,
      arg1,
    );
  }

  late final __mm_addsub_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d)>>(
          '_mm_addsub_pd');
  late final __mm_addsub_pd =
      __mm_addsub_pdPtr.asFunction<_m128d Function(_m128d, _m128d)>();

  _m128d _mm_hadd_pd(
    _m128d arg0,
    _m128d arg1,
  ) {
    return __mm_hadd_pd(
      arg0,
      arg1,
    );
  }

  late final __mm_hadd_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d)>>(
          '_mm_hadd_pd');
  late final __mm_hadd_pd =
      __mm_hadd_pdPtr.asFunction<_m128d Function(_m128d, _m128d)>();

  _m128d _mm_hsub_pd(
    _m128d arg0,
    _m128d arg1,
  ) {
    return __mm_hsub_pd(
      arg0,
      arg1,
    );
  }

  late final __mm_hsub_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d)>>(
          '_mm_hsub_pd');
  late final __mm_hsub_pd =
      __mm_hsub_pdPtr.asFunction<_m128d Function(_m128d, _m128d)>();

  _m128d _mm_loaddup_pd(
    ffi.Pointer<ffi.Double> arg0,
  ) {
    return __mm_loaddup_pd(
      arg0,
    );
  }

  late final __mm_loaddup_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(ffi.Pointer<ffi.Double>)>>(
          '_mm_loaddup_pd');
  late final __mm_loaddup_pd =
      __mm_loaddup_pdPtr.asFunction<_m128d Function(ffi.Pointer<ffi.Double>)>();

  _m128d _mm_movedup_pd(
    _m128d arg0,
  ) {
    return __mm_movedup_pd(
      arg0,
    );
  }

  late final __mm_movedup_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d)>>('_mm_movedup_pd');
  late final __mm_movedup_pd =
      __mm_movedup_pdPtr.asFunction<_m128d Function(_m128d)>();

  __m128i _mm_lddqu_si128(
    ffi.Pointer<__m128i> arg0,
  ) {
    return __mm_lddqu_si128(
      arg0,
    );
  }

  late final __mm_lddqu_si128Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(ffi.Pointer<__m128i>)>>(
          '_mm_lddqu_si128');
  late final __mm_lddqu_si128 =
      __mm_lddqu_si128Ptr.asFunction<__m128i Function(ffi.Pointer<__m128i>)>();

  void _mm_monitor(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    int arg2,
  ) {
    return __mm_monitor(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_monitorPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<ffi.Void>, ffi.Uint32, ffi.Uint32)>>('_mm_monitor');
  late final __mm_monitor = __mm_monitorPtr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, int, int)>();

  void _mm_mwait(
    int arg0,
    int arg1,
  ) {
    return __mm_mwait(
      arg0,
      arg1,
    );
  }

  late final __mm_mwaitPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Uint32, ffi.Uint32)>>(
          '_mm_mwait');
  late final __mm_mwait = __mm_mwaitPtr.asFunction<void Function(int, int)>();

  __m128i _mm_hadd_epi16(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_hadd_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm_hadd_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_hadd_epi16');
  late final __mm_hadd_epi16 =
      __mm_hadd_epi16Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_hadd_epi32(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_hadd_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm_hadd_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_hadd_epi32');
  late final __mm_hadd_epi32 =
      __mm_hadd_epi32Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_hadds_epi16(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_hadds_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm_hadds_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_hadds_epi16');
  late final __mm_hadds_epi16 =
      __mm_hadds_epi16Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_hsub_epi16(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_hsub_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm_hsub_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_hsub_epi16');
  late final __mm_hsub_epi16 =
      __mm_hsub_epi16Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_hsub_epi32(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_hsub_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm_hsub_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_hsub_epi32');
  late final __mm_hsub_epi32 =
      __mm_hsub_epi32Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_hsubs_epi16(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_hsubs_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm_hsubs_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_hsubs_epi16');
  late final __mm_hsubs_epi16 =
      __mm_hsubs_epi16Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_maddubs_epi16(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_maddubs_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm_maddubs_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_maddubs_epi16');
  late final __mm_maddubs_epi16 =
      __mm_maddubs_epi16Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_mulhrs_epi16(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_mulhrs_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm_mulhrs_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_mulhrs_epi16');
  late final __mm_mulhrs_epi16 =
      __mm_mulhrs_epi16Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_shuffle_epi8(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_shuffle_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm_shuffle_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_shuffle_epi8');
  late final __mm_shuffle_epi8 =
      __mm_shuffle_epi8Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_sign_epi8(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_sign_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm_sign_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_sign_epi8');
  late final __mm_sign_epi8 =
      __mm_sign_epi8Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_sign_epi16(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_sign_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm_sign_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_sign_epi16');
  late final __mm_sign_epi16 =
      __mm_sign_epi16Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_sign_epi32(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_sign_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm_sign_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_sign_epi32');
  late final __mm_sign_epi32 =
      __mm_sign_epi32Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_alignr_epi8(
    __m128i arg0,
    __m128i arg1,
    int arg2,
  ) {
    return __mm_alignr_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_alignr_epi8Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__m128i, __m128i, ffi.Int32)>>(
      '_mm_alignr_epi8');
  late final __mm_alignr_epi8 =
      __mm_alignr_epi8Ptr.asFunction<__m128i Function(__m128i, __m128i, int)>();

  __m128i _mm_abs_epi8(
    __m128i arg0,
  ) {
    return __mm_abs_epi8(
      arg0,
    );
  }

  late final __mm_abs_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i)>>('_mm_abs_epi8');
  late final __mm_abs_epi8 =
      __mm_abs_epi8Ptr.asFunction<__m128i Function(__m128i)>();

  __m128i _mm_abs_epi16(
    __m128i arg0,
  ) {
    return __mm_abs_epi16(
      arg0,
    );
  }

  late final __mm_abs_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i)>>('_mm_abs_epi16');
  late final __mm_abs_epi16 =
      __mm_abs_epi16Ptr.asFunction<__m128i Function(__m128i)>();

  __m128i _mm_abs_epi32(
    __m128i arg0,
  ) {
    return __mm_abs_epi32(
      arg0,
    );
  }

  late final __mm_abs_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i)>>('_mm_abs_epi32');
  late final __mm_abs_epi32 =
      __mm_abs_epi32Ptr.asFunction<__m128i Function(__m128i)>();

  __m128i _mm_blend_epi16(
    __m128i arg0,
    __m128i arg1,
    int arg2,
  ) {
    return __mm_blend_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_blend_epi16Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__m128i, __m128i, ffi.Int32)>>(
      '_mm_blend_epi16');
  late final __mm_blend_epi16 =
      __mm_blend_epi16Ptr.asFunction<__m128i Function(__m128i, __m128i, int)>();

  __m128i _mm_blendv_epi8(
    __m128i arg0,
    __m128i arg1,
    __m128i mask,
  ) {
    return __mm_blendv_epi8(
      arg0,
      arg1,
      mask,
    );
  }

  late final __mm_blendv_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i, __m128i)>>(
          '_mm_blendv_epi8');
  late final __mm_blendv_epi8 = __mm_blendv_epi8Ptr
      .asFunction<__m128i Function(__m128i, __m128i, __m128i)>();

  __m128 _mm_blend_ps(
    __m128 arg0,
    __m128 arg1,
    int arg2,
  ) {
    return __mm_blend_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_blend_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128, ffi.Int32)>>(
          '_mm_blend_ps');
  late final __mm_blend_ps =
      __mm_blend_psPtr.asFunction<__m128 Function(__m128, __m128, int)>();

  __m128 _mm_blendv_ps(
    __m128 arg0,
    __m128 arg1,
    __m128 arg2,
  ) {
    return __mm_blendv_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_blendv_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128, __m128)>>(
          '_mm_blendv_ps');
  late final __mm_blendv_ps =
      __mm_blendv_psPtr.asFunction<__m128 Function(__m128, __m128, __m128)>();

  _m128d _mm_blend_pd(
    _m128d arg0,
    _m128d arg1,
    int arg2,
  ) {
    return __mm_blend_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_blend_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d, ffi.Int32)>>(
          '_mm_blend_pd');
  late final __mm_blend_pd =
      __mm_blend_pdPtr.asFunction<_m128d Function(_m128d, _m128d, int)>();

  _m128d _mm_blendv_pd(
    _m128d arg0,
    _m128d arg1,
    _m128d arg2,
  ) {
    return __mm_blendv_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_blendv_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d, _m128d)>>(
          '_mm_blendv_pd');
  late final __mm_blendv_pd =
      __mm_blendv_pdPtr.asFunction<_m128d Function(_m128d, _m128d, _m128d)>();

  __m128 _mm_dp_ps(
    __m128 arg0,
    __m128 arg1,
    int arg2,
  ) {
    return __mm_dp_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_dp_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128, ffi.Int32)>>(
          '_mm_dp_ps');
  late final __mm_dp_ps =
      __mm_dp_psPtr.asFunction<__m128 Function(__m128, __m128, int)>();

  _m128d _mm_dp_pd(
    _m128d arg0,
    _m128d arg1,
    int arg2,
  ) {
    return __mm_dp_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_dp_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d, ffi.Int32)>>(
          '_mm_dp_pd');
  late final __mm_dp_pd =
      __mm_dp_pdPtr.asFunction<_m128d Function(_m128d, _m128d, int)>();

  __m128i _mm_cmpeq_epi64(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_cmpeq_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm_cmpeq_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_cmpeq_epi64');
  late final __mm_cmpeq_epi64 =
      __mm_cmpeq_epi64Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_min_epi8(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_min_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm_min_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_min_epi8');
  late final __mm_min_epi8 =
      __mm_min_epi8Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_max_epi8(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_max_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm_max_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_max_epi8');
  late final __mm_max_epi8 =
      __mm_max_epi8Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_min_epu16(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_min_epu16(
      arg0,
      arg1,
    );
  }

  late final __mm_min_epu16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_min_epu16');
  late final __mm_min_epu16 =
      __mm_min_epu16Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_max_epu16(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_max_epu16(
      arg0,
      arg1,
    );
  }

  late final __mm_max_epu16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_max_epu16');
  late final __mm_max_epu16 =
      __mm_max_epu16Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_min_epi32(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_min_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm_min_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_min_epi32');
  late final __mm_min_epi32 =
      __mm_min_epi32Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_max_epi32(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_max_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm_max_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_max_epi32');
  late final __mm_max_epi32 =
      __mm_max_epi32Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_min_epu32(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_min_epu32(
      arg0,
      arg1,
    );
  }

  late final __mm_min_epu32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_min_epu32');
  late final __mm_min_epu32 =
      __mm_min_epu32Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_max_epu32(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_max_epu32(
      arg0,
      arg1,
    );
  }

  late final __mm_max_epu32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_max_epu32');
  late final __mm_max_epu32 =
      __mm_max_epu32Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_mullo_epi32(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_mullo_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm_mullo_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_mullo_epi32');
  late final __mm_mullo_epi32 =
      __mm_mullo_epi32Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_mul_epi32(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_mul_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm_mul_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_mul_epi32');
  late final __mm_mul_epi32 =
      __mm_mul_epi32Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  int _mm_testz_si128(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_testz_si128(
      arg0,
      arg1,
    );
  }

  late final __mm_testz_si128Ptr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(__m128i, __m128i)>>(
          '_mm_testz_si128');
  late final __mm_testz_si128 =
      __mm_testz_si128Ptr.asFunction<int Function(__m128i, __m128i)>();

  int _mm_testc_si128(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_testc_si128(
      arg0,
      arg1,
    );
  }

  late final __mm_testc_si128Ptr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(__m128i, __m128i)>>(
          '_mm_testc_si128');
  late final __mm_testc_si128 =
      __mm_testc_si128Ptr.asFunction<int Function(__m128i, __m128i)>();

  int _mm_testnzc_si128(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_testnzc_si128(
      arg0,
      arg1,
    );
  }

  late final __mm_testnzc_si128Ptr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(__m128i, __m128i)>>(
          '_mm_testnzc_si128');
  late final __mm_testnzc_si128 =
      __mm_testnzc_si128Ptr.asFunction<int Function(__m128i, __m128i)>();

  __m128 _mm_insert_ps(
    __m128 arg0,
    __m128 arg1,
    int arg2,
  ) {
    return __mm_insert_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_insert_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128, ffi.Int32)>>(
          '_mm_insert_ps');
  late final __mm_insert_ps =
      __mm_insert_psPtr.asFunction<__m128 Function(__m128, __m128, int)>();

  int _mm_extract_ps(
    __m128 arg0,
    int arg1,
  ) {
    return __mm_extract_ps(
      arg0,
      arg1,
    );
  }

  late final __mm_extract_psPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(__m128, ffi.Int32)>>(
          '_mm_extract_ps');
  late final __mm_extract_ps =
      __mm_extract_psPtr.asFunction<int Function(__m128, int)>();

  __m128i _mm_insert_epi8(
    __m128i arg0,
    int arg1,
    int arg2,
  ) {
    return __mm_insert_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_insert_epi8Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__m128i, ffi.Int32, ffi.Int32)>>(
      '_mm_insert_epi8');
  late final __mm_insert_epi8 =
      __mm_insert_epi8Ptr.asFunction<__m128i Function(__m128i, int, int)>();

  __m128i _mm_insert_epi32(
    __m128i arg0,
    int arg1,
    int arg2,
  ) {
    return __mm_insert_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_insert_epi32Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__m128i, ffi.Int32, ffi.Int32)>>(
      '_mm_insert_epi32');
  late final __mm_insert_epi32 =
      __mm_insert_epi32Ptr.asFunction<__m128i Function(__m128i, int, int)>();

  __m128i _mm_insert_epi64(
    __m128i arg0,
    int arg1,
    int arg2,
  ) {
    return __mm_insert_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_insert_epi64Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__m128i, ffi.Int64, ffi.Int32)>>(
      '_mm_insert_epi64');
  late final __mm_insert_epi64 =
      __mm_insert_epi64Ptr.asFunction<__m128i Function(__m128i, int, int)>();

  int _mm_extract_epi8(
    __m128i arg0,
    int arg1,
  ) {
    return __mm_extract_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm_extract_epi8Ptr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(__m128i, ffi.Int32)>>(
          '_mm_extract_epi8');
  late final __mm_extract_epi8 =
      __mm_extract_epi8Ptr.asFunction<int Function(__m128i, int)>();

  int _mm_extract_epi32(
    __m128i arg0,
    int arg1,
  ) {
    return __mm_extract_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm_extract_epi32Ptr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(__m128i, ffi.Int32)>>(
          '_mm_extract_epi32');
  late final __mm_extract_epi32 =
      __mm_extract_epi32Ptr.asFunction<int Function(__m128i, int)>();

  int _mm_extract_epi64(
    __m128i arg0,
    int arg1,
  ) {
    return __mm_extract_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm_extract_epi64Ptr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(__m128i, ffi.Int32)>>(
          '_mm_extract_epi64');
  late final __mm_extract_epi64 =
      __mm_extract_epi64Ptr.asFunction<int Function(__m128i, int)>();

  __m128i _mm_minpos_epu16(
    __m128i arg0,
  ) {
    return __mm_minpos_epu16(
      arg0,
    );
  }

  late final __mm_minpos_epu16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i)>>(
          '_mm_minpos_epu16');
  late final __mm_minpos_epu16 =
      __mm_minpos_epu16Ptr.asFunction<__m128i Function(__m128i)>();

  _m128d _mm_round_pd(
    _m128d arg0,
    int arg1,
  ) {
    return __mm_round_pd(
      arg0,
      arg1,
    );
  }

  late final __mm_round_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, ffi.Int32)>>(
          '_mm_round_pd');
  late final __mm_round_pd =
      __mm_round_pdPtr.asFunction<_m128d Function(_m128d, int)>();

  _m128d _mm_round_sd(
    _m128d arg0,
    _m128d arg1,
    int arg2,
  ) {
    return __mm_round_sd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_round_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d, ffi.Int32)>>(
          '_mm_round_sd');
  late final __mm_round_sd =
      __mm_round_sdPtr.asFunction<_m128d Function(_m128d, _m128d, int)>();

  __m128 _mm_round_ps(
    __m128 arg0,
    int arg1,
  ) {
    return __mm_round_ps(
      arg0,
      arg1,
    );
  }

  late final __mm_round_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, ffi.Int32)>>(
          '_mm_round_ps');
  late final __mm_round_ps =
      __mm_round_psPtr.asFunction<__m128 Function(__m128, int)>();

  __m128 _mm_round_ss(
    __m128 arg0,
    __m128 arg1,
    int arg2,
  ) {
    return __mm_round_ss(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_round_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128, ffi.Int32)>>(
          '_mm_round_ss');
  late final __mm_round_ss =
      __mm_round_ssPtr.asFunction<__m128 Function(__m128, __m128, int)>();

  __m128i _mm_cvtepi8_epi32(
    __m128i arg0,
  ) {
    return __mm_cvtepi8_epi32(
      arg0,
    );
  }

  late final __mm_cvtepi8_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i)>>(
          '_mm_cvtepi8_epi32');
  late final __mm_cvtepi8_epi32 =
      __mm_cvtepi8_epi32Ptr.asFunction<__m128i Function(__m128i)>();

  __m128i _mm_cvtepi16_epi32(
    __m128i arg0,
  ) {
    return __mm_cvtepi16_epi32(
      arg0,
    );
  }

  late final __mm_cvtepi16_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i)>>(
          '_mm_cvtepi16_epi32');
  late final __mm_cvtepi16_epi32 =
      __mm_cvtepi16_epi32Ptr.asFunction<__m128i Function(__m128i)>();

  __m128i _mm_cvtepi8_epi64(
    __m128i arg0,
  ) {
    return __mm_cvtepi8_epi64(
      arg0,
    );
  }

  late final __mm_cvtepi8_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i)>>(
          '_mm_cvtepi8_epi64');
  late final __mm_cvtepi8_epi64 =
      __mm_cvtepi8_epi64Ptr.asFunction<__m128i Function(__m128i)>();

  __m128i _mm_cvtepi32_epi64(
    __m128i arg0,
  ) {
    return __mm_cvtepi32_epi64(
      arg0,
    );
  }

  late final __mm_cvtepi32_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i)>>(
          '_mm_cvtepi32_epi64');
  late final __mm_cvtepi32_epi64 =
      __mm_cvtepi32_epi64Ptr.asFunction<__m128i Function(__m128i)>();

  __m128i _mm_cvtepi16_epi64(
    __m128i arg0,
  ) {
    return __mm_cvtepi16_epi64(
      arg0,
    );
  }

  late final __mm_cvtepi16_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i)>>(
          '_mm_cvtepi16_epi64');
  late final __mm_cvtepi16_epi64 =
      __mm_cvtepi16_epi64Ptr.asFunction<__m128i Function(__m128i)>();

  __m128i _mm_cvtepi8_epi16(
    __m128i arg0,
  ) {
    return __mm_cvtepi8_epi16(
      arg0,
    );
  }

  late final __mm_cvtepi8_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i)>>(
          '_mm_cvtepi8_epi16');
  late final __mm_cvtepi8_epi16 =
      __mm_cvtepi8_epi16Ptr.asFunction<__m128i Function(__m128i)>();

  __m128i _mm_cvtepu8_epi32(
    __m128i arg0,
  ) {
    return __mm_cvtepu8_epi32(
      arg0,
    );
  }

  late final __mm_cvtepu8_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i)>>(
          '_mm_cvtepu8_epi32');
  late final __mm_cvtepu8_epi32 =
      __mm_cvtepu8_epi32Ptr.asFunction<__m128i Function(__m128i)>();

  __m128i _mm_cvtepu16_epi32(
    __m128i arg0,
  ) {
    return __mm_cvtepu16_epi32(
      arg0,
    );
  }

  late final __mm_cvtepu16_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i)>>(
          '_mm_cvtepu16_epi32');
  late final __mm_cvtepu16_epi32 =
      __mm_cvtepu16_epi32Ptr.asFunction<__m128i Function(__m128i)>();

  __m128i _mm_cvtepu8_epi64(
    __m128i arg0,
  ) {
    return __mm_cvtepu8_epi64(
      arg0,
    );
  }

  late final __mm_cvtepu8_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i)>>(
          '_mm_cvtepu8_epi64');
  late final __mm_cvtepu8_epi64 =
      __mm_cvtepu8_epi64Ptr.asFunction<__m128i Function(__m128i)>();

  __m128i _mm_cvtepu32_epi64(
    __m128i arg0,
  ) {
    return __mm_cvtepu32_epi64(
      arg0,
    );
  }

  late final __mm_cvtepu32_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i)>>(
          '_mm_cvtepu32_epi64');
  late final __mm_cvtepu32_epi64 =
      __mm_cvtepu32_epi64Ptr.asFunction<__m128i Function(__m128i)>();

  __m128i _mm_cvtepu16_epi64(
    __m128i arg0,
  ) {
    return __mm_cvtepu16_epi64(
      arg0,
    );
  }

  late final __mm_cvtepu16_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i)>>(
          '_mm_cvtepu16_epi64');
  late final __mm_cvtepu16_epi64 =
      __mm_cvtepu16_epi64Ptr.asFunction<__m128i Function(__m128i)>();

  __m128i _mm_cvtepu8_epi16(
    __m128i arg0,
  ) {
    return __mm_cvtepu8_epi16(
      arg0,
    );
  }

  late final __mm_cvtepu8_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i)>>(
          '_mm_cvtepu8_epi16');
  late final __mm_cvtepu8_epi16 =
      __mm_cvtepu8_epi16Ptr.asFunction<__m128i Function(__m128i)>();

  __m128i _mm_packus_epi32(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_packus_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm_packus_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_packus_epi32');
  late final __mm_packus_epi32 =
      __mm_packus_epi32Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_mpsadbw_epu8(
    __m128i arg0,
    __m128i arg1,
    int arg2,
  ) {
    return __mm_mpsadbw_epu8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mpsadbw_epu8Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__m128i, __m128i, ffi.Int32)>>(
      '_mm_mpsadbw_epu8');
  late final __mm_mpsadbw_epu8 = __mm_mpsadbw_epu8Ptr
      .asFunction<__m128i Function(__m128i, __m128i, int)>();

  __m128i _mm_stream_load_si128(
    ffi.Pointer<__m128i> arg0,
  ) {
    return __mm_stream_load_si128(
      arg0,
    );
  }

  late final __mm_stream_load_si128Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(ffi.Pointer<__m128i>)>>(
          '_mm_stream_load_si128');
  late final __mm_stream_load_si128 = __mm_stream_load_si128Ptr
      .asFunction<__m128i Function(ffi.Pointer<__m128i>)>();

  __m128i _mm_cmpistrm(
    __m128i arg0,
    __m128i arg1,
    int arg2,
  ) {
    return __mm_cmpistrm(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_cmpistrmPtr = _lookup<
          ffi.NativeFunction<__m128i Function(__m128i, __m128i, ffi.Int32)>>(
      '_mm_cmpistrm');
  late final __mm_cmpistrm =
      __mm_cmpistrmPtr.asFunction<__m128i Function(__m128i, __m128i, int)>();

  int _mm_cmpistri(
    __m128i arg0,
    __m128i arg1,
    int arg2,
  ) {
    return __mm_cmpistri(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_cmpistriPtr = _lookup<
          ffi.NativeFunction<ffi.Int32 Function(__m128i, __m128i, ffi.Int32)>>(
      '_mm_cmpistri');
  late final __mm_cmpistri =
      __mm_cmpistriPtr.asFunction<int Function(__m128i, __m128i, int)>();

  __m128i _mm_cmpestrm(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    int arg3,
    int arg4,
  ) {
    return __mm_cmpestrm(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_cmpestrmPtr = _lookup<
      ffi.NativeFunction<
          __m128i Function(__m128i, ffi.Int32, __m128i, ffi.Int32,
              ffi.Int32)>>('_mm_cmpestrm');
  late final __mm_cmpestrm = __mm_cmpestrmPtr
      .asFunction<__m128i Function(__m128i, int, __m128i, int, int)>();

  int _mm_cmpestri(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    int arg3,
    int arg4,
  ) {
    return __mm_cmpestri(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_cmpestriPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(__m128i, ffi.Int32, __m128i, ffi.Int32,
              ffi.Int32)>>('_mm_cmpestri');
  late final __mm_cmpestri = __mm_cmpestriPtr
      .asFunction<int Function(__m128i, int, __m128i, int, int)>();

  int _mm_cmpistrz(
    __m128i arg0,
    __m128i arg1,
    int arg2,
  ) {
    return __mm_cmpistrz(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_cmpistrzPtr = _lookup<
          ffi.NativeFunction<ffi.Int32 Function(__m128i, __m128i, ffi.Int32)>>(
      '_mm_cmpistrz');
  late final __mm_cmpistrz =
      __mm_cmpistrzPtr.asFunction<int Function(__m128i, __m128i, int)>();

  int _mm_cmpistrc(
    __m128i arg0,
    __m128i arg1,
    int arg2,
  ) {
    return __mm_cmpistrc(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_cmpistrcPtr = _lookup<
          ffi.NativeFunction<ffi.Int32 Function(__m128i, __m128i, ffi.Int32)>>(
      '_mm_cmpistrc');
  late final __mm_cmpistrc =
      __mm_cmpistrcPtr.asFunction<int Function(__m128i, __m128i, int)>();

  int _mm_cmpistrs(
    __m128i arg0,
    __m128i arg1,
    int arg2,
  ) {
    return __mm_cmpistrs(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_cmpistrsPtr = _lookup<
          ffi.NativeFunction<ffi.Int32 Function(__m128i, __m128i, ffi.Int32)>>(
      '_mm_cmpistrs');
  late final __mm_cmpistrs =
      __mm_cmpistrsPtr.asFunction<int Function(__m128i, __m128i, int)>();

  int _mm_cmpistro(
    __m128i arg0,
    __m128i arg1,
    int arg2,
  ) {
    return __mm_cmpistro(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_cmpistroPtr = _lookup<
          ffi.NativeFunction<ffi.Int32 Function(__m128i, __m128i, ffi.Int32)>>(
      '_mm_cmpistro');
  late final __mm_cmpistro =
      __mm_cmpistroPtr.asFunction<int Function(__m128i, __m128i, int)>();

  int _mm_cmpistra(
    __m128i arg0,
    __m128i arg1,
    int arg2,
  ) {
    return __mm_cmpistra(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_cmpistraPtr = _lookup<
          ffi.NativeFunction<ffi.Int32 Function(__m128i, __m128i, ffi.Int32)>>(
      '_mm_cmpistra');
  late final __mm_cmpistra =
      __mm_cmpistraPtr.asFunction<int Function(__m128i, __m128i, int)>();

  int _mm_cmpestrz(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    int arg3,
    int arg4,
  ) {
    return __mm_cmpestrz(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_cmpestrzPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(__m128i, ffi.Int32, __m128i, ffi.Int32,
              ffi.Int32)>>('_mm_cmpestrz');
  late final __mm_cmpestrz = __mm_cmpestrzPtr
      .asFunction<int Function(__m128i, int, __m128i, int, int)>();

  int _mm_cmpestrc(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    int arg3,
    int arg4,
  ) {
    return __mm_cmpestrc(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_cmpestrcPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(__m128i, ffi.Int32, __m128i, ffi.Int32,
              ffi.Int32)>>('_mm_cmpestrc');
  late final __mm_cmpestrc = __mm_cmpestrcPtr
      .asFunction<int Function(__m128i, int, __m128i, int, int)>();

  int _mm_cmpestrs(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    int arg3,
    int arg4,
  ) {
    return __mm_cmpestrs(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_cmpestrsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(__m128i, ffi.Int32, __m128i, ffi.Int32,
              ffi.Int32)>>('_mm_cmpestrs');
  late final __mm_cmpestrs = __mm_cmpestrsPtr
      .asFunction<int Function(__m128i, int, __m128i, int, int)>();

  int _mm_cmpestro(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    int arg3,
    int arg4,
  ) {
    return __mm_cmpestro(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_cmpestroPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(__m128i, ffi.Int32, __m128i, ffi.Int32,
              ffi.Int32)>>('_mm_cmpestro');
  late final __mm_cmpestro = __mm_cmpestroPtr
      .asFunction<int Function(__m128i, int, __m128i, int, int)>();

  int _mm_cmpestra(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    int arg3,
    int arg4,
  ) {
    return __mm_cmpestra(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_cmpestraPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(__m128i, ffi.Int32, __m128i, ffi.Int32,
              ffi.Int32)>>('_mm_cmpestra');
  late final __mm_cmpestra = __mm_cmpestraPtr
      .asFunction<int Function(__m128i, int, __m128i, int, int)>();

  __m128i _mm_cmpgt_epi64(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_cmpgt_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm_cmpgt_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_cmpgt_epi64');
  late final __mm_cmpgt_epi64 =
      __mm_cmpgt_epi64Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  int _mm_popcnt_u32(
    int arg0,
  ) {
    return __mm_popcnt_u32(
      arg0,
    );
  }

  late final __mm_popcnt_u32Ptr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Uint32)>>(
          '_mm_popcnt_u32');
  late final __mm_popcnt_u32 =
      __mm_popcnt_u32Ptr.asFunction<int Function(int)>();

  int _mm_popcnt_u64(
    int arg0,
  ) {
    return __mm_popcnt_u64(
      arg0,
    );
  }

  late final __mm_popcnt_u64Ptr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(ffi.Uint64)>>(
          '_mm_popcnt_u64');
  late final __mm_popcnt_u64 =
      __mm_popcnt_u64Ptr.asFunction<int Function(int)>();

  int _mm_crc32_u8(
    int arg0,
    int arg1,
  ) {
    return __mm_crc32_u8(
      arg0,
      arg1,
    );
  }

  late final __mm_crc32_u8Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint32 Function(ffi.Uint32, ffi.Uint8)>>(
          '_mm_crc32_u8');
  late final __mm_crc32_u8 =
      __mm_crc32_u8Ptr.asFunction<int Function(int, int)>();

  int _mm_crc32_u16(
    int arg0,
    int arg1,
  ) {
    return __mm_crc32_u16(
      arg0,
      arg1,
    );
  }

  late final __mm_crc32_u16Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint32 Function(ffi.Uint32, ffi.Uint16)>>(
          '_mm_crc32_u16');
  late final __mm_crc32_u16 =
      __mm_crc32_u16Ptr.asFunction<int Function(int, int)>();

  int _mm_crc32_u32(
    int arg0,
    int arg1,
  ) {
    return __mm_crc32_u32(
      arg0,
      arg1,
    );
  }

  late final __mm_crc32_u32Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint32 Function(ffi.Uint32, ffi.Uint32)>>(
          '_mm_crc32_u32');
  late final __mm_crc32_u32 =
      __mm_crc32_u32Ptr.asFunction<int Function(int, int)>();

  int _mm_crc32_u64(
    int arg0,
    int arg1,
  ) {
    return __mm_crc32_u64(
      arg0,
      arg1,
    );
  }

  late final __mm_crc32_u64Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function(ffi.Uint64, ffi.Uint64)>>(
          '_mm_crc32_u64');
  late final __mm_crc32_u64 =
      __mm_crc32_u64Ptr.asFunction<int Function(int, int)>();

  __m128i _mm_aesdec_si128(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_aesdec_si128(
      arg0,
      arg1,
    );
  }

  late final __mm_aesdec_si128Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_aesdec_si128');
  late final __mm_aesdec_si128 =
      __mm_aesdec_si128Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_aesdeclast_si128(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_aesdeclast_si128(
      arg0,
      arg1,
    );
  }

  late final __mm_aesdeclast_si128Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_aesdeclast_si128');
  late final __mm_aesdeclast_si128 =
      __mm_aesdeclast_si128Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_aesenc_si128(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_aesenc_si128(
      arg0,
      arg1,
    );
  }

  late final __mm_aesenc_si128Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_aesenc_si128');
  late final __mm_aesenc_si128 =
      __mm_aesenc_si128Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_aesenclast_si128(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_aesenclast_si128(
      arg0,
      arg1,
    );
  }

  late final __mm_aesenclast_si128Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_aesenclast_si128');
  late final __mm_aesenclast_si128 =
      __mm_aesenclast_si128Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_aesimc_si128(
    __m128i arg0,
  ) {
    return __mm_aesimc_si128(
      arg0,
    );
  }

  late final __mm_aesimc_si128Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i)>>(
          '_mm_aesimc_si128');
  late final __mm_aesimc_si128 =
      __mm_aesimc_si128Ptr.asFunction<__m128i Function(__m128i)>();

  __m128i _mm_aeskeygenassist_si128(
    __m128i arg0,
    int arg1,
  ) {
    return __mm_aeskeygenassist_si128(
      arg0,
      arg1,
    );
  }

  late final __mm_aeskeygenassist_si128Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, ffi.Int32)>>(
          '_mm_aeskeygenassist_si128');
  late final __mm_aeskeygenassist_si128 = __mm_aeskeygenassist_si128Ptr
      .asFunction<__m128i Function(__m128i, int)>();

  __m128i _mm_clmulepi64_si128(
    __m128i arg0,
    __m128i arg1,
    int arg2,
  ) {
    return __mm_clmulepi64_si128(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_clmulepi64_si128Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__m128i, __m128i, ffi.Int32)>>(
      '_mm_clmulepi64_si128');
  late final __mm_clmulepi64_si128 = __mm_clmulepi64_si128Ptr
      .asFunction<__m128i Function(__m128i, __m128i, int)>();

  _m256d _mm256_add_pd(
    _m256d arg0,
    _m256d arg1,
  ) {
    return __mm256_add_pd(
      arg0,
      arg1,
    );
  }

  late final __mm256_add_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d, _m256d)>>(
          '_mm256_add_pd');
  late final __mm256_add_pd =
      __mm256_add_pdPtr.asFunction<_m256d Function(_m256d, _m256d)>();

  __m256 _mm256_add_ps(
    __m256 arg0,
    __m256 arg1,
  ) {
    return __mm256_add_ps(
      arg0,
      arg1,
    );
  }

  late final __mm256_add_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256, __m256)>>(
          '_mm256_add_ps');
  late final __mm256_add_ps =
      __mm256_add_psPtr.asFunction<__m256 Function(__m256, __m256)>();

  _m256d _mm256_addsub_pd(
    _m256d arg0,
    _m256d arg1,
  ) {
    return __mm256_addsub_pd(
      arg0,
      arg1,
    );
  }

  late final __mm256_addsub_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d, _m256d)>>(
          '_mm256_addsub_pd');
  late final __mm256_addsub_pd =
      __mm256_addsub_pdPtr.asFunction<_m256d Function(_m256d, _m256d)>();

  __m256 _mm256_addsub_ps(
    __m256 arg0,
    __m256 arg1,
  ) {
    return __mm256_addsub_ps(
      arg0,
      arg1,
    );
  }

  late final __mm256_addsub_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256, __m256)>>(
          '_mm256_addsub_ps');
  late final __mm256_addsub_ps =
      __mm256_addsub_psPtr.asFunction<__m256 Function(__m256, __m256)>();

  _m256d _mm256_and_pd(
    _m256d arg0,
    _m256d arg1,
  ) {
    return __mm256_and_pd(
      arg0,
      arg1,
    );
  }

  late final __mm256_and_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d, _m256d)>>(
          '_mm256_and_pd');
  late final __mm256_and_pd =
      __mm256_and_pdPtr.asFunction<_m256d Function(_m256d, _m256d)>();

  __m256 _mm256_and_ps(
    __m256 arg0,
    __m256 arg1,
  ) {
    return __mm256_and_ps(
      arg0,
      arg1,
    );
  }

  late final __mm256_and_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256, __m256)>>(
          '_mm256_and_ps');
  late final __mm256_and_ps =
      __mm256_and_psPtr.asFunction<__m256 Function(__m256, __m256)>();

  _m256d _mm256_andnot_pd(
    _m256d arg0,
    _m256d arg1,
  ) {
    return __mm256_andnot_pd(
      arg0,
      arg1,
    );
  }

  late final __mm256_andnot_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d, _m256d)>>(
          '_mm256_andnot_pd');
  late final __mm256_andnot_pd =
      __mm256_andnot_pdPtr.asFunction<_m256d Function(_m256d, _m256d)>();

  __m256 _mm256_andnot_ps(
    __m256 arg0,
    __m256 arg1,
  ) {
    return __mm256_andnot_ps(
      arg0,
      arg1,
    );
  }

  late final __mm256_andnot_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256, __m256)>>(
          '_mm256_andnot_ps');
  late final __mm256_andnot_ps =
      __mm256_andnot_psPtr.asFunction<__m256 Function(__m256, __m256)>();

  _m256d _mm256_blend_pd(
    _m256d arg0,
    _m256d arg1,
    int arg2,
  ) {
    return __mm256_blend_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_blend_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d, _m256d, ffi.Int32)>>(
          '_mm256_blend_pd');
  late final __mm256_blend_pd =
      __mm256_blend_pdPtr.asFunction<_m256d Function(_m256d, _m256d, int)>();

  __m256 _mm256_blend_ps(
    __m256 arg0,
    __m256 arg1,
    int arg2,
  ) {
    return __mm256_blend_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_blend_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256, __m256, ffi.Int32)>>(
          '_mm256_blend_ps');
  late final __mm256_blend_ps =
      __mm256_blend_psPtr.asFunction<__m256 Function(__m256, __m256, int)>();

  _m256d _mm256_blendv_pd(
    _m256d arg0,
    _m256d arg1,
    _m256d arg2,
  ) {
    return __mm256_blendv_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_blendv_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d, _m256d, _m256d)>>(
          '_mm256_blendv_pd');
  late final __mm256_blendv_pd = __mm256_blendv_pdPtr
      .asFunction<_m256d Function(_m256d, _m256d, _m256d)>();

  __m256 _mm256_blendv_ps(
    __m256 arg0,
    __m256 arg1,
    __m256 arg2,
  ) {
    return __mm256_blendv_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_blendv_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256, __m256, __m256)>>(
          '_mm256_blendv_ps');
  late final __mm256_blendv_ps = __mm256_blendv_psPtr
      .asFunction<__m256 Function(__m256, __m256, __m256)>();

  _m256d _mm256_div_pd(
    _m256d arg0,
    _m256d arg1,
  ) {
    return __mm256_div_pd(
      arg0,
      arg1,
    );
  }

  late final __mm256_div_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d, _m256d)>>(
          '_mm256_div_pd');
  late final __mm256_div_pd =
      __mm256_div_pdPtr.asFunction<_m256d Function(_m256d, _m256d)>();

  __m256 _mm256_div_ps(
    __m256 arg0,
    __m256 arg1,
  ) {
    return __mm256_div_ps(
      arg0,
      arg1,
    );
  }

  late final __mm256_div_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256, __m256)>>(
          '_mm256_div_ps');
  late final __mm256_div_ps =
      __mm256_div_psPtr.asFunction<__m256 Function(__m256, __m256)>();

  __m256 _mm256_dp_ps(
    __m256 arg0,
    __m256 arg1,
    int arg2,
  ) {
    return __mm256_dp_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_dp_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256, __m256, ffi.Int32)>>(
          '_mm256_dp_ps');
  late final __mm256_dp_ps =
      __mm256_dp_psPtr.asFunction<__m256 Function(__m256, __m256, int)>();

  _m256d _mm256_hadd_pd(
    _m256d arg0,
    _m256d arg1,
  ) {
    return __mm256_hadd_pd(
      arg0,
      arg1,
    );
  }

  late final __mm256_hadd_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d, _m256d)>>(
          '_mm256_hadd_pd');
  late final __mm256_hadd_pd =
      __mm256_hadd_pdPtr.asFunction<_m256d Function(_m256d, _m256d)>();

  __m256 _mm256_hadd_ps(
    __m256 arg0,
    __m256 arg1,
  ) {
    return __mm256_hadd_ps(
      arg0,
      arg1,
    );
  }

  late final __mm256_hadd_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256, __m256)>>(
          '_mm256_hadd_ps');
  late final __mm256_hadd_ps =
      __mm256_hadd_psPtr.asFunction<__m256 Function(__m256, __m256)>();

  _m256d _mm256_hsub_pd(
    _m256d arg0,
    _m256d arg1,
  ) {
    return __mm256_hsub_pd(
      arg0,
      arg1,
    );
  }

  late final __mm256_hsub_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d, _m256d)>>(
          '_mm256_hsub_pd');
  late final __mm256_hsub_pd =
      __mm256_hsub_pdPtr.asFunction<_m256d Function(_m256d, _m256d)>();

  __m256 _mm256_hsub_ps(
    __m256 arg0,
    __m256 arg1,
  ) {
    return __mm256_hsub_ps(
      arg0,
      arg1,
    );
  }

  late final __mm256_hsub_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256, __m256)>>(
          '_mm256_hsub_ps');
  late final __mm256_hsub_ps =
      __mm256_hsub_psPtr.asFunction<__m256 Function(__m256, __m256)>();

  _m256d _mm256_max_pd(
    _m256d arg0,
    _m256d arg1,
  ) {
    return __mm256_max_pd(
      arg0,
      arg1,
    );
  }

  late final __mm256_max_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d, _m256d)>>(
          '_mm256_max_pd');
  late final __mm256_max_pd =
      __mm256_max_pdPtr.asFunction<_m256d Function(_m256d, _m256d)>();

  __m256 _mm256_max_ps(
    __m256 arg0,
    __m256 arg1,
  ) {
    return __mm256_max_ps(
      arg0,
      arg1,
    );
  }

  late final __mm256_max_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256, __m256)>>(
          '_mm256_max_ps');
  late final __mm256_max_ps =
      __mm256_max_psPtr.asFunction<__m256 Function(__m256, __m256)>();

  _m256d _mm256_min_pd(
    _m256d arg0,
    _m256d arg1,
  ) {
    return __mm256_min_pd(
      arg0,
      arg1,
    );
  }

  late final __mm256_min_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d, _m256d)>>(
          '_mm256_min_pd');
  late final __mm256_min_pd =
      __mm256_min_pdPtr.asFunction<_m256d Function(_m256d, _m256d)>();

  __m256 _mm256_min_ps(
    __m256 arg0,
    __m256 arg1,
  ) {
    return __mm256_min_ps(
      arg0,
      arg1,
    );
  }

  late final __mm256_min_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256, __m256)>>(
          '_mm256_min_ps');
  late final __mm256_min_ps =
      __mm256_min_psPtr.asFunction<__m256 Function(__m256, __m256)>();

  _m256d _mm256_mul_pd(
    _m256d arg0,
    _m256d arg1,
  ) {
    return __mm256_mul_pd(
      arg0,
      arg1,
    );
  }

  late final __mm256_mul_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d, _m256d)>>(
          '_mm256_mul_pd');
  late final __mm256_mul_pd =
      __mm256_mul_pdPtr.asFunction<_m256d Function(_m256d, _m256d)>();

  __m256 _mm256_mul_ps(
    __m256 arg0,
    __m256 arg1,
  ) {
    return __mm256_mul_ps(
      arg0,
      arg1,
    );
  }

  late final __mm256_mul_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256, __m256)>>(
          '_mm256_mul_ps');
  late final __mm256_mul_ps =
      __mm256_mul_psPtr.asFunction<__m256 Function(__m256, __m256)>();

  _m256d _mm256_or_pd(
    _m256d arg0,
    _m256d arg1,
  ) {
    return __mm256_or_pd(
      arg0,
      arg1,
    );
  }

  late final __mm256_or_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d, _m256d)>>(
          '_mm256_or_pd');
  late final __mm256_or_pd =
      __mm256_or_pdPtr.asFunction<_m256d Function(_m256d, _m256d)>();

  __m256 _mm256_or_ps(
    __m256 arg0,
    __m256 arg1,
  ) {
    return __mm256_or_ps(
      arg0,
      arg1,
    );
  }

  late final __mm256_or_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256, __m256)>>(
          '_mm256_or_ps');
  late final __mm256_or_ps =
      __mm256_or_psPtr.asFunction<__m256 Function(__m256, __m256)>();

  _m256d _mm256_shuffle_pd(
    _m256d arg0,
    _m256d arg1,
    int arg2,
  ) {
    return __mm256_shuffle_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_shuffle_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d, _m256d, ffi.Int32)>>(
          '_mm256_shuffle_pd');
  late final __mm256_shuffle_pd =
      __mm256_shuffle_pdPtr.asFunction<_m256d Function(_m256d, _m256d, int)>();

  __m256 _mm256_shuffle_ps(
    __m256 arg0,
    __m256 arg1,
    int arg2,
  ) {
    return __mm256_shuffle_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_shuffle_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256, __m256, ffi.Int32)>>(
          '_mm256_shuffle_ps');
  late final __mm256_shuffle_ps =
      __mm256_shuffle_psPtr.asFunction<__m256 Function(__m256, __m256, int)>();

  _m256d _mm256_sub_pd(
    _m256d arg0,
    _m256d arg1,
  ) {
    return __mm256_sub_pd(
      arg0,
      arg1,
    );
  }

  late final __mm256_sub_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d, _m256d)>>(
          '_mm256_sub_pd');
  late final __mm256_sub_pd =
      __mm256_sub_pdPtr.asFunction<_m256d Function(_m256d, _m256d)>();

  __m256 _mm256_sub_ps(
    __m256 arg0,
    __m256 arg1,
  ) {
    return __mm256_sub_ps(
      arg0,
      arg1,
    );
  }

  late final __mm256_sub_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256, __m256)>>(
          '_mm256_sub_ps');
  late final __mm256_sub_ps =
      __mm256_sub_psPtr.asFunction<__m256 Function(__m256, __m256)>();

  _m256d _mm256_xor_pd(
    _m256d arg0,
    _m256d arg1,
  ) {
    return __mm256_xor_pd(
      arg0,
      arg1,
    );
  }

  late final __mm256_xor_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d, _m256d)>>(
          '_mm256_xor_pd');
  late final __mm256_xor_pd =
      __mm256_xor_pdPtr.asFunction<_m256d Function(_m256d, _m256d)>();

  __m256 _mm256_xor_ps(
    __m256 arg0,
    __m256 arg1,
  ) {
    return __mm256_xor_ps(
      arg0,
      arg1,
    );
  }

  late final __mm256_xor_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256, __m256)>>(
          '_mm256_xor_ps');
  late final __mm256_xor_ps =
      __mm256_xor_psPtr.asFunction<__m256 Function(__m256, __m256)>();

  _m128d _mm_cmp_pd(
    _m128d arg0,
    _m128d arg1,
    int arg2,
  ) {
    return __mm_cmp_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_cmp_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d, ffi.Int32)>>(
          '_mm_cmp_pd');
  late final __mm_cmp_pd =
      __mm_cmp_pdPtr.asFunction<_m128d Function(_m128d, _m128d, int)>();

  _m256d _mm256_cmp_pd(
    _m256d arg0,
    _m256d arg1,
    int arg2,
  ) {
    return __mm256_cmp_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_cmp_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d, _m256d, ffi.Int32)>>(
          '_mm256_cmp_pd');
  late final __mm256_cmp_pd =
      __mm256_cmp_pdPtr.asFunction<_m256d Function(_m256d, _m256d, int)>();

  __m128 _mm_cmp_ps(
    __m128 arg0,
    __m128 arg1,
    int arg2,
  ) {
    return __mm_cmp_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_cmp_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128, ffi.Int32)>>(
          '_mm_cmp_ps');
  late final __mm_cmp_ps =
      __mm_cmp_psPtr.asFunction<__m128 Function(__m128, __m128, int)>();

  __m256 _mm256_cmp_ps(
    __m256 arg0,
    __m256 arg1,
    int arg2,
  ) {
    return __mm256_cmp_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_cmp_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256, __m256, ffi.Int32)>>(
          '_mm256_cmp_ps');
  late final __mm256_cmp_ps =
      __mm256_cmp_psPtr.asFunction<__m256 Function(__m256, __m256, int)>();

  _m128d _mm_cmp_sd(
    _m128d arg0,
    _m128d arg1,
    int arg2,
  ) {
    return __mm_cmp_sd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_cmp_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d, ffi.Int32)>>(
          '_mm_cmp_sd');
  late final __mm_cmp_sd =
      __mm_cmp_sdPtr.asFunction<_m128d Function(_m128d, _m128d, int)>();

  int _mm_comi_sd(
    _m128d arg0,
    _m128d arg1,
    int arg2,
  ) {
    return __mm_comi_sd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_comi_sdPtr = _lookup<
          ffi.NativeFunction<ffi.Int32 Function(_m128d, _m128d, ffi.Int32)>>(
      '_mm_comi_sd');
  late final __mm_comi_sd =
      __mm_comi_sdPtr.asFunction<int Function(_m128d, _m128d, int)>();

  __m128 _mm_cmp_ss(
    __m128 arg0,
    __m128 arg1,
    int arg2,
  ) {
    return __mm_cmp_ss(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_cmp_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128, ffi.Int32)>>(
          '_mm_cmp_ss');
  late final __mm_cmp_ss =
      __mm_cmp_ssPtr.asFunction<__m128 Function(__m128, __m128, int)>();

  int _mm_comi_ss(
    __m128 arg0,
    __m128 arg1,
    int arg2,
  ) {
    return __mm_comi_ss(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_comi_ssPtr = _lookup<
          ffi.NativeFunction<ffi.Int32 Function(__m128, __m128, ffi.Int32)>>(
      '_mm_comi_ss');
  late final __mm_comi_ss =
      __mm_comi_ssPtr.asFunction<int Function(__m128, __m128, int)>();

  _m256d _mm256_cvtepi32_pd(
    __m128i arg0,
  ) {
    return __mm256_cvtepi32_pd(
      arg0,
    );
  }

  late final __mm256_cvtepi32_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(__m128i)>>(
          '_mm256_cvtepi32_pd');
  late final __mm256_cvtepi32_pd =
      __mm256_cvtepi32_pdPtr.asFunction<_m256d Function(__m128i)>();

  __m256 _mm256_cvtepi32_ps(
    __m256i arg0,
  ) {
    return __mm256_cvtepi32_ps(
      arg0,
    );
  }

  late final __mm256_cvtepi32_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256i)>>(
          '_mm256_cvtepi32_ps');
  late final __mm256_cvtepi32_ps =
      __mm256_cvtepi32_psPtr.asFunction<__m256 Function(__m256i)>();

  __m128 _mm256_cvtpd_ps(
    _m256d arg0,
  ) {
    return __mm256_cvtpd_ps(
      arg0,
    );
  }

  late final __mm256_cvtpd_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(_m256d)>>('_mm256_cvtpd_ps');
  late final __mm256_cvtpd_ps =
      __mm256_cvtpd_psPtr.asFunction<__m128 Function(_m256d)>();

  __m256i _mm256_cvtps_epi32(
    __m256 arg0,
  ) {
    return __mm256_cvtps_epi32(
      arg0,
    );
  }

  late final __mm256_cvtps_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256)>>(
          '_mm256_cvtps_epi32');
  late final __mm256_cvtps_epi32 =
      __mm256_cvtps_epi32Ptr.asFunction<__m256i Function(__m256)>();

  _m256d _mm256_cvtps_pd(
    __m128 arg0,
  ) {
    return __mm256_cvtps_pd(
      arg0,
    );
  }

  late final __mm256_cvtps_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(__m128)>>('_mm256_cvtps_pd');
  late final __mm256_cvtps_pd =
      __mm256_cvtps_pdPtr.asFunction<_m256d Function(__m128)>();

  __m128i _mm256_cvttpd_epi32(
    _m256d arg0,
  ) {
    return __mm256_cvttpd_epi32(
      arg0,
    );
  }

  late final __mm256_cvttpd_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(_m256d)>>(
          '_mm256_cvttpd_epi32');
  late final __mm256_cvttpd_epi32 =
      __mm256_cvttpd_epi32Ptr.asFunction<__m128i Function(_m256d)>();

  __m128i _mm256_cvtpd_epi32(
    _m256d arg0,
  ) {
    return __mm256_cvtpd_epi32(
      arg0,
    );
  }

  late final __mm256_cvtpd_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(_m256d)>>(
          '_mm256_cvtpd_epi32');
  late final __mm256_cvtpd_epi32 =
      __mm256_cvtpd_epi32Ptr.asFunction<__m128i Function(_m256d)>();

  __m256i _mm256_cvttps_epi32(
    __m256 arg0,
  ) {
    return __mm256_cvttps_epi32(
      arg0,
    );
  }

  late final __mm256_cvttps_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256)>>(
          '_mm256_cvttps_epi32');
  late final __mm256_cvttps_epi32 =
      __mm256_cvttps_epi32Ptr.asFunction<__m256i Function(__m256)>();

  __m128 _mm256_extractf128_ps(
    __m256 arg0,
    int arg1,
  ) {
    return __mm256_extractf128_ps(
      arg0,
      arg1,
    );
  }

  late final __mm256_extractf128_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m256, ffi.Int32)>>(
          '_mm256_extractf128_ps');
  late final __mm256_extractf128_ps =
      __mm256_extractf128_psPtr.asFunction<__m128 Function(__m256, int)>();

  _m128d _mm256_extractf128_pd(
    _m256d arg0,
    int arg1,
  ) {
    return __mm256_extractf128_pd(
      arg0,
      arg1,
    );
  }

  late final __mm256_extractf128_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m256d, ffi.Int32)>>(
          '_mm256_extractf128_pd');
  late final __mm256_extractf128_pd =
      __mm256_extractf128_pdPtr.asFunction<_m128d Function(_m256d, int)>();

  __m128i _mm256_extractf128_si256(
    __m256i arg0,
    int arg1,
  ) {
    return __mm256_extractf128_si256(
      arg0,
      arg1,
    );
  }

  late final __mm256_extractf128_si256Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m256i, ffi.Int32)>>(
          '_mm256_extractf128_si256');
  late final __mm256_extractf128_si256 =
      __mm256_extractf128_si256Ptr.asFunction<__m128i Function(__m256i, int)>();

  void _mm256_zeroall() {
    return __mm256_zeroall();
  }

  late final __mm256_zeroallPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('_mm256_zeroall');
  late final __mm256_zeroall = __mm256_zeroallPtr.asFunction<void Function()>();

  void _mm256_zeroupper() {
    return __mm256_zeroupper();
  }

  late final __mm256_zeroupperPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('_mm256_zeroupper');
  late final __mm256_zeroupper =
      __mm256_zeroupperPtr.asFunction<void Function()>();

  __m256 _mm256_permutevar_ps(
    __m256 arg0,
    __m256i arg1,
  ) {
    return __mm256_permutevar_ps(
      arg0,
      arg1,
    );
  }

  late final __mm256_permutevar_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256, __m256i)>>(
          '_mm256_permutevar_ps');
  late final __mm256_permutevar_ps =
      __mm256_permutevar_psPtr.asFunction<__m256 Function(__m256, __m256i)>();

  __m128 _mm_permutevar_ps(
    __m128 arg0,
    __m128i arg1,
  ) {
    return __mm_permutevar_ps(
      arg0,
      arg1,
    );
  }

  late final __mm_permutevar_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128i)>>(
          '_mm_permutevar_ps');
  late final __mm_permutevar_ps =
      __mm_permutevar_psPtr.asFunction<__m128 Function(__m128, __m128i)>();

  __m256 _mm256_permute_ps(
    __m256 arg0,
    int arg1,
  ) {
    return __mm256_permute_ps(
      arg0,
      arg1,
    );
  }

  late final __mm256_permute_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256, ffi.Int32)>>(
          '_mm256_permute_ps');
  late final __mm256_permute_ps =
      __mm256_permute_psPtr.asFunction<__m256 Function(__m256, int)>();

  __m128 _mm_permute_ps(
    __m128 arg0,
    int arg1,
  ) {
    return __mm_permute_ps(
      arg0,
      arg1,
    );
  }

  late final __mm_permute_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, ffi.Int32)>>(
          '_mm_permute_ps');
  late final __mm_permute_ps =
      __mm_permute_psPtr.asFunction<__m128 Function(__m128, int)>();

  _m256d _mm256_permutevar_pd(
    _m256d arg0,
    __m256i arg1,
  ) {
    return __mm256_permutevar_pd(
      arg0,
      arg1,
    );
  }

  late final __mm256_permutevar_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d, __m256i)>>(
          '_mm256_permutevar_pd');
  late final __mm256_permutevar_pd =
      __mm256_permutevar_pdPtr.asFunction<_m256d Function(_m256d, __m256i)>();

  _m128d _mm_permutevar_pd(
    _m128d arg0,
    __m128i arg1,
  ) {
    return __mm_permutevar_pd(
      arg0,
      arg1,
    );
  }

  late final __mm_permutevar_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, __m128i)>>(
          '_mm_permutevar_pd');
  late final __mm_permutevar_pd =
      __mm_permutevar_pdPtr.asFunction<_m128d Function(_m128d, __m128i)>();

  _m256d _mm256_permute_pd(
    _m256d arg0,
    int arg1,
  ) {
    return __mm256_permute_pd(
      arg0,
      arg1,
    );
  }

  late final __mm256_permute_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d, ffi.Int32)>>(
          '_mm256_permute_pd');
  late final __mm256_permute_pd =
      __mm256_permute_pdPtr.asFunction<_m256d Function(_m256d, int)>();

  _m128d _mm_permute_pd(
    _m128d arg0,
    int arg1,
  ) {
    return __mm_permute_pd(
      arg0,
      arg1,
    );
  }

  late final __mm_permute_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, ffi.Int32)>>(
          '_mm_permute_pd');
  late final __mm_permute_pd =
      __mm_permute_pdPtr.asFunction<_m128d Function(_m128d, int)>();

  __m256 _mm256_permute2f128_ps(
    __m256 arg0,
    __m256 arg1,
    int arg2,
  ) {
    return __mm256_permute2f128_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_permute2f128_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256, __m256, ffi.Int32)>>(
          '_mm256_permute2f128_ps');
  late final __mm256_permute2f128_ps = __mm256_permute2f128_psPtr
      .asFunction<__m256 Function(__m256, __m256, int)>();

  _m256d _mm256_permute2f128_pd(
    _m256d arg0,
    _m256d arg1,
    int arg2,
  ) {
    return __mm256_permute2f128_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_permute2f128_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d, _m256d, ffi.Int32)>>(
          '_mm256_permute2f128_pd');
  late final __mm256_permute2f128_pd = __mm256_permute2f128_pdPtr
      .asFunction<_m256d Function(_m256d, _m256d, int)>();

  __m256i _mm256_permute2f128_si256(
    __m256i arg0,
    __m256i arg1,
    int arg2,
  ) {
    return __mm256_permute2f128_si256(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_permute2f128_si256Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__m256i, __m256i, ffi.Int32)>>(
      '_mm256_permute2f128_si256');
  late final __mm256_permute2f128_si256 = __mm256_permute2f128_si256Ptr
      .asFunction<__m256i Function(__m256i, __m256i, int)>();

  __m256 _mm256_broadcast_ss(
    ffi.Pointer<ffi.Float> arg0,
  ) {
    return __mm256_broadcast_ss(
      arg0,
    );
  }

  late final __mm256_broadcast_ssPtr =
      _lookup<ffi.NativeFunction<__m256 Function(ffi.Pointer<ffi.Float>)>>(
          '_mm256_broadcast_ss');
  late final __mm256_broadcast_ss = __mm256_broadcast_ssPtr
      .asFunction<__m256 Function(ffi.Pointer<ffi.Float>)>();

  __m128 _mm_broadcast_ss(
    ffi.Pointer<ffi.Float> arg0,
  ) {
    return __mm_broadcast_ss(
      arg0,
    );
  }

  late final __mm_broadcast_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(ffi.Pointer<ffi.Float>)>>(
          '_mm_broadcast_ss');
  late final __mm_broadcast_ss = __mm_broadcast_ssPtr
      .asFunction<__m128 Function(ffi.Pointer<ffi.Float>)>();

  _m256d _mm256_broadcast_sd(
    ffi.Pointer<ffi.Double> arg0,
  ) {
    return __mm256_broadcast_sd(
      arg0,
    );
  }

  late final __mm256_broadcast_sdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(ffi.Pointer<ffi.Double>)>>(
          '_mm256_broadcast_sd');
  late final __mm256_broadcast_sd = __mm256_broadcast_sdPtr
      .asFunction<_m256d Function(ffi.Pointer<ffi.Double>)>();

  __m256 _mm256_broadcast_ps(
    ffi.Pointer<__m128> arg0,
  ) {
    return __mm256_broadcast_ps(
      arg0,
    );
  }

  late final __mm256_broadcast_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(ffi.Pointer<__m128>)>>(
          '_mm256_broadcast_ps');
  late final __mm256_broadcast_ps = __mm256_broadcast_psPtr
      .asFunction<__m256 Function(ffi.Pointer<__m128>)>();

  _m256d _mm256_broadcast_pd(
    ffi.Pointer<_m128d> arg0,
  ) {
    return __mm256_broadcast_pd(
      arg0,
    );
  }

  late final __mm256_broadcast_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(ffi.Pointer<_m128d>)>>(
          '_mm256_broadcast_pd');
  late final __mm256_broadcast_pd = __mm256_broadcast_pdPtr
      .asFunction<_m256d Function(ffi.Pointer<_m128d>)>();

  __m256 _mm256_insertf128_ps(
    __m256 arg0,
    __m128 arg1,
    int arg2,
  ) {
    return __mm256_insertf128_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_insertf128_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256, __m128, ffi.Int32)>>(
          '_mm256_insertf128_ps');
  late final __mm256_insertf128_ps = __mm256_insertf128_psPtr
      .asFunction<__m256 Function(__m256, __m128, int)>();

  _m256d _mm256_insertf128_pd(
    _m256d arg0,
    _m128d arg1,
    int arg2,
  ) {
    return __mm256_insertf128_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_insertf128_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d, _m128d, ffi.Int32)>>(
          '_mm256_insertf128_pd');
  late final __mm256_insertf128_pd = __mm256_insertf128_pdPtr
      .asFunction<_m256d Function(_m256d, _m128d, int)>();

  __m256i _mm256_insertf128_si256(
    __m256i arg0,
    __m128i arg1,
    int arg2,
  ) {
    return __mm256_insertf128_si256(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_insertf128_si256Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__m256i, __m128i, ffi.Int32)>>(
      '_mm256_insertf128_si256');
  late final __mm256_insertf128_si256 = __mm256_insertf128_si256Ptr
      .asFunction<__m256i Function(__m256i, __m128i, int)>();

  _m256d _mm256_load_pd(
    ffi.Pointer<ffi.Double> arg0,
  ) {
    return __mm256_load_pd(
      arg0,
    );
  }

  late final __mm256_load_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(ffi.Pointer<ffi.Double>)>>(
          '_mm256_load_pd');
  late final __mm256_load_pd =
      __mm256_load_pdPtr.asFunction<_m256d Function(ffi.Pointer<ffi.Double>)>();

  void _mm256_store_pd(
    ffi.Pointer<ffi.Double> arg0,
    _m256d arg1,
  ) {
    return __mm256_store_pd(
      arg0,
      arg1,
    );
  }

  late final __mm256_store_pdPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<ffi.Double>, _m256d)>>('_mm256_store_pd');
  late final __mm256_store_pd = __mm256_store_pdPtr
      .asFunction<void Function(ffi.Pointer<ffi.Double>, _m256d)>();

  __m256 _mm256_load_ps(
    ffi.Pointer<ffi.Float> arg0,
  ) {
    return __mm256_load_ps(
      arg0,
    );
  }

  late final __mm256_load_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(ffi.Pointer<ffi.Float>)>>(
          '_mm256_load_ps');
  late final __mm256_load_ps =
      __mm256_load_psPtr.asFunction<__m256 Function(ffi.Pointer<ffi.Float>)>();

  void _mm256_store_ps(
    ffi.Pointer<ffi.Float> arg0,
    __m256 arg1,
  ) {
    return __mm256_store_ps(
      arg0,
      arg1,
    );
  }

  late final __mm256_store_psPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<ffi.Float>, __m256)>>('_mm256_store_ps');
  late final __mm256_store_ps = __mm256_store_psPtr
      .asFunction<void Function(ffi.Pointer<ffi.Float>, __m256)>();

  _m256d _mm256_loadu_pd(
    ffi.Pointer<ffi.Double> arg0,
  ) {
    return __mm256_loadu_pd(
      arg0,
    );
  }

  late final __mm256_loadu_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(ffi.Pointer<ffi.Double>)>>(
          '_mm256_loadu_pd');
  late final __mm256_loadu_pd = __mm256_loadu_pdPtr
      .asFunction<_m256d Function(ffi.Pointer<ffi.Double>)>();

  void _mm256_storeu_pd(
    ffi.Pointer<ffi.Double> arg0,
    _m256d arg1,
  ) {
    return __mm256_storeu_pd(
      arg0,
      arg1,
    );
  }

  late final __mm256_storeu_pdPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<ffi.Double>, _m256d)>>('_mm256_storeu_pd');
  late final __mm256_storeu_pd = __mm256_storeu_pdPtr
      .asFunction<void Function(ffi.Pointer<ffi.Double>, _m256d)>();

  __m256 _mm256_loadu_ps(
    ffi.Pointer<ffi.Float> arg0,
  ) {
    return __mm256_loadu_ps(
      arg0,
    );
  }

  late final __mm256_loadu_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(ffi.Pointer<ffi.Float>)>>(
          '_mm256_loadu_ps');
  late final __mm256_loadu_ps =
      __mm256_loadu_psPtr.asFunction<__m256 Function(ffi.Pointer<ffi.Float>)>();

  void _mm256_storeu_ps(
    ffi.Pointer<ffi.Float> arg0,
    __m256 arg1,
  ) {
    return __mm256_storeu_ps(
      arg0,
      arg1,
    );
  }

  late final __mm256_storeu_psPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<ffi.Float>, __m256)>>('_mm256_storeu_ps');
  late final __mm256_storeu_ps = __mm256_storeu_psPtr
      .asFunction<void Function(ffi.Pointer<ffi.Float>, __m256)>();

  __m256i _mm256_load_si256(
    ffi.Pointer<__m256i> arg0,
  ) {
    return __mm256_load_si256(
      arg0,
    );
  }

  late final __mm256_load_si256Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(ffi.Pointer<__m256i>)>>(
          '_mm256_load_si256');
  late final __mm256_load_si256 = __mm256_load_si256Ptr
      .asFunction<__m256i Function(ffi.Pointer<__m256i>)>();

  void _mm256_store_si256(
    ffi.Pointer<__m256i> arg0,
    __m256i arg1,
  ) {
    return __mm256_store_si256(
      arg0,
      arg1,
    );
  }

  late final __mm256_store_si256Ptr = _lookup<
          ffi.NativeFunction<ffi.Void Function(ffi.Pointer<__m256i>, __m256i)>>(
      '_mm256_store_si256');
  late final __mm256_store_si256 = __mm256_store_si256Ptr
      .asFunction<void Function(ffi.Pointer<__m256i>, __m256i)>();

  __m256i _mm256_loadu_si256(
    ffi.Pointer<__m256i> arg0,
  ) {
    return __mm256_loadu_si256(
      arg0,
    );
  }

  late final __mm256_loadu_si256Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(ffi.Pointer<__m256i>)>>(
          '_mm256_loadu_si256');
  late final __mm256_loadu_si256 = __mm256_loadu_si256Ptr
      .asFunction<__m256i Function(ffi.Pointer<__m256i>)>();

  void _mm256_storeu_si256(
    ffi.Pointer<__m256i> arg0,
    __m256i arg1,
  ) {
    return __mm256_storeu_si256(
      arg0,
      arg1,
    );
  }

  late final __mm256_storeu_si256Ptr = _lookup<
          ffi.NativeFunction<ffi.Void Function(ffi.Pointer<__m256i>, __m256i)>>(
      '_mm256_storeu_si256');
  late final __mm256_storeu_si256 = __mm256_storeu_si256Ptr
      .asFunction<void Function(ffi.Pointer<__m256i>, __m256i)>();

  _m256d _mm256_maskload_pd(
    ffi.Pointer<ffi.Double> arg0,
    __m256i arg1,
  ) {
    return __mm256_maskload_pd(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskload_pdPtr = _lookup<
      ffi.NativeFunction<
          _m256d Function(
              ffi.Pointer<ffi.Double>, __m256i)>>('_mm256_maskload_pd');
  late final __mm256_maskload_pd = __mm256_maskload_pdPtr
      .asFunction<_m256d Function(ffi.Pointer<ffi.Double>, __m256i)>();

  void _mm256_maskstore_pd(
    ffi.Pointer<ffi.Double> arg0,
    __m256i arg1,
    _m256d arg2,
  ) {
    return __mm256_maskstore_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskstore_pdPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Double>, __m256i,
              _m256d)>>('_mm256_maskstore_pd');
  late final __mm256_maskstore_pd = __mm256_maskstore_pdPtr
      .asFunction<void Function(ffi.Pointer<ffi.Double>, __m256i, _m256d)>();

  _m128d _mm_maskload_pd(
    ffi.Pointer<ffi.Double> arg0,
    __m128i arg1,
  ) {
    return __mm_maskload_pd(
      arg0,
      arg1,
    );
  }

  late final __mm_maskload_pdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              ffi.Pointer<ffi.Double>, __m128i)>>('_mm_maskload_pd');
  late final __mm_maskload_pd = __mm_maskload_pdPtr
      .asFunction<_m128d Function(ffi.Pointer<ffi.Double>, __m128i)>();

  void _mm_maskstore_pd(
    ffi.Pointer<ffi.Double> arg0,
    __m128i arg1,
    _m128d arg2,
  ) {
    return __mm_maskstore_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskstore_pdPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<ffi.Double>, __m128i, _m128d)>>('_mm_maskstore_pd');
  late final __mm_maskstore_pd = __mm_maskstore_pdPtr
      .asFunction<void Function(ffi.Pointer<ffi.Double>, __m128i, _m128d)>();

  __m256 _mm256_maskload_ps(
    ffi.Pointer<ffi.Float> arg0,
    __m256i arg1,
  ) {
    return __mm256_maskload_ps(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskload_psPtr = _lookup<
          ffi.NativeFunction<__m256 Function(ffi.Pointer<ffi.Float>, __m256i)>>(
      '_mm256_maskload_ps');
  late final __mm256_maskload_ps = __mm256_maskload_psPtr
      .asFunction<__m256 Function(ffi.Pointer<ffi.Float>, __m256i)>();

  void _mm256_maskstore_ps(
    ffi.Pointer<ffi.Float> arg0,
    __m256i arg1,
    __m256 arg2,
  ) {
    return __mm256_maskstore_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskstore_psPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<ffi.Float>, __m256i, __m256)>>('_mm256_maskstore_ps');
  late final __mm256_maskstore_ps = __mm256_maskstore_psPtr
      .asFunction<void Function(ffi.Pointer<ffi.Float>, __m256i, __m256)>();

  __m128 _mm_maskload_ps(
    ffi.Pointer<ffi.Float> arg0,
    __m128i arg1,
  ) {
    return __mm_maskload_ps(
      arg0,
      arg1,
    );
  }

  late final __mm_maskload_psPtr = _lookup<
          ffi.NativeFunction<__m128 Function(ffi.Pointer<ffi.Float>, __m128i)>>(
      '_mm_maskload_ps');
  late final __mm_maskload_ps = __mm_maskload_psPtr
      .asFunction<__m128 Function(ffi.Pointer<ffi.Float>, __m128i)>();

  void _mm_maskstore_ps(
    ffi.Pointer<ffi.Float> arg0,
    __m128i arg1,
    __m128 arg2,
  ) {
    return __mm_maskstore_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskstore_psPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<ffi.Float>, __m128i, __m128)>>('_mm_maskstore_ps');
  late final __mm_maskstore_ps = __mm_maskstore_psPtr
      .asFunction<void Function(ffi.Pointer<ffi.Float>, __m128i, __m128)>();

  __m256 _mm256_movehdup_ps(
    __m256 arg0,
  ) {
    return __mm256_movehdup_ps(
      arg0,
    );
  }

  late final __mm256_movehdup_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256)>>(
          '_mm256_movehdup_ps');
  late final __mm256_movehdup_ps =
      __mm256_movehdup_psPtr.asFunction<__m256 Function(__m256)>();

  __m256 _mm256_moveldup_ps(
    __m256 arg0,
  ) {
    return __mm256_moveldup_ps(
      arg0,
    );
  }

  late final __mm256_moveldup_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256)>>(
          '_mm256_moveldup_ps');
  late final __mm256_moveldup_ps =
      __mm256_moveldup_psPtr.asFunction<__m256 Function(__m256)>();

  _m256d _mm256_movedup_pd(
    _m256d arg0,
  ) {
    return __mm256_movedup_pd(
      arg0,
    );
  }

  late final __mm256_movedup_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d)>>('_mm256_movedup_pd');
  late final __mm256_movedup_pd =
      __mm256_movedup_pdPtr.asFunction<_m256d Function(_m256d)>();

  __m256i _mm256_lddqu_si256(
    ffi.Pointer<__m256i> arg0,
  ) {
    return __mm256_lddqu_si256(
      arg0,
    );
  }

  late final __mm256_lddqu_si256Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(ffi.Pointer<__m256i>)>>(
          '_mm256_lddqu_si256');
  late final __mm256_lddqu_si256 = __mm256_lddqu_si256Ptr
      .asFunction<__m256i Function(ffi.Pointer<__m256i>)>();

  void _mm256_stream_si256(
    ffi.Pointer<__m256i> arg0,
    __m256i arg1,
  ) {
    return __mm256_stream_si256(
      arg0,
      arg1,
    );
  }

  late final __mm256_stream_si256Ptr = _lookup<
          ffi.NativeFunction<ffi.Void Function(ffi.Pointer<__m256i>, __m256i)>>(
      '_mm256_stream_si256');
  late final __mm256_stream_si256 = __mm256_stream_si256Ptr
      .asFunction<void Function(ffi.Pointer<__m256i>, __m256i)>();

  void _mm256_stream_pd(
    ffi.Pointer<ffi.Double> arg0,
    _m256d arg1,
  ) {
    return __mm256_stream_pd(
      arg0,
      arg1,
    );
  }

  late final __mm256_stream_pdPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<ffi.Double>, _m256d)>>('_mm256_stream_pd');
  late final __mm256_stream_pd = __mm256_stream_pdPtr
      .asFunction<void Function(ffi.Pointer<ffi.Double>, _m256d)>();

  void _mm256_stream_ps(
    ffi.Pointer<ffi.Float> arg0,
    __m256 arg1,
  ) {
    return __mm256_stream_ps(
      arg0,
      arg1,
    );
  }

  late final __mm256_stream_psPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<ffi.Float>, __m256)>>('_mm256_stream_ps');
  late final __mm256_stream_ps = __mm256_stream_psPtr
      .asFunction<void Function(ffi.Pointer<ffi.Float>, __m256)>();

  __m256 _mm256_rcp_ps(
    __m256 arg0,
  ) {
    return __mm256_rcp_ps(
      arg0,
    );
  }

  late final __mm256_rcp_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256)>>('_mm256_rcp_ps');
  late final __mm256_rcp_ps =
      __mm256_rcp_psPtr.asFunction<__m256 Function(__m256)>();

  __m256 _mm256_rsqrt_ps(
    __m256 arg0,
  ) {
    return __mm256_rsqrt_ps(
      arg0,
    );
  }

  late final __mm256_rsqrt_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256)>>('_mm256_rsqrt_ps');
  late final __mm256_rsqrt_ps =
      __mm256_rsqrt_psPtr.asFunction<__m256 Function(__m256)>();

  _m256d _mm256_sqrt_pd(
    _m256d arg0,
  ) {
    return __mm256_sqrt_pd(
      arg0,
    );
  }

  late final __mm256_sqrt_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d)>>('_mm256_sqrt_pd');
  late final __mm256_sqrt_pd =
      __mm256_sqrt_pdPtr.asFunction<_m256d Function(_m256d)>();

  __m256 _mm256_sqrt_ps(
    __m256 arg0,
  ) {
    return __mm256_sqrt_ps(
      arg0,
    );
  }

  late final __mm256_sqrt_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256)>>('_mm256_sqrt_ps');
  late final __mm256_sqrt_ps =
      __mm256_sqrt_psPtr.asFunction<__m256 Function(__m256)>();

  _m256d _mm256_round_pd(
    _m256d arg0,
    int arg1,
  ) {
    return __mm256_round_pd(
      arg0,
      arg1,
    );
  }

  late final __mm256_round_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d, ffi.Int32)>>(
          '_mm256_round_pd');
  late final __mm256_round_pd =
      __mm256_round_pdPtr.asFunction<_m256d Function(_m256d, int)>();

  __m256 _mm256_round_ps(
    __m256 arg0,
    int arg1,
  ) {
    return __mm256_round_ps(
      arg0,
      arg1,
    );
  }

  late final __mm256_round_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256, ffi.Int32)>>(
          '_mm256_round_ps');
  late final __mm256_round_ps =
      __mm256_round_psPtr.asFunction<__m256 Function(__m256, int)>();

  _m256d _mm256_unpackhi_pd(
    _m256d arg0,
    _m256d arg1,
  ) {
    return __mm256_unpackhi_pd(
      arg0,
      arg1,
    );
  }

  late final __mm256_unpackhi_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d, _m256d)>>(
          '_mm256_unpackhi_pd');
  late final __mm256_unpackhi_pd =
      __mm256_unpackhi_pdPtr.asFunction<_m256d Function(_m256d, _m256d)>();

  __m256 _mm256_unpackhi_ps(
    __m256 arg0,
    __m256 arg1,
  ) {
    return __mm256_unpackhi_ps(
      arg0,
      arg1,
    );
  }

  late final __mm256_unpackhi_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256, __m256)>>(
          '_mm256_unpackhi_ps');
  late final __mm256_unpackhi_ps =
      __mm256_unpackhi_psPtr.asFunction<__m256 Function(__m256, __m256)>();

  _m256d _mm256_unpacklo_pd(
    _m256d arg0,
    _m256d arg1,
  ) {
    return __mm256_unpacklo_pd(
      arg0,
      arg1,
    );
  }

  late final __mm256_unpacklo_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d, _m256d)>>(
          '_mm256_unpacklo_pd');
  late final __mm256_unpacklo_pd =
      __mm256_unpacklo_pdPtr.asFunction<_m256d Function(_m256d, _m256d)>();

  __m256 _mm256_unpacklo_ps(
    __m256 arg0,
    __m256 arg1,
  ) {
    return __mm256_unpacklo_ps(
      arg0,
      arg1,
    );
  }

  late final __mm256_unpacklo_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256, __m256)>>(
          '_mm256_unpacklo_ps');
  late final __mm256_unpacklo_ps =
      __mm256_unpacklo_psPtr.asFunction<__m256 Function(__m256, __m256)>();

  int _mm256_testz_si256(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_testz_si256(
      arg0,
      arg1,
    );
  }

  late final __mm256_testz_si256Ptr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(__m256i, __m256i)>>(
          '_mm256_testz_si256');
  late final __mm256_testz_si256 =
      __mm256_testz_si256Ptr.asFunction<int Function(__m256i, __m256i)>();

  int _mm256_testc_si256(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_testc_si256(
      arg0,
      arg1,
    );
  }

  late final __mm256_testc_si256Ptr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(__m256i, __m256i)>>(
          '_mm256_testc_si256');
  late final __mm256_testc_si256 =
      __mm256_testc_si256Ptr.asFunction<int Function(__m256i, __m256i)>();

  int _mm256_testnzc_si256(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_testnzc_si256(
      arg0,
      arg1,
    );
  }

  late final __mm256_testnzc_si256Ptr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(__m256i, __m256i)>>(
          '_mm256_testnzc_si256');
  late final __mm256_testnzc_si256 =
      __mm256_testnzc_si256Ptr.asFunction<int Function(__m256i, __m256i)>();

  int _mm256_testz_pd(
    _m256d arg0,
    _m256d arg1,
  ) {
    return __mm256_testz_pd(
      arg0,
      arg1,
    );
  }

  late final __mm256_testz_pdPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(_m256d, _m256d)>>(
          '_mm256_testz_pd');
  late final __mm256_testz_pd =
      __mm256_testz_pdPtr.asFunction<int Function(_m256d, _m256d)>();

  int _mm256_testc_pd(
    _m256d arg0,
    _m256d arg1,
  ) {
    return __mm256_testc_pd(
      arg0,
      arg1,
    );
  }

  late final __mm256_testc_pdPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(_m256d, _m256d)>>(
          '_mm256_testc_pd');
  late final __mm256_testc_pd =
      __mm256_testc_pdPtr.asFunction<int Function(_m256d, _m256d)>();

  int _mm256_testnzc_pd(
    _m256d arg0,
    _m256d arg1,
  ) {
    return __mm256_testnzc_pd(
      arg0,
      arg1,
    );
  }

  late final __mm256_testnzc_pdPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(_m256d, _m256d)>>(
          '_mm256_testnzc_pd');
  late final __mm256_testnzc_pd =
      __mm256_testnzc_pdPtr.asFunction<int Function(_m256d, _m256d)>();

  int _mm_testz_pd(
    _m128d arg0,
    _m128d arg1,
  ) {
    return __mm_testz_pd(
      arg0,
      arg1,
    );
  }

  late final __mm_testz_pdPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(_m128d, _m128d)>>(
          '_mm_testz_pd');
  late final __mm_testz_pd =
      __mm_testz_pdPtr.asFunction<int Function(_m128d, _m128d)>();

  int _mm_testc_pd(
    _m128d arg0,
    _m128d arg1,
  ) {
    return __mm_testc_pd(
      arg0,
      arg1,
    );
  }

  late final __mm_testc_pdPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(_m128d, _m128d)>>(
          '_mm_testc_pd');
  late final __mm_testc_pd =
      __mm_testc_pdPtr.asFunction<int Function(_m128d, _m128d)>();

  int _mm_testnzc_pd(
    _m128d arg0,
    _m128d arg1,
  ) {
    return __mm_testnzc_pd(
      arg0,
      arg1,
    );
  }

  late final __mm_testnzc_pdPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(_m128d, _m128d)>>(
          '_mm_testnzc_pd');
  late final __mm_testnzc_pd =
      __mm_testnzc_pdPtr.asFunction<int Function(_m128d, _m128d)>();

  int _mm256_testz_ps(
    __m256 arg0,
    __m256 arg1,
  ) {
    return __mm256_testz_ps(
      arg0,
      arg1,
    );
  }

  late final __mm256_testz_psPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(__m256, __m256)>>(
          '_mm256_testz_ps');
  late final __mm256_testz_ps =
      __mm256_testz_psPtr.asFunction<int Function(__m256, __m256)>();

  int _mm256_testc_ps(
    __m256 arg0,
    __m256 arg1,
  ) {
    return __mm256_testc_ps(
      arg0,
      arg1,
    );
  }

  late final __mm256_testc_psPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(__m256, __m256)>>(
          '_mm256_testc_ps');
  late final __mm256_testc_ps =
      __mm256_testc_psPtr.asFunction<int Function(__m256, __m256)>();

  int _mm256_testnzc_ps(
    __m256 arg0,
    __m256 arg1,
  ) {
    return __mm256_testnzc_ps(
      arg0,
      arg1,
    );
  }

  late final __mm256_testnzc_psPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(__m256, __m256)>>(
          '_mm256_testnzc_ps');
  late final __mm256_testnzc_ps =
      __mm256_testnzc_psPtr.asFunction<int Function(__m256, __m256)>();

  int _mm_testz_ps(
    __m128 arg0,
    __m128 arg1,
  ) {
    return __mm_testz_ps(
      arg0,
      arg1,
    );
  }

  late final __mm_testz_psPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(__m128, __m128)>>(
          '_mm_testz_ps');
  late final __mm_testz_ps =
      __mm_testz_psPtr.asFunction<int Function(__m128, __m128)>();

  int _mm_testc_ps(
    __m128 arg0,
    __m128 arg1,
  ) {
    return __mm_testc_ps(
      arg0,
      arg1,
    );
  }

  late final __mm_testc_psPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(__m128, __m128)>>(
          '_mm_testc_ps');
  late final __mm_testc_ps =
      __mm_testc_psPtr.asFunction<int Function(__m128, __m128)>();

  int _mm_testnzc_ps(
    __m128 arg0,
    __m128 arg1,
  ) {
    return __mm_testnzc_ps(
      arg0,
      arg1,
    );
  }

  late final __mm_testnzc_psPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(__m128, __m128)>>(
          '_mm_testnzc_ps');
  late final __mm_testnzc_ps =
      __mm_testnzc_psPtr.asFunction<int Function(__m128, __m128)>();

  int _mm256_movemask_pd(
    _m256d arg0,
  ) {
    return __mm256_movemask_pd(
      arg0,
    );
  }

  late final __mm256_movemask_pdPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(_m256d)>>(
          '_mm256_movemask_pd');
  late final __mm256_movemask_pd =
      __mm256_movemask_pdPtr.asFunction<int Function(_m256d)>();

  int _mm256_movemask_ps(
    __m256 arg0,
  ) {
    return __mm256_movemask_ps(
      arg0,
    );
  }

  late final __mm256_movemask_psPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(__m256)>>(
          '_mm256_movemask_ps');
  late final __mm256_movemask_ps =
      __mm256_movemask_psPtr.asFunction<int Function(__m256)>();

  _m256d _mm256_setzero_pd() {
    return __mm256_setzero_pd();
  }

  late final __mm256_setzero_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function()>>('_mm256_setzero_pd');
  late final __mm256_setzero_pd =
      __mm256_setzero_pdPtr.asFunction<_m256d Function()>();

  __m256 _mm256_setzero_ps() {
    return __mm256_setzero_ps();
  }

  late final __mm256_setzero_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function()>>('_mm256_setzero_ps');
  late final __mm256_setzero_ps =
      __mm256_setzero_psPtr.asFunction<__m256 Function()>();

  __m256i _mm256_setzero_si256() {
    return __mm256_setzero_si256();
  }

  late final __mm256_setzero_si256Ptr =
      _lookup<ffi.NativeFunction<__m256i Function()>>('_mm256_setzero_si256');
  late final __mm256_setzero_si256 =
      __mm256_setzero_si256Ptr.asFunction<__m256i Function()>();

  _m256d _mm256_set_pd(
    double arg0,
    double arg1,
    double arg2,
    double arg3,
  ) {
    return __mm256_set_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_set_pdPtr = _lookup<
      ffi.NativeFunction<
          _m256d Function(ffi.Double, ffi.Double, ffi.Double,
              ffi.Double)>>('_mm256_set_pd');
  late final __mm256_set_pd = __mm256_set_pdPtr
      .asFunction<_m256d Function(double, double, double, double)>();

  __m256 _mm256_set_ps(
    double arg0,
    double arg1,
    double arg2,
    double arg3,
    double arg4,
    double arg5,
    double arg6,
    double arg7,
  ) {
    return __mm256_set_ps(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
      arg5,
      arg6,
      arg7,
    );
  }

  late final __mm256_set_psPtr = _lookup<
      ffi.NativeFunction<
          __m256 Function(ffi.Float, ffi.Float, ffi.Float, ffi.Float, ffi.Float,
              ffi.Float, ffi.Float, ffi.Float)>>('_mm256_set_ps');
  late final __mm256_set_ps = __mm256_set_psPtr.asFunction<
      __m256 Function(
          double, double, double, double, double, double, double, double)>();

  __m256i _mm256_set_epi8(
    int arg0,
    int arg1,
    int arg2,
    int arg3,
    int arg4,
    int arg5,
    int arg6,
    int arg7,
    int arg8,
    int arg9,
    int arg10,
    int arg11,
    int arg12,
    int arg13,
    int arg14,
    int arg15,
    int arg16,
    int arg17,
    int arg18,
    int arg19,
    int arg20,
    int arg21,
    int arg22,
    int arg23,
    int arg24,
    int arg25,
    int arg26,
    int arg27,
    int arg28,
    int arg29,
    int arg30,
    int arg31,
  ) {
    return __mm256_set_epi8(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
      arg5,
      arg6,
      arg7,
      arg8,
      arg9,
      arg10,
      arg11,
      arg12,
      arg13,
      arg14,
      arg15,
      arg16,
      arg17,
      arg18,
      arg19,
      arg20,
      arg21,
      arg22,
      arg23,
      arg24,
      arg25,
      arg26,
      arg27,
      arg28,
      arg29,
      arg30,
      arg31,
    );
  }

  late final __mm256_set_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8)>>('_mm256_set_epi8');
  late final __mm256_set_epi8 = __mm256_set_epi8Ptr.asFunction<
      __m256i Function(
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int)>();

  __m256i _mm256_set_epi16(
    int arg0,
    int arg1,
    int arg2,
    int arg3,
    int arg4,
    int arg5,
    int arg6,
    int arg7,
    int arg8,
    int arg9,
    int arg10,
    int arg11,
    int arg12,
    int arg13,
    int arg14,
    int arg15,
  ) {
    return __mm256_set_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
      arg5,
      arg6,
      arg7,
      arg8,
      arg9,
      arg10,
      arg11,
      arg12,
      arg13,
      arg14,
      arg15,
    );
  }

  late final __mm256_set_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16)>>('_mm256_set_epi16');
  late final __mm256_set_epi16 = __mm256_set_epi16Ptr.asFunction<
      __m256i Function(int, int, int, int, int, int, int, int, int, int, int,
          int, int, int, int, int)>();

  __m256i _mm256_set_epi32(
    int arg0,
    int arg1,
    int arg2,
    int arg3,
    int arg4,
    int arg5,
    int arg6,
    int arg7,
  ) {
    return __mm256_set_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
      arg5,
      arg6,
      arg7,
    );
  }

  late final __mm256_set_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(ffi.Int32, ffi.Int32, ffi.Int32, ffi.Int32,
              ffi.Int32, ffi.Int32, ffi.Int32, ffi.Int32)>>('_mm256_set_epi32');
  late final __mm256_set_epi32 = __mm256_set_epi32Ptr
      .asFunction<__m256i Function(int, int, int, int, int, int, int, int)>();

  __m256i _mm256_set_epi64x(
    int arg0,
    int arg1,
    int arg2,
    int arg3,
  ) {
    return __mm256_set_epi64x(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_set_epi64xPtr = _lookup<
      ffi.NativeFunction<
          __m256i Function(ffi.Int64, ffi.Int64, ffi.Int64,
              ffi.Int64)>>('_mm256_set_epi64x');
  late final __mm256_set_epi64x =
      __mm256_set_epi64xPtr.asFunction<__m256i Function(int, int, int, int)>();

  _m256d _mm256_setr_pd(
    double arg0,
    double arg1,
    double arg2,
    double arg3,
  ) {
    return __mm256_setr_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_setr_pdPtr = _lookup<
      ffi.NativeFunction<
          _m256d Function(ffi.Double, ffi.Double, ffi.Double,
              ffi.Double)>>('_mm256_setr_pd');
  late final __mm256_setr_pd = __mm256_setr_pdPtr
      .asFunction<_m256d Function(double, double, double, double)>();

  __m256 _mm256_setr_ps(
    double arg0,
    double arg1,
    double arg2,
    double arg3,
    double arg4,
    double arg5,
    double arg6,
    double arg7,
  ) {
    return __mm256_setr_ps(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
      arg5,
      arg6,
      arg7,
    );
  }

  late final __mm256_setr_psPtr = _lookup<
      ffi.NativeFunction<
          __m256 Function(ffi.Float, ffi.Float, ffi.Float, ffi.Float, ffi.Float,
              ffi.Float, ffi.Float, ffi.Float)>>('_mm256_setr_ps');
  late final __mm256_setr_ps = __mm256_setr_psPtr.asFunction<
      __m256 Function(
          double, double, double, double, double, double, double, double)>();

  __m256i _mm256_setr_epi8(
    int arg0,
    int arg1,
    int arg2,
    int arg3,
    int arg4,
    int arg5,
    int arg6,
    int arg7,
    int arg8,
    int arg9,
    int arg10,
    int arg11,
    int arg12,
    int arg13,
    int arg14,
    int arg15,
    int arg16,
    int arg17,
    int arg18,
    int arg19,
    int arg20,
    int arg21,
    int arg22,
    int arg23,
    int arg24,
    int arg25,
    int arg26,
    int arg27,
    int arg28,
    int arg29,
    int arg30,
    int arg31,
  ) {
    return __mm256_setr_epi8(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
      arg5,
      arg6,
      arg7,
      arg8,
      arg9,
      arg10,
      arg11,
      arg12,
      arg13,
      arg14,
      arg15,
      arg16,
      arg17,
      arg18,
      arg19,
      arg20,
      arg21,
      arg22,
      arg23,
      arg24,
      arg25,
      arg26,
      arg27,
      arg28,
      arg29,
      arg30,
      arg31,
    );
  }

  late final __mm256_setr_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8)>>('_mm256_setr_epi8');
  late final __mm256_setr_epi8 = __mm256_setr_epi8Ptr.asFunction<
      __m256i Function(
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int)>();

  __m256i _mm256_setr_epi16(
    int arg0,
    int arg1,
    int arg2,
    int arg3,
    int arg4,
    int arg5,
    int arg6,
    int arg7,
    int arg8,
    int arg9,
    int arg10,
    int arg11,
    int arg12,
    int arg13,
    int arg14,
    int arg15,
  ) {
    return __mm256_setr_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
      arg5,
      arg6,
      arg7,
      arg8,
      arg9,
      arg10,
      arg11,
      arg12,
      arg13,
      arg14,
      arg15,
    );
  }

  late final __mm256_setr_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16)>>('_mm256_setr_epi16');
  late final __mm256_setr_epi16 = __mm256_setr_epi16Ptr.asFunction<
      __m256i Function(int, int, int, int, int, int, int, int, int, int, int,
          int, int, int, int, int)>();

  __m256i _mm256_setr_epi32(
    int arg0,
    int arg1,
    int arg2,
    int arg3,
    int arg4,
    int arg5,
    int arg6,
    int arg7,
  ) {
    return __mm256_setr_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
      arg5,
      arg6,
      arg7,
    );
  }

  late final __mm256_setr_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              ffi.Int32,
              ffi.Int32,
              ffi.Int32,
              ffi.Int32,
              ffi.Int32,
              ffi.Int32,
              ffi.Int32,
              ffi.Int32)>>('_mm256_setr_epi32');
  late final __mm256_setr_epi32 = __mm256_setr_epi32Ptr
      .asFunction<__m256i Function(int, int, int, int, int, int, int, int)>();

  __m256i _mm256_setr_epi64x(
    int arg0,
    int arg1,
    int arg2,
    int arg3,
  ) {
    return __mm256_setr_epi64x(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_setr_epi64xPtr = _lookup<
      ffi.NativeFunction<
          __m256i Function(ffi.Int64, ffi.Int64, ffi.Int64,
              ffi.Int64)>>('_mm256_setr_epi64x');
  late final __mm256_setr_epi64x =
      __mm256_setr_epi64xPtr.asFunction<__m256i Function(int, int, int, int)>();

  _m256d _mm256_set1_pd(
    double arg0,
  ) {
    return __mm256_set1_pd(
      arg0,
    );
  }

  late final __mm256_set1_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(ffi.Double)>>(
          '_mm256_set1_pd');
  late final __mm256_set1_pd =
      __mm256_set1_pdPtr.asFunction<_m256d Function(double)>();

  __m256 _mm256_set1_ps(
    double arg0,
  ) {
    return __mm256_set1_ps(
      arg0,
    );
  }

  late final __mm256_set1_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(ffi.Float)>>('_mm256_set1_ps');
  late final __mm256_set1_ps =
      __mm256_set1_psPtr.asFunction<__m256 Function(double)>();

  __m256i _mm256_set1_epi8(
    int arg0,
  ) {
    return __mm256_set1_epi8(
      arg0,
    );
  }

  late final __mm256_set1_epi8Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(ffi.Int8)>>(
          '_mm256_set1_epi8');
  late final __mm256_set1_epi8 =
      __mm256_set1_epi8Ptr.asFunction<__m256i Function(int)>();

  __m256i _mm256_set1_epi16(
    int arg0,
  ) {
    return __mm256_set1_epi16(
      arg0,
    );
  }

  late final __mm256_set1_epi16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(ffi.Int16)>>(
          '_mm256_set1_epi16');
  late final __mm256_set1_epi16 =
      __mm256_set1_epi16Ptr.asFunction<__m256i Function(int)>();

  __m256i _mm256_set1_epi32(
    int arg0,
  ) {
    return __mm256_set1_epi32(
      arg0,
    );
  }

  late final __mm256_set1_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(ffi.Int32)>>(
          '_mm256_set1_epi32');
  late final __mm256_set1_epi32 =
      __mm256_set1_epi32Ptr.asFunction<__m256i Function(int)>();

  __m256i _mm256_set1_epi64x(
    int arg0,
  ) {
    return __mm256_set1_epi64x(
      arg0,
    );
  }

  late final __mm256_set1_epi64xPtr =
      _lookup<ffi.NativeFunction<__m256i Function(ffi.Int64)>>(
          '_mm256_set1_epi64x');
  late final __mm256_set1_epi64x =
      __mm256_set1_epi64xPtr.asFunction<__m256i Function(int)>();

  __m256 _mm256_castpd_ps(
    _m256d arg0,
  ) {
    return __mm256_castpd_ps(
      arg0,
    );
  }

  late final __mm256_castpd_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(_m256d)>>('_mm256_castpd_ps');
  late final __mm256_castpd_ps =
      __mm256_castpd_psPtr.asFunction<__m256 Function(_m256d)>();

  _m256d _mm256_castps_pd(
    __m256 arg0,
  ) {
    return __mm256_castps_pd(
      arg0,
    );
  }

  late final __mm256_castps_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(__m256)>>('_mm256_castps_pd');
  late final __mm256_castps_pd =
      __mm256_castps_pdPtr.asFunction<_m256d Function(__m256)>();

  __m256i _mm256_castps_si256(
    __m256 arg0,
  ) {
    return __mm256_castps_si256(
      arg0,
    );
  }

  late final __mm256_castps_si256Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256)>>(
          '_mm256_castps_si256');
  late final __mm256_castps_si256 =
      __mm256_castps_si256Ptr.asFunction<__m256i Function(__m256)>();

  __m256i _mm256_castpd_si256(
    _m256d arg0,
  ) {
    return __mm256_castpd_si256(
      arg0,
    );
  }

  late final __mm256_castpd_si256Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(_m256d)>>(
          '_mm256_castpd_si256');
  late final __mm256_castpd_si256 =
      __mm256_castpd_si256Ptr.asFunction<__m256i Function(_m256d)>();

  __m256 _mm256_castsi256_ps(
    __m256i arg0,
  ) {
    return __mm256_castsi256_ps(
      arg0,
    );
  }

  late final __mm256_castsi256_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256i)>>(
          '_mm256_castsi256_ps');
  late final __mm256_castsi256_ps =
      __mm256_castsi256_psPtr.asFunction<__m256 Function(__m256i)>();

  _m256d _mm256_castsi256_pd(
    __m256i arg0,
  ) {
    return __mm256_castsi256_pd(
      arg0,
    );
  }

  late final __mm256_castsi256_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(__m256i)>>(
          '_mm256_castsi256_pd');
  late final __mm256_castsi256_pd =
      __mm256_castsi256_pdPtr.asFunction<_m256d Function(__m256i)>();

  __m128 _mm256_castps256_ps128(
    __m256 arg0,
  ) {
    return __mm256_castps256_ps128(
      arg0,
    );
  }

  late final __mm256_castps256_ps128Ptr =
      _lookup<ffi.NativeFunction<__m128 Function(__m256)>>(
          '_mm256_castps256_ps128');
  late final __mm256_castps256_ps128 =
      __mm256_castps256_ps128Ptr.asFunction<__m128 Function(__m256)>();

  _m128d _mm256_castpd256_pd128(
    _m256d arg0,
  ) {
    return __mm256_castpd256_pd128(
      arg0,
    );
  }

  late final __mm256_castpd256_pd128Ptr =
      _lookup<ffi.NativeFunction<_m128d Function(_m256d)>>(
          '_mm256_castpd256_pd128');
  late final __mm256_castpd256_pd128 =
      __mm256_castpd256_pd128Ptr.asFunction<_m128d Function(_m256d)>();

  __m128i _mm256_castsi256_si128(
    __m256i arg0,
  ) {
    return __mm256_castsi256_si128(
      arg0,
    );
  }

  late final __mm256_castsi256_si128Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m256i)>>(
          '_mm256_castsi256_si128');
  late final __mm256_castsi256_si128 =
      __mm256_castsi256_si128Ptr.asFunction<__m128i Function(__m256i)>();

  __m256 _mm256_castps128_ps256(
    __m128 arg0,
  ) {
    return __mm256_castps128_ps256(
      arg0,
    );
  }

  late final __mm256_castps128_ps256Ptr =
      _lookup<ffi.NativeFunction<__m256 Function(__m128)>>(
          '_mm256_castps128_ps256');
  late final __mm256_castps128_ps256 =
      __mm256_castps128_ps256Ptr.asFunction<__m256 Function(__m128)>();

  _m256d _mm256_castpd128_pd256(
    _m128d arg0,
  ) {
    return __mm256_castpd128_pd256(
      arg0,
    );
  }

  late final __mm256_castpd128_pd256Ptr =
      _lookup<ffi.NativeFunction<_m256d Function(_m128d)>>(
          '_mm256_castpd128_pd256');
  late final __mm256_castpd128_pd256 =
      __mm256_castpd128_pd256Ptr.asFunction<_m256d Function(_m128d)>();

  __m256i _mm256_castsi128_si256(
    __m128i arg0,
  ) {
    return __mm256_castsi128_si256(
      arg0,
    );
  }

  late final __mm256_castsi128_si256Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m128i)>>(
          '_mm256_castsi128_si256');
  late final __mm256_castsi128_si256 =
      __mm256_castsi128_si256Ptr.asFunction<__m256i Function(__m128i)>();

  __m128 _mm_cvtph_ps(
    __m128i arg0,
  ) {
    return __mm_cvtph_ps(
      arg0,
    );
  }

  late final __mm_cvtph_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128i)>>('_mm_cvtph_ps');
  late final __mm_cvtph_ps =
      __mm_cvtph_psPtr.asFunction<__m128 Function(__m128i)>();

  __m256 _mm256_cvtph_ps(
    __m128i arg0,
  ) {
    return __mm256_cvtph_ps(
      arg0,
    );
  }

  late final __mm256_cvtph_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m128i)>>('_mm256_cvtph_ps');
  late final __mm256_cvtph_ps =
      __mm256_cvtph_psPtr.asFunction<__m256 Function(__m128i)>();

  __m128i _mm_cvtps_ph(
    __m128 arg0,
    int arg1,
  ) {
    return __mm_cvtps_ph(
      arg0,
      arg1,
    );
  }

  late final __mm_cvtps_phPtr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128, ffi.Int32)>>(
          '_mm_cvtps_ph');
  late final __mm_cvtps_ph =
      __mm_cvtps_phPtr.asFunction<__m128i Function(__m128, int)>();

  __m128i _mm256_cvtps_ph(
    __m256 arg0,
    int arg1,
  ) {
    return __mm256_cvtps_ph(
      arg0,
      arg1,
    );
  }

  late final __mm256_cvtps_phPtr =
      _lookup<ffi.NativeFunction<__m128i Function(__m256, ffi.Int32)>>(
          '_mm256_cvtps_ph');
  late final __mm256_cvtps_ph =
      __mm256_cvtps_phPtr.asFunction<__m128i Function(__m256, int)>();

  int _xgetbv(
    int arg0,
  ) {
    return __xgetbv(
      arg0,
    );
  }

  late final __xgetbvPtr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function(ffi.Uint32)>>('_xgetbv');
  late final __xgetbv = __xgetbvPtr.asFunction<int Function(int)>();

  void _xsetbv(
    int arg0,
    int arg1,
  ) {
    return __xsetbv(
      arg0,
      arg1,
    );
  }

  late final __xsetbvPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Uint32, ffi.Uint64)>>(
          '_xsetbv');
  late final __xsetbv = __xsetbvPtr.asFunction<void Function(int, int)>();

  void _xsave(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
  ) {
    return __xsave(
      arg0,
      arg1,
    );
  }

  late final __xsavePtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, ffi.Uint64)>>('_xsave');
  late final __xsave =
      __xsavePtr.asFunction<void Function(ffi.Pointer<ffi.Void>, int)>();

  void _xsave64(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
  ) {
    return __xsave64(
      arg0,
      arg1,
    );
  }

  late final __xsave64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, ffi.Uint64)>>('_xsave64');
  late final __xsave64 =
      __xsave64Ptr.asFunction<void Function(ffi.Pointer<ffi.Void>, int)>();

  void _xsaveopt(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
  ) {
    return __xsaveopt(
      arg0,
      arg1,
    );
  }

  late final __xsaveoptPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, ffi.Uint64)>>('_xsaveopt');
  late final __xsaveopt =
      __xsaveoptPtr.asFunction<void Function(ffi.Pointer<ffi.Void>, int)>();

  void _xsaveopt64(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
  ) {
    return __xsaveopt64(
      arg0,
      arg1,
    );
  }

  late final __xsaveopt64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, ffi.Uint64)>>('_xsaveopt64');
  late final __xsaveopt64 =
      __xsaveopt64Ptr.asFunction<void Function(ffi.Pointer<ffi.Void>, int)>();

  void _xsavec(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
  ) {
    return __xsavec(
      arg0,
      arg1,
    );
  }

  late final __xsavecPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, ffi.Uint64)>>('_xsavec');
  late final __xsavec =
      __xsavecPtr.asFunction<void Function(ffi.Pointer<ffi.Void>, int)>();

  void _xsavec64(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
  ) {
    return __xsavec64(
      arg0,
      arg1,
    );
  }

  late final __xsavec64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, ffi.Uint64)>>('_xsavec64');
  late final __xsavec64 =
      __xsavec64Ptr.asFunction<void Function(ffi.Pointer<ffi.Void>, int)>();

  void _xrstor(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
  ) {
    return __xrstor(
      arg0,
      arg1,
    );
  }

  late final __xrstorPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, ffi.Uint64)>>('_xrstor');
  late final __xrstor =
      __xrstorPtr.asFunction<void Function(ffi.Pointer<ffi.Void>, int)>();

  void _xrstor64(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
  ) {
    return __xrstor64(
      arg0,
      arg1,
    );
  }

  late final __xrstor64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, ffi.Uint64)>>('_xrstor64');
  late final __xrstor64 =
      __xrstor64Ptr.asFunction<void Function(ffi.Pointer<ffi.Void>, int)>();

  void _xsaves(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
  ) {
    return __xsaves(
      arg0,
      arg1,
    );
  }

  late final __xsavesPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, ffi.Uint64)>>('_xsaves');
  late final __xsaves =
      __xsavesPtr.asFunction<void Function(ffi.Pointer<ffi.Void>, int)>();

  void _xsaves64(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
  ) {
    return __xsaves64(
      arg0,
      arg1,
    );
  }

  late final __xsaves64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, ffi.Uint64)>>('_xsaves64');
  late final __xsaves64 =
      __xsaves64Ptr.asFunction<void Function(ffi.Pointer<ffi.Void>, int)>();

  void _xrstors(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
  ) {
    return __xrstors(
      arg0,
      arg1,
    );
  }

  late final __xrstorsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, ffi.Uint64)>>('_xrstors');
  late final __xrstors =
      __xrstorsPtr.asFunction<void Function(ffi.Pointer<ffi.Void>, int)>();

  void _xrstors64(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
  ) {
    return __xrstors64(
      arg0,
      arg1,
    );
  }

  late final __xrstors64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, ffi.Uint64)>>('_xrstors64');
  late final __xrstors64 =
      __xrstors64Ptr.asFunction<void Function(ffi.Pointer<ffi.Void>, int)>();

  void _fxsave(
    ffi.Pointer<ffi.Void> arg0,
  ) {
    return __fxsave(
      arg0,
    );
  }

  late final __fxsavePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ffi.Void>)>>(
          '_fxsave');
  late final __fxsave =
      __fxsavePtr.asFunction<void Function(ffi.Pointer<ffi.Void>)>();

  void _fxsave64(
    ffi.Pointer<ffi.Void> arg0,
  ) {
    return __fxsave64(
      arg0,
    );
  }

  late final __fxsave64Ptr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ffi.Void>)>>(
          '_fxsave64');
  late final __fxsave64 =
      __fxsave64Ptr.asFunction<void Function(ffi.Pointer<ffi.Void>)>();

  void _fxrstor(
    ffi.Pointer<ffi.Void> arg0,
  ) {
    return __fxrstor(
      arg0,
    );
  }

  late final __fxrstorPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ffi.Void>)>>(
          '_fxrstor');
  late final __fxrstor =
      __fxrstorPtr.asFunction<void Function(ffi.Pointer<ffi.Void>)>();

  void _fxrstor64(
    ffi.Pointer<ffi.Void> arg0,
  ) {
    return __fxrstor64(
      arg0,
    );
  }

  late final __fxrstor64Ptr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ffi.Void>)>>(
          '_fxrstor64');
  late final __fxrstor64 =
      __fxrstor64Ptr.asFunction<void Function(ffi.Pointer<ffi.Void>)>();

  int _rdrand16_step(
    ffi.Pointer<ffi.Uint16> arg0,
  ) {
    return __rdrand16_step(
      arg0,
    );
  }

  late final __rdrand16_stepPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<ffi.Uint16>)>>(
          '_rdrand16_step');
  late final __rdrand16_step =
      __rdrand16_stepPtr.asFunction<int Function(ffi.Pointer<ffi.Uint16>)>();

  int _rdrand32_step(
    ffi.Pointer<ffi.Uint32> arg0,
  ) {
    return __rdrand32_step(
      arg0,
    );
  }

  late final __rdrand32_stepPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<ffi.Uint32>)>>(
          '_rdrand32_step');
  late final __rdrand32_step =
      __rdrand32_stepPtr.asFunction<int Function(ffi.Pointer<ffi.Uint32>)>();

  int _rdrand64_step(
    ffi.Pointer<ffi.Uint64> arg0,
  ) {
    return __rdrand64_step(
      arg0,
    );
  }

  late final __rdrand64_stepPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<ffi.Uint64>)>>(
          '_rdrand64_step');
  late final __rdrand64_step =
      __rdrand64_stepPtr.asFunction<int Function(ffi.Pointer<ffi.Uint64>)>();

  int _readfsbase_u32() {
    return __readfsbase_u32();
  }

  late final __readfsbase_u32Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint32 Function()>>('_readfsbase_u32');
  late final __readfsbase_u32 =
      __readfsbase_u32Ptr.asFunction<int Function()>();

  int _readgsbase_u32() {
    return __readgsbase_u32();
  }

  late final __readgsbase_u32Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint32 Function()>>('_readgsbase_u32');
  late final __readgsbase_u32 =
      __readgsbase_u32Ptr.asFunction<int Function()>();

  int _readfsbase_u64() {
    return __readfsbase_u64();
  }

  late final __readfsbase_u64Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function()>>('_readfsbase_u64');
  late final __readfsbase_u64 =
      __readfsbase_u64Ptr.asFunction<int Function()>();

  int _readgsbase_u64() {
    return __readgsbase_u64();
  }

  late final __readgsbase_u64Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function()>>('_readgsbase_u64');
  late final __readgsbase_u64 =
      __readgsbase_u64Ptr.asFunction<int Function()>();

  void _writefsbase_u32(
    int arg0,
  ) {
    return __writefsbase_u32(
      arg0,
    );
  }

  late final __writefsbase_u32Ptr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Uint32)>>(
          '_writefsbase_u32');
  late final __writefsbase_u32 =
      __writefsbase_u32Ptr.asFunction<void Function(int)>();

  void _writegsbase_u32(
    int arg0,
  ) {
    return __writegsbase_u32(
      arg0,
    );
  }

  late final __writegsbase_u32Ptr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Uint32)>>(
          '_writegsbase_u32');
  late final __writegsbase_u32 =
      __writegsbase_u32Ptr.asFunction<void Function(int)>();

  void _writefsbase_u64(
    int arg0,
  ) {
    return __writefsbase_u64(
      arg0,
    );
  }

  late final __writefsbase_u64Ptr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Uint64)>>(
          '_writefsbase_u64');
  late final __writefsbase_u64 =
      __writefsbase_u64Ptr.asFunction<void Function(int)>();

  void _writegsbase_u64(
    int arg0,
  ) {
    return __writegsbase_u64(
      arg0,
    );
  }

  late final __writegsbase_u64Ptr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Uint64)>>(
          '_writegsbase_u64');
  late final __writegsbase_u64 =
      __writegsbase_u64Ptr.asFunction<void Function(int)>();

  __m128 _mm_fmadd_ps(
    __m128 arg0,
    __m128 arg1,
    __m128 arg2,
  ) {
    return __mm_fmadd_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_fmadd_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128, __m128)>>(
          '_mm_fmadd_ps');
  late final __mm_fmadd_ps =
      __mm_fmadd_psPtr.asFunction<__m128 Function(__m128, __m128, __m128)>();

  _m128d _mm_fmadd_pd(
    _m128d arg0,
    _m128d arg1,
    _m128d arg2,
  ) {
    return __mm_fmadd_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_fmadd_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d, _m128d)>>(
          '_mm_fmadd_pd');
  late final __mm_fmadd_pd =
      __mm_fmadd_pdPtr.asFunction<_m128d Function(_m128d, _m128d, _m128d)>();

  __m128 _mm_fmadd_ss(
    __m128 arg0,
    __m128 arg1,
    __m128 arg2,
  ) {
    return __mm_fmadd_ss(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_fmadd_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128, __m128)>>(
          '_mm_fmadd_ss');
  late final __mm_fmadd_ss =
      __mm_fmadd_ssPtr.asFunction<__m128 Function(__m128, __m128, __m128)>();

  _m128d _mm_fmadd_sd(
    _m128d arg0,
    _m128d arg1,
    _m128d arg2,
  ) {
    return __mm_fmadd_sd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_fmadd_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d, _m128d)>>(
          '_mm_fmadd_sd');
  late final __mm_fmadd_sd =
      __mm_fmadd_sdPtr.asFunction<_m128d Function(_m128d, _m128d, _m128d)>();

  __m128 _mm_fmsub_ps(
    __m128 arg0,
    __m128 arg1,
    __m128 arg2,
  ) {
    return __mm_fmsub_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_fmsub_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128, __m128)>>(
          '_mm_fmsub_ps');
  late final __mm_fmsub_ps =
      __mm_fmsub_psPtr.asFunction<__m128 Function(__m128, __m128, __m128)>();

  _m128d _mm_fmsub_pd(
    _m128d arg0,
    _m128d arg1,
    _m128d arg2,
  ) {
    return __mm_fmsub_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_fmsub_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d, _m128d)>>(
          '_mm_fmsub_pd');
  late final __mm_fmsub_pd =
      __mm_fmsub_pdPtr.asFunction<_m128d Function(_m128d, _m128d, _m128d)>();

  __m128 _mm_fmsub_ss(
    __m128 arg0,
    __m128 arg1,
    __m128 arg2,
  ) {
    return __mm_fmsub_ss(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_fmsub_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128, __m128)>>(
          '_mm_fmsub_ss');
  late final __mm_fmsub_ss =
      __mm_fmsub_ssPtr.asFunction<__m128 Function(__m128, __m128, __m128)>();

  _m128d _mm_fmsub_sd(
    _m128d arg0,
    _m128d arg1,
    _m128d arg2,
  ) {
    return __mm_fmsub_sd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_fmsub_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d, _m128d)>>(
          '_mm_fmsub_sd');
  late final __mm_fmsub_sd =
      __mm_fmsub_sdPtr.asFunction<_m128d Function(_m128d, _m128d, _m128d)>();

  __m128 _mm_fnmadd_ps(
    __m128 arg0,
    __m128 arg1,
    __m128 arg2,
  ) {
    return __mm_fnmadd_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_fnmadd_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128, __m128)>>(
          '_mm_fnmadd_ps');
  late final __mm_fnmadd_ps =
      __mm_fnmadd_psPtr.asFunction<__m128 Function(__m128, __m128, __m128)>();

  _m128d _mm_fnmadd_pd(
    _m128d arg0,
    _m128d arg1,
    _m128d arg2,
  ) {
    return __mm_fnmadd_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_fnmadd_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d, _m128d)>>(
          '_mm_fnmadd_pd');
  late final __mm_fnmadd_pd =
      __mm_fnmadd_pdPtr.asFunction<_m128d Function(_m128d, _m128d, _m128d)>();

  __m128 _mm_fnmadd_ss(
    __m128 arg0,
    __m128 arg1,
    __m128 arg2,
  ) {
    return __mm_fnmadd_ss(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_fnmadd_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128, __m128)>>(
          '_mm_fnmadd_ss');
  late final __mm_fnmadd_ss =
      __mm_fnmadd_ssPtr.asFunction<__m128 Function(__m128, __m128, __m128)>();

  _m128d _mm_fnmadd_sd(
    _m128d arg0,
    _m128d arg1,
    _m128d arg2,
  ) {
    return __mm_fnmadd_sd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_fnmadd_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d, _m128d)>>(
          '_mm_fnmadd_sd');
  late final __mm_fnmadd_sd =
      __mm_fnmadd_sdPtr.asFunction<_m128d Function(_m128d, _m128d, _m128d)>();

  __m128 _mm_fnmsub_ps(
    __m128 arg0,
    __m128 arg1,
    __m128 arg2,
  ) {
    return __mm_fnmsub_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_fnmsub_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128, __m128)>>(
          '_mm_fnmsub_ps');
  late final __mm_fnmsub_ps =
      __mm_fnmsub_psPtr.asFunction<__m128 Function(__m128, __m128, __m128)>();

  _m128d _mm_fnmsub_pd(
    _m128d arg0,
    _m128d arg1,
    _m128d arg2,
  ) {
    return __mm_fnmsub_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_fnmsub_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d, _m128d)>>(
          '_mm_fnmsub_pd');
  late final __mm_fnmsub_pd =
      __mm_fnmsub_pdPtr.asFunction<_m128d Function(_m128d, _m128d, _m128d)>();

  __m128 _mm_fnmsub_ss(
    __m128 arg0,
    __m128 arg1,
    __m128 arg2,
  ) {
    return __mm_fnmsub_ss(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_fnmsub_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128, __m128)>>(
          '_mm_fnmsub_ss');
  late final __mm_fnmsub_ss =
      __mm_fnmsub_ssPtr.asFunction<__m128 Function(__m128, __m128, __m128)>();

  _m128d _mm_fnmsub_sd(
    _m128d arg0,
    _m128d arg1,
    _m128d arg2,
  ) {
    return __mm_fnmsub_sd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_fnmsub_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d, _m128d)>>(
          '_mm_fnmsub_sd');
  late final __mm_fnmsub_sd =
      __mm_fnmsub_sdPtr.asFunction<_m128d Function(_m128d, _m128d, _m128d)>();

  __m256 _mm256_fmadd_ps(
    __m256 arg0,
    __m256 arg1,
    __m256 arg2,
  ) {
    return __mm256_fmadd_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_fmadd_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256, __m256, __m256)>>(
          '_mm256_fmadd_ps');
  late final __mm256_fmadd_ps =
      __mm256_fmadd_psPtr.asFunction<__m256 Function(__m256, __m256, __m256)>();

  _m256d _mm256_fmadd_pd(
    _m256d arg0,
    _m256d arg1,
    _m256d arg2,
  ) {
    return __mm256_fmadd_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_fmadd_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d, _m256d, _m256d)>>(
          '_mm256_fmadd_pd');
  late final __mm256_fmadd_pd =
      __mm256_fmadd_pdPtr.asFunction<_m256d Function(_m256d, _m256d, _m256d)>();

  __m256 _mm256_fmsub_ps(
    __m256 arg0,
    __m256 arg1,
    __m256 arg2,
  ) {
    return __mm256_fmsub_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_fmsub_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256, __m256, __m256)>>(
          '_mm256_fmsub_ps');
  late final __mm256_fmsub_ps =
      __mm256_fmsub_psPtr.asFunction<__m256 Function(__m256, __m256, __m256)>();

  _m256d _mm256_fmsub_pd(
    _m256d arg0,
    _m256d arg1,
    _m256d arg2,
  ) {
    return __mm256_fmsub_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_fmsub_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d, _m256d, _m256d)>>(
          '_mm256_fmsub_pd');
  late final __mm256_fmsub_pd =
      __mm256_fmsub_pdPtr.asFunction<_m256d Function(_m256d, _m256d, _m256d)>();

  __m256 _mm256_fnmadd_ps(
    __m256 arg0,
    __m256 arg1,
    __m256 arg2,
  ) {
    return __mm256_fnmadd_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_fnmadd_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256, __m256, __m256)>>(
          '_mm256_fnmadd_ps');
  late final __mm256_fnmadd_ps = __mm256_fnmadd_psPtr
      .asFunction<__m256 Function(__m256, __m256, __m256)>();

  _m256d _mm256_fnmadd_pd(
    _m256d arg0,
    _m256d arg1,
    _m256d arg2,
  ) {
    return __mm256_fnmadd_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_fnmadd_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d, _m256d, _m256d)>>(
          '_mm256_fnmadd_pd');
  late final __mm256_fnmadd_pd = __mm256_fnmadd_pdPtr
      .asFunction<_m256d Function(_m256d, _m256d, _m256d)>();

  __m256 _mm256_fnmsub_ps(
    __m256 arg0,
    __m256 arg1,
    __m256 arg2,
  ) {
    return __mm256_fnmsub_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_fnmsub_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256, __m256, __m256)>>(
          '_mm256_fnmsub_ps');
  late final __mm256_fnmsub_ps = __mm256_fnmsub_psPtr
      .asFunction<__m256 Function(__m256, __m256, __m256)>();

  _m256d _mm256_fnmsub_pd(
    _m256d arg0,
    _m256d arg1,
    _m256d arg2,
  ) {
    return __mm256_fnmsub_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_fnmsub_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d, _m256d, _m256d)>>(
          '_mm256_fnmsub_pd');
  late final __mm256_fnmsub_pd = __mm256_fnmsub_pdPtr
      .asFunction<_m256d Function(_m256d, _m256d, _m256d)>();

  __m128 _mm_fmaddsub_ps(
    __m128 arg0,
    __m128 arg1,
    __m128 arg2,
  ) {
    return __mm_fmaddsub_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_fmaddsub_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128, __m128)>>(
          '_mm_fmaddsub_ps');
  late final __mm_fmaddsub_ps =
      __mm_fmaddsub_psPtr.asFunction<__m128 Function(__m128, __m128, __m128)>();

  _m128d _mm_fmaddsub_pd(
    _m128d arg0,
    _m128d arg1,
    _m128d arg2,
  ) {
    return __mm_fmaddsub_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_fmaddsub_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d, _m128d)>>(
          '_mm_fmaddsub_pd');
  late final __mm_fmaddsub_pd =
      __mm_fmaddsub_pdPtr.asFunction<_m128d Function(_m128d, _m128d, _m128d)>();

  __m128 _mm_fmsubadd_ps(
    __m128 arg0,
    __m128 arg1,
    __m128 arg2,
  ) {
    return __mm_fmsubadd_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_fmsubadd_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128, __m128)>>(
          '_mm_fmsubadd_ps');
  late final __mm_fmsubadd_ps =
      __mm_fmsubadd_psPtr.asFunction<__m128 Function(__m128, __m128, __m128)>();

  _m128d _mm_fmsubadd_pd(
    _m128d arg0,
    _m128d arg1,
    _m128d arg2,
  ) {
    return __mm_fmsubadd_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_fmsubadd_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d, _m128d)>>(
          '_mm_fmsubadd_pd');
  late final __mm_fmsubadd_pd =
      __mm_fmsubadd_pdPtr.asFunction<_m128d Function(_m128d, _m128d, _m128d)>();

  __m256 _mm256_fmaddsub_ps(
    __m256 arg0,
    __m256 arg1,
    __m256 arg2,
  ) {
    return __mm256_fmaddsub_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_fmaddsub_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256, __m256, __m256)>>(
          '_mm256_fmaddsub_ps');
  late final __mm256_fmaddsub_ps = __mm256_fmaddsub_psPtr
      .asFunction<__m256 Function(__m256, __m256, __m256)>();

  _m256d _mm256_fmaddsub_pd(
    _m256d arg0,
    _m256d arg1,
    _m256d arg2,
  ) {
    return __mm256_fmaddsub_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_fmaddsub_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d, _m256d, _m256d)>>(
          '_mm256_fmaddsub_pd');
  late final __mm256_fmaddsub_pd = __mm256_fmaddsub_pdPtr
      .asFunction<_m256d Function(_m256d, _m256d, _m256d)>();

  __m256 _mm256_fmsubadd_ps(
    __m256 arg0,
    __m256 arg1,
    __m256 arg2,
  ) {
    return __mm256_fmsubadd_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_fmsubadd_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256, __m256, __m256)>>(
          '_mm256_fmsubadd_ps');
  late final __mm256_fmsubadd_ps = __mm256_fmsubadd_psPtr
      .asFunction<__m256 Function(__m256, __m256, __m256)>();

  _m256d _mm256_fmsubadd_pd(
    _m256d arg0,
    _m256d arg1,
    _m256d arg2,
  ) {
    return __mm256_fmsubadd_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_fmsubadd_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d, _m256d, _m256d)>>(
          '_mm256_fmsubadd_pd');
  late final __mm256_fmsubadd_pd = __mm256_fmsubadd_pdPtr
      .asFunction<_m256d Function(_m256d, _m256d, _m256d)>();

  __m256i _mm256_cmpeq_epi8(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_cmpeq_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm256_cmpeq_epi8Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_cmpeq_epi8');
  late final __mm256_cmpeq_epi8 =
      __mm256_cmpeq_epi8Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_cmpeq_epi16(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_cmpeq_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm256_cmpeq_epi16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_cmpeq_epi16');
  late final __mm256_cmpeq_epi16 =
      __mm256_cmpeq_epi16Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_cmpeq_epi32(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_cmpeq_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm256_cmpeq_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_cmpeq_epi32');
  late final __mm256_cmpeq_epi32 =
      __mm256_cmpeq_epi32Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_cmpeq_epi64(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_cmpeq_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm256_cmpeq_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_cmpeq_epi64');
  late final __mm256_cmpeq_epi64 =
      __mm256_cmpeq_epi64Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_cmpgt_epi8(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_cmpgt_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm256_cmpgt_epi8Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_cmpgt_epi8');
  late final __mm256_cmpgt_epi8 =
      __mm256_cmpgt_epi8Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_cmpgt_epi16(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_cmpgt_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm256_cmpgt_epi16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_cmpgt_epi16');
  late final __mm256_cmpgt_epi16 =
      __mm256_cmpgt_epi16Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_cmpgt_epi32(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_cmpgt_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm256_cmpgt_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_cmpgt_epi32');
  late final __mm256_cmpgt_epi32 =
      __mm256_cmpgt_epi32Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_cmpgt_epi64(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_cmpgt_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm256_cmpgt_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_cmpgt_epi64');
  late final __mm256_cmpgt_epi64 =
      __mm256_cmpgt_epi64Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_max_epi8(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_max_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm256_max_epi8Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_max_epi8');
  late final __mm256_max_epi8 =
      __mm256_max_epi8Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_max_epi16(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_max_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm256_max_epi16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_max_epi16');
  late final __mm256_max_epi16 =
      __mm256_max_epi16Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_max_epi32(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_max_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm256_max_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_max_epi32');
  late final __mm256_max_epi32 =
      __mm256_max_epi32Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_max_epu8(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_max_epu8(
      arg0,
      arg1,
    );
  }

  late final __mm256_max_epu8Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_max_epu8');
  late final __mm256_max_epu8 =
      __mm256_max_epu8Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_max_epu16(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_max_epu16(
      arg0,
      arg1,
    );
  }

  late final __mm256_max_epu16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_max_epu16');
  late final __mm256_max_epu16 =
      __mm256_max_epu16Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_max_epu32(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_max_epu32(
      arg0,
      arg1,
    );
  }

  late final __mm256_max_epu32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_max_epu32');
  late final __mm256_max_epu32 =
      __mm256_max_epu32Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_min_epi8(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_min_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm256_min_epi8Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_min_epi8');
  late final __mm256_min_epi8 =
      __mm256_min_epi8Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_min_epi16(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_min_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm256_min_epi16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_min_epi16');
  late final __mm256_min_epi16 =
      __mm256_min_epi16Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_min_epi32(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_min_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm256_min_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_min_epi32');
  late final __mm256_min_epi32 =
      __mm256_min_epi32Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_min_epu8(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_min_epu8(
      arg0,
      arg1,
    );
  }

  late final __mm256_min_epu8Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_min_epu8');
  late final __mm256_min_epu8 =
      __mm256_min_epu8Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_min_epu16(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_min_epu16(
      arg0,
      arg1,
    );
  }

  late final __mm256_min_epu16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_min_epu16');
  late final __mm256_min_epu16 =
      __mm256_min_epu16Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_min_epu32(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_min_epu32(
      arg0,
      arg1,
    );
  }

  late final __mm256_min_epu32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_min_epu32');
  late final __mm256_min_epu32 =
      __mm256_min_epu32Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_and_si256(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_and_si256(
      arg0,
      arg1,
    );
  }

  late final __mm256_and_si256Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_and_si256');
  late final __mm256_and_si256 =
      __mm256_and_si256Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_andnot_si256(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_andnot_si256(
      arg0,
      arg1,
    );
  }

  late final __mm256_andnot_si256Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_andnot_si256');
  late final __mm256_andnot_si256 =
      __mm256_andnot_si256Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_or_si256(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_or_si256(
      arg0,
      arg1,
    );
  }

  late final __mm256_or_si256Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_or_si256');
  late final __mm256_or_si256 =
      __mm256_or_si256Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_xor_si256(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_xor_si256(
      arg0,
      arg1,
    );
  }

  late final __mm256_xor_si256Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_xor_si256');
  late final __mm256_xor_si256 =
      __mm256_xor_si256Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_abs_epi8(
    __m256i arg0,
  ) {
    return __mm256_abs_epi8(
      arg0,
    );
  }

  late final __mm256_abs_epi8Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i)>>('_mm256_abs_epi8');
  late final __mm256_abs_epi8 =
      __mm256_abs_epi8Ptr.asFunction<__m256i Function(__m256i)>();

  __m256i _mm256_abs_epi16(
    __m256i arg0,
  ) {
    return __mm256_abs_epi16(
      arg0,
    );
  }

  late final __mm256_abs_epi16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i)>>(
          '_mm256_abs_epi16');
  late final __mm256_abs_epi16 =
      __mm256_abs_epi16Ptr.asFunction<__m256i Function(__m256i)>();

  __m256i _mm256_abs_epi32(
    __m256i arg0,
  ) {
    return __mm256_abs_epi32(
      arg0,
    );
  }

  late final __mm256_abs_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i)>>(
          '_mm256_abs_epi32');
  late final __mm256_abs_epi32 =
      __mm256_abs_epi32Ptr.asFunction<__m256i Function(__m256i)>();

  __m256i _mm256_add_epi8(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_add_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm256_add_epi8Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_add_epi8');
  late final __mm256_add_epi8 =
      __mm256_add_epi8Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_add_epi16(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_add_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm256_add_epi16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_add_epi16');
  late final __mm256_add_epi16 =
      __mm256_add_epi16Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_add_epi32(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_add_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm256_add_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_add_epi32');
  late final __mm256_add_epi32 =
      __mm256_add_epi32Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_add_epi64(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_add_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm256_add_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_add_epi64');
  late final __mm256_add_epi64 =
      __mm256_add_epi64Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_adds_epi8(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_adds_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm256_adds_epi8Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_adds_epi8');
  late final __mm256_adds_epi8 =
      __mm256_adds_epi8Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_adds_epi16(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_adds_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm256_adds_epi16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_adds_epi16');
  late final __mm256_adds_epi16 =
      __mm256_adds_epi16Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_adds_epu8(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_adds_epu8(
      arg0,
      arg1,
    );
  }

  late final __mm256_adds_epu8Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_adds_epu8');
  late final __mm256_adds_epu8 =
      __mm256_adds_epu8Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_adds_epu16(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_adds_epu16(
      arg0,
      arg1,
    );
  }

  late final __mm256_adds_epu16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_adds_epu16');
  late final __mm256_adds_epu16 =
      __mm256_adds_epu16Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_sub_epi8(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_sub_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm256_sub_epi8Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_sub_epi8');
  late final __mm256_sub_epi8 =
      __mm256_sub_epi8Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_sub_epi16(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_sub_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm256_sub_epi16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_sub_epi16');
  late final __mm256_sub_epi16 =
      __mm256_sub_epi16Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_sub_epi32(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_sub_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm256_sub_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_sub_epi32');
  late final __mm256_sub_epi32 =
      __mm256_sub_epi32Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_sub_epi64(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_sub_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm256_sub_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_sub_epi64');
  late final __mm256_sub_epi64 =
      __mm256_sub_epi64Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_subs_epi8(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_subs_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm256_subs_epi8Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_subs_epi8');
  late final __mm256_subs_epi8 =
      __mm256_subs_epi8Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_subs_epi16(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_subs_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm256_subs_epi16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_subs_epi16');
  late final __mm256_subs_epi16 =
      __mm256_subs_epi16Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_subs_epu8(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_subs_epu8(
      arg0,
      arg1,
    );
  }

  late final __mm256_subs_epu8Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_subs_epu8');
  late final __mm256_subs_epu8 =
      __mm256_subs_epu8Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_subs_epu16(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_subs_epu16(
      arg0,
      arg1,
    );
  }

  late final __mm256_subs_epu16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_subs_epu16');
  late final __mm256_subs_epu16 =
      __mm256_subs_epu16Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_avg_epu8(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_avg_epu8(
      arg0,
      arg1,
    );
  }

  late final __mm256_avg_epu8Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_avg_epu8');
  late final __mm256_avg_epu8 =
      __mm256_avg_epu8Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_avg_epu16(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_avg_epu16(
      arg0,
      arg1,
    );
  }

  late final __mm256_avg_epu16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_avg_epu16');
  late final __mm256_avg_epu16 =
      __mm256_avg_epu16Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_hadd_epi16(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_hadd_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm256_hadd_epi16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_hadd_epi16');
  late final __mm256_hadd_epi16 =
      __mm256_hadd_epi16Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_hadd_epi32(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_hadd_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm256_hadd_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_hadd_epi32');
  late final __mm256_hadd_epi32 =
      __mm256_hadd_epi32Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_hadds_epi16(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_hadds_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm256_hadds_epi16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_hadds_epi16');
  late final __mm256_hadds_epi16 =
      __mm256_hadds_epi16Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_hsub_epi16(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_hsub_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm256_hsub_epi16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_hsub_epi16');
  late final __mm256_hsub_epi16 =
      __mm256_hsub_epi16Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_hsub_epi32(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_hsub_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm256_hsub_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_hsub_epi32');
  late final __mm256_hsub_epi32 =
      __mm256_hsub_epi32Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_hsubs_epi16(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_hsubs_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm256_hsubs_epi16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_hsubs_epi16');
  late final __mm256_hsubs_epi16 =
      __mm256_hsubs_epi16Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_madd_epi16(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_madd_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm256_madd_epi16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_madd_epi16');
  late final __mm256_madd_epi16 =
      __mm256_madd_epi16Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_maddubs_epi16(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_maddubs_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm256_maddubs_epi16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_maddubs_epi16');
  late final __mm256_maddubs_epi16 =
      __mm256_maddubs_epi16Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_mulhi_epi16(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_mulhi_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm256_mulhi_epi16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_mulhi_epi16');
  late final __mm256_mulhi_epi16 =
      __mm256_mulhi_epi16Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_mulhi_epu16(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_mulhi_epu16(
      arg0,
      arg1,
    );
  }

  late final __mm256_mulhi_epu16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_mulhi_epu16');
  late final __mm256_mulhi_epu16 =
      __mm256_mulhi_epu16Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_mullo_epi16(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_mullo_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm256_mullo_epi16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_mullo_epi16');
  late final __mm256_mullo_epi16 =
      __mm256_mullo_epi16Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_mullo_epi32(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_mullo_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm256_mullo_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_mullo_epi32');
  late final __mm256_mullo_epi32 =
      __mm256_mullo_epi32Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_mul_epu32(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_mul_epu32(
      arg0,
      arg1,
    );
  }

  late final __mm256_mul_epu32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_mul_epu32');
  late final __mm256_mul_epu32 =
      __mm256_mul_epu32Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_mul_epi32(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_mul_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm256_mul_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_mul_epi32');
  late final __mm256_mul_epi32 =
      __mm256_mul_epi32Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_sign_epi8(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_sign_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm256_sign_epi8Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_sign_epi8');
  late final __mm256_sign_epi8 =
      __mm256_sign_epi8Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_sign_epi16(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_sign_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm256_sign_epi16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_sign_epi16');
  late final __mm256_sign_epi16 =
      __mm256_sign_epi16Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_sign_epi32(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_sign_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm256_sign_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_sign_epi32');
  late final __mm256_sign_epi32 =
      __mm256_sign_epi32Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_mulhrs_epi16(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_mulhrs_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm256_mulhrs_epi16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_mulhrs_epi16');
  late final __mm256_mulhrs_epi16 =
      __mm256_mulhrs_epi16Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_sad_epu8(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_sad_epu8(
      arg0,
      arg1,
    );
  }

  late final __mm256_sad_epu8Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_sad_epu8');
  late final __mm256_sad_epu8 =
      __mm256_sad_epu8Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_mpsadbw_epu8(
    __m256i arg0,
    __m256i arg1,
    int arg2,
  ) {
    return __mm256_mpsadbw_epu8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mpsadbw_epu8Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__m256i, __m256i, ffi.Int32)>>(
      '_mm256_mpsadbw_epu8');
  late final __mm256_mpsadbw_epu8 = __mm256_mpsadbw_epu8Ptr
      .asFunction<__m256i Function(__m256i, __m256i, int)>();

  __m256i _mm256_slli_si256(
    __m256i arg0,
    int arg1,
  ) {
    return __mm256_slli_si256(
      arg0,
      arg1,
    );
  }

  late final __mm256_slli_si256Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, ffi.Int32)>>(
          '_mm256_slli_si256');
  late final __mm256_slli_si256 =
      __mm256_slli_si256Ptr.asFunction<__m256i Function(__m256i, int)>();

  __m256i _mm256_srli_si256(
    __m256i arg0,
    int arg1,
  ) {
    return __mm256_srli_si256(
      arg0,
      arg1,
    );
  }

  late final __mm256_srli_si256Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, ffi.Int32)>>(
          '_mm256_srli_si256');
  late final __mm256_srli_si256 =
      __mm256_srli_si256Ptr.asFunction<__m256i Function(__m256i, int)>();

  __m256i _mm256_sll_epi16(
    __m256i arg0,
    __m128i arg1,
  ) {
    return __mm256_sll_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm256_sll_epi16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m128i)>>(
          '_mm256_sll_epi16');
  late final __mm256_sll_epi16 =
      __mm256_sll_epi16Ptr.asFunction<__m256i Function(__m256i, __m128i)>();

  __m256i _mm256_sll_epi32(
    __m256i arg0,
    __m128i arg1,
  ) {
    return __mm256_sll_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm256_sll_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m128i)>>(
          '_mm256_sll_epi32');
  late final __mm256_sll_epi32 =
      __mm256_sll_epi32Ptr.asFunction<__m256i Function(__m256i, __m128i)>();

  __m256i _mm256_sll_epi64(
    __m256i arg0,
    __m128i arg1,
  ) {
    return __mm256_sll_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm256_sll_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m128i)>>(
          '_mm256_sll_epi64');
  late final __mm256_sll_epi64 =
      __mm256_sll_epi64Ptr.asFunction<__m256i Function(__m256i, __m128i)>();

  __m256i _mm256_slli_epi16(
    __m256i arg0,
    int arg1,
  ) {
    return __mm256_slli_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm256_slli_epi16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, ffi.Int32)>>(
          '_mm256_slli_epi16');
  late final __mm256_slli_epi16 =
      __mm256_slli_epi16Ptr.asFunction<__m256i Function(__m256i, int)>();

  __m256i _mm256_slli_epi32(
    __m256i arg0,
    int arg1,
  ) {
    return __mm256_slli_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm256_slli_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, ffi.Int32)>>(
          '_mm256_slli_epi32');
  late final __mm256_slli_epi32 =
      __mm256_slli_epi32Ptr.asFunction<__m256i Function(__m256i, int)>();

  __m256i _mm256_slli_epi64(
    __m256i arg0,
    int arg1,
  ) {
    return __mm256_slli_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm256_slli_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, ffi.Int32)>>(
          '_mm256_slli_epi64');
  late final __mm256_slli_epi64 =
      __mm256_slli_epi64Ptr.asFunction<__m256i Function(__m256i, int)>();

  __m256i _mm256_sllv_epi32(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_sllv_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm256_sllv_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_sllv_epi32');
  late final __mm256_sllv_epi32 =
      __mm256_sllv_epi32Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_sllv_epi64(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_sllv_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm256_sllv_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_sllv_epi64');
  late final __mm256_sllv_epi64 =
      __mm256_sllv_epi64Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m128i _mm_sllv_epi32(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_sllv_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm_sllv_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_sllv_epi32');
  late final __mm_sllv_epi32 =
      __mm_sllv_epi32Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_sllv_epi64(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_sllv_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm_sllv_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_sllv_epi64');
  late final __mm_sllv_epi64 =
      __mm_sllv_epi64Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m256i _mm256_sra_epi16(
    __m256i arg0,
    __m128i arg1,
  ) {
    return __mm256_sra_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm256_sra_epi16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m128i)>>(
          '_mm256_sra_epi16');
  late final __mm256_sra_epi16 =
      __mm256_sra_epi16Ptr.asFunction<__m256i Function(__m256i, __m128i)>();

  __m256i _mm256_sra_epi32(
    __m256i arg0,
    __m128i arg1,
  ) {
    return __mm256_sra_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm256_sra_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m128i)>>(
          '_mm256_sra_epi32');
  late final __mm256_sra_epi32 =
      __mm256_sra_epi32Ptr.asFunction<__m256i Function(__m256i, __m128i)>();

  __m256i _mm256_srai_epi16(
    __m256i arg0,
    int arg1,
  ) {
    return __mm256_srai_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm256_srai_epi16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, ffi.Int32)>>(
          '_mm256_srai_epi16');
  late final __mm256_srai_epi16 =
      __mm256_srai_epi16Ptr.asFunction<__m256i Function(__m256i, int)>();

  __m256i _mm256_srai_epi32(
    __m256i arg0,
    int arg1,
  ) {
    return __mm256_srai_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm256_srai_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, ffi.Int32)>>(
          '_mm256_srai_epi32');
  late final __mm256_srai_epi32 =
      __mm256_srai_epi32Ptr.asFunction<__m256i Function(__m256i, int)>();

  __m256i _mm256_srav_epi32(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_srav_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm256_srav_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_srav_epi32');
  late final __mm256_srav_epi32 =
      __mm256_srav_epi32Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m128i _mm_srav_epi32(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_srav_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm_srav_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_srav_epi32');
  late final __mm_srav_epi32 =
      __mm_srav_epi32Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m256i _mm256_srl_epi16(
    __m256i arg0,
    __m128i arg1,
  ) {
    return __mm256_srl_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm256_srl_epi16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m128i)>>(
          '_mm256_srl_epi16');
  late final __mm256_srl_epi16 =
      __mm256_srl_epi16Ptr.asFunction<__m256i Function(__m256i, __m128i)>();

  __m256i _mm256_srl_epi32(
    __m256i arg0,
    __m128i arg1,
  ) {
    return __mm256_srl_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm256_srl_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m128i)>>(
          '_mm256_srl_epi32');
  late final __mm256_srl_epi32 =
      __mm256_srl_epi32Ptr.asFunction<__m256i Function(__m256i, __m128i)>();

  __m256i _mm256_srl_epi64(
    __m256i arg0,
    __m128i arg1,
  ) {
    return __mm256_srl_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm256_srl_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m128i)>>(
          '_mm256_srl_epi64');
  late final __mm256_srl_epi64 =
      __mm256_srl_epi64Ptr.asFunction<__m256i Function(__m256i, __m128i)>();

  __m256i _mm256_srli_epi16(
    __m256i arg0,
    int arg1,
  ) {
    return __mm256_srli_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm256_srli_epi16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, ffi.Int32)>>(
          '_mm256_srli_epi16');
  late final __mm256_srli_epi16 =
      __mm256_srli_epi16Ptr.asFunction<__m256i Function(__m256i, int)>();

  __m256i _mm256_srli_epi32(
    __m256i arg0,
    int arg1,
  ) {
    return __mm256_srli_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm256_srli_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, ffi.Int32)>>(
          '_mm256_srli_epi32');
  late final __mm256_srli_epi32 =
      __mm256_srli_epi32Ptr.asFunction<__m256i Function(__m256i, int)>();

  __m256i _mm256_srli_epi64(
    __m256i arg0,
    int arg1,
  ) {
    return __mm256_srli_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm256_srli_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, ffi.Int32)>>(
          '_mm256_srli_epi64');
  late final __mm256_srli_epi64 =
      __mm256_srli_epi64Ptr.asFunction<__m256i Function(__m256i, int)>();

  __m256i _mm256_srlv_epi32(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_srlv_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm256_srlv_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_srlv_epi32');
  late final __mm256_srlv_epi32 =
      __mm256_srlv_epi32Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_srlv_epi64(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_srlv_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm256_srlv_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_srlv_epi64');
  late final __mm256_srlv_epi64 =
      __mm256_srlv_epi64Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m128i _mm_srlv_epi32(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_srlv_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm_srlv_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_srlv_epi32');
  late final __mm_srlv_epi32 =
      __mm_srlv_epi32Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_srlv_epi64(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_srlv_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm_srlv_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_srlv_epi64');
  late final __mm_srlv_epi64 =
      __mm_srlv_epi64Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_blend_epi32(
    __m128i arg0,
    __m128i arg1,
    int arg2,
  ) {
    return __mm_blend_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_blend_epi32Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__m128i, __m128i, ffi.Int32)>>(
      '_mm_blend_epi32');
  late final __mm_blend_epi32 =
      __mm_blend_epi32Ptr.asFunction<__m128i Function(__m128i, __m128i, int)>();

  __m256i _mm256_blend_epi32(
    __m256i arg0,
    __m256i arg1,
    int arg2,
  ) {
    return __mm256_blend_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_blend_epi32Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__m256i, __m256i, ffi.Int32)>>(
      '_mm256_blend_epi32');
  late final __mm256_blend_epi32 = __mm256_blend_epi32Ptr
      .asFunction<__m256i Function(__m256i, __m256i, int)>();

  __m256i _mm256_alignr_epi8(
    __m256i arg0,
    __m256i arg1,
    int arg2,
  ) {
    return __mm256_alignr_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_alignr_epi8Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__m256i, __m256i, ffi.Int32)>>(
      '_mm256_alignr_epi8');
  late final __mm256_alignr_epi8 = __mm256_alignr_epi8Ptr
      .asFunction<__m256i Function(__m256i, __m256i, int)>();

  __m256i _mm256_blendv_epi8(
    __m256i arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_blendv_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_blendv_epi8Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i, __m256i)>>(
          '_mm256_blendv_epi8');
  late final __mm256_blendv_epi8 = __mm256_blendv_epi8Ptr
      .asFunction<__m256i Function(__m256i, __m256i, __m256i)>();

  __m256i _mm256_blend_epi16(
    __m256i arg0,
    __m256i arg1,
    int arg2,
  ) {
    return __mm256_blend_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_blend_epi16Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__m256i, __m256i, ffi.Int32)>>(
      '_mm256_blend_epi16');
  late final __mm256_blend_epi16 = __mm256_blend_epi16Ptr
      .asFunction<__m256i Function(__m256i, __m256i, int)>();

  __m256i _mm256_packs_epi16(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_packs_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm256_packs_epi16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_packs_epi16');
  late final __mm256_packs_epi16 =
      __mm256_packs_epi16Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_packs_epi32(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_packs_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm256_packs_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_packs_epi32');
  late final __mm256_packs_epi32 =
      __mm256_packs_epi32Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_packus_epi16(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_packus_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm256_packus_epi16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_packus_epi16');
  late final __mm256_packus_epi16 =
      __mm256_packus_epi16Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_packus_epi32(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_packus_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm256_packus_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_packus_epi32');
  late final __mm256_packus_epi32 =
      __mm256_packus_epi32Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_unpackhi_epi8(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_unpackhi_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm256_unpackhi_epi8Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_unpackhi_epi8');
  late final __mm256_unpackhi_epi8 =
      __mm256_unpackhi_epi8Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_unpackhi_epi16(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_unpackhi_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm256_unpackhi_epi16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_unpackhi_epi16');
  late final __mm256_unpackhi_epi16 = __mm256_unpackhi_epi16Ptr
      .asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_unpackhi_epi32(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_unpackhi_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm256_unpackhi_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_unpackhi_epi32');
  late final __mm256_unpackhi_epi32 = __mm256_unpackhi_epi32Ptr
      .asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_unpackhi_epi64(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_unpackhi_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm256_unpackhi_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_unpackhi_epi64');
  late final __mm256_unpackhi_epi64 = __mm256_unpackhi_epi64Ptr
      .asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_unpacklo_epi8(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_unpacklo_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm256_unpacklo_epi8Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_unpacklo_epi8');
  late final __mm256_unpacklo_epi8 =
      __mm256_unpacklo_epi8Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_unpacklo_epi16(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_unpacklo_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm256_unpacklo_epi16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_unpacklo_epi16');
  late final __mm256_unpacklo_epi16 = __mm256_unpacklo_epi16Ptr
      .asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_unpacklo_epi32(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_unpacklo_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm256_unpacklo_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_unpacklo_epi32');
  late final __mm256_unpacklo_epi32 = __mm256_unpacklo_epi32Ptr
      .asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_unpacklo_epi64(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_unpacklo_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm256_unpacklo_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_unpacklo_epi64');
  late final __mm256_unpacklo_epi64 = __mm256_unpacklo_epi64Ptr
      .asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_shuffle_epi8(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_shuffle_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm256_shuffle_epi8Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_shuffle_epi8');
  late final __mm256_shuffle_epi8 =
      __mm256_shuffle_epi8Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_shuffle_epi32(
    __m256i arg0,
    int arg1,
  ) {
    return __mm256_shuffle_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm256_shuffle_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, ffi.Int32)>>(
          '_mm256_shuffle_epi32');
  late final __mm256_shuffle_epi32 =
      __mm256_shuffle_epi32Ptr.asFunction<__m256i Function(__m256i, int)>();

  __m256i _mm256_shufflehi_epi16(
    __m256i arg0,
    int arg1,
  ) {
    return __mm256_shufflehi_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm256_shufflehi_epi16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, ffi.Int32)>>(
          '_mm256_shufflehi_epi16');
  late final __mm256_shufflehi_epi16 =
      __mm256_shufflehi_epi16Ptr.asFunction<__m256i Function(__m256i, int)>();

  __m256i _mm256_shufflelo_epi16(
    __m256i arg0,
    int arg1,
  ) {
    return __mm256_shufflelo_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm256_shufflelo_epi16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, ffi.Int32)>>(
          '_mm256_shufflelo_epi16');
  late final __mm256_shufflelo_epi16 =
      __mm256_shufflelo_epi16Ptr.asFunction<__m256i Function(__m256i, int)>();

  __m128i _mm256_extracti128_si256(
    __m256i arg0,
    int arg1,
  ) {
    return __mm256_extracti128_si256(
      arg0,
      arg1,
    );
  }

  late final __mm256_extracti128_si256Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m256i, ffi.Int32)>>(
          '_mm256_extracti128_si256');
  late final __mm256_extracti128_si256 =
      __mm256_extracti128_si256Ptr.asFunction<__m128i Function(__m256i, int)>();

  __m256i _mm256_inserti128_si256(
    __m256i arg0,
    __m128i arg1,
    int arg2,
  ) {
    return __mm256_inserti128_si256(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_inserti128_si256Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__m256i, __m128i, ffi.Int32)>>(
      '_mm256_inserti128_si256');
  late final __mm256_inserti128_si256 = __mm256_inserti128_si256Ptr
      .asFunction<__m256i Function(__m256i, __m128i, int)>();

  __m128 _mm_broadcastss_ps(
    __m128 arg0,
  ) {
    return __mm_broadcastss_ps(
      arg0,
    );
  }

  late final __mm_broadcastss_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128)>>(
          '_mm_broadcastss_ps');
  late final __mm_broadcastss_ps =
      __mm_broadcastss_psPtr.asFunction<__m128 Function(__m128)>();

  _m128d _mm_broadcastsd_pd(
    _m128d arg0,
  ) {
    return __mm_broadcastsd_pd(
      arg0,
    );
  }

  late final __mm_broadcastsd_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d)>>(
          '_mm_broadcastsd_pd');
  late final __mm_broadcastsd_pd =
      __mm_broadcastsd_pdPtr.asFunction<_m128d Function(_m128d)>();

  __m128i _mm_broadcastb_epi8(
    __m128i arg0,
  ) {
    return __mm_broadcastb_epi8(
      arg0,
    );
  }

  late final __mm_broadcastb_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i)>>(
          '_mm_broadcastb_epi8');
  late final __mm_broadcastb_epi8 =
      __mm_broadcastb_epi8Ptr.asFunction<__m128i Function(__m128i)>();

  __m128i _mm_broadcastw_epi16(
    __m128i arg0,
  ) {
    return __mm_broadcastw_epi16(
      arg0,
    );
  }

  late final __mm_broadcastw_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i)>>(
          '_mm_broadcastw_epi16');
  late final __mm_broadcastw_epi16 =
      __mm_broadcastw_epi16Ptr.asFunction<__m128i Function(__m128i)>();

  __m128i _mm_broadcastd_epi32(
    __m128i arg0,
  ) {
    return __mm_broadcastd_epi32(
      arg0,
    );
  }

  late final __mm_broadcastd_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i)>>(
          '_mm_broadcastd_epi32');
  late final __mm_broadcastd_epi32 =
      __mm_broadcastd_epi32Ptr.asFunction<__m128i Function(__m128i)>();

  __m128i _mm_broadcastq_epi64(
    __m128i arg0,
  ) {
    return __mm_broadcastq_epi64(
      arg0,
    );
  }

  late final __mm_broadcastq_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i)>>(
          '_mm_broadcastq_epi64');
  late final __mm_broadcastq_epi64 =
      __mm_broadcastq_epi64Ptr.asFunction<__m128i Function(__m128i)>();

  __m256 _mm256_broadcastss_ps(
    __m128 arg0,
  ) {
    return __mm256_broadcastss_ps(
      arg0,
    );
  }

  late final __mm256_broadcastss_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m128)>>(
          '_mm256_broadcastss_ps');
  late final __mm256_broadcastss_ps =
      __mm256_broadcastss_psPtr.asFunction<__m256 Function(__m128)>();

  _m256d _mm256_broadcastsd_pd(
    _m128d arg0,
  ) {
    return __mm256_broadcastsd_pd(
      arg0,
    );
  }

  late final __mm256_broadcastsd_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m128d)>>(
          '_mm256_broadcastsd_pd');
  late final __mm256_broadcastsd_pd =
      __mm256_broadcastsd_pdPtr.asFunction<_m256d Function(_m128d)>();

  __m256i _mm256_broadcastb_epi8(
    __m128i arg0,
  ) {
    return __mm256_broadcastb_epi8(
      arg0,
    );
  }

  late final __mm256_broadcastb_epi8Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m128i)>>(
          '_mm256_broadcastb_epi8');
  late final __mm256_broadcastb_epi8 =
      __mm256_broadcastb_epi8Ptr.asFunction<__m256i Function(__m128i)>();

  __m256i _mm256_broadcastw_epi16(
    __m128i arg0,
  ) {
    return __mm256_broadcastw_epi16(
      arg0,
    );
  }

  late final __mm256_broadcastw_epi16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m128i)>>(
          '_mm256_broadcastw_epi16');
  late final __mm256_broadcastw_epi16 =
      __mm256_broadcastw_epi16Ptr.asFunction<__m256i Function(__m128i)>();

  __m256i _mm256_broadcastd_epi32(
    __m128i arg0,
  ) {
    return __mm256_broadcastd_epi32(
      arg0,
    );
  }

  late final __mm256_broadcastd_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m128i)>>(
          '_mm256_broadcastd_epi32');
  late final __mm256_broadcastd_epi32 =
      __mm256_broadcastd_epi32Ptr.asFunction<__m256i Function(__m128i)>();

  __m256i _mm256_broadcastq_epi64(
    __m128i arg0,
  ) {
    return __mm256_broadcastq_epi64(
      arg0,
    );
  }

  late final __mm256_broadcastq_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m128i)>>(
          '_mm256_broadcastq_epi64');
  late final __mm256_broadcastq_epi64 =
      __mm256_broadcastq_epi64Ptr.asFunction<__m256i Function(__m128i)>();

  __m256i _mm256_broadcastsi128_si256(
    __m128i arg0,
  ) {
    return __mm256_broadcastsi128_si256(
      arg0,
    );
  }

  late final __mm256_broadcastsi128_si256Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m128i)>>(
          '_mm256_broadcastsi128_si256');
  late final __mm256_broadcastsi128_si256 =
      __mm256_broadcastsi128_si256Ptr.asFunction<__m256i Function(__m128i)>();

  __m256i _mm256_cvtepi8_epi16(
    __m128i arg0,
  ) {
    return __mm256_cvtepi8_epi16(
      arg0,
    );
  }

  late final __mm256_cvtepi8_epi16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m128i)>>(
          '_mm256_cvtepi8_epi16');
  late final __mm256_cvtepi8_epi16 =
      __mm256_cvtepi8_epi16Ptr.asFunction<__m256i Function(__m128i)>();

  __m256i _mm256_cvtepi8_epi32(
    __m128i arg0,
  ) {
    return __mm256_cvtepi8_epi32(
      arg0,
    );
  }

  late final __mm256_cvtepi8_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m128i)>>(
          '_mm256_cvtepi8_epi32');
  late final __mm256_cvtepi8_epi32 =
      __mm256_cvtepi8_epi32Ptr.asFunction<__m256i Function(__m128i)>();

  __m256i _mm256_cvtepi8_epi64(
    __m128i arg0,
  ) {
    return __mm256_cvtepi8_epi64(
      arg0,
    );
  }

  late final __mm256_cvtepi8_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m128i)>>(
          '_mm256_cvtepi8_epi64');
  late final __mm256_cvtepi8_epi64 =
      __mm256_cvtepi8_epi64Ptr.asFunction<__m256i Function(__m128i)>();

  __m256i _mm256_cvtepi16_epi32(
    __m128i arg0,
  ) {
    return __mm256_cvtepi16_epi32(
      arg0,
    );
  }

  late final __mm256_cvtepi16_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m128i)>>(
          '_mm256_cvtepi16_epi32');
  late final __mm256_cvtepi16_epi32 =
      __mm256_cvtepi16_epi32Ptr.asFunction<__m256i Function(__m128i)>();

  __m256i _mm256_cvtepi16_epi64(
    __m128i arg0,
  ) {
    return __mm256_cvtepi16_epi64(
      arg0,
    );
  }

  late final __mm256_cvtepi16_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m128i)>>(
          '_mm256_cvtepi16_epi64');
  late final __mm256_cvtepi16_epi64 =
      __mm256_cvtepi16_epi64Ptr.asFunction<__m256i Function(__m128i)>();

  __m256i _mm256_cvtepi32_epi64(
    __m128i arg0,
  ) {
    return __mm256_cvtepi32_epi64(
      arg0,
    );
  }

  late final __mm256_cvtepi32_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m128i)>>(
          '_mm256_cvtepi32_epi64');
  late final __mm256_cvtepi32_epi64 =
      __mm256_cvtepi32_epi64Ptr.asFunction<__m256i Function(__m128i)>();

  __m256i _mm256_cvtepu8_epi16(
    __m128i arg0,
  ) {
    return __mm256_cvtepu8_epi16(
      arg0,
    );
  }

  late final __mm256_cvtepu8_epi16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m128i)>>(
          '_mm256_cvtepu8_epi16');
  late final __mm256_cvtepu8_epi16 =
      __mm256_cvtepu8_epi16Ptr.asFunction<__m256i Function(__m128i)>();

  __m256i _mm256_cvtepu8_epi32(
    __m128i arg0,
  ) {
    return __mm256_cvtepu8_epi32(
      arg0,
    );
  }

  late final __mm256_cvtepu8_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m128i)>>(
          '_mm256_cvtepu8_epi32');
  late final __mm256_cvtepu8_epi32 =
      __mm256_cvtepu8_epi32Ptr.asFunction<__m256i Function(__m128i)>();

  __m256i _mm256_cvtepu8_epi64(
    __m128i arg0,
  ) {
    return __mm256_cvtepu8_epi64(
      arg0,
    );
  }

  late final __mm256_cvtepu8_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m128i)>>(
          '_mm256_cvtepu8_epi64');
  late final __mm256_cvtepu8_epi64 =
      __mm256_cvtepu8_epi64Ptr.asFunction<__m256i Function(__m128i)>();

  __m256i _mm256_cvtepu16_epi32(
    __m128i arg0,
  ) {
    return __mm256_cvtepu16_epi32(
      arg0,
    );
  }

  late final __mm256_cvtepu16_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m128i)>>(
          '_mm256_cvtepu16_epi32');
  late final __mm256_cvtepu16_epi32 =
      __mm256_cvtepu16_epi32Ptr.asFunction<__m256i Function(__m128i)>();

  __m256i _mm256_cvtepu16_epi64(
    __m128i arg0,
  ) {
    return __mm256_cvtepu16_epi64(
      arg0,
    );
  }

  late final __mm256_cvtepu16_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m128i)>>(
          '_mm256_cvtepu16_epi64');
  late final __mm256_cvtepu16_epi64 =
      __mm256_cvtepu16_epi64Ptr.asFunction<__m256i Function(__m128i)>();

  __m256i _mm256_cvtepu32_epi64(
    __m128i arg0,
  ) {
    return __mm256_cvtepu32_epi64(
      arg0,
    );
  }

  late final __mm256_cvtepu32_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m128i)>>(
          '_mm256_cvtepu32_epi64');
  late final __mm256_cvtepu32_epi64 =
      __mm256_cvtepu32_epi64Ptr.asFunction<__m256i Function(__m128i)>();

  int _mm256_movemask_epi8(
    __m256i arg0,
  ) {
    return __mm256_movemask_epi8(
      arg0,
    );
  }

  late final __mm256_movemask_epi8Ptr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(__m256i)>>(
          '_mm256_movemask_epi8');
  late final __mm256_movemask_epi8 =
      __mm256_movemask_epi8Ptr.asFunction<int Function(__m256i)>();

  __m128i _mm_maskload_epi32(
    ffi.Pointer<ffi.Int32> arg0,
    __m128i arg1,
  ) {
    return __mm_maskload_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm_maskload_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              ffi.Pointer<ffi.Int32>, __m128i)>>('_mm_maskload_epi32');
  late final __mm_maskload_epi32 = __mm_maskload_epi32Ptr
      .asFunction<__m128i Function(ffi.Pointer<ffi.Int32>, __m128i)>();

  __m128i _mm_maskload_epi64(
    ffi.Pointer<ffi.Int64> arg0,
    __m128i arg1,
  ) {
    return __mm_maskload_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm_maskload_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              ffi.Pointer<ffi.Int64>, __m128i)>>('_mm_maskload_epi64');
  late final __mm_maskload_epi64 = __mm_maskload_epi64Ptr
      .asFunction<__m128i Function(ffi.Pointer<ffi.Int64>, __m128i)>();

  void _mm_maskstore_epi32(
    ffi.Pointer<ffi.Int32> arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskstore_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskstore_epi32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Int32>, __m128i,
              __m128i)>>('_mm_maskstore_epi32');
  late final __mm_maskstore_epi32 = __mm_maskstore_epi32Ptr
      .asFunction<void Function(ffi.Pointer<ffi.Int32>, __m128i, __m128i)>();

  void _mm_maskstore_epi64(
    ffi.Pointer<ffi.Int64> arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskstore_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskstore_epi64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Int64>, __m128i,
              __m128i)>>('_mm_maskstore_epi64');
  late final __mm_maskstore_epi64 = __mm_maskstore_epi64Ptr
      .asFunction<void Function(ffi.Pointer<ffi.Int64>, __m128i, __m128i)>();

  __m256i _mm256_maskload_epi32(
    ffi.Pointer<ffi.Int32> arg0,
    __m256i arg1,
  ) {
    return __mm256_maskload_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskload_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              ffi.Pointer<ffi.Int32>, __m256i)>>('_mm256_maskload_epi32');
  late final __mm256_maskload_epi32 = __mm256_maskload_epi32Ptr
      .asFunction<__m256i Function(ffi.Pointer<ffi.Int32>, __m256i)>();

  __m256i _mm256_maskload_epi64(
    ffi.Pointer<ffi.Int64> arg0,
    __m256i arg1,
  ) {
    return __mm256_maskload_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskload_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              ffi.Pointer<ffi.Int64>, __m256i)>>('_mm256_maskload_epi64');
  late final __mm256_maskload_epi64 = __mm256_maskload_epi64Ptr
      .asFunction<__m256i Function(ffi.Pointer<ffi.Int64>, __m256i)>();

  void _mm256_maskstore_epi32(
    ffi.Pointer<ffi.Int32> arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskstore_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskstore_epi32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Int32>, __m256i,
              __m256i)>>('_mm256_maskstore_epi32');
  late final __mm256_maskstore_epi32 = __mm256_maskstore_epi32Ptr
      .asFunction<void Function(ffi.Pointer<ffi.Int32>, __m256i, __m256i)>();

  void _mm256_maskstore_epi64(
    ffi.Pointer<ffi.Int64> arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskstore_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskstore_epi64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Int64>, __m256i,
              __m256i)>>('_mm256_maskstore_epi64');
  late final __mm256_maskstore_epi64 = __mm256_maskstore_epi64Ptr
      .asFunction<void Function(ffi.Pointer<ffi.Int64>, __m256i, __m256i)>();

  __m256i _mm256_permutevar8x32_epi32(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_permutevar8x32_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm256_permutevar8x32_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_permutevar8x32_epi32');
  late final __mm256_permutevar8x32_epi32 = __mm256_permutevar8x32_epi32Ptr
      .asFunction<__m256i Function(__m256i, __m256i)>();

  __m256 _mm256_permutevar8x32_ps(
    __m256 arg0,
    __m256i arg1,
  ) {
    return __mm256_permutevar8x32_ps(
      arg0,
      arg1,
    );
  }

  late final __mm256_permutevar8x32_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256, __m256i)>>(
          '_mm256_permutevar8x32_ps');
  late final __mm256_permutevar8x32_ps = __mm256_permutevar8x32_psPtr
      .asFunction<__m256 Function(__m256, __m256i)>();

  __m256i _mm256_permute4x64_epi64(
    __m256i arg0,
    int arg1,
  ) {
    return __mm256_permute4x64_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm256_permute4x64_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, ffi.Int32)>>(
          '_mm256_permute4x64_epi64');
  late final __mm256_permute4x64_epi64 =
      __mm256_permute4x64_epi64Ptr.asFunction<__m256i Function(__m256i, int)>();

  _m256d _mm256_permute4x64_pd(
    _m256d arg0,
    int arg1,
  ) {
    return __mm256_permute4x64_pd(
      arg0,
      arg1,
    );
  }

  late final __mm256_permute4x64_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d, ffi.Int32)>>(
          '_mm256_permute4x64_pd');
  late final __mm256_permute4x64_pd =
      __mm256_permute4x64_pdPtr.asFunction<_m256d Function(_m256d, int)>();

  __m256i _mm256_permute2x128_si256(
    __m256i arg0,
    __m256i arg1,
    int arg2,
  ) {
    return __mm256_permute2x128_si256(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_permute2x128_si256Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__m256i, __m256i, ffi.Int32)>>(
      '_mm256_permute2x128_si256');
  late final __mm256_permute2x128_si256 = __mm256_permute2x128_si256Ptr
      .asFunction<__m256i Function(__m256i, __m256i, int)>();

  __m256i _mm256_stream_load_si256(
    ffi.Pointer<__m256i> arg0,
  ) {
    return __mm256_stream_load_si256(
      arg0,
    );
  }

  late final __mm256_stream_load_si256Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(ffi.Pointer<__m256i>)>>(
          '_mm256_stream_load_si256');
  late final __mm256_stream_load_si256 = __mm256_stream_load_si256Ptr
      .asFunction<__m256i Function(ffi.Pointer<__m256i>)>();

  _m256d _mm256_mask_i32gather_pd(
    _m256d arg0,
    ffi.Pointer<ffi.Double> arg1,
    __m128i arg2,
    _m256d arg3,
    int arg4,
  ) {
    return __mm256_mask_i32gather_pd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm256_mask_i32gather_pdPtr = _lookup<
      ffi.NativeFunction<
          _m256d Function(_m256d, ffi.Pointer<ffi.Double>, __m128i, _m256d,
              ffi.Int32)>>('_mm256_mask_i32gather_pd');
  late final __mm256_mask_i32gather_pd =
      __mm256_mask_i32gather_pdPtr.asFunction<
          _m256d Function(
              _m256d, ffi.Pointer<ffi.Double>, __m128i, _m256d, int)>();

  __m256 _mm256_mask_i32gather_ps(
    __m256 arg0,
    ffi.Pointer<ffi.Float> arg1,
    __m256i arg2,
    __m256 arg3,
    int arg4,
  ) {
    return __mm256_mask_i32gather_ps(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm256_mask_i32gather_psPtr = _lookup<
      ffi.NativeFunction<
          __m256 Function(__m256, ffi.Pointer<ffi.Float>, __m256i, __m256,
              ffi.Int32)>>('_mm256_mask_i32gather_ps');
  late final __mm256_mask_i32gather_ps =
      __mm256_mask_i32gather_psPtr.asFunction<
          __m256 Function(
              __m256, ffi.Pointer<ffi.Float>, __m256i, __m256, int)>();

  _m256d _mm256_mask_i64gather_pd(
    _m256d arg0,
    ffi.Pointer<ffi.Double> arg1,
    __m256i arg2,
    _m256d arg3,
    int arg4,
  ) {
    return __mm256_mask_i64gather_pd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm256_mask_i64gather_pdPtr = _lookup<
      ffi.NativeFunction<
          _m256d Function(_m256d, ffi.Pointer<ffi.Double>, __m256i, _m256d,
              ffi.Int32)>>('_mm256_mask_i64gather_pd');
  late final __mm256_mask_i64gather_pd =
      __mm256_mask_i64gather_pdPtr.asFunction<
          _m256d Function(
              _m256d, ffi.Pointer<ffi.Double>, __m256i, _m256d, int)>();

  __m128 _mm256_mask_i64gather_ps(
    __m128 arg0,
    ffi.Pointer<ffi.Float> arg1,
    __m256i arg2,
    __m128 arg3,
    int arg4,
  ) {
    return __mm256_mask_i64gather_ps(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm256_mask_i64gather_psPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(__m128, ffi.Pointer<ffi.Float>, __m256i, __m128,
              ffi.Int32)>>('_mm256_mask_i64gather_ps');
  late final __mm256_mask_i64gather_ps =
      __mm256_mask_i64gather_psPtr.asFunction<
          __m128 Function(
              __m128, ffi.Pointer<ffi.Float>, __m256i, __m128, int)>();

  _m128d _mm_mask_i32gather_pd(
    _m128d arg0,
    ffi.Pointer<ffi.Double> arg1,
    __m128i arg2,
    _m128d arg3,
    int arg4,
  ) {
    return __mm_mask_i32gather_pd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_i32gather_pdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(_m128d, ffi.Pointer<ffi.Double>, __m128i, _m128d,
              ffi.Int32)>>('_mm_mask_i32gather_pd');
  late final __mm_mask_i32gather_pd = __mm_mask_i32gather_pdPtr.asFunction<
      _m128d Function(_m128d, ffi.Pointer<ffi.Double>, __m128i, _m128d, int)>();

  __m128 _mm_mask_i32gather_ps(
    __m128 arg0,
    ffi.Pointer<ffi.Float> arg1,
    __m128i arg2,
    __m128 arg3,
    int arg4,
  ) {
    return __mm_mask_i32gather_ps(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_i32gather_psPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(__m128, ffi.Pointer<ffi.Float>, __m128i, __m128,
              ffi.Int32)>>('_mm_mask_i32gather_ps');
  late final __mm_mask_i32gather_ps = __mm_mask_i32gather_psPtr.asFunction<
      __m128 Function(__m128, ffi.Pointer<ffi.Float>, __m128i, __m128, int)>();

  _m128d _mm_mask_i64gather_pd(
    _m128d arg0,
    ffi.Pointer<ffi.Double> arg1,
    __m128i arg2,
    _m128d arg3,
    int arg4,
  ) {
    return __mm_mask_i64gather_pd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_i64gather_pdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(_m128d, ffi.Pointer<ffi.Double>, __m128i, _m128d,
              ffi.Int32)>>('_mm_mask_i64gather_pd');
  late final __mm_mask_i64gather_pd = __mm_mask_i64gather_pdPtr.asFunction<
      _m128d Function(_m128d, ffi.Pointer<ffi.Double>, __m128i, _m128d, int)>();

  __m128 _mm_mask_i64gather_ps(
    __m128 arg0,
    ffi.Pointer<ffi.Float> arg1,
    __m128i arg2,
    __m128 arg3,
    int arg4,
  ) {
    return __mm_mask_i64gather_ps(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_i64gather_psPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(__m128, ffi.Pointer<ffi.Float>, __m128i, __m128,
              ffi.Int32)>>('_mm_mask_i64gather_ps');
  late final __mm_mask_i64gather_ps = __mm_mask_i64gather_psPtr.asFunction<
      __m128 Function(__m128, ffi.Pointer<ffi.Float>, __m128i, __m128, int)>();

  __m256i _mm256_mask_i32gather_epi32(
    __m256i arg0,
    ffi.Pointer<ffi.Int32> arg1,
    __m256i arg2,
    __m256i arg3,
    int arg4,
  ) {
    return __mm256_mask_i32gather_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm256_mask_i32gather_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, ffi.Pointer<ffi.Int32>, __m256i, __m256i,
              ffi.Int32)>>('_mm256_mask_i32gather_epi32');
  late final __mm256_mask_i32gather_epi32 =
      __mm256_mask_i32gather_epi32Ptr.asFunction<
          __m256i Function(
              __m256i, ffi.Pointer<ffi.Int32>, __m256i, __m256i, int)>();

  __m256i _mm256_mask_i32gather_epi64(
    __m256i arg0,
    ffi.Pointer<ffi.Int64> arg1,
    __m128i arg2,
    __m256i arg3,
    int arg4,
  ) {
    return __mm256_mask_i32gather_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm256_mask_i32gather_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, ffi.Pointer<ffi.Int64>, __m128i, __m256i,
              ffi.Int32)>>('_mm256_mask_i32gather_epi64');
  late final __mm256_mask_i32gather_epi64 =
      __mm256_mask_i32gather_epi64Ptr.asFunction<
          __m256i Function(
              __m256i, ffi.Pointer<ffi.Int64>, __m128i, __m256i, int)>();

  __m128i _mm256_mask_i64gather_epi32(
    __m128i arg0,
    ffi.Pointer<ffi.Int32> arg1,
    __m256i arg2,
    __m128i arg3,
    int arg4,
  ) {
    return __mm256_mask_i64gather_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm256_mask_i64gather_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(__m128i, ffi.Pointer<ffi.Int32>, __m256i, __m128i,
              ffi.Int32)>>('_mm256_mask_i64gather_epi32');
  late final __mm256_mask_i64gather_epi32 =
      __mm256_mask_i64gather_epi32Ptr.asFunction<
          __m128i Function(
              __m128i, ffi.Pointer<ffi.Int32>, __m256i, __m128i, int)>();

  __m256i _mm256_mask_i64gather_epi64(
    __m256i arg0,
    ffi.Pointer<ffi.Int64> arg1,
    __m256i arg2,
    __m256i arg3,
    int arg4,
  ) {
    return __mm256_mask_i64gather_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm256_mask_i64gather_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, ffi.Pointer<ffi.Int64>, __m256i, __m256i,
              ffi.Int32)>>('_mm256_mask_i64gather_epi64');
  late final __mm256_mask_i64gather_epi64 =
      __mm256_mask_i64gather_epi64Ptr.asFunction<
          __m256i Function(
              __m256i, ffi.Pointer<ffi.Int64>, __m256i, __m256i, int)>();

  __m128i _mm_mask_i32gather_epi32(
    __m128i arg0,
    ffi.Pointer<ffi.Int32> arg1,
    __m128i arg2,
    __m128i arg3,
    int arg4,
  ) {
    return __mm_mask_i32gather_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_i32gather_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(__m128i, ffi.Pointer<ffi.Int32>, __m128i, __m128i,
              ffi.Int32)>>('_mm_mask_i32gather_epi32');
  late final __mm_mask_i32gather_epi32 =
      __mm_mask_i32gather_epi32Ptr.asFunction<
          __m128i Function(
              __m128i, ffi.Pointer<ffi.Int32>, __m128i, __m128i, int)>();

  __m128i _mm_mask_i32gather_epi64(
    __m128i arg0,
    ffi.Pointer<ffi.Int64> arg1,
    __m128i arg2,
    __m128i arg3,
    int arg4,
  ) {
    return __mm_mask_i32gather_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_i32gather_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(__m128i, ffi.Pointer<ffi.Int64>, __m128i, __m128i,
              ffi.Int32)>>('_mm_mask_i32gather_epi64');
  late final __mm_mask_i32gather_epi64 =
      __mm_mask_i32gather_epi64Ptr.asFunction<
          __m128i Function(
              __m128i, ffi.Pointer<ffi.Int64>, __m128i, __m128i, int)>();

  __m128i _mm_mask_i64gather_epi32(
    __m128i arg0,
    ffi.Pointer<ffi.Int32> arg1,
    __m128i arg2,
    __m128i arg3,
    int arg4,
  ) {
    return __mm_mask_i64gather_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_i64gather_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(__m128i, ffi.Pointer<ffi.Int32>, __m128i, __m128i,
              ffi.Int32)>>('_mm_mask_i64gather_epi32');
  late final __mm_mask_i64gather_epi32 =
      __mm_mask_i64gather_epi32Ptr.asFunction<
          __m128i Function(
              __m128i, ffi.Pointer<ffi.Int32>, __m128i, __m128i, int)>();

  __m128i _mm_mask_i64gather_epi64(
    __m128i arg0,
    ffi.Pointer<ffi.Int64> arg1,
    __m128i arg2,
    __m128i arg3,
    int arg4,
  ) {
    return __mm_mask_i64gather_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_i64gather_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(__m128i, ffi.Pointer<ffi.Int64>, __m128i, __m128i,
              ffi.Int32)>>('_mm_mask_i64gather_epi64');
  late final __mm_mask_i64gather_epi64 =
      __mm_mask_i64gather_epi64Ptr.asFunction<
          __m128i Function(
              __m128i, ffi.Pointer<ffi.Int64>, __m128i, __m128i, int)>();

  _m256d _mm256_i32gather_pd(
    ffi.Pointer<ffi.Double> arg0,
    __m128i arg1,
    int arg2,
  ) {
    return __mm256_i32gather_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_i32gather_pdPtr = _lookup<
      ffi.NativeFunction<
          _m256d Function(ffi.Pointer<ffi.Double>, __m128i,
              ffi.Int32)>>('_mm256_i32gather_pd');
  late final __mm256_i32gather_pd = __mm256_i32gather_pdPtr
      .asFunction<_m256d Function(ffi.Pointer<ffi.Double>, __m128i, int)>();

  __m256 _mm256_i32gather_ps(
    ffi.Pointer<ffi.Float> arg0,
    __m256i arg1,
    int arg2,
  ) {
    return __mm256_i32gather_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_i32gather_psPtr = _lookup<
      ffi.NativeFunction<
          __m256 Function(ffi.Pointer<ffi.Float>, __m256i,
              ffi.Int32)>>('_mm256_i32gather_ps');
  late final __mm256_i32gather_ps = __mm256_i32gather_psPtr
      .asFunction<__m256 Function(ffi.Pointer<ffi.Float>, __m256i, int)>();

  _m256d _mm256_i64gather_pd(
    ffi.Pointer<ffi.Double> arg0,
    __m256i arg1,
    int arg2,
  ) {
    return __mm256_i64gather_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_i64gather_pdPtr = _lookup<
      ffi.NativeFunction<
          _m256d Function(ffi.Pointer<ffi.Double>, __m256i,
              ffi.Int32)>>('_mm256_i64gather_pd');
  late final __mm256_i64gather_pd = __mm256_i64gather_pdPtr
      .asFunction<_m256d Function(ffi.Pointer<ffi.Double>, __m256i, int)>();

  __m128 _mm256_i64gather_ps(
    ffi.Pointer<ffi.Float> arg0,
    __m256i arg1,
    int arg2,
  ) {
    return __mm256_i64gather_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_i64gather_psPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(ffi.Pointer<ffi.Float>, __m256i,
              ffi.Int32)>>('_mm256_i64gather_ps');
  late final __mm256_i64gather_ps = __mm256_i64gather_psPtr
      .asFunction<__m128 Function(ffi.Pointer<ffi.Float>, __m256i, int)>();

  _m128d _mm_i32gather_pd(
    ffi.Pointer<ffi.Double> arg0,
    __m128i arg1,
    int arg2,
  ) {
    return __mm_i32gather_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_i32gather_pdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(ffi.Pointer<ffi.Double>, __m128i,
              ffi.Int32)>>('_mm_i32gather_pd');
  late final __mm_i32gather_pd = __mm_i32gather_pdPtr
      .asFunction<_m128d Function(ffi.Pointer<ffi.Double>, __m128i, int)>();

  __m128 _mm_i32gather_ps(
    ffi.Pointer<ffi.Float> arg0,
    __m128i arg1,
    int arg2,
  ) {
    return __mm_i32gather_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_i32gather_psPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              ffi.Pointer<ffi.Float>, __m128i, ffi.Int32)>>('_mm_i32gather_ps');
  late final __mm_i32gather_ps = __mm_i32gather_psPtr
      .asFunction<__m128 Function(ffi.Pointer<ffi.Float>, __m128i, int)>();

  _m128d _mm_i64gather_pd(
    ffi.Pointer<ffi.Double> arg0,
    __m128i arg1,
    int arg2,
  ) {
    return __mm_i64gather_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_i64gather_pdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(ffi.Pointer<ffi.Double>, __m128i,
              ffi.Int32)>>('_mm_i64gather_pd');
  late final __mm_i64gather_pd = __mm_i64gather_pdPtr
      .asFunction<_m128d Function(ffi.Pointer<ffi.Double>, __m128i, int)>();

  __m128 _mm_i64gather_ps(
    ffi.Pointer<ffi.Float> arg0,
    __m128i arg1,
    int arg2,
  ) {
    return __mm_i64gather_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_i64gather_psPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              ffi.Pointer<ffi.Float>, __m128i, ffi.Int32)>>('_mm_i64gather_ps');
  late final __mm_i64gather_ps = __mm_i64gather_psPtr
      .asFunction<__m128 Function(ffi.Pointer<ffi.Float>, __m128i, int)>();

  __m256i _mm256_i32gather_epi32(
    ffi.Pointer<ffi.Int32> arg0,
    __m256i arg1,
    int arg2,
  ) {
    return __mm256_i32gather_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_i32gather_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(ffi.Pointer<ffi.Int32>, __m256i,
              ffi.Int32)>>('_mm256_i32gather_epi32');
  late final __mm256_i32gather_epi32 = __mm256_i32gather_epi32Ptr
      .asFunction<__m256i Function(ffi.Pointer<ffi.Int32>, __m256i, int)>();

  __m256i _mm256_i32gather_epi64(
    ffi.Pointer<ffi.Int64> arg0,
    __m128i arg1,
    int arg2,
  ) {
    return __mm256_i32gather_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_i32gather_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(ffi.Pointer<ffi.Int64>, __m128i,
              ffi.Int32)>>('_mm256_i32gather_epi64');
  late final __mm256_i32gather_epi64 = __mm256_i32gather_epi64Ptr
      .asFunction<__m256i Function(ffi.Pointer<ffi.Int64>, __m128i, int)>();

  __m128i _mm256_i64gather_epi32(
    ffi.Pointer<ffi.Int32> arg0,
    __m256i arg1,
    int arg2,
  ) {
    return __mm256_i64gather_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_i64gather_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(ffi.Pointer<ffi.Int32>, __m256i,
              ffi.Int32)>>('_mm256_i64gather_epi32');
  late final __mm256_i64gather_epi32 = __mm256_i64gather_epi32Ptr
      .asFunction<__m128i Function(ffi.Pointer<ffi.Int32>, __m256i, int)>();

  __m256i _mm256_i64gather_epi64(
    ffi.Pointer<ffi.Int64> arg0,
    __m256i arg1,
    int arg2,
  ) {
    return __mm256_i64gather_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_i64gather_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(ffi.Pointer<ffi.Int64>, __m256i,
              ffi.Int32)>>('_mm256_i64gather_epi64');
  late final __mm256_i64gather_epi64 = __mm256_i64gather_epi64Ptr
      .asFunction<__m256i Function(ffi.Pointer<ffi.Int64>, __m256i, int)>();

  __m128i _mm_i32gather_epi32(
    ffi.Pointer<ffi.Int32> arg0,
    __m128i arg1,
    int arg2,
  ) {
    return __mm_i32gather_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_i32gather_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(ffi.Pointer<ffi.Int32>, __m128i,
              ffi.Int32)>>('_mm_i32gather_epi32');
  late final __mm_i32gather_epi32 = __mm_i32gather_epi32Ptr
      .asFunction<__m128i Function(ffi.Pointer<ffi.Int32>, __m128i, int)>();

  __m128i _mm_i32gather_epi64(
    ffi.Pointer<ffi.Int64> arg0,
    __m128i arg1,
    int arg2,
  ) {
    return __mm_i32gather_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_i32gather_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(ffi.Pointer<ffi.Int64>, __m128i,
              ffi.Int32)>>('_mm_i32gather_epi64');
  late final __mm_i32gather_epi64 = __mm_i32gather_epi64Ptr
      .asFunction<__m128i Function(ffi.Pointer<ffi.Int64>, __m128i, int)>();

  __m128i _mm_i64gather_epi32(
    ffi.Pointer<ffi.Int32> arg0,
    __m128i arg1,
    int arg2,
  ) {
    return __mm_i64gather_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_i64gather_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(ffi.Pointer<ffi.Int32>, __m128i,
              ffi.Int32)>>('_mm_i64gather_epi32');
  late final __mm_i64gather_epi32 = __mm_i64gather_epi32Ptr
      .asFunction<__m128i Function(ffi.Pointer<ffi.Int32>, __m128i, int)>();

  __m128i _mm_i64gather_epi64(
    ffi.Pointer<ffi.Int64> arg0,
    __m128i arg1,
    int arg2,
  ) {
    return __mm_i64gather_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_i64gather_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(ffi.Pointer<ffi.Int64>, __m128i,
              ffi.Int32)>>('_mm_i64gather_epi64');
  late final __mm_i64gather_epi64 = __mm_i64gather_epi64Ptr
      .asFunction<__m128i Function(ffi.Pointer<ffi.Int64>, __m128i, int)>();

  int _bextr_u32(
    int arg0,
    int arg1,
    int arg2,
  ) {
    return __bextr_u32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __bextr_u32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Uint32 Function(
              ffi.Uint32, ffi.Uint32, ffi.Uint32)>>('_bextr_u32');
  late final __bextr_u32 =
      __bextr_u32Ptr.asFunction<int Function(int, int, int)>();

  int _bextr2_u32(
    int arg0,
    int arg1,
  ) {
    return __bextr2_u32(
      arg0,
      arg1,
    );
  }

  late final __bextr2_u32Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint32 Function(ffi.Uint32, ffi.Uint32)>>(
          '_bextr2_u32');
  late final __bextr2_u32 =
      __bextr2_u32Ptr.asFunction<int Function(int, int)>();

  int _blsi_u32(
    int arg0,
  ) {
    return __blsi_u32(
      arg0,
    );
  }

  late final __blsi_u32Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint32 Function(ffi.Uint32)>>('_blsi_u32');
  late final __blsi_u32 = __blsi_u32Ptr.asFunction<int Function(int)>();

  int _blsmsk_u32(
    int arg0,
  ) {
    return __blsmsk_u32(
      arg0,
    );
  }

  late final __blsmsk_u32Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint32 Function(ffi.Uint32)>>(
          '_blsmsk_u32');
  late final __blsmsk_u32 = __blsmsk_u32Ptr.asFunction<int Function(int)>();

  int _blsr_u32(
    int arg0,
  ) {
    return __blsr_u32(
      arg0,
    );
  }

  late final __blsr_u32Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint32 Function(ffi.Uint32)>>('_blsr_u32');
  late final __blsr_u32 = __blsr_u32Ptr.asFunction<int Function(int)>();

  int _bzhi_u32(
    int arg0,
    int arg1,
  ) {
    return __bzhi_u32(
      arg0,
      arg1,
    );
  }

  late final __bzhi_u32Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint32 Function(ffi.Uint32, ffi.Uint32)>>(
          '_bzhi_u32');
  late final __bzhi_u32 = __bzhi_u32Ptr.asFunction<int Function(int, int)>();

  int _mulx_u32(
    int arg0,
    int arg1,
    ffi.Pointer<ffi.Uint32> arg2,
  ) {
    return __mulx_u32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mulx_u32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Uint32 Function(
              ffi.Uint32, ffi.Uint32, ffi.Pointer<ffi.Uint32>)>>('_mulx_u32');
  late final __mulx_u32 = __mulx_u32Ptr
      .asFunction<int Function(int, int, ffi.Pointer<ffi.Uint32>)>();

  int _pdep_u32(
    int arg0,
    int arg1,
  ) {
    return __pdep_u32(
      arg0,
      arg1,
    );
  }

  late final __pdep_u32Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint32 Function(ffi.Uint32, ffi.Uint32)>>(
          '_pdep_u32');
  late final __pdep_u32 = __pdep_u32Ptr.asFunction<int Function(int, int)>();

  int _pext_u32(
    int arg0,
    int arg1,
  ) {
    return __pext_u32(
      arg0,
      arg1,
    );
  }

  late final __pext_u32Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint32 Function(ffi.Uint32, ffi.Uint32)>>(
          '_pext_u32');
  late final __pext_u32 = __pext_u32Ptr.asFunction<int Function(int, int)>();

  int _rorx_u32(
    int arg0,
    int arg1,
  ) {
    return __rorx_u32(
      arg0,
      arg1,
    );
  }

  late final __rorx_u32Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint32 Function(ffi.Uint32, ffi.Uint32)>>(
          '_rorx_u32');
  late final __rorx_u32 = __rorx_u32Ptr.asFunction<int Function(int, int)>();

  int _sarx_i32(
    int arg0,
    int arg1,
  ) {
    return __sarx_i32(
      arg0,
      arg1,
    );
  }

  late final __sarx_i32Ptr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Int32, ffi.Uint32)>>(
          '_sarx_i32');
  late final __sarx_i32 = __sarx_i32Ptr.asFunction<int Function(int, int)>();

  int _shlx_u32(
    int arg0,
    int arg1,
  ) {
    return __shlx_u32(
      arg0,
      arg1,
    );
  }

  late final __shlx_u32Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint32 Function(ffi.Uint32, ffi.Uint32)>>(
          '_shlx_u32');
  late final __shlx_u32 = __shlx_u32Ptr.asFunction<int Function(int, int)>();

  int _shrx_u32(
    int arg0,
    int arg1,
  ) {
    return __shrx_u32(
      arg0,
      arg1,
    );
  }

  late final __shrx_u32Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint32 Function(ffi.Uint32, ffi.Uint32)>>(
          '_shrx_u32');
  late final __shrx_u32 = __shrx_u32Ptr.asFunction<int Function(int, int)>();

  int _bextr_u64(
    int arg0,
    int arg1,
    int arg2,
  ) {
    return __bextr_u64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __bextr_u64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Uint64 Function(
              ffi.Uint64, ffi.Uint32, ffi.Uint32)>>('_bextr_u64');
  late final __bextr_u64 =
      __bextr_u64Ptr.asFunction<int Function(int, int, int)>();

  int _bextr2_u64(
    int arg0,
    int arg1,
  ) {
    return __bextr2_u64(
      arg0,
      arg1,
    );
  }

  late final __bextr2_u64Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function(ffi.Uint64, ffi.Uint64)>>(
          '_bextr2_u64');
  late final __bextr2_u64 =
      __bextr2_u64Ptr.asFunction<int Function(int, int)>();

  int _blsi_u64(
    int arg0,
  ) {
    return __blsi_u64(
      arg0,
    );
  }

  late final __blsi_u64Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function(ffi.Uint64)>>('_blsi_u64');
  late final __blsi_u64 = __blsi_u64Ptr.asFunction<int Function(int)>();

  int _blsmsk_u64(
    int arg0,
  ) {
    return __blsmsk_u64(
      arg0,
    );
  }

  late final __blsmsk_u64Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function(ffi.Uint64)>>(
          '_blsmsk_u64');
  late final __blsmsk_u64 = __blsmsk_u64Ptr.asFunction<int Function(int)>();

  int _blsr_u64(
    int arg0,
  ) {
    return __blsr_u64(
      arg0,
    );
  }

  late final __blsr_u64Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function(ffi.Uint64)>>('_blsr_u64');
  late final __blsr_u64 = __blsr_u64Ptr.asFunction<int Function(int)>();

  int _bzhi_u64(
    int arg0,
    int arg1,
  ) {
    return __bzhi_u64(
      arg0,
      arg1,
    );
  }

  late final __bzhi_u64Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function(ffi.Uint64, ffi.Uint32)>>(
          '_bzhi_u64');
  late final __bzhi_u64 = __bzhi_u64Ptr.asFunction<int Function(int, int)>();

  int _mulx_u64(
    int arg0,
    int arg1,
    ffi.Pointer<ffi.Uint64> arg2,
  ) {
    return __mulx_u64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mulx_u64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Uint64 Function(
              ffi.Uint64, ffi.Uint64, ffi.Pointer<ffi.Uint64>)>>('_mulx_u64');
  late final __mulx_u64 = __mulx_u64Ptr
      .asFunction<int Function(int, int, ffi.Pointer<ffi.Uint64>)>();

  int _pdep_u64(
    int arg0,
    int arg1,
  ) {
    return __pdep_u64(
      arg0,
      arg1,
    );
  }

  late final __pdep_u64Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function(ffi.Uint64, ffi.Uint64)>>(
          '_pdep_u64');
  late final __pdep_u64 = __pdep_u64Ptr.asFunction<int Function(int, int)>();

  int _pext_u64(
    int arg0,
    int arg1,
  ) {
    return __pext_u64(
      arg0,
      arg1,
    );
  }

  late final __pext_u64Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function(ffi.Uint64, ffi.Uint64)>>(
          '_pext_u64');
  late final __pext_u64 = __pext_u64Ptr.asFunction<int Function(int, int)>();

  int _rorx_u64(
    int arg0,
    int arg1,
  ) {
    return __rorx_u64(
      arg0,
      arg1,
    );
  }

  late final __rorx_u64Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function(ffi.Uint64, ffi.Uint32)>>(
          '_rorx_u64');
  late final __rorx_u64 = __rorx_u64Ptr.asFunction<int Function(int, int)>();

  int _sarx_i64(
    int arg0,
    int arg1,
  ) {
    return __sarx_i64(
      arg0,
      arg1,
    );
  }

  late final __sarx_i64Ptr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(ffi.Int64, ffi.Uint32)>>(
          '_sarx_i64');
  late final __sarx_i64 = __sarx_i64Ptr.asFunction<int Function(int, int)>();

  int _shlx_u64(
    int arg0,
    int arg1,
  ) {
    return __shlx_u64(
      arg0,
      arg1,
    );
  }

  late final __shlx_u64Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function(ffi.Uint64, ffi.Uint32)>>(
          '_shlx_u64');
  late final __shlx_u64 = __shlx_u64Ptr.asFunction<int Function(int, int)>();

  int _shrx_u64(
    int arg0,
    int arg1,
  ) {
    return __shrx_u64(
      arg0,
      arg1,
    );
  }

  late final __shrx_u64Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function(ffi.Uint64, ffi.Uint32)>>(
          '_shrx_u64');
  late final __shrx_u64 = __shrx_u64Ptr.asFunction<int Function(int, int)>();

  int _lzcnt_u32(
    int arg0,
  ) {
    return __lzcnt_u32(
      arg0,
    );
  }

  late final __lzcnt_u32Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint32 Function(ffi.Uint32)>>(
          '_lzcnt_u32');
  late final __lzcnt_u32 = __lzcnt_u32Ptr.asFunction<int Function(int)>();

  int _lzcnt_u64(
    int arg0,
  ) {
    return __lzcnt_u64(
      arg0,
    );
  }

  late final __lzcnt_u64Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function(ffi.Uint64)>>(
          '_lzcnt_u64');
  late final __lzcnt_u64 = __lzcnt_u64Ptr.asFunction<int Function(int)>();

  int _tzcnt_u32(
    int arg0,
  ) {
    return __tzcnt_u32(
      arg0,
    );
  }

  late final __tzcnt_u32Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint32 Function(ffi.Uint32)>>(
          '_tzcnt_u32');
  late final __tzcnt_u32 = __tzcnt_u32Ptr.asFunction<int Function(int)>();

  int _tzcnt_u64(
    int arg0,
  ) {
    return __tzcnt_u64(
      arg0,
    );
  }

  late final __tzcnt_u64Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function(ffi.Uint64)>>(
          '_tzcnt_u64');
  late final __tzcnt_u64 = __tzcnt_u64Ptr.asFunction<int Function(int)>();

  void _invpcid(
    int arg0,
    ffi.Pointer<ffi.Void> arg1,
  ) {
    return __invpcid(
      arg0,
      arg1,
    );
  }

  late final __invpcidPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Uint32, ffi.Pointer<ffi.Void>)>>('_invpcid');
  late final __invpcid =
      __invpcidPtr.asFunction<void Function(int, ffi.Pointer<ffi.Void>)>();

  void _Store_HLERelease(
    ffi.Pointer<ffi.Int64> arg0,
    int arg1,
  ) {
    return __Store_HLERelease(
      arg0,
      arg1,
    );
  }

  late final __Store_HLEReleasePtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<ffi.Int64>, ffi.Int64)>>('_Store_HLERelease');
  late final __Store_HLERelease = __Store_HLEReleasePtr
      .asFunction<void Function(ffi.Pointer<ffi.Int64>, int)>();

  void _StorePointer_HLERelease(
    ffi.Pointer<ffi.Pointer<ffi.Void>> arg0,
    ffi.Pointer<ffi.Void> arg1,
  ) {
    return __StorePointer_HLERelease(
      arg0,
      arg1,
    );
  }

  late final __StorePointer_HLEReleasePtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Pointer<ffi.Void>>,
              ffi.Pointer<ffi.Void>)>>('_StorePointer_HLERelease');
  late final __StorePointer_HLERelease =
      __StorePointer_HLEReleasePtr.asFunction<
          void Function(
              ffi.Pointer<ffi.Pointer<ffi.Void>>, ffi.Pointer<ffi.Void>)>();

  int _InterlockedExchange_HLEAcquire(
    ffi.Pointer<ffi.Int64> arg0,
    int arg1,
  ) {
    return __InterlockedExchange_HLEAcquire(
      arg0,
      arg1,
    );
  }

  late final __InterlockedExchange_HLEAcquirePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int64 Function(ffi.Pointer<ffi.Int64>,
              ffi.Int64)>>('_InterlockedExchange_HLEAcquire');
  late final __InterlockedExchange_HLEAcquire =
      __InterlockedExchange_HLEAcquirePtr
          .asFunction<int Function(ffi.Pointer<ffi.Int64>, int)>();

  int _InterlockedExchange_HLERelease(
    ffi.Pointer<ffi.Int64> arg0,
    int arg1,
  ) {
    return __InterlockedExchange_HLERelease(
      arg0,
      arg1,
    );
  }

  late final __InterlockedExchange_HLEReleasePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int64 Function(ffi.Pointer<ffi.Int64>,
              ffi.Int64)>>('_InterlockedExchange_HLERelease');
  late final __InterlockedExchange_HLERelease =
      __InterlockedExchange_HLEReleasePtr
          .asFunction<int Function(ffi.Pointer<ffi.Int64>, int)>();

  ffi.Pointer<ffi.Void> _InterlockedExchangePointer_HLEAcquire(
    ffi.Pointer<ffi.Pointer<ffi.Void>> arg0,
    ffi.Pointer<ffi.Void> arg1,
  ) {
    return __InterlockedExchangePointer_HLEAcquire(
      arg0,
      arg1,
    );
  }

  late final __InterlockedExchangePointer_HLEAcquirePtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<ffi.Void> Function(
                  ffi.Pointer<ffi.Pointer<ffi.Void>>, ffi.Pointer<ffi.Void>)>>(
      '_InterlockedExchangePointer_HLEAcquire');
  late final __InterlockedExchangePointer_HLEAcquire =
      __InterlockedExchangePointer_HLEAcquirePtr.asFunction<
          ffi.Pointer<ffi.Void> Function(
              ffi.Pointer<ffi.Pointer<ffi.Void>>, ffi.Pointer<ffi.Void>)>();

  ffi.Pointer<ffi.Void> _InterlockedExchangePointer_HLERelease(
    ffi.Pointer<ffi.Pointer<ffi.Void>> arg0,
    ffi.Pointer<ffi.Void> arg1,
  ) {
    return __InterlockedExchangePointer_HLERelease(
      arg0,
      arg1,
    );
  }

  late final __InterlockedExchangePointer_HLEReleasePtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<ffi.Void> Function(
                  ffi.Pointer<ffi.Pointer<ffi.Void>>, ffi.Pointer<ffi.Void>)>>(
      '_InterlockedExchangePointer_HLERelease');
  late final __InterlockedExchangePointer_HLERelease =
      __InterlockedExchangePointer_HLEReleasePtr.asFunction<
          ffi.Pointer<ffi.Void> Function(
              ffi.Pointer<ffi.Pointer<ffi.Void>>, ffi.Pointer<ffi.Void>)>();

  int _InterlockedCompareExchange_HLEAcquire(
    ffi.Pointer<ffi.Int64> arg0,
    int arg1,
    int arg2,
  ) {
    return __InterlockedCompareExchange_HLEAcquire(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __InterlockedCompareExchange_HLEAcquirePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int64 Function(ffi.Pointer<ffi.Int64>, ffi.Int64,
              ffi.Int64)>>('_InterlockedCompareExchange_HLEAcquire');
  late final __InterlockedCompareExchange_HLEAcquire =
      __InterlockedCompareExchange_HLEAcquirePtr
          .asFunction<int Function(ffi.Pointer<ffi.Int64>, int, int)>();

  int _InterlockedCompareExchange_HLERelease(
    ffi.Pointer<ffi.Int64> arg0,
    int arg1,
    int arg2,
  ) {
    return __InterlockedCompareExchange_HLERelease(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __InterlockedCompareExchange_HLEReleasePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int64 Function(ffi.Pointer<ffi.Int64>, ffi.Int64,
              ffi.Int64)>>('_InterlockedCompareExchange_HLERelease');
  late final __InterlockedCompareExchange_HLERelease =
      __InterlockedCompareExchange_HLEReleasePtr
          .asFunction<int Function(ffi.Pointer<ffi.Int64>, int, int)>();

  int _InterlockedCompareExchange64_HLEAcquire(
    ffi.Pointer<ffi.Int64> arg0,
    int arg1,
    int arg2,
  ) {
    return __InterlockedCompareExchange64_HLEAcquire(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __InterlockedCompareExchange64_HLEAcquirePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int64 Function(ffi.Pointer<ffi.Int64>, ffi.Int64,
              ffi.Int64)>>('_InterlockedCompareExchange64_HLEAcquire');
  late final __InterlockedCompareExchange64_HLEAcquire =
      __InterlockedCompareExchange64_HLEAcquirePtr
          .asFunction<int Function(ffi.Pointer<ffi.Int64>, int, int)>();

  int _InterlockedCompareExchange64_HLERelease(
    ffi.Pointer<ffi.Int64> arg0,
    int arg1,
    int arg2,
  ) {
    return __InterlockedCompareExchange64_HLERelease(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __InterlockedCompareExchange64_HLEReleasePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int64 Function(ffi.Pointer<ffi.Int64>, ffi.Int64,
              ffi.Int64)>>('_InterlockedCompareExchange64_HLERelease');
  late final __InterlockedCompareExchange64_HLERelease =
      __InterlockedCompareExchange64_HLEReleasePtr
          .asFunction<int Function(ffi.Pointer<ffi.Int64>, int, int)>();

  ffi.Pointer<ffi.Void> _InterlockedCompareExchangePointer_HLEAcquire(
    ffi.Pointer<ffi.Pointer<ffi.Void>> arg0,
    ffi.Pointer<ffi.Void> arg1,
    ffi.Pointer<ffi.Void> arg2,
  ) {
    return __InterlockedCompareExchangePointer_HLEAcquire(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __InterlockedCompareExchangePointer_HLEAcquirePtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<ffi.Void> Function(ffi.Pointer<ffi.Pointer<ffi.Void>>,
                  ffi.Pointer<ffi.Void>, ffi.Pointer<ffi.Void>)>>(
      '_InterlockedCompareExchangePointer_HLEAcquire');
  late final __InterlockedCompareExchangePointer_HLEAcquire =
      __InterlockedCompareExchangePointer_HLEAcquirePtr.asFunction<
          ffi.Pointer<ffi.Void> Function(ffi.Pointer<ffi.Pointer<ffi.Void>>,
              ffi.Pointer<ffi.Void>, ffi.Pointer<ffi.Void>)>();

  ffi.Pointer<ffi.Void> _InterlockedCompareExchangePointer_HLERelease(
    ffi.Pointer<ffi.Pointer<ffi.Void>> arg0,
    ffi.Pointer<ffi.Void> arg1,
    ffi.Pointer<ffi.Void> arg2,
  ) {
    return __InterlockedCompareExchangePointer_HLERelease(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __InterlockedCompareExchangePointer_HLEReleasePtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<ffi.Void> Function(ffi.Pointer<ffi.Pointer<ffi.Void>>,
                  ffi.Pointer<ffi.Void>, ffi.Pointer<ffi.Void>)>>(
      '_InterlockedCompareExchangePointer_HLERelease');
  late final __InterlockedCompareExchangePointer_HLERelease =
      __InterlockedCompareExchangePointer_HLEReleasePtr.asFunction<
          ffi.Pointer<ffi.Void> Function(ffi.Pointer<ffi.Pointer<ffi.Void>>,
              ffi.Pointer<ffi.Void>, ffi.Pointer<ffi.Void>)>();

  int _InterlockedExchangeAdd_HLEAcquire(
    ffi.Pointer<ffi.Int64> arg0,
    int arg1,
  ) {
    return __InterlockedExchangeAdd_HLEAcquire(
      arg0,
      arg1,
    );
  }

  late final __InterlockedExchangeAdd_HLEAcquirePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int64 Function(ffi.Pointer<ffi.Int64>,
              ffi.Int64)>>('_InterlockedExchangeAdd_HLEAcquire');
  late final __InterlockedExchangeAdd_HLEAcquire =
      __InterlockedExchangeAdd_HLEAcquirePtr
          .asFunction<int Function(ffi.Pointer<ffi.Int64>, int)>();

  int _InterlockedExchangeAdd_HLERelease(
    ffi.Pointer<ffi.Int64> arg0,
    int arg1,
  ) {
    return __InterlockedExchangeAdd_HLERelease(
      arg0,
      arg1,
    );
  }

  late final __InterlockedExchangeAdd_HLEReleasePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int64 Function(ffi.Pointer<ffi.Int64>,
              ffi.Int64)>>('_InterlockedExchangeAdd_HLERelease');
  late final __InterlockedExchangeAdd_HLERelease =
      __InterlockedExchangeAdd_HLEReleasePtr
          .asFunction<int Function(ffi.Pointer<ffi.Int64>, int)>();

  int _InterlockedAnd_HLEAcquire(
    ffi.Pointer<ffi.Int64> arg0,
    int arg1,
  ) {
    return __InterlockedAnd_HLEAcquire(
      arg0,
      arg1,
    );
  }

  late final __InterlockedAnd_HLEAcquirePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int64 Function(ffi.Pointer<ffi.Int64>,
              ffi.Int64)>>('_InterlockedAnd_HLEAcquire');
  late final __InterlockedAnd_HLEAcquire = __InterlockedAnd_HLEAcquirePtr
      .asFunction<int Function(ffi.Pointer<ffi.Int64>, int)>();

  int _InterlockedAnd_HLERelease(
    ffi.Pointer<ffi.Int64> arg0,
    int arg1,
  ) {
    return __InterlockedAnd_HLERelease(
      arg0,
      arg1,
    );
  }

  late final __InterlockedAnd_HLEReleasePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int64 Function(ffi.Pointer<ffi.Int64>,
              ffi.Int64)>>('_InterlockedAnd_HLERelease');
  late final __InterlockedAnd_HLERelease = __InterlockedAnd_HLEReleasePtr
      .asFunction<int Function(ffi.Pointer<ffi.Int64>, int)>();

  int _InterlockedOr_HLEAcquire(
    ffi.Pointer<ffi.Int64> arg0,
    int arg1,
  ) {
    return __InterlockedOr_HLEAcquire(
      arg0,
      arg1,
    );
  }

  late final __InterlockedOr_HLEAcquirePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int64 Function(
              ffi.Pointer<ffi.Int64>, ffi.Int64)>>('_InterlockedOr_HLEAcquire');
  late final __InterlockedOr_HLEAcquire = __InterlockedOr_HLEAcquirePtr
      .asFunction<int Function(ffi.Pointer<ffi.Int64>, int)>();

  int _InterlockedOr_HLERelease(
    ffi.Pointer<ffi.Int64> arg0,
    int arg1,
  ) {
    return __InterlockedOr_HLERelease(
      arg0,
      arg1,
    );
  }

  late final __InterlockedOr_HLEReleasePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int64 Function(
              ffi.Pointer<ffi.Int64>, ffi.Int64)>>('_InterlockedOr_HLERelease');
  late final __InterlockedOr_HLERelease = __InterlockedOr_HLEReleasePtr
      .asFunction<int Function(ffi.Pointer<ffi.Int64>, int)>();

  int _InterlockedXor_HLEAcquire(
    ffi.Pointer<ffi.Int64> arg0,
    int arg1,
  ) {
    return __InterlockedXor_HLEAcquire(
      arg0,
      arg1,
    );
  }

  late final __InterlockedXor_HLEAcquirePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int64 Function(ffi.Pointer<ffi.Int64>,
              ffi.Int64)>>('_InterlockedXor_HLEAcquire');
  late final __InterlockedXor_HLEAcquire = __InterlockedXor_HLEAcquirePtr
      .asFunction<int Function(ffi.Pointer<ffi.Int64>, int)>();

  int _InterlockedXor_HLERelease(
    ffi.Pointer<ffi.Int64> arg0,
    int arg1,
  ) {
    return __InterlockedXor_HLERelease(
      arg0,
      arg1,
    );
  }

  late final __InterlockedXor_HLEReleasePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int64 Function(ffi.Pointer<ffi.Int64>,
              ffi.Int64)>>('_InterlockedXor_HLERelease');
  late final __InterlockedXor_HLERelease = __InterlockedXor_HLEReleasePtr
      .asFunction<int Function(ffi.Pointer<ffi.Int64>, int)>();

  int _interlockedbittestandset_HLEAcquire(
    ffi.Pointer<ffi.Int64> arg0,
    int arg1,
  ) {
    return __interlockedbittestandset_HLEAcquire(
      arg0,
      arg1,
    );
  }

  late final __interlockedbittestandset_HLEAcquirePtr = _lookup<
      ffi.NativeFunction<
          ffi.Uint8 Function(ffi.Pointer<ffi.Int64>,
              ffi.Int64)>>('_interlockedbittestandset_HLEAcquire');
  late final __interlockedbittestandset_HLEAcquire =
      __interlockedbittestandset_HLEAcquirePtr
          .asFunction<int Function(ffi.Pointer<ffi.Int64>, int)>();

  int _interlockedbittestandset_HLERelease(
    ffi.Pointer<ffi.Int64> arg0,
    int arg1,
  ) {
    return __interlockedbittestandset_HLERelease(
      arg0,
      arg1,
    );
  }

  late final __interlockedbittestandset_HLEReleasePtr = _lookup<
      ffi.NativeFunction<
          ffi.Uint8 Function(ffi.Pointer<ffi.Int64>,
              ffi.Int64)>>('_interlockedbittestandset_HLERelease');
  late final __interlockedbittestandset_HLERelease =
      __interlockedbittestandset_HLEReleasePtr
          .asFunction<int Function(ffi.Pointer<ffi.Int64>, int)>();

  int _interlockedbittestandreset_HLEAcquire(
    ffi.Pointer<ffi.Int64> arg0,
    int arg1,
  ) {
    return __interlockedbittestandreset_HLEAcquire(
      arg0,
      arg1,
    );
  }

  late final __interlockedbittestandreset_HLEAcquirePtr = _lookup<
      ffi.NativeFunction<
          ffi.Uint8 Function(ffi.Pointer<ffi.Int64>,
              ffi.Int64)>>('_interlockedbittestandreset_HLEAcquire');
  late final __interlockedbittestandreset_HLEAcquire =
      __interlockedbittestandreset_HLEAcquirePtr
          .asFunction<int Function(ffi.Pointer<ffi.Int64>, int)>();

  int _interlockedbittestandreset_HLERelease(
    ffi.Pointer<ffi.Int64> arg0,
    int arg1,
  ) {
    return __interlockedbittestandreset_HLERelease(
      arg0,
      arg1,
    );
  }

  late final __interlockedbittestandreset_HLEReleasePtr = _lookup<
      ffi.NativeFunction<
          ffi.Uint8 Function(ffi.Pointer<ffi.Int64>,
              ffi.Int64)>>('_interlockedbittestandreset_HLERelease');
  late final __interlockedbittestandreset_HLERelease =
      __interlockedbittestandreset_HLEReleasePtr
          .asFunction<int Function(ffi.Pointer<ffi.Int64>, int)>();

  void _Store64_HLERelease(
    ffi.Pointer<ffi.Int64> arg0,
    int arg1,
  ) {
    return __Store64_HLERelease(
      arg0,
      arg1,
    );
  }

  late final __Store64_HLEReleasePtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<ffi.Int64>, ffi.Int64)>>('_Store64_HLERelease');
  late final __Store64_HLERelease = __Store64_HLEReleasePtr
      .asFunction<void Function(ffi.Pointer<ffi.Int64>, int)>();

  int _InterlockedExchange64_HLEAcquire(
    ffi.Pointer<ffi.Int64> arg0,
    int arg1,
  ) {
    return __InterlockedExchange64_HLEAcquire(
      arg0,
      arg1,
    );
  }

  late final __InterlockedExchange64_HLEAcquirePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int64 Function(ffi.Pointer<ffi.Int64>,
              ffi.Int64)>>('_InterlockedExchange64_HLEAcquire');
  late final __InterlockedExchange64_HLEAcquire =
      __InterlockedExchange64_HLEAcquirePtr
          .asFunction<int Function(ffi.Pointer<ffi.Int64>, int)>();

  int _InterlockedExchange64_HLERelease(
    ffi.Pointer<ffi.Int64> arg0,
    int arg1,
  ) {
    return __InterlockedExchange64_HLERelease(
      arg0,
      arg1,
    );
  }

  late final __InterlockedExchange64_HLEReleasePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int64 Function(ffi.Pointer<ffi.Int64>,
              ffi.Int64)>>('_InterlockedExchange64_HLERelease');
  late final __InterlockedExchange64_HLERelease =
      __InterlockedExchange64_HLEReleasePtr
          .asFunction<int Function(ffi.Pointer<ffi.Int64>, int)>();

  int _InterlockedExchangeAdd64_HLEAcquire(
    ffi.Pointer<ffi.Int64> arg0,
    int arg1,
  ) {
    return __InterlockedExchangeAdd64_HLEAcquire(
      arg0,
      arg1,
    );
  }

  late final __InterlockedExchangeAdd64_HLEAcquirePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int64 Function(ffi.Pointer<ffi.Int64>,
              ffi.Int64)>>('_InterlockedExchangeAdd64_HLEAcquire');
  late final __InterlockedExchangeAdd64_HLEAcquire =
      __InterlockedExchangeAdd64_HLEAcquirePtr
          .asFunction<int Function(ffi.Pointer<ffi.Int64>, int)>();

  int _InterlockedExchangeAdd64_HLERelease(
    ffi.Pointer<ffi.Int64> arg0,
    int arg1,
  ) {
    return __InterlockedExchangeAdd64_HLERelease(
      arg0,
      arg1,
    );
  }

  late final __InterlockedExchangeAdd64_HLEReleasePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int64 Function(ffi.Pointer<ffi.Int64>,
              ffi.Int64)>>('_InterlockedExchangeAdd64_HLERelease');
  late final __InterlockedExchangeAdd64_HLERelease =
      __InterlockedExchangeAdd64_HLEReleasePtr
          .asFunction<int Function(ffi.Pointer<ffi.Int64>, int)>();

  int _InterlockedAnd64_HLEAcquire(
    ffi.Pointer<ffi.Int64> arg0,
    int arg1,
  ) {
    return __InterlockedAnd64_HLEAcquire(
      arg0,
      arg1,
    );
  }

  late final __InterlockedAnd64_HLEAcquirePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int64 Function(ffi.Pointer<ffi.Int64>,
              ffi.Int64)>>('_InterlockedAnd64_HLEAcquire');
  late final __InterlockedAnd64_HLEAcquire = __InterlockedAnd64_HLEAcquirePtr
      .asFunction<int Function(ffi.Pointer<ffi.Int64>, int)>();

  int _InterlockedAnd64_HLERelease(
    ffi.Pointer<ffi.Int64> arg0,
    int arg1,
  ) {
    return __InterlockedAnd64_HLERelease(
      arg0,
      arg1,
    );
  }

  late final __InterlockedAnd64_HLEReleasePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int64 Function(ffi.Pointer<ffi.Int64>,
              ffi.Int64)>>('_InterlockedAnd64_HLERelease');
  late final __InterlockedAnd64_HLERelease = __InterlockedAnd64_HLEReleasePtr
      .asFunction<int Function(ffi.Pointer<ffi.Int64>, int)>();

  int _InterlockedOr64_HLEAcquire(
    ffi.Pointer<ffi.Int64> arg0,
    int arg1,
  ) {
    return __InterlockedOr64_HLEAcquire(
      arg0,
      arg1,
    );
  }

  late final __InterlockedOr64_HLEAcquirePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int64 Function(ffi.Pointer<ffi.Int64>,
              ffi.Int64)>>('_InterlockedOr64_HLEAcquire');
  late final __InterlockedOr64_HLEAcquire = __InterlockedOr64_HLEAcquirePtr
      .asFunction<int Function(ffi.Pointer<ffi.Int64>, int)>();

  int _InterlockedOr64_HLERelease(
    ffi.Pointer<ffi.Int64> arg0,
    int arg1,
  ) {
    return __InterlockedOr64_HLERelease(
      arg0,
      arg1,
    );
  }

  late final __InterlockedOr64_HLEReleasePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int64 Function(ffi.Pointer<ffi.Int64>,
              ffi.Int64)>>('_InterlockedOr64_HLERelease');
  late final __InterlockedOr64_HLERelease = __InterlockedOr64_HLEReleasePtr
      .asFunction<int Function(ffi.Pointer<ffi.Int64>, int)>();

  int _InterlockedXor64_HLEAcquire(
    ffi.Pointer<ffi.Int64> arg0,
    int arg1,
  ) {
    return __InterlockedXor64_HLEAcquire(
      arg0,
      arg1,
    );
  }

  late final __InterlockedXor64_HLEAcquirePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int64 Function(ffi.Pointer<ffi.Int64>,
              ffi.Int64)>>('_InterlockedXor64_HLEAcquire');
  late final __InterlockedXor64_HLEAcquire = __InterlockedXor64_HLEAcquirePtr
      .asFunction<int Function(ffi.Pointer<ffi.Int64>, int)>();

  int _InterlockedXor64_HLERelease(
    ffi.Pointer<ffi.Int64> arg0,
    int arg1,
  ) {
    return __InterlockedXor64_HLERelease(
      arg0,
      arg1,
    );
  }

  late final __InterlockedXor64_HLEReleasePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int64 Function(ffi.Pointer<ffi.Int64>,
              ffi.Int64)>>('_InterlockedXor64_HLERelease');
  late final __InterlockedXor64_HLERelease = __InterlockedXor64_HLEReleasePtr
      .asFunction<int Function(ffi.Pointer<ffi.Int64>, int)>();

  int _interlockedbittestandset64_HLEAcquire(
    ffi.Pointer<ffi.Int64> arg0,
    int arg1,
  ) {
    return __interlockedbittestandset64_HLEAcquire(
      arg0,
      arg1,
    );
  }

  late final __interlockedbittestandset64_HLEAcquirePtr = _lookup<
      ffi.NativeFunction<
          ffi.Uint8 Function(ffi.Pointer<ffi.Int64>,
              ffi.Int64)>>('_interlockedbittestandset64_HLEAcquire');
  late final __interlockedbittestandset64_HLEAcquire =
      __interlockedbittestandset64_HLEAcquirePtr
          .asFunction<int Function(ffi.Pointer<ffi.Int64>, int)>();

  int _interlockedbittestandset64_HLERelease(
    ffi.Pointer<ffi.Int64> arg0,
    int arg1,
  ) {
    return __interlockedbittestandset64_HLERelease(
      arg0,
      arg1,
    );
  }

  late final __interlockedbittestandset64_HLEReleasePtr = _lookup<
      ffi.NativeFunction<
          ffi.Uint8 Function(ffi.Pointer<ffi.Int64>,
              ffi.Int64)>>('_interlockedbittestandset64_HLERelease');
  late final __interlockedbittestandset64_HLERelease =
      __interlockedbittestandset64_HLEReleasePtr
          .asFunction<int Function(ffi.Pointer<ffi.Int64>, int)>();

  int _interlockedbittestandreset64_HLEAcquire(
    ffi.Pointer<ffi.Int64> arg0,
    int arg1,
  ) {
    return __interlockedbittestandreset64_HLEAcquire(
      arg0,
      arg1,
    );
  }

  late final __interlockedbittestandreset64_HLEAcquirePtr = _lookup<
      ffi.NativeFunction<
          ffi.Uint8 Function(ffi.Pointer<ffi.Int64>,
              ffi.Int64)>>('_interlockedbittestandreset64_HLEAcquire');
  late final __interlockedbittestandreset64_HLEAcquire =
      __interlockedbittestandreset64_HLEAcquirePtr
          .asFunction<int Function(ffi.Pointer<ffi.Int64>, int)>();

  int _interlockedbittestandreset64_HLERelease(
    ffi.Pointer<ffi.Int64> arg0,
    int arg1,
  ) {
    return __interlockedbittestandreset64_HLERelease(
      arg0,
      arg1,
    );
  }

  late final __interlockedbittestandreset64_HLEReleasePtr = _lookup<
      ffi.NativeFunction<
          ffi.Uint8 Function(ffi.Pointer<ffi.Int64>,
              ffi.Int64)>>('_interlockedbittestandreset64_HLERelease');
  late final __interlockedbittestandreset64_HLERelease =
      __interlockedbittestandreset64_HLEReleasePtr
          .asFunction<int Function(ffi.Pointer<ffi.Int64>, int)>();

  int _xbegin() {
    return __xbegin();
  }

  late final __xbeginPtr =
      _lookup<ffi.NativeFunction<ffi.Uint32 Function()>>('_xbegin');
  late final __xbegin = __xbeginPtr.asFunction<int Function()>();

  void _xend() {
    return __xend();
  }

  late final __xendPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('_xend');
  late final __xend = __xendPtr.asFunction<void Function()>();

  void _xabort(
    int arg0,
  ) {
    return __xabort(
      arg0,
    );
  }

  late final __xabortPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Uint32)>>('_xabort');
  late final __xabort = __xabortPtr.asFunction<void Function(int)>();

  int _xtest() {
    return __xtest();
  }

  late final __xtestPtr =
      _lookup<ffi.NativeFunction<ffi.Uint8 Function()>>('_xtest');
  late final __xtest = __xtestPtr.asFunction<int Function()>();

  int _rdseed16_step(
    ffi.Pointer<ffi.Uint16> arg0,
  ) {
    return __rdseed16_step(
      arg0,
    );
  }

  late final __rdseed16_stepPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<ffi.Uint16>)>>(
          '_rdseed16_step');
  late final __rdseed16_step =
      __rdseed16_stepPtr.asFunction<int Function(ffi.Pointer<ffi.Uint16>)>();

  int _rdseed32_step(
    ffi.Pointer<ffi.Uint32> arg0,
  ) {
    return __rdseed32_step(
      arg0,
    );
  }

  late final __rdseed32_stepPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<ffi.Uint32>)>>(
          '_rdseed32_step');
  late final __rdseed32_step =
      __rdseed32_stepPtr.asFunction<int Function(ffi.Pointer<ffi.Uint32>)>();

  int _rdseed64_step(
    ffi.Pointer<ffi.Uint64> arg0,
  ) {
    return __rdseed64_step(
      arg0,
    );
  }

  late final __rdseed64_stepPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<ffi.Uint64>)>>(
          '_rdseed64_step');
  late final __rdseed64_step =
      __rdseed64_stepPtr.asFunction<int Function(ffi.Pointer<ffi.Uint64>)>();

  int _addcarryx_u32(
    int arg0,
    int arg1,
    int arg2,
    ffi.Pointer<ffi.Uint32> arg3,
  ) {
    return __addcarryx_u32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __addcarryx_u32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Uint8 Function(ffi.Uint8, ffi.Uint32, ffi.Uint32,
              ffi.Pointer<ffi.Uint32>)>>('_addcarryx_u32');
  late final __addcarryx_u32 = __addcarryx_u32Ptr
      .asFunction<int Function(int, int, int, ffi.Pointer<ffi.Uint32>)>();

  int _addcarryx_u64(
    int arg0,
    int arg1,
    int arg2,
    ffi.Pointer<ffi.Uint64> arg3,
  ) {
    return __addcarryx_u64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __addcarryx_u64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Uint8 Function(ffi.Uint8, ffi.Uint64, ffi.Uint64,
              ffi.Pointer<ffi.Uint64>)>>('_addcarryx_u64');
  late final __addcarryx_u64 = __addcarryx_u64Ptr
      .asFunction<int Function(int, int, int, ffi.Pointer<ffi.Uint64>)>();

  int _load_be_u16(
    ffi.Pointer<ffi.Void> arg0,
  ) {
    return __load_be_u16(
      arg0,
    );
  }

  late final __load_be_u16Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint16 Function(ffi.Pointer<ffi.Void>)>>(
          '_load_be_u16');
  late final __load_be_u16 =
      __load_be_u16Ptr.asFunction<int Function(ffi.Pointer<ffi.Void>)>();

  int _load_be_u32(
    ffi.Pointer<ffi.Void> arg0,
  ) {
    return __load_be_u32(
      arg0,
    );
  }

  late final __load_be_u32Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint32 Function(ffi.Pointer<ffi.Void>)>>(
          '_load_be_u32');
  late final __load_be_u32 =
      __load_be_u32Ptr.asFunction<int Function(ffi.Pointer<ffi.Void>)>();

  int _load_be_u64(
    ffi.Pointer<ffi.Void> arg0,
  ) {
    return __load_be_u64(
      arg0,
    );
  }

  late final __load_be_u64Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function(ffi.Pointer<ffi.Void>)>>(
          '_load_be_u64');
  late final __load_be_u64 =
      __load_be_u64Ptr.asFunction<int Function(ffi.Pointer<ffi.Void>)>();

  void _store_be_u16(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
  ) {
    return __store_be_u16(
      arg0,
      arg1,
    );
  }

  late final __store_be_u16Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<ffi.Void>, ffi.Uint16)>>('_store_be_u16');
  late final __store_be_u16 =
      __store_be_u16Ptr.asFunction<void Function(ffi.Pointer<ffi.Void>, int)>();

  void _store_be_u32(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
  ) {
    return __store_be_u32(
      arg0,
      arg1,
    );
  }

  late final __store_be_u32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<ffi.Void>, ffi.Uint32)>>('_store_be_u32');
  late final __store_be_u32 =
      __store_be_u32Ptr.asFunction<void Function(ffi.Pointer<ffi.Void>, int)>();

  void _store_be_u64(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
  ) {
    return __store_be_u64(
      arg0,
      arg1,
    );
  }

  late final __store_be_u64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<ffi.Void>, ffi.Uint64)>>('_store_be_u64');
  late final __store_be_u64 =
      __store_be_u64Ptr.asFunction<void Function(ffi.Pointer<ffi.Void>, int)>();

  __m128i _mm_sha1msg1_epu32(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_sha1msg1_epu32(
      arg0,
      arg1,
    );
  }

  late final __mm_sha1msg1_epu32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_sha1msg1_epu32');
  late final __mm_sha1msg1_epu32 =
      __mm_sha1msg1_epu32Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_sha1msg2_epu32(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_sha1msg2_epu32(
      arg0,
      arg1,
    );
  }

  late final __mm_sha1msg2_epu32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_sha1msg2_epu32');
  late final __mm_sha1msg2_epu32 =
      __mm_sha1msg2_epu32Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_sha1nexte_epu32(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_sha1nexte_epu32(
      arg0,
      arg1,
    );
  }

  late final __mm_sha1nexte_epu32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_sha1nexte_epu32');
  late final __mm_sha1nexte_epu32 =
      __mm_sha1nexte_epu32Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_sha1rnds4_epu32(
    __m128i arg0,
    __m128i arg1,
    int arg2,
  ) {
    return __mm_sha1rnds4_epu32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_sha1rnds4_epu32Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__m128i, __m128i, ffi.Int32)>>(
      '_mm_sha1rnds4_epu32');
  late final __mm_sha1rnds4_epu32 = __mm_sha1rnds4_epu32Ptr
      .asFunction<__m128i Function(__m128i, __m128i, int)>();

  __m128i _mm_sha256msg1_epu32(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_sha256msg1_epu32(
      arg0,
      arg1,
    );
  }

  late final __mm_sha256msg1_epu32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_sha256msg1_epu32');
  late final __mm_sha256msg1_epu32 =
      __mm_sha256msg1_epu32Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_sha256msg2_epu32(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_sha256msg2_epu32(
      arg0,
      arg1,
    );
  }

  late final __mm_sha256msg2_epu32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_sha256msg2_epu32');
  late final __mm_sha256msg2_epu32 =
      __mm_sha256msg2_epu32Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_sha256rnds2_epu32(
    __m128i arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_sha256rnds2_epu32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_sha256rnds2_epu32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i, __m128i)>>(
          '_mm_sha256rnds2_epu32');
  late final __mm_sha256rnds2_epu32 = __mm_sha256rnds2_epu32Ptr
      .asFunction<__m128i Function(__m128i, __m128i, __m128i)>();

  ffi.Pointer<ffi.Void> _bnd_set_ptr_bounds(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
  ) {
    return __bnd_set_ptr_bounds(
      arg0,
      arg1,
    );
  }

  late final __bnd_set_ptr_boundsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Void> Function(
              ffi.Pointer<ffi.Void>, size_t)>>('_bnd_set_ptr_bounds');
  late final __bnd_set_ptr_bounds = __bnd_set_ptr_boundsPtr
      .asFunction<ffi.Pointer<ffi.Void> Function(ffi.Pointer<ffi.Void>, int)>();

  ffi.Pointer<ffi.Void> _bnd_narrow_ptr_bounds(
    ffi.Pointer<ffi.Void> arg0,
    ffi.Pointer<ffi.Void> arg1,
    int arg2,
  ) {
    return __bnd_narrow_ptr_bounds(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __bnd_narrow_ptr_boundsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Void> Function(ffi.Pointer<ffi.Void>,
              ffi.Pointer<ffi.Void>, size_t)>>('_bnd_narrow_ptr_bounds');
  late final __bnd_narrow_ptr_bounds = __bnd_narrow_ptr_boundsPtr.asFunction<
      ffi.Pointer<ffi.Void> Function(
          ffi.Pointer<ffi.Void>, ffi.Pointer<ffi.Void>, int)>();

  ffi.Pointer<ffi.Void> _bnd_copy_ptr_bounds(
    ffi.Pointer<ffi.Void> arg0,
    ffi.Pointer<ffi.Void> arg1,
  ) {
    return __bnd_copy_ptr_bounds(
      arg0,
      arg1,
    );
  }

  late final __bnd_copy_ptr_boundsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Void> Function(ffi.Pointer<ffi.Void>,
              ffi.Pointer<ffi.Void>)>>('_bnd_copy_ptr_bounds');
  late final __bnd_copy_ptr_bounds = __bnd_copy_ptr_boundsPtr.asFunction<
      ffi.Pointer<ffi.Void> Function(
          ffi.Pointer<ffi.Void>, ffi.Pointer<ffi.Void>)>();

  ffi.Pointer<ffi.Void> _bnd_init_ptr_bounds(
    ffi.Pointer<ffi.Void> arg0,
  ) {
    return __bnd_init_ptr_bounds(
      arg0,
    );
  }

  late final __bnd_init_ptr_boundsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Void> Function(
              ffi.Pointer<ffi.Void>)>>('_bnd_init_ptr_bounds');
  late final __bnd_init_ptr_bounds = __bnd_init_ptr_boundsPtr
      .asFunction<ffi.Pointer<ffi.Void> Function(ffi.Pointer<ffi.Void>)>();

  void _bnd_store_ptr_bounds(
    ffi.Pointer<ffi.Pointer<ffi.Void>> arg0,
    ffi.Pointer<ffi.Void> arg1,
  ) {
    return __bnd_store_ptr_bounds(
      arg0,
      arg1,
    );
  }

  late final __bnd_store_ptr_boundsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Pointer<ffi.Void>>,
              ffi.Pointer<ffi.Void>)>>('_bnd_store_ptr_bounds');
  late final __bnd_store_ptr_bounds = __bnd_store_ptr_boundsPtr.asFunction<
      void Function(
          ffi.Pointer<ffi.Pointer<ffi.Void>>, ffi.Pointer<ffi.Void>)>();

  void _bnd_chk_ptr_lbounds(
    ffi.Pointer<ffi.Void> arg0,
  ) {
    return __bnd_chk_ptr_lbounds(
      arg0,
    );
  }

  late final __bnd_chk_ptr_lboundsPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ffi.Void>)>>(
          '_bnd_chk_ptr_lbounds');
  late final __bnd_chk_ptr_lbounds = __bnd_chk_ptr_lboundsPtr
      .asFunction<void Function(ffi.Pointer<ffi.Void>)>();

  void _bnd_chk_ptr_ubounds(
    ffi.Pointer<ffi.Void> arg0,
  ) {
    return __bnd_chk_ptr_ubounds(
      arg0,
    );
  }

  late final __bnd_chk_ptr_uboundsPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ffi.Void>)>>(
          '_bnd_chk_ptr_ubounds');
  late final __bnd_chk_ptr_ubounds = __bnd_chk_ptr_uboundsPtr
      .asFunction<void Function(ffi.Pointer<ffi.Void>)>();

  void _bnd_chk_ptr_bounds(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
  ) {
    return __bnd_chk_ptr_bounds(
      arg0,
      arg1,
    );
  }

  late final __bnd_chk_ptr_boundsPtr = _lookup<
          ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ffi.Void>, size_t)>>(
      '_bnd_chk_ptr_bounds');
  late final __bnd_chk_ptr_bounds = __bnd_chk_ptr_boundsPtr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, int)>();

  ffi.Pointer<ffi.Void> _bnd_load_ptr_bounds(
    ffi.Pointer<ffi.Pointer<ffi.Void>> arg0,
    ffi.Pointer<ffi.Void> arg1,
  ) {
    return __bnd_load_ptr_bounds(
      arg0,
      arg1,
    );
  }

  late final __bnd_load_ptr_boundsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Void> Function(ffi.Pointer<ffi.Pointer<ffi.Void>>,
              ffi.Pointer<ffi.Void>)>>('_bnd_load_ptr_bounds');
  late final __bnd_load_ptr_bounds = __bnd_load_ptr_boundsPtr.asFunction<
      ffi.Pointer<ffi.Void> Function(
          ffi.Pointer<ffi.Pointer<ffi.Void>>, ffi.Pointer<ffi.Void>)>();

  ffi.Pointer<ffi.Void> _bnd_get_ptr_lbound(
    ffi.Pointer<ffi.Void> arg0,
  ) {
    return __bnd_get_ptr_lbound(
      arg0,
    );
  }

  late final __bnd_get_ptr_lboundPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Void> Function(
              ffi.Pointer<ffi.Void>)>>('_bnd_get_ptr_lbound');
  late final __bnd_get_ptr_lbound = __bnd_get_ptr_lboundPtr
      .asFunction<ffi.Pointer<ffi.Void> Function(ffi.Pointer<ffi.Void>)>();

  ffi.Pointer<ffi.Void> _bnd_get_ptr_ubound(
    ffi.Pointer<ffi.Void> arg0,
  ) {
    return __bnd_get_ptr_ubound(
      arg0,
    );
  }

  late final __bnd_get_ptr_uboundPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Void> Function(
              ffi.Pointer<ffi.Void>)>>('_bnd_get_ptr_ubound');
  late final __bnd_get_ptr_ubound = __bnd_get_ptr_uboundPtr
      .asFunction<ffi.Pointer<ffi.Void> Function(ffi.Pointer<ffi.Void>)>();

  __m256i _mm256_insert_epi8(
    __m256i arg0,
    int arg1,
    int arg2,
  ) {
    return __mm256_insert_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_insert_epi8Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__m256i, ffi.Int32, ffi.Int32)>>(
      '_mm256_insert_epi8');
  late final __mm256_insert_epi8 =
      __mm256_insert_epi8Ptr.asFunction<__m256i Function(__m256i, int, int)>();

  __m256i _mm256_insert_epi16(
    __m256i arg0,
    int arg1,
    int arg2,
  ) {
    return __mm256_insert_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_insert_epi16Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__m256i, ffi.Int32, ffi.Int32)>>(
      '_mm256_insert_epi16');
  late final __mm256_insert_epi16 =
      __mm256_insert_epi16Ptr.asFunction<__m256i Function(__m256i, int, int)>();

  __m256i _mm256_insert_epi32(
    __m256i arg0,
    int arg1,
    int arg2,
  ) {
    return __mm256_insert_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_insert_epi32Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__m256i, ffi.Int32, ffi.Int32)>>(
      '_mm256_insert_epi32');
  late final __mm256_insert_epi32 =
      __mm256_insert_epi32Ptr.asFunction<__m256i Function(__m256i, int, int)>();

  __m256i _mm256_insert_epi64(
    __m256i arg0,
    int arg1,
    int arg2,
  ) {
    return __mm256_insert_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_insert_epi64Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__m256i, ffi.Int64, ffi.Int32)>>(
      '_mm256_insert_epi64');
  late final __mm256_insert_epi64 =
      __mm256_insert_epi64Ptr.asFunction<__m256i Function(__m256i, int, int)>();

  int _mm256_extract_epi8(
    __m256i arg0,
    int arg1,
  ) {
    return __mm256_extract_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm256_extract_epi8Ptr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(__m256i, ffi.Int32)>>(
          '_mm256_extract_epi8');
  late final __mm256_extract_epi8 =
      __mm256_extract_epi8Ptr.asFunction<int Function(__m256i, int)>();

  int _mm256_extract_epi16(
    __m256i arg0,
    int arg1,
  ) {
    return __mm256_extract_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm256_extract_epi16Ptr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(__m256i, ffi.Int32)>>(
          '_mm256_extract_epi16');
  late final __mm256_extract_epi16 =
      __mm256_extract_epi16Ptr.asFunction<int Function(__m256i, int)>();

  int _mm256_extract_epi32(
    __m256i arg0,
    int arg1,
  ) {
    return __mm256_extract_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm256_extract_epi32Ptr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(__m256i, ffi.Int32)>>(
          '_mm256_extract_epi32');
  late final __mm256_extract_epi32 =
      __mm256_extract_epi32Ptr.asFunction<int Function(__m256i, int)>();

  int _mm256_extract_epi64(
    __m256i arg0,
    int arg1,
  ) {
    return __mm256_extract_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm256_extract_epi64Ptr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(__m256i, ffi.Int32)>>(
          '_mm256_extract_epi64');
  late final __mm256_extract_epi64 =
      __mm256_extract_epi64Ptr.asFunction<int Function(__m256i, int)>();

  _m256d _mm256_zextpd128_pd256(
    _m128d arg0,
  ) {
    return __mm256_zextpd128_pd256(
      arg0,
    );
  }

  late final __mm256_zextpd128_pd256Ptr =
      _lookup<ffi.NativeFunction<_m256d Function(_m128d)>>(
          '_mm256_zextpd128_pd256');
  late final __mm256_zextpd128_pd256 =
      __mm256_zextpd128_pd256Ptr.asFunction<_m256d Function(_m128d)>();

  __m256 _mm256_zextps128_ps256(
    __m128 arg0,
  ) {
    return __mm256_zextps128_ps256(
      arg0,
    );
  }

  late final __mm256_zextps128_ps256Ptr =
      _lookup<ffi.NativeFunction<__m256 Function(__m128)>>(
          '_mm256_zextps128_ps256');
  late final __mm256_zextps128_ps256 =
      __mm256_zextps128_ps256Ptr.asFunction<__m256 Function(__m128)>();

  __m256i _mm256_zextsi128_si256(
    __m128i arg0,
  ) {
    return __mm256_zextsi128_si256(
      arg0,
    );
  }

  late final __mm256_zextsi128_si256Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m128i)>>(
          '_mm256_zextsi128_si256');
  late final __mm256_zextsi128_si256 =
      __mm256_zextsi128_si256Ptr.asFunction<__m256i Function(__m128i)>();

  int _rdpid_u32() {
    return __rdpid_u32();
  }

  late final __rdpid_u32Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint32 Function()>>('_rdpid_u32');
  late final __rdpid_u32 = __rdpid_u32Ptr.asFunction<int Function()>();

  void _ptwrite32(
    int arg0,
  ) {
    return __ptwrite32(
      arg0,
    );
  }

  late final __ptwrite32Ptr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Uint32)>>('_ptwrite32');
  late final __ptwrite32 = __ptwrite32Ptr.asFunction<void Function(int)>();

  void _ptwrite64(
    int arg0,
  ) {
    return __ptwrite64(
      arg0,
    );
  }

  late final __ptwrite64Ptr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Uint64)>>('_ptwrite64');
  late final __ptwrite64 = __ptwrite64Ptr.asFunction<void Function(int)>();

  __m128i _mm_dpbusd_avx_epi32(
    __m128i arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_dpbusd_avx_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_dpbusd_avx_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i, __m128i)>>(
          '_mm_dpbusd_avx_epi32');
  late final __mm_dpbusd_avx_epi32 = __mm_dpbusd_avx_epi32Ptr
      .asFunction<__m128i Function(__m128i, __m128i, __m128i)>();

  __m256i _mm256_dpbusd_avx_epi32(
    __m256i arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_dpbusd_avx_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_dpbusd_avx_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i, __m256i)>>(
          '_mm256_dpbusd_avx_epi32');
  late final __mm256_dpbusd_avx_epi32 = __mm256_dpbusd_avx_epi32Ptr
      .asFunction<__m256i Function(__m256i, __m256i, __m256i)>();

  __m128i _mm_dpbusds_avx_epi32(
    __m128i arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_dpbusds_avx_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_dpbusds_avx_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i, __m128i)>>(
          '_mm_dpbusds_avx_epi32');
  late final __mm_dpbusds_avx_epi32 = __mm_dpbusds_avx_epi32Ptr
      .asFunction<__m128i Function(__m128i, __m128i, __m128i)>();

  __m256i _mm256_dpbusds_avx_epi32(
    __m256i arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_dpbusds_avx_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_dpbusds_avx_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i, __m256i)>>(
          '_mm256_dpbusds_avx_epi32');
  late final __mm256_dpbusds_avx_epi32 = __mm256_dpbusds_avx_epi32Ptr
      .asFunction<__m256i Function(__m256i, __m256i, __m256i)>();

  __m128i _mm_dpwssd_avx_epi32(
    __m128i arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_dpwssd_avx_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_dpwssd_avx_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i, __m128i)>>(
          '_mm_dpwssd_avx_epi32');
  late final __mm_dpwssd_avx_epi32 = __mm_dpwssd_avx_epi32Ptr
      .asFunction<__m128i Function(__m128i, __m128i, __m128i)>();

  __m256i _mm256_dpwssd_avx_epi32(
    __m256i arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_dpwssd_avx_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_dpwssd_avx_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i, __m256i)>>(
          '_mm256_dpwssd_avx_epi32');
  late final __mm256_dpwssd_avx_epi32 = __mm256_dpwssd_avx_epi32Ptr
      .asFunction<__m256i Function(__m256i, __m256i, __m256i)>();

  __m128i _mm_dpwssds_avx_epi32(
    __m128i arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_dpwssds_avx_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_dpwssds_avx_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i, __m128i)>>(
          '_mm_dpwssds_avx_epi32');
  late final __mm_dpwssds_avx_epi32 = __mm_dpwssds_avx_epi32Ptr
      .asFunction<__m128i Function(__m128i, __m128i, __m128i)>();

  __m256i _mm256_dpwssds_avx_epi32(
    __m256i arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_dpwssds_avx_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_dpwssds_avx_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i, __m256i)>>(
          '_mm256_dpwssds_avx_epi32');
  late final __mm256_dpwssds_avx_epi32 = __mm256_dpwssds_avx_epi32Ptr
      .asFunction<__m256i Function(__m256i, __m256i, __m256i)>();

  int _pconfig_u32(
    int arg0,
    ffi.Pointer<size_t> __data,
  ) {
    return __pconfig_u32(
      arg0,
      __data,
    );
  }

  late final __pconfig_u32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Uint32 Function(ffi.Int32, ffi.Pointer<size_t>)>>('_pconfig_u32');
  late final __pconfig_u32 =
      __pconfig_u32Ptr.asFunction<int Function(int, ffi.Pointer<size_t>)>();

  void _wbnoinvd() {
    return __wbnoinvd();
  }

  late final __wbnoinvdPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('_wbnoinvd');
  late final __wbnoinvd = __wbnoinvdPtr.asFunction<void Function()>();

  int _encls_u32(
    int arg0,
    ffi.Pointer<size_t> __data,
  ) {
    return __encls_u32(
      arg0,
      __data,
    );
  }

  late final __encls_u32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Uint32 Function(ffi.Int32, ffi.Pointer<size_t>)>>('_encls_u32');
  late final __encls_u32 =
      __encls_u32Ptr.asFunction<int Function(int, ffi.Pointer<size_t>)>();

  int _enclu_u32(
    int arg0,
    ffi.Pointer<size_t> __data,
  ) {
    return __enclu_u32(
      arg0,
      __data,
    );
  }

  late final __enclu_u32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Uint32 Function(ffi.Int32, ffi.Pointer<size_t>)>>('_enclu_u32');
  late final __enclu_u32 =
      __enclu_u32Ptr.asFunction<int Function(int, ffi.Pointer<size_t>)>();

  int _enclv_u32(
    int arg0,
    ffi.Pointer<size_t> __data,
  ) {
    return __enclv_u32(
      arg0,
      __data,
    );
  }

  late final __enclv_u32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Uint32 Function(ffi.Int32, ffi.Pointer<size_t>)>>('_enclv_u32');
  late final __enclv_u32 =
      __enclv_u32Ptr.asFunction<int Function(int, ffi.Pointer<size_t>)>();

  int _udiv128(
    int arg0,
    int arg1,
    int arg2,
    ffi.Pointer<ffi.Uint64> arg3,
  ) {
    return __udiv128(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __udiv128Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Uint64 Function(ffi.Uint64, ffi.Uint64, ffi.Uint64,
              ffi.Pointer<ffi.Uint64>)>>('_udiv128');
  late final __udiv128 = __udiv128Ptr
      .asFunction<int Function(int, int, int, ffi.Pointer<ffi.Uint64>)>();

  int _div128(
    int arg0,
    int arg1,
    int arg2,
    ffi.Pointer<ffi.Int64> arg3,
  ) {
    return __div128(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __div128Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Int64 Function(ffi.Int64, ffi.Int64, ffi.Int64,
              ffi.Pointer<ffi.Int64>)>>('_div128');
  late final __div128 = __div128Ptr
      .asFunction<int Function(int, int, int, ffi.Pointer<ffi.Int64>)>();

  int _udiv64(
    int arg0,
    int arg1,
    ffi.Pointer<ffi.Uint32> arg2,
  ) {
    return __udiv64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __udiv64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Uint32 Function(
              ffi.Uint64, ffi.Uint32, ffi.Pointer<ffi.Uint32>)>>('_udiv64');
  late final __udiv64 =
      __udiv64Ptr.asFunction<int Function(int, int, ffi.Pointer<ffi.Uint32>)>();

  int _div64(
    int arg0,
    int arg1,
    ffi.Pointer<ffi.Int32> arg2,
  ) {
    return __div64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __div64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Int64, ffi.Int32, ffi.Pointer<ffi.Int32>)>>('_div64');
  late final __div64 =
      __div64Ptr.asFunction<int Function(int, int, ffi.Pointer<ffi.Int32>)>();

  int _mm_aesdec128kl_u8(
    ffi.Pointer<__m128i> arg0,
    __m128i arg1,
    ffi.Pointer<ffi.Void> arg2,
  ) {
    return __mm_aesdec128kl_u8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_aesdec128kl_u8Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Uint8 Function(ffi.Pointer<__m128i>, __m128i,
              ffi.Pointer<ffi.Void>)>>('_mm_aesdec128kl_u8');
  late final __mm_aesdec128kl_u8 = __mm_aesdec128kl_u8Ptr.asFunction<
      int Function(ffi.Pointer<__m128i>, __m128i, ffi.Pointer<ffi.Void>)>();

  int _mm_aesdec256kl_u8(
    ffi.Pointer<__m128i> arg0,
    __m128i arg1,
    ffi.Pointer<ffi.Void> arg2,
  ) {
    return __mm_aesdec256kl_u8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_aesdec256kl_u8Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Uint8 Function(ffi.Pointer<__m128i>, __m128i,
              ffi.Pointer<ffi.Void>)>>('_mm_aesdec256kl_u8');
  late final __mm_aesdec256kl_u8 = __mm_aesdec256kl_u8Ptr.asFunction<
      int Function(ffi.Pointer<__m128i>, __m128i, ffi.Pointer<ffi.Void>)>();

  int _mm_aesdecwide128kl_u8(
    ffi.Pointer<__m128i> arg0,
    ffi.Pointer<__m128i> arg1,
    ffi.Pointer<ffi.Void> arg2,
  ) {
    return __mm_aesdecwide128kl_u8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_aesdecwide128kl_u8Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Uint8 Function(ffi.Pointer<__m128i>, ffi.Pointer<__m128i>,
              ffi.Pointer<ffi.Void>)>>('_mm_aesdecwide128kl_u8');
  late final __mm_aesdecwide128kl_u8 = __mm_aesdecwide128kl_u8Ptr.asFunction<
      int Function(
          ffi.Pointer<__m128i>, ffi.Pointer<__m128i>, ffi.Pointer<ffi.Void>)>();

  int _mm_aesdecwide256kl_u8(
    ffi.Pointer<__m128i> arg0,
    ffi.Pointer<__m128i> arg1,
    ffi.Pointer<ffi.Void> arg2,
  ) {
    return __mm_aesdecwide256kl_u8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_aesdecwide256kl_u8Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Uint8 Function(ffi.Pointer<__m128i>, ffi.Pointer<__m128i>,
              ffi.Pointer<ffi.Void>)>>('_mm_aesdecwide256kl_u8');
  late final __mm_aesdecwide256kl_u8 = __mm_aesdecwide256kl_u8Ptr.asFunction<
      int Function(
          ffi.Pointer<__m128i>, ffi.Pointer<__m128i>, ffi.Pointer<ffi.Void>)>();

  int _mm_aesenc128kl_u8(
    ffi.Pointer<__m128i> arg0,
    __m128i arg1,
    ffi.Pointer<ffi.Void> arg2,
  ) {
    return __mm_aesenc128kl_u8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_aesenc128kl_u8Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Uint8 Function(ffi.Pointer<__m128i>, __m128i,
              ffi.Pointer<ffi.Void>)>>('_mm_aesenc128kl_u8');
  late final __mm_aesenc128kl_u8 = __mm_aesenc128kl_u8Ptr.asFunction<
      int Function(ffi.Pointer<__m128i>, __m128i, ffi.Pointer<ffi.Void>)>();

  int _mm_aesenc256kl_u8(
    ffi.Pointer<__m128i> arg0,
    __m128i arg1,
    ffi.Pointer<ffi.Void> arg2,
  ) {
    return __mm_aesenc256kl_u8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_aesenc256kl_u8Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Uint8 Function(ffi.Pointer<__m128i>, __m128i,
              ffi.Pointer<ffi.Void>)>>('_mm_aesenc256kl_u8');
  late final __mm_aesenc256kl_u8 = __mm_aesenc256kl_u8Ptr.asFunction<
      int Function(ffi.Pointer<__m128i>, __m128i, ffi.Pointer<ffi.Void>)>();

  int _mm_aesencwide128kl_u8(
    ffi.Pointer<__m128i> arg0,
    ffi.Pointer<__m128i> arg1,
    ffi.Pointer<ffi.Void> arg2,
  ) {
    return __mm_aesencwide128kl_u8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_aesencwide128kl_u8Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Uint8 Function(ffi.Pointer<__m128i>, ffi.Pointer<__m128i>,
              ffi.Pointer<ffi.Void>)>>('_mm_aesencwide128kl_u8');
  late final __mm_aesencwide128kl_u8 = __mm_aesencwide128kl_u8Ptr.asFunction<
      int Function(
          ffi.Pointer<__m128i>, ffi.Pointer<__m128i>, ffi.Pointer<ffi.Void>)>();

  int _mm_aesencwide256kl_u8(
    ffi.Pointer<__m128i> arg0,
    ffi.Pointer<__m128i> arg1,
    ffi.Pointer<ffi.Void> arg2,
  ) {
    return __mm_aesencwide256kl_u8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_aesencwide256kl_u8Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Uint8 Function(ffi.Pointer<__m128i>, ffi.Pointer<__m128i>,
              ffi.Pointer<ffi.Void>)>>('_mm_aesencwide256kl_u8');
  late final __mm_aesencwide256kl_u8 = __mm_aesencwide256kl_u8Ptr.asFunction<
      int Function(
          ffi.Pointer<__m128i>, ffi.Pointer<__m128i>, ffi.Pointer<ffi.Void>)>();

  int _mm_encodekey128_u32(
    int arg0,
    __m128i arg1,
    ffi.Pointer<ffi.Void> arg2,
  ) {
    return __mm_encodekey128_u32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_encodekey128_u32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Uint32 Function(ffi.Uint32, __m128i,
              ffi.Pointer<ffi.Void>)>>('_mm_encodekey128_u32');
  late final __mm_encodekey128_u32 = __mm_encodekey128_u32Ptr
      .asFunction<int Function(int, __m128i, ffi.Pointer<ffi.Void>)>();

  int _mm_encodekey256_u32(
    int arg0,
    __m128i arg1,
    __m128i arg2,
    ffi.Pointer<ffi.Void> arg3,
  ) {
    return __mm_encodekey256_u32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_encodekey256_u32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Uint32 Function(ffi.Uint32, __m128i, __m128i,
              ffi.Pointer<ffi.Void>)>>('_mm_encodekey256_u32');
  late final __mm_encodekey256_u32 = __mm_encodekey256_u32Ptr
      .asFunction<int Function(int, __m128i, __m128i, ffi.Pointer<ffi.Void>)>();

  void _mm_loadiwkey(
    int arg0,
    __m128i arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_loadiwkey(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_loadiwkeyPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Uint32, __m128i, __m128i, __m128i)>>('_mm_loadiwkey');
  late final __mm_loadiwkey = __mm_loadiwkeyPtr
      .asFunction<void Function(int, __m128i, __m128i, __m128i)>();

  int _rdpkru_u32() {
    return __rdpkru_u32();
  }

  late final __rdpkru_u32Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint32 Function()>>('_rdpkru_u32');
  late final __rdpkru_u32 = __rdpkru_u32Ptr.asFunction<int Function()>();

  void _wrpkru(
    int arg0,
  ) {
    return __wrpkru(
      arg0,
    );
  }

  late final __wrpkruPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Uint32)>>('_wrpkru');
  late final __wrpkru = __wrpkruPtr.asFunction<void Function(int)>();

  int _enqcmd(
    ffi.Pointer<ffi.Void> arg0,
    ffi.Pointer<ffi.Void> arg1,
  ) {
    return __enqcmd(
      arg0,
      arg1,
    );
  }

  late final __enqcmdPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<ffi.Void>, ffi.Pointer<ffi.Void>)>>('_enqcmd');
  late final __enqcmd = __enqcmdPtr
      .asFunction<int Function(ffi.Pointer<ffi.Void>, ffi.Pointer<ffi.Void>)>();

  int _enqcmds(
    ffi.Pointer<ffi.Void> arg0,
    ffi.Pointer<ffi.Void> arg1,
  ) {
    return __enqcmds(
      arg0,
      arg1,
    );
  }

  late final __enqcmdsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<ffi.Void>, ffi.Pointer<ffi.Void>)>>('_enqcmds');
  late final __enqcmds = __enqcmdsPtr
      .asFunction<int Function(ffi.Pointer<ffi.Void>, ffi.Pointer<ffi.Void>)>();

  void _incsspd(
    int arg0,
  ) {
    return __incsspd(
      arg0,
    );
  }

  late final __incsspdPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Uint32)>>('_incsspd');
  late final __incsspd = __incsspdPtr.asFunction<void Function(int)>();

  int _rdsspd() {
    return __rdsspd();
  }

  late final __rdsspdPtr =
      _lookup<ffi.NativeFunction<ffi.Uint32 Function()>>('_rdsspd');
  late final __rdsspd = __rdsspdPtr.asFunction<int Function()>();

  void _saveprevssp() {
    return __saveprevssp();
  }

  late final __saveprevsspPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('_saveprevssp');
  late final __saveprevssp = __saveprevsspPtr.asFunction<void Function()>();

  void _rstorssp(
    ffi.Pointer<ffi.Void> arg0,
  ) {
    return __rstorssp(
      arg0,
    );
  }

  late final __rstorsspPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ffi.Void>)>>(
          '_rstorssp');
  late final __rstorssp =
      __rstorsspPtr.asFunction<void Function(ffi.Pointer<ffi.Void>)>();

  void _wrssd(
    int arg0,
    ffi.Pointer<ffi.Void> arg1,
  ) {
    return __wrssd(
      arg0,
      arg1,
    );
  }

  late final __wrssdPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Uint32, ffi.Pointer<ffi.Void>)>>('_wrssd');
  late final __wrssd =
      __wrssdPtr.asFunction<void Function(int, ffi.Pointer<ffi.Void>)>();

  void _wrussd(
    int arg0,
    ffi.Pointer<ffi.Void> arg1,
  ) {
    return __wrussd(
      arg0,
      arg1,
    );
  }

  late final __wrussdPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Uint32, ffi.Pointer<ffi.Void>)>>('_wrussd');
  late final __wrussd =
      __wrussdPtr.asFunction<void Function(int, ffi.Pointer<ffi.Void>)>();

  void _setssbsy() {
    return __setssbsy();
  }

  late final __setssbsyPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('_setssbsy');
  late final __setssbsy = __setssbsyPtr.asFunction<void Function()>();

  void _clrssbsy(
    ffi.Pointer<ffi.Void> arg0,
  ) {
    return __clrssbsy(
      arg0,
    );
  }

  late final __clrssbsyPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ffi.Void>)>>(
          '_clrssbsy');
  late final __clrssbsy =
      __clrssbsyPtr.asFunction<void Function(ffi.Pointer<ffi.Void>)>();

  ffi.Pointer<ffi.Void> _switchssp(
    ffi.Pointer<ffi.Void> arg0,
  ) {
    return __switchssp(
      arg0,
    );
  }

  late final __switchsspPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Void> Function(ffi.Pointer<ffi.Void>)>>('_switchssp');
  late final __switchssp = __switchsspPtr
      .asFunction<ffi.Pointer<ffi.Void> Function(ffi.Pointer<ffi.Void>)>();

  void _incsspq(
    int arg0,
  ) {
    return __incsspq(
      arg0,
    );
  }

  late final __incsspqPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Uint64)>>('_incsspq');
  late final __incsspq = __incsspqPtr.asFunction<void Function(int)>();

  int _rdsspq() {
    return __rdsspq();
  }

  late final __rdsspqPtr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function()>>('_rdsspq');
  late final __rdsspq = __rdsspqPtr.asFunction<int Function()>();

  void _wrssq(
    int arg0,
    ffi.Pointer<ffi.Void> arg1,
  ) {
    return __wrssq(
      arg0,
      arg1,
    );
  }

  late final __wrssqPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Uint64, ffi.Pointer<ffi.Void>)>>('_wrssq');
  late final __wrssq =
      __wrssqPtr.asFunction<void Function(int, ffi.Pointer<ffi.Void>)>();

  void _wrussq(
    int arg0,
    ffi.Pointer<ffi.Void> arg1,
  ) {
    return __wrussq(
      arg0,
      arg1,
    );
  }

  late final __wrussqPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Uint64, ffi.Pointer<ffi.Void>)>>('_wrussq');
  late final __wrussq =
      __wrussqPtr.asFunction<void Function(int, ffi.Pointer<ffi.Void>)>();

  __m128i _mm_div_epi8(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_div_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm_div_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_div_epi8');
  late final __mm_div_epi8 =
      __mm_div_epi8Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_div_epi16(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_div_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm_div_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_div_epi16');
  late final __mm_div_epi16 =
      __mm_div_epi16Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_div_epi32(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_div_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm_div_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_div_epi32');
  late final __mm_div_epi32 =
      __mm_div_epi32Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_div_epi64(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_div_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm_div_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_div_epi64');
  late final __mm_div_epi64 =
      __mm_div_epi64Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_div_epu8(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_div_epu8(
      arg0,
      arg1,
    );
  }

  late final __mm_div_epu8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_div_epu8');
  late final __mm_div_epu8 =
      __mm_div_epu8Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_div_epu16(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_div_epu16(
      arg0,
      arg1,
    );
  }

  late final __mm_div_epu16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_div_epu16');
  late final __mm_div_epu16 =
      __mm_div_epu16Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_div_epu32(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_div_epu32(
      arg0,
      arg1,
    );
  }

  late final __mm_div_epu32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_div_epu32');
  late final __mm_div_epu32 =
      __mm_div_epu32Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_div_epu64(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_div_epu64(
      arg0,
      arg1,
    );
  }

  late final __mm_div_epu64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_div_epu64');
  late final __mm_div_epu64 =
      __mm_div_epu64Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_rem_epi8(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_rem_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm_rem_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_rem_epi8');
  late final __mm_rem_epi8 =
      __mm_rem_epi8Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_rem_epi16(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_rem_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm_rem_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_rem_epi16');
  late final __mm_rem_epi16 =
      __mm_rem_epi16Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_rem_epi32(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_rem_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm_rem_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_rem_epi32');
  late final __mm_rem_epi32 =
      __mm_rem_epi32Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_rem_epi64(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_rem_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm_rem_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_rem_epi64');
  late final __mm_rem_epi64 =
      __mm_rem_epi64Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_rem_epu8(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_rem_epu8(
      arg0,
      arg1,
    );
  }

  late final __mm_rem_epu8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_rem_epu8');
  late final __mm_rem_epu8 =
      __mm_rem_epu8Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_rem_epu16(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_rem_epu16(
      arg0,
      arg1,
    );
  }

  late final __mm_rem_epu16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_rem_epu16');
  late final __mm_rem_epu16 =
      __mm_rem_epu16Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_rem_epu32(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_rem_epu32(
      arg0,
      arg1,
    );
  }

  late final __mm_rem_epu32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_rem_epu32');
  late final __mm_rem_epu32 =
      __mm_rem_epu32Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_rem_epu64(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_rem_epu64(
      arg0,
      arg1,
    );
  }

  late final __mm_rem_epu64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_rem_epu64');
  late final __mm_rem_epu64 =
      __mm_rem_epu64Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m256i _mm256_div_epi8(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_div_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm256_div_epi8Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_div_epi8');
  late final __mm256_div_epi8 =
      __mm256_div_epi8Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_div_epi16(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_div_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm256_div_epi16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_div_epi16');
  late final __mm256_div_epi16 =
      __mm256_div_epi16Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_div_epi32(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_div_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm256_div_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_div_epi32');
  late final __mm256_div_epi32 =
      __mm256_div_epi32Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_div_epi64(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_div_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm256_div_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_div_epi64');
  late final __mm256_div_epi64 =
      __mm256_div_epi64Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_div_epu8(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_div_epu8(
      arg0,
      arg1,
    );
  }

  late final __mm256_div_epu8Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_div_epu8');
  late final __mm256_div_epu8 =
      __mm256_div_epu8Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_div_epu16(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_div_epu16(
      arg0,
      arg1,
    );
  }

  late final __mm256_div_epu16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_div_epu16');
  late final __mm256_div_epu16 =
      __mm256_div_epu16Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_div_epu32(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_div_epu32(
      arg0,
      arg1,
    );
  }

  late final __mm256_div_epu32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_div_epu32');
  late final __mm256_div_epu32 =
      __mm256_div_epu32Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_div_epu64(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_div_epu64(
      arg0,
      arg1,
    );
  }

  late final __mm256_div_epu64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_div_epu64');
  late final __mm256_div_epu64 =
      __mm256_div_epu64Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_rem_epi8(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_rem_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm256_rem_epi8Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_rem_epi8');
  late final __mm256_rem_epi8 =
      __mm256_rem_epi8Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_rem_epi16(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_rem_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm256_rem_epi16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_rem_epi16');
  late final __mm256_rem_epi16 =
      __mm256_rem_epi16Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_rem_epi32(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_rem_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm256_rem_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_rem_epi32');
  late final __mm256_rem_epi32 =
      __mm256_rem_epi32Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_rem_epi64(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_rem_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm256_rem_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_rem_epi64');
  late final __mm256_rem_epi64 =
      __mm256_rem_epi64Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_rem_epu8(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_rem_epu8(
      arg0,
      arg1,
    );
  }

  late final __mm256_rem_epu8Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_rem_epu8');
  late final __mm256_rem_epu8 =
      __mm256_rem_epu8Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_rem_epu16(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_rem_epu16(
      arg0,
      arg1,
    );
  }

  late final __mm256_rem_epu16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_rem_epu16');
  late final __mm256_rem_epu16 =
      __mm256_rem_epu16Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_rem_epu32(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_rem_epu32(
      arg0,
      arg1,
    );
  }

  late final __mm256_rem_epu32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_rem_epu32');
  late final __mm256_rem_epu32 =
      __mm256_rem_epu32Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_rem_epu64(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_rem_epu64(
      arg0,
      arg1,
    );
  }

  late final __mm256_rem_epu64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_rem_epu64');
  late final __mm256_rem_epu64 =
      __mm256_rem_epu64Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m128i _mm_divrem_epi32(
    ffi.Pointer<__m128i> arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_divrem_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_divrem_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              ffi.Pointer<__m128i>, __m128i, __m128i)>>('_mm_divrem_epi32');
  late final __mm_divrem_epi32 = __mm_divrem_epi32Ptr
      .asFunction<__m128i Function(ffi.Pointer<__m128i>, __m128i, __m128i)>();

  __m128i _mm_divrem_epu32(
    ffi.Pointer<__m128i> arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_divrem_epu32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_divrem_epu32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              ffi.Pointer<__m128i>, __m128i, __m128i)>>('_mm_divrem_epu32');
  late final __mm_divrem_epu32 = __mm_divrem_epu32Ptr
      .asFunction<__m128i Function(ffi.Pointer<__m128i>, __m128i, __m128i)>();

  __m256i _mm256_divrem_epi32(
    ffi.Pointer<__m256i> arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_divrem_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_divrem_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              ffi.Pointer<__m256i>, __m256i, __m256i)>>('_mm256_divrem_epi32');
  late final __mm256_divrem_epi32 = __mm256_divrem_epi32Ptr
      .asFunction<__m256i Function(ffi.Pointer<__m256i>, __m256i, __m256i)>();

  __m256i _mm256_divrem_epu32(
    ffi.Pointer<__m256i> arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_divrem_epu32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_divrem_epu32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              ffi.Pointer<__m256i>, __m256i, __m256i)>>('_mm256_divrem_epu32');
  late final __mm256_divrem_epu32 = __mm256_divrem_epu32Ptr
      .asFunction<__m256i Function(ffi.Pointer<__m256i>, __m256i, __m256i)>();

  __m128 _mm_sin_ps(
    __m128 arg0,
  ) {
    return __mm_sin_ps(
      arg0,
    );
  }

  late final __mm_sin_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128)>>('_mm_sin_ps');
  late final __mm_sin_ps = __mm_sin_psPtr.asFunction<__m128 Function(__m128)>();

  _m128d _mm_sin_pd(
    _m128d arg0,
  ) {
    return __mm_sin_pd(
      arg0,
    );
  }

  late final __mm_sin_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d)>>('_mm_sin_pd');
  late final __mm_sin_pd = __mm_sin_pdPtr.asFunction<_m128d Function(_m128d)>();

  __m256 _mm256_sin_ps(
    __m256 arg0,
  ) {
    return __mm256_sin_ps(
      arg0,
    );
  }

  late final __mm256_sin_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256)>>('_mm256_sin_ps');
  late final __mm256_sin_ps =
      __mm256_sin_psPtr.asFunction<__m256 Function(__m256)>();

  _m256d _mm256_sin_pd(
    _m256d arg0,
  ) {
    return __mm256_sin_pd(
      arg0,
    );
  }

  late final __mm256_sin_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d)>>('_mm256_sin_pd');
  late final __mm256_sin_pd =
      __mm256_sin_pdPtr.asFunction<_m256d Function(_m256d)>();

  __m128 _mm_cos_ps(
    __m128 arg0,
  ) {
    return __mm_cos_ps(
      arg0,
    );
  }

  late final __mm_cos_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128)>>('_mm_cos_ps');
  late final __mm_cos_ps = __mm_cos_psPtr.asFunction<__m128 Function(__m128)>();

  _m128d _mm_cos_pd(
    _m128d arg0,
  ) {
    return __mm_cos_pd(
      arg0,
    );
  }

  late final __mm_cos_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d)>>('_mm_cos_pd');
  late final __mm_cos_pd = __mm_cos_pdPtr.asFunction<_m128d Function(_m128d)>();

  __m256 _mm256_cos_ps(
    __m256 arg0,
  ) {
    return __mm256_cos_ps(
      arg0,
    );
  }

  late final __mm256_cos_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256)>>('_mm256_cos_ps');
  late final __mm256_cos_ps =
      __mm256_cos_psPtr.asFunction<__m256 Function(__m256)>();

  _m256d _mm256_cos_pd(
    _m256d arg0,
  ) {
    return __mm256_cos_pd(
      arg0,
    );
  }

  late final __mm256_cos_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d)>>('_mm256_cos_pd');
  late final __mm256_cos_pd =
      __mm256_cos_pdPtr.asFunction<_m256d Function(_m256d)>();

  __m128 _mm_sincos_ps(
    ffi.Pointer<__m128> arg0,
    __m128 arg1,
  ) {
    return __mm_sincos_ps(
      arg0,
      arg1,
    );
  }

  late final __mm_sincos_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(ffi.Pointer<__m128>, __m128)>>(
          '_mm_sincos_ps');
  late final __mm_sincos_ps = __mm_sincos_psPtr
      .asFunction<__m128 Function(ffi.Pointer<__m128>, __m128)>();

  _m128d _mm_sincos_pd(
    ffi.Pointer<_m128d> arg0,
    _m128d arg1,
  ) {
    return __mm_sincos_pd(
      arg0,
      arg1,
    );
  }

  late final __mm_sincos_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(ffi.Pointer<_m128d>, _m128d)>>(
          '_mm_sincos_pd');
  late final __mm_sincos_pd = __mm_sincos_pdPtr
      .asFunction<_m128d Function(ffi.Pointer<_m128d>, _m128d)>();

  __m256 _mm256_sincos_ps(
    ffi.Pointer<__m256> arg0,
    __m256 arg1,
  ) {
    return __mm256_sincos_ps(
      arg0,
      arg1,
    );
  }

  late final __mm256_sincos_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(ffi.Pointer<__m256>, __m256)>>(
          '_mm256_sincos_ps');
  late final __mm256_sincos_ps = __mm256_sincos_psPtr
      .asFunction<__m256 Function(ffi.Pointer<__m256>, __m256)>();

  _m256d _mm256_sincos_pd(
    ffi.Pointer<_m256d> arg0,
    _m256d arg1,
  ) {
    return __mm256_sincos_pd(
      arg0,
      arg1,
    );
  }

  late final __mm256_sincos_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(ffi.Pointer<_m256d>, _m256d)>>(
          '_mm256_sincos_pd');
  late final __mm256_sincos_pd = __mm256_sincos_pdPtr
      .asFunction<_m256d Function(ffi.Pointer<_m256d>, _m256d)>();

  __m128 _mm_tan_ps(
    __m128 arg0,
  ) {
    return __mm_tan_ps(
      arg0,
    );
  }

  late final __mm_tan_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128)>>('_mm_tan_ps');
  late final __mm_tan_ps = __mm_tan_psPtr.asFunction<__m128 Function(__m128)>();

  _m128d _mm_tan_pd(
    _m128d arg0,
  ) {
    return __mm_tan_pd(
      arg0,
    );
  }

  late final __mm_tan_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d)>>('_mm_tan_pd');
  late final __mm_tan_pd = __mm_tan_pdPtr.asFunction<_m128d Function(_m128d)>();

  __m256 _mm256_tan_ps(
    __m256 arg0,
  ) {
    return __mm256_tan_ps(
      arg0,
    );
  }

  late final __mm256_tan_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256)>>('_mm256_tan_ps');
  late final __mm256_tan_ps =
      __mm256_tan_psPtr.asFunction<__m256 Function(__m256)>();

  _m256d _mm256_tan_pd(
    _m256d arg0,
  ) {
    return __mm256_tan_pd(
      arg0,
    );
  }

  late final __mm256_tan_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d)>>('_mm256_tan_pd');
  late final __mm256_tan_pd =
      __mm256_tan_pdPtr.asFunction<_m256d Function(_m256d)>();

  __m128 _mm_asin_ps(
    __m128 arg0,
  ) {
    return __mm_asin_ps(
      arg0,
    );
  }

  late final __mm_asin_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128)>>('_mm_asin_ps');
  late final __mm_asin_ps =
      __mm_asin_psPtr.asFunction<__m128 Function(__m128)>();

  _m128d _mm_asin_pd(
    _m128d arg0,
  ) {
    return __mm_asin_pd(
      arg0,
    );
  }

  late final __mm_asin_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d)>>('_mm_asin_pd');
  late final __mm_asin_pd =
      __mm_asin_pdPtr.asFunction<_m128d Function(_m128d)>();

  __m256 _mm256_asin_ps(
    __m256 arg0,
  ) {
    return __mm256_asin_ps(
      arg0,
    );
  }

  late final __mm256_asin_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256)>>('_mm256_asin_ps');
  late final __mm256_asin_ps =
      __mm256_asin_psPtr.asFunction<__m256 Function(__m256)>();

  _m256d _mm256_asin_pd(
    _m256d arg0,
  ) {
    return __mm256_asin_pd(
      arg0,
    );
  }

  late final __mm256_asin_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d)>>('_mm256_asin_pd');
  late final __mm256_asin_pd =
      __mm256_asin_pdPtr.asFunction<_m256d Function(_m256d)>();

  __m128 _mm_acos_ps(
    __m128 arg0,
  ) {
    return __mm_acos_ps(
      arg0,
    );
  }

  late final __mm_acos_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128)>>('_mm_acos_ps');
  late final __mm_acos_ps =
      __mm_acos_psPtr.asFunction<__m128 Function(__m128)>();

  _m128d _mm_acos_pd(
    _m128d arg0,
  ) {
    return __mm_acos_pd(
      arg0,
    );
  }

  late final __mm_acos_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d)>>('_mm_acos_pd');
  late final __mm_acos_pd =
      __mm_acos_pdPtr.asFunction<_m128d Function(_m128d)>();

  __m256 _mm256_acos_ps(
    __m256 arg0,
  ) {
    return __mm256_acos_ps(
      arg0,
    );
  }

  late final __mm256_acos_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256)>>('_mm256_acos_ps');
  late final __mm256_acos_ps =
      __mm256_acos_psPtr.asFunction<__m256 Function(__m256)>();

  _m256d _mm256_acos_pd(
    _m256d arg0,
  ) {
    return __mm256_acos_pd(
      arg0,
    );
  }

  late final __mm256_acos_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d)>>('_mm256_acos_pd');
  late final __mm256_acos_pd =
      __mm256_acos_pdPtr.asFunction<_m256d Function(_m256d)>();

  __m128 _mm_atan_ps(
    __m128 arg0,
  ) {
    return __mm_atan_ps(
      arg0,
    );
  }

  late final __mm_atan_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128)>>('_mm_atan_ps');
  late final __mm_atan_ps =
      __mm_atan_psPtr.asFunction<__m128 Function(__m128)>();

  _m128d _mm_atan_pd(
    _m128d arg0,
  ) {
    return __mm_atan_pd(
      arg0,
    );
  }

  late final __mm_atan_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d)>>('_mm_atan_pd');
  late final __mm_atan_pd =
      __mm_atan_pdPtr.asFunction<_m128d Function(_m128d)>();

  __m256 _mm256_atan_ps(
    __m256 arg0,
  ) {
    return __mm256_atan_ps(
      arg0,
    );
  }

  late final __mm256_atan_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256)>>('_mm256_atan_ps');
  late final __mm256_atan_ps =
      __mm256_atan_psPtr.asFunction<__m256 Function(__m256)>();

  _m256d _mm256_atan_pd(
    _m256d arg0,
  ) {
    return __mm256_atan_pd(
      arg0,
    );
  }

  late final __mm256_atan_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d)>>('_mm256_atan_pd');
  late final __mm256_atan_pd =
      __mm256_atan_pdPtr.asFunction<_m256d Function(_m256d)>();

  __m128 _mm_atan2_ps(
    __m128 arg0,
    __m128 arg1,
  ) {
    return __mm_atan2_ps(
      arg0,
      arg1,
    );
  }

  late final __mm_atan2_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128)>>(
          '_mm_atan2_ps');
  late final __mm_atan2_ps =
      __mm_atan2_psPtr.asFunction<__m128 Function(__m128, __m128)>();

  _m128d _mm_atan2_pd(
    _m128d arg0,
    _m128d arg1,
  ) {
    return __mm_atan2_pd(
      arg0,
      arg1,
    );
  }

  late final __mm_atan2_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d)>>(
          '_mm_atan2_pd');
  late final __mm_atan2_pd =
      __mm_atan2_pdPtr.asFunction<_m128d Function(_m128d, _m128d)>();

  __m256 _mm256_atan2_ps(
    __m256 arg0,
    __m256 arg1,
  ) {
    return __mm256_atan2_ps(
      arg0,
      arg1,
    );
  }

  late final __mm256_atan2_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256, __m256)>>(
          '_mm256_atan2_ps');
  late final __mm256_atan2_ps =
      __mm256_atan2_psPtr.asFunction<__m256 Function(__m256, __m256)>();

  _m256d _mm256_atan2_pd(
    _m256d arg0,
    _m256d arg1,
  ) {
    return __mm256_atan2_pd(
      arg0,
      arg1,
    );
  }

  late final __mm256_atan2_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d, _m256d)>>(
          '_mm256_atan2_pd');
  late final __mm256_atan2_pd =
      __mm256_atan2_pdPtr.asFunction<_m256d Function(_m256d, _m256d)>();

  __m128 _mm_sind_ps(
    __m128 arg0,
  ) {
    return __mm_sind_ps(
      arg0,
    );
  }

  late final __mm_sind_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128)>>('_mm_sind_ps');
  late final __mm_sind_ps =
      __mm_sind_psPtr.asFunction<__m128 Function(__m128)>();

  _m128d _mm_sind_pd(
    _m128d arg0,
  ) {
    return __mm_sind_pd(
      arg0,
    );
  }

  late final __mm_sind_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d)>>('_mm_sind_pd');
  late final __mm_sind_pd =
      __mm_sind_pdPtr.asFunction<_m128d Function(_m128d)>();

  __m256 _mm256_sind_ps(
    __m256 arg0,
  ) {
    return __mm256_sind_ps(
      arg0,
    );
  }

  late final __mm256_sind_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256)>>('_mm256_sind_ps');
  late final __mm256_sind_ps =
      __mm256_sind_psPtr.asFunction<__m256 Function(__m256)>();

  _m256d _mm256_sind_pd(
    _m256d arg0,
  ) {
    return __mm256_sind_pd(
      arg0,
    );
  }

  late final __mm256_sind_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d)>>('_mm256_sind_pd');
  late final __mm256_sind_pd =
      __mm256_sind_pdPtr.asFunction<_m256d Function(_m256d)>();

  __m128 _mm_cosd_ps(
    __m128 arg0,
  ) {
    return __mm_cosd_ps(
      arg0,
    );
  }

  late final __mm_cosd_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128)>>('_mm_cosd_ps');
  late final __mm_cosd_ps =
      __mm_cosd_psPtr.asFunction<__m128 Function(__m128)>();

  _m128d _mm_cosd_pd(
    _m128d arg0,
  ) {
    return __mm_cosd_pd(
      arg0,
    );
  }

  late final __mm_cosd_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d)>>('_mm_cosd_pd');
  late final __mm_cosd_pd =
      __mm_cosd_pdPtr.asFunction<_m128d Function(_m128d)>();

  __m256 _mm256_cosd_ps(
    __m256 arg0,
  ) {
    return __mm256_cosd_ps(
      arg0,
    );
  }

  late final __mm256_cosd_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256)>>('_mm256_cosd_ps');
  late final __mm256_cosd_ps =
      __mm256_cosd_psPtr.asFunction<__m256 Function(__m256)>();

  _m256d _mm256_cosd_pd(
    _m256d arg0,
  ) {
    return __mm256_cosd_pd(
      arg0,
    );
  }

  late final __mm256_cosd_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d)>>('_mm256_cosd_pd');
  late final __mm256_cosd_pd =
      __mm256_cosd_pdPtr.asFunction<_m256d Function(_m256d)>();

  __m128 _mm_tand_ps(
    __m128 arg0,
  ) {
    return __mm_tand_ps(
      arg0,
    );
  }

  late final __mm_tand_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128)>>('_mm_tand_ps');
  late final __mm_tand_ps =
      __mm_tand_psPtr.asFunction<__m128 Function(__m128)>();

  _m128d _mm_tand_pd(
    _m128d arg0,
  ) {
    return __mm_tand_pd(
      arg0,
    );
  }

  late final __mm_tand_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d)>>('_mm_tand_pd');
  late final __mm_tand_pd =
      __mm_tand_pdPtr.asFunction<_m128d Function(_m128d)>();

  __m256 _mm256_tand_ps(
    __m256 arg0,
  ) {
    return __mm256_tand_ps(
      arg0,
    );
  }

  late final __mm256_tand_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256)>>('_mm256_tand_ps');
  late final __mm256_tand_ps =
      __mm256_tand_psPtr.asFunction<__m256 Function(__m256)>();

  _m256d _mm256_tand_pd(
    _m256d arg0,
  ) {
    return __mm256_tand_pd(
      arg0,
    );
  }

  late final __mm256_tand_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d)>>('_mm256_tand_pd');
  late final __mm256_tand_pd =
      __mm256_tand_pdPtr.asFunction<_m256d Function(_m256d)>();

  __m128 _mm_sinh_ps(
    __m128 arg0,
  ) {
    return __mm_sinh_ps(
      arg0,
    );
  }

  late final __mm_sinh_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128)>>('_mm_sinh_ps');
  late final __mm_sinh_ps =
      __mm_sinh_psPtr.asFunction<__m128 Function(__m128)>();

  _m128d _mm_sinh_pd(
    _m128d arg0,
  ) {
    return __mm_sinh_pd(
      arg0,
    );
  }

  late final __mm_sinh_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d)>>('_mm_sinh_pd');
  late final __mm_sinh_pd =
      __mm_sinh_pdPtr.asFunction<_m128d Function(_m128d)>();

  __m256 _mm256_sinh_ps(
    __m256 arg0,
  ) {
    return __mm256_sinh_ps(
      arg0,
    );
  }

  late final __mm256_sinh_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256)>>('_mm256_sinh_ps');
  late final __mm256_sinh_ps =
      __mm256_sinh_psPtr.asFunction<__m256 Function(__m256)>();

  _m256d _mm256_sinh_pd(
    _m256d arg0,
  ) {
    return __mm256_sinh_pd(
      arg0,
    );
  }

  late final __mm256_sinh_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d)>>('_mm256_sinh_pd');
  late final __mm256_sinh_pd =
      __mm256_sinh_pdPtr.asFunction<_m256d Function(_m256d)>();

  __m128 _mm_cosh_ps(
    __m128 arg0,
  ) {
    return __mm_cosh_ps(
      arg0,
    );
  }

  late final __mm_cosh_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128)>>('_mm_cosh_ps');
  late final __mm_cosh_ps =
      __mm_cosh_psPtr.asFunction<__m128 Function(__m128)>();

  _m128d _mm_cosh_pd(
    _m128d arg0,
  ) {
    return __mm_cosh_pd(
      arg0,
    );
  }

  late final __mm_cosh_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d)>>('_mm_cosh_pd');
  late final __mm_cosh_pd =
      __mm_cosh_pdPtr.asFunction<_m128d Function(_m128d)>();

  __m256 _mm256_cosh_ps(
    __m256 arg0,
  ) {
    return __mm256_cosh_ps(
      arg0,
    );
  }

  late final __mm256_cosh_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256)>>('_mm256_cosh_ps');
  late final __mm256_cosh_ps =
      __mm256_cosh_psPtr.asFunction<__m256 Function(__m256)>();

  _m256d _mm256_cosh_pd(
    _m256d arg0,
  ) {
    return __mm256_cosh_pd(
      arg0,
    );
  }

  late final __mm256_cosh_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d)>>('_mm256_cosh_pd');
  late final __mm256_cosh_pd =
      __mm256_cosh_pdPtr.asFunction<_m256d Function(_m256d)>();

  __m128 _mm_tanh_ps(
    __m128 arg0,
  ) {
    return __mm_tanh_ps(
      arg0,
    );
  }

  late final __mm_tanh_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128)>>('_mm_tanh_ps');
  late final __mm_tanh_ps =
      __mm_tanh_psPtr.asFunction<__m128 Function(__m128)>();

  _m128d _mm_tanh_pd(
    _m128d arg0,
  ) {
    return __mm_tanh_pd(
      arg0,
    );
  }

  late final __mm_tanh_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d)>>('_mm_tanh_pd');
  late final __mm_tanh_pd =
      __mm_tanh_pdPtr.asFunction<_m128d Function(_m128d)>();

  __m256 _mm256_tanh_ps(
    __m256 arg0,
  ) {
    return __mm256_tanh_ps(
      arg0,
    );
  }

  late final __mm256_tanh_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256)>>('_mm256_tanh_ps');
  late final __mm256_tanh_ps =
      __mm256_tanh_psPtr.asFunction<__m256 Function(__m256)>();

  _m256d _mm256_tanh_pd(
    _m256d arg0,
  ) {
    return __mm256_tanh_pd(
      arg0,
    );
  }

  late final __mm256_tanh_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d)>>('_mm256_tanh_pd');
  late final __mm256_tanh_pd =
      __mm256_tanh_pdPtr.asFunction<_m256d Function(_m256d)>();

  __m128 _mm_asinh_ps(
    __m128 arg0,
  ) {
    return __mm_asinh_ps(
      arg0,
    );
  }

  late final __mm_asinh_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128)>>('_mm_asinh_ps');
  late final __mm_asinh_ps =
      __mm_asinh_psPtr.asFunction<__m128 Function(__m128)>();

  _m128d _mm_asinh_pd(
    _m128d arg0,
  ) {
    return __mm_asinh_pd(
      arg0,
    );
  }

  late final __mm_asinh_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d)>>('_mm_asinh_pd');
  late final __mm_asinh_pd =
      __mm_asinh_pdPtr.asFunction<_m128d Function(_m128d)>();

  __m256 _mm256_asinh_ps(
    __m256 arg0,
  ) {
    return __mm256_asinh_ps(
      arg0,
    );
  }

  late final __mm256_asinh_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256)>>('_mm256_asinh_ps');
  late final __mm256_asinh_ps =
      __mm256_asinh_psPtr.asFunction<__m256 Function(__m256)>();

  _m256d _mm256_asinh_pd(
    _m256d arg0,
  ) {
    return __mm256_asinh_pd(
      arg0,
    );
  }

  late final __mm256_asinh_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d)>>('_mm256_asinh_pd');
  late final __mm256_asinh_pd =
      __mm256_asinh_pdPtr.asFunction<_m256d Function(_m256d)>();

  __m128 _mm_acosh_ps(
    __m128 arg0,
  ) {
    return __mm_acosh_ps(
      arg0,
    );
  }

  late final __mm_acosh_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128)>>('_mm_acosh_ps');
  late final __mm_acosh_ps =
      __mm_acosh_psPtr.asFunction<__m128 Function(__m128)>();

  _m128d _mm_acosh_pd(
    _m128d arg0,
  ) {
    return __mm_acosh_pd(
      arg0,
    );
  }

  late final __mm_acosh_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d)>>('_mm_acosh_pd');
  late final __mm_acosh_pd =
      __mm_acosh_pdPtr.asFunction<_m128d Function(_m128d)>();

  __m256 _mm256_acosh_ps(
    __m256 arg0,
  ) {
    return __mm256_acosh_ps(
      arg0,
    );
  }

  late final __mm256_acosh_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256)>>('_mm256_acosh_ps');
  late final __mm256_acosh_ps =
      __mm256_acosh_psPtr.asFunction<__m256 Function(__m256)>();

  _m256d _mm256_acosh_pd(
    _m256d arg0,
  ) {
    return __mm256_acosh_pd(
      arg0,
    );
  }

  late final __mm256_acosh_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d)>>('_mm256_acosh_pd');
  late final __mm256_acosh_pd =
      __mm256_acosh_pdPtr.asFunction<_m256d Function(_m256d)>();

  __m128 _mm_atanh_ps(
    __m128 arg0,
  ) {
    return __mm_atanh_ps(
      arg0,
    );
  }

  late final __mm_atanh_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128)>>('_mm_atanh_ps');
  late final __mm_atanh_ps =
      __mm_atanh_psPtr.asFunction<__m128 Function(__m128)>();

  _m128d _mm_atanh_pd(
    _m128d arg0,
  ) {
    return __mm_atanh_pd(
      arg0,
    );
  }

  late final __mm_atanh_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d)>>('_mm_atanh_pd');
  late final __mm_atanh_pd =
      __mm_atanh_pdPtr.asFunction<_m128d Function(_m128d)>();

  __m256 _mm256_atanh_ps(
    __m256 arg0,
  ) {
    return __mm256_atanh_ps(
      arg0,
    );
  }

  late final __mm256_atanh_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256)>>('_mm256_atanh_ps');
  late final __mm256_atanh_ps =
      __mm256_atanh_psPtr.asFunction<__m256 Function(__m256)>();

  _m256d _mm256_atanh_pd(
    _m256d arg0,
  ) {
    return __mm256_atanh_pd(
      arg0,
    );
  }

  late final __mm256_atanh_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d)>>('_mm256_atanh_pd');
  late final __mm256_atanh_pd =
      __mm256_atanh_pdPtr.asFunction<_m256d Function(_m256d)>();

  __m128 _mm_log_ps(
    __m128 arg0,
  ) {
    return __mm_log_ps(
      arg0,
    );
  }

  late final __mm_log_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128)>>('_mm_log_ps');
  late final __mm_log_ps = __mm_log_psPtr.asFunction<__m128 Function(__m128)>();

  _m128d _mm_log_pd(
    _m128d arg0,
  ) {
    return __mm_log_pd(
      arg0,
    );
  }

  late final __mm_log_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d)>>('_mm_log_pd');
  late final __mm_log_pd = __mm_log_pdPtr.asFunction<_m128d Function(_m128d)>();

  __m256 _mm256_log_ps(
    __m256 arg0,
  ) {
    return __mm256_log_ps(
      arg0,
    );
  }

  late final __mm256_log_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256)>>('_mm256_log_ps');
  late final __mm256_log_ps =
      __mm256_log_psPtr.asFunction<__m256 Function(__m256)>();

  _m256d _mm256_log_pd(
    _m256d arg0,
  ) {
    return __mm256_log_pd(
      arg0,
    );
  }

  late final __mm256_log_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d)>>('_mm256_log_pd');
  late final __mm256_log_pd =
      __mm256_log_pdPtr.asFunction<_m256d Function(_m256d)>();

  __m128 _mm_log1p_ps(
    __m128 arg0,
  ) {
    return __mm_log1p_ps(
      arg0,
    );
  }

  late final __mm_log1p_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128)>>('_mm_log1p_ps');
  late final __mm_log1p_ps =
      __mm_log1p_psPtr.asFunction<__m128 Function(__m128)>();

  _m128d _mm_log1p_pd(
    _m128d arg0,
  ) {
    return __mm_log1p_pd(
      arg0,
    );
  }

  late final __mm_log1p_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d)>>('_mm_log1p_pd');
  late final __mm_log1p_pd =
      __mm_log1p_pdPtr.asFunction<_m128d Function(_m128d)>();

  __m256 _mm256_log1p_ps(
    __m256 arg0,
  ) {
    return __mm256_log1p_ps(
      arg0,
    );
  }

  late final __mm256_log1p_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256)>>('_mm256_log1p_ps');
  late final __mm256_log1p_ps =
      __mm256_log1p_psPtr.asFunction<__m256 Function(__m256)>();

  _m256d _mm256_log1p_pd(
    _m256d arg0,
  ) {
    return __mm256_log1p_pd(
      arg0,
    );
  }

  late final __mm256_log1p_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d)>>('_mm256_log1p_pd');
  late final __mm256_log1p_pd =
      __mm256_log1p_pdPtr.asFunction<_m256d Function(_m256d)>();

  __m128 _mm_log10_ps(
    __m128 arg0,
  ) {
    return __mm_log10_ps(
      arg0,
    );
  }

  late final __mm_log10_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128)>>('_mm_log10_ps');
  late final __mm_log10_ps =
      __mm_log10_psPtr.asFunction<__m128 Function(__m128)>();

  _m128d _mm_log10_pd(
    _m128d arg0,
  ) {
    return __mm_log10_pd(
      arg0,
    );
  }

  late final __mm_log10_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d)>>('_mm_log10_pd');
  late final __mm_log10_pd =
      __mm_log10_pdPtr.asFunction<_m128d Function(_m128d)>();

  __m256 _mm256_log10_ps(
    __m256 arg0,
  ) {
    return __mm256_log10_ps(
      arg0,
    );
  }

  late final __mm256_log10_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256)>>('_mm256_log10_ps');
  late final __mm256_log10_ps =
      __mm256_log10_psPtr.asFunction<__m256 Function(__m256)>();

  _m256d _mm256_log10_pd(
    _m256d arg0,
  ) {
    return __mm256_log10_pd(
      arg0,
    );
  }

  late final __mm256_log10_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d)>>('_mm256_log10_pd');
  late final __mm256_log10_pd =
      __mm256_log10_pdPtr.asFunction<_m256d Function(_m256d)>();

  __m128 _mm_log2_ps(
    __m128 arg0,
  ) {
    return __mm_log2_ps(
      arg0,
    );
  }

  late final __mm_log2_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128)>>('_mm_log2_ps');
  late final __mm_log2_ps =
      __mm_log2_psPtr.asFunction<__m128 Function(__m128)>();

  _m128d _mm_log2_pd(
    _m128d arg0,
  ) {
    return __mm_log2_pd(
      arg0,
    );
  }

  late final __mm_log2_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d)>>('_mm_log2_pd');
  late final __mm_log2_pd =
      __mm_log2_pdPtr.asFunction<_m128d Function(_m128d)>();

  __m256 _mm256_log2_ps(
    __m256 arg0,
  ) {
    return __mm256_log2_ps(
      arg0,
    );
  }

  late final __mm256_log2_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256)>>('_mm256_log2_ps');
  late final __mm256_log2_ps =
      __mm256_log2_psPtr.asFunction<__m256 Function(__m256)>();

  _m256d _mm256_log2_pd(
    _m256d arg0,
  ) {
    return __mm256_log2_pd(
      arg0,
    );
  }

  late final __mm256_log2_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d)>>('_mm256_log2_pd');
  late final __mm256_log2_pd =
      __mm256_log2_pdPtr.asFunction<_m256d Function(_m256d)>();

  __m128 _mm_logb_ps(
    __m128 arg0,
  ) {
    return __mm_logb_ps(
      arg0,
    );
  }

  late final __mm_logb_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128)>>('_mm_logb_ps');
  late final __mm_logb_ps =
      __mm_logb_psPtr.asFunction<__m128 Function(__m128)>();

  _m128d _mm_logb_pd(
    _m128d arg0,
  ) {
    return __mm_logb_pd(
      arg0,
    );
  }

  late final __mm_logb_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d)>>('_mm_logb_pd');
  late final __mm_logb_pd =
      __mm_logb_pdPtr.asFunction<_m128d Function(_m128d)>();

  __m256 _mm256_logb_ps(
    __m256 arg0,
  ) {
    return __mm256_logb_ps(
      arg0,
    );
  }

  late final __mm256_logb_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256)>>('_mm256_logb_ps');
  late final __mm256_logb_ps =
      __mm256_logb_psPtr.asFunction<__m256 Function(__m256)>();

  _m256d _mm256_logb_pd(
    _m256d arg0,
  ) {
    return __mm256_logb_pd(
      arg0,
    );
  }

  late final __mm256_logb_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d)>>('_mm256_logb_pd');
  late final __mm256_logb_pd =
      __mm256_logb_pdPtr.asFunction<_m256d Function(_m256d)>();

  __m128 _mm_exp_ps(
    __m128 arg0,
  ) {
    return __mm_exp_ps(
      arg0,
    );
  }

  late final __mm_exp_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128)>>('_mm_exp_ps');
  late final __mm_exp_ps = __mm_exp_psPtr.asFunction<__m128 Function(__m128)>();

  _m128d _mm_exp_pd(
    _m128d arg0,
  ) {
    return __mm_exp_pd(
      arg0,
    );
  }

  late final __mm_exp_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d)>>('_mm_exp_pd');
  late final __mm_exp_pd = __mm_exp_pdPtr.asFunction<_m128d Function(_m128d)>();

  __m256 _mm256_exp_ps(
    __m256 arg0,
  ) {
    return __mm256_exp_ps(
      arg0,
    );
  }

  late final __mm256_exp_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256)>>('_mm256_exp_ps');
  late final __mm256_exp_ps =
      __mm256_exp_psPtr.asFunction<__m256 Function(__m256)>();

  _m256d _mm256_exp_pd(
    _m256d arg0,
  ) {
    return __mm256_exp_pd(
      arg0,
    );
  }

  late final __mm256_exp_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d)>>('_mm256_exp_pd');
  late final __mm256_exp_pd =
      __mm256_exp_pdPtr.asFunction<_m256d Function(_m256d)>();

  __m128 _mm_exp10_ps(
    __m128 arg0,
  ) {
    return __mm_exp10_ps(
      arg0,
    );
  }

  late final __mm_exp10_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128)>>('_mm_exp10_ps');
  late final __mm_exp10_ps =
      __mm_exp10_psPtr.asFunction<__m128 Function(__m128)>();

  _m128d _mm_exp10_pd(
    _m128d arg0,
  ) {
    return __mm_exp10_pd(
      arg0,
    );
  }

  late final __mm_exp10_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d)>>('_mm_exp10_pd');
  late final __mm_exp10_pd =
      __mm_exp10_pdPtr.asFunction<_m128d Function(_m128d)>();

  __m256 _mm256_exp10_ps(
    __m256 arg0,
  ) {
    return __mm256_exp10_ps(
      arg0,
    );
  }

  late final __mm256_exp10_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256)>>('_mm256_exp10_ps');
  late final __mm256_exp10_ps =
      __mm256_exp10_psPtr.asFunction<__m256 Function(__m256)>();

  _m256d _mm256_exp10_pd(
    _m256d arg0,
  ) {
    return __mm256_exp10_pd(
      arg0,
    );
  }

  late final __mm256_exp10_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d)>>('_mm256_exp10_pd');
  late final __mm256_exp10_pd =
      __mm256_exp10_pdPtr.asFunction<_m256d Function(_m256d)>();

  __m128 _mm_exp2_ps(
    __m128 arg0,
  ) {
    return __mm_exp2_ps(
      arg0,
    );
  }

  late final __mm_exp2_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128)>>('_mm_exp2_ps');
  late final __mm_exp2_ps =
      __mm_exp2_psPtr.asFunction<__m128 Function(__m128)>();

  _m128d _mm_exp2_pd(
    _m128d arg0,
  ) {
    return __mm_exp2_pd(
      arg0,
    );
  }

  late final __mm_exp2_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d)>>('_mm_exp2_pd');
  late final __mm_exp2_pd =
      __mm_exp2_pdPtr.asFunction<_m128d Function(_m128d)>();

  __m256 _mm256_exp2_ps(
    __m256 arg0,
  ) {
    return __mm256_exp2_ps(
      arg0,
    );
  }

  late final __mm256_exp2_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256)>>('_mm256_exp2_ps');
  late final __mm256_exp2_ps =
      __mm256_exp2_psPtr.asFunction<__m256 Function(__m256)>();

  _m256d _mm256_exp2_pd(
    _m256d arg0,
  ) {
    return __mm256_exp2_pd(
      arg0,
    );
  }

  late final __mm256_exp2_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d)>>('_mm256_exp2_pd');
  late final __mm256_exp2_pd =
      __mm256_exp2_pdPtr.asFunction<_m256d Function(_m256d)>();

  __m128 _mm_expm1_ps(
    __m128 arg0,
  ) {
    return __mm_expm1_ps(
      arg0,
    );
  }

  late final __mm_expm1_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128)>>('_mm_expm1_ps');
  late final __mm_expm1_ps =
      __mm_expm1_psPtr.asFunction<__m128 Function(__m128)>();

  _m128d _mm_expm1_pd(
    _m128d arg0,
  ) {
    return __mm_expm1_pd(
      arg0,
    );
  }

  late final __mm_expm1_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d)>>('_mm_expm1_pd');
  late final __mm_expm1_pd =
      __mm_expm1_pdPtr.asFunction<_m128d Function(_m128d)>();

  __m256 _mm256_expm1_ps(
    __m256 arg0,
  ) {
    return __mm256_expm1_ps(
      arg0,
    );
  }

  late final __mm256_expm1_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256)>>('_mm256_expm1_ps');
  late final __mm256_expm1_ps =
      __mm256_expm1_psPtr.asFunction<__m256 Function(__m256)>();

  _m256d _mm256_expm1_pd(
    _m256d arg0,
  ) {
    return __mm256_expm1_pd(
      arg0,
    );
  }

  late final __mm256_expm1_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d)>>('_mm256_expm1_pd');
  late final __mm256_expm1_pd =
      __mm256_expm1_pdPtr.asFunction<_m256d Function(_m256d)>();

  __m128 _mm_pow_ps(
    __m128 arg0,
    __m128 arg1,
  ) {
    return __mm_pow_ps(
      arg0,
      arg1,
    );
  }

  late final __mm_pow_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128)>>(
          '_mm_pow_ps');
  late final __mm_pow_ps =
      __mm_pow_psPtr.asFunction<__m128 Function(__m128, __m128)>();

  _m128d _mm_pow_pd(
    _m128d arg0,
    _m128d arg1,
  ) {
    return __mm_pow_pd(
      arg0,
      arg1,
    );
  }

  late final __mm_pow_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d)>>(
          '_mm_pow_pd');
  late final __mm_pow_pd =
      __mm_pow_pdPtr.asFunction<_m128d Function(_m128d, _m128d)>();

  __m256 _mm256_pow_ps(
    __m256 arg0,
    __m256 arg1,
  ) {
    return __mm256_pow_ps(
      arg0,
      arg1,
    );
  }

  late final __mm256_pow_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256, __m256)>>(
          '_mm256_pow_ps');
  late final __mm256_pow_ps =
      __mm256_pow_psPtr.asFunction<__m256 Function(__m256, __m256)>();

  _m256d _mm256_pow_pd(
    _m256d arg0,
    _m256d arg1,
  ) {
    return __mm256_pow_pd(
      arg0,
      arg1,
    );
  }

  late final __mm256_pow_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d, _m256d)>>(
          '_mm256_pow_pd');
  late final __mm256_pow_pd =
      __mm256_pow_pdPtr.asFunction<_m256d Function(_m256d, _m256d)>();

  __m128 _mm_trunc_ps(
    __m128 arg0,
  ) {
    return __mm_trunc_ps(
      arg0,
    );
  }

  late final __mm_trunc_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128)>>('_mm_trunc_ps');
  late final __mm_trunc_ps =
      __mm_trunc_psPtr.asFunction<__m128 Function(__m128)>();

  _m128d _mm_trunc_pd(
    _m128d arg0,
  ) {
    return __mm_trunc_pd(
      arg0,
    );
  }

  late final __mm_trunc_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d)>>('_mm_trunc_pd');
  late final __mm_trunc_pd =
      __mm_trunc_pdPtr.asFunction<_m128d Function(_m128d)>();

  __m256 _mm256_trunc_ps(
    __m256 arg0,
  ) {
    return __mm256_trunc_ps(
      arg0,
    );
  }

  late final __mm256_trunc_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256)>>('_mm256_trunc_ps');
  late final __mm256_trunc_ps =
      __mm256_trunc_psPtr.asFunction<__m256 Function(__m256)>();

  _m256d _mm256_trunc_pd(
    _m256d arg0,
  ) {
    return __mm256_trunc_pd(
      arg0,
    );
  }

  late final __mm256_trunc_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d)>>('_mm256_trunc_pd');
  late final __mm256_trunc_pd =
      __mm256_trunc_pdPtr.asFunction<_m256d Function(_m256d)>();

  __m128 _mm_svml_floor_ps(
    __m128 arg0,
  ) {
    return __mm_svml_floor_ps(
      arg0,
    );
  }

  late final __mm_svml_floor_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128)>>('_mm_svml_floor_ps');
  late final __mm_svml_floor_ps =
      __mm_svml_floor_psPtr.asFunction<__m128 Function(__m128)>();

  _m128d _mm_svml_floor_pd(
    _m128d arg0,
  ) {
    return __mm_svml_floor_pd(
      arg0,
    );
  }

  late final __mm_svml_floor_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d)>>('_mm_svml_floor_pd');
  late final __mm_svml_floor_pd =
      __mm_svml_floor_pdPtr.asFunction<_m128d Function(_m128d)>();

  __m256 _mm256_svml_floor_ps(
    __m256 arg0,
  ) {
    return __mm256_svml_floor_ps(
      arg0,
    );
  }

  late final __mm256_svml_floor_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256)>>(
          '_mm256_svml_floor_ps');
  late final __mm256_svml_floor_ps =
      __mm256_svml_floor_psPtr.asFunction<__m256 Function(__m256)>();

  _m256d _mm256_svml_floor_pd(
    _m256d arg0,
  ) {
    return __mm256_svml_floor_pd(
      arg0,
    );
  }

  late final __mm256_svml_floor_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d)>>(
          '_mm256_svml_floor_pd');
  late final __mm256_svml_floor_pd =
      __mm256_svml_floor_pdPtr.asFunction<_m256d Function(_m256d)>();

  __m128 _mm_svml_ceil_ps(
    __m128 arg0,
  ) {
    return __mm_svml_ceil_ps(
      arg0,
    );
  }

  late final __mm_svml_ceil_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128)>>('_mm_svml_ceil_ps');
  late final __mm_svml_ceil_ps =
      __mm_svml_ceil_psPtr.asFunction<__m128 Function(__m128)>();

  _m128d _mm_svml_ceil_pd(
    _m128d arg0,
  ) {
    return __mm_svml_ceil_pd(
      arg0,
    );
  }

  late final __mm_svml_ceil_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d)>>('_mm_svml_ceil_pd');
  late final __mm_svml_ceil_pd =
      __mm_svml_ceil_pdPtr.asFunction<_m128d Function(_m128d)>();

  __m256 _mm256_svml_ceil_ps(
    __m256 arg0,
  ) {
    return __mm256_svml_ceil_ps(
      arg0,
    );
  }

  late final __mm256_svml_ceil_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256)>>(
          '_mm256_svml_ceil_ps');
  late final __mm256_svml_ceil_ps =
      __mm256_svml_ceil_psPtr.asFunction<__m256 Function(__m256)>();

  _m256d _mm256_svml_ceil_pd(
    _m256d arg0,
  ) {
    return __mm256_svml_ceil_pd(
      arg0,
    );
  }

  late final __mm256_svml_ceil_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d)>>(
          '_mm256_svml_ceil_pd');
  late final __mm256_svml_ceil_pd =
      __mm256_svml_ceil_pdPtr.asFunction<_m256d Function(_m256d)>();

  __m128 _mm_svml_round_ps(
    __m128 arg0,
  ) {
    return __mm_svml_round_ps(
      arg0,
    );
  }

  late final __mm_svml_round_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128)>>('_mm_svml_round_ps');
  late final __mm_svml_round_ps =
      __mm_svml_round_psPtr.asFunction<__m128 Function(__m128)>();

  _m128d _mm_svml_round_pd(
    _m128d arg0,
  ) {
    return __mm_svml_round_pd(
      arg0,
    );
  }

  late final __mm_svml_round_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d)>>('_mm_svml_round_pd');
  late final __mm_svml_round_pd =
      __mm_svml_round_pdPtr.asFunction<_m128d Function(_m128d)>();

  __m256 _mm256_svml_round_ps(
    __m256 arg0,
  ) {
    return __mm256_svml_round_ps(
      arg0,
    );
  }

  late final __mm256_svml_round_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256)>>(
          '_mm256_svml_round_ps');
  late final __mm256_svml_round_ps =
      __mm256_svml_round_psPtr.asFunction<__m256 Function(__m256)>();

  _m256d _mm256_svml_round_pd(
    _m256d arg0,
  ) {
    return __mm256_svml_round_pd(
      arg0,
    );
  }

  late final __mm256_svml_round_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d)>>(
          '_mm256_svml_round_pd');
  late final __mm256_svml_round_pd =
      __mm256_svml_round_pdPtr.asFunction<_m256d Function(_m256d)>();

  __m128 _mm_fmod_ps(
    __m128 arg0,
    __m128 arg1,
  ) {
    return __mm_fmod_ps(
      arg0,
      arg1,
    );
  }

  late final __mm_fmod_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128)>>(
          '_mm_fmod_ps');
  late final __mm_fmod_ps =
      __mm_fmod_psPtr.asFunction<__m128 Function(__m128, __m128)>();

  _m128d _mm_fmod_pd(
    _m128d arg0,
    _m128d arg1,
  ) {
    return __mm_fmod_pd(
      arg0,
      arg1,
    );
  }

  late final __mm_fmod_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d)>>(
          '_mm_fmod_pd');
  late final __mm_fmod_pd =
      __mm_fmod_pdPtr.asFunction<_m128d Function(_m128d, _m128d)>();

  __m256 _mm256_fmod_ps(
    __m256 arg0,
    __m256 arg1,
  ) {
    return __mm256_fmod_ps(
      arg0,
      arg1,
    );
  }

  late final __mm256_fmod_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256, __m256)>>(
          '_mm256_fmod_ps');
  late final __mm256_fmod_ps =
      __mm256_fmod_psPtr.asFunction<__m256 Function(__m256, __m256)>();

  _m256d _mm256_fmod_pd(
    _m256d arg0,
    _m256d arg1,
  ) {
    return __mm256_fmod_pd(
      arg0,
      arg1,
    );
  }

  late final __mm256_fmod_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d, _m256d)>>(
          '_mm256_fmod_pd');
  late final __mm256_fmod_pd =
      __mm256_fmod_pdPtr.asFunction<_m256d Function(_m256d, _m256d)>();

  __m128 _mm_svml_sqrt_ps(
    __m128 arg0,
  ) {
    return __mm_svml_sqrt_ps(
      arg0,
    );
  }

  late final __mm_svml_sqrt_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128)>>('_mm_svml_sqrt_ps');
  late final __mm_svml_sqrt_ps =
      __mm_svml_sqrt_psPtr.asFunction<__m128 Function(__m128)>();

  _m128d _mm_svml_sqrt_pd(
    _m128d arg0,
  ) {
    return __mm_svml_sqrt_pd(
      arg0,
    );
  }

  late final __mm_svml_sqrt_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d)>>('_mm_svml_sqrt_pd');
  late final __mm_svml_sqrt_pd =
      __mm_svml_sqrt_pdPtr.asFunction<_m128d Function(_m128d)>();

  __m256 _mm256_svml_sqrt_ps(
    __m256 arg0,
  ) {
    return __mm256_svml_sqrt_ps(
      arg0,
    );
  }

  late final __mm256_svml_sqrt_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256)>>(
          '_mm256_svml_sqrt_ps');
  late final __mm256_svml_sqrt_ps =
      __mm256_svml_sqrt_psPtr.asFunction<__m256 Function(__m256)>();

  _m256d _mm256_svml_sqrt_pd(
    _m256d arg0,
  ) {
    return __mm256_svml_sqrt_pd(
      arg0,
    );
  }

  late final __mm256_svml_sqrt_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d)>>(
          '_mm256_svml_sqrt_pd');
  late final __mm256_svml_sqrt_pd =
      __mm256_svml_sqrt_pdPtr.asFunction<_m256d Function(_m256d)>();

  __m128 _mm_invsqrt_ps(
    __m128 arg0,
  ) {
    return __mm_invsqrt_ps(
      arg0,
    );
  }

  late final __mm_invsqrt_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128)>>('_mm_invsqrt_ps');
  late final __mm_invsqrt_ps =
      __mm_invsqrt_psPtr.asFunction<__m128 Function(__m128)>();

  _m128d _mm_invsqrt_pd(
    _m128d arg0,
  ) {
    return __mm_invsqrt_pd(
      arg0,
    );
  }

  late final __mm_invsqrt_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d)>>('_mm_invsqrt_pd');
  late final __mm_invsqrt_pd =
      __mm_invsqrt_pdPtr.asFunction<_m128d Function(_m128d)>();

  __m256 _mm256_invsqrt_ps(
    __m256 arg0,
  ) {
    return __mm256_invsqrt_ps(
      arg0,
    );
  }

  late final __mm256_invsqrt_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256)>>('_mm256_invsqrt_ps');
  late final __mm256_invsqrt_ps =
      __mm256_invsqrt_psPtr.asFunction<__m256 Function(__m256)>();

  _m256d _mm256_invsqrt_pd(
    _m256d arg0,
  ) {
    return __mm256_invsqrt_pd(
      arg0,
    );
  }

  late final __mm256_invsqrt_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d)>>('_mm256_invsqrt_pd');
  late final __mm256_invsqrt_pd =
      __mm256_invsqrt_pdPtr.asFunction<_m256d Function(_m256d)>();

  __m128 _mm_cbrt_ps(
    __m128 arg0,
  ) {
    return __mm_cbrt_ps(
      arg0,
    );
  }

  late final __mm_cbrt_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128)>>('_mm_cbrt_ps');
  late final __mm_cbrt_ps =
      __mm_cbrt_psPtr.asFunction<__m128 Function(__m128)>();

  _m128d _mm_cbrt_pd(
    _m128d arg0,
  ) {
    return __mm_cbrt_pd(
      arg0,
    );
  }

  late final __mm_cbrt_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d)>>('_mm_cbrt_pd');
  late final __mm_cbrt_pd =
      __mm_cbrt_pdPtr.asFunction<_m128d Function(_m128d)>();

  __m256 _mm256_cbrt_ps(
    __m256 arg0,
  ) {
    return __mm256_cbrt_ps(
      arg0,
    );
  }

  late final __mm256_cbrt_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256)>>('_mm256_cbrt_ps');
  late final __mm256_cbrt_ps =
      __mm256_cbrt_psPtr.asFunction<__m256 Function(__m256)>();

  _m256d _mm256_cbrt_pd(
    _m256d arg0,
  ) {
    return __mm256_cbrt_pd(
      arg0,
    );
  }

  late final __mm256_cbrt_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d)>>('_mm256_cbrt_pd');
  late final __mm256_cbrt_pd =
      __mm256_cbrt_pdPtr.asFunction<_m256d Function(_m256d)>();

  __m128 _mm_invcbrt_ps(
    __m128 arg0,
  ) {
    return __mm_invcbrt_ps(
      arg0,
    );
  }

  late final __mm_invcbrt_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128)>>('_mm_invcbrt_ps');
  late final __mm_invcbrt_ps =
      __mm_invcbrt_psPtr.asFunction<__m128 Function(__m128)>();

  _m128d _mm_invcbrt_pd(
    _m128d arg0,
  ) {
    return __mm_invcbrt_pd(
      arg0,
    );
  }

  late final __mm_invcbrt_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d)>>('_mm_invcbrt_pd');
  late final __mm_invcbrt_pd =
      __mm_invcbrt_pdPtr.asFunction<_m128d Function(_m128d)>();

  __m256 _mm256_invcbrt_ps(
    __m256 arg0,
  ) {
    return __mm256_invcbrt_ps(
      arg0,
    );
  }

  late final __mm256_invcbrt_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256)>>('_mm256_invcbrt_ps');
  late final __mm256_invcbrt_ps =
      __mm256_invcbrt_psPtr.asFunction<__m256 Function(__m256)>();

  _m256d _mm256_invcbrt_pd(
    _m256d arg0,
  ) {
    return __mm256_invcbrt_pd(
      arg0,
    );
  }

  late final __mm256_invcbrt_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d)>>('_mm256_invcbrt_pd');
  late final __mm256_invcbrt_pd =
      __mm256_invcbrt_pdPtr.asFunction<_m256d Function(_m256d)>();

  __m128 _mm_hypot_ps(
    __m128 arg0,
    __m128 arg1,
  ) {
    return __mm_hypot_ps(
      arg0,
      arg1,
    );
  }

  late final __mm_hypot_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128)>>(
          '_mm_hypot_ps');
  late final __mm_hypot_ps =
      __mm_hypot_psPtr.asFunction<__m128 Function(__m128, __m128)>();

  _m128d _mm_hypot_pd(
    _m128d arg0,
    _m128d arg1,
  ) {
    return __mm_hypot_pd(
      arg0,
      arg1,
    );
  }

  late final __mm_hypot_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d)>>(
          '_mm_hypot_pd');
  late final __mm_hypot_pd =
      __mm_hypot_pdPtr.asFunction<_m128d Function(_m128d, _m128d)>();

  __m256 _mm256_hypot_ps(
    __m256 arg0,
    __m256 arg1,
  ) {
    return __mm256_hypot_ps(
      arg0,
      arg1,
    );
  }

  late final __mm256_hypot_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256, __m256)>>(
          '_mm256_hypot_ps');
  late final __mm256_hypot_ps =
      __mm256_hypot_psPtr.asFunction<__m256 Function(__m256, __m256)>();

  _m256d _mm256_hypot_pd(
    _m256d arg0,
    _m256d arg1,
  ) {
    return __mm256_hypot_pd(
      arg0,
      arg1,
    );
  }

  late final __mm256_hypot_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d, _m256d)>>(
          '_mm256_hypot_pd');
  late final __mm256_hypot_pd =
      __mm256_hypot_pdPtr.asFunction<_m256d Function(_m256d, _m256d)>();

  __m128 _mm_cdfnorm_ps(
    __m128 arg0,
  ) {
    return __mm_cdfnorm_ps(
      arg0,
    );
  }

  late final __mm_cdfnorm_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128)>>('_mm_cdfnorm_ps');
  late final __mm_cdfnorm_ps =
      __mm_cdfnorm_psPtr.asFunction<__m128 Function(__m128)>();

  _m128d _mm_cdfnorm_pd(
    _m128d arg0,
  ) {
    return __mm_cdfnorm_pd(
      arg0,
    );
  }

  late final __mm_cdfnorm_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d)>>('_mm_cdfnorm_pd');
  late final __mm_cdfnorm_pd =
      __mm_cdfnorm_pdPtr.asFunction<_m128d Function(_m128d)>();

  __m256 _mm256_cdfnorm_ps(
    __m256 arg0,
  ) {
    return __mm256_cdfnorm_ps(
      arg0,
    );
  }

  late final __mm256_cdfnorm_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256)>>('_mm256_cdfnorm_ps');
  late final __mm256_cdfnorm_ps =
      __mm256_cdfnorm_psPtr.asFunction<__m256 Function(__m256)>();

  _m256d _mm256_cdfnorm_pd(
    _m256d arg0,
  ) {
    return __mm256_cdfnorm_pd(
      arg0,
    );
  }

  late final __mm256_cdfnorm_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d)>>('_mm256_cdfnorm_pd');
  late final __mm256_cdfnorm_pd =
      __mm256_cdfnorm_pdPtr.asFunction<_m256d Function(_m256d)>();

  __m128 _mm_cdfnorminv_ps(
    __m128 arg0,
  ) {
    return __mm_cdfnorminv_ps(
      arg0,
    );
  }

  late final __mm_cdfnorminv_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128)>>('_mm_cdfnorminv_ps');
  late final __mm_cdfnorminv_ps =
      __mm_cdfnorminv_psPtr.asFunction<__m128 Function(__m128)>();

  _m128d _mm_cdfnorminv_pd(
    _m128d arg0,
  ) {
    return __mm_cdfnorminv_pd(
      arg0,
    );
  }

  late final __mm_cdfnorminv_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d)>>('_mm_cdfnorminv_pd');
  late final __mm_cdfnorminv_pd =
      __mm_cdfnorminv_pdPtr.asFunction<_m128d Function(_m128d)>();

  __m256 _mm256_cdfnorminv_ps(
    __m256 arg0,
  ) {
    return __mm256_cdfnorminv_ps(
      arg0,
    );
  }

  late final __mm256_cdfnorminv_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256)>>(
          '_mm256_cdfnorminv_ps');
  late final __mm256_cdfnorminv_ps =
      __mm256_cdfnorminv_psPtr.asFunction<__m256 Function(__m256)>();

  _m256d _mm256_cdfnorminv_pd(
    _m256d arg0,
  ) {
    return __mm256_cdfnorminv_pd(
      arg0,
    );
  }

  late final __mm256_cdfnorminv_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d)>>(
          '_mm256_cdfnorminv_pd');
  late final __mm256_cdfnorminv_pd =
      __mm256_cdfnorminv_pdPtr.asFunction<_m256d Function(_m256d)>();

  __m128 _mm_cexp_ps(
    __m128 arg0,
  ) {
    return __mm_cexp_ps(
      arg0,
    );
  }

  late final __mm_cexp_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128)>>('_mm_cexp_ps');
  late final __mm_cexp_ps =
      __mm_cexp_psPtr.asFunction<__m128 Function(__m128)>();

  __m256 _mm256_cexp_ps(
    __m256 arg0,
  ) {
    return __mm256_cexp_ps(
      arg0,
    );
  }

  late final __mm256_cexp_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256)>>('_mm256_cexp_ps');
  late final __mm256_cexp_ps =
      __mm256_cexp_psPtr.asFunction<__m256 Function(__m256)>();

  __m128 _mm_clog_ps(
    __m128 arg0,
  ) {
    return __mm_clog_ps(
      arg0,
    );
  }

  late final __mm_clog_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128)>>('_mm_clog_ps');
  late final __mm_clog_ps =
      __mm_clog_psPtr.asFunction<__m128 Function(__m128)>();

  __m256 _mm256_clog_ps(
    __m256 arg0,
  ) {
    return __mm256_clog_ps(
      arg0,
    );
  }

  late final __mm256_clog_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256)>>('_mm256_clog_ps');
  late final __mm256_clog_ps =
      __mm256_clog_psPtr.asFunction<__m256 Function(__m256)>();

  __m128 _mm_csqrt_ps(
    __m128 arg0,
  ) {
    return __mm_csqrt_ps(
      arg0,
    );
  }

  late final __mm_csqrt_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128)>>('_mm_csqrt_ps');
  late final __mm_csqrt_ps =
      __mm_csqrt_psPtr.asFunction<__m128 Function(__m128)>();

  __m256 _mm256_csqrt_ps(
    __m256 arg0,
  ) {
    return __mm256_csqrt_ps(
      arg0,
    );
  }

  late final __mm256_csqrt_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256)>>('_mm256_csqrt_ps');
  late final __mm256_csqrt_ps =
      __mm256_csqrt_psPtr.asFunction<__m256 Function(__m256)>();

  __m128 _mm_erf_ps(
    __m128 arg0,
  ) {
    return __mm_erf_ps(
      arg0,
    );
  }

  late final __mm_erf_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128)>>('_mm_erf_ps');
  late final __mm_erf_ps = __mm_erf_psPtr.asFunction<__m128 Function(__m128)>();

  _m128d _mm_erf_pd(
    _m128d arg0,
  ) {
    return __mm_erf_pd(
      arg0,
    );
  }

  late final __mm_erf_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d)>>('_mm_erf_pd');
  late final __mm_erf_pd = __mm_erf_pdPtr.asFunction<_m128d Function(_m128d)>();

  __m256 _mm256_erf_ps(
    __m256 arg0,
  ) {
    return __mm256_erf_ps(
      arg0,
    );
  }

  late final __mm256_erf_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256)>>('_mm256_erf_ps');
  late final __mm256_erf_ps =
      __mm256_erf_psPtr.asFunction<__m256 Function(__m256)>();

  _m256d _mm256_erf_pd(
    _m256d arg0,
  ) {
    return __mm256_erf_pd(
      arg0,
    );
  }

  late final __mm256_erf_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d)>>('_mm256_erf_pd');
  late final __mm256_erf_pd =
      __mm256_erf_pdPtr.asFunction<_m256d Function(_m256d)>();

  __m128 _mm_erfc_ps(
    __m128 arg0,
  ) {
    return __mm_erfc_ps(
      arg0,
    );
  }

  late final __mm_erfc_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128)>>('_mm_erfc_ps');
  late final __mm_erfc_ps =
      __mm_erfc_psPtr.asFunction<__m128 Function(__m128)>();

  _m128d _mm_erfc_pd(
    _m128d arg0,
  ) {
    return __mm_erfc_pd(
      arg0,
    );
  }

  late final __mm_erfc_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d)>>('_mm_erfc_pd');
  late final __mm_erfc_pd =
      __mm_erfc_pdPtr.asFunction<_m128d Function(_m128d)>();

  __m256 _mm256_erfc_ps(
    __m256 arg0,
  ) {
    return __mm256_erfc_ps(
      arg0,
    );
  }

  late final __mm256_erfc_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256)>>('_mm256_erfc_ps');
  late final __mm256_erfc_ps =
      __mm256_erfc_psPtr.asFunction<__m256 Function(__m256)>();

  _m256d _mm256_erfc_pd(
    _m256d arg0,
  ) {
    return __mm256_erfc_pd(
      arg0,
    );
  }

  late final __mm256_erfc_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d)>>('_mm256_erfc_pd');
  late final __mm256_erfc_pd =
      __mm256_erfc_pdPtr.asFunction<_m256d Function(_m256d)>();

  __m128 _mm_erfcinv_ps(
    __m128 arg0,
  ) {
    return __mm_erfcinv_ps(
      arg0,
    );
  }

  late final __mm_erfcinv_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128)>>('_mm_erfcinv_ps');
  late final __mm_erfcinv_ps =
      __mm_erfcinv_psPtr.asFunction<__m128 Function(__m128)>();

  _m128d _mm_erfcinv_pd(
    _m128d arg0,
  ) {
    return __mm_erfcinv_pd(
      arg0,
    );
  }

  late final __mm_erfcinv_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d)>>('_mm_erfcinv_pd');
  late final __mm_erfcinv_pd =
      __mm_erfcinv_pdPtr.asFunction<_m128d Function(_m128d)>();

  __m256 _mm256_erfcinv_ps(
    __m256 arg0,
  ) {
    return __mm256_erfcinv_ps(
      arg0,
    );
  }

  late final __mm256_erfcinv_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256)>>('_mm256_erfcinv_ps');
  late final __mm256_erfcinv_ps =
      __mm256_erfcinv_psPtr.asFunction<__m256 Function(__m256)>();

  _m256d _mm256_erfcinv_pd(
    _m256d arg0,
  ) {
    return __mm256_erfcinv_pd(
      arg0,
    );
  }

  late final __mm256_erfcinv_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d)>>('_mm256_erfcinv_pd');
  late final __mm256_erfcinv_pd =
      __mm256_erfcinv_pdPtr.asFunction<_m256d Function(_m256d)>();

  __m128 _mm_erfinv_ps(
    __m128 arg0,
  ) {
    return __mm_erfinv_ps(
      arg0,
    );
  }

  late final __mm_erfinv_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128)>>('_mm_erfinv_ps');
  late final __mm_erfinv_ps =
      __mm_erfinv_psPtr.asFunction<__m128 Function(__m128)>();

  _m128d _mm_erfinv_pd(
    _m128d arg0,
  ) {
    return __mm_erfinv_pd(
      arg0,
    );
  }

  late final __mm_erfinv_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d)>>('_mm_erfinv_pd');
  late final __mm_erfinv_pd =
      __mm_erfinv_pdPtr.asFunction<_m128d Function(_m128d)>();

  __m256 _mm256_erfinv_ps(
    __m256 arg0,
  ) {
    return __mm256_erfinv_ps(
      arg0,
    );
  }

  late final __mm256_erfinv_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256)>>('_mm256_erfinv_ps');
  late final __mm256_erfinv_ps =
      __mm256_erfinv_psPtr.asFunction<__m256 Function(__m256)>();

  _m256d _mm256_erfinv_pd(
    _m256d arg0,
  ) {
    return __mm256_erfinv_pd(
      arg0,
    );
  }

  late final __mm256_erfinv_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d)>>('_mm256_erfinv_pd');
  late final __mm256_erfinv_pd =
      __mm256_erfinv_pdPtr.asFunction<_m256d Function(_m256d)>();

  void _mm_cldemote(
    ffi.Pointer<ffi.Void> arg0,
  ) {
    return __mm_cldemote(
      arg0,
    );
  }

  late final __mm_cldemotePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ffi.Void>)>>(
          '_mm_cldemote');
  late final __mm_cldemote =
      __mm_cldemotePtr.asFunction<void Function(ffi.Pointer<ffi.Void>)>();

  void _directstoreu_u32(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
  ) {
    return __directstoreu_u32(
      arg0,
      arg1,
    );
  }

  late final __directstoreu_u32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<ffi.Void>, ffi.Uint32)>>('_directstoreu_u32');
  late final __directstoreu_u32 = __directstoreu_u32Ptr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, int)>();

  void _directstoreu_u64(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
  ) {
    return __directstoreu_u64(
      arg0,
      arg1,
    );
  }

  late final __directstoreu_u64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<ffi.Void>, ffi.Uint64)>>('_directstoreu_u64');
  late final __directstoreu_u64 = __directstoreu_u64Ptr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, int)>();

  void _movdir64b(
    ffi.Pointer<ffi.Void> arg0,
    ffi.Pointer<ffi.Void> arg1,
  ) {
    return __movdir64b(
      arg0,
      arg1,
    );
  }

  late final __movdir64bPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<ffi.Void>, ffi.Pointer<ffi.Void>)>>('_movdir64b');
  late final __movdir64b = __movdir64bPtr.asFunction<
      void Function(ffi.Pointer<ffi.Void>, ffi.Pointer<ffi.Void>)>();

  void _serialize() {
    return __serialize();
  }

  late final __serializePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('_serialize');
  late final __serialize = __serializePtr.asFunction<void Function()>();

  void _xsusldtrk() {
    return __xsusldtrk();
  }

  late final __xsusldtrkPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('_xsusldtrk');
  late final __xsusldtrk = __xsusldtrkPtr.asFunction<void Function()>();

  void _xresldtrk() {
    return __xresldtrk();
  }

  late final __xresldtrkPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('_xresldtrk');
  late final __xresldtrk = __xresldtrkPtr.asFunction<void Function()>();

  void _umonitor(
    ffi.Pointer<ffi.Void> arg0,
  ) {
    return __umonitor(
      arg0,
    );
  }

  late final __umonitorPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ffi.Void>)>>(
          '_umonitor');
  late final __umonitor =
      __umonitorPtr.asFunction<void Function(ffi.Pointer<ffi.Void>)>();

  int _umwait(
    int arg0,
    int arg1,
  ) {
    return __umwait(
      arg0,
      arg1,
    );
  }

  late final __umwaitPtr =
      _lookup<ffi.NativeFunction<ffi.Uint8 Function(ffi.Uint32, ffi.Uint64)>>(
          '_umwait');
  late final __umwait = __umwaitPtr.asFunction<int Function(int, int)>();

  int _tpause(
    int arg0,
    int arg1,
  ) {
    return __tpause(
      arg0,
      arg1,
    );
  }

  late final __tpausePtr =
      _lookup<ffi.NativeFunction<ffi.Uint8 Function(ffi.Uint32, ffi.Uint64)>>(
          '_tpause');
  late final __tpause = __tpausePtr.asFunction<int Function(int, int)>();

  void _clui() {
    return __clui();
  }

  late final __cluiPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('_clui');
  late final __clui = __cluiPtr.asFunction<void Function()>();

  void _stui() {
    return __stui();
  }

  late final __stuiPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('_stui');
  late final __stui = __stuiPtr.asFunction<void Function()>();

  int _testui() {
    return __testui();
  }

  late final __testuiPtr =
      _lookup<ffi.NativeFunction<ffi.Uint8 Function()>>('_testui');
  late final __testui = __testuiPtr.asFunction<int Function()>();

  void _senduipi(
    int arg0,
  ) {
    return __senduipi(
      arg0,
    );
  }

  late final __senduipiPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Uint64)>>('_senduipi');
  late final __senduipi = __senduipiPtr.asFunction<void Function(int)>();

  void _hreset(
    int arg0,
  ) {
    return __hreset(
      arg0,
    );
  }

  late final __hresetPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Uint32)>>('_hreset');
  late final __hreset = __hresetPtr.asFunction<void Function(int)>();

  __m128 _mm_svml_cvtepu32_ps(
    __m128i arg0,
  ) {
    return __mm_svml_cvtepu32_ps(
      arg0,
    );
  }

  late final __mm_svml_cvtepu32_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128i)>>(
          '_mm_svml_cvtepu32_ps');
  late final __mm_svml_cvtepu32_ps =
      __mm_svml_cvtepu32_psPtr.asFunction<__m128 Function(__m128i)>();

  __m256 _mm256_svml_cvtepu32_ps(
    __m256i arg0,
  ) {
    return __mm256_svml_cvtepu32_ps(
      arg0,
    );
  }

  late final __mm256_svml_cvtepu32_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256i)>>(
          '_mm256_svml_cvtepu32_ps');
  late final __mm256_svml_cvtepu32_ps =
      __mm256_svml_cvtepu32_psPtr.asFunction<__m256 Function(__m256i)>();

  _m128d _mm_svml_cvtepu32_pd(
    __m128i arg0,
  ) {
    return __mm_svml_cvtepu32_pd(
      arg0,
    );
  }

  late final __mm_svml_cvtepu32_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(__m128i)>>(
          '_mm_svml_cvtepu32_pd');
  late final __mm_svml_cvtepu32_pd =
      __mm_svml_cvtepu32_pdPtr.asFunction<_m128d Function(__m128i)>();

  _m256d _mm256_svml_cvtepu32_pd(
    __m128i arg0,
  ) {
    return __mm256_svml_cvtepu32_pd(
      arg0,
    );
  }

  late final __mm256_svml_cvtepu32_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(__m128i)>>(
          '_mm256_svml_cvtepu32_pd');
  late final __mm256_svml_cvtepu32_pd =
      __mm256_svml_cvtepu32_pdPtr.asFunction<_m256d Function(__m128i)>();

  _m128d _mm_svml_cvtepi64_pd(
    __m128i arg0,
  ) {
    return __mm_svml_cvtepi64_pd(
      arg0,
    );
  }

  late final __mm_svml_cvtepi64_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(__m128i)>>(
          '_mm_svml_cvtepi64_pd');
  late final __mm_svml_cvtepi64_pd =
      __mm_svml_cvtepi64_pdPtr.asFunction<_m128d Function(__m128i)>();

  _m256d _mm256_svml_cvtepi64_pd(
    __m256i arg0,
  ) {
    return __mm256_svml_cvtepi64_pd(
      arg0,
    );
  }

  late final __mm256_svml_cvtepi64_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(__m256i)>>(
          '_mm256_svml_cvtepi64_pd');
  late final __mm256_svml_cvtepi64_pd =
      __mm256_svml_cvtepi64_pdPtr.asFunction<_m256d Function(__m256i)>();

  _m128d _mm_svml_cvtepu64_pd(
    __m128i arg0,
  ) {
    return __mm_svml_cvtepu64_pd(
      arg0,
    );
  }

  late final __mm_svml_cvtepu64_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(__m128i)>>(
          '_mm_svml_cvtepu64_pd');
  late final __mm_svml_cvtepu64_pd =
      __mm_svml_cvtepu64_pdPtr.asFunction<_m128d Function(__m128i)>();

  _m256d _mm256_svml_cvtepu64_pd(
    __m256i arg0,
  ) {
    return __mm256_svml_cvtepu64_pd(
      arg0,
    );
  }

  late final __mm256_svml_cvtepu64_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(__m256i)>>(
          '_mm256_svml_cvtepu64_pd');
  late final __mm256_svml_cvtepu64_pd =
      __mm256_svml_cvtepu64_pdPtr.asFunction<_m256d Function(__m256i)>();

  __m256 _mm512_castps512_ps256(
    __m512 arg0,
  ) {
    return __mm512_castps512_ps256(
      arg0,
    );
  }

  late final __mm512_castps512_ps256Ptr =
      _lookup<ffi.NativeFunction<__m256 Function(__m512)>>(
          '_mm512_castps512_ps256');
  late final __mm512_castps512_ps256 =
      __mm512_castps512_ps256Ptr.asFunction<__m256 Function(__m512)>();

  __m512 _mm512_castpd_ps(
    _m512d arg0,
  ) {
    return __mm512_castpd_ps(
      arg0,
    );
  }

  late final __mm512_castpd_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(_m512d)>>('_mm512_castpd_ps');
  late final __mm512_castpd_ps =
      __mm512_castpd_psPtr.asFunction<__m512 Function(_m512d)>();

  __m512 _mm512_castps256_ps512(
    __m256 arg0,
  ) {
    return __mm512_castps256_ps512(
      arg0,
    );
  }

  late final __mm512_castps256_ps512Ptr =
      _lookup<ffi.NativeFunction<__m512 Function(__m256)>>(
          '_mm512_castps256_ps512');
  late final __mm512_castps256_ps512 =
      __mm512_castps256_ps512Ptr.asFunction<__m512 Function(__m256)>();

  __m512 _mm512_castsi512_ps(
    __m512i arg0,
  ) {
    return __mm512_castsi512_ps(
      arg0,
    );
  }

  late final __mm512_castsi512_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512i)>>(
          '_mm512_castsi512_ps');
  late final __mm512_castsi512_ps =
      __mm512_castsi512_psPtr.asFunction<__m512 Function(__m512i)>();

  __m512 _mm512_castps128_ps512(
    __m128 arg0,
  ) {
    return __mm512_castps128_ps512(
      arg0,
    );
  }

  late final __mm512_castps128_ps512Ptr =
      _lookup<ffi.NativeFunction<__m512 Function(__m128)>>(
          '_mm512_castps128_ps512');
  late final __mm512_castps128_ps512 =
      __mm512_castps128_ps512Ptr.asFunction<__m512 Function(__m128)>();

  _m256d _mm512_castpd512_pd256(
    _m512d arg0,
  ) {
    return __mm512_castpd512_pd256(
      arg0,
    );
  }

  late final __mm512_castpd512_pd256Ptr =
      _lookup<ffi.NativeFunction<_m256d Function(_m512d)>>(
          '_mm512_castpd512_pd256');
  late final __mm512_castpd512_pd256 =
      __mm512_castpd512_pd256Ptr.asFunction<_m256d Function(_m512d)>();

  _m512d _mm512_castpd256_pd512(
    _m256d arg0,
  ) {
    return __mm512_castpd256_pd512(
      arg0,
    );
  }

  late final __mm512_castpd256_pd512Ptr =
      _lookup<ffi.NativeFunction<_m512d Function(_m256d)>>(
          '_mm512_castpd256_pd512');
  late final __mm512_castpd256_pd512 =
      __mm512_castpd256_pd512Ptr.asFunction<_m512d Function(_m256d)>();

  _m512d _mm512_castps_pd(
    __m512 arg0,
  ) {
    return __mm512_castps_pd(
      arg0,
    );
  }

  late final __mm512_castps_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(__m512)>>('_mm512_castps_pd');
  late final __mm512_castps_pd =
      __mm512_castps_pdPtr.asFunction<_m512d Function(__m512)>();

  _m512d _mm512_castsi512_pd(
    __m512i arg0,
  ) {
    return __mm512_castsi512_pd(
      arg0,
    );
  }

  late final __mm512_castsi512_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(__m512i)>>(
          '_mm512_castsi512_pd');
  late final __mm512_castsi512_pd =
      __mm512_castsi512_pdPtr.asFunction<_m512d Function(__m512i)>();

  _m512d _mm512_castpd128_pd512(
    _m128d arg0,
  ) {
    return __mm512_castpd128_pd512(
      arg0,
    );
  }

  late final __mm512_castpd128_pd512Ptr =
      _lookup<ffi.NativeFunction<_m512d Function(_m128d)>>(
          '_mm512_castpd128_pd512');
  late final __mm512_castpd128_pd512 =
      __mm512_castpd128_pd512Ptr.asFunction<_m512d Function(_m128d)>();

  __m256i _mm512_castsi512_si256(
    __m512i arg0,
  ) {
    return __mm512_castsi512_si256(
      arg0,
    );
  }

  late final __mm512_castsi512_si256Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m512i)>>(
          '_mm512_castsi512_si256');
  late final __mm512_castsi512_si256 =
      __mm512_castsi512_si256Ptr.asFunction<__m256i Function(__m512i)>();

  __m512i _mm512_castpd_si512(
    _m512d arg0,
  ) {
    return __mm512_castpd_si512(
      arg0,
    );
  }

  late final __mm512_castpd_si512Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(_m512d)>>(
          '_mm512_castpd_si512');
  late final __mm512_castpd_si512 =
      __mm512_castpd_si512Ptr.asFunction<__m512i Function(_m512d)>();

  __m512i _mm512_castps_si512(
    __m512 arg0,
  ) {
    return __mm512_castps_si512(
      arg0,
    );
  }

  late final __mm512_castps_si512Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512)>>(
          '_mm512_castps_si512');
  late final __mm512_castps_si512 =
      __mm512_castps_si512Ptr.asFunction<__m512i Function(__m512)>();

  __m512i _mm512_castsi256_si512(
    __m256i arg0,
  ) {
    return __mm512_castsi256_si512(
      arg0,
    );
  }

  late final __mm512_castsi256_si512Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m256i)>>(
          '_mm512_castsi256_si512');
  late final __mm512_castsi256_si512 =
      __mm512_castsi256_si512Ptr.asFunction<__m512i Function(__m256i)>();

  __m512 _mm512_setzero_ps() {
    return __mm512_setzero_ps();
  }

  late final __mm512_setzero_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function()>>('_mm512_setzero_ps');
  late final __mm512_setzero_ps =
      __mm512_setzero_psPtr.asFunction<__m512 Function()>();

  _m512d _mm512_setzero_pd() {
    return __mm512_setzero_pd();
  }

  late final __mm512_setzero_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function()>>('_mm512_setzero_pd');
  late final __mm512_setzero_pd =
      __mm512_setzero_pdPtr.asFunction<_m512d Function()>();

  __m512 _mm512_set_ps(
    double arg0,
    double arg1,
    double arg2,
    double arg3,
    double arg4,
    double arg5,
    double arg6,
    double arg7,
    double arg8,
    double arg9,
    double arg10,
    double arg11,
    double arg12,
    double arg13,
    double arg14,
    double arg15,
  ) {
    return __mm512_set_ps(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
      arg5,
      arg6,
      arg7,
      arg8,
      arg9,
      arg10,
      arg11,
      arg12,
      arg13,
      arg14,
      arg15,
    );
  }

  late final __mm512_set_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(
              ffi.Float,
              ffi.Float,
              ffi.Float,
              ffi.Float,
              ffi.Float,
              ffi.Float,
              ffi.Float,
              ffi.Float,
              ffi.Float,
              ffi.Float,
              ffi.Float,
              ffi.Float,
              ffi.Float,
              ffi.Float,
              ffi.Float,
              ffi.Float)>>('_mm512_set_ps');
  late final __mm512_set_ps = __mm512_set_psPtr.asFunction<
      __m512 Function(
          double,
          double,
          double,
          double,
          double,
          double,
          double,
          double,
          double,
          double,
          double,
          double,
          double,
          double,
          double,
          double)>();

  _m512d _mm512_set_pd(
    double arg0,
    double arg1,
    double arg2,
    double arg3,
    double arg4,
    double arg5,
    double arg6,
    double arg7,
  ) {
    return __mm512_set_pd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
      arg5,
      arg6,
      arg7,
    );
  }

  late final __mm512_set_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(
              ffi.Double,
              ffi.Double,
              ffi.Double,
              ffi.Double,
              ffi.Double,
              ffi.Double,
              ffi.Double,
              ffi.Double)>>('_mm512_set_pd');
  late final __mm512_set_pd = __mm512_set_pdPtr.asFunction<
      _m512d Function(
          double, double, double, double, double, double, double, double)>();

  __m512 _mm512_setr_ps(
    double arg0,
    double arg1,
    double arg2,
    double arg3,
    double arg4,
    double arg5,
    double arg6,
    double arg7,
    double arg8,
    double arg9,
    double arg10,
    double arg11,
    double arg12,
    double arg13,
    double arg14,
    double arg15,
  ) {
    return __mm512_setr_ps(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
      arg5,
      arg6,
      arg7,
      arg8,
      arg9,
      arg10,
      arg11,
      arg12,
      arg13,
      arg14,
      arg15,
    );
  }

  late final __mm512_setr_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(
              ffi.Float,
              ffi.Float,
              ffi.Float,
              ffi.Float,
              ffi.Float,
              ffi.Float,
              ffi.Float,
              ffi.Float,
              ffi.Float,
              ffi.Float,
              ffi.Float,
              ffi.Float,
              ffi.Float,
              ffi.Float,
              ffi.Float,
              ffi.Float)>>('_mm512_setr_ps');
  late final __mm512_setr_ps = __mm512_setr_psPtr.asFunction<
      __m512 Function(
          double,
          double,
          double,
          double,
          double,
          double,
          double,
          double,
          double,
          double,
          double,
          double,
          double,
          double,
          double,
          double)>();

  _m512d _mm512_setr_pd(
    double arg0,
    double arg1,
    double arg2,
    double arg3,
    double arg4,
    double arg5,
    double arg6,
    double arg7,
  ) {
    return __mm512_setr_pd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
      arg5,
      arg6,
      arg7,
    );
  }

  late final __mm512_setr_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(
              ffi.Double,
              ffi.Double,
              ffi.Double,
              ffi.Double,
              ffi.Double,
              ffi.Double,
              ffi.Double,
              ffi.Double)>>('_mm512_setr_pd');
  late final __mm512_setr_pd = __mm512_setr_pdPtr.asFunction<
      _m512d Function(
          double, double, double, double, double, double, double, double)>();

  __m512 _mm512_set1_ps(
    double arg0,
  ) {
    return __mm512_set1_ps(
      arg0,
    );
  }

  late final __mm512_set1_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(ffi.Float)>>('_mm512_set1_ps');
  late final __mm512_set1_ps =
      __mm512_set1_psPtr.asFunction<__m512 Function(double)>();

  _m512d _mm512_set1_pd(
    double arg0,
  ) {
    return __mm512_set1_pd(
      arg0,
    );
  }

  late final __mm512_set1_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(ffi.Double)>>(
          '_mm512_set1_pd');
  late final __mm512_set1_pd =
      __mm512_set1_pdPtr.asFunction<_m512d Function(double)>();

  __m512 _mm512_load_ps(
    ffi.Pointer<ffi.Void> arg0,
  ) {
    return __mm512_load_ps(
      arg0,
    );
  }

  late final __mm512_load_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(ffi.Pointer<ffi.Void>)>>(
          '_mm512_load_ps');
  late final __mm512_load_ps =
      __mm512_load_psPtr.asFunction<__m512 Function(ffi.Pointer<ffi.Void>)>();

  _m512d _mm512_load_pd(
    ffi.Pointer<ffi.Void> arg0,
  ) {
    return __mm512_load_pd(
      arg0,
    );
  }

  late final __mm512_load_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(ffi.Pointer<ffi.Void>)>>(
          '_mm512_load_pd');
  late final __mm512_load_pd =
      __mm512_load_pdPtr.asFunction<_m512d Function(ffi.Pointer<ffi.Void>)>();

  __m512 _mm512_maskz_load_ps(
    int arg0,
    ffi.Pointer<ffi.Void> arg1,
  ) {
    return __mm512_maskz_load_ps(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_load_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(
              __mmask16, ffi.Pointer<ffi.Void>)>>('_mm512_maskz_load_ps');
  late final __mm512_maskz_load_ps = __mm512_maskz_load_psPtr
      .asFunction<__m512 Function(int, ffi.Pointer<ffi.Void>)>();

  _m512d _mm512_maskz_load_pd(
    int arg0,
    ffi.Pointer<ffi.Void> arg1,
  ) {
    return __mm512_maskz_load_pd(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_load_pdPtr = _lookup<
          ffi.NativeFunction<_m512d Function(__mmask8, ffi.Pointer<ffi.Void>)>>(
      '_mm512_maskz_load_pd');
  late final __mm512_maskz_load_pd = __mm512_maskz_load_pdPtr
      .asFunction<_m512d Function(int, ffi.Pointer<ffi.Void>)>();

  __m512 _mm512_mask_load_ps(
    __m512 arg0,
    int arg1,
    ffi.Pointer<ffi.Void> arg2,
  ) {
    return __mm512_mask_load_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_load_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__m512, __mmask16,
              ffi.Pointer<ffi.Void>)>>('_mm512_mask_load_ps');
  late final __mm512_mask_load_ps = __mm512_mask_load_psPtr
      .asFunction<__m512 Function(__m512, int, ffi.Pointer<ffi.Void>)>();

  _m512d _mm512_mask_load_pd(
    _m512d arg0,
    int arg1,
    ffi.Pointer<ffi.Void> arg2,
  ) {
    return __mm512_mask_load_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_load_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(
              _m512d, __mmask8, ffi.Pointer<ffi.Void>)>>('_mm512_mask_load_pd');
  late final __mm512_mask_load_pd = __mm512_mask_load_pdPtr
      .asFunction<_m512d Function(_m512d, int, ffi.Pointer<ffi.Void>)>();

  __m512 _mm512_loadu_ps(
    ffi.Pointer<ffi.Void> arg0,
  ) {
    return __mm512_loadu_ps(
      arg0,
    );
  }

  late final __mm512_loadu_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(ffi.Pointer<ffi.Void>)>>(
          '_mm512_loadu_ps');
  late final __mm512_loadu_ps =
      __mm512_loadu_psPtr.asFunction<__m512 Function(ffi.Pointer<ffi.Void>)>();

  _m512d _mm512_loadu_pd(
    ffi.Pointer<ffi.Void> arg0,
  ) {
    return __mm512_loadu_pd(
      arg0,
    );
  }

  late final __mm512_loadu_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(ffi.Pointer<ffi.Void>)>>(
          '_mm512_loadu_pd');
  late final __mm512_loadu_pd =
      __mm512_loadu_pdPtr.asFunction<_m512d Function(ffi.Pointer<ffi.Void>)>();

  __m512 _mm512_maskz_loadu_ps(
    int arg0,
    ffi.Pointer<ffi.Void> arg1,
  ) {
    return __mm512_maskz_loadu_ps(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_loadu_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(
              __mmask16, ffi.Pointer<ffi.Void>)>>('_mm512_maskz_loadu_ps');
  late final __mm512_maskz_loadu_ps = __mm512_maskz_loadu_psPtr
      .asFunction<__m512 Function(int, ffi.Pointer<ffi.Void>)>();

  _m512d _mm512_maskz_loadu_pd(
    int arg0,
    ffi.Pointer<ffi.Void> arg1,
  ) {
    return __mm512_maskz_loadu_pd(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_loadu_pdPtr = _lookup<
          ffi.NativeFunction<_m512d Function(__mmask8, ffi.Pointer<ffi.Void>)>>(
      '_mm512_maskz_loadu_pd');
  late final __mm512_maskz_loadu_pd = __mm512_maskz_loadu_pdPtr
      .asFunction<_m512d Function(int, ffi.Pointer<ffi.Void>)>();

  __m512 _mm512_mask_loadu_ps(
    __m512 arg0,
    int arg1,
    ffi.Pointer<ffi.Void> arg2,
  ) {
    return __mm512_mask_loadu_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_loadu_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__m512, __mmask16,
              ffi.Pointer<ffi.Void>)>>('_mm512_mask_loadu_ps');
  late final __mm512_mask_loadu_ps = __mm512_mask_loadu_psPtr
      .asFunction<__m512 Function(__m512, int, ffi.Pointer<ffi.Void>)>();

  _m512d _mm512_mask_loadu_pd(
    _m512d arg0,
    int arg1,
    ffi.Pointer<ffi.Void> arg2,
  ) {
    return __mm512_mask_loadu_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_loadu_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(_m512d, __mmask8,
              ffi.Pointer<ffi.Void>)>>('_mm512_mask_loadu_pd');
  late final __mm512_mask_loadu_pd = __mm512_mask_loadu_pdPtr
      .asFunction<_m512d Function(_m512d, int, ffi.Pointer<ffi.Void>)>();

  void _mm512_store_ps(
    ffi.Pointer<ffi.Void> arg0,
    __m512 arg1,
  ) {
    return __mm512_store_ps(
      arg0,
      arg1,
    );
  }

  late final __mm512_store_psPtr = _lookup<
          ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ffi.Void>, __m512)>>(
      '_mm512_store_ps');
  late final __mm512_store_ps = __mm512_store_psPtr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, __m512)>();

  void _mm512_store_pd(
    ffi.Pointer<ffi.Void> arg0,
    _m512d arg1,
  ) {
    return __mm512_store_pd(
      arg0,
      arg1,
    );
  }

  late final __mm512_store_pdPtr = _lookup<
          ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ffi.Void>, _m512d)>>(
      '_mm512_store_pd');
  late final __mm512_store_pd = __mm512_store_pdPtr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, _m512d)>();

  void _mm512_storeu_ps(
    ffi.Pointer<ffi.Void> arg0,
    __m512 arg1,
  ) {
    return __mm512_storeu_ps(
      arg0,
      arg1,
    );
  }

  late final __mm512_storeu_psPtr = _lookup<
          ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ffi.Void>, __m512)>>(
      '_mm512_storeu_ps');
  late final __mm512_storeu_ps = __mm512_storeu_psPtr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, __m512)>();

  void _mm512_storeu_pd(
    ffi.Pointer<ffi.Void> arg0,
    _m512d arg1,
  ) {
    return __mm512_storeu_pd(
      arg0,
      arg1,
    );
  }

  late final __mm512_storeu_pdPtr = _lookup<
          ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ffi.Void>, _m512d)>>(
      '_mm512_storeu_pd');
  late final __mm512_storeu_pd = __mm512_storeu_pdPtr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, _m512d)>();

  void _mm512_mask_store_ps(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m512 arg2,
  ) {
    return __mm512_mask_store_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_store_psPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask16,
              __m512)>>('_mm512_mask_store_ps');
  late final __mm512_mask_store_ps = __mm512_mask_store_psPtr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m512)>();

  void _mm512_mask_store_pd(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    _m512d arg2,
  ) {
    return __mm512_mask_store_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_store_pdPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8,
              _m512d)>>('_mm512_mask_store_pd');
  late final __mm512_mask_store_pd = __mm512_mask_store_pdPtr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, int, _m512d)>();

  void _mm512_mask_storeu_ps(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m512 arg2,
  ) {
    return __mm512_mask_storeu_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_storeu_psPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask16,
              __m512)>>('_mm512_mask_storeu_ps');
  late final __mm512_mask_storeu_ps = __mm512_mask_storeu_psPtr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m512)>();

  void _mm512_mask_storeu_pd(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    _m512d arg2,
  ) {
    return __mm512_mask_storeu_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_storeu_pdPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8,
              _m512d)>>('_mm512_mask_storeu_pd');
  late final __mm512_mask_storeu_pd = __mm512_mask_storeu_pdPtr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, int, _m512d)>();

  __m512 _mm512_add_ps(
    __m512 arg0,
    __m512 arg1,
  ) {
    return __mm512_add_ps(
      arg0,
      arg1,
    );
  }

  late final __mm512_add_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __m512)>>(
          '_mm512_add_ps');
  late final __mm512_add_ps =
      __mm512_add_psPtr.asFunction<__m512 Function(__m512, __m512)>();

  __m512 _mm512_maskz_add_ps(
    int arg0,
    __m512 arg1,
    __m512 arg2,
  ) {
    return __mm512_maskz_add_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_add_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__mmask16, __m512, __m512)>>(
          '_mm512_maskz_add_ps');
  late final __mm512_maskz_add_ps = __mm512_maskz_add_psPtr
      .asFunction<__m512 Function(int, __m512, __m512)>();

  __m512 _mm512_mask_add_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
    __m512 arg3,
  ) {
    return __mm512_mask_add_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_add_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(
              __m512, __mmask16, __m512, __m512)>>('_mm512_mask_add_ps');
  late final __mm512_mask_add_ps = __mm512_mask_add_psPtr
      .asFunction<__m512 Function(__m512, int, __m512, __m512)>();

  __m512 _mm512_add_round_ps(
    __m512 arg0,
    __m512 arg1,
    int arg2,
  ) {
    return __mm512_add_round_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_add_round_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __m512, ffi.Int32)>>(
          '_mm512_add_round_ps');
  late final __mm512_add_round_ps = __mm512_add_round_psPtr
      .asFunction<__m512 Function(__m512, __m512, int)>();

  __m512 _mm512_maskz_add_round_ps(
    int arg0,
    __m512 arg1,
    __m512 arg2,
    int arg3,
  ) {
    return __mm512_maskz_add_round_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_add_round_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__mmask16, __m512, __m512,
              ffi.Int32)>>('_mm512_maskz_add_round_ps');
  late final __mm512_maskz_add_round_ps = __mm512_maskz_add_round_psPtr
      .asFunction<__m512 Function(int, __m512, __m512, int)>();

  __m512 _mm512_mask_add_round_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
    __m512 arg3,
    int arg4,
  ) {
    return __mm512_mask_add_round_ps(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_add_round_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__m512, __mmask16, __m512, __m512,
              ffi.Int32)>>('_mm512_mask_add_round_ps');
  late final __mm512_mask_add_round_ps = __mm512_mask_add_round_psPtr
      .asFunction<__m512 Function(__m512, int, __m512, __m512, int)>();

  _m512d _mm512_add_pd(
    _m512d arg0,
    _m512d arg1,
  ) {
    return __mm512_add_pd(
      arg0,
      arg1,
    );
  }

  late final __mm512_add_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, _m512d)>>(
          '_mm512_add_pd');
  late final __mm512_add_pd =
      __mm512_add_pdPtr.asFunction<_m512d Function(_m512d, _m512d)>();

  _m512d _mm512_maskz_add_pd(
    int arg0,
    _m512d arg1,
    _m512d arg2,
  ) {
    return __mm512_maskz_add_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_add_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(__mmask8, _m512d, _m512d)>>(
          '_mm512_maskz_add_pd');
  late final __mm512_maskz_add_pd = __mm512_maskz_add_pdPtr
      .asFunction<_m512d Function(int, _m512d, _m512d)>();

  _m512d _mm512_mask_add_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
    _m512d arg3,
  ) {
    return __mm512_mask_add_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_add_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(
              _m512d, __mmask8, _m512d, _m512d)>>('_mm512_mask_add_pd');
  late final __mm512_mask_add_pd = __mm512_mask_add_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d, _m512d)>();

  _m512d _mm512_add_round_pd(
    _m512d arg0,
    _m512d arg1,
    int arg2,
  ) {
    return __mm512_add_round_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_add_round_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, _m512d, ffi.Int32)>>(
          '_mm512_add_round_pd');
  late final __mm512_add_round_pd = __mm512_add_round_pdPtr
      .asFunction<_m512d Function(_m512d, _m512d, int)>();

  _m512d _mm512_maskz_add_round_pd(
    int arg0,
    _m512d arg1,
    _m512d arg2,
    int arg3,
  ) {
    return __mm512_maskz_add_round_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_add_round_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(__mmask8, _m512d, _m512d,
              ffi.Int32)>>('_mm512_maskz_add_round_pd');
  late final __mm512_maskz_add_round_pd = __mm512_maskz_add_round_pdPtr
      .asFunction<_m512d Function(int, _m512d, _m512d, int)>();

  _m512d _mm512_mask_add_round_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
    _m512d arg3,
    int arg4,
  ) {
    return __mm512_mask_add_round_pd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_add_round_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(_m512d, __mmask8, _m512d, _m512d,
              ffi.Int32)>>('_mm512_mask_add_round_pd');
  late final __mm512_mask_add_round_pd = __mm512_mask_add_round_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d, _m512d, int)>();

  __m512 _mm512_sub_ps(
    __m512 arg0,
    __m512 arg1,
  ) {
    return __mm512_sub_ps(
      arg0,
      arg1,
    );
  }

  late final __mm512_sub_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __m512)>>(
          '_mm512_sub_ps');
  late final __mm512_sub_ps =
      __mm512_sub_psPtr.asFunction<__m512 Function(__m512, __m512)>();

  __m512 _mm512_maskz_sub_ps(
    int arg0,
    __m512 arg1,
    __m512 arg2,
  ) {
    return __mm512_maskz_sub_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_sub_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__mmask16, __m512, __m512)>>(
          '_mm512_maskz_sub_ps');
  late final __mm512_maskz_sub_ps = __mm512_maskz_sub_psPtr
      .asFunction<__m512 Function(int, __m512, __m512)>();

  __m512 _mm512_mask_sub_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
    __m512 arg3,
  ) {
    return __mm512_mask_sub_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_sub_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(
              __m512, __mmask16, __m512, __m512)>>('_mm512_mask_sub_ps');
  late final __mm512_mask_sub_ps = __mm512_mask_sub_psPtr
      .asFunction<__m512 Function(__m512, int, __m512, __m512)>();

  __m512 _mm512_sub_round_ps(
    __m512 arg0,
    __m512 arg1,
    int arg2,
  ) {
    return __mm512_sub_round_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_sub_round_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __m512, ffi.Int32)>>(
          '_mm512_sub_round_ps');
  late final __mm512_sub_round_ps = __mm512_sub_round_psPtr
      .asFunction<__m512 Function(__m512, __m512, int)>();

  __m512 _mm512_maskz_sub_round_ps(
    int arg0,
    __m512 arg1,
    __m512 arg2,
    int arg3,
  ) {
    return __mm512_maskz_sub_round_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_sub_round_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__mmask16, __m512, __m512,
              ffi.Int32)>>('_mm512_maskz_sub_round_ps');
  late final __mm512_maskz_sub_round_ps = __mm512_maskz_sub_round_psPtr
      .asFunction<__m512 Function(int, __m512, __m512, int)>();

  __m512 _mm512_mask_sub_round_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
    __m512 arg3,
    int arg4,
  ) {
    return __mm512_mask_sub_round_ps(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_sub_round_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__m512, __mmask16, __m512, __m512,
              ffi.Int32)>>('_mm512_mask_sub_round_ps');
  late final __mm512_mask_sub_round_ps = __mm512_mask_sub_round_psPtr
      .asFunction<__m512 Function(__m512, int, __m512, __m512, int)>();

  _m512d _mm512_sub_pd(
    _m512d arg0,
    _m512d arg1,
  ) {
    return __mm512_sub_pd(
      arg0,
      arg1,
    );
  }

  late final __mm512_sub_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, _m512d)>>(
          '_mm512_sub_pd');
  late final __mm512_sub_pd =
      __mm512_sub_pdPtr.asFunction<_m512d Function(_m512d, _m512d)>();

  _m512d _mm512_maskz_sub_pd(
    int arg0,
    _m512d arg1,
    _m512d arg2,
  ) {
    return __mm512_maskz_sub_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_sub_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(__mmask8, _m512d, _m512d)>>(
          '_mm512_maskz_sub_pd');
  late final __mm512_maskz_sub_pd = __mm512_maskz_sub_pdPtr
      .asFunction<_m512d Function(int, _m512d, _m512d)>();

  _m512d _mm512_mask_sub_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
    _m512d arg3,
  ) {
    return __mm512_mask_sub_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_sub_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(
              _m512d, __mmask8, _m512d, _m512d)>>('_mm512_mask_sub_pd');
  late final __mm512_mask_sub_pd = __mm512_mask_sub_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d, _m512d)>();

  _m512d _mm512_sub_round_pd(
    _m512d arg0,
    _m512d arg1,
    int arg2,
  ) {
    return __mm512_sub_round_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_sub_round_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, _m512d, ffi.Int32)>>(
          '_mm512_sub_round_pd');
  late final __mm512_sub_round_pd = __mm512_sub_round_pdPtr
      .asFunction<_m512d Function(_m512d, _m512d, int)>();

  _m512d _mm512_maskz_sub_round_pd(
    int arg0,
    _m512d arg1,
    _m512d arg2,
    int arg3,
  ) {
    return __mm512_maskz_sub_round_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_sub_round_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(__mmask8, _m512d, _m512d,
              ffi.Int32)>>('_mm512_maskz_sub_round_pd');
  late final __mm512_maskz_sub_round_pd = __mm512_maskz_sub_round_pdPtr
      .asFunction<_m512d Function(int, _m512d, _m512d, int)>();

  _m512d _mm512_mask_sub_round_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
    _m512d arg3,
    int arg4,
  ) {
    return __mm512_mask_sub_round_pd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_sub_round_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(_m512d, __mmask8, _m512d, _m512d,
              ffi.Int32)>>('_mm512_mask_sub_round_pd');
  late final __mm512_mask_sub_round_pd = __mm512_mask_sub_round_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d, _m512d, int)>();

  __m512 _mm512_mul_ps(
    __m512 arg0,
    __m512 arg1,
  ) {
    return __mm512_mul_ps(
      arg0,
      arg1,
    );
  }

  late final __mm512_mul_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __m512)>>(
          '_mm512_mul_ps');
  late final __mm512_mul_ps =
      __mm512_mul_psPtr.asFunction<__m512 Function(__m512, __m512)>();

  __m512 _mm512_maskz_mul_ps(
    int arg0,
    __m512 arg1,
    __m512 arg2,
  ) {
    return __mm512_maskz_mul_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_mul_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__mmask16, __m512, __m512)>>(
          '_mm512_maskz_mul_ps');
  late final __mm512_maskz_mul_ps = __mm512_maskz_mul_psPtr
      .asFunction<__m512 Function(int, __m512, __m512)>();

  __m512 _mm512_mask_mul_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
    __m512 arg3,
  ) {
    return __mm512_mask_mul_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_mul_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(
              __m512, __mmask16, __m512, __m512)>>('_mm512_mask_mul_ps');
  late final __mm512_mask_mul_ps = __mm512_mask_mul_psPtr
      .asFunction<__m512 Function(__m512, int, __m512, __m512)>();

  __m512 _mm512_mul_round_ps(
    __m512 arg0,
    __m512 arg1,
    int arg2,
  ) {
    return __mm512_mul_round_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mul_round_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __m512, ffi.Int32)>>(
          '_mm512_mul_round_ps');
  late final __mm512_mul_round_ps = __mm512_mul_round_psPtr
      .asFunction<__m512 Function(__m512, __m512, int)>();

  __m512 _mm512_maskz_mul_round_ps(
    int arg0,
    __m512 arg1,
    __m512 arg2,
    int arg3,
  ) {
    return __mm512_maskz_mul_round_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_mul_round_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__mmask16, __m512, __m512,
              ffi.Int32)>>('_mm512_maskz_mul_round_ps');
  late final __mm512_maskz_mul_round_ps = __mm512_maskz_mul_round_psPtr
      .asFunction<__m512 Function(int, __m512, __m512, int)>();

  __m512 _mm512_mask_mul_round_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
    __m512 arg3,
    int arg4,
  ) {
    return __mm512_mask_mul_round_ps(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_mul_round_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__m512, __mmask16, __m512, __m512,
              ffi.Int32)>>('_mm512_mask_mul_round_ps');
  late final __mm512_mask_mul_round_ps = __mm512_mask_mul_round_psPtr
      .asFunction<__m512 Function(__m512, int, __m512, __m512, int)>();

  _m512d _mm512_mul_pd(
    _m512d arg0,
    _m512d arg1,
  ) {
    return __mm512_mul_pd(
      arg0,
      arg1,
    );
  }

  late final __mm512_mul_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, _m512d)>>(
          '_mm512_mul_pd');
  late final __mm512_mul_pd =
      __mm512_mul_pdPtr.asFunction<_m512d Function(_m512d, _m512d)>();

  _m512d _mm512_maskz_mul_pd(
    int arg0,
    _m512d arg1,
    _m512d arg2,
  ) {
    return __mm512_maskz_mul_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_mul_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(__mmask8, _m512d, _m512d)>>(
          '_mm512_maskz_mul_pd');
  late final __mm512_maskz_mul_pd = __mm512_maskz_mul_pdPtr
      .asFunction<_m512d Function(int, _m512d, _m512d)>();

  _m512d _mm512_mask_mul_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
    _m512d arg3,
  ) {
    return __mm512_mask_mul_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_mul_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(
              _m512d, __mmask8, _m512d, _m512d)>>('_mm512_mask_mul_pd');
  late final __mm512_mask_mul_pd = __mm512_mask_mul_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d, _m512d)>();

  _m512d _mm512_mul_round_pd(
    _m512d arg0,
    _m512d arg1,
    int arg2,
  ) {
    return __mm512_mul_round_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mul_round_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, _m512d, ffi.Int32)>>(
          '_mm512_mul_round_pd');
  late final __mm512_mul_round_pd = __mm512_mul_round_pdPtr
      .asFunction<_m512d Function(_m512d, _m512d, int)>();

  _m512d _mm512_maskz_mul_round_pd(
    int arg0,
    _m512d arg1,
    _m512d arg2,
    int arg3,
  ) {
    return __mm512_maskz_mul_round_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_mul_round_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(__mmask8, _m512d, _m512d,
              ffi.Int32)>>('_mm512_maskz_mul_round_pd');
  late final __mm512_maskz_mul_round_pd = __mm512_maskz_mul_round_pdPtr
      .asFunction<_m512d Function(int, _m512d, _m512d, int)>();

  _m512d _mm512_mask_mul_round_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
    _m512d arg3,
    int arg4,
  ) {
    return __mm512_mask_mul_round_pd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_mul_round_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(_m512d, __mmask8, _m512d, _m512d,
              ffi.Int32)>>('_mm512_mask_mul_round_pd');
  late final __mm512_mask_mul_round_pd = __mm512_mask_mul_round_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d, _m512d, int)>();

  __m512 _mm512_div_ps(
    __m512 arg0,
    __m512 arg1,
  ) {
    return __mm512_div_ps(
      arg0,
      arg1,
    );
  }

  late final __mm512_div_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __m512)>>(
          '_mm512_div_ps');
  late final __mm512_div_ps =
      __mm512_div_psPtr.asFunction<__m512 Function(__m512, __m512)>();

  __m512 _mm512_maskz_div_ps(
    int arg0,
    __m512 arg1,
    __m512 arg2,
  ) {
    return __mm512_maskz_div_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_div_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__mmask16, __m512, __m512)>>(
          '_mm512_maskz_div_ps');
  late final __mm512_maskz_div_ps = __mm512_maskz_div_psPtr
      .asFunction<__m512 Function(int, __m512, __m512)>();

  __m512 _mm512_mask_div_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
    __m512 arg3,
  ) {
    return __mm512_mask_div_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_div_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(
              __m512, __mmask16, __m512, __m512)>>('_mm512_mask_div_ps');
  late final __mm512_mask_div_ps = __mm512_mask_div_psPtr
      .asFunction<__m512 Function(__m512, int, __m512, __m512)>();

  __m512 _mm512_div_round_ps(
    __m512 arg0,
    __m512 arg1,
    int arg2,
  ) {
    return __mm512_div_round_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_div_round_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __m512, ffi.Int32)>>(
          '_mm512_div_round_ps');
  late final __mm512_div_round_ps = __mm512_div_round_psPtr
      .asFunction<__m512 Function(__m512, __m512, int)>();

  __m512 _mm512_maskz_div_round_ps(
    int arg0,
    __m512 arg1,
    __m512 arg2,
    int arg3,
  ) {
    return __mm512_maskz_div_round_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_div_round_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__mmask16, __m512, __m512,
              ffi.Int32)>>('_mm512_maskz_div_round_ps');
  late final __mm512_maskz_div_round_ps = __mm512_maskz_div_round_psPtr
      .asFunction<__m512 Function(int, __m512, __m512, int)>();

  __m512 _mm512_mask_div_round_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
    __m512 arg3,
    int arg4,
  ) {
    return __mm512_mask_div_round_ps(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_div_round_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__m512, __mmask16, __m512, __m512,
              ffi.Int32)>>('_mm512_mask_div_round_ps');
  late final __mm512_mask_div_round_ps = __mm512_mask_div_round_psPtr
      .asFunction<__m512 Function(__m512, int, __m512, __m512, int)>();

  _m512d _mm512_div_pd(
    _m512d arg0,
    _m512d arg1,
  ) {
    return __mm512_div_pd(
      arg0,
      arg1,
    );
  }

  late final __mm512_div_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, _m512d)>>(
          '_mm512_div_pd');
  late final __mm512_div_pd =
      __mm512_div_pdPtr.asFunction<_m512d Function(_m512d, _m512d)>();

  _m512d _mm512_maskz_div_pd(
    int arg0,
    _m512d arg1,
    _m512d arg2,
  ) {
    return __mm512_maskz_div_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_div_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(__mmask8, _m512d, _m512d)>>(
          '_mm512_maskz_div_pd');
  late final __mm512_maskz_div_pd = __mm512_maskz_div_pdPtr
      .asFunction<_m512d Function(int, _m512d, _m512d)>();

  _m512d _mm512_mask_div_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
    _m512d arg3,
  ) {
    return __mm512_mask_div_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_div_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(
              _m512d, __mmask8, _m512d, _m512d)>>('_mm512_mask_div_pd');
  late final __mm512_mask_div_pd = __mm512_mask_div_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d, _m512d)>();

  _m512d _mm512_div_round_pd(
    _m512d arg0,
    _m512d arg1,
    int arg2,
  ) {
    return __mm512_div_round_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_div_round_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, _m512d, ffi.Int32)>>(
          '_mm512_div_round_pd');
  late final __mm512_div_round_pd = __mm512_div_round_pdPtr
      .asFunction<_m512d Function(_m512d, _m512d, int)>();

  _m512d _mm512_maskz_div_round_pd(
    int arg0,
    _m512d arg1,
    _m512d arg2,
    int arg3,
  ) {
    return __mm512_maskz_div_round_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_div_round_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(__mmask8, _m512d, _m512d,
              ffi.Int32)>>('_mm512_maskz_div_round_pd');
  late final __mm512_maskz_div_round_pd = __mm512_maskz_div_round_pdPtr
      .asFunction<_m512d Function(int, _m512d, _m512d, int)>();

  _m512d _mm512_mask_div_round_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
    _m512d arg3,
    int arg4,
  ) {
    return __mm512_mask_div_round_pd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_div_round_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(_m512d, __mmask8, _m512d, _m512d,
              ffi.Int32)>>('_mm512_mask_div_round_pd');
  late final __mm512_mask_div_round_pd = __mm512_mask_div_round_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d, _m512d, int)>();

  __m512 _mm512_fmadd_ps(
    __m512 arg0,
    __m512 arg1,
    __m512 arg2,
  ) {
    return __mm512_fmadd_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_fmadd_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __m512, __m512)>>(
          '_mm512_fmadd_ps');
  late final __mm512_fmadd_ps =
      __mm512_fmadd_psPtr.asFunction<__m512 Function(__m512, __m512, __m512)>();

  __m512 _mm512_mask_fmadd_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
    __m512 arg3,
  ) {
    return __mm512_mask_fmadd_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_fmadd_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(
              __m512, __mmask16, __m512, __m512)>>('_mm512_mask_fmadd_ps');
  late final __mm512_mask_fmadd_ps = __mm512_mask_fmadd_psPtr
      .asFunction<__m512 Function(__m512, int, __m512, __m512)>();

  __m512 _mm512_mask3_fmadd_ps(
    __m512 arg0,
    __m512 arg1,
    __m512 arg2,
    int arg3,
  ) {
    return __mm512_mask3_fmadd_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask3_fmadd_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(
              __m512, __m512, __m512, __mmask16)>>('_mm512_mask3_fmadd_ps');
  late final __mm512_mask3_fmadd_ps = __mm512_mask3_fmadd_psPtr
      .asFunction<__m512 Function(__m512, __m512, __m512, int)>();

  __m512 _mm512_maskz_fmadd_ps(
    int arg0,
    __m512 arg1,
    __m512 arg2,
    __m512 arg3,
  ) {
    return __mm512_maskz_fmadd_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_fmadd_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(
              __mmask16, __m512, __m512, __m512)>>('_mm512_maskz_fmadd_ps');
  late final __mm512_maskz_fmadd_ps = __mm512_maskz_fmadd_psPtr
      .asFunction<__m512 Function(int, __m512, __m512, __m512)>();

  __m512 _mm512_fmadd_round_ps(
    __m512 arg0,
    __m512 arg1,
    __m512 arg2,
    int arg3,
  ) {
    return __mm512_fmadd_round_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_fmadd_round_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(
              __m512, __m512, __m512, ffi.Int32)>>('_mm512_fmadd_round_ps');
  late final __mm512_fmadd_round_ps = __mm512_fmadd_round_psPtr
      .asFunction<__m512 Function(__m512, __m512, __m512, int)>();

  __m512 _mm512_mask_fmadd_round_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
    __m512 arg3,
    int arg4,
  ) {
    return __mm512_mask_fmadd_round_ps(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_fmadd_round_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__m512, __mmask16, __m512, __m512,
              ffi.Int32)>>('_mm512_mask_fmadd_round_ps');
  late final __mm512_mask_fmadd_round_ps = __mm512_mask_fmadd_round_psPtr
      .asFunction<__m512 Function(__m512, int, __m512, __m512, int)>();

  __m512 _mm512_mask3_fmadd_round_ps(
    __m512 arg0,
    __m512 arg1,
    __m512 arg2,
    int arg3,
    int arg4,
  ) {
    return __mm512_mask3_fmadd_round_ps(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask3_fmadd_round_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__m512, __m512, __m512, __mmask16,
              ffi.Int32)>>('_mm512_mask3_fmadd_round_ps');
  late final __mm512_mask3_fmadd_round_ps = __mm512_mask3_fmadd_round_psPtr
      .asFunction<__m512 Function(__m512, __m512, __m512, int, int)>();

  __m512 _mm512_maskz_fmadd_round_ps(
    int arg0,
    __m512 arg1,
    __m512 arg2,
    __m512 arg3,
    int arg4,
  ) {
    return __mm512_maskz_fmadd_round_ps(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_maskz_fmadd_round_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__mmask16, __m512, __m512, __m512,
              ffi.Int32)>>('_mm512_maskz_fmadd_round_ps');
  late final __mm512_maskz_fmadd_round_ps = __mm512_maskz_fmadd_round_psPtr
      .asFunction<__m512 Function(int, __m512, __m512, __m512, int)>();

  _m512d _mm512_fmadd_pd(
    _m512d arg0,
    _m512d arg1,
    _m512d arg2,
  ) {
    return __mm512_fmadd_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_fmadd_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, _m512d, _m512d)>>(
          '_mm512_fmadd_pd');
  late final __mm512_fmadd_pd =
      __mm512_fmadd_pdPtr.asFunction<_m512d Function(_m512d, _m512d, _m512d)>();

  _m512d _mm512_mask_fmadd_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
    _m512d arg3,
  ) {
    return __mm512_mask_fmadd_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_fmadd_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(
              _m512d, __mmask8, _m512d, _m512d)>>('_mm512_mask_fmadd_pd');
  late final __mm512_mask_fmadd_pd = __mm512_mask_fmadd_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d, _m512d)>();

  _m512d _mm512_mask3_fmadd_pd(
    _m512d arg0,
    _m512d arg1,
    _m512d arg2,
    int arg3,
  ) {
    return __mm512_mask3_fmadd_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask3_fmadd_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(
              _m512d, _m512d, _m512d, __mmask8)>>('_mm512_mask3_fmadd_pd');
  late final __mm512_mask3_fmadd_pd = __mm512_mask3_fmadd_pdPtr
      .asFunction<_m512d Function(_m512d, _m512d, _m512d, int)>();

  _m512d _mm512_maskz_fmadd_pd(
    int arg0,
    _m512d arg1,
    _m512d arg2,
    _m512d arg3,
  ) {
    return __mm512_maskz_fmadd_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_fmadd_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(
              __mmask8, _m512d, _m512d, _m512d)>>('_mm512_maskz_fmadd_pd');
  late final __mm512_maskz_fmadd_pd = __mm512_maskz_fmadd_pdPtr
      .asFunction<_m512d Function(int, _m512d, _m512d, _m512d)>();

  _m512d _mm512_fmadd_round_pd(
    _m512d arg0,
    _m512d arg1,
    _m512d arg2,
    int arg3,
  ) {
    return __mm512_fmadd_round_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_fmadd_round_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(
              _m512d, _m512d, _m512d, ffi.Int32)>>('_mm512_fmadd_round_pd');
  late final __mm512_fmadd_round_pd = __mm512_fmadd_round_pdPtr
      .asFunction<_m512d Function(_m512d, _m512d, _m512d, int)>();

  _m512d _mm512_mask_fmadd_round_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
    _m512d arg3,
    int arg4,
  ) {
    return __mm512_mask_fmadd_round_pd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_fmadd_round_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(_m512d, __mmask8, _m512d, _m512d,
              ffi.Int32)>>('_mm512_mask_fmadd_round_pd');
  late final __mm512_mask_fmadd_round_pd = __mm512_mask_fmadd_round_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d, _m512d, int)>();

  _m512d _mm512_mask3_fmadd_round_pd(
    _m512d arg0,
    _m512d arg1,
    _m512d arg2,
    int arg3,
    int arg4,
  ) {
    return __mm512_mask3_fmadd_round_pd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask3_fmadd_round_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(_m512d, _m512d, _m512d, __mmask8,
              ffi.Int32)>>('_mm512_mask3_fmadd_round_pd');
  late final __mm512_mask3_fmadd_round_pd = __mm512_mask3_fmadd_round_pdPtr
      .asFunction<_m512d Function(_m512d, _m512d, _m512d, int, int)>();

  _m512d _mm512_maskz_fmadd_round_pd(
    int arg0,
    _m512d arg1,
    _m512d arg2,
    _m512d arg3,
    int arg4,
  ) {
    return __mm512_maskz_fmadd_round_pd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_maskz_fmadd_round_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(__mmask8, _m512d, _m512d, _m512d,
              ffi.Int32)>>('_mm512_maskz_fmadd_round_pd');
  late final __mm512_maskz_fmadd_round_pd = __mm512_maskz_fmadd_round_pdPtr
      .asFunction<_m512d Function(int, _m512d, _m512d, _m512d, int)>();

  __m512 _mm512_fmsub_ps(
    __m512 arg0,
    __m512 arg1,
    __m512 arg2,
  ) {
    return __mm512_fmsub_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_fmsub_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __m512, __m512)>>(
          '_mm512_fmsub_ps');
  late final __mm512_fmsub_ps =
      __mm512_fmsub_psPtr.asFunction<__m512 Function(__m512, __m512, __m512)>();

  __m512 _mm512_mask_fmsub_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
    __m512 arg3,
  ) {
    return __mm512_mask_fmsub_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_fmsub_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(
              __m512, __mmask16, __m512, __m512)>>('_mm512_mask_fmsub_ps');
  late final __mm512_mask_fmsub_ps = __mm512_mask_fmsub_psPtr
      .asFunction<__m512 Function(__m512, int, __m512, __m512)>();

  __m512 _mm512_mask3_fmsub_ps(
    __m512 arg0,
    __m512 arg1,
    __m512 arg2,
    int arg3,
  ) {
    return __mm512_mask3_fmsub_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask3_fmsub_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(
              __m512, __m512, __m512, __mmask16)>>('_mm512_mask3_fmsub_ps');
  late final __mm512_mask3_fmsub_ps = __mm512_mask3_fmsub_psPtr
      .asFunction<__m512 Function(__m512, __m512, __m512, int)>();

  __m512 _mm512_maskz_fmsub_ps(
    int arg0,
    __m512 arg1,
    __m512 arg2,
    __m512 arg3,
  ) {
    return __mm512_maskz_fmsub_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_fmsub_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(
              __mmask16, __m512, __m512, __m512)>>('_mm512_maskz_fmsub_ps');
  late final __mm512_maskz_fmsub_ps = __mm512_maskz_fmsub_psPtr
      .asFunction<__m512 Function(int, __m512, __m512, __m512)>();

  __m512 _mm512_fmsub_round_ps(
    __m512 arg0,
    __m512 arg1,
    __m512 arg2,
    int arg3,
  ) {
    return __mm512_fmsub_round_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_fmsub_round_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(
              __m512, __m512, __m512, ffi.Int32)>>('_mm512_fmsub_round_ps');
  late final __mm512_fmsub_round_ps = __mm512_fmsub_round_psPtr
      .asFunction<__m512 Function(__m512, __m512, __m512, int)>();

  __m512 _mm512_mask_fmsub_round_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
    __m512 arg3,
    int arg4,
  ) {
    return __mm512_mask_fmsub_round_ps(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_fmsub_round_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__m512, __mmask16, __m512, __m512,
              ffi.Int32)>>('_mm512_mask_fmsub_round_ps');
  late final __mm512_mask_fmsub_round_ps = __mm512_mask_fmsub_round_psPtr
      .asFunction<__m512 Function(__m512, int, __m512, __m512, int)>();

  __m512 _mm512_mask3_fmsub_round_ps(
    __m512 arg0,
    __m512 arg1,
    __m512 arg2,
    int arg3,
    int arg4,
  ) {
    return __mm512_mask3_fmsub_round_ps(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask3_fmsub_round_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__m512, __m512, __m512, __mmask16,
              ffi.Int32)>>('_mm512_mask3_fmsub_round_ps');
  late final __mm512_mask3_fmsub_round_ps = __mm512_mask3_fmsub_round_psPtr
      .asFunction<__m512 Function(__m512, __m512, __m512, int, int)>();

  __m512 _mm512_maskz_fmsub_round_ps(
    int arg0,
    __m512 arg1,
    __m512 arg2,
    __m512 arg3,
    int arg4,
  ) {
    return __mm512_maskz_fmsub_round_ps(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_maskz_fmsub_round_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__mmask16, __m512, __m512, __m512,
              ffi.Int32)>>('_mm512_maskz_fmsub_round_ps');
  late final __mm512_maskz_fmsub_round_ps = __mm512_maskz_fmsub_round_psPtr
      .asFunction<__m512 Function(int, __m512, __m512, __m512, int)>();

  _m512d _mm512_fmsub_pd(
    _m512d arg0,
    _m512d arg1,
    _m512d arg2,
  ) {
    return __mm512_fmsub_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_fmsub_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, _m512d, _m512d)>>(
          '_mm512_fmsub_pd');
  late final __mm512_fmsub_pd =
      __mm512_fmsub_pdPtr.asFunction<_m512d Function(_m512d, _m512d, _m512d)>();

  _m512d _mm512_mask_fmsub_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
    _m512d arg3,
  ) {
    return __mm512_mask_fmsub_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_fmsub_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(
              _m512d, __mmask8, _m512d, _m512d)>>('_mm512_mask_fmsub_pd');
  late final __mm512_mask_fmsub_pd = __mm512_mask_fmsub_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d, _m512d)>();

  _m512d _mm512_mask3_fmsub_pd(
    _m512d arg0,
    _m512d arg1,
    _m512d arg2,
    int arg3,
  ) {
    return __mm512_mask3_fmsub_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask3_fmsub_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(
              _m512d, _m512d, _m512d, __mmask8)>>('_mm512_mask3_fmsub_pd');
  late final __mm512_mask3_fmsub_pd = __mm512_mask3_fmsub_pdPtr
      .asFunction<_m512d Function(_m512d, _m512d, _m512d, int)>();

  _m512d _mm512_maskz_fmsub_pd(
    int arg0,
    _m512d arg1,
    _m512d arg2,
    _m512d arg3,
  ) {
    return __mm512_maskz_fmsub_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_fmsub_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(
              __mmask8, _m512d, _m512d, _m512d)>>('_mm512_maskz_fmsub_pd');
  late final __mm512_maskz_fmsub_pd = __mm512_maskz_fmsub_pdPtr
      .asFunction<_m512d Function(int, _m512d, _m512d, _m512d)>();

  _m512d _mm512_fmsub_round_pd(
    _m512d arg0,
    _m512d arg1,
    _m512d arg2,
    int arg3,
  ) {
    return __mm512_fmsub_round_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_fmsub_round_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(
              _m512d, _m512d, _m512d, ffi.Int32)>>('_mm512_fmsub_round_pd');
  late final __mm512_fmsub_round_pd = __mm512_fmsub_round_pdPtr
      .asFunction<_m512d Function(_m512d, _m512d, _m512d, int)>();

  _m512d _mm512_mask_fmsub_round_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
    _m512d arg3,
    int arg4,
  ) {
    return __mm512_mask_fmsub_round_pd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_fmsub_round_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(_m512d, __mmask8, _m512d, _m512d,
              ffi.Int32)>>('_mm512_mask_fmsub_round_pd');
  late final __mm512_mask_fmsub_round_pd = __mm512_mask_fmsub_round_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d, _m512d, int)>();

  _m512d _mm512_mask3_fmsub_round_pd(
    _m512d arg0,
    _m512d arg1,
    _m512d arg2,
    int arg3,
    int arg4,
  ) {
    return __mm512_mask3_fmsub_round_pd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask3_fmsub_round_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(_m512d, _m512d, _m512d, __mmask8,
              ffi.Int32)>>('_mm512_mask3_fmsub_round_pd');
  late final __mm512_mask3_fmsub_round_pd = __mm512_mask3_fmsub_round_pdPtr
      .asFunction<_m512d Function(_m512d, _m512d, _m512d, int, int)>();

  _m512d _mm512_maskz_fmsub_round_pd(
    int arg0,
    _m512d arg1,
    _m512d arg2,
    _m512d arg3,
    int arg4,
  ) {
    return __mm512_maskz_fmsub_round_pd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_maskz_fmsub_round_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(__mmask8, _m512d, _m512d, _m512d,
              ffi.Int32)>>('_mm512_maskz_fmsub_round_pd');
  late final __mm512_maskz_fmsub_round_pd = __mm512_maskz_fmsub_round_pdPtr
      .asFunction<_m512d Function(int, _m512d, _m512d, _m512d, int)>();

  __m512 _mm512_fmaddsub_ps(
    __m512 arg0,
    __m512 arg1,
    __m512 arg2,
  ) {
    return __mm512_fmaddsub_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_fmaddsub_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __m512, __m512)>>(
          '_mm512_fmaddsub_ps');
  late final __mm512_fmaddsub_ps = __mm512_fmaddsub_psPtr
      .asFunction<__m512 Function(__m512, __m512, __m512)>();

  __m512 _mm512_mask_fmaddsub_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
    __m512 arg3,
  ) {
    return __mm512_mask_fmaddsub_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_fmaddsub_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(
              __m512, __mmask16, __m512, __m512)>>('_mm512_mask_fmaddsub_ps');
  late final __mm512_mask_fmaddsub_ps = __mm512_mask_fmaddsub_psPtr
      .asFunction<__m512 Function(__m512, int, __m512, __m512)>();

  __m512 _mm512_mask3_fmaddsub_ps(
    __m512 arg0,
    __m512 arg1,
    __m512 arg2,
    int arg3,
  ) {
    return __mm512_mask3_fmaddsub_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask3_fmaddsub_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(
              __m512, __m512, __m512, __mmask16)>>('_mm512_mask3_fmaddsub_ps');
  late final __mm512_mask3_fmaddsub_ps = __mm512_mask3_fmaddsub_psPtr
      .asFunction<__m512 Function(__m512, __m512, __m512, int)>();

  __m512 _mm512_maskz_fmaddsub_ps(
    int arg0,
    __m512 arg1,
    __m512 arg2,
    __m512 arg3,
  ) {
    return __mm512_maskz_fmaddsub_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_fmaddsub_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(
              __mmask16, __m512, __m512, __m512)>>('_mm512_maskz_fmaddsub_ps');
  late final __mm512_maskz_fmaddsub_ps = __mm512_maskz_fmaddsub_psPtr
      .asFunction<__m512 Function(int, __m512, __m512, __m512)>();

  __m512 _mm512_fmaddsub_round_ps(
    __m512 arg0,
    __m512 arg1,
    __m512 arg2,
    int arg3,
  ) {
    return __mm512_fmaddsub_round_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_fmaddsub_round_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(
              __m512, __m512, __m512, ffi.Int32)>>('_mm512_fmaddsub_round_ps');
  late final __mm512_fmaddsub_round_ps = __mm512_fmaddsub_round_psPtr
      .asFunction<__m512 Function(__m512, __m512, __m512, int)>();

  __m512 _mm512_mask_fmaddsub_round_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
    __m512 arg3,
    int arg4,
  ) {
    return __mm512_mask_fmaddsub_round_ps(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_fmaddsub_round_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__m512, __mmask16, __m512, __m512,
              ffi.Int32)>>('_mm512_mask_fmaddsub_round_ps');
  late final __mm512_mask_fmaddsub_round_ps = __mm512_mask_fmaddsub_round_psPtr
      .asFunction<__m512 Function(__m512, int, __m512, __m512, int)>();

  __m512 _mm512_mask3_fmaddsub_round_ps(
    __m512 arg0,
    __m512 arg1,
    __m512 arg2,
    int arg3,
    int arg4,
  ) {
    return __mm512_mask3_fmaddsub_round_ps(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask3_fmaddsub_round_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__m512, __m512, __m512, __mmask16,
              ffi.Int32)>>('_mm512_mask3_fmaddsub_round_ps');
  late final __mm512_mask3_fmaddsub_round_ps =
      __mm512_mask3_fmaddsub_round_psPtr
          .asFunction<__m512 Function(__m512, __m512, __m512, int, int)>();

  __m512 _mm512_maskz_fmaddsub_round_ps(
    int arg0,
    __m512 arg1,
    __m512 arg2,
    __m512 arg3,
    int arg4,
  ) {
    return __mm512_maskz_fmaddsub_round_ps(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_maskz_fmaddsub_round_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__mmask16, __m512, __m512, __m512,
              ffi.Int32)>>('_mm512_maskz_fmaddsub_round_ps');
  late final __mm512_maskz_fmaddsub_round_ps =
      __mm512_maskz_fmaddsub_round_psPtr
          .asFunction<__m512 Function(int, __m512, __m512, __m512, int)>();

  _m512d _mm512_fmaddsub_pd(
    _m512d arg0,
    _m512d arg1,
    _m512d arg2,
  ) {
    return __mm512_fmaddsub_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_fmaddsub_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, _m512d, _m512d)>>(
          '_mm512_fmaddsub_pd');
  late final __mm512_fmaddsub_pd = __mm512_fmaddsub_pdPtr
      .asFunction<_m512d Function(_m512d, _m512d, _m512d)>();

  _m512d _mm512_mask_fmaddsub_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
    _m512d arg3,
  ) {
    return __mm512_mask_fmaddsub_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_fmaddsub_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(
              _m512d, __mmask8, _m512d, _m512d)>>('_mm512_mask_fmaddsub_pd');
  late final __mm512_mask_fmaddsub_pd = __mm512_mask_fmaddsub_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d, _m512d)>();

  _m512d _mm512_mask3_fmaddsub_pd(
    _m512d arg0,
    _m512d arg1,
    _m512d arg2,
    int arg3,
  ) {
    return __mm512_mask3_fmaddsub_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask3_fmaddsub_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(
              _m512d, _m512d, _m512d, __mmask8)>>('_mm512_mask3_fmaddsub_pd');
  late final __mm512_mask3_fmaddsub_pd = __mm512_mask3_fmaddsub_pdPtr
      .asFunction<_m512d Function(_m512d, _m512d, _m512d, int)>();

  _m512d _mm512_maskz_fmaddsub_pd(
    int arg0,
    _m512d arg1,
    _m512d arg2,
    _m512d arg3,
  ) {
    return __mm512_maskz_fmaddsub_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_fmaddsub_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(
              __mmask8, _m512d, _m512d, _m512d)>>('_mm512_maskz_fmaddsub_pd');
  late final __mm512_maskz_fmaddsub_pd = __mm512_maskz_fmaddsub_pdPtr
      .asFunction<_m512d Function(int, _m512d, _m512d, _m512d)>();

  _m512d _mm512_fmaddsub_round_pd(
    _m512d arg0,
    _m512d arg1,
    _m512d arg2,
    int arg3,
  ) {
    return __mm512_fmaddsub_round_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_fmaddsub_round_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(
              _m512d, _m512d, _m512d, ffi.Int32)>>('_mm512_fmaddsub_round_pd');
  late final __mm512_fmaddsub_round_pd = __mm512_fmaddsub_round_pdPtr
      .asFunction<_m512d Function(_m512d, _m512d, _m512d, int)>();

  _m512d _mm512_mask_fmaddsub_round_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
    _m512d arg3,
    int arg4,
  ) {
    return __mm512_mask_fmaddsub_round_pd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_fmaddsub_round_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(_m512d, __mmask8, _m512d, _m512d,
              ffi.Int32)>>('_mm512_mask_fmaddsub_round_pd');
  late final __mm512_mask_fmaddsub_round_pd = __mm512_mask_fmaddsub_round_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d, _m512d, int)>();

  _m512d _mm512_mask3_fmaddsub_round_pd(
    _m512d arg0,
    _m512d arg1,
    _m512d arg2,
    int arg3,
    int arg4,
  ) {
    return __mm512_mask3_fmaddsub_round_pd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask3_fmaddsub_round_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(_m512d, _m512d, _m512d, __mmask8,
              ffi.Int32)>>('_mm512_mask3_fmaddsub_round_pd');
  late final __mm512_mask3_fmaddsub_round_pd =
      __mm512_mask3_fmaddsub_round_pdPtr
          .asFunction<_m512d Function(_m512d, _m512d, _m512d, int, int)>();

  _m512d _mm512_maskz_fmaddsub_round_pd(
    int arg0,
    _m512d arg1,
    _m512d arg2,
    _m512d arg3,
    int arg4,
  ) {
    return __mm512_maskz_fmaddsub_round_pd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_maskz_fmaddsub_round_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(__mmask8, _m512d, _m512d, _m512d,
              ffi.Int32)>>('_mm512_maskz_fmaddsub_round_pd');
  late final __mm512_maskz_fmaddsub_round_pd =
      __mm512_maskz_fmaddsub_round_pdPtr
          .asFunction<_m512d Function(int, _m512d, _m512d, _m512d, int)>();

  __m512 _mm512_fmsubadd_ps(
    __m512 arg0,
    __m512 arg1,
    __m512 arg2,
  ) {
    return __mm512_fmsubadd_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_fmsubadd_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __m512, __m512)>>(
          '_mm512_fmsubadd_ps');
  late final __mm512_fmsubadd_ps = __mm512_fmsubadd_psPtr
      .asFunction<__m512 Function(__m512, __m512, __m512)>();

  __m512 _mm512_mask_fmsubadd_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
    __m512 arg3,
  ) {
    return __mm512_mask_fmsubadd_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_fmsubadd_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(
              __m512, __mmask16, __m512, __m512)>>('_mm512_mask_fmsubadd_ps');
  late final __mm512_mask_fmsubadd_ps = __mm512_mask_fmsubadd_psPtr
      .asFunction<__m512 Function(__m512, int, __m512, __m512)>();

  __m512 _mm512_mask3_fmsubadd_ps(
    __m512 arg0,
    __m512 arg1,
    __m512 arg2,
    int arg3,
  ) {
    return __mm512_mask3_fmsubadd_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask3_fmsubadd_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(
              __m512, __m512, __m512, __mmask16)>>('_mm512_mask3_fmsubadd_ps');
  late final __mm512_mask3_fmsubadd_ps = __mm512_mask3_fmsubadd_psPtr
      .asFunction<__m512 Function(__m512, __m512, __m512, int)>();

  __m512 _mm512_maskz_fmsubadd_ps(
    int arg0,
    __m512 arg1,
    __m512 arg2,
    __m512 arg3,
  ) {
    return __mm512_maskz_fmsubadd_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_fmsubadd_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(
              __mmask16, __m512, __m512, __m512)>>('_mm512_maskz_fmsubadd_ps');
  late final __mm512_maskz_fmsubadd_ps = __mm512_maskz_fmsubadd_psPtr
      .asFunction<__m512 Function(int, __m512, __m512, __m512)>();

  __m512 _mm512_fmsubadd_round_ps(
    __m512 arg0,
    __m512 arg1,
    __m512 arg2,
    int arg3,
  ) {
    return __mm512_fmsubadd_round_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_fmsubadd_round_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(
              __m512, __m512, __m512, ffi.Int32)>>('_mm512_fmsubadd_round_ps');
  late final __mm512_fmsubadd_round_ps = __mm512_fmsubadd_round_psPtr
      .asFunction<__m512 Function(__m512, __m512, __m512, int)>();

  __m512 _mm512_mask_fmsubadd_round_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
    __m512 arg3,
    int arg4,
  ) {
    return __mm512_mask_fmsubadd_round_ps(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_fmsubadd_round_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__m512, __mmask16, __m512, __m512,
              ffi.Int32)>>('_mm512_mask_fmsubadd_round_ps');
  late final __mm512_mask_fmsubadd_round_ps = __mm512_mask_fmsubadd_round_psPtr
      .asFunction<__m512 Function(__m512, int, __m512, __m512, int)>();

  __m512 _mm512_mask3_fmsubadd_round_ps(
    __m512 arg0,
    __m512 arg1,
    __m512 arg2,
    int arg3,
    int arg4,
  ) {
    return __mm512_mask3_fmsubadd_round_ps(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask3_fmsubadd_round_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__m512, __m512, __m512, __mmask16,
              ffi.Int32)>>('_mm512_mask3_fmsubadd_round_ps');
  late final __mm512_mask3_fmsubadd_round_ps =
      __mm512_mask3_fmsubadd_round_psPtr
          .asFunction<__m512 Function(__m512, __m512, __m512, int, int)>();

  __m512 _mm512_maskz_fmsubadd_round_ps(
    int arg0,
    __m512 arg1,
    __m512 arg2,
    __m512 arg3,
    int arg4,
  ) {
    return __mm512_maskz_fmsubadd_round_ps(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_maskz_fmsubadd_round_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__mmask16, __m512, __m512, __m512,
              ffi.Int32)>>('_mm512_maskz_fmsubadd_round_ps');
  late final __mm512_maskz_fmsubadd_round_ps =
      __mm512_maskz_fmsubadd_round_psPtr
          .asFunction<__m512 Function(int, __m512, __m512, __m512, int)>();

  _m512d _mm512_fmsubadd_pd(
    _m512d arg0,
    _m512d arg1,
    _m512d arg2,
  ) {
    return __mm512_fmsubadd_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_fmsubadd_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, _m512d, _m512d)>>(
          '_mm512_fmsubadd_pd');
  late final __mm512_fmsubadd_pd = __mm512_fmsubadd_pdPtr
      .asFunction<_m512d Function(_m512d, _m512d, _m512d)>();

  _m512d _mm512_mask_fmsubadd_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
    _m512d arg3,
  ) {
    return __mm512_mask_fmsubadd_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_fmsubadd_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(
              _m512d, __mmask8, _m512d, _m512d)>>('_mm512_mask_fmsubadd_pd');
  late final __mm512_mask_fmsubadd_pd = __mm512_mask_fmsubadd_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d, _m512d)>();

  _m512d _mm512_mask3_fmsubadd_pd(
    _m512d arg0,
    _m512d arg1,
    _m512d arg2,
    int arg3,
  ) {
    return __mm512_mask3_fmsubadd_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask3_fmsubadd_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(
              _m512d, _m512d, _m512d, __mmask8)>>('_mm512_mask3_fmsubadd_pd');
  late final __mm512_mask3_fmsubadd_pd = __mm512_mask3_fmsubadd_pdPtr
      .asFunction<_m512d Function(_m512d, _m512d, _m512d, int)>();

  _m512d _mm512_maskz_fmsubadd_pd(
    int arg0,
    _m512d arg1,
    _m512d arg2,
    _m512d arg3,
  ) {
    return __mm512_maskz_fmsubadd_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_fmsubadd_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(
              __mmask8, _m512d, _m512d, _m512d)>>('_mm512_maskz_fmsubadd_pd');
  late final __mm512_maskz_fmsubadd_pd = __mm512_maskz_fmsubadd_pdPtr
      .asFunction<_m512d Function(int, _m512d, _m512d, _m512d)>();

  _m512d _mm512_fmsubadd_round_pd(
    _m512d arg0,
    _m512d arg1,
    _m512d arg2,
    int arg3,
  ) {
    return __mm512_fmsubadd_round_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_fmsubadd_round_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(
              _m512d, _m512d, _m512d, ffi.Int32)>>('_mm512_fmsubadd_round_pd');
  late final __mm512_fmsubadd_round_pd = __mm512_fmsubadd_round_pdPtr
      .asFunction<_m512d Function(_m512d, _m512d, _m512d, int)>();

  _m512d _mm512_mask_fmsubadd_round_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
    _m512d arg3,
    int arg4,
  ) {
    return __mm512_mask_fmsubadd_round_pd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_fmsubadd_round_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(_m512d, __mmask8, _m512d, _m512d,
              ffi.Int32)>>('_mm512_mask_fmsubadd_round_pd');
  late final __mm512_mask_fmsubadd_round_pd = __mm512_mask_fmsubadd_round_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d, _m512d, int)>();

  _m512d _mm512_mask3_fmsubadd_round_pd(
    _m512d arg0,
    _m512d arg1,
    _m512d arg2,
    int arg3,
    int arg4,
  ) {
    return __mm512_mask3_fmsubadd_round_pd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask3_fmsubadd_round_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(_m512d, _m512d, _m512d, __mmask8,
              ffi.Int32)>>('_mm512_mask3_fmsubadd_round_pd');
  late final __mm512_mask3_fmsubadd_round_pd =
      __mm512_mask3_fmsubadd_round_pdPtr
          .asFunction<_m512d Function(_m512d, _m512d, _m512d, int, int)>();

  _m512d _mm512_maskz_fmsubadd_round_pd(
    int arg0,
    _m512d arg1,
    _m512d arg2,
    _m512d arg3,
    int arg4,
  ) {
    return __mm512_maskz_fmsubadd_round_pd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_maskz_fmsubadd_round_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(__mmask8, _m512d, _m512d, _m512d,
              ffi.Int32)>>('_mm512_maskz_fmsubadd_round_pd');
  late final __mm512_maskz_fmsubadd_round_pd =
      __mm512_maskz_fmsubadd_round_pdPtr
          .asFunction<_m512d Function(int, _m512d, _m512d, _m512d, int)>();

  __m512 _mm512_fnmadd_ps(
    __m512 arg0,
    __m512 arg1,
    __m512 arg2,
  ) {
    return __mm512_fnmadd_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_fnmadd_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __m512, __m512)>>(
          '_mm512_fnmadd_ps');
  late final __mm512_fnmadd_ps = __mm512_fnmadd_psPtr
      .asFunction<__m512 Function(__m512, __m512, __m512)>();

  __m512 _mm512_mask_fnmadd_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
    __m512 arg3,
  ) {
    return __mm512_mask_fnmadd_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_fnmadd_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(
              __m512, __mmask16, __m512, __m512)>>('_mm512_mask_fnmadd_ps');
  late final __mm512_mask_fnmadd_ps = __mm512_mask_fnmadd_psPtr
      .asFunction<__m512 Function(__m512, int, __m512, __m512)>();

  __m512 _mm512_mask3_fnmadd_ps(
    __m512 arg0,
    __m512 arg1,
    __m512 arg2,
    int arg3,
  ) {
    return __mm512_mask3_fnmadd_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask3_fnmadd_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(
              __m512, __m512, __m512, __mmask16)>>('_mm512_mask3_fnmadd_ps');
  late final __mm512_mask3_fnmadd_ps = __mm512_mask3_fnmadd_psPtr
      .asFunction<__m512 Function(__m512, __m512, __m512, int)>();

  __m512 _mm512_maskz_fnmadd_ps(
    int arg0,
    __m512 arg1,
    __m512 arg2,
    __m512 arg3,
  ) {
    return __mm512_maskz_fnmadd_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_fnmadd_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(
              __mmask16, __m512, __m512, __m512)>>('_mm512_maskz_fnmadd_ps');
  late final __mm512_maskz_fnmadd_ps = __mm512_maskz_fnmadd_psPtr
      .asFunction<__m512 Function(int, __m512, __m512, __m512)>();

  __m512 _mm512_fnmadd_round_ps(
    __m512 arg0,
    __m512 arg1,
    __m512 arg2,
    int arg3,
  ) {
    return __mm512_fnmadd_round_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_fnmadd_round_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(
              __m512, __m512, __m512, ffi.Int32)>>('_mm512_fnmadd_round_ps');
  late final __mm512_fnmadd_round_ps = __mm512_fnmadd_round_psPtr
      .asFunction<__m512 Function(__m512, __m512, __m512, int)>();

  __m512 _mm512_mask_fnmadd_round_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
    __m512 arg3,
    int arg4,
  ) {
    return __mm512_mask_fnmadd_round_ps(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_fnmadd_round_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__m512, __mmask16, __m512, __m512,
              ffi.Int32)>>('_mm512_mask_fnmadd_round_ps');
  late final __mm512_mask_fnmadd_round_ps = __mm512_mask_fnmadd_round_psPtr
      .asFunction<__m512 Function(__m512, int, __m512, __m512, int)>();

  __m512 _mm512_mask3_fnmadd_round_ps(
    __m512 arg0,
    __m512 arg1,
    __m512 arg2,
    int arg3,
    int arg4,
  ) {
    return __mm512_mask3_fnmadd_round_ps(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask3_fnmadd_round_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__m512, __m512, __m512, __mmask16,
              ffi.Int32)>>('_mm512_mask3_fnmadd_round_ps');
  late final __mm512_mask3_fnmadd_round_ps = __mm512_mask3_fnmadd_round_psPtr
      .asFunction<__m512 Function(__m512, __m512, __m512, int, int)>();

  __m512 _mm512_maskz_fnmadd_round_ps(
    int arg0,
    __m512 arg1,
    __m512 arg2,
    __m512 arg3,
    int arg4,
  ) {
    return __mm512_maskz_fnmadd_round_ps(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_maskz_fnmadd_round_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__mmask16, __m512, __m512, __m512,
              ffi.Int32)>>('_mm512_maskz_fnmadd_round_ps');
  late final __mm512_maskz_fnmadd_round_ps = __mm512_maskz_fnmadd_round_psPtr
      .asFunction<__m512 Function(int, __m512, __m512, __m512, int)>();

  _m512d _mm512_fnmadd_pd(
    _m512d arg0,
    _m512d arg1,
    _m512d arg2,
  ) {
    return __mm512_fnmadd_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_fnmadd_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, _m512d, _m512d)>>(
          '_mm512_fnmadd_pd');
  late final __mm512_fnmadd_pd = __mm512_fnmadd_pdPtr
      .asFunction<_m512d Function(_m512d, _m512d, _m512d)>();

  _m512d _mm512_mask_fnmadd_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
    _m512d arg3,
  ) {
    return __mm512_mask_fnmadd_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_fnmadd_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(
              _m512d, __mmask8, _m512d, _m512d)>>('_mm512_mask_fnmadd_pd');
  late final __mm512_mask_fnmadd_pd = __mm512_mask_fnmadd_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d, _m512d)>();

  _m512d _mm512_mask3_fnmadd_pd(
    _m512d arg0,
    _m512d arg1,
    _m512d arg2,
    int arg3,
  ) {
    return __mm512_mask3_fnmadd_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask3_fnmadd_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(
              _m512d, _m512d, _m512d, __mmask8)>>('_mm512_mask3_fnmadd_pd');
  late final __mm512_mask3_fnmadd_pd = __mm512_mask3_fnmadd_pdPtr
      .asFunction<_m512d Function(_m512d, _m512d, _m512d, int)>();

  _m512d _mm512_maskz_fnmadd_pd(
    int arg0,
    _m512d arg1,
    _m512d arg2,
    _m512d arg3,
  ) {
    return __mm512_maskz_fnmadd_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_fnmadd_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(
              __mmask8, _m512d, _m512d, _m512d)>>('_mm512_maskz_fnmadd_pd');
  late final __mm512_maskz_fnmadd_pd = __mm512_maskz_fnmadd_pdPtr
      .asFunction<_m512d Function(int, _m512d, _m512d, _m512d)>();

  _m512d _mm512_fnmadd_round_pd(
    _m512d arg0,
    _m512d arg1,
    _m512d arg2,
    int arg3,
  ) {
    return __mm512_fnmadd_round_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_fnmadd_round_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(
              _m512d, _m512d, _m512d, ffi.Int32)>>('_mm512_fnmadd_round_pd');
  late final __mm512_fnmadd_round_pd = __mm512_fnmadd_round_pdPtr
      .asFunction<_m512d Function(_m512d, _m512d, _m512d, int)>();

  _m512d _mm512_mask_fnmadd_round_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
    _m512d arg3,
    int arg4,
  ) {
    return __mm512_mask_fnmadd_round_pd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_fnmadd_round_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(_m512d, __mmask8, _m512d, _m512d,
              ffi.Int32)>>('_mm512_mask_fnmadd_round_pd');
  late final __mm512_mask_fnmadd_round_pd = __mm512_mask_fnmadd_round_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d, _m512d, int)>();

  _m512d _mm512_mask3_fnmadd_round_pd(
    _m512d arg0,
    _m512d arg1,
    _m512d arg2,
    int arg3,
    int arg4,
  ) {
    return __mm512_mask3_fnmadd_round_pd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask3_fnmadd_round_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(_m512d, _m512d, _m512d, __mmask8,
              ffi.Int32)>>('_mm512_mask3_fnmadd_round_pd');
  late final __mm512_mask3_fnmadd_round_pd = __mm512_mask3_fnmadd_round_pdPtr
      .asFunction<_m512d Function(_m512d, _m512d, _m512d, int, int)>();

  _m512d _mm512_maskz_fnmadd_round_pd(
    int arg0,
    _m512d arg1,
    _m512d arg2,
    _m512d arg3,
    int arg4,
  ) {
    return __mm512_maskz_fnmadd_round_pd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_maskz_fnmadd_round_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(__mmask8, _m512d, _m512d, _m512d,
              ffi.Int32)>>('_mm512_maskz_fnmadd_round_pd');
  late final __mm512_maskz_fnmadd_round_pd = __mm512_maskz_fnmadd_round_pdPtr
      .asFunction<_m512d Function(int, _m512d, _m512d, _m512d, int)>();

  __m512 _mm512_fnmsub_ps(
    __m512 arg0,
    __m512 arg1,
    __m512 arg2,
  ) {
    return __mm512_fnmsub_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_fnmsub_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __m512, __m512)>>(
          '_mm512_fnmsub_ps');
  late final __mm512_fnmsub_ps = __mm512_fnmsub_psPtr
      .asFunction<__m512 Function(__m512, __m512, __m512)>();

  __m512 _mm512_mask_fnmsub_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
    __m512 arg3,
  ) {
    return __mm512_mask_fnmsub_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_fnmsub_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(
              __m512, __mmask16, __m512, __m512)>>('_mm512_mask_fnmsub_ps');
  late final __mm512_mask_fnmsub_ps = __mm512_mask_fnmsub_psPtr
      .asFunction<__m512 Function(__m512, int, __m512, __m512)>();

  __m512 _mm512_mask3_fnmsub_ps(
    __m512 arg0,
    __m512 arg1,
    __m512 arg2,
    int arg3,
  ) {
    return __mm512_mask3_fnmsub_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask3_fnmsub_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(
              __m512, __m512, __m512, __mmask16)>>('_mm512_mask3_fnmsub_ps');
  late final __mm512_mask3_fnmsub_ps = __mm512_mask3_fnmsub_psPtr
      .asFunction<__m512 Function(__m512, __m512, __m512, int)>();

  __m512 _mm512_maskz_fnmsub_ps(
    int arg0,
    __m512 arg1,
    __m512 arg2,
    __m512 arg3,
  ) {
    return __mm512_maskz_fnmsub_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_fnmsub_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(
              __mmask16, __m512, __m512, __m512)>>('_mm512_maskz_fnmsub_ps');
  late final __mm512_maskz_fnmsub_ps = __mm512_maskz_fnmsub_psPtr
      .asFunction<__m512 Function(int, __m512, __m512, __m512)>();

  __m512 _mm512_fnmsub_round_ps(
    __m512 arg0,
    __m512 arg1,
    __m512 arg2,
    int arg3,
  ) {
    return __mm512_fnmsub_round_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_fnmsub_round_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(
              __m512, __m512, __m512, ffi.Int32)>>('_mm512_fnmsub_round_ps');
  late final __mm512_fnmsub_round_ps = __mm512_fnmsub_round_psPtr
      .asFunction<__m512 Function(__m512, __m512, __m512, int)>();

  __m512 _mm512_mask_fnmsub_round_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
    __m512 arg3,
    int arg4,
  ) {
    return __mm512_mask_fnmsub_round_ps(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_fnmsub_round_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__m512, __mmask16, __m512, __m512,
              ffi.Int32)>>('_mm512_mask_fnmsub_round_ps');
  late final __mm512_mask_fnmsub_round_ps = __mm512_mask_fnmsub_round_psPtr
      .asFunction<__m512 Function(__m512, int, __m512, __m512, int)>();

  __m512 _mm512_mask3_fnmsub_round_ps(
    __m512 arg0,
    __m512 arg1,
    __m512 arg2,
    int arg3,
    int arg4,
  ) {
    return __mm512_mask3_fnmsub_round_ps(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask3_fnmsub_round_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__m512, __m512, __m512, __mmask16,
              ffi.Int32)>>('_mm512_mask3_fnmsub_round_ps');
  late final __mm512_mask3_fnmsub_round_ps = __mm512_mask3_fnmsub_round_psPtr
      .asFunction<__m512 Function(__m512, __m512, __m512, int, int)>();

  __m512 _mm512_maskz_fnmsub_round_ps(
    int arg0,
    __m512 arg1,
    __m512 arg2,
    __m512 arg3,
    int arg4,
  ) {
    return __mm512_maskz_fnmsub_round_ps(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_maskz_fnmsub_round_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__mmask16, __m512, __m512, __m512,
              ffi.Int32)>>('_mm512_maskz_fnmsub_round_ps');
  late final __mm512_maskz_fnmsub_round_ps = __mm512_maskz_fnmsub_round_psPtr
      .asFunction<__m512 Function(int, __m512, __m512, __m512, int)>();

  _m512d _mm512_fnmsub_pd(
    _m512d arg0,
    _m512d arg1,
    _m512d arg2,
  ) {
    return __mm512_fnmsub_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_fnmsub_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, _m512d, _m512d)>>(
          '_mm512_fnmsub_pd');
  late final __mm512_fnmsub_pd = __mm512_fnmsub_pdPtr
      .asFunction<_m512d Function(_m512d, _m512d, _m512d)>();

  _m512d _mm512_mask_fnmsub_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
    _m512d arg3,
  ) {
    return __mm512_mask_fnmsub_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_fnmsub_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(
              _m512d, __mmask8, _m512d, _m512d)>>('_mm512_mask_fnmsub_pd');
  late final __mm512_mask_fnmsub_pd = __mm512_mask_fnmsub_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d, _m512d)>();

  _m512d _mm512_mask3_fnmsub_pd(
    _m512d arg0,
    _m512d arg1,
    _m512d arg2,
    int arg3,
  ) {
    return __mm512_mask3_fnmsub_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask3_fnmsub_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(
              _m512d, _m512d, _m512d, __mmask8)>>('_mm512_mask3_fnmsub_pd');
  late final __mm512_mask3_fnmsub_pd = __mm512_mask3_fnmsub_pdPtr
      .asFunction<_m512d Function(_m512d, _m512d, _m512d, int)>();

  _m512d _mm512_maskz_fnmsub_pd(
    int arg0,
    _m512d arg1,
    _m512d arg2,
    _m512d arg3,
  ) {
    return __mm512_maskz_fnmsub_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_fnmsub_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(
              __mmask8, _m512d, _m512d, _m512d)>>('_mm512_maskz_fnmsub_pd');
  late final __mm512_maskz_fnmsub_pd = __mm512_maskz_fnmsub_pdPtr
      .asFunction<_m512d Function(int, _m512d, _m512d, _m512d)>();

  _m512d _mm512_fnmsub_round_pd(
    _m512d arg0,
    _m512d arg1,
    _m512d arg2,
    int arg3,
  ) {
    return __mm512_fnmsub_round_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_fnmsub_round_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(
              _m512d, _m512d, _m512d, ffi.Int32)>>('_mm512_fnmsub_round_pd');
  late final __mm512_fnmsub_round_pd = __mm512_fnmsub_round_pdPtr
      .asFunction<_m512d Function(_m512d, _m512d, _m512d, int)>();

  _m512d _mm512_mask_fnmsub_round_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
    _m512d arg3,
    int arg4,
  ) {
    return __mm512_mask_fnmsub_round_pd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_fnmsub_round_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(_m512d, __mmask8, _m512d, _m512d,
              ffi.Int32)>>('_mm512_mask_fnmsub_round_pd');
  late final __mm512_mask_fnmsub_round_pd = __mm512_mask_fnmsub_round_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d, _m512d, int)>();

  _m512d _mm512_mask3_fnmsub_round_pd(
    _m512d arg0,
    _m512d arg1,
    _m512d arg2,
    int arg3,
    int arg4,
  ) {
    return __mm512_mask3_fnmsub_round_pd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask3_fnmsub_round_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(_m512d, _m512d, _m512d, __mmask8,
              ffi.Int32)>>('_mm512_mask3_fnmsub_round_pd');
  late final __mm512_mask3_fnmsub_round_pd = __mm512_mask3_fnmsub_round_pdPtr
      .asFunction<_m512d Function(_m512d, _m512d, _m512d, int, int)>();

  _m512d _mm512_maskz_fnmsub_round_pd(
    int arg0,
    _m512d arg1,
    _m512d arg2,
    _m512d arg3,
    int arg4,
  ) {
    return __mm512_maskz_fnmsub_round_pd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_maskz_fnmsub_round_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(__mmask8, _m512d, _m512d, _m512d,
              ffi.Int32)>>('_mm512_maskz_fnmsub_round_pd');
  late final __mm512_maskz_fnmsub_round_pd = __mm512_maskz_fnmsub_round_pdPtr
      .asFunction<_m512d Function(int, _m512d, _m512d, _m512d, int)>();

  __m512 _mm512_sqrt_ps(
    __m512 arg0,
  ) {
    return __mm512_sqrt_ps(
      arg0,
    );
  }

  late final __mm512_sqrt_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512)>>('_mm512_sqrt_ps');
  late final __mm512_sqrt_ps =
      __mm512_sqrt_psPtr.asFunction<__m512 Function(__m512)>();

  _m512d _mm512_sqrt_pd(
    _m512d arg0,
  ) {
    return __mm512_sqrt_pd(
      arg0,
    );
  }

  late final __mm512_sqrt_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d)>>('_mm512_sqrt_pd');
  late final __mm512_sqrt_pd =
      __mm512_sqrt_pdPtr.asFunction<_m512d Function(_m512d)>();

  __m512 _mm512_maskz_sqrt_ps(
    int arg0,
    __m512 arg1,
  ) {
    return __mm512_maskz_sqrt_ps(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_sqrt_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__mmask16, __m512)>>(
          '_mm512_maskz_sqrt_ps');
  late final __mm512_maskz_sqrt_ps =
      __mm512_maskz_sqrt_psPtr.asFunction<__m512 Function(int, __m512)>();

  _m512d _mm512_maskz_sqrt_pd(
    int arg0,
    _m512d arg1,
  ) {
    return __mm512_maskz_sqrt_pd(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_sqrt_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(__mmask8, _m512d)>>(
          '_mm512_maskz_sqrt_pd');
  late final __mm512_maskz_sqrt_pd =
      __mm512_maskz_sqrt_pdPtr.asFunction<_m512d Function(int, _m512d)>();

  __m512 _mm512_mask_sqrt_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
  ) {
    return __mm512_mask_sqrt_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_sqrt_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __mmask16, __m512)>>(
          '_mm512_mask_sqrt_ps');
  late final __mm512_mask_sqrt_ps = __mm512_mask_sqrt_psPtr
      .asFunction<__m512 Function(__m512, int, __m512)>();

  _m512d _mm512_mask_sqrt_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
  ) {
    return __mm512_mask_sqrt_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_sqrt_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, __mmask8, _m512d)>>(
          '_mm512_mask_sqrt_pd');
  late final __mm512_mask_sqrt_pd = __mm512_mask_sqrt_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d)>();

  __m512 _mm512_sqrt_round_ps(
    __m512 arg0,
    int arg1,
  ) {
    return __mm512_sqrt_round_ps(
      arg0,
      arg1,
    );
  }

  late final __mm512_sqrt_round_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, ffi.Int32)>>(
          '_mm512_sqrt_round_ps');
  late final __mm512_sqrt_round_ps =
      __mm512_sqrt_round_psPtr.asFunction<__m512 Function(__m512, int)>();

  _m512d _mm512_sqrt_round_pd(
    _m512d arg0,
    int arg1,
  ) {
    return __mm512_sqrt_round_pd(
      arg0,
      arg1,
    );
  }

  late final __mm512_sqrt_round_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, ffi.Int32)>>(
          '_mm512_sqrt_round_pd');
  late final __mm512_sqrt_round_pd =
      __mm512_sqrt_round_pdPtr.asFunction<_m512d Function(_m512d, int)>();

  __m512 _mm512_maskz_sqrt_round_ps(
    int arg0,
    __m512 arg1,
    int arg2,
  ) {
    return __mm512_maskz_sqrt_round_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_sqrt_round_psPtr = _lookup<
          ffi.NativeFunction<__m512 Function(__mmask16, __m512, ffi.Int32)>>(
      '_mm512_maskz_sqrt_round_ps');
  late final __mm512_maskz_sqrt_round_ps = __mm512_maskz_sqrt_round_psPtr
      .asFunction<__m512 Function(int, __m512, int)>();

  _m512d _mm512_maskz_sqrt_round_pd(
    int arg0,
    _m512d arg1,
    int arg2,
  ) {
    return __mm512_maskz_sqrt_round_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_sqrt_round_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(__mmask8, _m512d, ffi.Int32)>>(
          '_mm512_maskz_sqrt_round_pd');
  late final __mm512_maskz_sqrt_round_pd = __mm512_maskz_sqrt_round_pdPtr
      .asFunction<_m512d Function(int, _m512d, int)>();

  __m512 _mm512_mask_sqrt_round_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
    int arg3,
  ) {
    return __mm512_mask_sqrt_round_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_sqrt_round_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__m512, __mmask16, __m512,
              ffi.Int32)>>('_mm512_mask_sqrt_round_ps');
  late final __mm512_mask_sqrt_round_ps = __mm512_mask_sqrt_round_psPtr
      .asFunction<__m512 Function(__m512, int, __m512, int)>();

  _m512d _mm512_mask_sqrt_round_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
    int arg3,
  ) {
    return __mm512_mask_sqrt_round_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_sqrt_round_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(_m512d, __mmask8, _m512d,
              ffi.Int32)>>('_mm512_mask_sqrt_round_pd');
  late final __mm512_mask_sqrt_round_pd = __mm512_mask_sqrt_round_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d, int)>();

  __m512 _mm512_abs_ps(
    __m512 arg0,
  ) {
    return __mm512_abs_ps(
      arg0,
    );
  }

  late final __mm512_abs_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512)>>('_mm512_abs_ps');
  late final __mm512_abs_ps =
      __mm512_abs_psPtr.asFunction<__m512 Function(__m512)>();

  __m512 _mm512_maskz_abs_ps(
    int arg0,
    __m512 arg1,
  ) {
    return __mm512_maskz_abs_ps(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_abs_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__mmask16, __m512)>>(
          '_mm512_maskz_abs_ps');
  late final __mm512_maskz_abs_ps =
      __mm512_maskz_abs_psPtr.asFunction<__m512 Function(int, __m512)>();

  __m512 _mm512_mask_abs_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
  ) {
    return __mm512_mask_abs_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_abs_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __mmask16, __m512)>>(
          '_mm512_mask_abs_ps');
  late final __mm512_mask_abs_ps =
      __mm512_mask_abs_psPtr.asFunction<__m512 Function(__m512, int, __m512)>();

  _m512d _mm512_abs_pd(
    _m512d arg0,
  ) {
    return __mm512_abs_pd(
      arg0,
    );
  }

  late final __mm512_abs_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d)>>('_mm512_abs_pd');
  late final __mm512_abs_pd =
      __mm512_abs_pdPtr.asFunction<_m512d Function(_m512d)>();

  _m512d _mm512_maskz_abs_pd(
    int arg0,
    _m512d arg1,
  ) {
    return __mm512_maskz_abs_pd(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_abs_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(__mmask8, _m512d)>>(
          '_mm512_maskz_abs_pd');
  late final __mm512_maskz_abs_pd =
      __mm512_maskz_abs_pdPtr.asFunction<_m512d Function(int, _m512d)>();

  _m512d _mm512_mask_abs_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
  ) {
    return __mm512_mask_abs_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_abs_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, __mmask8, _m512d)>>(
          '_mm512_mask_abs_pd');
  late final __mm512_mask_abs_pd =
      __mm512_mask_abs_pdPtr.asFunction<_m512d Function(_m512d, int, _m512d)>();

  __m512 _mm512_max_ps(
    __m512 arg0,
    __m512 arg1,
  ) {
    return __mm512_max_ps(
      arg0,
      arg1,
    );
  }

  late final __mm512_max_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __m512)>>(
          '_mm512_max_ps');
  late final __mm512_max_ps =
      __mm512_max_psPtr.asFunction<__m512 Function(__m512, __m512)>();

  _m512d _mm512_max_pd(
    _m512d arg0,
    _m512d arg1,
  ) {
    return __mm512_max_pd(
      arg0,
      arg1,
    );
  }

  late final __mm512_max_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, _m512d)>>(
          '_mm512_max_pd');
  late final __mm512_max_pd =
      __mm512_max_pdPtr.asFunction<_m512d Function(_m512d, _m512d)>();

  __m512 _mm512_maskz_max_ps(
    int arg0,
    __m512 arg1,
    __m512 arg2,
  ) {
    return __mm512_maskz_max_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_max_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__mmask16, __m512, __m512)>>(
          '_mm512_maskz_max_ps');
  late final __mm512_maskz_max_ps = __mm512_maskz_max_psPtr
      .asFunction<__m512 Function(int, __m512, __m512)>();

  _m512d _mm512_maskz_max_pd(
    int arg0,
    _m512d arg1,
    _m512d arg2,
  ) {
    return __mm512_maskz_max_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_max_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(__mmask8, _m512d, _m512d)>>(
          '_mm512_maskz_max_pd');
  late final __mm512_maskz_max_pd = __mm512_maskz_max_pdPtr
      .asFunction<_m512d Function(int, _m512d, _m512d)>();

  __m512 _mm512_mask_max_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
    __m512 arg3,
  ) {
    return __mm512_mask_max_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_max_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(
              __m512, __mmask16, __m512, __m512)>>('_mm512_mask_max_ps');
  late final __mm512_mask_max_ps = __mm512_mask_max_psPtr
      .asFunction<__m512 Function(__m512, int, __m512, __m512)>();

  _m512d _mm512_mask_max_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
    _m512d arg3,
  ) {
    return __mm512_mask_max_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_max_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(
              _m512d, __mmask8, _m512d, _m512d)>>('_mm512_mask_max_pd');
  late final __mm512_mask_max_pd = __mm512_mask_max_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d, _m512d)>();

  __m512 _mm512_max_round_ps(
    __m512 arg0,
    __m512 arg1,
    int arg2,
  ) {
    return __mm512_max_round_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_max_round_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __m512, ffi.Int32)>>(
          '_mm512_max_round_ps');
  late final __mm512_max_round_ps = __mm512_max_round_psPtr
      .asFunction<__m512 Function(__m512, __m512, int)>();

  _m512d _mm512_max_round_pd(
    _m512d arg0,
    _m512d arg1,
    int arg2,
  ) {
    return __mm512_max_round_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_max_round_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, _m512d, ffi.Int32)>>(
          '_mm512_max_round_pd');
  late final __mm512_max_round_pd = __mm512_max_round_pdPtr
      .asFunction<_m512d Function(_m512d, _m512d, int)>();

  __m512 _mm512_maskz_max_round_ps(
    int arg0,
    __m512 arg1,
    __m512 arg2,
    int arg3,
  ) {
    return __mm512_maskz_max_round_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_max_round_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__mmask16, __m512, __m512,
              ffi.Int32)>>('_mm512_maskz_max_round_ps');
  late final __mm512_maskz_max_round_ps = __mm512_maskz_max_round_psPtr
      .asFunction<__m512 Function(int, __m512, __m512, int)>();

  _m512d _mm512_maskz_max_round_pd(
    int arg0,
    _m512d arg1,
    _m512d arg2,
    int arg3,
  ) {
    return __mm512_maskz_max_round_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_max_round_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(__mmask8, _m512d, _m512d,
              ffi.Int32)>>('_mm512_maskz_max_round_pd');
  late final __mm512_maskz_max_round_pd = __mm512_maskz_max_round_pdPtr
      .asFunction<_m512d Function(int, _m512d, _m512d, int)>();

  __m512 _mm512_mask_max_round_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
    __m512 arg3,
    int arg4,
  ) {
    return __mm512_mask_max_round_ps(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_max_round_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__m512, __mmask16, __m512, __m512,
              ffi.Int32)>>('_mm512_mask_max_round_ps');
  late final __mm512_mask_max_round_ps = __mm512_mask_max_round_psPtr
      .asFunction<__m512 Function(__m512, int, __m512, __m512, int)>();

  _m512d _mm512_mask_max_round_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
    _m512d arg3,
    int arg4,
  ) {
    return __mm512_mask_max_round_pd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_max_round_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(_m512d, __mmask8, _m512d, _m512d,
              ffi.Int32)>>('_mm512_mask_max_round_pd');
  late final __mm512_mask_max_round_pd = __mm512_mask_max_round_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d, _m512d, int)>();

  __m512 _mm512_min_ps(
    __m512 arg0,
    __m512 arg1,
  ) {
    return __mm512_min_ps(
      arg0,
      arg1,
    );
  }

  late final __mm512_min_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __m512)>>(
          '_mm512_min_ps');
  late final __mm512_min_ps =
      __mm512_min_psPtr.asFunction<__m512 Function(__m512, __m512)>();

  _m512d _mm512_min_pd(
    _m512d arg0,
    _m512d arg1,
  ) {
    return __mm512_min_pd(
      arg0,
      arg1,
    );
  }

  late final __mm512_min_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, _m512d)>>(
          '_mm512_min_pd');
  late final __mm512_min_pd =
      __mm512_min_pdPtr.asFunction<_m512d Function(_m512d, _m512d)>();

  __m512 _mm512_maskz_min_ps(
    int arg0,
    __m512 arg1,
    __m512 arg2,
  ) {
    return __mm512_maskz_min_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_min_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__mmask16, __m512, __m512)>>(
          '_mm512_maskz_min_ps');
  late final __mm512_maskz_min_ps = __mm512_maskz_min_psPtr
      .asFunction<__m512 Function(int, __m512, __m512)>();

  _m512d _mm512_maskz_min_pd(
    int arg0,
    _m512d arg1,
    _m512d arg2,
  ) {
    return __mm512_maskz_min_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_min_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(__mmask8, _m512d, _m512d)>>(
          '_mm512_maskz_min_pd');
  late final __mm512_maskz_min_pd = __mm512_maskz_min_pdPtr
      .asFunction<_m512d Function(int, _m512d, _m512d)>();

  __m512 _mm512_mask_min_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
    __m512 arg3,
  ) {
    return __mm512_mask_min_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_min_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(
              __m512, __mmask16, __m512, __m512)>>('_mm512_mask_min_ps');
  late final __mm512_mask_min_ps = __mm512_mask_min_psPtr
      .asFunction<__m512 Function(__m512, int, __m512, __m512)>();

  _m512d _mm512_mask_min_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
    _m512d arg3,
  ) {
    return __mm512_mask_min_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_min_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(
              _m512d, __mmask8, _m512d, _m512d)>>('_mm512_mask_min_pd');
  late final __mm512_mask_min_pd = __mm512_mask_min_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d, _m512d)>();

  __m512 _mm512_min_round_ps(
    __m512 arg0,
    __m512 arg1,
    int arg2,
  ) {
    return __mm512_min_round_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_min_round_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __m512, ffi.Int32)>>(
          '_mm512_min_round_ps');
  late final __mm512_min_round_ps = __mm512_min_round_psPtr
      .asFunction<__m512 Function(__m512, __m512, int)>();

  _m512d _mm512_min_round_pd(
    _m512d arg0,
    _m512d arg1,
    int arg2,
  ) {
    return __mm512_min_round_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_min_round_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, _m512d, ffi.Int32)>>(
          '_mm512_min_round_pd');
  late final __mm512_min_round_pd = __mm512_min_round_pdPtr
      .asFunction<_m512d Function(_m512d, _m512d, int)>();

  __m512 _mm512_maskz_min_round_ps(
    int arg0,
    __m512 arg1,
    __m512 arg2,
    int arg3,
  ) {
    return __mm512_maskz_min_round_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_min_round_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__mmask16, __m512, __m512,
              ffi.Int32)>>('_mm512_maskz_min_round_ps');
  late final __mm512_maskz_min_round_ps = __mm512_maskz_min_round_psPtr
      .asFunction<__m512 Function(int, __m512, __m512, int)>();

  _m512d _mm512_maskz_min_round_pd(
    int arg0,
    _m512d arg1,
    _m512d arg2,
    int arg3,
  ) {
    return __mm512_maskz_min_round_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_min_round_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(__mmask8, _m512d, _m512d,
              ffi.Int32)>>('_mm512_maskz_min_round_pd');
  late final __mm512_maskz_min_round_pd = __mm512_maskz_min_round_pdPtr
      .asFunction<_m512d Function(int, _m512d, _m512d, int)>();

  __m512 _mm512_mask_min_round_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
    __m512 arg3,
    int arg4,
  ) {
    return __mm512_mask_min_round_ps(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_min_round_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__m512, __mmask16, __m512, __m512,
              ffi.Int32)>>('_mm512_mask_min_round_ps');
  late final __mm512_mask_min_round_ps = __mm512_mask_min_round_psPtr
      .asFunction<__m512 Function(__m512, int, __m512, __m512, int)>();

  _m512d _mm512_mask_min_round_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
    _m512d arg3,
    int arg4,
  ) {
    return __mm512_mask_min_round_pd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_min_round_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(_m512d, __mmask8, _m512d, _m512d,
              ffi.Int32)>>('_mm512_mask_min_round_pd');
  late final __mm512_mask_min_round_pd = __mm512_mask_min_round_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d, _m512d, int)>();

  __m512 _mm512_rcp14_ps(
    __m512 arg0,
  ) {
    return __mm512_rcp14_ps(
      arg0,
    );
  }

  late final __mm512_rcp14_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512)>>('_mm512_rcp14_ps');
  late final __mm512_rcp14_ps =
      __mm512_rcp14_psPtr.asFunction<__m512 Function(__m512)>();

  _m512d _mm512_rcp14_pd(
    _m512d arg0,
  ) {
    return __mm512_rcp14_pd(
      arg0,
    );
  }

  late final __mm512_rcp14_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d)>>('_mm512_rcp14_pd');
  late final __mm512_rcp14_pd =
      __mm512_rcp14_pdPtr.asFunction<_m512d Function(_m512d)>();

  __m512 _mm512_maskz_rcp14_ps(
    int arg0,
    __m512 arg1,
  ) {
    return __mm512_maskz_rcp14_ps(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_rcp14_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__mmask16, __m512)>>(
          '_mm512_maskz_rcp14_ps');
  late final __mm512_maskz_rcp14_ps =
      __mm512_maskz_rcp14_psPtr.asFunction<__m512 Function(int, __m512)>();

  _m512d _mm512_maskz_rcp14_pd(
    int arg0,
    _m512d arg1,
  ) {
    return __mm512_maskz_rcp14_pd(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_rcp14_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(__mmask8, _m512d)>>(
          '_mm512_maskz_rcp14_pd');
  late final __mm512_maskz_rcp14_pd =
      __mm512_maskz_rcp14_pdPtr.asFunction<_m512d Function(int, _m512d)>();

  __m512 _mm512_mask_rcp14_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
  ) {
    return __mm512_mask_rcp14_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_rcp14_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __mmask16, __m512)>>(
          '_mm512_mask_rcp14_ps');
  late final __mm512_mask_rcp14_ps = __mm512_mask_rcp14_psPtr
      .asFunction<__m512 Function(__m512, int, __m512)>();

  _m512d _mm512_mask_rcp14_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
  ) {
    return __mm512_mask_rcp14_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_rcp14_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, __mmask8, _m512d)>>(
          '_mm512_mask_rcp14_pd');
  late final __mm512_mask_rcp14_pd = __mm512_mask_rcp14_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d)>();

  __m512 _mm512_rsqrt14_ps(
    __m512 arg0,
  ) {
    return __mm512_rsqrt14_ps(
      arg0,
    );
  }

  late final __mm512_rsqrt14_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512)>>('_mm512_rsqrt14_ps');
  late final __mm512_rsqrt14_ps =
      __mm512_rsqrt14_psPtr.asFunction<__m512 Function(__m512)>();

  _m512d _mm512_rsqrt14_pd(
    _m512d arg0,
  ) {
    return __mm512_rsqrt14_pd(
      arg0,
    );
  }

  late final __mm512_rsqrt14_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d)>>('_mm512_rsqrt14_pd');
  late final __mm512_rsqrt14_pd =
      __mm512_rsqrt14_pdPtr.asFunction<_m512d Function(_m512d)>();

  __m512 _mm512_maskz_rsqrt14_ps(
    int arg0,
    __m512 arg1,
  ) {
    return __mm512_maskz_rsqrt14_ps(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_rsqrt14_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__mmask16, __m512)>>(
          '_mm512_maskz_rsqrt14_ps');
  late final __mm512_maskz_rsqrt14_ps =
      __mm512_maskz_rsqrt14_psPtr.asFunction<__m512 Function(int, __m512)>();

  _m512d _mm512_maskz_rsqrt14_pd(
    int arg0,
    _m512d arg1,
  ) {
    return __mm512_maskz_rsqrt14_pd(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_rsqrt14_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(__mmask8, _m512d)>>(
          '_mm512_maskz_rsqrt14_pd');
  late final __mm512_maskz_rsqrt14_pd =
      __mm512_maskz_rsqrt14_pdPtr.asFunction<_m512d Function(int, _m512d)>();

  __m512 _mm512_mask_rsqrt14_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
  ) {
    return __mm512_mask_rsqrt14_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_rsqrt14_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __mmask16, __m512)>>(
          '_mm512_mask_rsqrt14_ps');
  late final __mm512_mask_rsqrt14_ps = __mm512_mask_rsqrt14_psPtr
      .asFunction<__m512 Function(__m512, int, __m512)>();

  _m512d _mm512_mask_rsqrt14_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
  ) {
    return __mm512_mask_rsqrt14_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_rsqrt14_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, __mmask8, _m512d)>>(
          '_mm512_mask_rsqrt14_pd');
  late final __mm512_mask_rsqrt14_pd = __mm512_mask_rsqrt14_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d)>();

  _m512d _mm512_cvtps_pd(
    __m256 arg0,
  ) {
    return __mm512_cvtps_pd(
      arg0,
    );
  }

  late final __mm512_cvtps_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(__m256)>>('_mm512_cvtps_pd');
  late final __mm512_cvtps_pd =
      __mm512_cvtps_pdPtr.asFunction<_m512d Function(__m256)>();

  __m256 _mm512_cvtpd_ps(
    _m512d arg0,
  ) {
    return __mm512_cvtpd_ps(
      arg0,
    );
  }

  late final __mm512_cvtpd_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(_m512d)>>('_mm512_cvtpd_ps');
  late final __mm512_cvtpd_ps =
      __mm512_cvtpd_psPtr.asFunction<__m256 Function(_m512d)>();

  _m512d _mm512_maskz_cvtps_pd(
    int arg0,
    __m256 arg1,
  ) {
    return __mm512_maskz_cvtps_pd(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvtps_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(__mmask8, __m256)>>(
          '_mm512_maskz_cvtps_pd');
  late final __mm512_maskz_cvtps_pd =
      __mm512_maskz_cvtps_pdPtr.asFunction<_m512d Function(int, __m256)>();

  __m256 _mm512_maskz_cvtpd_ps(
    int arg0,
    _m512d arg1,
  ) {
    return __mm512_maskz_cvtpd_ps(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvtpd_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__mmask8, _m512d)>>(
          '_mm512_maskz_cvtpd_ps');
  late final __mm512_maskz_cvtpd_ps =
      __mm512_maskz_cvtpd_psPtr.asFunction<__m256 Function(int, _m512d)>();

  _m512d _mm512_mask_cvtps_pd(
    _m512d arg0,
    int arg1,
    __m256 arg2,
  ) {
    return __mm512_mask_cvtps_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtps_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, __mmask8, __m256)>>(
          '_mm512_mask_cvtps_pd');
  late final __mm512_mask_cvtps_pd = __mm512_mask_cvtps_pdPtr
      .asFunction<_m512d Function(_m512d, int, __m256)>();

  __m256 _mm512_mask_cvtpd_ps(
    __m256 arg0,
    int arg1,
    _m512d arg2,
  ) {
    return __mm512_mask_cvtpd_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtpd_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256, __mmask8, _m512d)>>(
          '_mm512_mask_cvtpd_ps');
  late final __mm512_mask_cvtpd_ps = __mm512_mask_cvtpd_psPtr
      .asFunction<__m256 Function(__m256, int, _m512d)>();

  _m512d _mm512_cvt_roundps_pd(
    __m256 arg0,
    int arg1,
  ) {
    return __mm512_cvt_roundps_pd(
      arg0,
      arg1,
    );
  }

  late final __mm512_cvt_roundps_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(__m256, ffi.Int32)>>(
          '_mm512_cvt_roundps_pd');
  late final __mm512_cvt_roundps_pd =
      __mm512_cvt_roundps_pdPtr.asFunction<_m512d Function(__m256, int)>();

  __m256 _mm512_cvt_roundpd_ps(
    _m512d arg0,
    int arg1,
  ) {
    return __mm512_cvt_roundpd_ps(
      arg0,
      arg1,
    );
  }

  late final __mm512_cvt_roundpd_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(_m512d, ffi.Int32)>>(
          '_mm512_cvt_roundpd_ps');
  late final __mm512_cvt_roundpd_ps =
      __mm512_cvt_roundpd_psPtr.asFunction<__m256 Function(_m512d, int)>();

  _m512d _mm512_maskz_cvt_roundps_pd(
    int arg0,
    __m256 arg1,
    int arg2,
  ) {
    return __mm512_maskz_cvt_roundps_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_cvt_roundps_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(__mmask8, __m256, ffi.Int32)>>(
          '_mm512_maskz_cvt_roundps_pd');
  late final __mm512_maskz_cvt_roundps_pd = __mm512_maskz_cvt_roundps_pdPtr
      .asFunction<_m512d Function(int, __m256, int)>();

  __m256 _mm512_maskz_cvt_roundpd_ps(
    int arg0,
    _m512d arg1,
    int arg2,
  ) {
    return __mm512_maskz_cvt_roundpd_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_cvt_roundpd_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__mmask8, _m512d, ffi.Int32)>>(
          '_mm512_maskz_cvt_roundpd_ps');
  late final __mm512_maskz_cvt_roundpd_ps = __mm512_maskz_cvt_roundpd_psPtr
      .asFunction<__m256 Function(int, _m512d, int)>();

  _m512d _mm512_mask_cvt_roundps_pd(
    _m512d arg0,
    int arg1,
    __m256 arg2,
    int arg3,
  ) {
    return __mm512_mask_cvt_roundps_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_cvt_roundps_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(_m512d, __mmask8, __m256,
              ffi.Int32)>>('_mm512_mask_cvt_roundps_pd');
  late final __mm512_mask_cvt_roundps_pd = __mm512_mask_cvt_roundps_pdPtr
      .asFunction<_m512d Function(_m512d, int, __m256, int)>();

  __m256 _mm512_mask_cvt_roundpd_ps(
    __m256 arg0,
    int arg1,
    _m512d arg2,
    int arg3,
  ) {
    return __mm512_mask_cvt_roundpd_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_cvt_roundpd_psPtr = _lookup<
      ffi.NativeFunction<
          __m256 Function(__m256, __mmask8, _m512d,
              ffi.Int32)>>('_mm512_mask_cvt_roundpd_ps');
  late final __mm512_mask_cvt_roundpd_ps = __mm512_mask_cvt_roundpd_psPtr
      .asFunction<__m256 Function(__m256, int, _m512d, int)>();

  int _mm512_cmp_ps_mask(
    __m512 arg0,
    __m512 arg1,
    int arg2,
  ) {
    return __mm512_cmp_ps_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_cmp_ps_maskPtr = _lookup<
          ffi.NativeFunction<__mmask16 Function(__m512, __m512, ffi.Int32)>>(
      '_mm512_cmp_ps_mask');
  late final __mm512_cmp_ps_mask =
      __mm512_cmp_ps_maskPtr.asFunction<int Function(__m512, __m512, int)>();

  int _mm512_mask_cmp_ps_mask(
    int arg0,
    __m512 arg1,
    __m512 arg2,
    int arg3,
  ) {
    return __mm512_mask_cmp_ps_mask(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_cmp_ps_maskPtr = _lookup<
      ffi.NativeFunction<
          __mmask16 Function(__mmask16, __m512, __m512,
              ffi.Int32)>>('_mm512_mask_cmp_ps_mask');
  late final __mm512_mask_cmp_ps_mask = __mm512_mask_cmp_ps_maskPtr
      .asFunction<int Function(int, __m512, __m512, int)>();

  int _mm512_cmp_round_ps_mask(
    __m512 arg0,
    __m512 arg1,
    int arg2,
    int arg3,
  ) {
    return __mm512_cmp_round_ps_mask(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_cmp_round_ps_maskPtr = _lookup<
      ffi.NativeFunction<
          __mmask16 Function(__m512, __m512, ffi.Int32,
              ffi.Int32)>>('_mm512_cmp_round_ps_mask');
  late final __mm512_cmp_round_ps_mask = __mm512_cmp_round_ps_maskPtr
      .asFunction<int Function(__m512, __m512, int, int)>();

  int _mm512_mask_cmp_round_ps_mask(
    int arg0,
    __m512 arg1,
    __m512 arg2,
    int arg3,
    int arg4,
  ) {
    return __mm512_mask_cmp_round_ps_mask(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_cmp_round_ps_maskPtr = _lookup<
      ffi.NativeFunction<
          __mmask16 Function(__mmask16, __m512, __m512, ffi.Int32,
              ffi.Int32)>>('_mm512_mask_cmp_round_ps_mask');
  late final __mm512_mask_cmp_round_ps_mask = __mm512_mask_cmp_round_ps_maskPtr
      .asFunction<int Function(int, __m512, __m512, int, int)>();

  int _mm512_cmp_pd_mask(
    _m512d arg0,
    _m512d arg1,
    int arg2,
  ) {
    return __mm512_cmp_pd_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_cmp_pd_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(_m512d, _m512d, ffi.Int32)>>(
          '_mm512_cmp_pd_mask');
  late final __mm512_cmp_pd_mask =
      __mm512_cmp_pd_maskPtr.asFunction<int Function(_m512d, _m512d, int)>();

  int _mm512_mask_cmp_pd_mask(
    int arg0,
    _m512d arg1,
    _m512d arg2,
    int arg3,
  ) {
    return __mm512_mask_cmp_pd_mask(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_cmp_pd_maskPtr = _lookup<
      ffi.NativeFunction<
          __mmask8 Function(
              __mmask8, _m512d, _m512d, ffi.Int32)>>('_mm512_mask_cmp_pd_mask');
  late final __mm512_mask_cmp_pd_mask = __mm512_mask_cmp_pd_maskPtr
      .asFunction<int Function(int, _m512d, _m512d, int)>();

  int _mm512_cmp_round_pd_mask(
    _m512d arg0,
    _m512d arg1,
    int arg2,
    int arg3,
  ) {
    return __mm512_cmp_round_pd_mask(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_cmp_round_pd_maskPtr = _lookup<
      ffi.NativeFunction<
          __mmask8 Function(_m512d, _m512d, ffi.Int32,
              ffi.Int32)>>('_mm512_cmp_round_pd_mask');
  late final __mm512_cmp_round_pd_mask = __mm512_cmp_round_pd_maskPtr
      .asFunction<int Function(_m512d, _m512d, int, int)>();

  int _mm512_mask_cmp_round_pd_mask(
    int arg0,
    _m512d arg1,
    _m512d arg2,
    int arg3,
    int arg4,
  ) {
    return __mm512_mask_cmp_round_pd_mask(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_cmp_round_pd_maskPtr = _lookup<
      ffi.NativeFunction<
          __mmask8 Function(__mmask8, _m512d, _m512d, ffi.Int32,
              ffi.Int32)>>('_mm512_mask_cmp_round_pd_mask');
  late final __mm512_mask_cmp_round_pd_mask = __mm512_mask_cmp_round_pd_maskPtr
      .asFunction<int Function(int, _m512d, _m512d, int, int)>();

  __m512 _mm512_broadcast_f32x2(
    __m128 arg0,
  ) {
    return __mm512_broadcast_f32x2(
      arg0,
    );
  }

  late final __mm512_broadcast_f32x2Ptr =
      _lookup<ffi.NativeFunction<__m512 Function(__m128)>>(
          '_mm512_broadcast_f32x2');
  late final __mm512_broadcast_f32x2 =
      __mm512_broadcast_f32x2Ptr.asFunction<__m512 Function(__m128)>();

  __m512 _mm512_mask_broadcast_f32x2(
    __m512 arg0,
    int arg1,
    __m128 arg2,
  ) {
    return __mm512_mask_broadcast_f32x2(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_broadcast_f32x2Ptr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __mmask16, __m128)>>(
          '_mm512_mask_broadcast_f32x2');
  late final __mm512_mask_broadcast_f32x2 = __mm512_mask_broadcast_f32x2Ptr
      .asFunction<__m512 Function(__m512, int, __m128)>();

  __m512 _mm512_maskz_broadcast_f32x2(
    int arg0,
    __m128 arg1,
  ) {
    return __mm512_maskz_broadcast_f32x2(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_broadcast_f32x2Ptr =
      _lookup<ffi.NativeFunction<__m512 Function(__mmask16, __m128)>>(
          '_mm512_maskz_broadcast_f32x2');
  late final __mm512_maskz_broadcast_f32x2 = __mm512_maskz_broadcast_f32x2Ptr
      .asFunction<__m512 Function(int, __m128)>();

  __m512 _mm512_broadcast_f32x4(
    __m128 arg0,
  ) {
    return __mm512_broadcast_f32x4(
      arg0,
    );
  }

  late final __mm512_broadcast_f32x4Ptr =
      _lookup<ffi.NativeFunction<__m512 Function(__m128)>>(
          '_mm512_broadcast_f32x4');
  late final __mm512_broadcast_f32x4 =
      __mm512_broadcast_f32x4Ptr.asFunction<__m512 Function(__m128)>();

  __m512 _mm512_mask_broadcast_f32x4(
    __m512 arg0,
    int arg1,
    __m128 arg2,
  ) {
    return __mm512_mask_broadcast_f32x4(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_broadcast_f32x4Ptr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __mmask16, __m128)>>(
          '_mm512_mask_broadcast_f32x4');
  late final __mm512_mask_broadcast_f32x4 = __mm512_mask_broadcast_f32x4Ptr
      .asFunction<__m512 Function(__m512, int, __m128)>();

  __m512 _mm512_maskz_broadcast_f32x4(
    int arg0,
    __m128 arg1,
  ) {
    return __mm512_maskz_broadcast_f32x4(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_broadcast_f32x4Ptr =
      _lookup<ffi.NativeFunction<__m512 Function(__mmask16, __m128)>>(
          '_mm512_maskz_broadcast_f32x4');
  late final __mm512_maskz_broadcast_f32x4 = __mm512_maskz_broadcast_f32x4Ptr
      .asFunction<__m512 Function(int, __m128)>();

  __m512 _mm512_broadcast_f32x8(
    __m256 arg0,
  ) {
    return __mm512_broadcast_f32x8(
      arg0,
    );
  }

  late final __mm512_broadcast_f32x8Ptr =
      _lookup<ffi.NativeFunction<__m512 Function(__m256)>>(
          '_mm512_broadcast_f32x8');
  late final __mm512_broadcast_f32x8 =
      __mm512_broadcast_f32x8Ptr.asFunction<__m512 Function(__m256)>();

  __m512 _mm512_mask_broadcast_f32x8(
    __m512 arg0,
    int arg1,
    __m256 arg2,
  ) {
    return __mm512_mask_broadcast_f32x8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_broadcast_f32x8Ptr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __mmask16, __m256)>>(
          '_mm512_mask_broadcast_f32x8');
  late final __mm512_mask_broadcast_f32x8 = __mm512_mask_broadcast_f32x8Ptr
      .asFunction<__m512 Function(__m512, int, __m256)>();

  __m512 _mm512_maskz_broadcast_f32x8(
    int arg0,
    __m256 arg1,
  ) {
    return __mm512_maskz_broadcast_f32x8(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_broadcast_f32x8Ptr =
      _lookup<ffi.NativeFunction<__m512 Function(__mmask16, __m256)>>(
          '_mm512_maskz_broadcast_f32x8');
  late final __mm512_maskz_broadcast_f32x8 = __mm512_maskz_broadcast_f32x8Ptr
      .asFunction<__m512 Function(int, __m256)>();

  _m512d _mm512_broadcast_f64x2(
    _m128d arg0,
  ) {
    return __mm512_broadcast_f64x2(
      arg0,
    );
  }

  late final __mm512_broadcast_f64x2Ptr =
      _lookup<ffi.NativeFunction<_m512d Function(_m128d)>>(
          '_mm512_broadcast_f64x2');
  late final __mm512_broadcast_f64x2 =
      __mm512_broadcast_f64x2Ptr.asFunction<_m512d Function(_m128d)>();

  _m512d _mm512_mask_broadcast_f64x2(
    _m512d arg0,
    int arg1,
    _m128d arg2,
  ) {
    return __mm512_mask_broadcast_f64x2(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_broadcast_f64x2Ptr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, __mmask8, _m128d)>>(
          '_mm512_mask_broadcast_f64x2');
  late final __mm512_mask_broadcast_f64x2 = __mm512_mask_broadcast_f64x2Ptr
      .asFunction<_m512d Function(_m512d, int, _m128d)>();

  _m512d _mm512_maskz_broadcast_f64x2(
    int arg0,
    _m128d arg1,
  ) {
    return __mm512_maskz_broadcast_f64x2(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_broadcast_f64x2Ptr =
      _lookup<ffi.NativeFunction<_m512d Function(__mmask8, _m128d)>>(
          '_mm512_maskz_broadcast_f64x2');
  late final __mm512_maskz_broadcast_f64x2 = __mm512_maskz_broadcast_f64x2Ptr
      .asFunction<_m512d Function(int, _m128d)>();

  _m512d _mm512_broadcast_f64x4(
    _m256d arg0,
  ) {
    return __mm512_broadcast_f64x4(
      arg0,
    );
  }

  late final __mm512_broadcast_f64x4Ptr =
      _lookup<ffi.NativeFunction<_m512d Function(_m256d)>>(
          '_mm512_broadcast_f64x4');
  late final __mm512_broadcast_f64x4 =
      __mm512_broadcast_f64x4Ptr.asFunction<_m512d Function(_m256d)>();

  _m512d _mm512_mask_broadcast_f64x4(
    _m512d arg0,
    int arg1,
    _m256d arg2,
  ) {
    return __mm512_mask_broadcast_f64x4(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_broadcast_f64x4Ptr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, __mmask8, _m256d)>>(
          '_mm512_mask_broadcast_f64x4');
  late final __mm512_mask_broadcast_f64x4 = __mm512_mask_broadcast_f64x4Ptr
      .asFunction<_m512d Function(_m512d, int, _m256d)>();

  _m512d _mm512_maskz_broadcast_f64x4(
    int arg0,
    _m256d arg1,
  ) {
    return __mm512_maskz_broadcast_f64x4(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_broadcast_f64x4Ptr =
      _lookup<ffi.NativeFunction<_m512d Function(__mmask8, _m256d)>>(
          '_mm512_maskz_broadcast_f64x4');
  late final __mm512_maskz_broadcast_f64x4 = __mm512_maskz_broadcast_f64x4Ptr
      .asFunction<_m512d Function(int, _m256d)>();

  _m512d _mm512_broadcastsd_pd(
    _m128d arg0,
  ) {
    return __mm512_broadcastsd_pd(
      arg0,
    );
  }

  late final __mm512_broadcastsd_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m128d)>>(
          '_mm512_broadcastsd_pd');
  late final __mm512_broadcastsd_pd =
      __mm512_broadcastsd_pdPtr.asFunction<_m512d Function(_m128d)>();

  _m512d _mm512_mask_broadcastsd_pd(
    _m512d arg0,
    int arg1,
    _m128d arg2,
  ) {
    return __mm512_mask_broadcastsd_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_broadcastsd_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, __mmask8, _m128d)>>(
          '_mm512_mask_broadcastsd_pd');
  late final __mm512_mask_broadcastsd_pd = __mm512_mask_broadcastsd_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m128d)>();

  _m512d _mm512_maskz_broadcastsd_pd(
    int arg0,
    _m128d arg1,
  ) {
    return __mm512_maskz_broadcastsd_pd(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_broadcastsd_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(__mmask8, _m128d)>>(
          '_mm512_maskz_broadcastsd_pd');
  late final __mm512_maskz_broadcastsd_pd = __mm512_maskz_broadcastsd_pdPtr
      .asFunction<_m512d Function(int, _m128d)>();

  __m512 _mm512_broadcastss_ps(
    __m128 arg0,
  ) {
    return __mm512_broadcastss_ps(
      arg0,
    );
  }

  late final __mm512_broadcastss_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m128)>>(
          '_mm512_broadcastss_ps');
  late final __mm512_broadcastss_ps =
      __mm512_broadcastss_psPtr.asFunction<__m512 Function(__m128)>();

  __m512 _mm512_mask_broadcastss_ps(
    __m512 arg0,
    int arg1,
    __m128 arg2,
  ) {
    return __mm512_mask_broadcastss_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_broadcastss_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __mmask16, __m128)>>(
          '_mm512_mask_broadcastss_ps');
  late final __mm512_mask_broadcastss_ps = __mm512_mask_broadcastss_psPtr
      .asFunction<__m512 Function(__m512, int, __m128)>();

  __m512 _mm512_maskz_broadcastss_ps(
    int arg0,
    __m128 arg1,
  ) {
    return __mm512_maskz_broadcastss_ps(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_broadcastss_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__mmask16, __m128)>>(
          '_mm512_maskz_broadcastss_ps');
  late final __mm512_maskz_broadcastss_ps = __mm512_maskz_broadcastss_psPtr
      .asFunction<__m512 Function(int, __m128)>();

  __m128 _mm512_extractf32x4_ps(
    __m512 arg0,
    int arg1,
  ) {
    return __mm512_extractf32x4_ps(
      arg0,
      arg1,
    );
  }

  late final __mm512_extractf32x4_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m512, ffi.Int32)>>(
          '_mm512_extractf32x4_ps');
  late final __mm512_extractf32x4_ps =
      __mm512_extractf32x4_psPtr.asFunction<__m128 Function(__m512, int)>();

  __m128 _mm512_mask_extractf32x4_ps(
    __m128 arg0,
    int arg1,
    __m512 arg2,
    int arg3,
  ) {
    return __mm512_mask_extractf32x4_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_extractf32x4_psPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(__m128, __mmask8, __m512,
              ffi.Int32)>>('_mm512_mask_extractf32x4_ps');
  late final __mm512_mask_extractf32x4_ps = __mm512_mask_extractf32x4_psPtr
      .asFunction<__m128 Function(__m128, int, __m512, int)>();

  __m128 _mm512_maskz_extractf32x4_ps(
    int arg0,
    __m512 arg1,
    int arg2,
  ) {
    return __mm512_maskz_extractf32x4_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_extractf32x4_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__mmask8, __m512, ffi.Int32)>>(
          '_mm512_maskz_extractf32x4_ps');
  late final __mm512_maskz_extractf32x4_ps = __mm512_maskz_extractf32x4_psPtr
      .asFunction<__m128 Function(int, __m512, int)>();

  __m256 _mm512_extractf32x8_ps(
    __m512 arg0,
    int arg1,
  ) {
    return __mm512_extractf32x8_ps(
      arg0,
      arg1,
    );
  }

  late final __mm512_extractf32x8_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m512, ffi.Int32)>>(
          '_mm512_extractf32x8_ps');
  late final __mm512_extractf32x8_ps =
      __mm512_extractf32x8_psPtr.asFunction<__m256 Function(__m512, int)>();

  __m256 _mm512_mask_extractf32x8_ps(
    __m256 arg0,
    int arg1,
    __m512 arg2,
    int arg3,
  ) {
    return __mm512_mask_extractf32x8_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_extractf32x8_psPtr = _lookup<
      ffi.NativeFunction<
          __m256 Function(__m256, __mmask8, __m512,
              ffi.Int32)>>('_mm512_mask_extractf32x8_ps');
  late final __mm512_mask_extractf32x8_ps = __mm512_mask_extractf32x8_psPtr
      .asFunction<__m256 Function(__m256, int, __m512, int)>();

  __m256 _mm512_maskz_extractf32x8_ps(
    int arg0,
    __m512 arg1,
    int arg2,
  ) {
    return __mm512_maskz_extractf32x8_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_extractf32x8_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__mmask8, __m512, ffi.Int32)>>(
          '_mm512_maskz_extractf32x8_ps');
  late final __mm512_maskz_extractf32x8_ps = __mm512_maskz_extractf32x8_psPtr
      .asFunction<__m256 Function(int, __m512, int)>();

  _m128d _mm512_extractf64x2_pd(
    _m512d arg0,
    int arg1,
  ) {
    return __mm512_extractf64x2_pd(
      arg0,
      arg1,
    );
  }

  late final __mm512_extractf64x2_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m512d, ffi.Int32)>>(
          '_mm512_extractf64x2_pd');
  late final __mm512_extractf64x2_pd =
      __mm512_extractf64x2_pdPtr.asFunction<_m128d Function(_m512d, int)>();

  _m128d _mm512_mask_extractf64x2_pd(
    _m128d arg0,
    int arg1,
    _m512d arg2,
    int arg3,
  ) {
    return __mm512_mask_extractf64x2_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_extractf64x2_pdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(_m128d, __mmask8, _m512d,
              ffi.Int32)>>('_mm512_mask_extractf64x2_pd');
  late final __mm512_mask_extractf64x2_pd = __mm512_mask_extractf64x2_pdPtr
      .asFunction<_m128d Function(_m128d, int, _m512d, int)>();

  _m128d _mm512_maskz_extractf64x2_pd(
    int arg0,
    _m512d arg1,
    int arg2,
  ) {
    return __mm512_maskz_extractf64x2_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_extractf64x2_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(__mmask8, _m512d, ffi.Int32)>>(
          '_mm512_maskz_extractf64x2_pd');
  late final __mm512_maskz_extractf64x2_pd = __mm512_maskz_extractf64x2_pdPtr
      .asFunction<_m128d Function(int, _m512d, int)>();

  _m256d _mm512_extractf64x4_pd(
    _m512d arg0,
    int arg1,
  ) {
    return __mm512_extractf64x4_pd(
      arg0,
      arg1,
    );
  }

  late final __mm512_extractf64x4_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m512d, ffi.Int32)>>(
          '_mm512_extractf64x4_pd');
  late final __mm512_extractf64x4_pd =
      __mm512_extractf64x4_pdPtr.asFunction<_m256d Function(_m512d, int)>();

  _m256d _mm512_mask_extractf64x4_pd(
    _m256d arg0,
    int arg1,
    _m512d arg2,
    int arg3,
  ) {
    return __mm512_mask_extractf64x4_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_extractf64x4_pdPtr = _lookup<
      ffi.NativeFunction<
          _m256d Function(_m256d, __mmask8, _m512d,
              ffi.Int32)>>('_mm512_mask_extractf64x4_pd');
  late final __mm512_mask_extractf64x4_pd = __mm512_mask_extractf64x4_pdPtr
      .asFunction<_m256d Function(_m256d, int, _m512d, int)>();

  _m256d _mm512_maskz_extractf64x4_pd(
    int arg0,
    _m512d arg1,
    int arg2,
  ) {
    return __mm512_maskz_extractf64x4_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_extractf64x4_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(__mmask8, _m512d, ffi.Int32)>>(
          '_mm512_maskz_extractf64x4_pd');
  late final __mm512_maskz_extractf64x4_pd = __mm512_maskz_extractf64x4_pdPtr
      .asFunction<_m256d Function(int, _m512d, int)>();

  __m512 _mm512_insertf32x4(
    __m512 arg0,
    __m128 arg1,
    int arg2,
  ) {
    return __mm512_insertf32x4(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_insertf32x4Ptr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __m128, ffi.Int32)>>(
          '_mm512_insertf32x4');
  late final __mm512_insertf32x4 =
      __mm512_insertf32x4Ptr.asFunction<__m512 Function(__m512, __m128, int)>();

  __m512 _mm512_mask_insertf32x4(
    __m512 arg0,
    int arg1,
    __m512 arg2,
    __m128 arg3,
    int arg4,
  ) {
    return __mm512_mask_insertf32x4(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_insertf32x4Ptr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__m512, __mmask16, __m512, __m128,
              ffi.Int32)>>('_mm512_mask_insertf32x4');
  late final __mm512_mask_insertf32x4 = __mm512_mask_insertf32x4Ptr
      .asFunction<__m512 Function(__m512, int, __m512, __m128, int)>();

  __m512 _mm512_maskz_insertf32x4(
    int arg0,
    __m512 arg1,
    __m128 arg2,
    int arg3,
  ) {
    return __mm512_maskz_insertf32x4(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_insertf32x4Ptr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__mmask16, __m512, __m128,
              ffi.Int32)>>('_mm512_maskz_insertf32x4');
  late final __mm512_maskz_insertf32x4 = __mm512_maskz_insertf32x4Ptr
      .asFunction<__m512 Function(int, __m512, __m128, int)>();

  __m512 _mm512_insertf32x8(
    __m512 arg0,
    __m256 arg1,
    int arg2,
  ) {
    return __mm512_insertf32x8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_insertf32x8Ptr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __m256, ffi.Int32)>>(
          '_mm512_insertf32x8');
  late final __mm512_insertf32x8 =
      __mm512_insertf32x8Ptr.asFunction<__m512 Function(__m512, __m256, int)>();

  __m512 _mm512_mask_insertf32x8(
    __m512 arg0,
    int arg1,
    __m512 arg2,
    __m256 arg3,
    int arg4,
  ) {
    return __mm512_mask_insertf32x8(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_insertf32x8Ptr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__m512, __mmask16, __m512, __m256,
              ffi.Int32)>>('_mm512_mask_insertf32x8');
  late final __mm512_mask_insertf32x8 = __mm512_mask_insertf32x8Ptr
      .asFunction<__m512 Function(__m512, int, __m512, __m256, int)>();

  __m512 _mm512_maskz_insertf32x8(
    int arg0,
    __m512 arg1,
    __m256 arg2,
    int arg3,
  ) {
    return __mm512_maskz_insertf32x8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_insertf32x8Ptr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__mmask16, __m512, __m256,
              ffi.Int32)>>('_mm512_maskz_insertf32x8');
  late final __mm512_maskz_insertf32x8 = __mm512_maskz_insertf32x8Ptr
      .asFunction<__m512 Function(int, __m512, __m256, int)>();

  _m512d _mm512_insertf64x2(
    _m512d arg0,
    _m128d arg1,
    int arg2,
  ) {
    return __mm512_insertf64x2(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_insertf64x2Ptr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, _m128d, ffi.Int32)>>(
          '_mm512_insertf64x2');
  late final __mm512_insertf64x2 =
      __mm512_insertf64x2Ptr.asFunction<_m512d Function(_m512d, _m128d, int)>();

  _m512d _mm512_mask_insertf64x2(
    _m512d arg0,
    int arg1,
    _m512d arg2,
    _m128d arg3,
    int arg4,
  ) {
    return __mm512_mask_insertf64x2(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_insertf64x2Ptr = _lookup<
      ffi.NativeFunction<
          _m512d Function(_m512d, __mmask8, _m512d, _m128d,
              ffi.Int32)>>('_mm512_mask_insertf64x2');
  late final __mm512_mask_insertf64x2 = __mm512_mask_insertf64x2Ptr
      .asFunction<_m512d Function(_m512d, int, _m512d, _m128d, int)>();

  _m512d _mm512_maskz_insertf64x2(
    int arg0,
    _m512d arg1,
    _m128d arg2,
    int arg3,
  ) {
    return __mm512_maskz_insertf64x2(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_insertf64x2Ptr = _lookup<
      ffi.NativeFunction<
          _m512d Function(__mmask8, _m512d, _m128d,
              ffi.Int32)>>('_mm512_maskz_insertf64x2');
  late final __mm512_maskz_insertf64x2 = __mm512_maskz_insertf64x2Ptr
      .asFunction<_m512d Function(int, _m512d, _m128d, int)>();

  _m512d _mm512_insertf64x4(
    _m512d arg0,
    _m256d arg1,
    int arg2,
  ) {
    return __mm512_insertf64x4(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_insertf64x4Ptr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, _m256d, ffi.Int32)>>(
          '_mm512_insertf64x4');
  late final __mm512_insertf64x4 =
      __mm512_insertf64x4Ptr.asFunction<_m512d Function(_m512d, _m256d, int)>();

  _m512d _mm512_mask_insertf64x4(
    _m512d arg0,
    int arg1,
    _m512d arg2,
    _m256d arg3,
    int arg4,
  ) {
    return __mm512_mask_insertf64x4(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_insertf64x4Ptr = _lookup<
      ffi.NativeFunction<
          _m512d Function(_m512d, __mmask8, _m512d, _m256d,
              ffi.Int32)>>('_mm512_mask_insertf64x4');
  late final __mm512_mask_insertf64x4 = __mm512_mask_insertf64x4Ptr
      .asFunction<_m512d Function(_m512d, int, _m512d, _m256d, int)>();

  _m512d _mm512_maskz_insertf64x4(
    int arg0,
    _m512d arg1,
    _m256d arg2,
    int arg3,
  ) {
    return __mm512_maskz_insertf64x4(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_insertf64x4Ptr = _lookup<
      ffi.NativeFunction<
          _m512d Function(__mmask8, _m512d, _m256d,
              ffi.Int32)>>('_mm512_maskz_insertf64x4');
  late final __mm512_maskz_insertf64x4 = __mm512_maskz_insertf64x4Ptr
      .asFunction<_m512d Function(int, _m512d, _m256d, int)>();

  __m512 _mm512_shuffle_f32x4(
    __m512 arg0,
    __m512 arg1,
    int arg2,
  ) {
    return __mm512_shuffle_f32x4(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_shuffle_f32x4Ptr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __m512, ffi.Int32)>>(
          '_mm512_shuffle_f32x4');
  late final __mm512_shuffle_f32x4 = __mm512_shuffle_f32x4Ptr
      .asFunction<__m512 Function(__m512, __m512, int)>();

  __m512 _mm512_mask_shuffle_f32x4(
    __m512 arg0,
    int arg1,
    __m512 arg2,
    __m512 arg3,
    int arg4,
  ) {
    return __mm512_mask_shuffle_f32x4(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_shuffle_f32x4Ptr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__m512, __mmask16, __m512, __m512,
              ffi.Int32)>>('_mm512_mask_shuffle_f32x4');
  late final __mm512_mask_shuffle_f32x4 = __mm512_mask_shuffle_f32x4Ptr
      .asFunction<__m512 Function(__m512, int, __m512, __m512, int)>();

  __m512 _mm512_maskz_shuffle_f32x4(
    int arg0,
    __m512 arg1,
    __m512 arg2,
    int arg3,
  ) {
    return __mm512_maskz_shuffle_f32x4(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_shuffle_f32x4Ptr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__mmask16, __m512, __m512,
              ffi.Int32)>>('_mm512_maskz_shuffle_f32x4');
  late final __mm512_maskz_shuffle_f32x4 = __mm512_maskz_shuffle_f32x4Ptr
      .asFunction<__m512 Function(int, __m512, __m512, int)>();

  _m512d _mm512_shuffle_f64x2(
    _m512d arg0,
    _m512d arg1,
    int arg2,
  ) {
    return __mm512_shuffle_f64x2(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_shuffle_f64x2Ptr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, _m512d, ffi.Int32)>>(
          '_mm512_shuffle_f64x2');
  late final __mm512_shuffle_f64x2 = __mm512_shuffle_f64x2Ptr
      .asFunction<_m512d Function(_m512d, _m512d, int)>();

  _m512d _mm512_mask_shuffle_f64x2(
    _m512d arg0,
    int arg1,
    _m512d arg2,
    _m512d arg3,
    int arg4,
  ) {
    return __mm512_mask_shuffle_f64x2(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_shuffle_f64x2Ptr = _lookup<
      ffi.NativeFunction<
          _m512d Function(_m512d, __mmask8, _m512d, _m512d,
              ffi.Int32)>>('_mm512_mask_shuffle_f64x2');
  late final __mm512_mask_shuffle_f64x2 = __mm512_mask_shuffle_f64x2Ptr
      .asFunction<_m512d Function(_m512d, int, _m512d, _m512d, int)>();

  _m512d _mm512_maskz_shuffle_f64x2(
    int arg0,
    _m512d arg1,
    _m512d arg2,
    int arg3,
  ) {
    return __mm512_maskz_shuffle_f64x2(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_shuffle_f64x2Ptr = _lookup<
      ffi.NativeFunction<
          _m512d Function(__mmask8, _m512d, _m512d,
              ffi.Int32)>>('_mm512_maskz_shuffle_f64x2');
  late final __mm512_maskz_shuffle_f64x2 = __mm512_maskz_shuffle_f64x2Ptr
      .asFunction<_m512d Function(int, _m512d, _m512d, int)>();

  _m512d _mm512_shuffle_pd(
    _m512d arg0,
    _m512d arg1,
    int arg2,
  ) {
    return __mm512_shuffle_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_shuffle_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, _m512d, ffi.Int32)>>(
          '_mm512_shuffle_pd');
  late final __mm512_shuffle_pd =
      __mm512_shuffle_pdPtr.asFunction<_m512d Function(_m512d, _m512d, int)>();

  _m512d _mm512_mask_shuffle_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
    _m512d arg3,
    int arg4,
  ) {
    return __mm512_mask_shuffle_pd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_shuffle_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(_m512d, __mmask8, _m512d, _m512d,
              ffi.Int32)>>('_mm512_mask_shuffle_pd');
  late final __mm512_mask_shuffle_pd = __mm512_mask_shuffle_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d, _m512d, int)>();

  _m512d _mm512_maskz_shuffle_pd(
    int arg0,
    _m512d arg1,
    _m512d arg2,
    int arg3,
  ) {
    return __mm512_maskz_shuffle_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_shuffle_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(
              __mmask8, _m512d, _m512d, ffi.Int32)>>('_mm512_maskz_shuffle_pd');
  late final __mm512_maskz_shuffle_pd = __mm512_maskz_shuffle_pdPtr
      .asFunction<_m512d Function(int, _m512d, _m512d, int)>();

  __m512 _mm512_shuffle_ps(
    __m512 arg0,
    __m512 arg1,
    int arg2,
  ) {
    return __mm512_shuffle_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_shuffle_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __m512, ffi.Int32)>>(
          '_mm512_shuffle_ps');
  late final __mm512_shuffle_ps =
      __mm512_shuffle_psPtr.asFunction<__m512 Function(__m512, __m512, int)>();

  __m512 _mm512_mask_shuffle_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
    __m512 arg3,
    int arg4,
  ) {
    return __mm512_mask_shuffle_ps(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_shuffle_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__m512, __mmask16, __m512, __m512,
              ffi.Int32)>>('_mm512_mask_shuffle_ps');
  late final __mm512_mask_shuffle_ps = __mm512_mask_shuffle_psPtr
      .asFunction<__m512 Function(__m512, int, __m512, __m512, int)>();

  __m512 _mm512_maskz_shuffle_ps(
    int arg0,
    __m512 arg1,
    __m512 arg2,
    int arg3,
  ) {
    return __mm512_maskz_shuffle_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_shuffle_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__mmask16, __m512, __m512,
              ffi.Int32)>>('_mm512_maskz_shuffle_ps');
  late final __mm512_maskz_shuffle_ps = __mm512_maskz_shuffle_psPtr
      .asFunction<__m512 Function(int, __m512, __m512, int)>();

  int _mm512_cmpeq_ps_mask(
    __m512 arg0,
    __m512 arg1,
  ) {
    return __mm512_cmpeq_ps_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_cmpeq_ps_maskPtr =
      _lookup<ffi.NativeFunction<__mmask16 Function(__m512, __m512)>>(
          '_mm512_cmpeq_ps_mask');
  late final __mm512_cmpeq_ps_mask =
      __mm512_cmpeq_ps_maskPtr.asFunction<int Function(__m512, __m512)>();

  int _mm512_cmple_ps_mask(
    __m512 arg0,
    __m512 arg1,
  ) {
    return __mm512_cmple_ps_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_cmple_ps_maskPtr =
      _lookup<ffi.NativeFunction<__mmask16 Function(__m512, __m512)>>(
          '_mm512_cmple_ps_mask');
  late final __mm512_cmple_ps_mask =
      __mm512_cmple_ps_maskPtr.asFunction<int Function(__m512, __m512)>();

  int _mm512_cmplt_ps_mask(
    __m512 arg0,
    __m512 arg1,
  ) {
    return __mm512_cmplt_ps_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_cmplt_ps_maskPtr =
      _lookup<ffi.NativeFunction<__mmask16 Function(__m512, __m512)>>(
          '_mm512_cmplt_ps_mask');
  late final __mm512_cmplt_ps_mask =
      __mm512_cmplt_ps_maskPtr.asFunction<int Function(__m512, __m512)>();

  int _mm512_cmpneq_ps_mask(
    __m512 arg0,
    __m512 arg1,
  ) {
    return __mm512_cmpneq_ps_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_cmpneq_ps_maskPtr =
      _lookup<ffi.NativeFunction<__mmask16 Function(__m512, __m512)>>(
          '_mm512_cmpneq_ps_mask');
  late final __mm512_cmpneq_ps_mask =
      __mm512_cmpneq_ps_maskPtr.asFunction<int Function(__m512, __m512)>();

  int _mm512_cmpnle_ps_mask(
    __m512 arg0,
    __m512 arg1,
  ) {
    return __mm512_cmpnle_ps_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_cmpnle_ps_maskPtr =
      _lookup<ffi.NativeFunction<__mmask16 Function(__m512, __m512)>>(
          '_mm512_cmpnle_ps_mask');
  late final __mm512_cmpnle_ps_mask =
      __mm512_cmpnle_ps_maskPtr.asFunction<int Function(__m512, __m512)>();

  int _mm512_cmpnlt_ps_mask(
    __m512 arg0,
    __m512 arg1,
  ) {
    return __mm512_cmpnlt_ps_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_cmpnlt_ps_maskPtr =
      _lookup<ffi.NativeFunction<__mmask16 Function(__m512, __m512)>>(
          '_mm512_cmpnlt_ps_mask');
  late final __mm512_cmpnlt_ps_mask =
      __mm512_cmpnlt_ps_maskPtr.asFunction<int Function(__m512, __m512)>();

  int _mm512_cmpord_ps_mask(
    __m512 arg0,
    __m512 arg1,
  ) {
    return __mm512_cmpord_ps_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_cmpord_ps_maskPtr =
      _lookup<ffi.NativeFunction<__mmask16 Function(__m512, __m512)>>(
          '_mm512_cmpord_ps_mask');
  late final __mm512_cmpord_ps_mask =
      __mm512_cmpord_ps_maskPtr.asFunction<int Function(__m512, __m512)>();

  int _mm512_cmpunord_ps_mask(
    __m512 arg0,
    __m512 arg1,
  ) {
    return __mm512_cmpunord_ps_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_cmpunord_ps_maskPtr =
      _lookup<ffi.NativeFunction<__mmask16 Function(__m512, __m512)>>(
          '_mm512_cmpunord_ps_mask');
  late final __mm512_cmpunord_ps_mask =
      __mm512_cmpunord_ps_maskPtr.asFunction<int Function(__m512, __m512)>();

  int _mm512_mask_cmpeq_ps_mask(
    int arg0,
    __m512 arg1,
    __m512 arg2,
  ) {
    return __mm512_mask_cmpeq_ps_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cmpeq_ps_maskPtr = _lookup<
          ffi.NativeFunction<__mmask16 Function(__mmask16, __m512, __m512)>>(
      '_mm512_mask_cmpeq_ps_mask');
  late final __mm512_mask_cmpeq_ps_mask = __mm512_mask_cmpeq_ps_maskPtr
      .asFunction<int Function(int, __m512, __m512)>();

  int _mm512_mask_cmple_ps_mask(
    int arg0,
    __m512 arg1,
    __m512 arg2,
  ) {
    return __mm512_mask_cmple_ps_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cmple_ps_maskPtr = _lookup<
          ffi.NativeFunction<__mmask16 Function(__mmask16, __m512, __m512)>>(
      '_mm512_mask_cmple_ps_mask');
  late final __mm512_mask_cmple_ps_mask = __mm512_mask_cmple_ps_maskPtr
      .asFunction<int Function(int, __m512, __m512)>();

  int _mm512_mask_cmplt_ps_mask(
    int arg0,
    __m512 arg1,
    __m512 arg2,
  ) {
    return __mm512_mask_cmplt_ps_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cmplt_ps_maskPtr = _lookup<
          ffi.NativeFunction<__mmask16 Function(__mmask16, __m512, __m512)>>(
      '_mm512_mask_cmplt_ps_mask');
  late final __mm512_mask_cmplt_ps_mask = __mm512_mask_cmplt_ps_maskPtr
      .asFunction<int Function(int, __m512, __m512)>();

  int _mm512_mask_cmpneq_ps_mask(
    int arg0,
    __m512 arg1,
    __m512 arg2,
  ) {
    return __mm512_mask_cmpneq_ps_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cmpneq_ps_maskPtr = _lookup<
          ffi.NativeFunction<__mmask16 Function(__mmask16, __m512, __m512)>>(
      '_mm512_mask_cmpneq_ps_mask');
  late final __mm512_mask_cmpneq_ps_mask = __mm512_mask_cmpneq_ps_maskPtr
      .asFunction<int Function(int, __m512, __m512)>();

  int _mm512_mask_cmpnle_ps_mask(
    int arg0,
    __m512 arg1,
    __m512 arg2,
  ) {
    return __mm512_mask_cmpnle_ps_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cmpnle_ps_maskPtr = _lookup<
          ffi.NativeFunction<__mmask16 Function(__mmask16, __m512, __m512)>>(
      '_mm512_mask_cmpnle_ps_mask');
  late final __mm512_mask_cmpnle_ps_mask = __mm512_mask_cmpnle_ps_maskPtr
      .asFunction<int Function(int, __m512, __m512)>();

  int _mm512_mask_cmpnlt_ps_mask(
    int arg0,
    __m512 arg1,
    __m512 arg2,
  ) {
    return __mm512_mask_cmpnlt_ps_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cmpnlt_ps_maskPtr = _lookup<
          ffi.NativeFunction<__mmask16 Function(__mmask16, __m512, __m512)>>(
      '_mm512_mask_cmpnlt_ps_mask');
  late final __mm512_mask_cmpnlt_ps_mask = __mm512_mask_cmpnlt_ps_maskPtr
      .asFunction<int Function(int, __m512, __m512)>();

  int _mm512_mask_cmpord_ps_mask(
    int arg0,
    __m512 arg1,
    __m512 arg2,
  ) {
    return __mm512_mask_cmpord_ps_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cmpord_ps_maskPtr = _lookup<
          ffi.NativeFunction<__mmask16 Function(__mmask16, __m512, __m512)>>(
      '_mm512_mask_cmpord_ps_mask');
  late final __mm512_mask_cmpord_ps_mask = __mm512_mask_cmpord_ps_maskPtr
      .asFunction<int Function(int, __m512, __m512)>();

  int _mm512_mask_cmpunord_ps_mask(
    int arg0,
    __m512 arg1,
    __m512 arg2,
  ) {
    return __mm512_mask_cmpunord_ps_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cmpunord_ps_maskPtr = _lookup<
          ffi.NativeFunction<__mmask16 Function(__mmask16, __m512, __m512)>>(
      '_mm512_mask_cmpunord_ps_mask');
  late final __mm512_mask_cmpunord_ps_mask = __mm512_mask_cmpunord_ps_maskPtr
      .asFunction<int Function(int, __m512, __m512)>();

  int _mm512_cmpeq_pd_mask(
    _m512d arg0,
    _m512d arg1,
  ) {
    return __mm512_cmpeq_pd_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_cmpeq_pd_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(_m512d, _m512d)>>(
          '_mm512_cmpeq_pd_mask');
  late final __mm512_cmpeq_pd_mask =
      __mm512_cmpeq_pd_maskPtr.asFunction<int Function(_m512d, _m512d)>();

  int _mm512_cmple_pd_mask(
    _m512d arg0,
    _m512d arg1,
  ) {
    return __mm512_cmple_pd_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_cmple_pd_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(_m512d, _m512d)>>(
          '_mm512_cmple_pd_mask');
  late final __mm512_cmple_pd_mask =
      __mm512_cmple_pd_maskPtr.asFunction<int Function(_m512d, _m512d)>();

  int _mm512_cmplt_pd_mask(
    _m512d arg0,
    _m512d arg1,
  ) {
    return __mm512_cmplt_pd_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_cmplt_pd_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(_m512d, _m512d)>>(
          '_mm512_cmplt_pd_mask');
  late final __mm512_cmplt_pd_mask =
      __mm512_cmplt_pd_maskPtr.asFunction<int Function(_m512d, _m512d)>();

  int _mm512_cmpneq_pd_mask(
    _m512d arg0,
    _m512d arg1,
  ) {
    return __mm512_cmpneq_pd_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_cmpneq_pd_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(_m512d, _m512d)>>(
          '_mm512_cmpneq_pd_mask');
  late final __mm512_cmpneq_pd_mask =
      __mm512_cmpneq_pd_maskPtr.asFunction<int Function(_m512d, _m512d)>();

  int _mm512_cmpnle_pd_mask(
    _m512d arg0,
    _m512d arg1,
  ) {
    return __mm512_cmpnle_pd_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_cmpnle_pd_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(_m512d, _m512d)>>(
          '_mm512_cmpnle_pd_mask');
  late final __mm512_cmpnle_pd_mask =
      __mm512_cmpnle_pd_maskPtr.asFunction<int Function(_m512d, _m512d)>();

  int _mm512_cmpnlt_pd_mask(
    _m512d arg0,
    _m512d arg1,
  ) {
    return __mm512_cmpnlt_pd_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_cmpnlt_pd_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(_m512d, _m512d)>>(
          '_mm512_cmpnlt_pd_mask');
  late final __mm512_cmpnlt_pd_mask =
      __mm512_cmpnlt_pd_maskPtr.asFunction<int Function(_m512d, _m512d)>();

  int _mm512_cmpord_pd_mask(
    _m512d arg0,
    _m512d arg1,
  ) {
    return __mm512_cmpord_pd_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_cmpord_pd_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(_m512d, _m512d)>>(
          '_mm512_cmpord_pd_mask');
  late final __mm512_cmpord_pd_mask =
      __mm512_cmpord_pd_maskPtr.asFunction<int Function(_m512d, _m512d)>();

  int _mm512_cmpunord_pd_mask(
    _m512d arg0,
    _m512d arg1,
  ) {
    return __mm512_cmpunord_pd_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_cmpunord_pd_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(_m512d, _m512d)>>(
          '_mm512_cmpunord_pd_mask');
  late final __mm512_cmpunord_pd_mask =
      __mm512_cmpunord_pd_maskPtr.asFunction<int Function(_m512d, _m512d)>();

  int _mm512_mask_cmpeq_pd_mask(
    int arg0,
    _m512d arg1,
    _m512d arg2,
  ) {
    return __mm512_mask_cmpeq_pd_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cmpeq_pd_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__mmask8, _m512d, _m512d)>>(
          '_mm512_mask_cmpeq_pd_mask');
  late final __mm512_mask_cmpeq_pd_mask = __mm512_mask_cmpeq_pd_maskPtr
      .asFunction<int Function(int, _m512d, _m512d)>();

  int _mm512_mask_cmple_pd_mask(
    int arg0,
    _m512d arg1,
    _m512d arg2,
  ) {
    return __mm512_mask_cmple_pd_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cmple_pd_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__mmask8, _m512d, _m512d)>>(
          '_mm512_mask_cmple_pd_mask');
  late final __mm512_mask_cmple_pd_mask = __mm512_mask_cmple_pd_maskPtr
      .asFunction<int Function(int, _m512d, _m512d)>();

  int _mm512_mask_cmplt_pd_mask(
    int arg0,
    _m512d arg1,
    _m512d arg2,
  ) {
    return __mm512_mask_cmplt_pd_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cmplt_pd_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__mmask8, _m512d, _m512d)>>(
          '_mm512_mask_cmplt_pd_mask');
  late final __mm512_mask_cmplt_pd_mask = __mm512_mask_cmplt_pd_maskPtr
      .asFunction<int Function(int, _m512d, _m512d)>();

  int _mm512_mask_cmpneq_pd_mask(
    int arg0,
    _m512d arg1,
    _m512d arg2,
  ) {
    return __mm512_mask_cmpneq_pd_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cmpneq_pd_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__mmask8, _m512d, _m512d)>>(
          '_mm512_mask_cmpneq_pd_mask');
  late final __mm512_mask_cmpneq_pd_mask = __mm512_mask_cmpneq_pd_maskPtr
      .asFunction<int Function(int, _m512d, _m512d)>();

  int _mm512_mask_cmpnle_pd_mask(
    int arg0,
    _m512d arg1,
    _m512d arg2,
  ) {
    return __mm512_mask_cmpnle_pd_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cmpnle_pd_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__mmask8, _m512d, _m512d)>>(
          '_mm512_mask_cmpnle_pd_mask');
  late final __mm512_mask_cmpnle_pd_mask = __mm512_mask_cmpnle_pd_maskPtr
      .asFunction<int Function(int, _m512d, _m512d)>();

  int _mm512_mask_cmpnlt_pd_mask(
    int arg0,
    _m512d arg1,
    _m512d arg2,
  ) {
    return __mm512_mask_cmpnlt_pd_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cmpnlt_pd_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__mmask8, _m512d, _m512d)>>(
          '_mm512_mask_cmpnlt_pd_mask');
  late final __mm512_mask_cmpnlt_pd_mask = __mm512_mask_cmpnlt_pd_maskPtr
      .asFunction<int Function(int, _m512d, _m512d)>();

  int _mm512_mask_cmpord_pd_mask(
    int arg0,
    _m512d arg1,
    _m512d arg2,
  ) {
    return __mm512_mask_cmpord_pd_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cmpord_pd_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__mmask8, _m512d, _m512d)>>(
          '_mm512_mask_cmpord_pd_mask');
  late final __mm512_mask_cmpord_pd_mask = __mm512_mask_cmpord_pd_maskPtr
      .asFunction<int Function(int, _m512d, _m512d)>();

  int _mm512_mask_cmpunord_pd_mask(
    int arg0,
    _m512d arg1,
    _m512d arg2,
  ) {
    return __mm512_mask_cmpunord_pd_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cmpunord_pd_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__mmask8, _m512d, _m512d)>>(
          '_mm512_mask_cmpunord_pd_mask');
  late final __mm512_mask_cmpunord_pd_mask = __mm512_mask_cmpunord_pd_maskPtr
      .asFunction<int Function(int, _m512d, _m512d)>();

  __m512i _mm512_setzero_si512() {
    return __mm512_setzero_si512();
  }

  late final __mm512_setzero_si512Ptr =
      _lookup<ffi.NativeFunction<__m512i Function()>>('_mm512_setzero_si512');
  late final __mm512_setzero_si512 =
      __mm512_setzero_si512Ptr.asFunction<__m512i Function()>();

  __m512i _mm512_set_epi8(
    int arg0,
    int arg1,
    int arg2,
    int arg3,
    int arg4,
    int arg5,
    int arg6,
    int arg7,
    int arg8,
    int arg9,
    int arg10,
    int arg11,
    int arg12,
    int arg13,
    int arg14,
    int arg15,
    int arg16,
    int arg17,
    int arg18,
    int arg19,
    int arg20,
    int arg21,
    int arg22,
    int arg23,
    int arg24,
    int arg25,
    int arg26,
    int arg27,
    int arg28,
    int arg29,
    int arg30,
    int arg31,
    int arg32,
    int arg33,
    int arg34,
    int arg35,
    int arg36,
    int arg37,
    int arg38,
    int arg39,
    int arg40,
    int arg41,
    int arg42,
    int arg43,
    int arg44,
    int arg45,
    int arg46,
    int arg47,
    int arg48,
    int arg49,
    int arg50,
    int arg51,
    int arg52,
    int arg53,
    int arg54,
    int arg55,
    int arg56,
    int arg57,
    int arg58,
    int arg59,
    int arg60,
    int arg61,
    int arg62,
    int arg63,
  ) {
    return __mm512_set_epi8(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
      arg5,
      arg6,
      arg7,
      arg8,
      arg9,
      arg10,
      arg11,
      arg12,
      arg13,
      arg14,
      arg15,
      arg16,
      arg17,
      arg18,
      arg19,
      arg20,
      arg21,
      arg22,
      arg23,
      arg24,
      arg25,
      arg26,
      arg27,
      arg28,
      arg29,
      arg30,
      arg31,
      arg32,
      arg33,
      arg34,
      arg35,
      arg36,
      arg37,
      arg38,
      arg39,
      arg40,
      arg41,
      arg42,
      arg43,
      arg44,
      arg45,
      arg46,
      arg47,
      arg48,
      arg49,
      arg50,
      arg51,
      arg52,
      arg53,
      arg54,
      arg55,
      arg56,
      arg57,
      arg58,
      arg59,
      arg60,
      arg61,
      arg62,
      arg63,
    );
  }

  late final __mm512_set_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8)>>('_mm512_set_epi8');
  late final __mm512_set_epi8 = __mm512_set_epi8Ptr.asFunction<
      __m512i Function(
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int)>();

  __m512i _mm512_set_epi16(
    int arg0,
    int arg1,
    int arg2,
    int arg3,
    int arg4,
    int arg5,
    int arg6,
    int arg7,
    int arg8,
    int arg9,
    int arg10,
    int arg11,
    int arg12,
    int arg13,
    int arg14,
    int arg15,
    int arg16,
    int arg17,
    int arg18,
    int arg19,
    int arg20,
    int arg21,
    int arg22,
    int arg23,
    int arg24,
    int arg25,
    int arg26,
    int arg27,
    int arg28,
    int arg29,
    int arg30,
    int arg31,
  ) {
    return __mm512_set_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
      arg5,
      arg6,
      arg7,
      arg8,
      arg9,
      arg10,
      arg11,
      arg12,
      arg13,
      arg14,
      arg15,
      arg16,
      arg17,
      arg18,
      arg19,
      arg20,
      arg21,
      arg22,
      arg23,
      arg24,
      arg25,
      arg26,
      arg27,
      arg28,
      arg29,
      arg30,
      arg31,
    );
  }

  late final __mm512_set_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16)>>('_mm512_set_epi16');
  late final __mm512_set_epi16 = __mm512_set_epi16Ptr.asFunction<
      __m512i Function(
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int)>();

  __m512i _mm512_set_epi32(
    int arg0,
    int arg1,
    int arg2,
    int arg3,
    int arg4,
    int arg5,
    int arg6,
    int arg7,
    int arg8,
    int arg9,
    int arg10,
    int arg11,
    int arg12,
    int arg13,
    int arg14,
    int arg15,
  ) {
    return __mm512_set_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
      arg5,
      arg6,
      arg7,
      arg8,
      arg9,
      arg10,
      arg11,
      arg12,
      arg13,
      arg14,
      arg15,
    );
  }

  late final __mm512_set_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              ffi.Int32,
              ffi.Int32,
              ffi.Int32,
              ffi.Int32,
              ffi.Int32,
              ffi.Int32,
              ffi.Int32,
              ffi.Int32,
              ffi.Int32,
              ffi.Int32,
              ffi.Int32,
              ffi.Int32,
              ffi.Int32,
              ffi.Int32,
              ffi.Int32,
              ffi.Int32)>>('_mm512_set_epi32');
  late final __mm512_set_epi32 = __mm512_set_epi32Ptr.asFunction<
      __m512i Function(int, int, int, int, int, int, int, int, int, int, int,
          int, int, int, int, int)>();

  __m512i _mm512_set_epi64(
    int arg0,
    int arg1,
    int arg2,
    int arg3,
    int arg4,
    int arg5,
    int arg6,
    int arg7,
  ) {
    return __mm512_set_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
      arg5,
      arg6,
      arg7,
    );
  }

  late final __mm512_set_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(ffi.Int64, ffi.Int64, ffi.Int64, ffi.Int64,
              ffi.Int64, ffi.Int64, ffi.Int64, ffi.Int64)>>('_mm512_set_epi64');
  late final __mm512_set_epi64 = __mm512_set_epi64Ptr
      .asFunction<__m512i Function(int, int, int, int, int, int, int, int)>();

  __m512i _mm512_setr_epi8(
    int arg0,
    int arg1,
    int arg2,
    int arg3,
    int arg4,
    int arg5,
    int arg6,
    int arg7,
    int arg8,
    int arg9,
    int arg10,
    int arg11,
    int arg12,
    int arg13,
    int arg14,
    int arg15,
    int arg16,
    int arg17,
    int arg18,
    int arg19,
    int arg20,
    int arg21,
    int arg22,
    int arg23,
    int arg24,
    int arg25,
    int arg26,
    int arg27,
    int arg28,
    int arg29,
    int arg30,
    int arg31,
    int arg32,
    int arg33,
    int arg34,
    int arg35,
    int arg36,
    int arg37,
    int arg38,
    int arg39,
    int arg40,
    int arg41,
    int arg42,
    int arg43,
    int arg44,
    int arg45,
    int arg46,
    int arg47,
    int arg48,
    int arg49,
    int arg50,
    int arg51,
    int arg52,
    int arg53,
    int arg54,
    int arg55,
    int arg56,
    int arg57,
    int arg58,
    int arg59,
    int arg60,
    int arg61,
    int arg62,
    int arg63,
  ) {
    return __mm512_setr_epi8(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
      arg5,
      arg6,
      arg7,
      arg8,
      arg9,
      arg10,
      arg11,
      arg12,
      arg13,
      arg14,
      arg15,
      arg16,
      arg17,
      arg18,
      arg19,
      arg20,
      arg21,
      arg22,
      arg23,
      arg24,
      arg25,
      arg26,
      arg27,
      arg28,
      arg29,
      arg30,
      arg31,
      arg32,
      arg33,
      arg34,
      arg35,
      arg36,
      arg37,
      arg38,
      arg39,
      arg40,
      arg41,
      arg42,
      arg43,
      arg44,
      arg45,
      arg46,
      arg47,
      arg48,
      arg49,
      arg50,
      arg51,
      arg52,
      arg53,
      arg54,
      arg55,
      arg56,
      arg57,
      arg58,
      arg59,
      arg60,
      arg61,
      arg62,
      arg63,
    );
  }

  late final __mm512_setr_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8,
              ffi.Int8)>>('_mm512_setr_epi8');
  late final __mm512_setr_epi8 = __mm512_setr_epi8Ptr.asFunction<
      __m512i Function(
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int)>();

  __m512i _mm512_setr_epi16(
    int arg0,
    int arg1,
    int arg2,
    int arg3,
    int arg4,
    int arg5,
    int arg6,
    int arg7,
    int arg8,
    int arg9,
    int arg10,
    int arg11,
    int arg12,
    int arg13,
    int arg14,
    int arg15,
    int arg16,
    int arg17,
    int arg18,
    int arg19,
    int arg20,
    int arg21,
    int arg22,
    int arg23,
    int arg24,
    int arg25,
    int arg26,
    int arg27,
    int arg28,
    int arg29,
    int arg30,
    int arg31,
  ) {
    return __mm512_setr_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
      arg5,
      arg6,
      arg7,
      arg8,
      arg9,
      arg10,
      arg11,
      arg12,
      arg13,
      arg14,
      arg15,
      arg16,
      arg17,
      arg18,
      arg19,
      arg20,
      arg21,
      arg22,
      arg23,
      arg24,
      arg25,
      arg26,
      arg27,
      arg28,
      arg29,
      arg30,
      arg31,
    );
  }

  late final __mm512_setr_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16,
              ffi.Int16)>>('_mm512_setr_epi16');
  late final __mm512_setr_epi16 = __mm512_setr_epi16Ptr.asFunction<
      __m512i Function(
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int,
          int)>();

  __m512i _mm512_setr_epi32(
    int arg0,
    int arg1,
    int arg2,
    int arg3,
    int arg4,
    int arg5,
    int arg6,
    int arg7,
    int arg8,
    int arg9,
    int arg10,
    int arg11,
    int arg12,
    int arg13,
    int arg14,
    int arg15,
  ) {
    return __mm512_setr_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
      arg5,
      arg6,
      arg7,
      arg8,
      arg9,
      arg10,
      arg11,
      arg12,
      arg13,
      arg14,
      arg15,
    );
  }

  late final __mm512_setr_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              ffi.Int32,
              ffi.Int32,
              ffi.Int32,
              ffi.Int32,
              ffi.Int32,
              ffi.Int32,
              ffi.Int32,
              ffi.Int32,
              ffi.Int32,
              ffi.Int32,
              ffi.Int32,
              ffi.Int32,
              ffi.Int32,
              ffi.Int32,
              ffi.Int32,
              ffi.Int32)>>('_mm512_setr_epi32');
  late final __mm512_setr_epi32 = __mm512_setr_epi32Ptr.asFunction<
      __m512i Function(int, int, int, int, int, int, int, int, int, int, int,
          int, int, int, int, int)>();

  __m512i _mm512_setr_epi64(
    int arg0,
    int arg1,
    int arg2,
    int arg3,
    int arg4,
    int arg5,
    int arg6,
    int arg7,
  ) {
    return __mm512_setr_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
      arg5,
      arg6,
      arg7,
    );
  }

  late final __mm512_setr_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              ffi.Int64,
              ffi.Int64,
              ffi.Int64,
              ffi.Int64,
              ffi.Int64,
              ffi.Int64,
              ffi.Int64,
              ffi.Int64)>>('_mm512_setr_epi64');
  late final __mm512_setr_epi64 = __mm512_setr_epi64Ptr
      .asFunction<__m512i Function(int, int, int, int, int, int, int, int)>();

  __m512i _mm512_set1_epi8(
    int arg0,
  ) {
    return __mm512_set1_epi8(
      arg0,
    );
  }

  late final __mm512_set1_epi8Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(ffi.Int8)>>(
          '_mm512_set1_epi8');
  late final __mm512_set1_epi8 =
      __mm512_set1_epi8Ptr.asFunction<__m512i Function(int)>();

  __m512i _mm512_mask_set1_epi8(
    __m512i arg0,
    int arg1,
    int arg2,
  ) {
    return __mm512_mask_set1_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_set1_epi8Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__m512i, __mmask64, ffi.Int8)>>(
      '_mm512_mask_set1_epi8');
  late final __mm512_mask_set1_epi8 = __mm512_mask_set1_epi8Ptr
      .asFunction<__m512i Function(__m512i, int, int)>();

  __m512i _mm512_maskz_set1_epi8(
    int arg0,
    int arg1,
  ) {
    return __mm512_maskz_set1_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_set1_epi8Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask64, ffi.Int8)>>(
          '_mm512_maskz_set1_epi8');
  late final __mm512_maskz_set1_epi8 =
      __mm512_maskz_set1_epi8Ptr.asFunction<__m512i Function(int, int)>();

  __m512i _mm512_set1_epi16(
    int arg0,
  ) {
    return __mm512_set1_epi16(
      arg0,
    );
  }

  late final __mm512_set1_epi16Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(ffi.Int16)>>(
          '_mm512_set1_epi16');
  late final __mm512_set1_epi16 =
      __mm512_set1_epi16Ptr.asFunction<__m512i Function(int)>();

  __m512i _mm512_mask_set1_epi16(
    __m512i arg0,
    int arg1,
    int arg2,
  ) {
    return __mm512_mask_set1_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_set1_epi16Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__m512i, __mmask32, ffi.Int16)>>(
      '_mm512_mask_set1_epi16');
  late final __mm512_mask_set1_epi16 = __mm512_mask_set1_epi16Ptr
      .asFunction<__m512i Function(__m512i, int, int)>();

  __m512i _mm512_maskz_set1_epi16(
    int arg0,
    int arg1,
  ) {
    return __mm512_maskz_set1_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_set1_epi16Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask32, ffi.Int16)>>(
          '_mm512_maskz_set1_epi16');
  late final __mm512_maskz_set1_epi16 =
      __mm512_maskz_set1_epi16Ptr.asFunction<__m512i Function(int, int)>();

  __m512i _mm512_set1_epi32(
    int arg0,
  ) {
    return __mm512_set1_epi32(
      arg0,
    );
  }

  late final __mm512_set1_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(ffi.Int32)>>(
          '_mm512_set1_epi32');
  late final __mm512_set1_epi32 =
      __mm512_set1_epi32Ptr.asFunction<__m512i Function(int)>();

  __m512i _mm512_mask_set1_epi32(
    __m512i arg0,
    int arg1,
    int arg2,
  ) {
    return __mm512_mask_set1_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_set1_epi32Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__m512i, __mmask16, ffi.Int32)>>(
      '_mm512_mask_set1_epi32');
  late final __mm512_mask_set1_epi32 = __mm512_mask_set1_epi32Ptr
      .asFunction<__m512i Function(__m512i, int, int)>();

  __m512i _mm512_maskz_set1_epi32(
    int arg0,
    int arg1,
  ) {
    return __mm512_maskz_set1_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_set1_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask16, ffi.Int32)>>(
          '_mm512_maskz_set1_epi32');
  late final __mm512_maskz_set1_epi32 =
      __mm512_maskz_set1_epi32Ptr.asFunction<__m512i Function(int, int)>();

  __m512i _mm512_set1_epi64(
    int arg0,
  ) {
    return __mm512_set1_epi64(
      arg0,
    );
  }

  late final __mm512_set1_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(ffi.Int64)>>(
          '_mm512_set1_epi64');
  late final __mm512_set1_epi64 =
      __mm512_set1_epi64Ptr.asFunction<__m512i Function(int)>();

  __m512i _mm512_mask_set1_epi64(
    __m512i arg0,
    int arg1,
    int arg2,
  ) {
    return __mm512_mask_set1_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_set1_epi64Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__m512i, __mmask8, ffi.Int64)>>(
      '_mm512_mask_set1_epi64');
  late final __mm512_mask_set1_epi64 = __mm512_mask_set1_epi64Ptr
      .asFunction<__m512i Function(__m512i, int, int)>();

  __m512i _mm512_maskz_set1_epi64(
    int arg0,
    int arg1,
  ) {
    return __mm512_maskz_set1_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_set1_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask8, ffi.Int64)>>(
          '_mm512_maskz_set1_epi64');
  late final __mm512_maskz_set1_epi64 =
      __mm512_maskz_set1_epi64Ptr.asFunction<__m512i Function(int, int)>();

  __m512i _mm512_add_epi8(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_add_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm512_add_epi8Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_add_epi8');
  late final __mm512_add_epi8 =
      __mm512_add_epi8Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_add_epi8(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_add_epi8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_add_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask64, __m512i, __m512i)>>('_mm512_mask_add_epi8');
  late final __mm512_mask_add_epi8 = __mm512_mask_add_epi8Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_add_epi8(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_add_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_add_epi8Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask64, __m512i, __m512i)>>(
      '_mm512_maskz_add_epi8');
  late final __mm512_maskz_add_epi8 = __mm512_maskz_add_epi8Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_add_epi16(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_add_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm512_add_epi16Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_add_epi16');
  late final __mm512_add_epi16 =
      __mm512_add_epi16Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_add_epi16(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_add_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_add_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask32, __m512i, __m512i)>>('_mm512_mask_add_epi16');
  late final __mm512_mask_add_epi16 = __mm512_mask_add_epi16Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_add_epi16(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_add_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_add_epi16Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask32, __m512i, __m512i)>>(
      '_mm512_maskz_add_epi16');
  late final __mm512_maskz_add_epi16 = __mm512_maskz_add_epi16Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_add_epi32(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_add_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_add_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_add_epi32');
  late final __mm512_add_epi32 =
      __mm512_add_epi32Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_add_epi32(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_add_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_add_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask16, __m512i, __m512i)>>('_mm512_mask_add_epi32');
  late final __mm512_mask_add_epi32 = __mm512_mask_add_epi32Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_add_epi32(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_add_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_add_epi32Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask16, __m512i, __m512i)>>(
      '_mm512_maskz_add_epi32');
  late final __mm512_maskz_add_epi32 = __mm512_maskz_add_epi32Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_add_epi64(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_add_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm512_add_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_add_epi64');
  late final __mm512_add_epi64 =
      __mm512_add_epi64Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_add_epi64(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_add_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_add_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask8, __m512i, __m512i)>>('_mm512_mask_add_epi64');
  late final __mm512_mask_add_epi64 = __mm512_mask_add_epi64Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_add_epi64(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_add_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_add_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask8, __m512i, __m512i)>>(
          '_mm512_maskz_add_epi64');
  late final __mm512_maskz_add_epi64 = __mm512_maskz_add_epi64Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_adds_epi8(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_adds_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm512_adds_epi8Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_adds_epi8');
  late final __mm512_adds_epi8 =
      __mm512_adds_epi8Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_adds_epi8(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_adds_epi8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_adds_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask64, __m512i, __m512i)>>('_mm512_mask_adds_epi8');
  late final __mm512_mask_adds_epi8 = __mm512_mask_adds_epi8Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_adds_epi8(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_adds_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_adds_epi8Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask64, __m512i, __m512i)>>(
      '_mm512_maskz_adds_epi8');
  late final __mm512_maskz_adds_epi8 = __mm512_maskz_adds_epi8Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_adds_epi16(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_adds_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm512_adds_epi16Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_adds_epi16');
  late final __mm512_adds_epi16 =
      __mm512_adds_epi16Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_adds_epi16(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_adds_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_adds_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask32, __m512i, __m512i)>>('_mm512_mask_adds_epi16');
  late final __mm512_mask_adds_epi16 = __mm512_mask_adds_epi16Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_adds_epi16(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_adds_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_adds_epi16Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask32, __m512i, __m512i)>>(
      '_mm512_maskz_adds_epi16');
  late final __mm512_maskz_adds_epi16 = __mm512_maskz_adds_epi16Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_adds_epu8(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_adds_epu8(
      arg0,
      arg1,
    );
  }

  late final __mm512_adds_epu8Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_adds_epu8');
  late final __mm512_adds_epu8 =
      __mm512_adds_epu8Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_adds_epu8(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_adds_epu8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_adds_epu8Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask64, __m512i, __m512i)>>('_mm512_mask_adds_epu8');
  late final __mm512_mask_adds_epu8 = __mm512_mask_adds_epu8Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_adds_epu8(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_adds_epu8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_adds_epu8Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask64, __m512i, __m512i)>>(
      '_mm512_maskz_adds_epu8');
  late final __mm512_maskz_adds_epu8 = __mm512_maskz_adds_epu8Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_adds_epu16(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_adds_epu16(
      arg0,
      arg1,
    );
  }

  late final __mm512_adds_epu16Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_adds_epu16');
  late final __mm512_adds_epu16 =
      __mm512_adds_epu16Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_adds_epu16(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_adds_epu16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_adds_epu16Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask32, __m512i, __m512i)>>('_mm512_mask_adds_epu16');
  late final __mm512_mask_adds_epu16 = __mm512_mask_adds_epu16Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_adds_epu16(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_adds_epu16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_adds_epu16Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask32, __m512i, __m512i)>>(
      '_mm512_maskz_adds_epu16');
  late final __mm512_maskz_adds_epu16 = __mm512_maskz_adds_epu16Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_abs_epi8(
    __m512i arg0,
  ) {
    return __mm512_abs_epi8(
      arg0,
    );
  }

  late final __mm512_abs_epi8Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i)>>('_mm512_abs_epi8');
  late final __mm512_abs_epi8 =
      __mm512_abs_epi8Ptr.asFunction<__m512i Function(__m512i)>();

  __m512i _mm512_mask_abs_epi8(
    __m512i arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_abs_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_abs_epi8Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__m512i, __mmask64, __m512i)>>(
      '_mm512_mask_abs_epi8');
  late final __mm512_mask_abs_epi8 = __mm512_mask_abs_epi8Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i)>();

  __m512i _mm512_maskz_abs_epi8(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_maskz_abs_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_abs_epi8Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask64, __m512i)>>(
          '_mm512_maskz_abs_epi8');
  late final __mm512_maskz_abs_epi8 =
      __mm512_maskz_abs_epi8Ptr.asFunction<__m512i Function(int, __m512i)>();

  __m512i _mm512_abs_epi16(
    __m512i arg0,
  ) {
    return __mm512_abs_epi16(
      arg0,
    );
  }

  late final __mm512_abs_epi16Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i)>>(
          '_mm512_abs_epi16');
  late final __mm512_abs_epi16 =
      __mm512_abs_epi16Ptr.asFunction<__m512i Function(__m512i)>();

  __m512i _mm512_mask_abs_epi16(
    __m512i arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_abs_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_abs_epi16Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__m512i, __mmask32, __m512i)>>(
      '_mm512_mask_abs_epi16');
  late final __mm512_mask_abs_epi16 = __mm512_mask_abs_epi16Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i)>();

  __m512i _mm512_maskz_abs_epi16(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_maskz_abs_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_abs_epi16Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask32, __m512i)>>(
          '_mm512_maskz_abs_epi16');
  late final __mm512_maskz_abs_epi16 =
      __mm512_maskz_abs_epi16Ptr.asFunction<__m512i Function(int, __m512i)>();

  __m512i _mm512_abs_epi32(
    __m512i arg0,
  ) {
    return __mm512_abs_epi32(
      arg0,
    );
  }

  late final __mm512_abs_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i)>>(
          '_mm512_abs_epi32');
  late final __mm512_abs_epi32 =
      __mm512_abs_epi32Ptr.asFunction<__m512i Function(__m512i)>();

  __m512i _mm512_mask_abs_epi32(
    __m512i arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_abs_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_abs_epi32Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__m512i, __mmask16, __m512i)>>(
      '_mm512_mask_abs_epi32');
  late final __mm512_mask_abs_epi32 = __mm512_mask_abs_epi32Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i)>();

  __m512i _mm512_maskz_abs_epi32(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_maskz_abs_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_abs_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask16, __m512i)>>(
          '_mm512_maskz_abs_epi32');
  late final __mm512_maskz_abs_epi32 =
      __mm512_maskz_abs_epi32Ptr.asFunction<__m512i Function(int, __m512i)>();

  __m512i _mm512_abs_epi64(
    __m512i arg0,
  ) {
    return __mm512_abs_epi64(
      arg0,
    );
  }

  late final __mm512_abs_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i)>>(
          '_mm512_abs_epi64');
  late final __mm512_abs_epi64 =
      __mm512_abs_epi64Ptr.asFunction<__m512i Function(__m512i)>();

  __m512i _mm512_mask_abs_epi64(
    __m512i arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_abs_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_abs_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __mmask8, __m512i)>>(
          '_mm512_mask_abs_epi64');
  late final __mm512_mask_abs_epi64 = __mm512_mask_abs_epi64Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i)>();

  __m512i _mm512_maskz_abs_epi64(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_maskz_abs_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_abs_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask8, __m512i)>>(
          '_mm512_maskz_abs_epi64');
  late final __mm512_maskz_abs_epi64 =
      __mm512_maskz_abs_epi64Ptr.asFunction<__m512i Function(int, __m512i)>();

  __m512i _mm512_broadcast_i32x2(
    __m128i arg0,
  ) {
    return __mm512_broadcast_i32x2(
      arg0,
    );
  }

  late final __mm512_broadcast_i32x2Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m128i)>>(
          '_mm512_broadcast_i32x2');
  late final __mm512_broadcast_i32x2 =
      __mm512_broadcast_i32x2Ptr.asFunction<__m512i Function(__m128i)>();

  __m512i _mm512_mask_broadcast_i32x2(
    __m512i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm512_mask_broadcast_i32x2(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_broadcast_i32x2Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__m512i, __mmask16, __m128i)>>(
      '_mm512_mask_broadcast_i32x2');
  late final __mm512_mask_broadcast_i32x2 = __mm512_mask_broadcast_i32x2Ptr
      .asFunction<__m512i Function(__m512i, int, __m128i)>();

  __m512i _mm512_maskz_broadcast_i32x2(
    int arg0,
    __m128i arg1,
  ) {
    return __mm512_maskz_broadcast_i32x2(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_broadcast_i32x2Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask16, __m128i)>>(
          '_mm512_maskz_broadcast_i32x2');
  late final __mm512_maskz_broadcast_i32x2 = __mm512_maskz_broadcast_i32x2Ptr
      .asFunction<__m512i Function(int, __m128i)>();

  __m512i _mm512_broadcast_i32x4(
    __m128i arg0,
  ) {
    return __mm512_broadcast_i32x4(
      arg0,
    );
  }

  late final __mm512_broadcast_i32x4Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m128i)>>(
          '_mm512_broadcast_i32x4');
  late final __mm512_broadcast_i32x4 =
      __mm512_broadcast_i32x4Ptr.asFunction<__m512i Function(__m128i)>();

  __m512i _mm512_mask_broadcast_i32x4(
    __m512i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm512_mask_broadcast_i32x4(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_broadcast_i32x4Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__m512i, __mmask16, __m128i)>>(
      '_mm512_mask_broadcast_i32x4');
  late final __mm512_mask_broadcast_i32x4 = __mm512_mask_broadcast_i32x4Ptr
      .asFunction<__m512i Function(__m512i, int, __m128i)>();

  __m512i _mm512_maskz_broadcast_i32x4(
    int arg0,
    __m128i arg1,
  ) {
    return __mm512_maskz_broadcast_i32x4(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_broadcast_i32x4Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask16, __m128i)>>(
          '_mm512_maskz_broadcast_i32x4');
  late final __mm512_maskz_broadcast_i32x4 = __mm512_maskz_broadcast_i32x4Ptr
      .asFunction<__m512i Function(int, __m128i)>();

  __m512i _mm512_broadcast_i32x8(
    __m256i arg0,
  ) {
    return __mm512_broadcast_i32x8(
      arg0,
    );
  }

  late final __mm512_broadcast_i32x8Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m256i)>>(
          '_mm512_broadcast_i32x8');
  late final __mm512_broadcast_i32x8 =
      __mm512_broadcast_i32x8Ptr.asFunction<__m512i Function(__m256i)>();

  __m512i _mm512_mask_broadcast_i32x8(
    __m512i arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm512_mask_broadcast_i32x8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_broadcast_i32x8Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__m512i, __mmask16, __m256i)>>(
      '_mm512_mask_broadcast_i32x8');
  late final __mm512_mask_broadcast_i32x8 = __mm512_mask_broadcast_i32x8Ptr
      .asFunction<__m512i Function(__m512i, int, __m256i)>();

  __m512i _mm512_maskz_broadcast_i32x8(
    int arg0,
    __m256i arg1,
  ) {
    return __mm512_maskz_broadcast_i32x8(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_broadcast_i32x8Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask16, __m256i)>>(
          '_mm512_maskz_broadcast_i32x8');
  late final __mm512_maskz_broadcast_i32x8 = __mm512_maskz_broadcast_i32x8Ptr
      .asFunction<__m512i Function(int, __m256i)>();

  __m512i _mm512_broadcast_i64x2(
    __m128i arg0,
  ) {
    return __mm512_broadcast_i64x2(
      arg0,
    );
  }

  late final __mm512_broadcast_i64x2Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m128i)>>(
          '_mm512_broadcast_i64x2');
  late final __mm512_broadcast_i64x2 =
      __mm512_broadcast_i64x2Ptr.asFunction<__m512i Function(__m128i)>();

  __m512i _mm512_mask_broadcast_i64x2(
    __m512i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm512_mask_broadcast_i64x2(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_broadcast_i64x2Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __mmask8, __m128i)>>(
          '_mm512_mask_broadcast_i64x2');
  late final __mm512_mask_broadcast_i64x2 = __mm512_mask_broadcast_i64x2Ptr
      .asFunction<__m512i Function(__m512i, int, __m128i)>();

  __m512i _mm512_maskz_broadcast_i64x2(
    int arg0,
    __m128i arg1,
  ) {
    return __mm512_maskz_broadcast_i64x2(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_broadcast_i64x2Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask8, __m128i)>>(
          '_mm512_maskz_broadcast_i64x2');
  late final __mm512_maskz_broadcast_i64x2 = __mm512_maskz_broadcast_i64x2Ptr
      .asFunction<__m512i Function(int, __m128i)>();

  __m512i _mm512_broadcast_i64x4(
    __m256i arg0,
  ) {
    return __mm512_broadcast_i64x4(
      arg0,
    );
  }

  late final __mm512_broadcast_i64x4Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m256i)>>(
          '_mm512_broadcast_i64x4');
  late final __mm512_broadcast_i64x4 =
      __mm512_broadcast_i64x4Ptr.asFunction<__m512i Function(__m256i)>();

  __m512i _mm512_mask_broadcast_i64x4(
    __m512i arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm512_mask_broadcast_i64x4(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_broadcast_i64x4Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __mmask8, __m256i)>>(
          '_mm512_mask_broadcast_i64x4');
  late final __mm512_mask_broadcast_i64x4 = __mm512_mask_broadcast_i64x4Ptr
      .asFunction<__m512i Function(__m512i, int, __m256i)>();

  __m512i _mm512_maskz_broadcast_i64x4(
    int arg0,
    __m256i arg1,
  ) {
    return __mm512_maskz_broadcast_i64x4(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_broadcast_i64x4Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask8, __m256i)>>(
          '_mm512_maskz_broadcast_i64x4');
  late final __mm512_maskz_broadcast_i64x4 = __mm512_maskz_broadcast_i64x4Ptr
      .asFunction<__m512i Function(int, __m256i)>();

  __m512i _mm512_broadcastb_epi8(
    __m128i arg0,
  ) {
    return __mm512_broadcastb_epi8(
      arg0,
    );
  }

  late final __mm512_broadcastb_epi8Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m128i)>>(
          '_mm512_broadcastb_epi8');
  late final __mm512_broadcastb_epi8 =
      __mm512_broadcastb_epi8Ptr.asFunction<__m512i Function(__m128i)>();

  __m512i _mm512_mask_broadcastb_epi8(
    __m512i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm512_mask_broadcastb_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_broadcastb_epi8Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__m512i, __mmask64, __m128i)>>(
      '_mm512_mask_broadcastb_epi8');
  late final __mm512_mask_broadcastb_epi8 = __mm512_mask_broadcastb_epi8Ptr
      .asFunction<__m512i Function(__m512i, int, __m128i)>();

  __m512i _mm512_maskz_broadcastb_epi8(
    int arg0,
    __m128i arg1,
  ) {
    return __mm512_maskz_broadcastb_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_broadcastb_epi8Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask64, __m128i)>>(
          '_mm512_maskz_broadcastb_epi8');
  late final __mm512_maskz_broadcastb_epi8 = __mm512_maskz_broadcastb_epi8Ptr
      .asFunction<__m512i Function(int, __m128i)>();

  __m512i _mm512_broadcastw_epi16(
    __m128i arg0,
  ) {
    return __mm512_broadcastw_epi16(
      arg0,
    );
  }

  late final __mm512_broadcastw_epi16Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m128i)>>(
          '_mm512_broadcastw_epi16');
  late final __mm512_broadcastw_epi16 =
      __mm512_broadcastw_epi16Ptr.asFunction<__m512i Function(__m128i)>();

  __m512i _mm512_mask_broadcastw_epi16(
    __m512i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm512_mask_broadcastw_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_broadcastw_epi16Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__m512i, __mmask32, __m128i)>>(
      '_mm512_mask_broadcastw_epi16');
  late final __mm512_mask_broadcastw_epi16 = __mm512_mask_broadcastw_epi16Ptr
      .asFunction<__m512i Function(__m512i, int, __m128i)>();

  __m512i _mm512_maskz_broadcastw_epi16(
    int arg0,
    __m128i arg1,
  ) {
    return __mm512_maskz_broadcastw_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_broadcastw_epi16Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask32, __m128i)>>(
          '_mm512_maskz_broadcastw_epi16');
  late final __mm512_maskz_broadcastw_epi16 = __mm512_maskz_broadcastw_epi16Ptr
      .asFunction<__m512i Function(int, __m128i)>();

  __m512i _mm512_broadcastd_epi32(
    __m128i arg0,
  ) {
    return __mm512_broadcastd_epi32(
      arg0,
    );
  }

  late final __mm512_broadcastd_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m128i)>>(
          '_mm512_broadcastd_epi32');
  late final __mm512_broadcastd_epi32 =
      __mm512_broadcastd_epi32Ptr.asFunction<__m512i Function(__m128i)>();

  __m512i _mm512_mask_broadcastd_epi32(
    __m512i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm512_mask_broadcastd_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_broadcastd_epi32Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__m512i, __mmask16, __m128i)>>(
      '_mm512_mask_broadcastd_epi32');
  late final __mm512_mask_broadcastd_epi32 = __mm512_mask_broadcastd_epi32Ptr
      .asFunction<__m512i Function(__m512i, int, __m128i)>();

  __m512i _mm512_maskz_broadcastd_epi32(
    int arg0,
    __m128i arg1,
  ) {
    return __mm512_maskz_broadcastd_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_broadcastd_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask16, __m128i)>>(
          '_mm512_maskz_broadcastd_epi32');
  late final __mm512_maskz_broadcastd_epi32 = __mm512_maskz_broadcastd_epi32Ptr
      .asFunction<__m512i Function(int, __m128i)>();

  __m512i _mm512_broadcastq_epi64(
    __m128i arg0,
  ) {
    return __mm512_broadcastq_epi64(
      arg0,
    );
  }

  late final __mm512_broadcastq_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m128i)>>(
          '_mm512_broadcastq_epi64');
  late final __mm512_broadcastq_epi64 =
      __mm512_broadcastq_epi64Ptr.asFunction<__m512i Function(__m128i)>();

  __m512i _mm512_mask_broadcastq_epi64(
    __m512i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm512_mask_broadcastq_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_broadcastq_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __mmask8, __m128i)>>(
          '_mm512_mask_broadcastq_epi64');
  late final __mm512_mask_broadcastq_epi64 = __mm512_mask_broadcastq_epi64Ptr
      .asFunction<__m512i Function(__m512i, int, __m128i)>();

  __m512i _mm512_maskz_broadcastq_epi64(
    int arg0,
    __m128i arg1,
  ) {
    return __mm512_maskz_broadcastq_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_broadcastq_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask8, __m128i)>>(
          '_mm512_maskz_broadcastq_epi64');
  late final __mm512_maskz_broadcastq_epi64 = __mm512_maskz_broadcastq_epi64Ptr
      .asFunction<__m512i Function(int, __m128i)>();

  __m512i _mm512_broadcastmw_epi32(
    int arg0,
  ) {
    return __mm512_broadcastmw_epi32(
      arg0,
    );
  }

  late final __mm512_broadcastmw_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask16)>>(
          '_mm512_broadcastmw_epi32');
  late final __mm512_broadcastmw_epi32 =
      __mm512_broadcastmw_epi32Ptr.asFunction<__m512i Function(int)>();

  __m512i _mm512_broadcastmb_epi64(
    int arg0,
  ) {
    return __mm512_broadcastmb_epi64(
      arg0,
    );
  }

  late final __mm512_broadcastmb_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask8)>>(
          '_mm512_broadcastmb_epi64');
  late final __mm512_broadcastmb_epi64 =
      __mm512_broadcastmb_epi64Ptr.asFunction<__m512i Function(int)>();

  __m512i _mm512_sub_epi8(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_sub_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm512_sub_epi8Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_sub_epi8');
  late final __mm512_sub_epi8 =
      __mm512_sub_epi8Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_sub_epi8(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_sub_epi8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_sub_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask64, __m512i, __m512i)>>('_mm512_mask_sub_epi8');
  late final __mm512_mask_sub_epi8 = __mm512_mask_sub_epi8Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_sub_epi8(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_sub_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_sub_epi8Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask64, __m512i, __m512i)>>(
      '_mm512_maskz_sub_epi8');
  late final __mm512_maskz_sub_epi8 = __mm512_maskz_sub_epi8Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_sub_epi16(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_sub_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm512_sub_epi16Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_sub_epi16');
  late final __mm512_sub_epi16 =
      __mm512_sub_epi16Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_sub_epi16(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_sub_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_sub_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask32, __m512i, __m512i)>>('_mm512_mask_sub_epi16');
  late final __mm512_mask_sub_epi16 = __mm512_mask_sub_epi16Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_sub_epi16(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_sub_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_sub_epi16Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask32, __m512i, __m512i)>>(
      '_mm512_maskz_sub_epi16');
  late final __mm512_maskz_sub_epi16 = __mm512_maskz_sub_epi16Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_sub_epi32(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_sub_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_sub_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_sub_epi32');
  late final __mm512_sub_epi32 =
      __mm512_sub_epi32Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_sub_epi32(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_sub_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_sub_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask16, __m512i, __m512i)>>('_mm512_mask_sub_epi32');
  late final __mm512_mask_sub_epi32 = __mm512_mask_sub_epi32Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_sub_epi32(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_sub_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_sub_epi32Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask16, __m512i, __m512i)>>(
      '_mm512_maskz_sub_epi32');
  late final __mm512_maskz_sub_epi32 = __mm512_maskz_sub_epi32Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_sub_epi64(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_sub_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm512_sub_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_sub_epi64');
  late final __mm512_sub_epi64 =
      __mm512_sub_epi64Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_sub_epi64(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_sub_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_sub_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask8, __m512i, __m512i)>>('_mm512_mask_sub_epi64');
  late final __mm512_mask_sub_epi64 = __mm512_mask_sub_epi64Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_sub_epi64(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_sub_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_sub_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask8, __m512i, __m512i)>>(
          '_mm512_maskz_sub_epi64');
  late final __mm512_maskz_sub_epi64 = __mm512_maskz_sub_epi64Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_subs_epi8(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_subs_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm512_subs_epi8Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_subs_epi8');
  late final __mm512_subs_epi8 =
      __mm512_subs_epi8Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_subs_epi8(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_subs_epi8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_subs_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask64, __m512i, __m512i)>>('_mm512_mask_subs_epi8');
  late final __mm512_mask_subs_epi8 = __mm512_mask_subs_epi8Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_subs_epi8(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_subs_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_subs_epi8Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask64, __m512i, __m512i)>>(
      '_mm512_maskz_subs_epi8');
  late final __mm512_maskz_subs_epi8 = __mm512_maskz_subs_epi8Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_subs_epi16(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_subs_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm512_subs_epi16Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_subs_epi16');
  late final __mm512_subs_epi16 =
      __mm512_subs_epi16Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_subs_epi16(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_subs_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_subs_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask32, __m512i, __m512i)>>('_mm512_mask_subs_epi16');
  late final __mm512_mask_subs_epi16 = __mm512_mask_subs_epi16Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_subs_epi16(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_subs_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_subs_epi16Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask32, __m512i, __m512i)>>(
      '_mm512_maskz_subs_epi16');
  late final __mm512_maskz_subs_epi16 = __mm512_maskz_subs_epi16Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_subs_epu8(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_subs_epu8(
      arg0,
      arg1,
    );
  }

  late final __mm512_subs_epu8Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_subs_epu8');
  late final __mm512_subs_epu8 =
      __mm512_subs_epu8Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_subs_epu8(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_subs_epu8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_subs_epu8Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask64, __m512i, __m512i)>>('_mm512_mask_subs_epu8');
  late final __mm512_mask_subs_epu8 = __mm512_mask_subs_epu8Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_subs_epu8(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_subs_epu8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_subs_epu8Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask64, __m512i, __m512i)>>(
      '_mm512_maskz_subs_epu8');
  late final __mm512_maskz_subs_epu8 = __mm512_maskz_subs_epu8Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_subs_epu16(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_subs_epu16(
      arg0,
      arg1,
    );
  }

  late final __mm512_subs_epu16Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_subs_epu16');
  late final __mm512_subs_epu16 =
      __mm512_subs_epu16Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_subs_epu16(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_subs_epu16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_subs_epu16Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask32, __m512i, __m512i)>>('_mm512_mask_subs_epu16');
  late final __mm512_mask_subs_epu16 = __mm512_mask_subs_epu16Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_subs_epu16(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_subs_epu16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_subs_epu16Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask32, __m512i, __m512i)>>(
      '_mm512_maskz_subs_epu16');
  late final __mm512_maskz_subs_epu16 = __mm512_maskz_subs_epu16Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_max_epi8(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_max_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm512_max_epi8Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_max_epi8');
  late final __mm512_max_epi8 =
      __mm512_max_epi8Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_max_epi8(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_max_epi8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_max_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask64, __m512i, __m512i)>>('_mm512_mask_max_epi8');
  late final __mm512_mask_max_epi8 = __mm512_mask_max_epi8Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_max_epi8(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_max_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_max_epi8Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask64, __m512i, __m512i)>>(
      '_mm512_maskz_max_epi8');
  late final __mm512_maskz_max_epi8 = __mm512_maskz_max_epi8Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_max_epi16(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_max_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm512_max_epi16Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_max_epi16');
  late final __mm512_max_epi16 =
      __mm512_max_epi16Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_max_epi16(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_max_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_max_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask32, __m512i, __m512i)>>('_mm512_mask_max_epi16');
  late final __mm512_mask_max_epi16 = __mm512_mask_max_epi16Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_max_epi16(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_max_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_max_epi16Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask32, __m512i, __m512i)>>(
      '_mm512_maskz_max_epi16');
  late final __mm512_maskz_max_epi16 = __mm512_maskz_max_epi16Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_max_epi32(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_max_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_max_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_max_epi32');
  late final __mm512_max_epi32 =
      __mm512_max_epi32Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_max_epi32(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_max_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_max_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask16, __m512i, __m512i)>>('_mm512_mask_max_epi32');
  late final __mm512_mask_max_epi32 = __mm512_mask_max_epi32Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_max_epi32(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_max_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_max_epi32Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask16, __m512i, __m512i)>>(
      '_mm512_maskz_max_epi32');
  late final __mm512_maskz_max_epi32 = __mm512_maskz_max_epi32Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_max_epi64(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_max_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm512_max_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_max_epi64');
  late final __mm512_max_epi64 =
      __mm512_max_epi64Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_max_epi64(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_max_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_max_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask8, __m512i, __m512i)>>('_mm512_mask_max_epi64');
  late final __mm512_mask_max_epi64 = __mm512_mask_max_epi64Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_max_epi64(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_max_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_max_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask8, __m512i, __m512i)>>(
          '_mm512_maskz_max_epi64');
  late final __mm512_maskz_max_epi64 = __mm512_maskz_max_epi64Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_max_epu8(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_max_epu8(
      arg0,
      arg1,
    );
  }

  late final __mm512_max_epu8Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_max_epu8');
  late final __mm512_max_epu8 =
      __mm512_max_epu8Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_max_epu8(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_max_epu8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_max_epu8Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask64, __m512i, __m512i)>>('_mm512_mask_max_epu8');
  late final __mm512_mask_max_epu8 = __mm512_mask_max_epu8Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_max_epu8(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_max_epu8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_max_epu8Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask64, __m512i, __m512i)>>(
      '_mm512_maskz_max_epu8');
  late final __mm512_maskz_max_epu8 = __mm512_maskz_max_epu8Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_max_epu16(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_max_epu16(
      arg0,
      arg1,
    );
  }

  late final __mm512_max_epu16Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_max_epu16');
  late final __mm512_max_epu16 =
      __mm512_max_epu16Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_max_epu16(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_max_epu16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_max_epu16Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask32, __m512i, __m512i)>>('_mm512_mask_max_epu16');
  late final __mm512_mask_max_epu16 = __mm512_mask_max_epu16Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_max_epu16(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_max_epu16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_max_epu16Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask32, __m512i, __m512i)>>(
      '_mm512_maskz_max_epu16');
  late final __mm512_maskz_max_epu16 = __mm512_maskz_max_epu16Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_max_epu32(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_max_epu32(
      arg0,
      arg1,
    );
  }

  late final __mm512_max_epu32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_max_epu32');
  late final __mm512_max_epu32 =
      __mm512_max_epu32Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_max_epu32(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_max_epu32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_max_epu32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask16, __m512i, __m512i)>>('_mm512_mask_max_epu32');
  late final __mm512_mask_max_epu32 = __mm512_mask_max_epu32Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_max_epu32(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_max_epu32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_max_epu32Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask16, __m512i, __m512i)>>(
      '_mm512_maskz_max_epu32');
  late final __mm512_maskz_max_epu32 = __mm512_maskz_max_epu32Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_max_epu64(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_max_epu64(
      arg0,
      arg1,
    );
  }

  late final __mm512_max_epu64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_max_epu64');
  late final __mm512_max_epu64 =
      __mm512_max_epu64Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_max_epu64(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_max_epu64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_max_epu64Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask8, __m512i, __m512i)>>('_mm512_mask_max_epu64');
  late final __mm512_mask_max_epu64 = __mm512_mask_max_epu64Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_max_epu64(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_max_epu64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_max_epu64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask8, __m512i, __m512i)>>(
          '_mm512_maskz_max_epu64');
  late final __mm512_maskz_max_epu64 = __mm512_maskz_max_epu64Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_min_epi8(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_min_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm512_min_epi8Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_min_epi8');
  late final __mm512_min_epi8 =
      __mm512_min_epi8Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_min_epi8(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_min_epi8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_min_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask64, __m512i, __m512i)>>('_mm512_mask_min_epi8');
  late final __mm512_mask_min_epi8 = __mm512_mask_min_epi8Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_min_epi8(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_min_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_min_epi8Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask64, __m512i, __m512i)>>(
      '_mm512_maskz_min_epi8');
  late final __mm512_maskz_min_epi8 = __mm512_maskz_min_epi8Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_min_epi16(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_min_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm512_min_epi16Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_min_epi16');
  late final __mm512_min_epi16 =
      __mm512_min_epi16Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_min_epi16(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_min_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_min_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask32, __m512i, __m512i)>>('_mm512_mask_min_epi16');
  late final __mm512_mask_min_epi16 = __mm512_mask_min_epi16Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_min_epi16(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_min_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_min_epi16Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask32, __m512i, __m512i)>>(
      '_mm512_maskz_min_epi16');
  late final __mm512_maskz_min_epi16 = __mm512_maskz_min_epi16Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_min_epi32(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_min_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_min_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_min_epi32');
  late final __mm512_min_epi32 =
      __mm512_min_epi32Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_min_epi32(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_min_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_min_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask16, __m512i, __m512i)>>('_mm512_mask_min_epi32');
  late final __mm512_mask_min_epi32 = __mm512_mask_min_epi32Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_min_epi32(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_min_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_min_epi32Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask16, __m512i, __m512i)>>(
      '_mm512_maskz_min_epi32');
  late final __mm512_maskz_min_epi32 = __mm512_maskz_min_epi32Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_min_epi64(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_min_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm512_min_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_min_epi64');
  late final __mm512_min_epi64 =
      __mm512_min_epi64Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_min_epi64(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_min_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_min_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask8, __m512i, __m512i)>>('_mm512_mask_min_epi64');
  late final __mm512_mask_min_epi64 = __mm512_mask_min_epi64Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_min_epi64(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_min_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_min_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask8, __m512i, __m512i)>>(
          '_mm512_maskz_min_epi64');
  late final __mm512_maskz_min_epi64 = __mm512_maskz_min_epi64Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_min_epu8(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_min_epu8(
      arg0,
      arg1,
    );
  }

  late final __mm512_min_epu8Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_min_epu8');
  late final __mm512_min_epu8 =
      __mm512_min_epu8Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_min_epu8(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_min_epu8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_min_epu8Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask64, __m512i, __m512i)>>('_mm512_mask_min_epu8');
  late final __mm512_mask_min_epu8 = __mm512_mask_min_epu8Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_min_epu8(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_min_epu8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_min_epu8Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask64, __m512i, __m512i)>>(
      '_mm512_maskz_min_epu8');
  late final __mm512_maskz_min_epu8 = __mm512_maskz_min_epu8Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_min_epu16(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_min_epu16(
      arg0,
      arg1,
    );
  }

  late final __mm512_min_epu16Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_min_epu16');
  late final __mm512_min_epu16 =
      __mm512_min_epu16Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_min_epu16(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_min_epu16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_min_epu16Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask32, __m512i, __m512i)>>('_mm512_mask_min_epu16');
  late final __mm512_mask_min_epu16 = __mm512_mask_min_epu16Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_min_epu16(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_min_epu16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_min_epu16Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask32, __m512i, __m512i)>>(
      '_mm512_maskz_min_epu16');
  late final __mm512_maskz_min_epu16 = __mm512_maskz_min_epu16Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_min_epu32(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_min_epu32(
      arg0,
      arg1,
    );
  }

  late final __mm512_min_epu32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_min_epu32');
  late final __mm512_min_epu32 =
      __mm512_min_epu32Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_min_epu32(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_min_epu32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_min_epu32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask16, __m512i, __m512i)>>('_mm512_mask_min_epu32');
  late final __mm512_mask_min_epu32 = __mm512_mask_min_epu32Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_min_epu32(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_min_epu32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_min_epu32Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask16, __m512i, __m512i)>>(
      '_mm512_maskz_min_epu32');
  late final __mm512_maskz_min_epu32 = __mm512_maskz_min_epu32Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_min_epu64(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_min_epu64(
      arg0,
      arg1,
    );
  }

  late final __mm512_min_epu64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_min_epu64');
  late final __mm512_min_epu64 =
      __mm512_min_epu64Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_min_epu64(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_min_epu64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_min_epu64Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask8, __m512i, __m512i)>>('_mm512_mask_min_epu64');
  late final __mm512_mask_min_epu64 = __mm512_mask_min_epu64Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_min_epu64(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_min_epu64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_min_epu64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask8, __m512i, __m512i)>>(
          '_mm512_maskz_min_epu64');
  late final __mm512_maskz_min_epu64 = __mm512_maskz_min_epu64Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_mul_epi32(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_mul_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_mul_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_mul_epi32');
  late final __mm512_mul_epi32 =
      __mm512_mul_epi32Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_mul_epi32(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_mul_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_mul_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask8, __m512i, __m512i)>>('_mm512_mask_mul_epi32');
  late final __mm512_mask_mul_epi32 = __mm512_mask_mul_epi32Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_mul_epi32(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_mul_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_mul_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask8, __m512i, __m512i)>>(
          '_mm512_maskz_mul_epi32');
  late final __mm512_maskz_mul_epi32 = __mm512_maskz_mul_epi32Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_mul_epu32(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_mul_epu32(
      arg0,
      arg1,
    );
  }

  late final __mm512_mul_epu32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_mul_epu32');
  late final __mm512_mul_epu32 =
      __mm512_mul_epu32Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_mul_epu32(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_mul_epu32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_mul_epu32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask8, __m512i, __m512i)>>('_mm512_mask_mul_epu32');
  late final __mm512_mask_mul_epu32 = __mm512_mask_mul_epu32Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_mul_epu32(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_mul_epu32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_mul_epu32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask8, __m512i, __m512i)>>(
          '_mm512_maskz_mul_epu32');
  late final __mm512_maskz_mul_epu32 = __mm512_maskz_mul_epu32Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_mulhi_epi16(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_mulhi_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm512_mulhi_epi16Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_mulhi_epi16');
  late final __mm512_mulhi_epi16 =
      __mm512_mulhi_epi16Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_mulhi_epi16(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_mulhi_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_mulhi_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask32, __m512i,
              __m512i)>>('_mm512_mask_mulhi_epi16');
  late final __mm512_mask_mulhi_epi16 = __mm512_mask_mulhi_epi16Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_mulhi_epi16(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_mulhi_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_mulhi_epi16Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask32, __m512i, __m512i)>>(
      '_mm512_maskz_mulhi_epi16');
  late final __mm512_maskz_mulhi_epi16 = __mm512_maskz_mulhi_epi16Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_mulhi_epu16(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_mulhi_epu16(
      arg0,
      arg1,
    );
  }

  late final __mm512_mulhi_epu16Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_mulhi_epu16');
  late final __mm512_mulhi_epu16 =
      __mm512_mulhi_epu16Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_mulhi_epu16(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_mulhi_epu16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_mulhi_epu16Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask32, __m512i,
              __m512i)>>('_mm512_mask_mulhi_epu16');
  late final __mm512_mask_mulhi_epu16 = __mm512_mask_mulhi_epu16Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_mulhi_epu16(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_mulhi_epu16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_mulhi_epu16Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask32, __m512i, __m512i)>>(
      '_mm512_maskz_mulhi_epu16');
  late final __mm512_maskz_mulhi_epu16 = __mm512_maskz_mulhi_epu16Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_mullo_epi16(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_mullo_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm512_mullo_epi16Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_mullo_epi16');
  late final __mm512_mullo_epi16 =
      __mm512_mullo_epi16Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_mullo_epi16(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_mullo_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_mullo_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask32, __m512i,
              __m512i)>>('_mm512_mask_mullo_epi16');
  late final __mm512_mask_mullo_epi16 = __mm512_mask_mullo_epi16Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_mullo_epi16(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_mullo_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_mullo_epi16Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask32, __m512i, __m512i)>>(
      '_mm512_maskz_mullo_epi16');
  late final __mm512_maskz_mullo_epi16 = __mm512_maskz_mullo_epi16Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_mullo_epi32(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_mullo_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_mullo_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_mullo_epi32');
  late final __mm512_mullo_epi32 =
      __mm512_mullo_epi32Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_mullo_epi32(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_mullo_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_mullo_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask16, __m512i,
              __m512i)>>('_mm512_mask_mullo_epi32');
  late final __mm512_mask_mullo_epi32 = __mm512_mask_mullo_epi32Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_mullo_epi32(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_mullo_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_mullo_epi32Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask16, __m512i, __m512i)>>(
      '_mm512_maskz_mullo_epi32');
  late final __mm512_maskz_mullo_epi32 = __mm512_maskz_mullo_epi32Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_mullo_epi64(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_mullo_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm512_mullo_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_mullo_epi64');
  late final __mm512_mullo_epi64 =
      __mm512_mullo_epi64Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_mullo_epi64(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_mullo_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_mullo_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask8, __m512i, __m512i)>>('_mm512_mask_mullo_epi64');
  late final __mm512_mask_mullo_epi64 = __mm512_mask_mullo_epi64Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_mullo_epi64(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_mullo_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_mullo_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask8, __m512i, __m512i)>>(
          '_mm512_maskz_mullo_epi64');
  late final __mm512_maskz_mullo_epi64 = __mm512_maskz_mullo_epi64Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_mullox_epi64(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_mullox_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm512_mullox_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_mullox_epi64');
  late final __mm512_mullox_epi64 =
      __mm512_mullox_epi64Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_mullox_epi64(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_mullox_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_mullox_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask8, __m512i,
              __m512i)>>('_mm512_mask_mullox_epi64');
  late final __mm512_mask_mullox_epi64 = __mm512_mask_mullox_epi64Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_mulhrs_epi16(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_mulhrs_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm512_mulhrs_epi16Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_mulhrs_epi16');
  late final __mm512_mulhrs_epi16 =
      __mm512_mulhrs_epi16Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_mulhrs_epi16(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_mulhrs_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_mulhrs_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask32, __m512i,
              __m512i)>>('_mm512_mask_mulhrs_epi16');
  late final __mm512_mask_mulhrs_epi16 = __mm512_mask_mulhrs_epi16Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_mulhrs_epi16(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_mulhrs_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_mulhrs_epi16Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask32, __m512i, __m512i)>>(
      '_mm512_maskz_mulhrs_epi16');
  late final __mm512_maskz_mulhrs_epi16 = __mm512_maskz_mulhrs_epi16Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_load_epi32(
    ffi.Pointer<ffi.Void> arg0,
  ) {
    return __mm512_load_epi32(
      arg0,
    );
  }

  late final __mm512_load_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(ffi.Pointer<ffi.Void>)>>(
          '_mm512_load_epi32');
  late final __mm512_load_epi32 = __mm512_load_epi32Ptr
      .asFunction<__m512i Function(ffi.Pointer<ffi.Void>)>();

  __m512i _mm512_mask_load_epi32(
    __m512i arg0,
    int arg1,
    ffi.Pointer<ffi.Void> arg2,
  ) {
    return __mm512_mask_load_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_load_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask16,
              ffi.Pointer<ffi.Void>)>>('_mm512_mask_load_epi32');
  late final __mm512_mask_load_epi32 = __mm512_mask_load_epi32Ptr
      .asFunction<__m512i Function(__m512i, int, ffi.Pointer<ffi.Void>)>();

  __m512i _mm512_maskz_load_epi32(
    int arg0,
    ffi.Pointer<ffi.Void> arg1,
  ) {
    return __mm512_maskz_load_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_load_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __mmask16, ffi.Pointer<ffi.Void>)>>('_mm512_maskz_load_epi32');
  late final __mm512_maskz_load_epi32 = __mm512_maskz_load_epi32Ptr
      .asFunction<__m512i Function(int, ffi.Pointer<ffi.Void>)>();

  __m512i _mm512_load_epi64(
    ffi.Pointer<ffi.Void> arg0,
  ) {
    return __mm512_load_epi64(
      arg0,
    );
  }

  late final __mm512_load_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(ffi.Pointer<ffi.Void>)>>(
          '_mm512_load_epi64');
  late final __mm512_load_epi64 = __mm512_load_epi64Ptr
      .asFunction<__m512i Function(ffi.Pointer<ffi.Void>)>();

  __m512i _mm512_mask_load_epi64(
    __m512i arg0,
    int arg1,
    ffi.Pointer<ffi.Void> arg2,
  ) {
    return __mm512_mask_load_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_load_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask8,
              ffi.Pointer<ffi.Void>)>>('_mm512_mask_load_epi64');
  late final __mm512_mask_load_epi64 = __mm512_mask_load_epi64Ptr
      .asFunction<__m512i Function(__m512i, int, ffi.Pointer<ffi.Void>)>();

  __m512i _mm512_maskz_load_epi64(
    int arg0,
    ffi.Pointer<ffi.Void> arg1,
  ) {
    return __mm512_maskz_load_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_load_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __mmask8, ffi.Pointer<ffi.Void>)>>('_mm512_maskz_load_epi64');
  late final __mm512_maskz_load_epi64 = __mm512_maskz_load_epi64Ptr
      .asFunction<__m512i Function(int, ffi.Pointer<ffi.Void>)>();

  __m512i _mm512_loadu_epi8(
    ffi.Pointer<ffi.Void> arg0,
  ) {
    return __mm512_loadu_epi8(
      arg0,
    );
  }

  late final __mm512_loadu_epi8Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(ffi.Pointer<ffi.Void>)>>(
          '_mm512_loadu_epi8');
  late final __mm512_loadu_epi8 = __mm512_loadu_epi8Ptr
      .asFunction<__m512i Function(ffi.Pointer<ffi.Void>)>();

  __m512i _mm512_mask_loadu_epi8(
    __m512i arg0,
    int arg1,
    ffi.Pointer<ffi.Void> arg2,
  ) {
    return __mm512_mask_loadu_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_loadu_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask64,
              ffi.Pointer<ffi.Void>)>>('_mm512_mask_loadu_epi8');
  late final __mm512_mask_loadu_epi8 = __mm512_mask_loadu_epi8Ptr
      .asFunction<__m512i Function(__m512i, int, ffi.Pointer<ffi.Void>)>();

  __m512i _mm512_maskz_loadu_epi8(
    int arg0,
    ffi.Pointer<ffi.Void> arg1,
  ) {
    return __mm512_maskz_loadu_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_loadu_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __mmask64, ffi.Pointer<ffi.Void>)>>('_mm512_maskz_loadu_epi8');
  late final __mm512_maskz_loadu_epi8 = __mm512_maskz_loadu_epi8Ptr
      .asFunction<__m512i Function(int, ffi.Pointer<ffi.Void>)>();

  __m512i _mm512_loadu_epi16(
    ffi.Pointer<ffi.Void> arg0,
  ) {
    return __mm512_loadu_epi16(
      arg0,
    );
  }

  late final __mm512_loadu_epi16Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(ffi.Pointer<ffi.Void>)>>(
          '_mm512_loadu_epi16');
  late final __mm512_loadu_epi16 = __mm512_loadu_epi16Ptr
      .asFunction<__m512i Function(ffi.Pointer<ffi.Void>)>();

  __m512i _mm512_mask_loadu_epi16(
    __m512i arg0,
    int arg1,
    ffi.Pointer<ffi.Void> arg2,
  ) {
    return __mm512_mask_loadu_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_loadu_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask32,
              ffi.Pointer<ffi.Void>)>>('_mm512_mask_loadu_epi16');
  late final __mm512_mask_loadu_epi16 = __mm512_mask_loadu_epi16Ptr
      .asFunction<__m512i Function(__m512i, int, ffi.Pointer<ffi.Void>)>();

  __m512i _mm512_maskz_loadu_epi16(
    int arg0,
    ffi.Pointer<ffi.Void> arg1,
  ) {
    return __mm512_maskz_loadu_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_loadu_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __mmask32, ffi.Pointer<ffi.Void>)>>('_mm512_maskz_loadu_epi16');
  late final __mm512_maskz_loadu_epi16 = __mm512_maskz_loadu_epi16Ptr
      .asFunction<__m512i Function(int, ffi.Pointer<ffi.Void>)>();

  __m512i _mm512_loadu_epi32(
    ffi.Pointer<ffi.Void> arg0,
  ) {
    return __mm512_loadu_epi32(
      arg0,
    );
  }

  late final __mm512_loadu_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(ffi.Pointer<ffi.Void>)>>(
          '_mm512_loadu_epi32');
  late final __mm512_loadu_epi32 = __mm512_loadu_epi32Ptr
      .asFunction<__m512i Function(ffi.Pointer<ffi.Void>)>();

  __m512i _mm512_mask_loadu_epi32(
    __m512i arg0,
    int arg1,
    ffi.Pointer<ffi.Void> arg2,
  ) {
    return __mm512_mask_loadu_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_loadu_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask16,
              ffi.Pointer<ffi.Void>)>>('_mm512_mask_loadu_epi32');
  late final __mm512_mask_loadu_epi32 = __mm512_mask_loadu_epi32Ptr
      .asFunction<__m512i Function(__m512i, int, ffi.Pointer<ffi.Void>)>();

  __m512i _mm512_maskz_loadu_epi32(
    int arg0,
    ffi.Pointer<ffi.Void> arg1,
  ) {
    return __mm512_maskz_loadu_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_loadu_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __mmask16, ffi.Pointer<ffi.Void>)>>('_mm512_maskz_loadu_epi32');
  late final __mm512_maskz_loadu_epi32 = __mm512_maskz_loadu_epi32Ptr
      .asFunction<__m512i Function(int, ffi.Pointer<ffi.Void>)>();

  __m512i _mm512_loadu_epi64(
    ffi.Pointer<ffi.Void> arg0,
  ) {
    return __mm512_loadu_epi64(
      arg0,
    );
  }

  late final __mm512_loadu_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(ffi.Pointer<ffi.Void>)>>(
          '_mm512_loadu_epi64');
  late final __mm512_loadu_epi64 = __mm512_loadu_epi64Ptr
      .asFunction<__m512i Function(ffi.Pointer<ffi.Void>)>();

  __m512i _mm512_mask_loadu_epi64(
    __m512i arg0,
    int arg1,
    ffi.Pointer<ffi.Void> arg2,
  ) {
    return __mm512_mask_loadu_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_loadu_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask8,
              ffi.Pointer<ffi.Void>)>>('_mm512_mask_loadu_epi64');
  late final __mm512_mask_loadu_epi64 = __mm512_mask_loadu_epi64Ptr
      .asFunction<__m512i Function(__m512i, int, ffi.Pointer<ffi.Void>)>();

  __m512i _mm512_maskz_loadu_epi64(
    int arg0,
    ffi.Pointer<ffi.Void> arg1,
  ) {
    return __mm512_maskz_loadu_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_loadu_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __mmask8, ffi.Pointer<ffi.Void>)>>('_mm512_maskz_loadu_epi64');
  late final __mm512_maskz_loadu_epi64 = __mm512_maskz_loadu_epi64Ptr
      .asFunction<__m512i Function(int, ffi.Pointer<ffi.Void>)>();

  void _mm512_store_epi32(
    ffi.Pointer<ffi.Void> arg0,
    __m512i arg1,
  ) {
    return __mm512_store_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_store_epi32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<ffi.Void>, __m512i)>>('_mm512_store_epi32');
  late final __mm512_store_epi32 = __mm512_store_epi32Ptr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, __m512i)>();

  void _mm512_mask_store_epi32(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_store_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_store_epi32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask16,
              __m512i)>>('_mm512_mask_store_epi32');
  late final __mm512_mask_store_epi32 = __mm512_mask_store_epi32Ptr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m512i)>();

  void _mm512_store_epi64(
    ffi.Pointer<ffi.Void> arg0,
    __m512i arg1,
  ) {
    return __mm512_store_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm512_store_epi64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<ffi.Void>, __m512i)>>('_mm512_store_epi64');
  late final __mm512_store_epi64 = __mm512_store_epi64Ptr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, __m512i)>();

  void _mm512_mask_store_epi64(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_store_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_store_epi64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8,
              __m512i)>>('_mm512_mask_store_epi64');
  late final __mm512_mask_store_epi64 = __mm512_mask_store_epi64Ptr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m512i)>();

  void _mm512_storeu_epi8(
    ffi.Pointer<ffi.Void> arg0,
    __m512i arg1,
  ) {
    return __mm512_storeu_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm512_storeu_epi8Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<ffi.Void>, __m512i)>>('_mm512_storeu_epi8');
  late final __mm512_storeu_epi8 = __mm512_storeu_epi8Ptr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, __m512i)>();

  void _mm512_mask_storeu_epi8(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_storeu_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_storeu_epi8Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask64,
              __m512i)>>('_mm512_mask_storeu_epi8');
  late final __mm512_mask_storeu_epi8 = __mm512_mask_storeu_epi8Ptr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m512i)>();

  void _mm512_storeu_epi16(
    ffi.Pointer<ffi.Void> arg0,
    __m512i arg1,
  ) {
    return __mm512_storeu_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm512_storeu_epi16Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<ffi.Void>, __m512i)>>('_mm512_storeu_epi16');
  late final __mm512_storeu_epi16 = __mm512_storeu_epi16Ptr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, __m512i)>();

  void _mm512_mask_storeu_epi16(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_storeu_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_storeu_epi16Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask32,
              __m512i)>>('_mm512_mask_storeu_epi16');
  late final __mm512_mask_storeu_epi16 = __mm512_mask_storeu_epi16Ptr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m512i)>();

  void _mm512_storeu_epi32(
    ffi.Pointer<ffi.Void> arg0,
    __m512i arg1,
  ) {
    return __mm512_storeu_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_storeu_epi32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<ffi.Void>, __m512i)>>('_mm512_storeu_epi32');
  late final __mm512_storeu_epi32 = __mm512_storeu_epi32Ptr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, __m512i)>();

  void _mm512_mask_storeu_epi32(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_storeu_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_storeu_epi32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask16,
              __m512i)>>('_mm512_mask_storeu_epi32');
  late final __mm512_mask_storeu_epi32 = __mm512_mask_storeu_epi32Ptr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m512i)>();

  void _mm512_storeu_epi64(
    ffi.Pointer<ffi.Void> arg0,
    __m512i arg1,
  ) {
    return __mm512_storeu_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm512_storeu_epi64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<ffi.Void>, __m512i)>>('_mm512_storeu_epi64');
  late final __mm512_storeu_epi64 = __mm512_storeu_epi64Ptr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, __m512i)>();

  void _mm512_mask_storeu_epi64(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_storeu_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_storeu_epi64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8,
              __m512i)>>('_mm512_mask_storeu_epi64');
  late final __mm512_mask_storeu_epi64 = __mm512_mask_storeu_epi64Ptr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m512i)>();

  __m128i _mm512_extracti32x4_epi32(
    __m512i arg0,
    int arg1,
  ) {
    return __mm512_extracti32x4_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_extracti32x4_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m512i, ffi.Int32)>>(
          '_mm512_extracti32x4_epi32');
  late final __mm512_extracti32x4_epi32 = __mm512_extracti32x4_epi32Ptr
      .asFunction<__m128i Function(__m512i, int)>();

  __m128i _mm512_mask_extracti32x4_epi32(
    __m128i arg0,
    int arg1,
    __m512i arg2,
    int arg3,
  ) {
    return __mm512_mask_extracti32x4_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_extracti32x4_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(__m128i, __mmask8, __m512i,
              ffi.Int32)>>('_mm512_mask_extracti32x4_epi32');
  late final __mm512_mask_extracti32x4_epi32 =
      __mm512_mask_extracti32x4_epi32Ptr
          .asFunction<__m128i Function(__m128i, int, __m512i, int)>();

  __m128i _mm512_maskz_extracti32x4_epi32(
    int arg0,
    __m512i arg1,
    int arg2,
  ) {
    return __mm512_maskz_extracti32x4_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_extracti32x4_epi32Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__mmask8, __m512i, ffi.Int32)>>(
      '_mm512_maskz_extracti32x4_epi32');
  late final __mm512_maskz_extracti32x4_epi32 =
      __mm512_maskz_extracti32x4_epi32Ptr
          .asFunction<__m128i Function(int, __m512i, int)>();

  __m256i _mm512_extracti32x8_epi32(
    __m512i arg0,
    int arg1,
  ) {
    return __mm512_extracti32x8_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_extracti32x8_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m512i, ffi.Int32)>>(
          '_mm512_extracti32x8_epi32');
  late final __mm512_extracti32x8_epi32 = __mm512_extracti32x8_epi32Ptr
      .asFunction<__m256i Function(__m512i, int)>();

  __m256i _mm512_mask_extracti32x8_epi32(
    __m256i arg0,
    int arg1,
    __m512i arg2,
    int arg3,
  ) {
    return __mm512_mask_extracti32x8_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_extracti32x8_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask8, __m512i,
              ffi.Int32)>>('_mm512_mask_extracti32x8_epi32');
  late final __mm512_mask_extracti32x8_epi32 =
      __mm512_mask_extracti32x8_epi32Ptr
          .asFunction<__m256i Function(__m256i, int, __m512i, int)>();

  __m256i _mm512_maskz_extracti32x8_epi32(
    int arg0,
    __m512i arg1,
    int arg2,
  ) {
    return __mm512_maskz_extracti32x8_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_extracti32x8_epi32Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__mmask8, __m512i, ffi.Int32)>>(
      '_mm512_maskz_extracti32x8_epi32');
  late final __mm512_maskz_extracti32x8_epi32 =
      __mm512_maskz_extracti32x8_epi32Ptr
          .asFunction<__m256i Function(int, __m512i, int)>();

  __m128i _mm512_extracti64x2_epi64(
    __m512i arg0,
    int arg1,
  ) {
    return __mm512_extracti64x2_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm512_extracti64x2_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m512i, ffi.Int32)>>(
          '_mm512_extracti64x2_epi64');
  late final __mm512_extracti64x2_epi64 = __mm512_extracti64x2_epi64Ptr
      .asFunction<__m128i Function(__m512i, int)>();

  __m128i _mm512_mask_extracti64x2_epi64(
    __m128i arg0,
    int arg1,
    __m512i arg2,
    int arg3,
  ) {
    return __mm512_mask_extracti64x2_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_extracti64x2_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(__m128i, __mmask8, __m512i,
              ffi.Int32)>>('_mm512_mask_extracti64x2_epi64');
  late final __mm512_mask_extracti64x2_epi64 =
      __mm512_mask_extracti64x2_epi64Ptr
          .asFunction<__m128i Function(__m128i, int, __m512i, int)>();

  __m128i _mm512_maskz_extracti64x2_epi64(
    int arg0,
    __m512i arg1,
    int arg2,
  ) {
    return __mm512_maskz_extracti64x2_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_extracti64x2_epi64Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__mmask8, __m512i, ffi.Int32)>>(
      '_mm512_maskz_extracti64x2_epi64');
  late final __mm512_maskz_extracti64x2_epi64 =
      __mm512_maskz_extracti64x2_epi64Ptr
          .asFunction<__m128i Function(int, __m512i, int)>();

  __m256i _mm512_extracti64x4_epi64(
    __m512i arg0,
    int arg1,
  ) {
    return __mm512_extracti64x4_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm512_extracti64x4_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m512i, ffi.Int32)>>(
          '_mm512_extracti64x4_epi64');
  late final __mm512_extracti64x4_epi64 = __mm512_extracti64x4_epi64Ptr
      .asFunction<__m256i Function(__m512i, int)>();

  __m256i _mm512_mask_extracti64x4_epi64(
    __m256i arg0,
    int arg1,
    __m512i arg2,
    int arg3,
  ) {
    return __mm512_mask_extracti64x4_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_extracti64x4_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask8, __m512i,
              ffi.Int32)>>('_mm512_mask_extracti64x4_epi64');
  late final __mm512_mask_extracti64x4_epi64 =
      __mm512_mask_extracti64x4_epi64Ptr
          .asFunction<__m256i Function(__m256i, int, __m512i, int)>();

  __m256i _mm512_maskz_extracti64x4_epi64(
    int arg0,
    __m512i arg1,
    int arg2,
  ) {
    return __mm512_maskz_extracti64x4_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_extracti64x4_epi64Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__mmask8, __m512i, ffi.Int32)>>(
      '_mm512_maskz_extracti64x4_epi64');
  late final __mm512_maskz_extracti64x4_epi64 =
      __mm512_maskz_extracti64x4_epi64Ptr
          .asFunction<__m256i Function(int, __m512i, int)>();

  __m512i _mm512_inserti32x4(
    __m512i arg0,
    __m128i arg1,
    int arg2,
  ) {
    return __mm512_inserti32x4(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_inserti32x4Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__m512i, __m128i, ffi.Int32)>>(
      '_mm512_inserti32x4');
  late final __mm512_inserti32x4 = __mm512_inserti32x4Ptr
      .asFunction<__m512i Function(__m512i, __m128i, int)>();

  __m512i _mm512_mask_inserti32x4(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m128i arg3,
    int arg4,
  ) {
    return __mm512_mask_inserti32x4(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_inserti32x4Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask16, __m512i, __m128i,
              ffi.Int32)>>('_mm512_mask_inserti32x4');
  late final __mm512_mask_inserti32x4 = __mm512_mask_inserti32x4Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m128i, int)>();

  __m512i _mm512_maskz_inserti32x4(
    int arg0,
    __m512i arg1,
    __m128i arg2,
    int arg3,
  ) {
    return __mm512_maskz_inserti32x4(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_inserti32x4Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__mmask16, __m512i, __m128i,
              ffi.Int32)>>('_mm512_maskz_inserti32x4');
  late final __mm512_maskz_inserti32x4 = __mm512_maskz_inserti32x4Ptr
      .asFunction<__m512i Function(int, __m512i, __m128i, int)>();

  __m512i _mm512_inserti32x8(
    __m512i arg0,
    __m256i arg1,
    int arg2,
  ) {
    return __mm512_inserti32x8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_inserti32x8Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__m512i, __m256i, ffi.Int32)>>(
      '_mm512_inserti32x8');
  late final __mm512_inserti32x8 = __mm512_inserti32x8Ptr
      .asFunction<__m512i Function(__m512i, __m256i, int)>();

  __m512i _mm512_mask_inserti32x8(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m256i arg3,
    int arg4,
  ) {
    return __mm512_mask_inserti32x8(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_inserti32x8Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask16, __m512i, __m256i,
              ffi.Int32)>>('_mm512_mask_inserti32x8');
  late final __mm512_mask_inserti32x8 = __mm512_mask_inserti32x8Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m256i, int)>();

  __m512i _mm512_maskz_inserti32x8(
    int arg0,
    __m512i arg1,
    __m256i arg2,
    int arg3,
  ) {
    return __mm512_maskz_inserti32x8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_inserti32x8Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__mmask16, __m512i, __m256i,
              ffi.Int32)>>('_mm512_maskz_inserti32x8');
  late final __mm512_maskz_inserti32x8 = __mm512_maskz_inserti32x8Ptr
      .asFunction<__m512i Function(int, __m512i, __m256i, int)>();

  __m512i _mm512_inserti64x2(
    __m512i arg0,
    __m128i arg1,
    int arg2,
  ) {
    return __mm512_inserti64x2(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_inserti64x2Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__m512i, __m128i, ffi.Int32)>>(
      '_mm512_inserti64x2');
  late final __mm512_inserti64x2 = __mm512_inserti64x2Ptr
      .asFunction<__m512i Function(__m512i, __m128i, int)>();

  __m512i _mm512_mask_inserti64x2(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m128i arg3,
    int arg4,
  ) {
    return __mm512_mask_inserti64x2(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_inserti64x2Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask8, __m512i, __m128i,
              ffi.Int32)>>('_mm512_mask_inserti64x2');
  late final __mm512_mask_inserti64x2 = __mm512_mask_inserti64x2Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m128i, int)>();

  __m512i _mm512_maskz_inserti64x2(
    int arg0,
    __m512i arg1,
    __m128i arg2,
    int arg3,
  ) {
    return __mm512_maskz_inserti64x2(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_inserti64x2Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__mmask8, __m512i, __m128i,
              ffi.Int32)>>('_mm512_maskz_inserti64x2');
  late final __mm512_maskz_inserti64x2 = __mm512_maskz_inserti64x2Ptr
      .asFunction<__m512i Function(int, __m512i, __m128i, int)>();

  __m512i _mm512_inserti64x4(
    __m512i arg0,
    __m256i arg1,
    int arg2,
  ) {
    return __mm512_inserti64x4(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_inserti64x4Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__m512i, __m256i, ffi.Int32)>>(
      '_mm512_inserti64x4');
  late final __mm512_inserti64x4 = __mm512_inserti64x4Ptr
      .asFunction<__m512i Function(__m512i, __m256i, int)>();

  __m512i _mm512_mask_inserti64x4(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m256i arg3,
    int arg4,
  ) {
    return __mm512_mask_inserti64x4(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_inserti64x4Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask8, __m512i, __m256i,
              ffi.Int32)>>('_mm512_mask_inserti64x4');
  late final __mm512_mask_inserti64x4 = __mm512_mask_inserti64x4Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m256i, int)>();

  __m512i _mm512_maskz_inserti64x4(
    int arg0,
    __m512i arg1,
    __m256i arg2,
    int arg3,
  ) {
    return __mm512_maskz_inserti64x4(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_inserti64x4Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__mmask8, __m512i, __m256i,
              ffi.Int32)>>('_mm512_maskz_inserti64x4');
  late final __mm512_maskz_inserti64x4 = __mm512_maskz_inserti64x4Ptr
      .asFunction<__m512i Function(int, __m512i, __m256i, int)>();

  __m512i _mm512_shuffle_epi8(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_shuffle_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm512_shuffle_epi8Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_shuffle_epi8');
  late final __mm512_shuffle_epi8 =
      __mm512_shuffle_epi8Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_shuffle_epi8(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_shuffle_epi8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_shuffle_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask64, __m512i,
              __m512i)>>('_mm512_mask_shuffle_epi8');
  late final __mm512_mask_shuffle_epi8 = __mm512_mask_shuffle_epi8Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_shuffle_epi8(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_shuffle_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_shuffle_epi8Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask64, __m512i, __m512i)>>(
      '_mm512_maskz_shuffle_epi8');
  late final __mm512_maskz_shuffle_epi8 = __mm512_maskz_shuffle_epi8Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_shuffle_epi32(
    __m512i arg0,
    int arg1,
  ) {
    return __mm512_shuffle_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_shuffle_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, ffi.Int32)>>(
          '_mm512_shuffle_epi32');
  late final __mm512_shuffle_epi32 =
      __mm512_shuffle_epi32Ptr.asFunction<__m512i Function(__m512i, int)>();

  __m512i _mm512_mask_shuffle_epi32(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    int arg3,
  ) {
    return __mm512_mask_shuffle_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_shuffle_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask16, __m512i,
              ffi.Int32)>>('_mm512_mask_shuffle_epi32');
  late final __mm512_mask_shuffle_epi32 = __mm512_mask_shuffle_epi32Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, int)>();

  __m512i _mm512_maskz_shuffle_epi32(
    int arg0,
    __m512i arg1,
    int arg2,
  ) {
    return __mm512_maskz_shuffle_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_shuffle_epi32Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask16, __m512i, ffi.Int32)>>(
      '_mm512_maskz_shuffle_epi32');
  late final __mm512_maskz_shuffle_epi32 = __mm512_maskz_shuffle_epi32Ptr
      .asFunction<__m512i Function(int, __m512i, int)>();

  __m512i _mm512_shuffle_i32x4(
    __m512i arg0,
    __m512i arg1,
    int arg2,
  ) {
    return __mm512_shuffle_i32x4(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_shuffle_i32x4Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__m512i, __m512i, ffi.Int32)>>(
      '_mm512_shuffle_i32x4');
  late final __mm512_shuffle_i32x4 = __mm512_shuffle_i32x4Ptr
      .asFunction<__m512i Function(__m512i, __m512i, int)>();

  __m512i _mm512_mask_shuffle_i32x4(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
    int arg4,
  ) {
    return __mm512_mask_shuffle_i32x4(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_shuffle_i32x4Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask16, __m512i, __m512i,
              ffi.Int32)>>('_mm512_mask_shuffle_i32x4');
  late final __mm512_mask_shuffle_i32x4 = __mm512_mask_shuffle_i32x4Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i, int)>();

  __m512i _mm512_maskz_shuffle_i32x4(
    int arg0,
    __m512i arg1,
    __m512i arg2,
    int arg3,
  ) {
    return __mm512_maskz_shuffle_i32x4(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_shuffle_i32x4Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__mmask16, __m512i, __m512i,
              ffi.Int32)>>('_mm512_maskz_shuffle_i32x4');
  late final __mm512_maskz_shuffle_i32x4 = __mm512_maskz_shuffle_i32x4Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i, int)>();

  __m512i _mm512_shuffle_i64x2(
    __m512i arg0,
    __m512i arg1,
    int arg2,
  ) {
    return __mm512_shuffle_i64x2(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_shuffle_i64x2Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__m512i, __m512i, ffi.Int32)>>(
      '_mm512_shuffle_i64x2');
  late final __mm512_shuffle_i64x2 = __mm512_shuffle_i64x2Ptr
      .asFunction<__m512i Function(__m512i, __m512i, int)>();

  __m512i _mm512_mask_shuffle_i64x2(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
    int arg4,
  ) {
    return __mm512_mask_shuffle_i64x2(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_shuffle_i64x2Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask8, __m512i, __m512i,
              ffi.Int32)>>('_mm512_mask_shuffle_i64x2');
  late final __mm512_mask_shuffle_i64x2 = __mm512_mask_shuffle_i64x2Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i, int)>();

  __m512i _mm512_maskz_shuffle_i64x2(
    int arg0,
    __m512i arg1,
    __m512i arg2,
    int arg3,
  ) {
    return __mm512_maskz_shuffle_i64x2(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_shuffle_i64x2Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__mmask8, __m512i, __m512i,
              ffi.Int32)>>('_mm512_maskz_shuffle_i64x2');
  late final __mm512_maskz_shuffle_i64x2 = __mm512_maskz_shuffle_i64x2Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i, int)>();

  __m512i _mm512_shufflehi_epi16(
    __m512i arg0,
    int arg1,
  ) {
    return __mm512_shufflehi_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm512_shufflehi_epi16Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, ffi.Int32)>>(
          '_mm512_shufflehi_epi16');
  late final __mm512_shufflehi_epi16 =
      __mm512_shufflehi_epi16Ptr.asFunction<__m512i Function(__m512i, int)>();

  __m512i _mm512_mask_shufflehi_epi16(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    int arg3,
  ) {
    return __mm512_mask_shufflehi_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_shufflehi_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask32, __m512i,
              ffi.Int32)>>('_mm512_mask_shufflehi_epi16');
  late final __mm512_mask_shufflehi_epi16 = __mm512_mask_shufflehi_epi16Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, int)>();

  __m512i _mm512_maskz_shufflehi_epi16(
    int arg0,
    __m512i arg1,
    int arg2,
  ) {
    return __mm512_maskz_shufflehi_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_shufflehi_epi16Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask32, __m512i, ffi.Int32)>>(
      '_mm512_maskz_shufflehi_epi16');
  late final __mm512_maskz_shufflehi_epi16 = __mm512_maskz_shufflehi_epi16Ptr
      .asFunction<__m512i Function(int, __m512i, int)>();

  __m512i _mm512_shufflelo_epi16(
    __m512i arg0,
    int arg1,
  ) {
    return __mm512_shufflelo_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm512_shufflelo_epi16Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, ffi.Int32)>>(
          '_mm512_shufflelo_epi16');
  late final __mm512_shufflelo_epi16 =
      __mm512_shufflelo_epi16Ptr.asFunction<__m512i Function(__m512i, int)>();

  __m512i _mm512_mask_shufflelo_epi16(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    int arg3,
  ) {
    return __mm512_mask_shufflelo_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_shufflelo_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask32, __m512i,
              ffi.Int32)>>('_mm512_mask_shufflelo_epi16');
  late final __mm512_mask_shufflelo_epi16 = __mm512_mask_shufflelo_epi16Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, int)>();

  __m512i _mm512_maskz_shufflelo_epi16(
    int arg0,
    __m512i arg1,
    int arg2,
  ) {
    return __mm512_maskz_shufflelo_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_shufflelo_epi16Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask32, __m512i, ffi.Int32)>>(
      '_mm512_maskz_shufflelo_epi16');
  late final __mm512_maskz_shufflelo_epi16 = __mm512_maskz_shufflelo_epi16Ptr
      .asFunction<__m512i Function(int, __m512i, int)>();

  __m512 _mm512_mask_mov_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
  ) {
    return __mm512_mask_mov_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_mov_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __mmask16, __m512)>>(
          '_mm512_mask_mov_ps');
  late final __mm512_mask_mov_ps =
      __mm512_mask_mov_psPtr.asFunction<__m512 Function(__m512, int, __m512)>();

  __m512 _mm512_maskz_mov_ps(
    int arg0,
    __m512 arg1,
  ) {
    return __mm512_maskz_mov_ps(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_mov_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__mmask16, __m512)>>(
          '_mm512_maskz_mov_ps');
  late final __mm512_maskz_mov_ps =
      __mm512_maskz_mov_psPtr.asFunction<__m512 Function(int, __m512)>();

  _m512d _mm512_mask_mov_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
  ) {
    return __mm512_mask_mov_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_mov_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, __mmask8, _m512d)>>(
          '_mm512_mask_mov_pd');
  late final __mm512_mask_mov_pd =
      __mm512_mask_mov_pdPtr.asFunction<_m512d Function(_m512d, int, _m512d)>();

  _m512d _mm512_maskz_mov_pd(
    int arg0,
    _m512d arg1,
  ) {
    return __mm512_maskz_mov_pd(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_mov_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(__mmask8, _m512d)>>(
          '_mm512_maskz_mov_pd');
  late final __mm512_maskz_mov_pd =
      __mm512_maskz_mov_pdPtr.asFunction<_m512d Function(int, _m512d)>();

  __m512i _mm512_mask_mov_epi8(
    __m512i arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_mov_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_mov_epi8Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__m512i, __mmask64, __m512i)>>(
      '_mm512_mask_mov_epi8');
  late final __mm512_mask_mov_epi8 = __mm512_mask_mov_epi8Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i)>();

  __m512i _mm512_maskz_mov_epi8(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_maskz_mov_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_mov_epi8Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask64, __m512i)>>(
          '_mm512_maskz_mov_epi8');
  late final __mm512_maskz_mov_epi8 =
      __mm512_maskz_mov_epi8Ptr.asFunction<__m512i Function(int, __m512i)>();

  __m512i _mm512_mask_mov_epi16(
    __m512i arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_mov_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_mov_epi16Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__m512i, __mmask32, __m512i)>>(
      '_mm512_mask_mov_epi16');
  late final __mm512_mask_mov_epi16 = __mm512_mask_mov_epi16Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i)>();

  __m512i _mm512_maskz_mov_epi16(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_maskz_mov_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_mov_epi16Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask32, __m512i)>>(
          '_mm512_maskz_mov_epi16');
  late final __mm512_maskz_mov_epi16 =
      __mm512_maskz_mov_epi16Ptr.asFunction<__m512i Function(int, __m512i)>();

  __m512i _mm512_mask_mov_epi32(
    __m512i arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_mov_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_mov_epi32Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__m512i, __mmask16, __m512i)>>(
      '_mm512_mask_mov_epi32');
  late final __mm512_mask_mov_epi32 = __mm512_mask_mov_epi32Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i)>();

  __m512i _mm512_maskz_mov_epi32(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_maskz_mov_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_mov_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask16, __m512i)>>(
          '_mm512_maskz_mov_epi32');
  late final __mm512_maskz_mov_epi32 =
      __mm512_maskz_mov_epi32Ptr.asFunction<__m512i Function(int, __m512i)>();

  __m512i _mm512_mask_mov_epi64(
    __m512i arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_mov_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_mov_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __mmask8, __m512i)>>(
          '_mm512_mask_mov_epi64');
  late final __mm512_mask_mov_epi64 = __mm512_mask_mov_epi64Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i)>();

  __m512i _mm512_maskz_mov_epi64(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_maskz_mov_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_mov_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask8, __m512i)>>(
          '_mm512_maskz_mov_epi64');
  late final __mm512_maskz_mov_epi64 =
      __mm512_maskz_mov_epi64Ptr.asFunction<__m512i Function(int, __m512i)>();

  _m512d _mm512_movedup_pd(
    _m512d arg0,
  ) {
    return __mm512_movedup_pd(
      arg0,
    );
  }

  late final __mm512_movedup_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d)>>('_mm512_movedup_pd');
  late final __mm512_movedup_pd =
      __mm512_movedup_pdPtr.asFunction<_m512d Function(_m512d)>();

  _m512d _mm512_mask_movedup_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
  ) {
    return __mm512_mask_movedup_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_movedup_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, __mmask8, _m512d)>>(
          '_mm512_mask_movedup_pd');
  late final __mm512_mask_movedup_pd = __mm512_mask_movedup_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d)>();

  _m512d _mm512_maskz_movedup_pd(
    int arg0,
    _m512d arg1,
  ) {
    return __mm512_maskz_movedup_pd(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_movedup_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(__mmask8, _m512d)>>(
          '_mm512_maskz_movedup_pd');
  late final __mm512_maskz_movedup_pd =
      __mm512_maskz_movedup_pdPtr.asFunction<_m512d Function(int, _m512d)>();

  __m512 _mm512_movehdup_ps(
    __m512 arg0,
  ) {
    return __mm512_movehdup_ps(
      arg0,
    );
  }

  late final __mm512_movehdup_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512)>>(
          '_mm512_movehdup_ps');
  late final __mm512_movehdup_ps =
      __mm512_movehdup_psPtr.asFunction<__m512 Function(__m512)>();

  __m512 _mm512_mask_movehdup_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
  ) {
    return __mm512_mask_movehdup_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_movehdup_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __mmask16, __m512)>>(
          '_mm512_mask_movehdup_ps');
  late final __mm512_mask_movehdup_ps = __mm512_mask_movehdup_psPtr
      .asFunction<__m512 Function(__m512, int, __m512)>();

  __m512 _mm512_maskz_movehdup_ps(
    int arg0,
    __m512 arg1,
  ) {
    return __mm512_maskz_movehdup_ps(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_movehdup_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__mmask16, __m512)>>(
          '_mm512_maskz_movehdup_ps');
  late final __mm512_maskz_movehdup_ps =
      __mm512_maskz_movehdup_psPtr.asFunction<__m512 Function(int, __m512)>();

  __m512 _mm512_moveldup_ps(
    __m512 arg0,
  ) {
    return __mm512_moveldup_ps(
      arg0,
    );
  }

  late final __mm512_moveldup_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512)>>(
          '_mm512_moveldup_ps');
  late final __mm512_moveldup_ps =
      __mm512_moveldup_psPtr.asFunction<__m512 Function(__m512)>();

  __m512 _mm512_mask_moveldup_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
  ) {
    return __mm512_mask_moveldup_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_moveldup_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __mmask16, __m512)>>(
          '_mm512_mask_moveldup_ps');
  late final __mm512_mask_moveldup_ps = __mm512_mask_moveldup_psPtr
      .asFunction<__m512 Function(__m512, int, __m512)>();

  __m512 _mm512_maskz_moveldup_ps(
    int arg0,
    __m512 arg1,
  ) {
    return __mm512_maskz_moveldup_ps(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_moveldup_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__mmask16, __m512)>>(
          '_mm512_maskz_moveldup_ps');
  late final __mm512_maskz_moveldup_ps =
      __mm512_maskz_moveldup_psPtr.asFunction<__m512 Function(int, __m512)>();

  __m512i _mm512_movm_epi8(
    int arg0,
  ) {
    return __mm512_movm_epi8(
      arg0,
    );
  }

  late final __mm512_movm_epi8Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask64)>>(
          '_mm512_movm_epi8');
  late final __mm512_movm_epi8 =
      __mm512_movm_epi8Ptr.asFunction<__m512i Function(int)>();

  __m512i _mm512_movm_epi16(
    int arg0,
  ) {
    return __mm512_movm_epi16(
      arg0,
    );
  }

  late final __mm512_movm_epi16Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask32)>>(
          '_mm512_movm_epi16');
  late final __mm512_movm_epi16 =
      __mm512_movm_epi16Ptr.asFunction<__m512i Function(int)>();

  __m512i _mm512_movm_epi32(
    int arg0,
  ) {
    return __mm512_movm_epi32(
      arg0,
    );
  }

  late final __mm512_movm_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask16)>>(
          '_mm512_movm_epi32');
  late final __mm512_movm_epi32 =
      __mm512_movm_epi32Ptr.asFunction<__m512i Function(int)>();

  __m512i _mm512_movm_epi64(
    int arg0,
  ) {
    return __mm512_movm_epi64(
      arg0,
    );
  }

  late final __mm512_movm_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask8)>>(
          '_mm512_movm_epi64');
  late final __mm512_movm_epi64 =
      __mm512_movm_epi64Ptr.asFunction<__m512i Function(int)>();

  int _mm512_movepi8_mask(
    __m512i arg0,
  ) {
    return __mm512_movepi8_mask(
      arg0,
    );
  }

  late final __mm512_movepi8_maskPtr =
      _lookup<ffi.NativeFunction<__mmask64 Function(__m512i)>>(
          '_mm512_movepi8_mask');
  late final __mm512_movepi8_mask =
      __mm512_movepi8_maskPtr.asFunction<int Function(__m512i)>();

  int _mm512_movepi16_mask(
    __m512i arg0,
  ) {
    return __mm512_movepi16_mask(
      arg0,
    );
  }

  late final __mm512_movepi16_maskPtr =
      _lookup<ffi.NativeFunction<__mmask32 Function(__m512i)>>(
          '_mm512_movepi16_mask');
  late final __mm512_movepi16_mask =
      __mm512_movepi16_maskPtr.asFunction<int Function(__m512i)>();

  int _mm512_movepi32_mask(
    __m512i arg0,
  ) {
    return __mm512_movepi32_mask(
      arg0,
    );
  }

  late final __mm512_movepi32_maskPtr =
      _lookup<ffi.NativeFunction<__mmask16 Function(__m512i)>>(
          '_mm512_movepi32_mask');
  late final __mm512_movepi32_mask =
      __mm512_movepi32_maskPtr.asFunction<int Function(__m512i)>();

  int _mm512_movepi64_mask(
    __m512i arg0,
  ) {
    return __mm512_movepi64_mask(
      arg0,
    );
  }

  late final __mm512_movepi64_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m512i)>>(
          '_mm512_movepi64_mask');
  late final __mm512_movepi64_mask =
      __mm512_movepi64_maskPtr.asFunction<int Function(__m512i)>();

  __m512i _mm512_alignr_epi8(
    __m512i arg0,
    __m512i arg1,
    int arg2,
  ) {
    return __mm512_alignr_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_alignr_epi8Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__m512i, __m512i, ffi.Int32)>>(
      '_mm512_alignr_epi8');
  late final __mm512_alignr_epi8 = __mm512_alignr_epi8Ptr
      .asFunction<__m512i Function(__m512i, __m512i, int)>();

  __m512i _mm512_mask_alignr_epi8(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
    int arg4,
  ) {
    return __mm512_mask_alignr_epi8(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_alignr_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask64, __m512i, __m512i,
              ffi.Int32)>>('_mm512_mask_alignr_epi8');
  late final __mm512_mask_alignr_epi8 = __mm512_mask_alignr_epi8Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i, int)>();

  __m512i _mm512_maskz_alignr_epi8(
    int arg0,
    __m512i arg1,
    __m512i arg2,
    int arg3,
  ) {
    return __mm512_maskz_alignr_epi8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_alignr_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__mmask64, __m512i, __m512i,
              ffi.Int32)>>('_mm512_maskz_alignr_epi8');
  late final __mm512_maskz_alignr_epi8 = __mm512_maskz_alignr_epi8Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i, int)>();

  __m512i _mm512_alignr_epi32(
    __m512i arg0,
    __m512i arg1,
    int arg2,
  ) {
    return __mm512_alignr_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_alignr_epi32Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__m512i, __m512i, ffi.Int32)>>(
      '_mm512_alignr_epi32');
  late final __mm512_alignr_epi32 = __mm512_alignr_epi32Ptr
      .asFunction<__m512i Function(__m512i, __m512i, int)>();

  __m512i _mm512_mask_alignr_epi32(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
    int arg4,
  ) {
    return __mm512_mask_alignr_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_alignr_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask16, __m512i, __m512i,
              ffi.Int32)>>('_mm512_mask_alignr_epi32');
  late final __mm512_mask_alignr_epi32 = __mm512_mask_alignr_epi32Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i, int)>();

  __m512i _mm512_maskz_alignr_epi32(
    int arg0,
    __m512i arg1,
    __m512i arg2,
    int arg3,
  ) {
    return __mm512_maskz_alignr_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_alignr_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__mmask16, __m512i, __m512i,
              ffi.Int32)>>('_mm512_maskz_alignr_epi32');
  late final __mm512_maskz_alignr_epi32 = __mm512_maskz_alignr_epi32Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i, int)>();

  __m512i _mm512_alignr_epi64(
    __m512i arg0,
    __m512i arg1,
    int arg2,
  ) {
    return __mm512_alignr_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_alignr_epi64Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__m512i, __m512i, ffi.Int32)>>(
      '_mm512_alignr_epi64');
  late final __mm512_alignr_epi64 = __mm512_alignr_epi64Ptr
      .asFunction<__m512i Function(__m512i, __m512i, int)>();

  __m512i _mm512_mask_alignr_epi64(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
    int arg4,
  ) {
    return __mm512_mask_alignr_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_alignr_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask8, __m512i, __m512i,
              ffi.Int32)>>('_mm512_mask_alignr_epi64');
  late final __mm512_mask_alignr_epi64 = __mm512_mask_alignr_epi64Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i, int)>();

  __m512i _mm512_maskz_alignr_epi64(
    int arg0,
    __m512i arg1,
    __m512i arg2,
    int arg3,
  ) {
    return __mm512_maskz_alignr_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_alignr_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__mmask8, __m512i, __m512i,
              ffi.Int32)>>('_mm512_maskz_alignr_epi64');
  late final __mm512_maskz_alignr_epi64 = __mm512_maskz_alignr_epi64Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i, int)>();

  _m512d _mm512_and_pd(
    _m512d arg0,
    _m512d arg1,
  ) {
    return __mm512_and_pd(
      arg0,
      arg1,
    );
  }

  late final __mm512_and_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, _m512d)>>(
          '_mm512_and_pd');
  late final __mm512_and_pd =
      __mm512_and_pdPtr.asFunction<_m512d Function(_m512d, _m512d)>();

  _m512d _mm512_mask_and_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
    _m512d arg3,
  ) {
    return __mm512_mask_and_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_and_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(
              _m512d, __mmask8, _m512d, _m512d)>>('_mm512_mask_and_pd');
  late final __mm512_mask_and_pd = __mm512_mask_and_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d, _m512d)>();

  _m512d _mm512_maskz_and_pd(
    int arg0,
    _m512d arg1,
    _m512d arg2,
  ) {
    return __mm512_maskz_and_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_and_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(__mmask8, _m512d, _m512d)>>(
          '_mm512_maskz_and_pd');
  late final __mm512_maskz_and_pd = __mm512_maskz_and_pdPtr
      .asFunction<_m512d Function(int, _m512d, _m512d)>();

  __m512 _mm512_and_ps(
    __m512 arg0,
    __m512 arg1,
  ) {
    return __mm512_and_ps(
      arg0,
      arg1,
    );
  }

  late final __mm512_and_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __m512)>>(
          '_mm512_and_ps');
  late final __mm512_and_ps =
      __mm512_and_psPtr.asFunction<__m512 Function(__m512, __m512)>();

  __m512 _mm512_mask_and_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
    __m512 arg3,
  ) {
    return __mm512_mask_and_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_and_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(
              __m512, __mmask16, __m512, __m512)>>('_mm512_mask_and_ps');
  late final __mm512_mask_and_ps = __mm512_mask_and_psPtr
      .asFunction<__m512 Function(__m512, int, __m512, __m512)>();

  __m512 _mm512_maskz_and_ps(
    int arg0,
    __m512 arg1,
    __m512 arg2,
  ) {
    return __mm512_maskz_and_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_and_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__mmask16, __m512, __m512)>>(
          '_mm512_maskz_and_ps');
  late final __mm512_maskz_and_ps = __mm512_maskz_and_psPtr
      .asFunction<__m512 Function(int, __m512, __m512)>();

  __m512i _mm512_and_epi32(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_and_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_and_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_and_epi32');
  late final __mm512_and_epi32 =
      __mm512_and_epi32Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_and_epi32(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_and_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_and_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask16, __m512i, __m512i)>>('_mm512_mask_and_epi32');
  late final __mm512_mask_and_epi32 = __mm512_mask_and_epi32Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_and_epi32(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_and_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_and_epi32Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask16, __m512i, __m512i)>>(
      '_mm512_maskz_and_epi32');
  late final __mm512_maskz_and_epi32 = __mm512_maskz_and_epi32Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_and_epi64(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_and_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm512_and_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_and_epi64');
  late final __mm512_and_epi64 =
      __mm512_and_epi64Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_and_epi64(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_and_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_and_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask8, __m512i, __m512i)>>('_mm512_mask_and_epi64');
  late final __mm512_mask_and_epi64 = __mm512_mask_and_epi64Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_and_epi64(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_and_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_and_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask8, __m512i, __m512i)>>(
          '_mm512_maskz_and_epi64');
  late final __mm512_maskz_and_epi64 = __mm512_maskz_and_epi64Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  _m512d _mm512_andnot_pd(
    _m512d arg0,
    _m512d arg1,
  ) {
    return __mm512_andnot_pd(
      arg0,
      arg1,
    );
  }

  late final __mm512_andnot_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, _m512d)>>(
          '_mm512_andnot_pd');
  late final __mm512_andnot_pd =
      __mm512_andnot_pdPtr.asFunction<_m512d Function(_m512d, _m512d)>();

  _m512d _mm512_mask_andnot_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
    _m512d arg3,
  ) {
    return __mm512_mask_andnot_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_andnot_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(
              _m512d, __mmask8, _m512d, _m512d)>>('_mm512_mask_andnot_pd');
  late final __mm512_mask_andnot_pd = __mm512_mask_andnot_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d, _m512d)>();

  _m512d _mm512_maskz_andnot_pd(
    int arg0,
    _m512d arg1,
    _m512d arg2,
  ) {
    return __mm512_maskz_andnot_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_andnot_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(__mmask8, _m512d, _m512d)>>(
          '_mm512_maskz_andnot_pd');
  late final __mm512_maskz_andnot_pd = __mm512_maskz_andnot_pdPtr
      .asFunction<_m512d Function(int, _m512d, _m512d)>();

  __m512 _mm512_andnot_ps(
    __m512 arg0,
    __m512 arg1,
  ) {
    return __mm512_andnot_ps(
      arg0,
      arg1,
    );
  }

  late final __mm512_andnot_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __m512)>>(
          '_mm512_andnot_ps');
  late final __mm512_andnot_ps =
      __mm512_andnot_psPtr.asFunction<__m512 Function(__m512, __m512)>();

  __m512 _mm512_mask_andnot_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
    __m512 arg3,
  ) {
    return __mm512_mask_andnot_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_andnot_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(
              __m512, __mmask16, __m512, __m512)>>('_mm512_mask_andnot_ps');
  late final __mm512_mask_andnot_ps = __mm512_mask_andnot_psPtr
      .asFunction<__m512 Function(__m512, int, __m512, __m512)>();

  __m512 _mm512_maskz_andnot_ps(
    int arg0,
    __m512 arg1,
    __m512 arg2,
  ) {
    return __mm512_maskz_andnot_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_andnot_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__mmask16, __m512, __m512)>>(
          '_mm512_maskz_andnot_ps');
  late final __mm512_maskz_andnot_ps = __mm512_maskz_andnot_psPtr
      .asFunction<__m512 Function(int, __m512, __m512)>();

  __m512i _mm512_andnot_epi32(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_andnot_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_andnot_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_andnot_epi32');
  late final __mm512_andnot_epi32 =
      __mm512_andnot_epi32Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_andnot_epi32(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_andnot_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_andnot_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask16, __m512i,
              __m512i)>>('_mm512_mask_andnot_epi32');
  late final __mm512_mask_andnot_epi32 = __mm512_mask_andnot_epi32Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_andnot_epi32(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_andnot_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_andnot_epi32Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask16, __m512i, __m512i)>>(
      '_mm512_maskz_andnot_epi32');
  late final __mm512_maskz_andnot_epi32 = __mm512_maskz_andnot_epi32Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_andnot_epi64(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_andnot_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm512_andnot_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_andnot_epi64');
  late final __mm512_andnot_epi64 =
      __mm512_andnot_epi64Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_andnot_epi64(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_andnot_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_andnot_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask8, __m512i,
              __m512i)>>('_mm512_mask_andnot_epi64');
  late final __mm512_mask_andnot_epi64 = __mm512_mask_andnot_epi64Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_andnot_epi64(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_andnot_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_andnot_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask8, __m512i, __m512i)>>(
          '_mm512_maskz_andnot_epi64');
  late final __mm512_maskz_andnot_epi64 = __mm512_maskz_andnot_epi64Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  _m512d _mm512_or_pd(
    _m512d arg0,
    _m512d arg1,
  ) {
    return __mm512_or_pd(
      arg0,
      arg1,
    );
  }

  late final __mm512_or_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, _m512d)>>(
          '_mm512_or_pd');
  late final __mm512_or_pd =
      __mm512_or_pdPtr.asFunction<_m512d Function(_m512d, _m512d)>();

  _m512d _mm512_mask_or_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
    _m512d arg3,
  ) {
    return __mm512_mask_or_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_or_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(
              _m512d, __mmask8, _m512d, _m512d)>>('_mm512_mask_or_pd');
  late final __mm512_mask_or_pd = __mm512_mask_or_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d, _m512d)>();

  _m512d _mm512_maskz_or_pd(
    int arg0,
    _m512d arg1,
    _m512d arg2,
  ) {
    return __mm512_maskz_or_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_or_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(__mmask8, _m512d, _m512d)>>(
          '_mm512_maskz_or_pd');
  late final __mm512_maskz_or_pd =
      __mm512_maskz_or_pdPtr.asFunction<_m512d Function(int, _m512d, _m512d)>();

  __m512 _mm512_or_ps(
    __m512 arg0,
    __m512 arg1,
  ) {
    return __mm512_or_ps(
      arg0,
      arg1,
    );
  }

  late final __mm512_or_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __m512)>>(
          '_mm512_or_ps');
  late final __mm512_or_ps =
      __mm512_or_psPtr.asFunction<__m512 Function(__m512, __m512)>();

  __m512 _mm512_mask_or_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
    __m512 arg3,
  ) {
    return __mm512_mask_or_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_or_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(
              __m512, __mmask16, __m512, __m512)>>('_mm512_mask_or_ps');
  late final __mm512_mask_or_ps = __mm512_mask_or_psPtr
      .asFunction<__m512 Function(__m512, int, __m512, __m512)>();

  __m512 _mm512_maskz_or_ps(
    int arg0,
    __m512 arg1,
    __m512 arg2,
  ) {
    return __mm512_maskz_or_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_or_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__mmask16, __m512, __m512)>>(
          '_mm512_maskz_or_ps');
  late final __mm512_maskz_or_ps =
      __mm512_maskz_or_psPtr.asFunction<__m512 Function(int, __m512, __m512)>();

  __m512i _mm512_or_epi32(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_or_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_or_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_or_epi32');
  late final __mm512_or_epi32 =
      __mm512_or_epi32Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_or_epi32(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_or_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_or_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask16, __m512i, __m512i)>>('_mm512_mask_or_epi32');
  late final __mm512_mask_or_epi32 = __mm512_mask_or_epi32Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_or_epi32(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_or_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_or_epi32Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask16, __m512i, __m512i)>>(
      '_mm512_maskz_or_epi32');
  late final __mm512_maskz_or_epi32 = __mm512_maskz_or_epi32Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_or_epi64(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_or_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm512_or_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_or_epi64');
  late final __mm512_or_epi64 =
      __mm512_or_epi64Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_or_epi64(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_or_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_or_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask8, __m512i, __m512i)>>('_mm512_mask_or_epi64');
  late final __mm512_mask_or_epi64 = __mm512_mask_or_epi64Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_or_epi64(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_or_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_or_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask8, __m512i, __m512i)>>(
          '_mm512_maskz_or_epi64');
  late final __mm512_maskz_or_epi64 = __mm512_maskz_or_epi64Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  _m512d _mm512_xor_pd(
    _m512d arg0,
    _m512d arg1,
  ) {
    return __mm512_xor_pd(
      arg0,
      arg1,
    );
  }

  late final __mm512_xor_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, _m512d)>>(
          '_mm512_xor_pd');
  late final __mm512_xor_pd =
      __mm512_xor_pdPtr.asFunction<_m512d Function(_m512d, _m512d)>();

  _m512d _mm512_mask_xor_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
    _m512d arg3,
  ) {
    return __mm512_mask_xor_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_xor_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(
              _m512d, __mmask8, _m512d, _m512d)>>('_mm512_mask_xor_pd');
  late final __mm512_mask_xor_pd = __mm512_mask_xor_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d, _m512d)>();

  _m512d _mm512_maskz_xor_pd(
    int arg0,
    _m512d arg1,
    _m512d arg2,
  ) {
    return __mm512_maskz_xor_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_xor_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(__mmask8, _m512d, _m512d)>>(
          '_mm512_maskz_xor_pd');
  late final __mm512_maskz_xor_pd = __mm512_maskz_xor_pdPtr
      .asFunction<_m512d Function(int, _m512d, _m512d)>();

  __m512 _mm512_xor_ps(
    __m512 arg0,
    __m512 arg1,
  ) {
    return __mm512_xor_ps(
      arg0,
      arg1,
    );
  }

  late final __mm512_xor_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __m512)>>(
          '_mm512_xor_ps');
  late final __mm512_xor_ps =
      __mm512_xor_psPtr.asFunction<__m512 Function(__m512, __m512)>();

  __m512 _mm512_mask_xor_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
    __m512 arg3,
  ) {
    return __mm512_mask_xor_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_xor_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(
              __m512, __mmask16, __m512, __m512)>>('_mm512_mask_xor_ps');
  late final __mm512_mask_xor_ps = __mm512_mask_xor_psPtr
      .asFunction<__m512 Function(__m512, int, __m512, __m512)>();

  __m512 _mm512_maskz_xor_ps(
    int arg0,
    __m512 arg1,
    __m512 arg2,
  ) {
    return __mm512_maskz_xor_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_xor_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__mmask16, __m512, __m512)>>(
          '_mm512_maskz_xor_ps');
  late final __mm512_maskz_xor_ps = __mm512_maskz_xor_psPtr
      .asFunction<__m512 Function(int, __m512, __m512)>();

  __m512i _mm512_xor_epi32(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_xor_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_xor_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_xor_epi32');
  late final __mm512_xor_epi32 =
      __mm512_xor_epi32Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_xor_epi32(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_xor_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_xor_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask16, __m512i, __m512i)>>('_mm512_mask_xor_epi32');
  late final __mm512_mask_xor_epi32 = __mm512_mask_xor_epi32Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_xor_epi32(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_xor_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_xor_epi32Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask16, __m512i, __m512i)>>(
      '_mm512_maskz_xor_epi32');
  late final __mm512_maskz_xor_epi32 = __mm512_maskz_xor_epi32Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_xor_epi64(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_xor_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm512_xor_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_xor_epi64');
  late final __mm512_xor_epi64 =
      __mm512_xor_epi64Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_xor_epi64(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_xor_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_xor_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask8, __m512i, __m512i)>>('_mm512_mask_xor_epi64');
  late final __mm512_mask_xor_epi64 = __mm512_mask_xor_epi64Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_xor_epi64(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_xor_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_xor_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask8, __m512i, __m512i)>>(
          '_mm512_maskz_xor_epi64');
  late final __mm512_maskz_xor_epi64 = __mm512_maskz_xor_epi64Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512 _mm512_mask_blend_ps(
    int arg0,
    __m512 arg1,
    __m512 arg2,
  ) {
    return __mm512_mask_blend_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_blend_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__mmask16, __m512, __m512)>>(
          '_mm512_mask_blend_ps');
  late final __mm512_mask_blend_ps = __mm512_mask_blend_psPtr
      .asFunction<__m512 Function(int, __m512, __m512)>();

  _m512d _mm512_mask_blend_pd(
    int arg0,
    _m512d arg1,
    _m512d arg2,
  ) {
    return __mm512_mask_blend_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_blend_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(__mmask8, _m512d, _m512d)>>(
          '_mm512_mask_blend_pd');
  late final __mm512_mask_blend_pd = __mm512_mask_blend_pdPtr
      .asFunction<_m512d Function(int, _m512d, _m512d)>();

  __m512i _mm512_mask_blend_epi8(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_blend_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_blend_epi8Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask64, __m512i, __m512i)>>(
      '_mm512_mask_blend_epi8');
  late final __mm512_mask_blend_epi8 = __mm512_mask_blend_epi8Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_mask_blend_epi16(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_blend_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_blend_epi16Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask32, __m512i, __m512i)>>(
      '_mm512_mask_blend_epi16');
  late final __mm512_mask_blend_epi16 = __mm512_mask_blend_epi16Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_mask_blend_epi32(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_blend_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_blend_epi32Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask16, __m512i, __m512i)>>(
      '_mm512_mask_blend_epi32');
  late final __mm512_mask_blend_epi32 = __mm512_mask_blend_epi32Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_mask_blend_epi64(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_blend_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_blend_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask8, __m512i, __m512i)>>(
          '_mm512_mask_blend_epi64');
  late final __mm512_mask_blend_epi64 = __mm512_mask_blend_epi64Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_sll_epi16(
    __m512i arg0,
    __m128i arg1,
  ) {
    return __mm512_sll_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm512_sll_epi16Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m128i)>>(
          '_mm512_sll_epi16');
  late final __mm512_sll_epi16 =
      __mm512_sll_epi16Ptr.asFunction<__m512i Function(__m512i, __m128i)>();

  __m512i _mm512_sll_epi32(
    __m512i arg0,
    __m128i arg1,
  ) {
    return __mm512_sll_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_sll_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m128i)>>(
          '_mm512_sll_epi32');
  late final __mm512_sll_epi32 =
      __mm512_sll_epi32Ptr.asFunction<__m512i Function(__m512i, __m128i)>();

  __m512i _mm512_sll_epi64(
    __m512i arg0,
    __m128i arg1,
  ) {
    return __mm512_sll_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm512_sll_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m128i)>>(
          '_mm512_sll_epi64');
  late final __mm512_sll_epi64 =
      __mm512_sll_epi64Ptr.asFunction<__m512i Function(__m512i, __m128i)>();

  __m512i _mm512_slli_epi16(
    __m512i arg0,
    int arg1,
  ) {
    return __mm512_slli_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm512_slli_epi16Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, ffi.Uint32)>>(
          '_mm512_slli_epi16');
  late final __mm512_slli_epi16 =
      __mm512_slli_epi16Ptr.asFunction<__m512i Function(__m512i, int)>();

  __m512i _mm512_slli_epi32(
    __m512i arg0,
    int arg1,
  ) {
    return __mm512_slli_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_slli_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, ffi.Uint32)>>(
          '_mm512_slli_epi32');
  late final __mm512_slli_epi32 =
      __mm512_slli_epi32Ptr.asFunction<__m512i Function(__m512i, int)>();

  __m512i _mm512_slli_epi64(
    __m512i arg0,
    int arg1,
  ) {
    return __mm512_slli_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm512_slli_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, ffi.Uint32)>>(
          '_mm512_slli_epi64');
  late final __mm512_slli_epi64 =
      __mm512_slli_epi64Ptr.asFunction<__m512i Function(__m512i, int)>();

  __m512i _mm512_sllv_epi16(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_sllv_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm512_sllv_epi16Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_sllv_epi16');
  late final __mm512_sllv_epi16 =
      __mm512_sllv_epi16Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_sllv_epi32(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_sllv_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_sllv_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_sllv_epi32');
  late final __mm512_sllv_epi32 =
      __mm512_sllv_epi32Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_sllv_epi64(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_sllv_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm512_sllv_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_sllv_epi64');
  late final __mm512_sllv_epi64 =
      __mm512_sllv_epi64Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_sll_epi16(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m128i arg3,
  ) {
    return __mm512_mask_sll_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_sll_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask32, __m512i, __m128i)>>('_mm512_mask_sll_epi16');
  late final __mm512_mask_sll_epi16 = __mm512_mask_sll_epi16Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m128i)>();

  __m512i _mm512_maskz_sll_epi16(
    int arg0,
    __m512i arg1,
    __m128i arg2,
  ) {
    return __mm512_maskz_sll_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_sll_epi16Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask32, __m512i, __m128i)>>(
      '_mm512_maskz_sll_epi16');
  late final __mm512_maskz_sll_epi16 = __mm512_maskz_sll_epi16Ptr
      .asFunction<__m512i Function(int, __m512i, __m128i)>();

  __m512i _mm512_mask_sll_epi32(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m128i arg3,
  ) {
    return __mm512_mask_sll_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_sll_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask16, __m512i, __m128i)>>('_mm512_mask_sll_epi32');
  late final __mm512_mask_sll_epi32 = __mm512_mask_sll_epi32Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m128i)>();

  __m512i _mm512_maskz_sll_epi32(
    int arg0,
    __m512i arg1,
    __m128i arg2,
  ) {
    return __mm512_maskz_sll_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_sll_epi32Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask16, __m512i, __m128i)>>(
      '_mm512_maskz_sll_epi32');
  late final __mm512_maskz_sll_epi32 = __mm512_maskz_sll_epi32Ptr
      .asFunction<__m512i Function(int, __m512i, __m128i)>();

  __m512i _mm512_mask_sll_epi64(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m128i arg3,
  ) {
    return __mm512_mask_sll_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_sll_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask8, __m512i, __m128i)>>('_mm512_mask_sll_epi64');
  late final __mm512_mask_sll_epi64 = __mm512_mask_sll_epi64Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m128i)>();

  __m512i _mm512_maskz_sll_epi64(
    int arg0,
    __m512i arg1,
    __m128i arg2,
  ) {
    return __mm512_maskz_sll_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_sll_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask8, __m512i, __m128i)>>(
          '_mm512_maskz_sll_epi64');
  late final __mm512_maskz_sll_epi64 = __mm512_maskz_sll_epi64Ptr
      .asFunction<__m512i Function(int, __m512i, __m128i)>();

  __m512i _mm512_mask_slli_epi16(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    int arg3,
  ) {
    return __mm512_mask_slli_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_slli_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask32, __m512i,
              ffi.Uint32)>>('_mm512_mask_slli_epi16');
  late final __mm512_mask_slli_epi16 = __mm512_mask_slli_epi16Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, int)>();

  __m512i _mm512_maskz_slli_epi16(
    int arg0,
    __m512i arg1,
    int arg2,
  ) {
    return __mm512_maskz_slli_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_slli_epi16Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask32, __m512i, ffi.Uint32)>>(
      '_mm512_maskz_slli_epi16');
  late final __mm512_maskz_slli_epi16 = __mm512_maskz_slli_epi16Ptr
      .asFunction<__m512i Function(int, __m512i, int)>();

  __m512i _mm512_mask_slli_epi32(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    int arg3,
  ) {
    return __mm512_mask_slli_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_slli_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask16, __m512i,
              ffi.Uint32)>>('_mm512_mask_slli_epi32');
  late final __mm512_mask_slli_epi32 = __mm512_mask_slli_epi32Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, int)>();

  __m512i _mm512_maskz_slli_epi32(
    int arg0,
    __m512i arg1,
    int arg2,
  ) {
    return __mm512_maskz_slli_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_slli_epi32Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask16, __m512i, ffi.Uint32)>>(
      '_mm512_maskz_slli_epi32');
  late final __mm512_maskz_slli_epi32 = __mm512_maskz_slli_epi32Ptr
      .asFunction<__m512i Function(int, __m512i, int)>();

  __m512i _mm512_mask_slli_epi64(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    int arg3,
  ) {
    return __mm512_mask_slli_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_slli_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask8, __m512i,
              ffi.Uint32)>>('_mm512_mask_slli_epi64');
  late final __mm512_mask_slli_epi64 = __mm512_mask_slli_epi64Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, int)>();

  __m512i _mm512_maskz_slli_epi64(
    int arg0,
    __m512i arg1,
    int arg2,
  ) {
    return __mm512_maskz_slli_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_slli_epi64Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask8, __m512i, ffi.Uint32)>>(
      '_mm512_maskz_slli_epi64');
  late final __mm512_maskz_slli_epi64 = __mm512_maskz_slli_epi64Ptr
      .asFunction<__m512i Function(int, __m512i, int)>();

  __m512i _mm512_mask_sllv_epi16(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_sllv_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_sllv_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask32, __m512i, __m512i)>>('_mm512_mask_sllv_epi16');
  late final __mm512_mask_sllv_epi16 = __mm512_mask_sllv_epi16Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_sllv_epi16(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_sllv_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_sllv_epi16Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask32, __m512i, __m512i)>>(
      '_mm512_maskz_sllv_epi16');
  late final __mm512_maskz_sllv_epi16 = __mm512_maskz_sllv_epi16Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_mask_sllv_epi32(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_sllv_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_sllv_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask16, __m512i, __m512i)>>('_mm512_mask_sllv_epi32');
  late final __mm512_mask_sllv_epi32 = __mm512_mask_sllv_epi32Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_sllv_epi32(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_sllv_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_sllv_epi32Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask16, __m512i, __m512i)>>(
      '_mm512_maskz_sllv_epi32');
  late final __mm512_maskz_sllv_epi32 = __mm512_maskz_sllv_epi32Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_mask_sllv_epi64(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_sllv_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_sllv_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask8, __m512i, __m512i)>>('_mm512_mask_sllv_epi64');
  late final __mm512_mask_sllv_epi64 = __mm512_mask_sllv_epi64Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_sllv_epi64(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_sllv_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_sllv_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask8, __m512i, __m512i)>>(
          '_mm512_maskz_sllv_epi64');
  late final __mm512_maskz_sllv_epi64 = __mm512_maskz_sllv_epi64Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_srl_epi16(
    __m512i arg0,
    __m128i arg1,
  ) {
    return __mm512_srl_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm512_srl_epi16Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m128i)>>(
          '_mm512_srl_epi16');
  late final __mm512_srl_epi16 =
      __mm512_srl_epi16Ptr.asFunction<__m512i Function(__m512i, __m128i)>();

  __m512i _mm512_srl_epi32(
    __m512i arg0,
    __m128i arg1,
  ) {
    return __mm512_srl_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_srl_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m128i)>>(
          '_mm512_srl_epi32');
  late final __mm512_srl_epi32 =
      __mm512_srl_epi32Ptr.asFunction<__m512i Function(__m512i, __m128i)>();

  __m512i _mm512_srl_epi64(
    __m512i arg0,
    __m128i arg1,
  ) {
    return __mm512_srl_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm512_srl_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m128i)>>(
          '_mm512_srl_epi64');
  late final __mm512_srl_epi64 =
      __mm512_srl_epi64Ptr.asFunction<__m512i Function(__m512i, __m128i)>();

  __m512i _mm512_srli_epi16(
    __m512i arg0,
    int arg1,
  ) {
    return __mm512_srli_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm512_srli_epi16Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, ffi.Int32)>>(
          '_mm512_srli_epi16');
  late final __mm512_srli_epi16 =
      __mm512_srli_epi16Ptr.asFunction<__m512i Function(__m512i, int)>();

  __m512i _mm512_srli_epi32(
    __m512i arg0,
    int arg1,
  ) {
    return __mm512_srli_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_srli_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, ffi.Uint32)>>(
          '_mm512_srli_epi32');
  late final __mm512_srli_epi32 =
      __mm512_srli_epi32Ptr.asFunction<__m512i Function(__m512i, int)>();

  __m512i _mm512_srli_epi64(
    __m512i arg0,
    int arg1,
  ) {
    return __mm512_srli_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm512_srli_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, ffi.Uint32)>>(
          '_mm512_srli_epi64');
  late final __mm512_srli_epi64 =
      __mm512_srli_epi64Ptr.asFunction<__m512i Function(__m512i, int)>();

  __m512i _mm512_srlv_epi16(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_srlv_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm512_srlv_epi16Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_srlv_epi16');
  late final __mm512_srlv_epi16 =
      __mm512_srlv_epi16Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_srlv_epi32(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_srlv_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_srlv_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_srlv_epi32');
  late final __mm512_srlv_epi32 =
      __mm512_srlv_epi32Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_srlv_epi64(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_srlv_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm512_srlv_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_srlv_epi64');
  late final __mm512_srlv_epi64 =
      __mm512_srlv_epi64Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_srl_epi16(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m128i arg3,
  ) {
    return __mm512_mask_srl_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_srl_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask32, __m512i, __m128i)>>('_mm512_mask_srl_epi16');
  late final __mm512_mask_srl_epi16 = __mm512_mask_srl_epi16Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m128i)>();

  __m512i _mm512_maskz_srl_epi16(
    int arg0,
    __m512i arg1,
    __m128i arg2,
  ) {
    return __mm512_maskz_srl_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_srl_epi16Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask32, __m512i, __m128i)>>(
      '_mm512_maskz_srl_epi16');
  late final __mm512_maskz_srl_epi16 = __mm512_maskz_srl_epi16Ptr
      .asFunction<__m512i Function(int, __m512i, __m128i)>();

  __m512i _mm512_mask_srl_epi32(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m128i arg3,
  ) {
    return __mm512_mask_srl_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_srl_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask16, __m512i, __m128i)>>('_mm512_mask_srl_epi32');
  late final __mm512_mask_srl_epi32 = __mm512_mask_srl_epi32Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m128i)>();

  __m512i _mm512_maskz_srl_epi32(
    int arg0,
    __m512i arg1,
    __m128i arg2,
  ) {
    return __mm512_maskz_srl_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_srl_epi32Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask16, __m512i, __m128i)>>(
      '_mm512_maskz_srl_epi32');
  late final __mm512_maskz_srl_epi32 = __mm512_maskz_srl_epi32Ptr
      .asFunction<__m512i Function(int, __m512i, __m128i)>();

  __m512i _mm512_mask_srl_epi64(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m128i arg3,
  ) {
    return __mm512_mask_srl_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_srl_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask8, __m512i, __m128i)>>('_mm512_mask_srl_epi64');
  late final __mm512_mask_srl_epi64 = __mm512_mask_srl_epi64Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m128i)>();

  __m512i _mm512_maskz_srl_epi64(
    int arg0,
    __m512i arg1,
    __m128i arg2,
  ) {
    return __mm512_maskz_srl_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_srl_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask8, __m512i, __m128i)>>(
          '_mm512_maskz_srl_epi64');
  late final __mm512_maskz_srl_epi64 = __mm512_maskz_srl_epi64Ptr
      .asFunction<__m512i Function(int, __m512i, __m128i)>();

  __m512i _mm512_mask_srli_epi16(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    int arg3,
  ) {
    return __mm512_mask_srli_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_srli_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask32, __m512i,
              ffi.Uint32)>>('_mm512_mask_srli_epi16');
  late final __mm512_mask_srli_epi16 = __mm512_mask_srli_epi16Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, int)>();

  __m512i _mm512_maskz_srli_epi16(
    int arg0,
    __m512i arg1,
    int arg2,
  ) {
    return __mm512_maskz_srli_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_srli_epi16Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask32, __m512i, ffi.Int32)>>(
      '_mm512_maskz_srli_epi16');
  late final __mm512_maskz_srli_epi16 = __mm512_maskz_srli_epi16Ptr
      .asFunction<__m512i Function(int, __m512i, int)>();

  __m512i _mm512_mask_srli_epi32(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    int arg3,
  ) {
    return __mm512_mask_srli_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_srli_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask16, __m512i,
              ffi.Uint32)>>('_mm512_mask_srli_epi32');
  late final __mm512_mask_srli_epi32 = __mm512_mask_srli_epi32Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, int)>();

  __m512i _mm512_maskz_srli_epi32(
    int arg0,
    __m512i arg1,
    int arg2,
  ) {
    return __mm512_maskz_srli_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_srli_epi32Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask16, __m512i, ffi.Uint32)>>(
      '_mm512_maskz_srli_epi32');
  late final __mm512_maskz_srli_epi32 = __mm512_maskz_srli_epi32Ptr
      .asFunction<__m512i Function(int, __m512i, int)>();

  __m512i _mm512_mask_srli_epi64(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    int arg3,
  ) {
    return __mm512_mask_srli_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_srli_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask8, __m512i,
              ffi.Uint32)>>('_mm512_mask_srli_epi64');
  late final __mm512_mask_srli_epi64 = __mm512_mask_srli_epi64Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, int)>();

  __m512i _mm512_maskz_srli_epi64(
    int arg0,
    __m512i arg1,
    int arg2,
  ) {
    return __mm512_maskz_srli_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_srli_epi64Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask8, __m512i, ffi.Uint32)>>(
      '_mm512_maskz_srli_epi64');
  late final __mm512_maskz_srli_epi64 = __mm512_maskz_srli_epi64Ptr
      .asFunction<__m512i Function(int, __m512i, int)>();

  __m512i _mm512_mask_srlv_epi16(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_srlv_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_srlv_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask32, __m512i, __m512i)>>('_mm512_mask_srlv_epi16');
  late final __mm512_mask_srlv_epi16 = __mm512_mask_srlv_epi16Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_srlv_epi16(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_srlv_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_srlv_epi16Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask32, __m512i, __m512i)>>(
      '_mm512_maskz_srlv_epi16');
  late final __mm512_maskz_srlv_epi16 = __mm512_maskz_srlv_epi16Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_mask_srlv_epi32(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_srlv_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_srlv_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask16, __m512i, __m512i)>>('_mm512_mask_srlv_epi32');
  late final __mm512_mask_srlv_epi32 = __mm512_mask_srlv_epi32Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_srlv_epi32(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_srlv_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_srlv_epi32Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask16, __m512i, __m512i)>>(
      '_mm512_maskz_srlv_epi32');
  late final __mm512_maskz_srlv_epi32 = __mm512_maskz_srlv_epi32Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_mask_srlv_epi64(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_srlv_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_srlv_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask8, __m512i, __m512i)>>('_mm512_mask_srlv_epi64');
  late final __mm512_mask_srlv_epi64 = __mm512_mask_srlv_epi64Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_srlv_epi64(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_srlv_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_srlv_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask8, __m512i, __m512i)>>(
          '_mm512_maskz_srlv_epi64');
  late final __mm512_maskz_srlv_epi64 = __mm512_maskz_srlv_epi64Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_sra_epi16(
    __m512i arg0,
    __m128i arg1,
  ) {
    return __mm512_sra_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm512_sra_epi16Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m128i)>>(
          '_mm512_sra_epi16');
  late final __mm512_sra_epi16 =
      __mm512_sra_epi16Ptr.asFunction<__m512i Function(__m512i, __m128i)>();

  __m512i _mm512_sra_epi32(
    __m512i arg0,
    __m128i arg1,
  ) {
    return __mm512_sra_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_sra_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m128i)>>(
          '_mm512_sra_epi32');
  late final __mm512_sra_epi32 =
      __mm512_sra_epi32Ptr.asFunction<__m512i Function(__m512i, __m128i)>();

  __m512i _mm512_sra_epi64(
    __m512i arg0,
    __m128i arg1,
  ) {
    return __mm512_sra_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm512_sra_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m128i)>>(
          '_mm512_sra_epi64');
  late final __mm512_sra_epi64 =
      __mm512_sra_epi64Ptr.asFunction<__m512i Function(__m512i, __m128i)>();

  __m512i _mm512_srai_epi16(
    __m512i arg0,
    int arg1,
  ) {
    return __mm512_srai_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm512_srai_epi16Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, ffi.Uint32)>>(
          '_mm512_srai_epi16');
  late final __mm512_srai_epi16 =
      __mm512_srai_epi16Ptr.asFunction<__m512i Function(__m512i, int)>();

  __m512i _mm512_srai_epi32(
    __m512i arg0,
    int arg1,
  ) {
    return __mm512_srai_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_srai_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, ffi.Uint32)>>(
          '_mm512_srai_epi32');
  late final __mm512_srai_epi32 =
      __mm512_srai_epi32Ptr.asFunction<__m512i Function(__m512i, int)>();

  __m512i _mm512_srai_epi64(
    __m512i arg0,
    int arg1,
  ) {
    return __mm512_srai_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm512_srai_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, ffi.Uint32)>>(
          '_mm512_srai_epi64');
  late final __mm512_srai_epi64 =
      __mm512_srai_epi64Ptr.asFunction<__m512i Function(__m512i, int)>();

  __m512i _mm512_srav_epi16(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_srav_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm512_srav_epi16Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_srav_epi16');
  late final __mm512_srav_epi16 =
      __mm512_srav_epi16Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_srav_epi32(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_srav_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_srav_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_srav_epi32');
  late final __mm512_srav_epi32 =
      __mm512_srav_epi32Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_srav_epi64(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_srav_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm512_srav_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_srav_epi64');
  late final __mm512_srav_epi64 =
      __mm512_srav_epi64Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_sra_epi16(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m128i arg3,
  ) {
    return __mm512_mask_sra_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_sra_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask32, __m512i, __m128i)>>('_mm512_mask_sra_epi16');
  late final __mm512_mask_sra_epi16 = __mm512_mask_sra_epi16Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m128i)>();

  __m512i _mm512_maskz_sra_epi16(
    int arg0,
    __m512i arg1,
    __m128i arg2,
  ) {
    return __mm512_maskz_sra_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_sra_epi16Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask32, __m512i, __m128i)>>(
      '_mm512_maskz_sra_epi16');
  late final __mm512_maskz_sra_epi16 = __mm512_maskz_sra_epi16Ptr
      .asFunction<__m512i Function(int, __m512i, __m128i)>();

  __m512i _mm512_mask_sra_epi32(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m128i arg3,
  ) {
    return __mm512_mask_sra_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_sra_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask16, __m512i, __m128i)>>('_mm512_mask_sra_epi32');
  late final __mm512_mask_sra_epi32 = __mm512_mask_sra_epi32Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m128i)>();

  __m512i _mm512_maskz_sra_epi32(
    int arg0,
    __m512i arg1,
    __m128i arg2,
  ) {
    return __mm512_maskz_sra_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_sra_epi32Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask16, __m512i, __m128i)>>(
      '_mm512_maskz_sra_epi32');
  late final __mm512_maskz_sra_epi32 = __mm512_maskz_sra_epi32Ptr
      .asFunction<__m512i Function(int, __m512i, __m128i)>();

  __m512i _mm512_mask_sra_epi64(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m128i arg3,
  ) {
    return __mm512_mask_sra_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_sra_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask8, __m512i, __m128i)>>('_mm512_mask_sra_epi64');
  late final __mm512_mask_sra_epi64 = __mm512_mask_sra_epi64Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m128i)>();

  __m512i _mm512_maskz_sra_epi64(
    int arg0,
    __m512i arg1,
    __m128i arg2,
  ) {
    return __mm512_maskz_sra_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_sra_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask8, __m512i, __m128i)>>(
          '_mm512_maskz_sra_epi64');
  late final __mm512_maskz_sra_epi64 = __mm512_maskz_sra_epi64Ptr
      .asFunction<__m512i Function(int, __m512i, __m128i)>();

  __m512i _mm512_mask_srai_epi16(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    int arg3,
  ) {
    return __mm512_mask_srai_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_srai_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask32, __m512i,
              ffi.Uint32)>>('_mm512_mask_srai_epi16');
  late final __mm512_mask_srai_epi16 = __mm512_mask_srai_epi16Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, int)>();

  __m512i _mm512_maskz_srai_epi16(
    int arg0,
    __m512i arg1,
    int arg2,
  ) {
    return __mm512_maskz_srai_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_srai_epi16Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask32, __m512i, ffi.Uint32)>>(
      '_mm512_maskz_srai_epi16');
  late final __mm512_maskz_srai_epi16 = __mm512_maskz_srai_epi16Ptr
      .asFunction<__m512i Function(int, __m512i, int)>();

  __m512i _mm512_mask_srai_epi32(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    int arg3,
  ) {
    return __mm512_mask_srai_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_srai_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask16, __m512i,
              ffi.Uint32)>>('_mm512_mask_srai_epi32');
  late final __mm512_mask_srai_epi32 = __mm512_mask_srai_epi32Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, int)>();

  __m512i _mm512_maskz_srai_epi32(
    int arg0,
    __m512i arg1,
    int arg2,
  ) {
    return __mm512_maskz_srai_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_srai_epi32Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask16, __m512i, ffi.Uint32)>>(
      '_mm512_maskz_srai_epi32');
  late final __mm512_maskz_srai_epi32 = __mm512_maskz_srai_epi32Ptr
      .asFunction<__m512i Function(int, __m512i, int)>();

  __m512i _mm512_mask_srai_epi64(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    int arg3,
  ) {
    return __mm512_mask_srai_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_srai_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask8, __m512i,
              ffi.Uint32)>>('_mm512_mask_srai_epi64');
  late final __mm512_mask_srai_epi64 = __mm512_mask_srai_epi64Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, int)>();

  __m512i _mm512_maskz_srai_epi64(
    int arg0,
    __m512i arg1,
    int arg2,
  ) {
    return __mm512_maskz_srai_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_srai_epi64Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask8, __m512i, ffi.Uint32)>>(
      '_mm512_maskz_srai_epi64');
  late final __mm512_maskz_srai_epi64 = __mm512_maskz_srai_epi64Ptr
      .asFunction<__m512i Function(int, __m512i, int)>();

  __m512i _mm512_mask_srav_epi16(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_srav_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_srav_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask32, __m512i, __m512i)>>('_mm512_mask_srav_epi16');
  late final __mm512_mask_srav_epi16 = __mm512_mask_srav_epi16Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_srav_epi16(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_srav_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_srav_epi16Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask32, __m512i, __m512i)>>(
      '_mm512_maskz_srav_epi16');
  late final __mm512_maskz_srav_epi16 = __mm512_maskz_srav_epi16Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_mask_srav_epi32(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_srav_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_srav_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask16, __m512i, __m512i)>>('_mm512_mask_srav_epi32');
  late final __mm512_mask_srav_epi32 = __mm512_mask_srav_epi32Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_srav_epi32(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_srav_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_srav_epi32Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask16, __m512i, __m512i)>>(
      '_mm512_maskz_srav_epi32');
  late final __mm512_maskz_srav_epi32 = __mm512_maskz_srav_epi32Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_mask_srav_epi64(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_srav_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_srav_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask8, __m512i, __m512i)>>('_mm512_mask_srav_epi64');
  late final __mm512_mask_srav_epi64 = __mm512_mask_srav_epi64Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_srav_epi64(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_srav_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_srav_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask8, __m512i, __m512i)>>(
          '_mm512_maskz_srav_epi64');
  late final __mm512_maskz_srav_epi64 = __mm512_maskz_srav_epi64Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_bslli_epi128(
    __m512i arg0,
    int arg1,
  ) {
    return __mm512_bslli_epi128(
      arg0,
      arg1,
    );
  }

  late final __mm512_bslli_epi128Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, ffi.Int32)>>(
          '_mm512_bslli_epi128');
  late final __mm512_bslli_epi128 =
      __mm512_bslli_epi128Ptr.asFunction<__m512i Function(__m512i, int)>();

  __m512i _mm512_bsrli_epi128(
    __m512i arg0,
    int arg1,
  ) {
    return __mm512_bsrli_epi128(
      arg0,
      arg1,
    );
  }

  late final __mm512_bsrli_epi128Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, ffi.Int32)>>(
          '_mm512_bsrli_epi128');
  late final __mm512_bsrli_epi128 =
      __mm512_bsrli_epi128Ptr.asFunction<__m512i Function(__m512i, int)>();

  __m512i _mm512_rol_epi32(
    __m512i arg0,
    int arg1,
  ) {
    return __mm512_rol_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_rol_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, ffi.Int32)>>(
          '_mm512_rol_epi32');
  late final __mm512_rol_epi32 =
      __mm512_rol_epi32Ptr.asFunction<__m512i Function(__m512i, int)>();

  __m512i _mm512_mask_rol_epi32(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    int arg3,
  ) {
    return __mm512_mask_rol_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_rol_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask16, __m512i,
              ffi.Int32)>>('_mm512_mask_rol_epi32');
  late final __mm512_mask_rol_epi32 = __mm512_mask_rol_epi32Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, int)>();

  __m512i _mm512_maskz_rol_epi32(
    int arg0,
    __m512i arg1,
    int arg2,
  ) {
    return __mm512_maskz_rol_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_rol_epi32Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask16, __m512i, ffi.Int32)>>(
      '_mm512_maskz_rol_epi32');
  late final __mm512_maskz_rol_epi32 = __mm512_maskz_rol_epi32Ptr
      .asFunction<__m512i Function(int, __m512i, int)>();

  __m512i _mm512_rol_epi64(
    __m512i arg0,
    int arg1,
  ) {
    return __mm512_rol_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm512_rol_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, ffi.Int32)>>(
          '_mm512_rol_epi64');
  late final __mm512_rol_epi64 =
      __mm512_rol_epi64Ptr.asFunction<__m512i Function(__m512i, int)>();

  __m512i _mm512_mask_rol_epi64(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    int arg3,
  ) {
    return __mm512_mask_rol_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_rol_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask8, __m512i, ffi.Int32)>>('_mm512_mask_rol_epi64');
  late final __mm512_mask_rol_epi64 = __mm512_mask_rol_epi64Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, int)>();

  __m512i _mm512_maskz_rol_epi64(
    int arg0,
    __m512i arg1,
    int arg2,
  ) {
    return __mm512_maskz_rol_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_rol_epi64Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask8, __m512i, ffi.Int32)>>(
      '_mm512_maskz_rol_epi64');
  late final __mm512_maskz_rol_epi64 = __mm512_maskz_rol_epi64Ptr
      .asFunction<__m512i Function(int, __m512i, int)>();

  __m512i _mm512_rolv_epi32(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_rolv_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_rolv_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_rolv_epi32');
  late final __mm512_rolv_epi32 =
      __mm512_rolv_epi32Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_rolv_epi32(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_rolv_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_rolv_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask16, __m512i, __m512i)>>('_mm512_mask_rolv_epi32');
  late final __mm512_mask_rolv_epi32 = __mm512_mask_rolv_epi32Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_rolv_epi32(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_rolv_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_rolv_epi32Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask16, __m512i, __m512i)>>(
      '_mm512_maskz_rolv_epi32');
  late final __mm512_maskz_rolv_epi32 = __mm512_maskz_rolv_epi32Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_rolv_epi64(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_rolv_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm512_rolv_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_rolv_epi64');
  late final __mm512_rolv_epi64 =
      __mm512_rolv_epi64Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_rolv_epi64(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_rolv_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_rolv_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask8, __m512i, __m512i)>>('_mm512_mask_rolv_epi64');
  late final __mm512_mask_rolv_epi64 = __mm512_mask_rolv_epi64Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_rolv_epi64(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_rolv_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_rolv_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask8, __m512i, __m512i)>>(
          '_mm512_maskz_rolv_epi64');
  late final __mm512_maskz_rolv_epi64 = __mm512_maskz_rolv_epi64Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_ror_epi32(
    __m512i arg0,
    int arg1,
  ) {
    return __mm512_ror_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_ror_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, ffi.Int32)>>(
          '_mm512_ror_epi32');
  late final __mm512_ror_epi32 =
      __mm512_ror_epi32Ptr.asFunction<__m512i Function(__m512i, int)>();

  __m512i _mm512_mask_ror_epi32(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    int arg3,
  ) {
    return __mm512_mask_ror_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_ror_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask16, __m512i,
              ffi.Int32)>>('_mm512_mask_ror_epi32');
  late final __mm512_mask_ror_epi32 = __mm512_mask_ror_epi32Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, int)>();

  __m512i _mm512_maskz_ror_epi32(
    int arg0,
    __m512i arg1,
    int arg2,
  ) {
    return __mm512_maskz_ror_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_ror_epi32Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask16, __m512i, ffi.Int32)>>(
      '_mm512_maskz_ror_epi32');
  late final __mm512_maskz_ror_epi32 = __mm512_maskz_ror_epi32Ptr
      .asFunction<__m512i Function(int, __m512i, int)>();

  __m512i _mm512_ror_epi64(
    __m512i arg0,
    int arg1,
  ) {
    return __mm512_ror_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm512_ror_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, ffi.Int32)>>(
          '_mm512_ror_epi64');
  late final __mm512_ror_epi64 =
      __mm512_ror_epi64Ptr.asFunction<__m512i Function(__m512i, int)>();

  __m512i _mm512_mask_ror_epi64(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    int arg3,
  ) {
    return __mm512_mask_ror_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_ror_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask8, __m512i, ffi.Int32)>>('_mm512_mask_ror_epi64');
  late final __mm512_mask_ror_epi64 = __mm512_mask_ror_epi64Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, int)>();

  __m512i _mm512_maskz_ror_epi64(
    int arg0,
    __m512i arg1,
    int arg2,
  ) {
    return __mm512_maskz_ror_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_ror_epi64Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask8, __m512i, ffi.Int32)>>(
      '_mm512_maskz_ror_epi64');
  late final __mm512_maskz_ror_epi64 = __mm512_maskz_ror_epi64Ptr
      .asFunction<__m512i Function(int, __m512i, int)>();

  __m512i _mm512_rorv_epi32(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_rorv_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_rorv_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_rorv_epi32');
  late final __mm512_rorv_epi32 =
      __mm512_rorv_epi32Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_rorv_epi32(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_rorv_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_rorv_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask16, __m512i, __m512i)>>('_mm512_mask_rorv_epi32');
  late final __mm512_mask_rorv_epi32 = __mm512_mask_rorv_epi32Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_rorv_epi32(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_rorv_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_rorv_epi32Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask16, __m512i, __m512i)>>(
      '_mm512_maskz_rorv_epi32');
  late final __mm512_maskz_rorv_epi32 = __mm512_maskz_rorv_epi32Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_rorv_epi64(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_rorv_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm512_rorv_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_rorv_epi64');
  late final __mm512_rorv_epi64 =
      __mm512_rorv_epi64Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_rorv_epi64(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_rorv_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_rorv_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask8, __m512i, __m512i)>>('_mm512_mask_rorv_epi64');
  late final __mm512_mask_rorv_epi64 = __mm512_mask_rorv_epi64Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_rorv_epi64(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_rorv_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_rorv_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask8, __m512i, __m512i)>>(
          '_mm512_maskz_rorv_epi64');
  late final __mm512_maskz_rorv_epi64 = __mm512_maskz_rorv_epi64Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  _m512d _mm512_unpackhi_pd(
    _m512d arg0,
    _m512d arg1,
  ) {
    return __mm512_unpackhi_pd(
      arg0,
      arg1,
    );
  }

  late final __mm512_unpackhi_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, _m512d)>>(
          '_mm512_unpackhi_pd');
  late final __mm512_unpackhi_pd =
      __mm512_unpackhi_pdPtr.asFunction<_m512d Function(_m512d, _m512d)>();

  _m512d _mm512_mask_unpackhi_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
    _m512d arg3,
  ) {
    return __mm512_mask_unpackhi_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_unpackhi_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(
              _m512d, __mmask8, _m512d, _m512d)>>('_mm512_mask_unpackhi_pd');
  late final __mm512_mask_unpackhi_pd = __mm512_mask_unpackhi_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d, _m512d)>();

  _m512d _mm512_maskz_unpackhi_pd(
    int arg0,
    _m512d arg1,
    _m512d arg2,
  ) {
    return __mm512_maskz_unpackhi_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_unpackhi_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(__mmask8, _m512d, _m512d)>>(
          '_mm512_maskz_unpackhi_pd');
  late final __mm512_maskz_unpackhi_pd = __mm512_maskz_unpackhi_pdPtr
      .asFunction<_m512d Function(int, _m512d, _m512d)>();

  __m512 _mm512_unpackhi_ps(
    __m512 arg0,
    __m512 arg1,
  ) {
    return __mm512_unpackhi_ps(
      arg0,
      arg1,
    );
  }

  late final __mm512_unpackhi_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __m512)>>(
          '_mm512_unpackhi_ps');
  late final __mm512_unpackhi_ps =
      __mm512_unpackhi_psPtr.asFunction<__m512 Function(__m512, __m512)>();

  __m512 _mm512_mask_unpackhi_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
    __m512 arg3,
  ) {
    return __mm512_mask_unpackhi_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_unpackhi_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(
              __m512, __mmask16, __m512, __m512)>>('_mm512_mask_unpackhi_ps');
  late final __mm512_mask_unpackhi_ps = __mm512_mask_unpackhi_psPtr
      .asFunction<__m512 Function(__m512, int, __m512, __m512)>();

  __m512 _mm512_maskz_unpackhi_ps(
    int arg0,
    __m512 arg1,
    __m512 arg2,
  ) {
    return __mm512_maskz_unpackhi_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_unpackhi_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__mmask16, __m512, __m512)>>(
          '_mm512_maskz_unpackhi_ps');
  late final __mm512_maskz_unpackhi_ps = __mm512_maskz_unpackhi_psPtr
      .asFunction<__m512 Function(int, __m512, __m512)>();

  _m512d _mm512_unpacklo_pd(
    _m512d arg0,
    _m512d arg1,
  ) {
    return __mm512_unpacklo_pd(
      arg0,
      arg1,
    );
  }

  late final __mm512_unpacklo_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, _m512d)>>(
          '_mm512_unpacklo_pd');
  late final __mm512_unpacklo_pd =
      __mm512_unpacklo_pdPtr.asFunction<_m512d Function(_m512d, _m512d)>();

  _m512d _mm512_mask_unpacklo_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
    _m512d arg3,
  ) {
    return __mm512_mask_unpacklo_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_unpacklo_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(
              _m512d, __mmask8, _m512d, _m512d)>>('_mm512_mask_unpacklo_pd');
  late final __mm512_mask_unpacklo_pd = __mm512_mask_unpacklo_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d, _m512d)>();

  _m512d _mm512_maskz_unpacklo_pd(
    int arg0,
    _m512d arg1,
    _m512d arg2,
  ) {
    return __mm512_maskz_unpacklo_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_unpacklo_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(__mmask8, _m512d, _m512d)>>(
          '_mm512_maskz_unpacklo_pd');
  late final __mm512_maskz_unpacklo_pd = __mm512_maskz_unpacklo_pdPtr
      .asFunction<_m512d Function(int, _m512d, _m512d)>();

  __m512 _mm512_unpacklo_ps(
    __m512 arg0,
    __m512 arg1,
  ) {
    return __mm512_unpacklo_ps(
      arg0,
      arg1,
    );
  }

  late final __mm512_unpacklo_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __m512)>>(
          '_mm512_unpacklo_ps');
  late final __mm512_unpacklo_ps =
      __mm512_unpacklo_psPtr.asFunction<__m512 Function(__m512, __m512)>();

  __m512 _mm512_mask_unpacklo_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
    __m512 arg3,
  ) {
    return __mm512_mask_unpacklo_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_unpacklo_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(
              __m512, __mmask16, __m512, __m512)>>('_mm512_mask_unpacklo_ps');
  late final __mm512_mask_unpacklo_ps = __mm512_mask_unpacklo_psPtr
      .asFunction<__m512 Function(__m512, int, __m512, __m512)>();

  __m512 _mm512_maskz_unpacklo_ps(
    int arg0,
    __m512 arg1,
    __m512 arg2,
  ) {
    return __mm512_maskz_unpacklo_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_unpacklo_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__mmask16, __m512, __m512)>>(
          '_mm512_maskz_unpacklo_ps');
  late final __mm512_maskz_unpacklo_ps = __mm512_maskz_unpacklo_psPtr
      .asFunction<__m512 Function(int, __m512, __m512)>();

  __m512i _mm512_unpackhi_epi8(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_unpackhi_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm512_unpackhi_epi8Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_unpackhi_epi8');
  late final __mm512_unpackhi_epi8 =
      __mm512_unpackhi_epi8Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_unpackhi_epi8(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_unpackhi_epi8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_unpackhi_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask64, __m512i,
              __m512i)>>('_mm512_mask_unpackhi_epi8');
  late final __mm512_mask_unpackhi_epi8 = __mm512_mask_unpackhi_epi8Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_unpackhi_epi8(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_unpackhi_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_unpackhi_epi8Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask64, __m512i, __m512i)>>(
      '_mm512_maskz_unpackhi_epi8');
  late final __mm512_maskz_unpackhi_epi8 = __mm512_maskz_unpackhi_epi8Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_unpackhi_epi16(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_unpackhi_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm512_unpackhi_epi16Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_unpackhi_epi16');
  late final __mm512_unpackhi_epi16 = __mm512_unpackhi_epi16Ptr
      .asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_unpackhi_epi16(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_unpackhi_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_unpackhi_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask32, __m512i,
              __m512i)>>('_mm512_mask_unpackhi_epi16');
  late final __mm512_mask_unpackhi_epi16 = __mm512_mask_unpackhi_epi16Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_unpackhi_epi16(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_unpackhi_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_unpackhi_epi16Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask32, __m512i, __m512i)>>(
      '_mm512_maskz_unpackhi_epi16');
  late final __mm512_maskz_unpackhi_epi16 = __mm512_maskz_unpackhi_epi16Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_unpackhi_epi32(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_unpackhi_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_unpackhi_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_unpackhi_epi32');
  late final __mm512_unpackhi_epi32 = __mm512_unpackhi_epi32Ptr
      .asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_unpackhi_epi32(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_unpackhi_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_unpackhi_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask16, __m512i,
              __m512i)>>('_mm512_mask_unpackhi_epi32');
  late final __mm512_mask_unpackhi_epi32 = __mm512_mask_unpackhi_epi32Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_unpackhi_epi32(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_unpackhi_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_unpackhi_epi32Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask16, __m512i, __m512i)>>(
      '_mm512_maskz_unpackhi_epi32');
  late final __mm512_maskz_unpackhi_epi32 = __mm512_maskz_unpackhi_epi32Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_unpackhi_epi64(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_unpackhi_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm512_unpackhi_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_unpackhi_epi64');
  late final __mm512_unpackhi_epi64 = __mm512_unpackhi_epi64Ptr
      .asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_unpackhi_epi64(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_unpackhi_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_unpackhi_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask8, __m512i,
              __m512i)>>('_mm512_mask_unpackhi_epi64');
  late final __mm512_mask_unpackhi_epi64 = __mm512_mask_unpackhi_epi64Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_unpackhi_epi64(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_unpackhi_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_unpackhi_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask8, __m512i, __m512i)>>(
          '_mm512_maskz_unpackhi_epi64');
  late final __mm512_maskz_unpackhi_epi64 = __mm512_maskz_unpackhi_epi64Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_unpacklo_epi8(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_unpacklo_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm512_unpacklo_epi8Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_unpacklo_epi8');
  late final __mm512_unpacklo_epi8 =
      __mm512_unpacklo_epi8Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_unpacklo_epi8(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_unpacklo_epi8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_unpacklo_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask64, __m512i,
              __m512i)>>('_mm512_mask_unpacklo_epi8');
  late final __mm512_mask_unpacklo_epi8 = __mm512_mask_unpacklo_epi8Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_unpacklo_epi8(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_unpacklo_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_unpacklo_epi8Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask64, __m512i, __m512i)>>(
      '_mm512_maskz_unpacklo_epi8');
  late final __mm512_maskz_unpacklo_epi8 = __mm512_maskz_unpacklo_epi8Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_unpacklo_epi16(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_unpacklo_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm512_unpacklo_epi16Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_unpacklo_epi16');
  late final __mm512_unpacklo_epi16 = __mm512_unpacklo_epi16Ptr
      .asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_unpacklo_epi16(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_unpacklo_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_unpacklo_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask32, __m512i,
              __m512i)>>('_mm512_mask_unpacklo_epi16');
  late final __mm512_mask_unpacklo_epi16 = __mm512_mask_unpacklo_epi16Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_unpacklo_epi16(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_unpacklo_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_unpacklo_epi16Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask32, __m512i, __m512i)>>(
      '_mm512_maskz_unpacklo_epi16');
  late final __mm512_maskz_unpacklo_epi16 = __mm512_maskz_unpacklo_epi16Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_unpacklo_epi32(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_unpacklo_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_unpacklo_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_unpacklo_epi32');
  late final __mm512_unpacklo_epi32 = __mm512_unpacklo_epi32Ptr
      .asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_unpacklo_epi32(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_unpacklo_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_unpacklo_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask16, __m512i,
              __m512i)>>('_mm512_mask_unpacklo_epi32');
  late final __mm512_mask_unpacklo_epi32 = __mm512_mask_unpacklo_epi32Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_unpacklo_epi32(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_unpacklo_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_unpacklo_epi32Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask16, __m512i, __m512i)>>(
      '_mm512_maskz_unpacklo_epi32');
  late final __mm512_maskz_unpacklo_epi32 = __mm512_maskz_unpacklo_epi32Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_unpacklo_epi64(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_unpacklo_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm512_unpacklo_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_unpacklo_epi64');
  late final __mm512_unpacklo_epi64 = __mm512_unpacklo_epi64Ptr
      .asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_unpacklo_epi64(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_unpacklo_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_unpacklo_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask8, __m512i,
              __m512i)>>('_mm512_mask_unpacklo_epi64');
  late final __mm512_mask_unpacklo_epi64 = __mm512_mask_unpacklo_epi64Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_unpacklo_epi64(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_unpacklo_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_unpacklo_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask8, __m512i, __m512i)>>(
          '_mm512_maskz_unpacklo_epi64');
  late final __mm512_maskz_unpacklo_epi64 = __mm512_maskz_unpacklo_epi64Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512 _mm512_getexp_ps(
    __m512 arg0,
  ) {
    return __mm512_getexp_ps(
      arg0,
    );
  }

  late final __mm512_getexp_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512)>>('_mm512_getexp_ps');
  late final __mm512_getexp_ps =
      __mm512_getexp_psPtr.asFunction<__m512 Function(__m512)>();

  __m512 _mm512_mask_getexp_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
  ) {
    return __mm512_mask_getexp_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_getexp_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __mmask16, __m512)>>(
          '_mm512_mask_getexp_ps');
  late final __mm512_mask_getexp_ps = __mm512_mask_getexp_psPtr
      .asFunction<__m512 Function(__m512, int, __m512)>();

  __m512 _mm512_maskz_getexp_ps(
    int arg0,
    __m512 arg1,
  ) {
    return __mm512_maskz_getexp_ps(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_getexp_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__mmask16, __m512)>>(
          '_mm512_maskz_getexp_ps');
  late final __mm512_maskz_getexp_ps =
      __mm512_maskz_getexp_psPtr.asFunction<__m512 Function(int, __m512)>();

  __m512 _mm512_getexp_round_ps(
    __m512 arg0,
    int arg1,
  ) {
    return __mm512_getexp_round_ps(
      arg0,
      arg1,
    );
  }

  late final __mm512_getexp_round_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, ffi.Int32)>>(
          '_mm512_getexp_round_ps');
  late final __mm512_getexp_round_ps =
      __mm512_getexp_round_psPtr.asFunction<__m512 Function(__m512, int)>();

  __m512 _mm512_mask_getexp_round_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
    int arg3,
  ) {
    return __mm512_mask_getexp_round_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_getexp_round_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__m512, __mmask16, __m512,
              ffi.Int32)>>('_mm512_mask_getexp_round_ps');
  late final __mm512_mask_getexp_round_ps = __mm512_mask_getexp_round_psPtr
      .asFunction<__m512 Function(__m512, int, __m512, int)>();

  __m512 _mm512_maskz_getexp_round_ps(
    int arg0,
    __m512 arg1,
    int arg2,
  ) {
    return __mm512_maskz_getexp_round_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_getexp_round_psPtr = _lookup<
          ffi.NativeFunction<__m512 Function(__mmask16, __m512, ffi.Int32)>>(
      '_mm512_maskz_getexp_round_ps');
  late final __mm512_maskz_getexp_round_ps = __mm512_maskz_getexp_round_psPtr
      .asFunction<__m512 Function(int, __m512, int)>();

  _m512d _mm512_getexp_pd(
    _m512d arg0,
  ) {
    return __mm512_getexp_pd(
      arg0,
    );
  }

  late final __mm512_getexp_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d)>>('_mm512_getexp_pd');
  late final __mm512_getexp_pd =
      __mm512_getexp_pdPtr.asFunction<_m512d Function(_m512d)>();

  _m512d _mm512_mask_getexp_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
  ) {
    return __mm512_mask_getexp_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_getexp_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, __mmask8, _m512d)>>(
          '_mm512_mask_getexp_pd');
  late final __mm512_mask_getexp_pd = __mm512_mask_getexp_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d)>();

  _m512d _mm512_maskz_getexp_pd(
    int arg0,
    _m512d arg1,
  ) {
    return __mm512_maskz_getexp_pd(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_getexp_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(__mmask8, _m512d)>>(
          '_mm512_maskz_getexp_pd');
  late final __mm512_maskz_getexp_pd =
      __mm512_maskz_getexp_pdPtr.asFunction<_m512d Function(int, _m512d)>();

  _m512d _mm512_getexp_round_pd(
    _m512d arg0,
    int arg1,
  ) {
    return __mm512_getexp_round_pd(
      arg0,
      arg1,
    );
  }

  late final __mm512_getexp_round_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, ffi.Int32)>>(
          '_mm512_getexp_round_pd');
  late final __mm512_getexp_round_pd =
      __mm512_getexp_round_pdPtr.asFunction<_m512d Function(_m512d, int)>();

  _m512d _mm512_mask_getexp_round_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
    int arg3,
  ) {
    return __mm512_mask_getexp_round_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_getexp_round_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(_m512d, __mmask8, _m512d,
              ffi.Int32)>>('_mm512_mask_getexp_round_pd');
  late final __mm512_mask_getexp_round_pd = __mm512_mask_getexp_round_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d, int)>();

  _m512d _mm512_maskz_getexp_round_pd(
    int arg0,
    _m512d arg1,
    int arg2,
  ) {
    return __mm512_maskz_getexp_round_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_getexp_round_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(__mmask8, _m512d, ffi.Int32)>>(
          '_mm512_maskz_getexp_round_pd');
  late final __mm512_maskz_getexp_round_pd = __mm512_maskz_getexp_round_pdPtr
      .asFunction<_m512d Function(int, _m512d, int)>();

  __m512 _mm512_getmant_ps(
    __m512 arg0,
    int arg1,
    int arg2,
  ) {
    return __mm512_getmant_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_getmant_psPtr = _lookup<
          ffi.NativeFunction<__m512 Function(__m512, ffi.Int32, ffi.Int32)>>(
      '_mm512_getmant_ps');
  late final __mm512_getmant_ps =
      __mm512_getmant_psPtr.asFunction<__m512 Function(__m512, int, int)>();

  __m512 _mm512_mask_getmant_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
    int arg3,
    int arg4,
  ) {
    return __mm512_mask_getmant_ps(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_getmant_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__m512, __mmask16, __m512, ffi.Int32,
              ffi.Int32)>>('_mm512_mask_getmant_ps');
  late final __mm512_mask_getmant_ps = __mm512_mask_getmant_psPtr
      .asFunction<__m512 Function(__m512, int, __m512, int, int)>();

  __m512 _mm512_maskz_getmant_ps(
    int arg0,
    __m512 arg1,
    int arg2,
    int arg3,
  ) {
    return __mm512_maskz_getmant_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_getmant_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__mmask16, __m512, ffi.Int32,
              ffi.Int32)>>('_mm512_maskz_getmant_ps');
  late final __mm512_maskz_getmant_ps = __mm512_maskz_getmant_psPtr
      .asFunction<__m512 Function(int, __m512, int, int)>();

  __m512 _mm512_getmant_round_ps(
    __m512 arg0,
    int arg1,
    int arg2,
    int arg3,
  ) {
    return __mm512_getmant_round_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_getmant_round_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__m512, ffi.Int32, ffi.Int32,
              ffi.Int32)>>('_mm512_getmant_round_ps');
  late final __mm512_getmant_round_ps = __mm512_getmant_round_psPtr
      .asFunction<__m512 Function(__m512, int, int, int)>();

  __m512 _mm512_mask_getmant_round_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
    int arg3,
    int arg4,
    int arg5,
  ) {
    return __mm512_mask_getmant_round_ps(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
      arg5,
    );
  }

  late final __mm512_mask_getmant_round_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__m512, __mmask16, __m512, ffi.Int32, ffi.Int32,
              ffi.Int32)>>('_mm512_mask_getmant_round_ps');
  late final __mm512_mask_getmant_round_ps = __mm512_mask_getmant_round_psPtr
      .asFunction<__m512 Function(__m512, int, __m512, int, int, int)>();

  __m512 _mm512_maskz_getmant_round_ps(
    int arg0,
    __m512 arg1,
    int arg2,
    int arg3,
    int arg4,
  ) {
    return __mm512_maskz_getmant_round_ps(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_maskz_getmant_round_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__mmask16, __m512, ffi.Int32, ffi.Int32,
              ffi.Int32)>>('_mm512_maskz_getmant_round_ps');
  late final __mm512_maskz_getmant_round_ps = __mm512_maskz_getmant_round_psPtr
      .asFunction<__m512 Function(int, __m512, int, int, int)>();

  _m512d _mm512_getmant_pd(
    _m512d arg0,
    int arg1,
    int arg2,
  ) {
    return __mm512_getmant_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_getmant_pdPtr = _lookup<
          ffi.NativeFunction<_m512d Function(_m512d, ffi.Int32, ffi.Int32)>>(
      '_mm512_getmant_pd');
  late final __mm512_getmant_pd =
      __mm512_getmant_pdPtr.asFunction<_m512d Function(_m512d, int, int)>();

  _m512d _mm512_mask_getmant_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
    int arg3,
    int arg4,
  ) {
    return __mm512_mask_getmant_pd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_getmant_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(_m512d, __mmask8, _m512d, ffi.Int32,
              ffi.Int32)>>('_mm512_mask_getmant_pd');
  late final __mm512_mask_getmant_pd = __mm512_mask_getmant_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d, int, int)>();

  _m512d _mm512_maskz_getmant_pd(
    int arg0,
    _m512d arg1,
    int arg2,
    int arg3,
  ) {
    return __mm512_maskz_getmant_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_getmant_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(__mmask8, _m512d, ffi.Int32,
              ffi.Int32)>>('_mm512_maskz_getmant_pd');
  late final __mm512_maskz_getmant_pd = __mm512_maskz_getmant_pdPtr
      .asFunction<_m512d Function(int, _m512d, int, int)>();

  _m512d _mm512_getmant_round_pd(
    _m512d arg0,
    int arg1,
    int arg2,
    int arg3,
  ) {
    return __mm512_getmant_round_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_getmant_round_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(_m512d, ffi.Int32, ffi.Int32,
              ffi.Int32)>>('_mm512_getmant_round_pd');
  late final __mm512_getmant_round_pd = __mm512_getmant_round_pdPtr
      .asFunction<_m512d Function(_m512d, int, int, int)>();

  _m512d _mm512_mask_getmant_round_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
    int arg3,
    int arg4,
    int arg5,
  ) {
    return __mm512_mask_getmant_round_pd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
      arg5,
    );
  }

  late final __mm512_mask_getmant_round_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(_m512d, __mmask8, _m512d, ffi.Int32, ffi.Int32,
              ffi.Int32)>>('_mm512_mask_getmant_round_pd');
  late final __mm512_mask_getmant_round_pd = __mm512_mask_getmant_round_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d, int, int, int)>();

  _m512d _mm512_maskz_getmant_round_pd(
    int arg0,
    _m512d arg1,
    int arg2,
    int arg3,
    int arg4,
  ) {
    return __mm512_maskz_getmant_round_pd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_maskz_getmant_round_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(__mmask8, _m512d, ffi.Int32, ffi.Int32,
              ffi.Int32)>>('_mm512_maskz_getmant_round_pd');
  late final __mm512_maskz_getmant_round_pd = __mm512_maskz_getmant_round_pdPtr
      .asFunction<_m512d Function(int, _m512d, int, int, int)>();

  _m512d _mm512_permute_pd(
    _m512d arg0,
    int arg1,
  ) {
    return __mm512_permute_pd(
      arg0,
      arg1,
    );
  }

  late final __mm512_permute_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, ffi.Int32)>>(
          '_mm512_permute_pd');
  late final __mm512_permute_pd =
      __mm512_permute_pdPtr.asFunction<_m512d Function(_m512d, int)>();

  _m512d _mm512_mask_permute_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
    int arg3,
  ) {
    return __mm512_mask_permute_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_permute_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(
              _m512d, __mmask8, _m512d, ffi.Int32)>>('_mm512_mask_permute_pd');
  late final __mm512_mask_permute_pd = __mm512_mask_permute_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d, int)>();

  _m512d _mm512_maskz_permute_pd(
    int arg0,
    _m512d arg1,
    int arg2,
  ) {
    return __mm512_maskz_permute_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_permute_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(__mmask8, _m512d, ffi.Int32)>>(
          '_mm512_maskz_permute_pd');
  late final __mm512_maskz_permute_pd = __mm512_maskz_permute_pdPtr
      .asFunction<_m512d Function(int, _m512d, int)>();

  __m512 _mm512_permute_ps(
    __m512 arg0,
    int arg1,
  ) {
    return __mm512_permute_ps(
      arg0,
      arg1,
    );
  }

  late final __mm512_permute_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, ffi.Int32)>>(
          '_mm512_permute_ps');
  late final __mm512_permute_ps =
      __mm512_permute_psPtr.asFunction<__m512 Function(__m512, int)>();

  __m512 _mm512_mask_permute_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
    int arg3,
  ) {
    return __mm512_mask_permute_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_permute_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(
              __m512, __mmask16, __m512, ffi.Int32)>>('_mm512_mask_permute_ps');
  late final __mm512_mask_permute_ps = __mm512_mask_permute_psPtr
      .asFunction<__m512 Function(__m512, int, __m512, int)>();

  __m512 _mm512_maskz_permute_ps(
    int arg0,
    __m512 arg1,
    int arg2,
  ) {
    return __mm512_maskz_permute_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_permute_psPtr = _lookup<
          ffi.NativeFunction<__m512 Function(__mmask16, __m512, ffi.Int32)>>(
      '_mm512_maskz_permute_ps');
  late final __mm512_maskz_permute_ps = __mm512_maskz_permute_psPtr
      .asFunction<__m512 Function(int, __m512, int)>();

  _m512d _mm512_permutevar_pd(
    _m512d arg0,
    __m512i arg1,
  ) {
    return __mm512_permutevar_pd(
      arg0,
      arg1,
    );
  }

  late final __mm512_permutevar_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, __m512i)>>(
          '_mm512_permutevar_pd');
  late final __mm512_permutevar_pd =
      __mm512_permutevar_pdPtr.asFunction<_m512d Function(_m512d, __m512i)>();

  _m512d _mm512_mask_permutevar_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_permutevar_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_permutevar_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(
              _m512d, __mmask8, _m512d, __m512i)>>('_mm512_mask_permutevar_pd');
  late final __mm512_mask_permutevar_pd = __mm512_mask_permutevar_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d, __m512i)>();

  _m512d _mm512_maskz_permutevar_pd(
    int arg0,
    _m512d arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_permutevar_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_permutevar_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(__mmask8, _m512d, __m512i)>>(
          '_mm512_maskz_permutevar_pd');
  late final __mm512_maskz_permutevar_pd = __mm512_maskz_permutevar_pdPtr
      .asFunction<_m512d Function(int, _m512d, __m512i)>();

  __m512 _mm512_permutevar_ps(
    __m512 arg0,
    __m512i arg1,
  ) {
    return __mm512_permutevar_ps(
      arg0,
      arg1,
    );
  }

  late final __mm512_permutevar_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __m512i)>>(
          '_mm512_permutevar_ps');
  late final __mm512_permutevar_ps =
      __mm512_permutevar_psPtr.asFunction<__m512 Function(__m512, __m512i)>();

  __m512 _mm512_mask_permutevar_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_permutevar_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_permutevar_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__m512, __mmask16, __m512,
              __m512i)>>('_mm512_mask_permutevar_ps');
  late final __mm512_mask_permutevar_ps = __mm512_mask_permutevar_psPtr
      .asFunction<__m512 Function(__m512, int, __m512, __m512i)>();

  __m512 _mm512_maskz_permutevar_ps(
    int arg0,
    __m512 arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_permutevar_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_permutevar_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__mmask16, __m512, __m512i)>>(
          '_mm512_maskz_permutevar_ps');
  late final __mm512_maskz_permutevar_ps = __mm512_maskz_permutevar_psPtr
      .asFunction<__m512 Function(int, __m512, __m512i)>();

  __m512i _mm512_permutevar_epi32(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_permutevar_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_permutevar_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_permutevar_epi32');
  late final __mm512_permutevar_epi32 = __mm512_permutevar_epi32Ptr
      .asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_permutevar_epi32(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_permutevar_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_permutevar_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask16, __m512i,
              __m512i)>>('_mm512_mask_permutevar_epi32');
  late final __mm512_mask_permutevar_epi32 = __mm512_mask_permutevar_epi32Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  _m512d _mm512_permutex_pd(
    _m512d arg0,
    int arg1,
  ) {
    return __mm512_permutex_pd(
      arg0,
      arg1,
    );
  }

  late final __mm512_permutex_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, ffi.Int32)>>(
          '_mm512_permutex_pd');
  late final __mm512_permutex_pd =
      __mm512_permutex_pdPtr.asFunction<_m512d Function(_m512d, int)>();

  _m512d _mm512_mask_permutex_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
    int arg3,
  ) {
    return __mm512_mask_permutex_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_permutex_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(
              _m512d, __mmask8, _m512d, ffi.Int32)>>('_mm512_mask_permutex_pd');
  late final __mm512_mask_permutex_pd = __mm512_mask_permutex_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d, int)>();

  _m512d _mm512_maskz_permutex_pd(
    int arg0,
    _m512d arg1,
    int arg2,
  ) {
    return __mm512_maskz_permutex_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_permutex_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(__mmask8, _m512d, ffi.Int32)>>(
          '_mm512_maskz_permutex_pd');
  late final __mm512_maskz_permutex_pd = __mm512_maskz_permutex_pdPtr
      .asFunction<_m512d Function(int, _m512d, int)>();

  __m512i _mm512_permutex_epi64(
    __m512i arg0,
    int arg1,
  ) {
    return __mm512_permutex_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm512_permutex_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, ffi.Int32)>>(
          '_mm512_permutex_epi64');
  late final __mm512_permutex_epi64 =
      __mm512_permutex_epi64Ptr.asFunction<__m512i Function(__m512i, int)>();

  __m512i _mm512_mask_permutex_epi64(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    int arg3,
  ) {
    return __mm512_mask_permutex_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_permutex_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask8, __m512i,
              ffi.Int32)>>('_mm512_mask_permutex_epi64');
  late final __mm512_mask_permutex_epi64 = __mm512_mask_permutex_epi64Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, int)>();

  __m512i _mm512_maskz_permutex_epi64(
    int arg0,
    __m512i arg1,
    int arg2,
  ) {
    return __mm512_maskz_permutex_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_permutex_epi64Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask8, __m512i, ffi.Int32)>>(
      '_mm512_maskz_permutex_epi64');
  late final __mm512_maskz_permutex_epi64 = __mm512_maskz_permutex_epi64Ptr
      .asFunction<__m512i Function(int, __m512i, int)>();

  _m512d _mm512_permutexvar_pd(
    __m512i arg0,
    _m512d arg1,
  ) {
    return __mm512_permutexvar_pd(
      arg0,
      arg1,
    );
  }

  late final __mm512_permutexvar_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(__m512i, _m512d)>>(
          '_mm512_permutexvar_pd');
  late final __mm512_permutexvar_pd =
      __mm512_permutexvar_pdPtr.asFunction<_m512d Function(__m512i, _m512d)>();

  _m512d _mm512_mask_permutexvar_pd(
    _m512d arg0,
    int arg1,
    __m512i arg2,
    _m512d arg3,
  ) {
    return __mm512_mask_permutexvar_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_permutexvar_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(_m512d, __mmask8, __m512i,
              _m512d)>>('_mm512_mask_permutexvar_pd');
  late final __mm512_mask_permutexvar_pd = __mm512_mask_permutexvar_pdPtr
      .asFunction<_m512d Function(_m512d, int, __m512i, _m512d)>();

  _m512d _mm512_maskz_permutexvar_pd(
    int arg0,
    __m512i arg1,
    _m512d arg2,
  ) {
    return __mm512_maskz_permutexvar_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_permutexvar_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(__mmask8, __m512i, _m512d)>>(
          '_mm512_maskz_permutexvar_pd');
  late final __mm512_maskz_permutexvar_pd = __mm512_maskz_permutexvar_pdPtr
      .asFunction<_m512d Function(int, __m512i, _m512d)>();

  __m512 _mm512_permutexvar_ps(
    __m512i arg0,
    __m512 arg1,
  ) {
    return __mm512_permutexvar_ps(
      arg0,
      arg1,
    );
  }

  late final __mm512_permutexvar_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512i, __m512)>>(
          '_mm512_permutexvar_ps');
  late final __mm512_permutexvar_ps =
      __mm512_permutexvar_psPtr.asFunction<__m512 Function(__m512i, __m512)>();

  __m512 _mm512_mask_permutexvar_ps(
    __m512 arg0,
    int arg1,
    __m512i arg2,
    __m512 arg3,
  ) {
    return __mm512_mask_permutexvar_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_permutexvar_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__m512, __mmask16, __m512i,
              __m512)>>('_mm512_mask_permutexvar_ps');
  late final __mm512_mask_permutexvar_ps = __mm512_mask_permutexvar_psPtr
      .asFunction<__m512 Function(__m512, int, __m512i, __m512)>();

  __m512 _mm512_maskz_permutexvar_ps(
    int arg0,
    __m512i arg1,
    __m512 arg2,
  ) {
    return __mm512_maskz_permutexvar_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_permutexvar_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__mmask16, __m512i, __m512)>>(
          '_mm512_maskz_permutexvar_ps');
  late final __mm512_maskz_permutexvar_ps = __mm512_maskz_permutexvar_psPtr
      .asFunction<__m512 Function(int, __m512i, __m512)>();

  __m512i _mm512_permutexvar_epi16(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_permutexvar_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm512_permutexvar_epi16Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_permutexvar_epi16');
  late final __mm512_permutexvar_epi16 = __mm512_permutexvar_epi16Ptr
      .asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_permutexvar_epi16(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_permutexvar_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_permutexvar_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask32, __m512i,
              __m512i)>>('_mm512_mask_permutexvar_epi16');
  late final __mm512_mask_permutexvar_epi16 = __mm512_mask_permutexvar_epi16Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_permutexvar_epi16(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_permutexvar_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_permutexvar_epi16Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask32, __m512i, __m512i)>>(
      '_mm512_maskz_permutexvar_epi16');
  late final __mm512_maskz_permutexvar_epi16 =
      __mm512_maskz_permutexvar_epi16Ptr
          .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_permutexvar_epi32(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_permutexvar_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_permutexvar_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_permutexvar_epi32');
  late final __mm512_permutexvar_epi32 = __mm512_permutexvar_epi32Ptr
      .asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_permutexvar_epi32(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_permutexvar_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_permutexvar_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask16, __m512i,
              __m512i)>>('_mm512_mask_permutexvar_epi32');
  late final __mm512_mask_permutexvar_epi32 = __mm512_mask_permutexvar_epi32Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_permutexvar_epi32(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_permutexvar_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_permutexvar_epi32Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask16, __m512i, __m512i)>>(
      '_mm512_maskz_permutexvar_epi32');
  late final __mm512_maskz_permutexvar_epi32 =
      __mm512_maskz_permutexvar_epi32Ptr
          .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_permutexvar_epi64(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_permutexvar_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm512_permutexvar_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_permutexvar_epi64');
  late final __mm512_permutexvar_epi64 = __mm512_permutexvar_epi64Ptr
      .asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_permutexvar_epi64(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_permutexvar_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_permutexvar_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask8, __m512i,
              __m512i)>>('_mm512_mask_permutexvar_epi64');
  late final __mm512_mask_permutexvar_epi64 = __mm512_mask_permutexvar_epi64Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_permutexvar_epi64(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_permutexvar_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_permutexvar_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask8, __m512i, __m512i)>>(
          '_mm512_maskz_permutexvar_epi64');
  late final __mm512_maskz_permutexvar_epi64 =
      __mm512_maskz_permutexvar_epi64Ptr
          .asFunction<__m512i Function(int, __m512i, __m512i)>();

  _m512d _mm512_permutex2var_pd(
    _m512d arg0,
    __m512i arg1,
    _m512d arg2,
  ) {
    return __mm512_permutex2var_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_permutex2var_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, __m512i, _m512d)>>(
          '_mm512_permutex2var_pd');
  late final __mm512_permutex2var_pd = __mm512_permutex2var_pdPtr
      .asFunction<_m512d Function(_m512d, __m512i, _m512d)>();

  _m512d _mm512_mask_permutex2var_pd(
    _m512d arg0,
    int arg1,
    __m512i arg2,
    _m512d arg3,
  ) {
    return __mm512_mask_permutex2var_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_permutex2var_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(_m512d, __mmask8, __m512i,
              _m512d)>>('_mm512_mask_permutex2var_pd');
  late final __mm512_mask_permutex2var_pd = __mm512_mask_permutex2var_pdPtr
      .asFunction<_m512d Function(_m512d, int, __m512i, _m512d)>();

  _m512d _mm512_mask2_permutex2var_pd(
    _m512d arg0,
    __m512i arg1,
    int arg2,
    _m512d arg3,
  ) {
    return __mm512_mask2_permutex2var_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask2_permutex2var_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(_m512d, __m512i, __mmask8,
              _m512d)>>('_mm512_mask2_permutex2var_pd');
  late final __mm512_mask2_permutex2var_pd = __mm512_mask2_permutex2var_pdPtr
      .asFunction<_m512d Function(_m512d, __m512i, int, _m512d)>();

  _m512d _mm512_maskz_permutex2var_pd(
    int arg0,
    _m512d arg1,
    __m512i arg2,
    _m512d arg3,
  ) {
    return __mm512_maskz_permutex2var_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_permutex2var_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(__mmask8, _m512d, __m512i,
              _m512d)>>('_mm512_maskz_permutex2var_pd');
  late final __mm512_maskz_permutex2var_pd = __mm512_maskz_permutex2var_pdPtr
      .asFunction<_m512d Function(int, _m512d, __m512i, _m512d)>();

  __m512 _mm512_permutex2var_ps(
    __m512 arg0,
    __m512i arg1,
    __m512 arg2,
  ) {
    return __mm512_permutex2var_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_permutex2var_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __m512i, __m512)>>(
          '_mm512_permutex2var_ps');
  late final __mm512_permutex2var_ps = __mm512_permutex2var_psPtr
      .asFunction<__m512 Function(__m512, __m512i, __m512)>();

  __m512 _mm512_mask_permutex2var_ps(
    __m512 arg0,
    int arg1,
    __m512i arg2,
    __m512 arg3,
  ) {
    return __mm512_mask_permutex2var_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_permutex2var_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__m512, __mmask16, __m512i,
              __m512)>>('_mm512_mask_permutex2var_ps');
  late final __mm512_mask_permutex2var_ps = __mm512_mask_permutex2var_psPtr
      .asFunction<__m512 Function(__m512, int, __m512i, __m512)>();

  __m512 _mm512_mask2_permutex2var_ps(
    __m512 arg0,
    __m512i arg1,
    int arg2,
    __m512 arg3,
  ) {
    return __mm512_mask2_permutex2var_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask2_permutex2var_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__m512, __m512i, __mmask16,
              __m512)>>('_mm512_mask2_permutex2var_ps');
  late final __mm512_mask2_permutex2var_ps = __mm512_mask2_permutex2var_psPtr
      .asFunction<__m512 Function(__m512, __m512i, int, __m512)>();

  __m512 _mm512_maskz_permutex2var_ps(
    int arg0,
    __m512 arg1,
    __m512i arg2,
    __m512 arg3,
  ) {
    return __mm512_maskz_permutex2var_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_permutex2var_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__mmask16, __m512, __m512i,
              __m512)>>('_mm512_maskz_permutex2var_ps');
  late final __mm512_maskz_permutex2var_ps = __mm512_maskz_permutex2var_psPtr
      .asFunction<__m512 Function(int, __m512, __m512i, __m512)>();

  __m512i _mm512_permutex2var_epi16(
    __m512i arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_permutex2var_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_permutex2var_epi16Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i, __m512i)>>(
          '_mm512_permutex2var_epi16');
  late final __mm512_permutex2var_epi16 = __mm512_permutex2var_epi16Ptr
      .asFunction<__m512i Function(__m512i, __m512i, __m512i)>();

  __m512i _mm512_mask_permutex2var_epi16(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_permutex2var_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_permutex2var_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask32, __m512i,
              __m512i)>>('_mm512_mask_permutex2var_epi16');
  late final __mm512_mask_permutex2var_epi16 =
      __mm512_mask_permutex2var_epi16Ptr
          .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_mask2_permutex2var_epi16(
    __m512i arg0,
    __m512i arg1,
    int arg2,
    __m512i arg3,
  ) {
    return __mm512_mask2_permutex2var_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask2_permutex2var_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __m512i, __mmask32,
              __m512i)>>('_mm512_mask2_permutex2var_epi16');
  late final __mm512_mask2_permutex2var_epi16 =
      __mm512_mask2_permutex2var_epi16Ptr
          .asFunction<__m512i Function(__m512i, __m512i, int, __m512i)>();

  __m512i _mm512_maskz_permutex2var_epi16(
    int arg0,
    __m512i arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_maskz_permutex2var_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_permutex2var_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__mmask32, __m512i, __m512i,
              __m512i)>>('_mm512_maskz_permutex2var_epi16');
  late final __mm512_maskz_permutex2var_epi16 =
      __mm512_maskz_permutex2var_epi16Ptr
          .asFunction<__m512i Function(int, __m512i, __m512i, __m512i)>();

  __m512i _mm512_permutex2var_epi32(
    __m512i arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_permutex2var_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_permutex2var_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i, __m512i)>>(
          '_mm512_permutex2var_epi32');
  late final __mm512_permutex2var_epi32 = __mm512_permutex2var_epi32Ptr
      .asFunction<__m512i Function(__m512i, __m512i, __m512i)>();

  __m512i _mm512_mask_permutex2var_epi32(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_permutex2var_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_permutex2var_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask16, __m512i,
              __m512i)>>('_mm512_mask_permutex2var_epi32');
  late final __mm512_mask_permutex2var_epi32 =
      __mm512_mask_permutex2var_epi32Ptr
          .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_mask2_permutex2var_epi32(
    __m512i arg0,
    __m512i arg1,
    int arg2,
    __m512i arg3,
  ) {
    return __mm512_mask2_permutex2var_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask2_permutex2var_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __m512i, __mmask16,
              __m512i)>>('_mm512_mask2_permutex2var_epi32');
  late final __mm512_mask2_permutex2var_epi32 =
      __mm512_mask2_permutex2var_epi32Ptr
          .asFunction<__m512i Function(__m512i, __m512i, int, __m512i)>();

  __m512i _mm512_maskz_permutex2var_epi32(
    int arg0,
    __m512i arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_maskz_permutex2var_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_permutex2var_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__mmask16, __m512i, __m512i,
              __m512i)>>('_mm512_maskz_permutex2var_epi32');
  late final __mm512_maskz_permutex2var_epi32 =
      __mm512_maskz_permutex2var_epi32Ptr
          .asFunction<__m512i Function(int, __m512i, __m512i, __m512i)>();

  __m512i _mm512_permutex2var_epi64(
    __m512i arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_permutex2var_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_permutex2var_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i, __m512i)>>(
          '_mm512_permutex2var_epi64');
  late final __mm512_permutex2var_epi64 = __mm512_permutex2var_epi64Ptr
      .asFunction<__m512i Function(__m512i, __m512i, __m512i)>();

  __m512i _mm512_mask_permutex2var_epi64(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_permutex2var_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_permutex2var_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask8, __m512i,
              __m512i)>>('_mm512_mask_permutex2var_epi64');
  late final __mm512_mask_permutex2var_epi64 =
      __mm512_mask_permutex2var_epi64Ptr
          .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_mask2_permutex2var_epi64(
    __m512i arg0,
    __m512i arg1,
    int arg2,
    __m512i arg3,
  ) {
    return __mm512_mask2_permutex2var_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask2_permutex2var_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __m512i, __mmask8,
              __m512i)>>('_mm512_mask2_permutex2var_epi64');
  late final __mm512_mask2_permutex2var_epi64 =
      __mm512_mask2_permutex2var_epi64Ptr
          .asFunction<__m512i Function(__m512i, __m512i, int, __m512i)>();

  __m512i _mm512_maskz_permutex2var_epi64(
    int arg0,
    __m512i arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_maskz_permutex2var_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_permutex2var_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__mmask8, __m512i, __m512i,
              __m512i)>>('_mm512_maskz_permutex2var_epi64');
  late final __mm512_maskz_permutex2var_epi64 =
      __mm512_maskz_permutex2var_epi64Ptr
          .asFunction<__m512i Function(int, __m512i, __m512i, __m512i)>();

  _m512d _mm512_mask_compress_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
  ) {
    return __mm512_mask_compress_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_compress_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, __mmask8, _m512d)>>(
          '_mm512_mask_compress_pd');
  late final __mm512_mask_compress_pd = __mm512_mask_compress_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d)>();

  _m512d _mm512_maskz_compress_pd(
    int arg0,
    _m512d arg1,
  ) {
    return __mm512_maskz_compress_pd(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_compress_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(__mmask8, _m512d)>>(
          '_mm512_maskz_compress_pd');
  late final __mm512_maskz_compress_pd =
      __mm512_maskz_compress_pdPtr.asFunction<_m512d Function(int, _m512d)>();

  __m512 _mm512_mask_compress_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
  ) {
    return __mm512_mask_compress_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_compress_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __mmask16, __m512)>>(
          '_mm512_mask_compress_ps');
  late final __mm512_mask_compress_ps = __mm512_mask_compress_psPtr
      .asFunction<__m512 Function(__m512, int, __m512)>();

  __m512 _mm512_maskz_compress_ps(
    int arg0,
    __m512 arg1,
  ) {
    return __mm512_maskz_compress_ps(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_compress_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__mmask16, __m512)>>(
          '_mm512_maskz_compress_ps');
  late final __mm512_maskz_compress_ps =
      __mm512_maskz_compress_psPtr.asFunction<__m512 Function(int, __m512)>();

  __m512i _mm512_mask_compress_epi8(
    __m512i arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_compress_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_compress_epi8Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__m512i, __mmask64, __m512i)>>(
      '_mm512_mask_compress_epi8');
  late final __mm512_mask_compress_epi8 = __mm512_mask_compress_epi8Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i)>();

  __m512i _mm512_maskz_compress_epi8(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_maskz_compress_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_compress_epi8Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask64, __m512i)>>(
          '_mm512_maskz_compress_epi8');
  late final __mm512_maskz_compress_epi8 = __mm512_maskz_compress_epi8Ptr
      .asFunction<__m512i Function(int, __m512i)>();

  __m512i _mm512_mask_compress_epi16(
    __m512i arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_compress_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_compress_epi16Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__m512i, __mmask32, __m512i)>>(
      '_mm512_mask_compress_epi16');
  late final __mm512_mask_compress_epi16 = __mm512_mask_compress_epi16Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i)>();

  __m512i _mm512_maskz_compress_epi16(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_maskz_compress_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_compress_epi16Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask32, __m512i)>>(
          '_mm512_maskz_compress_epi16');
  late final __mm512_maskz_compress_epi16 = __mm512_maskz_compress_epi16Ptr
      .asFunction<__m512i Function(int, __m512i)>();

  __m512i _mm512_mask_compress_epi32(
    __m512i arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_compress_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_compress_epi32Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__m512i, __mmask16, __m512i)>>(
      '_mm512_mask_compress_epi32');
  late final __mm512_mask_compress_epi32 = __mm512_mask_compress_epi32Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i)>();

  __m512i _mm512_maskz_compress_epi32(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_maskz_compress_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_compress_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask16, __m512i)>>(
          '_mm512_maskz_compress_epi32');
  late final __mm512_maskz_compress_epi32 = __mm512_maskz_compress_epi32Ptr
      .asFunction<__m512i Function(int, __m512i)>();

  __m512i _mm512_mask_compress_epi64(
    __m512i arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_compress_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_compress_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __mmask8, __m512i)>>(
          '_mm512_mask_compress_epi64');
  late final __mm512_mask_compress_epi64 = __mm512_mask_compress_epi64Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i)>();

  __m512i _mm512_maskz_compress_epi64(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_maskz_compress_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_compress_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask8, __m512i)>>(
          '_mm512_maskz_compress_epi64');
  late final __mm512_maskz_compress_epi64 = __mm512_maskz_compress_epi64Ptr
      .asFunction<__m512i Function(int, __m512i)>();

  void _mm512_mask_compressstoreu_pd(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    _m512d arg2,
  ) {
    return __mm512_mask_compressstoreu_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_compressstoreu_pdPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8,
              _m512d)>>('_mm512_mask_compressstoreu_pd');
  late final __mm512_mask_compressstoreu_pd = __mm512_mask_compressstoreu_pdPtr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, int, _m512d)>();

  void _mm512_mask_compressstoreu_ps(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m512 arg2,
  ) {
    return __mm512_mask_compressstoreu_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_compressstoreu_psPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask16,
              __m512)>>('_mm512_mask_compressstoreu_ps');
  late final __mm512_mask_compressstoreu_ps = __mm512_mask_compressstoreu_psPtr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m512)>();

  void _mm512_mask_compressstoreu_epi8(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_compressstoreu_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_compressstoreu_epi8Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask64,
              __m512i)>>('_mm512_mask_compressstoreu_epi8');
  late final __mm512_mask_compressstoreu_epi8 =
      __mm512_mask_compressstoreu_epi8Ptr
          .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m512i)>();

  void _mm512_mask_compressstoreu_epi16(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_compressstoreu_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_compressstoreu_epi16Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask32,
              __m512i)>>('_mm512_mask_compressstoreu_epi16');
  late final __mm512_mask_compressstoreu_epi16 =
      __mm512_mask_compressstoreu_epi16Ptr
          .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m512i)>();

  void _mm512_mask_compressstoreu_epi32(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_compressstoreu_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_compressstoreu_epi32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask16,
              __m512i)>>('_mm512_mask_compressstoreu_epi32');
  late final __mm512_mask_compressstoreu_epi32 =
      __mm512_mask_compressstoreu_epi32Ptr
          .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m512i)>();

  void _mm512_mask_compressstoreu_epi64(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_compressstoreu_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_compressstoreu_epi64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8,
              __m512i)>>('_mm512_mask_compressstoreu_epi64');
  late final __mm512_mask_compressstoreu_epi64 =
      __mm512_mask_compressstoreu_epi64Ptr
          .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m512i)>();

  _m512d _mm512_mask_expand_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
  ) {
    return __mm512_mask_expand_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_expand_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, __mmask8, _m512d)>>(
          '_mm512_mask_expand_pd');
  late final __mm512_mask_expand_pd = __mm512_mask_expand_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d)>();

  _m512d _mm512_maskz_expand_pd(
    int arg0,
    _m512d arg1,
  ) {
    return __mm512_maskz_expand_pd(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_expand_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(__mmask8, _m512d)>>(
          '_mm512_maskz_expand_pd');
  late final __mm512_maskz_expand_pd =
      __mm512_maskz_expand_pdPtr.asFunction<_m512d Function(int, _m512d)>();

  __m512 _mm512_mask_expand_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
  ) {
    return __mm512_mask_expand_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_expand_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __mmask16, __m512)>>(
          '_mm512_mask_expand_ps');
  late final __mm512_mask_expand_ps = __mm512_mask_expand_psPtr
      .asFunction<__m512 Function(__m512, int, __m512)>();

  __m512 _mm512_maskz_expand_ps(
    int arg0,
    __m512 arg1,
  ) {
    return __mm512_maskz_expand_ps(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_expand_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__mmask16, __m512)>>(
          '_mm512_maskz_expand_ps');
  late final __mm512_maskz_expand_ps =
      __mm512_maskz_expand_psPtr.asFunction<__m512 Function(int, __m512)>();

  __m512i _mm512_mask_expand_epi8(
    __m512i arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_expand_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_expand_epi8Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__m512i, __mmask64, __m512i)>>(
      '_mm512_mask_expand_epi8');
  late final __mm512_mask_expand_epi8 = __mm512_mask_expand_epi8Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i)>();

  __m512i _mm512_maskz_expand_epi8(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_maskz_expand_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_expand_epi8Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask64, __m512i)>>(
          '_mm512_maskz_expand_epi8');
  late final __mm512_maskz_expand_epi8 =
      __mm512_maskz_expand_epi8Ptr.asFunction<__m512i Function(int, __m512i)>();

  __m512i _mm512_mask_expand_epi16(
    __m512i arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_expand_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_expand_epi16Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__m512i, __mmask32, __m512i)>>(
      '_mm512_mask_expand_epi16');
  late final __mm512_mask_expand_epi16 = __mm512_mask_expand_epi16Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i)>();

  __m512i _mm512_maskz_expand_epi16(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_maskz_expand_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_expand_epi16Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask32, __m512i)>>(
          '_mm512_maskz_expand_epi16');
  late final __mm512_maskz_expand_epi16 = __mm512_maskz_expand_epi16Ptr
      .asFunction<__m512i Function(int, __m512i)>();

  __m512i _mm512_mask_expand_epi32(
    __m512i arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_expand_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_expand_epi32Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__m512i, __mmask16, __m512i)>>(
      '_mm512_mask_expand_epi32');
  late final __mm512_mask_expand_epi32 = __mm512_mask_expand_epi32Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i)>();

  __m512i _mm512_maskz_expand_epi32(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_maskz_expand_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_expand_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask16, __m512i)>>(
          '_mm512_maskz_expand_epi32');
  late final __mm512_maskz_expand_epi32 = __mm512_maskz_expand_epi32Ptr
      .asFunction<__m512i Function(int, __m512i)>();

  __m512i _mm512_mask_expand_epi64(
    __m512i arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_expand_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_expand_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __mmask8, __m512i)>>(
          '_mm512_mask_expand_epi64');
  late final __mm512_mask_expand_epi64 = __mm512_mask_expand_epi64Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i)>();

  __m512i _mm512_maskz_expand_epi64(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_maskz_expand_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_expand_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask8, __m512i)>>(
          '_mm512_maskz_expand_epi64');
  late final __mm512_maskz_expand_epi64 = __mm512_maskz_expand_epi64Ptr
      .asFunction<__m512i Function(int, __m512i)>();

  _m512d _mm512_mask_expandloadu_pd(
    _m512d arg0,
    int arg1,
    ffi.Pointer<ffi.Void> arg2,
  ) {
    return __mm512_mask_expandloadu_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_expandloadu_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(_m512d, __mmask8,
              ffi.Pointer<ffi.Void>)>>('_mm512_mask_expandloadu_pd');
  late final __mm512_mask_expandloadu_pd = __mm512_mask_expandloadu_pdPtr
      .asFunction<_m512d Function(_m512d, int, ffi.Pointer<ffi.Void>)>();

  _m512d _mm512_maskz_expandloadu_pd(
    int arg0,
    ffi.Pointer<ffi.Void> arg1,
  ) {
    return __mm512_maskz_expandloadu_pd(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_expandloadu_pdPtr = _lookup<
          ffi.NativeFunction<_m512d Function(__mmask8, ffi.Pointer<ffi.Void>)>>(
      '_mm512_maskz_expandloadu_pd');
  late final __mm512_maskz_expandloadu_pd = __mm512_maskz_expandloadu_pdPtr
      .asFunction<_m512d Function(int, ffi.Pointer<ffi.Void>)>();

  __m512 _mm512_mask_expandloadu_ps(
    __m512 arg0,
    int arg1,
    ffi.Pointer<ffi.Void> arg2,
  ) {
    return __mm512_mask_expandloadu_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_expandloadu_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__m512, __mmask16,
              ffi.Pointer<ffi.Void>)>>('_mm512_mask_expandloadu_ps');
  late final __mm512_mask_expandloadu_ps = __mm512_mask_expandloadu_psPtr
      .asFunction<__m512 Function(__m512, int, ffi.Pointer<ffi.Void>)>();

  __m512 _mm512_maskz_expandloadu_ps(
    int arg0,
    ffi.Pointer<ffi.Void> arg1,
  ) {
    return __mm512_maskz_expandloadu_ps(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_expandloadu_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__mmask16,
              ffi.Pointer<ffi.Void>)>>('_mm512_maskz_expandloadu_ps');
  late final __mm512_maskz_expandloadu_ps = __mm512_maskz_expandloadu_psPtr
      .asFunction<__m512 Function(int, ffi.Pointer<ffi.Void>)>();

  __m512i _mm512_mask_expandloadu_epi8(
    __m512i arg0,
    int arg1,
    ffi.Pointer<ffi.Void> arg2,
  ) {
    return __mm512_mask_expandloadu_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_expandloadu_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask64,
              ffi.Pointer<ffi.Void>)>>('_mm512_mask_expandloadu_epi8');
  late final __mm512_mask_expandloadu_epi8 = __mm512_mask_expandloadu_epi8Ptr
      .asFunction<__m512i Function(__m512i, int, ffi.Pointer<ffi.Void>)>();

  __m512i _mm512_maskz_expandloadu_epi8(
    int arg0,
    ffi.Pointer<ffi.Void> arg1,
  ) {
    return __mm512_maskz_expandloadu_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_expandloadu_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__mmask64,
              ffi.Pointer<ffi.Void>)>>('_mm512_maskz_expandloadu_epi8');
  late final __mm512_maskz_expandloadu_epi8 = __mm512_maskz_expandloadu_epi8Ptr
      .asFunction<__m512i Function(int, ffi.Pointer<ffi.Void>)>();

  __m512i _mm512_mask_expandloadu_epi16(
    __m512i arg0,
    int arg1,
    ffi.Pointer<ffi.Void> arg2,
  ) {
    return __mm512_mask_expandloadu_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_expandloadu_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask32,
              ffi.Pointer<ffi.Void>)>>('_mm512_mask_expandloadu_epi16');
  late final __mm512_mask_expandloadu_epi16 = __mm512_mask_expandloadu_epi16Ptr
      .asFunction<__m512i Function(__m512i, int, ffi.Pointer<ffi.Void>)>();

  __m512i _mm512_maskz_expandloadu_epi16(
    int arg0,
    ffi.Pointer<ffi.Void> arg1,
  ) {
    return __mm512_maskz_expandloadu_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_expandloadu_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__mmask32,
              ffi.Pointer<ffi.Void>)>>('_mm512_maskz_expandloadu_epi16');
  late final __mm512_maskz_expandloadu_epi16 =
      __mm512_maskz_expandloadu_epi16Ptr
          .asFunction<__m512i Function(int, ffi.Pointer<ffi.Void>)>();

  __m512i _mm512_mask_expandloadu_epi32(
    __m512i arg0,
    int arg1,
    ffi.Pointer<ffi.Void> arg2,
  ) {
    return __mm512_mask_expandloadu_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_expandloadu_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask16,
              ffi.Pointer<ffi.Void>)>>('_mm512_mask_expandloadu_epi32');
  late final __mm512_mask_expandloadu_epi32 = __mm512_mask_expandloadu_epi32Ptr
      .asFunction<__m512i Function(__m512i, int, ffi.Pointer<ffi.Void>)>();

  __m512i _mm512_maskz_expandloadu_epi32(
    int arg0,
    ffi.Pointer<ffi.Void> arg1,
  ) {
    return __mm512_maskz_expandloadu_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_expandloadu_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__mmask16,
              ffi.Pointer<ffi.Void>)>>('_mm512_maskz_expandloadu_epi32');
  late final __mm512_maskz_expandloadu_epi32 =
      __mm512_maskz_expandloadu_epi32Ptr
          .asFunction<__m512i Function(int, ffi.Pointer<ffi.Void>)>();

  __m512i _mm512_mask_expandloadu_epi64(
    __m512i arg0,
    int arg1,
    ffi.Pointer<ffi.Void> arg2,
  ) {
    return __mm512_mask_expandloadu_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_expandloadu_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask8,
              ffi.Pointer<ffi.Void>)>>('_mm512_mask_expandloadu_epi64');
  late final __mm512_mask_expandloadu_epi64 = __mm512_mask_expandloadu_epi64Ptr
      .asFunction<__m512i Function(__m512i, int, ffi.Pointer<ffi.Void>)>();

  __m512i _mm512_maskz_expandloadu_epi64(
    int arg0,
    ffi.Pointer<ffi.Void> arg1,
  ) {
    return __mm512_maskz_expandloadu_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_expandloadu_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__mmask8,
              ffi.Pointer<ffi.Void>)>>('_mm512_maskz_expandloadu_epi64');
  late final __mm512_maskz_expandloadu_epi64 =
      __mm512_maskz_expandloadu_epi64Ptr
          .asFunction<__m512i Function(int, ffi.Pointer<ffi.Void>)>();

  __m512i _mm512_ternarylogic_epi32(
    __m512i arg0,
    __m512i arg1,
    __m512i arg2,
    int arg3,
  ) {
    return __mm512_ternarylogic_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_ternarylogic_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __m512i, __m512i,
              ffi.Int32)>>('_mm512_ternarylogic_epi32');
  late final __mm512_ternarylogic_epi32 = __mm512_ternarylogic_epi32Ptr
      .asFunction<__m512i Function(__m512i, __m512i, __m512i, int)>();

  __m512i _mm512_mask_ternarylogic_epi32(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
    int arg4,
  ) {
    return __mm512_mask_ternarylogic_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_ternarylogic_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask16, __m512i, __m512i,
              ffi.Int32)>>('_mm512_mask_ternarylogic_epi32');
  late final __mm512_mask_ternarylogic_epi32 =
      __mm512_mask_ternarylogic_epi32Ptr
          .asFunction<__m512i Function(__m512i, int, __m512i, __m512i, int)>();

  __m512i _mm512_maskz_ternarylogic_epi32(
    int arg0,
    __m512i arg1,
    __m512i arg2,
    __m512i arg3,
    int arg4,
  ) {
    return __mm512_maskz_ternarylogic_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_maskz_ternarylogic_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__mmask16, __m512i, __m512i, __m512i,
              ffi.Int32)>>('_mm512_maskz_ternarylogic_epi32');
  late final __mm512_maskz_ternarylogic_epi32 =
      __mm512_maskz_ternarylogic_epi32Ptr
          .asFunction<__m512i Function(int, __m512i, __m512i, __m512i, int)>();

  __m512i _mm512_ternarylogic_epi64(
    __m512i arg0,
    __m512i arg1,
    __m512i arg2,
    int arg3,
  ) {
    return __mm512_ternarylogic_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_ternarylogic_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __m512i, __m512i,
              ffi.Int32)>>('_mm512_ternarylogic_epi64');
  late final __mm512_ternarylogic_epi64 = __mm512_ternarylogic_epi64Ptr
      .asFunction<__m512i Function(__m512i, __m512i, __m512i, int)>();

  __m512i _mm512_mask_ternarylogic_epi64(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
    int arg4,
  ) {
    return __mm512_mask_ternarylogic_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_ternarylogic_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask8, __m512i, __m512i,
              ffi.Int32)>>('_mm512_mask_ternarylogic_epi64');
  late final __mm512_mask_ternarylogic_epi64 =
      __mm512_mask_ternarylogic_epi64Ptr
          .asFunction<__m512i Function(__m512i, int, __m512i, __m512i, int)>();

  __m512i _mm512_maskz_ternarylogic_epi64(
    int arg0,
    __m512i arg1,
    __m512i arg2,
    __m512i arg3,
    int arg4,
  ) {
    return __mm512_maskz_ternarylogic_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_maskz_ternarylogic_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__mmask8, __m512i, __m512i, __m512i,
              ffi.Int32)>>('_mm512_maskz_ternarylogic_epi64');
  late final __mm512_maskz_ternarylogic_epi64 =
      __mm512_maskz_ternarylogic_epi64Ptr
          .asFunction<__m512i Function(int, __m512i, __m512i, __m512i, int)>();

  __m512i _mm512_conflict_epi32(
    __m512i arg0,
  ) {
    return __mm512_conflict_epi32(
      arg0,
    );
  }

  late final __mm512_conflict_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i)>>(
          '_mm512_conflict_epi32');
  late final __mm512_conflict_epi32 =
      __mm512_conflict_epi32Ptr.asFunction<__m512i Function(__m512i)>();

  __m512i _mm512_mask_conflict_epi32(
    __m512i arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_conflict_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_conflict_epi32Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__m512i, __mmask16, __m512i)>>(
      '_mm512_mask_conflict_epi32');
  late final __mm512_mask_conflict_epi32 = __mm512_mask_conflict_epi32Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i)>();

  __m512i _mm512_maskz_conflict_epi32(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_maskz_conflict_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_conflict_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask16, __m512i)>>(
          '_mm512_maskz_conflict_epi32');
  late final __mm512_maskz_conflict_epi32 = __mm512_maskz_conflict_epi32Ptr
      .asFunction<__m512i Function(int, __m512i)>();

  __m512i _mm512_conflict_epi64(
    __m512i arg0,
  ) {
    return __mm512_conflict_epi64(
      arg0,
    );
  }

  late final __mm512_conflict_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i)>>(
          '_mm512_conflict_epi64');
  late final __mm512_conflict_epi64 =
      __mm512_conflict_epi64Ptr.asFunction<__m512i Function(__m512i)>();

  __m512i _mm512_mask_conflict_epi64(
    __m512i arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_conflict_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_conflict_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __mmask8, __m512i)>>(
          '_mm512_mask_conflict_epi64');
  late final __mm512_mask_conflict_epi64 = __mm512_mask_conflict_epi64Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i)>();

  __m512i _mm512_maskz_conflict_epi64(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_maskz_conflict_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_conflict_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask8, __m512i)>>(
          '_mm512_maskz_conflict_epi64');
  late final __mm512_maskz_conflict_epi64 = __mm512_maskz_conflict_epi64Ptr
      .asFunction<__m512i Function(int, __m512i)>();

  __m512i _mm512_lzcnt_epi32(
    __m512i arg0,
  ) {
    return __mm512_lzcnt_epi32(
      arg0,
    );
  }

  late final __mm512_lzcnt_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i)>>(
          '_mm512_lzcnt_epi32');
  late final __mm512_lzcnt_epi32 =
      __mm512_lzcnt_epi32Ptr.asFunction<__m512i Function(__m512i)>();

  __m512i _mm512_mask_lzcnt_epi32(
    __m512i arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_lzcnt_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_lzcnt_epi32Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__m512i, __mmask16, __m512i)>>(
      '_mm512_mask_lzcnt_epi32');
  late final __mm512_mask_lzcnt_epi32 = __mm512_mask_lzcnt_epi32Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i)>();

  __m512i _mm512_maskz_lzcnt_epi32(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_maskz_lzcnt_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_lzcnt_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask16, __m512i)>>(
          '_mm512_maskz_lzcnt_epi32');
  late final __mm512_maskz_lzcnt_epi32 =
      __mm512_maskz_lzcnt_epi32Ptr.asFunction<__m512i Function(int, __m512i)>();

  __m512i _mm512_lzcnt_epi64(
    __m512i arg0,
  ) {
    return __mm512_lzcnt_epi64(
      arg0,
    );
  }

  late final __mm512_lzcnt_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i)>>(
          '_mm512_lzcnt_epi64');
  late final __mm512_lzcnt_epi64 =
      __mm512_lzcnt_epi64Ptr.asFunction<__m512i Function(__m512i)>();

  __m512i _mm512_mask_lzcnt_epi64(
    __m512i arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_lzcnt_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_lzcnt_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __mmask8, __m512i)>>(
          '_mm512_mask_lzcnt_epi64');
  late final __mm512_mask_lzcnt_epi64 = __mm512_mask_lzcnt_epi64Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i)>();

  __m512i _mm512_maskz_lzcnt_epi64(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_maskz_lzcnt_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_lzcnt_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask8, __m512i)>>(
          '_mm512_maskz_lzcnt_epi64');
  late final __mm512_maskz_lzcnt_epi64 =
      __mm512_maskz_lzcnt_epi64Ptr.asFunction<__m512i Function(int, __m512i)>();

  __m512i _mm512_avg_epu8(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_avg_epu8(
      arg0,
      arg1,
    );
  }

  late final __mm512_avg_epu8Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_avg_epu8');
  late final __mm512_avg_epu8 =
      __mm512_avg_epu8Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_avg_epu8(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_avg_epu8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_avg_epu8Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask64, __m512i, __m512i)>>('_mm512_mask_avg_epu8');
  late final __mm512_mask_avg_epu8 = __mm512_mask_avg_epu8Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_avg_epu8(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_avg_epu8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_avg_epu8Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask64, __m512i, __m512i)>>(
      '_mm512_maskz_avg_epu8');
  late final __mm512_maskz_avg_epu8 = __mm512_maskz_avg_epu8Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_avg_epu16(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_avg_epu16(
      arg0,
      arg1,
    );
  }

  late final __mm512_avg_epu16Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_avg_epu16');
  late final __mm512_avg_epu16 =
      __mm512_avg_epu16Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_avg_epu16(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_avg_epu16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_avg_epu16Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask32, __m512i, __m512i)>>('_mm512_mask_avg_epu16');
  late final __mm512_mask_avg_epu16 = __mm512_mask_avg_epu16Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_avg_epu16(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_avg_epu16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_avg_epu16Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask32, __m512i, __m512i)>>(
      '_mm512_maskz_avg_epu16');
  late final __mm512_maskz_avg_epu16 = __mm512_maskz_avg_epu16Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_sad_epu8(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_sad_epu8(
      arg0,
      arg1,
    );
  }

  late final __mm512_sad_epu8Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_sad_epu8');
  late final __mm512_sad_epu8 =
      __mm512_sad_epu8Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_dbsad_epu8(
    __m512i arg0,
    __m512i arg1,
    int arg2,
  ) {
    return __mm512_dbsad_epu8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_dbsad_epu8Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__m512i, __m512i, ffi.Int32)>>(
      '_mm512_dbsad_epu8');
  late final __mm512_dbsad_epu8 = __mm512_dbsad_epu8Ptr
      .asFunction<__m512i Function(__m512i, __m512i, int)>();

  __m512i _mm512_mask_dbsad_epu8(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
    int arg4,
  ) {
    return __mm512_mask_dbsad_epu8(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_dbsad_epu8Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask32, __m512i, __m512i,
              ffi.Int32)>>('_mm512_mask_dbsad_epu8');
  late final __mm512_mask_dbsad_epu8 = __mm512_mask_dbsad_epu8Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i, int)>();

  __m512i _mm512_maskz_dbsad_epu8(
    int arg0,
    __m512i arg1,
    __m512i arg2,
    int arg3,
  ) {
    return __mm512_maskz_dbsad_epu8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_dbsad_epu8Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__mmask32, __m512i, __m512i,
              ffi.Int32)>>('_mm512_maskz_dbsad_epu8');
  late final __mm512_maskz_dbsad_epu8 = __mm512_maskz_dbsad_epu8Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i, int)>();

  double _mm512_reduce_add_ps(
    __m512 arg0,
  ) {
    return __mm512_reduce_add_ps(
      arg0,
    );
  }

  late final __mm512_reduce_add_psPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(__m512)>>(
          '_mm512_reduce_add_ps');
  late final __mm512_reduce_add_ps =
      __mm512_reduce_add_psPtr.asFunction<double Function(__m512)>();

  double _mm512_mask_reduce_add_ps(
    int arg0,
    __m512 arg1,
  ) {
    return __mm512_mask_reduce_add_ps(
      arg0,
      arg1,
    );
  }

  late final __mm512_mask_reduce_add_psPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(__mmask16, __m512)>>(
          '_mm512_mask_reduce_add_ps');
  late final __mm512_mask_reduce_add_ps =
      __mm512_mask_reduce_add_psPtr.asFunction<double Function(int, __m512)>();

  double _mm512_reduce_add_pd(
    _m512d arg0,
  ) {
    return __mm512_reduce_add_pd(
      arg0,
    );
  }

  late final __mm512_reduce_add_pdPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(_m512d)>>(
          '_mm512_reduce_add_pd');
  late final __mm512_reduce_add_pd =
      __mm512_reduce_add_pdPtr.asFunction<double Function(_m512d)>();

  double _mm512_mask_reduce_add_pd(
    int arg0,
    _m512d arg1,
  ) {
    return __mm512_mask_reduce_add_pd(
      arg0,
      arg1,
    );
  }

  late final __mm512_mask_reduce_add_pdPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(__mmask8, _m512d)>>(
          '_mm512_mask_reduce_add_pd');
  late final __mm512_mask_reduce_add_pd =
      __mm512_mask_reduce_add_pdPtr.asFunction<double Function(int, _m512d)>();

  int _mm512_reduce_add_epi8(
    __m512i arg0,
  ) {
    return __mm512_reduce_add_epi8(
      arg0,
    );
  }

  late final __mm512_reduce_add_epi8Ptr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(__m512i)>>(
          '_mm512_reduce_add_epi8');
  late final __mm512_reduce_add_epi8 =
      __mm512_reduce_add_epi8Ptr.asFunction<int Function(__m512i)>();

  int _mm512_mask_reduce_add_epi8(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_mask_reduce_add_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm512_mask_reduce_add_epi8Ptr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(__mmask64, __m512i)>>(
          '_mm512_mask_reduce_add_epi8');
  late final __mm512_mask_reduce_add_epi8 =
      __mm512_mask_reduce_add_epi8Ptr.asFunction<int Function(int, __m512i)>();

  int _mm512_reduce_add_epi16(
    __m512i arg0,
  ) {
    return __mm512_reduce_add_epi16(
      arg0,
    );
  }

  late final __mm512_reduce_add_epi16Ptr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(__m512i)>>(
          '_mm512_reduce_add_epi16');
  late final __mm512_reduce_add_epi16 =
      __mm512_reduce_add_epi16Ptr.asFunction<int Function(__m512i)>();

  int _mm512_mask_reduce_add_epi16(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_mask_reduce_add_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm512_mask_reduce_add_epi16Ptr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(__mmask32, __m512i)>>(
          '_mm512_mask_reduce_add_epi16');
  late final __mm512_mask_reduce_add_epi16 =
      __mm512_mask_reduce_add_epi16Ptr.asFunction<int Function(int, __m512i)>();

  int _mm512_reduce_add_epi32(
    __m512i arg0,
  ) {
    return __mm512_reduce_add_epi32(
      arg0,
    );
  }

  late final __mm512_reduce_add_epi32Ptr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(__m512i)>>(
          '_mm512_reduce_add_epi32');
  late final __mm512_reduce_add_epi32 =
      __mm512_reduce_add_epi32Ptr.asFunction<int Function(__m512i)>();

  int _mm512_mask_reduce_add_epi32(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_mask_reduce_add_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_mask_reduce_add_epi32Ptr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(__mmask16, __m512i)>>(
          '_mm512_mask_reduce_add_epi32');
  late final __mm512_mask_reduce_add_epi32 =
      __mm512_mask_reduce_add_epi32Ptr.asFunction<int Function(int, __m512i)>();

  int _mm512_reduce_add_epi64(
    __m512i arg0,
  ) {
    return __mm512_reduce_add_epi64(
      arg0,
    );
  }

  late final __mm512_reduce_add_epi64Ptr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(__m512i)>>(
          '_mm512_reduce_add_epi64');
  late final __mm512_reduce_add_epi64 =
      __mm512_reduce_add_epi64Ptr.asFunction<int Function(__m512i)>();

  int _mm512_mask_reduce_add_epi64(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_mask_reduce_add_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm512_mask_reduce_add_epi64Ptr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(__mmask8, __m512i)>>(
          '_mm512_mask_reduce_add_epi64');
  late final __mm512_mask_reduce_add_epi64 =
      __mm512_mask_reduce_add_epi64Ptr.asFunction<int Function(int, __m512i)>();

  int _mm512_reduce_add_epu8(
    __m512i arg0,
  ) {
    return __mm512_reduce_add_epu8(
      arg0,
    );
  }

  late final __mm512_reduce_add_epu8Ptr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(__m512i)>>(
          '_mm512_reduce_add_epu8');
  late final __mm512_reduce_add_epu8 =
      __mm512_reduce_add_epu8Ptr.asFunction<int Function(__m512i)>();

  int _mm512_mask_reduce_add_epu8(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_mask_reduce_add_epu8(
      arg0,
      arg1,
    );
  }

  late final __mm512_mask_reduce_add_epu8Ptr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(__mmask64, __m512i)>>(
          '_mm512_mask_reduce_add_epu8');
  late final __mm512_mask_reduce_add_epu8 =
      __mm512_mask_reduce_add_epu8Ptr.asFunction<int Function(int, __m512i)>();

  int _mm512_reduce_add_epu16(
    __m512i arg0,
  ) {
    return __mm512_reduce_add_epu16(
      arg0,
    );
  }

  late final __mm512_reduce_add_epu16Ptr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(__m512i)>>(
          '_mm512_reduce_add_epu16');
  late final __mm512_reduce_add_epu16 =
      __mm512_reduce_add_epu16Ptr.asFunction<int Function(__m512i)>();

  int _mm512_mask_reduce_add_epu16(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_mask_reduce_add_epu16(
      arg0,
      arg1,
    );
  }

  late final __mm512_mask_reduce_add_epu16Ptr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(__mmask32, __m512i)>>(
          '_mm512_mask_reduce_add_epu16');
  late final __mm512_mask_reduce_add_epu16 =
      __mm512_mask_reduce_add_epu16Ptr.asFunction<int Function(int, __m512i)>();

  double _mm512_reduce_mul_ps(
    __m512 arg0,
  ) {
    return __mm512_reduce_mul_ps(
      arg0,
    );
  }

  late final __mm512_reduce_mul_psPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(__m512)>>(
          '_mm512_reduce_mul_ps');
  late final __mm512_reduce_mul_ps =
      __mm512_reduce_mul_psPtr.asFunction<double Function(__m512)>();

  double _mm512_mask_reduce_mul_ps(
    int arg0,
    __m512 arg1,
  ) {
    return __mm512_mask_reduce_mul_ps(
      arg0,
      arg1,
    );
  }

  late final __mm512_mask_reduce_mul_psPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(__mmask16, __m512)>>(
          '_mm512_mask_reduce_mul_ps');
  late final __mm512_mask_reduce_mul_ps =
      __mm512_mask_reduce_mul_psPtr.asFunction<double Function(int, __m512)>();

  double _mm512_reduce_mul_pd(
    _m512d arg0,
  ) {
    return __mm512_reduce_mul_pd(
      arg0,
    );
  }

  late final __mm512_reduce_mul_pdPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(_m512d)>>(
          '_mm512_reduce_mul_pd');
  late final __mm512_reduce_mul_pd =
      __mm512_reduce_mul_pdPtr.asFunction<double Function(_m512d)>();

  double _mm512_mask_reduce_mul_pd(
    int arg0,
    _m512d arg1,
  ) {
    return __mm512_mask_reduce_mul_pd(
      arg0,
      arg1,
    );
  }

  late final __mm512_mask_reduce_mul_pdPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(__mmask8, _m512d)>>(
          '_mm512_mask_reduce_mul_pd');
  late final __mm512_mask_reduce_mul_pd =
      __mm512_mask_reduce_mul_pdPtr.asFunction<double Function(int, _m512d)>();

  int _mm512_reduce_mul_epi32(
    __m512i arg0,
  ) {
    return __mm512_reduce_mul_epi32(
      arg0,
    );
  }

  late final __mm512_reduce_mul_epi32Ptr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(__m512i)>>(
          '_mm512_reduce_mul_epi32');
  late final __mm512_reduce_mul_epi32 =
      __mm512_reduce_mul_epi32Ptr.asFunction<int Function(__m512i)>();

  int _mm512_mask_reduce_mul_epi32(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_mask_reduce_mul_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_mask_reduce_mul_epi32Ptr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(__mmask16, __m512i)>>(
          '_mm512_mask_reduce_mul_epi32');
  late final __mm512_mask_reduce_mul_epi32 =
      __mm512_mask_reduce_mul_epi32Ptr.asFunction<int Function(int, __m512i)>();

  int _mm512_reduce_mul_epi64(
    __m512i arg0,
  ) {
    return __mm512_reduce_mul_epi64(
      arg0,
    );
  }

  late final __mm512_reduce_mul_epi64Ptr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(__m512i)>>(
          '_mm512_reduce_mul_epi64');
  late final __mm512_reduce_mul_epi64 =
      __mm512_reduce_mul_epi64Ptr.asFunction<int Function(__m512i)>();

  int _mm512_mask_reduce_mul_epi64(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_mask_reduce_mul_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm512_mask_reduce_mul_epi64Ptr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(__mmask8, __m512i)>>(
          '_mm512_mask_reduce_mul_epi64');
  late final __mm512_mask_reduce_mul_epi64 =
      __mm512_mask_reduce_mul_epi64Ptr.asFunction<int Function(int, __m512i)>();

  double _mm512_reduce_min_ps(
    __m512 arg0,
  ) {
    return __mm512_reduce_min_ps(
      arg0,
    );
  }

  late final __mm512_reduce_min_psPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(__m512)>>(
          '_mm512_reduce_min_ps');
  late final __mm512_reduce_min_ps =
      __mm512_reduce_min_psPtr.asFunction<double Function(__m512)>();

  double _mm512_mask_reduce_min_ps(
    int arg0,
    __m512 arg1,
  ) {
    return __mm512_mask_reduce_min_ps(
      arg0,
      arg1,
    );
  }

  late final __mm512_mask_reduce_min_psPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(__mmask16, __m512)>>(
          '_mm512_mask_reduce_min_ps');
  late final __mm512_mask_reduce_min_ps =
      __mm512_mask_reduce_min_psPtr.asFunction<double Function(int, __m512)>();

  double _mm512_reduce_min_pd(
    _m512d arg0,
  ) {
    return __mm512_reduce_min_pd(
      arg0,
    );
  }

  late final __mm512_reduce_min_pdPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(_m512d)>>(
          '_mm512_reduce_min_pd');
  late final __mm512_reduce_min_pd =
      __mm512_reduce_min_pdPtr.asFunction<double Function(_m512d)>();

  double _mm512_mask_reduce_min_pd(
    int arg0,
    _m512d arg1,
  ) {
    return __mm512_mask_reduce_min_pd(
      arg0,
      arg1,
    );
  }

  late final __mm512_mask_reduce_min_pdPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(__mmask8, _m512d)>>(
          '_mm512_mask_reduce_min_pd');
  late final __mm512_mask_reduce_min_pd =
      __mm512_mask_reduce_min_pdPtr.asFunction<double Function(int, _m512d)>();

  int _mm512_reduce_min_epi32(
    __m512i arg0,
  ) {
    return __mm512_reduce_min_epi32(
      arg0,
    );
  }

  late final __mm512_reduce_min_epi32Ptr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(__m512i)>>(
          '_mm512_reduce_min_epi32');
  late final __mm512_reduce_min_epi32 =
      __mm512_reduce_min_epi32Ptr.asFunction<int Function(__m512i)>();

  int _mm512_mask_reduce_min_epi32(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_mask_reduce_min_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_mask_reduce_min_epi32Ptr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(__mmask16, __m512i)>>(
          '_mm512_mask_reduce_min_epi32');
  late final __mm512_mask_reduce_min_epi32 =
      __mm512_mask_reduce_min_epi32Ptr.asFunction<int Function(int, __m512i)>();

  int _mm512_reduce_min_epi64(
    __m512i arg0,
  ) {
    return __mm512_reduce_min_epi64(
      arg0,
    );
  }

  late final __mm512_reduce_min_epi64Ptr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(__m512i)>>(
          '_mm512_reduce_min_epi64');
  late final __mm512_reduce_min_epi64 =
      __mm512_reduce_min_epi64Ptr.asFunction<int Function(__m512i)>();

  int _mm512_mask_reduce_min_epi64(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_mask_reduce_min_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm512_mask_reduce_min_epi64Ptr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(__mmask8, __m512i)>>(
          '_mm512_mask_reduce_min_epi64');
  late final __mm512_mask_reduce_min_epi64 =
      __mm512_mask_reduce_min_epi64Ptr.asFunction<int Function(int, __m512i)>();

  int _mm512_reduce_min_epu32(
    __m512i arg0,
  ) {
    return __mm512_reduce_min_epu32(
      arg0,
    );
  }

  late final __mm512_reduce_min_epu32Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint32 Function(__m512i)>>(
          '_mm512_reduce_min_epu32');
  late final __mm512_reduce_min_epu32 =
      __mm512_reduce_min_epu32Ptr.asFunction<int Function(__m512i)>();

  int _mm512_mask_reduce_min_epu32(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_mask_reduce_min_epu32(
      arg0,
      arg1,
    );
  }

  late final __mm512_mask_reduce_min_epu32Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint32 Function(__mmask16, __m512i)>>(
          '_mm512_mask_reduce_min_epu32');
  late final __mm512_mask_reduce_min_epu32 =
      __mm512_mask_reduce_min_epu32Ptr.asFunction<int Function(int, __m512i)>();

  int _mm512_reduce_min_epu64(
    __m512i arg0,
  ) {
    return __mm512_reduce_min_epu64(
      arg0,
    );
  }

  late final __mm512_reduce_min_epu64Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function(__m512i)>>(
          '_mm512_reduce_min_epu64');
  late final __mm512_reduce_min_epu64 =
      __mm512_reduce_min_epu64Ptr.asFunction<int Function(__m512i)>();

  int _mm512_mask_reduce_min_epu64(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_mask_reduce_min_epu64(
      arg0,
      arg1,
    );
  }

  late final __mm512_mask_reduce_min_epu64Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function(__mmask8, __m512i)>>(
          '_mm512_mask_reduce_min_epu64');
  late final __mm512_mask_reduce_min_epu64 =
      __mm512_mask_reduce_min_epu64Ptr.asFunction<int Function(int, __m512i)>();

  double _mm512_reduce_max_ps(
    __m512 arg0,
  ) {
    return __mm512_reduce_max_ps(
      arg0,
    );
  }

  late final __mm512_reduce_max_psPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(__m512)>>(
          '_mm512_reduce_max_ps');
  late final __mm512_reduce_max_ps =
      __mm512_reduce_max_psPtr.asFunction<double Function(__m512)>();

  double _mm512_mask_reduce_max_ps(
    int arg0,
    __m512 arg1,
  ) {
    return __mm512_mask_reduce_max_ps(
      arg0,
      arg1,
    );
  }

  late final __mm512_mask_reduce_max_psPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(__mmask16, __m512)>>(
          '_mm512_mask_reduce_max_ps');
  late final __mm512_mask_reduce_max_ps =
      __mm512_mask_reduce_max_psPtr.asFunction<double Function(int, __m512)>();

  double _mm512_reduce_max_pd(
    _m512d arg0,
  ) {
    return __mm512_reduce_max_pd(
      arg0,
    );
  }

  late final __mm512_reduce_max_pdPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(_m512d)>>(
          '_mm512_reduce_max_pd');
  late final __mm512_reduce_max_pd =
      __mm512_reduce_max_pdPtr.asFunction<double Function(_m512d)>();

  double _mm512_mask_reduce_max_pd(
    int arg0,
    _m512d arg1,
  ) {
    return __mm512_mask_reduce_max_pd(
      arg0,
      arg1,
    );
  }

  late final __mm512_mask_reduce_max_pdPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(__mmask8, _m512d)>>(
          '_mm512_mask_reduce_max_pd');
  late final __mm512_mask_reduce_max_pd =
      __mm512_mask_reduce_max_pdPtr.asFunction<double Function(int, _m512d)>();

  int _mm512_reduce_max_epi32(
    __m512i arg0,
  ) {
    return __mm512_reduce_max_epi32(
      arg0,
    );
  }

  late final __mm512_reduce_max_epi32Ptr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(__m512i)>>(
          '_mm512_reduce_max_epi32');
  late final __mm512_reduce_max_epi32 =
      __mm512_reduce_max_epi32Ptr.asFunction<int Function(__m512i)>();

  int _mm512_mask_reduce_max_epi32(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_mask_reduce_max_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_mask_reduce_max_epi32Ptr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(__mmask16, __m512i)>>(
          '_mm512_mask_reduce_max_epi32');
  late final __mm512_mask_reduce_max_epi32 =
      __mm512_mask_reduce_max_epi32Ptr.asFunction<int Function(int, __m512i)>();

  int _mm512_reduce_max_epi64(
    __m512i arg0,
  ) {
    return __mm512_reduce_max_epi64(
      arg0,
    );
  }

  late final __mm512_reduce_max_epi64Ptr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(__m512i)>>(
          '_mm512_reduce_max_epi64');
  late final __mm512_reduce_max_epi64 =
      __mm512_reduce_max_epi64Ptr.asFunction<int Function(__m512i)>();

  int _mm512_mask_reduce_max_epi64(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_mask_reduce_max_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm512_mask_reduce_max_epi64Ptr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(__mmask8, __m512i)>>(
          '_mm512_mask_reduce_max_epi64');
  late final __mm512_mask_reduce_max_epi64 =
      __mm512_mask_reduce_max_epi64Ptr.asFunction<int Function(int, __m512i)>();

  int _mm512_reduce_max_epu32(
    __m512i arg0,
  ) {
    return __mm512_reduce_max_epu32(
      arg0,
    );
  }

  late final __mm512_reduce_max_epu32Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint32 Function(__m512i)>>(
          '_mm512_reduce_max_epu32');
  late final __mm512_reduce_max_epu32 =
      __mm512_reduce_max_epu32Ptr.asFunction<int Function(__m512i)>();

  int _mm512_mask_reduce_max_epu32(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_mask_reduce_max_epu32(
      arg0,
      arg1,
    );
  }

  late final __mm512_mask_reduce_max_epu32Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint32 Function(__mmask16, __m512i)>>(
          '_mm512_mask_reduce_max_epu32');
  late final __mm512_mask_reduce_max_epu32 =
      __mm512_mask_reduce_max_epu32Ptr.asFunction<int Function(int, __m512i)>();

  int _mm512_reduce_max_epu64(
    __m512i arg0,
  ) {
    return __mm512_reduce_max_epu64(
      arg0,
    );
  }

  late final __mm512_reduce_max_epu64Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function(__m512i)>>(
          '_mm512_reduce_max_epu64');
  late final __mm512_reduce_max_epu64 =
      __mm512_reduce_max_epu64Ptr.asFunction<int Function(__m512i)>();

  int _mm512_mask_reduce_max_epu64(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_mask_reduce_max_epu64(
      arg0,
      arg1,
    );
  }

  late final __mm512_mask_reduce_max_epu64Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function(__mmask8, __m512i)>>(
          '_mm512_mask_reduce_max_epu64');
  late final __mm512_mask_reduce_max_epu64 =
      __mm512_mask_reduce_max_epu64Ptr.asFunction<int Function(int, __m512i)>();

  int _mm512_reduce_and_epi32(
    __m512i arg0,
  ) {
    return __mm512_reduce_and_epi32(
      arg0,
    );
  }

  late final __mm512_reduce_and_epi32Ptr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(__m512i)>>(
          '_mm512_reduce_and_epi32');
  late final __mm512_reduce_and_epi32 =
      __mm512_reduce_and_epi32Ptr.asFunction<int Function(__m512i)>();

  int _mm512_mask_reduce_and_epi32(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_mask_reduce_and_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_mask_reduce_and_epi32Ptr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(__mmask16, __m512i)>>(
          '_mm512_mask_reduce_and_epi32');
  late final __mm512_mask_reduce_and_epi32 =
      __mm512_mask_reduce_and_epi32Ptr.asFunction<int Function(int, __m512i)>();

  int _mm512_reduce_and_epi64(
    __m512i arg0,
  ) {
    return __mm512_reduce_and_epi64(
      arg0,
    );
  }

  late final __mm512_reduce_and_epi64Ptr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(__m512i)>>(
          '_mm512_reduce_and_epi64');
  late final __mm512_reduce_and_epi64 =
      __mm512_reduce_and_epi64Ptr.asFunction<int Function(__m512i)>();

  int _mm512_mask_reduce_and_epi64(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_mask_reduce_and_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm512_mask_reduce_and_epi64Ptr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(__mmask8, __m512i)>>(
          '_mm512_mask_reduce_and_epi64');
  late final __mm512_mask_reduce_and_epi64 =
      __mm512_mask_reduce_and_epi64Ptr.asFunction<int Function(int, __m512i)>();

  int _mm512_reduce_or_epi32(
    __m512i arg0,
  ) {
    return __mm512_reduce_or_epi32(
      arg0,
    );
  }

  late final __mm512_reduce_or_epi32Ptr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(__m512i)>>(
          '_mm512_reduce_or_epi32');
  late final __mm512_reduce_or_epi32 =
      __mm512_reduce_or_epi32Ptr.asFunction<int Function(__m512i)>();

  int _mm512_mask_reduce_or_epi32(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_mask_reduce_or_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_mask_reduce_or_epi32Ptr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(__mmask16, __m512i)>>(
          '_mm512_mask_reduce_or_epi32');
  late final __mm512_mask_reduce_or_epi32 =
      __mm512_mask_reduce_or_epi32Ptr.asFunction<int Function(int, __m512i)>();

  int _mm512_reduce_or_epi64(
    __m512i arg0,
  ) {
    return __mm512_reduce_or_epi64(
      arg0,
    );
  }

  late final __mm512_reduce_or_epi64Ptr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(__m512i)>>(
          '_mm512_reduce_or_epi64');
  late final __mm512_reduce_or_epi64 =
      __mm512_reduce_or_epi64Ptr.asFunction<int Function(__m512i)>();

  int _mm512_mask_reduce_or_epi64(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_mask_reduce_or_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm512_mask_reduce_or_epi64Ptr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(__mmask8, __m512i)>>(
          '_mm512_mask_reduce_or_epi64');
  late final __mm512_mask_reduce_or_epi64 =
      __mm512_mask_reduce_or_epi64Ptr.asFunction<int Function(int, __m512i)>();

  int _mm512_reduce_xor_epi32(
    __m512i arg0,
  ) {
    return __mm512_reduce_xor_epi32(
      arg0,
    );
  }

  late final __mm512_reduce_xor_epi32Ptr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(__m512i)>>(
          '_mm512_reduce_xor_epi32');
  late final __mm512_reduce_xor_epi32 =
      __mm512_reduce_xor_epi32Ptr.asFunction<int Function(__m512i)>();

  int _mm512_mask_reduce_xor_epi32(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_mask_reduce_xor_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_mask_reduce_xor_epi32Ptr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(__mmask16, __m512i)>>(
          '_mm512_mask_reduce_xor_epi32');
  late final __mm512_mask_reduce_xor_epi32 =
      __mm512_mask_reduce_xor_epi32Ptr.asFunction<int Function(int, __m512i)>();

  int _mm512_reduce_xor_epi64(
    __m512i arg0,
  ) {
    return __mm512_reduce_xor_epi64(
      arg0,
    );
  }

  late final __mm512_reduce_xor_epi64Ptr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(__m512i)>>(
          '_mm512_reduce_xor_epi64');
  late final __mm512_reduce_xor_epi64 =
      __mm512_reduce_xor_epi64Ptr.asFunction<int Function(__m512i)>();

  int _mm512_mask_reduce_xor_epi64(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_mask_reduce_xor_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm512_mask_reduce_xor_epi64Ptr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(__mmask8, __m512i)>>(
          '_mm512_mask_reduce_xor_epi64');
  late final __mm512_mask_reduce_xor_epi64 =
      __mm512_mask_reduce_xor_epi64Ptr.asFunction<int Function(int, __m512i)>();

  _m512d _mm512_reduce_pd(
    _m512d arg0,
    int arg1,
  ) {
    return __mm512_reduce_pd(
      arg0,
      arg1,
    );
  }

  late final __mm512_reduce_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, ffi.Int32)>>(
          '_mm512_reduce_pd');
  late final __mm512_reduce_pd =
      __mm512_reduce_pdPtr.asFunction<_m512d Function(_m512d, int)>();

  _m512d _mm512_mask_reduce_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
    int arg3,
  ) {
    return __mm512_mask_reduce_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_reduce_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(
              _m512d, __mmask8, _m512d, ffi.Int32)>>('_mm512_mask_reduce_pd');
  late final __mm512_mask_reduce_pd = __mm512_mask_reduce_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d, int)>();

  _m512d _mm512_maskz_reduce_pd(
    int arg0,
    _m512d arg1,
    int arg2,
  ) {
    return __mm512_maskz_reduce_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_reduce_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(__mmask8, _m512d, ffi.Int32)>>(
          '_mm512_maskz_reduce_pd');
  late final __mm512_maskz_reduce_pd = __mm512_maskz_reduce_pdPtr
      .asFunction<_m512d Function(int, _m512d, int)>();

  _m512d _mm512_reduce_round_pd(
    _m512d arg0,
    int arg1,
    int arg2,
  ) {
    return __mm512_reduce_round_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_reduce_round_pdPtr = _lookup<
          ffi.NativeFunction<_m512d Function(_m512d, ffi.Int32, ffi.Int32)>>(
      '_mm512_reduce_round_pd');
  late final __mm512_reduce_round_pd = __mm512_reduce_round_pdPtr
      .asFunction<_m512d Function(_m512d, int, int)>();

  _m512d _mm512_mask_reduce_round_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
    int arg3,
    int arg4,
  ) {
    return __mm512_mask_reduce_round_pd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_reduce_round_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(_m512d, __mmask8, _m512d, ffi.Int32,
              ffi.Int32)>>('_mm512_mask_reduce_round_pd');
  late final __mm512_mask_reduce_round_pd = __mm512_mask_reduce_round_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d, int, int)>();

  _m512d _mm512_maskz_reduce_round_pd(
    int arg0,
    _m512d arg1,
    int arg2,
    int arg3,
  ) {
    return __mm512_maskz_reduce_round_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_reduce_round_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(__mmask8, _m512d, ffi.Int32,
              ffi.Int32)>>('_mm512_maskz_reduce_round_pd');
  late final __mm512_maskz_reduce_round_pd = __mm512_maskz_reduce_round_pdPtr
      .asFunction<_m512d Function(int, _m512d, int, int)>();

  __m512 _mm512_reduce_ps(
    __m512 arg0,
    int arg1,
  ) {
    return __mm512_reduce_ps(
      arg0,
      arg1,
    );
  }

  late final __mm512_reduce_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, ffi.Int32)>>(
          '_mm512_reduce_ps');
  late final __mm512_reduce_ps =
      __mm512_reduce_psPtr.asFunction<__m512 Function(__m512, int)>();

  __m512 _mm512_mask_reduce_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
    int arg3,
  ) {
    return __mm512_mask_reduce_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_reduce_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(
              __m512, __mmask16, __m512, ffi.Int32)>>('_mm512_mask_reduce_ps');
  late final __mm512_mask_reduce_ps = __mm512_mask_reduce_psPtr
      .asFunction<__m512 Function(__m512, int, __m512, int)>();

  __m512 _mm512_maskz_reduce_ps(
    int arg0,
    __m512 arg1,
    int arg2,
  ) {
    return __mm512_maskz_reduce_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_reduce_psPtr = _lookup<
          ffi.NativeFunction<__m512 Function(__mmask16, __m512, ffi.Int32)>>(
      '_mm512_maskz_reduce_ps');
  late final __mm512_maskz_reduce_ps = __mm512_maskz_reduce_psPtr
      .asFunction<__m512 Function(int, __m512, int)>();

  __m512 _mm512_reduce_round_ps(
    __m512 arg0,
    int arg1,
    int arg2,
  ) {
    return __mm512_reduce_round_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_reduce_round_psPtr = _lookup<
          ffi.NativeFunction<__m512 Function(__m512, ffi.Int32, ffi.Int32)>>(
      '_mm512_reduce_round_ps');
  late final __mm512_reduce_round_ps = __mm512_reduce_round_psPtr
      .asFunction<__m512 Function(__m512, int, int)>();

  __m512 _mm512_mask_reduce_round_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
    int arg3,
    int arg4,
  ) {
    return __mm512_mask_reduce_round_ps(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_reduce_round_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__m512, __mmask16, __m512, ffi.Int32,
              ffi.Int32)>>('_mm512_mask_reduce_round_ps');
  late final __mm512_mask_reduce_round_ps = __mm512_mask_reduce_round_psPtr
      .asFunction<__m512 Function(__m512, int, __m512, int, int)>();

  __m512 _mm512_maskz_reduce_round_ps(
    int arg0,
    __m512 arg1,
    int arg2,
    int arg3,
  ) {
    return __mm512_maskz_reduce_round_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_reduce_round_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__mmask16, __m512, ffi.Int32,
              ffi.Int32)>>('_mm512_maskz_reduce_round_ps');
  late final __mm512_maskz_reduce_round_ps = __mm512_maskz_reduce_round_psPtr
      .asFunction<__m512 Function(int, __m512, int, int)>();

  _m512d _mm512_roundscale_pd(
    _m512d arg0,
    int arg1,
  ) {
    return __mm512_roundscale_pd(
      arg0,
      arg1,
    );
  }

  late final __mm512_roundscale_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, ffi.Int32)>>(
          '_mm512_roundscale_pd');
  late final __mm512_roundscale_pd =
      __mm512_roundscale_pdPtr.asFunction<_m512d Function(_m512d, int)>();

  _m512d _mm512_mask_roundscale_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
    int arg3,
  ) {
    return __mm512_mask_roundscale_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_roundscale_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(_m512d, __mmask8, _m512d,
              ffi.Int32)>>('_mm512_mask_roundscale_pd');
  late final __mm512_mask_roundscale_pd = __mm512_mask_roundscale_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d, int)>();

  _m512d _mm512_maskz_roundscale_pd(
    int arg0,
    _m512d arg1,
    int arg2,
  ) {
    return __mm512_maskz_roundscale_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_roundscale_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(__mmask8, _m512d, ffi.Int32)>>(
          '_mm512_maskz_roundscale_pd');
  late final __mm512_maskz_roundscale_pd = __mm512_maskz_roundscale_pdPtr
      .asFunction<_m512d Function(int, _m512d, int)>();

  _m512d _mm512_roundscale_round_pd(
    _m512d arg0,
    int arg1,
    int arg2,
  ) {
    return __mm512_roundscale_round_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_roundscale_round_pdPtr = _lookup<
          ffi.NativeFunction<_m512d Function(_m512d, ffi.Int32, ffi.Int32)>>(
      '_mm512_roundscale_round_pd');
  late final __mm512_roundscale_round_pd = __mm512_roundscale_round_pdPtr
      .asFunction<_m512d Function(_m512d, int, int)>();

  _m512d _mm512_mask_roundscale_round_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
    int arg3,
    int arg4,
  ) {
    return __mm512_mask_roundscale_round_pd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_roundscale_round_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(_m512d, __mmask8, _m512d, ffi.Int32,
              ffi.Int32)>>('_mm512_mask_roundscale_round_pd');
  late final __mm512_mask_roundscale_round_pd =
      __mm512_mask_roundscale_round_pdPtr
          .asFunction<_m512d Function(_m512d, int, _m512d, int, int)>();

  _m512d _mm512_maskz_roundscale_round_pd(
    int arg0,
    _m512d arg1,
    int arg2,
    int arg3,
  ) {
    return __mm512_maskz_roundscale_round_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_roundscale_round_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(__mmask8, _m512d, ffi.Int32,
              ffi.Int32)>>('_mm512_maskz_roundscale_round_pd');
  late final __mm512_maskz_roundscale_round_pd =
      __mm512_maskz_roundscale_round_pdPtr
          .asFunction<_m512d Function(int, _m512d, int, int)>();

  __m512 _mm512_roundscale_ps(
    __m512 arg0,
    int arg1,
  ) {
    return __mm512_roundscale_ps(
      arg0,
      arg1,
    );
  }

  late final __mm512_roundscale_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, ffi.Int32)>>(
          '_mm512_roundscale_ps');
  late final __mm512_roundscale_ps =
      __mm512_roundscale_psPtr.asFunction<__m512 Function(__m512, int)>();

  __m512 _mm512_mask_roundscale_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
    int arg3,
  ) {
    return __mm512_mask_roundscale_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_roundscale_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__m512, __mmask16, __m512,
              ffi.Int32)>>('_mm512_mask_roundscale_ps');
  late final __mm512_mask_roundscale_ps = __mm512_mask_roundscale_psPtr
      .asFunction<__m512 Function(__m512, int, __m512, int)>();

  __m512 _mm512_maskz_roundscale_ps(
    int arg0,
    __m512 arg1,
    int arg2,
  ) {
    return __mm512_maskz_roundscale_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_roundscale_psPtr = _lookup<
          ffi.NativeFunction<__m512 Function(__mmask16, __m512, ffi.Int32)>>(
      '_mm512_maskz_roundscale_ps');
  late final __mm512_maskz_roundscale_ps = __mm512_maskz_roundscale_psPtr
      .asFunction<__m512 Function(int, __m512, int)>();

  __m512 _mm512_roundscale_round_ps(
    __m512 arg0,
    int arg1,
    int arg2,
  ) {
    return __mm512_roundscale_round_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_roundscale_round_psPtr = _lookup<
          ffi.NativeFunction<__m512 Function(__m512, ffi.Int32, ffi.Int32)>>(
      '_mm512_roundscale_round_ps');
  late final __mm512_roundscale_round_ps = __mm512_roundscale_round_psPtr
      .asFunction<__m512 Function(__m512, int, int)>();

  __m512 _mm512_mask_roundscale_round_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
    int arg3,
    int arg4,
  ) {
    return __mm512_mask_roundscale_round_ps(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_roundscale_round_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__m512, __mmask16, __m512, ffi.Int32,
              ffi.Int32)>>('_mm512_mask_roundscale_round_ps');
  late final __mm512_mask_roundscale_round_ps =
      __mm512_mask_roundscale_round_psPtr
          .asFunction<__m512 Function(__m512, int, __m512, int, int)>();

  __m512 _mm512_maskz_roundscale_round_ps(
    int arg0,
    __m512 arg1,
    int arg2,
    int arg3,
  ) {
    return __mm512_maskz_roundscale_round_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_roundscale_round_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__mmask16, __m512, ffi.Int32,
              ffi.Int32)>>('_mm512_maskz_roundscale_round_ps');
  late final __mm512_maskz_roundscale_round_ps =
      __mm512_maskz_roundscale_round_psPtr
          .asFunction<__m512 Function(int, __m512, int, int)>();

  _m512d _mm512_scalef_pd(
    _m512d arg0,
    _m512d arg1,
  ) {
    return __mm512_scalef_pd(
      arg0,
      arg1,
    );
  }

  late final __mm512_scalef_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, _m512d)>>(
          '_mm512_scalef_pd');
  late final __mm512_scalef_pd =
      __mm512_scalef_pdPtr.asFunction<_m512d Function(_m512d, _m512d)>();

  _m512d _mm512_mask_scalef_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
    _m512d arg3,
  ) {
    return __mm512_mask_scalef_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_scalef_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(
              _m512d, __mmask8, _m512d, _m512d)>>('_mm512_mask_scalef_pd');
  late final __mm512_mask_scalef_pd = __mm512_mask_scalef_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d, _m512d)>();

  _m512d _mm512_maskz_scalef_pd(
    int arg0,
    _m512d arg1,
    _m512d arg2,
  ) {
    return __mm512_maskz_scalef_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_scalef_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(__mmask8, _m512d, _m512d)>>(
          '_mm512_maskz_scalef_pd');
  late final __mm512_maskz_scalef_pd = __mm512_maskz_scalef_pdPtr
      .asFunction<_m512d Function(int, _m512d, _m512d)>();

  _m512d _mm512_scalef_round_pd(
    _m512d arg0,
    _m512d arg1,
    int arg2,
  ) {
    return __mm512_scalef_round_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_scalef_round_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, _m512d, ffi.Int32)>>(
          '_mm512_scalef_round_pd');
  late final __mm512_scalef_round_pd = __mm512_scalef_round_pdPtr
      .asFunction<_m512d Function(_m512d, _m512d, int)>();

  _m512d _mm512_mask_scalef_round_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
    _m512d arg3,
    int arg4,
  ) {
    return __mm512_mask_scalef_round_pd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_scalef_round_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(_m512d, __mmask8, _m512d, _m512d,
              ffi.Int32)>>('_mm512_mask_scalef_round_pd');
  late final __mm512_mask_scalef_round_pd = __mm512_mask_scalef_round_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d, _m512d, int)>();

  _m512d _mm512_maskz_scalef_round_pd(
    int arg0,
    _m512d arg1,
    _m512d arg2,
    int arg3,
  ) {
    return __mm512_maskz_scalef_round_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_scalef_round_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(__mmask8, _m512d, _m512d,
              ffi.Int32)>>('_mm512_maskz_scalef_round_pd');
  late final __mm512_maskz_scalef_round_pd = __mm512_maskz_scalef_round_pdPtr
      .asFunction<_m512d Function(int, _m512d, _m512d, int)>();

  __m512 _mm512_scalef_ps(
    __m512 arg0,
    __m512 arg1,
  ) {
    return __mm512_scalef_ps(
      arg0,
      arg1,
    );
  }

  late final __mm512_scalef_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __m512)>>(
          '_mm512_scalef_ps');
  late final __mm512_scalef_ps =
      __mm512_scalef_psPtr.asFunction<__m512 Function(__m512, __m512)>();

  __m512 _mm512_mask_scalef_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
    __m512 arg3,
  ) {
    return __mm512_mask_scalef_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_scalef_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(
              __m512, __mmask16, __m512, __m512)>>('_mm512_mask_scalef_ps');
  late final __mm512_mask_scalef_ps = __mm512_mask_scalef_psPtr
      .asFunction<__m512 Function(__m512, int, __m512, __m512)>();

  __m512 _mm512_maskz_scalef_ps(
    int arg0,
    __m512 arg1,
    __m512 arg2,
  ) {
    return __mm512_maskz_scalef_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_scalef_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__mmask16, __m512, __m512)>>(
          '_mm512_maskz_scalef_ps');
  late final __mm512_maskz_scalef_ps = __mm512_maskz_scalef_psPtr
      .asFunction<__m512 Function(int, __m512, __m512)>();

  __m512 _mm512_scalef_round_ps(
    __m512 arg0,
    __m512 arg1,
    int arg2,
  ) {
    return __mm512_scalef_round_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_scalef_round_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __m512, ffi.Int32)>>(
          '_mm512_scalef_round_ps');
  late final __mm512_scalef_round_ps = __mm512_scalef_round_psPtr
      .asFunction<__m512 Function(__m512, __m512, int)>();

  __m512 _mm512_mask_scalef_round_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
    __m512 arg3,
    int arg4,
  ) {
    return __mm512_mask_scalef_round_ps(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_scalef_round_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__m512, __mmask16, __m512, __m512,
              ffi.Int32)>>('_mm512_mask_scalef_round_ps');
  late final __mm512_mask_scalef_round_ps = __mm512_mask_scalef_round_psPtr
      .asFunction<__m512 Function(__m512, int, __m512, __m512, int)>();

  __m512 _mm512_maskz_scalef_round_ps(
    int arg0,
    __m512 arg1,
    __m512 arg2,
    int arg3,
  ) {
    return __mm512_maskz_scalef_round_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_scalef_round_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__mmask16, __m512, __m512,
              ffi.Int32)>>('_mm512_maskz_scalef_round_ps');
  late final __mm512_maskz_scalef_round_ps = __mm512_maskz_scalef_round_psPtr
      .asFunction<__m512 Function(int, __m512, __m512, int)>();

  _m512d _mm512_fixupimm_pd(
    _m512d arg0,
    _m512d arg1,
    __m512i arg2,
    int arg3,
  ) {
    return __mm512_fixupimm_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_fixupimm_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(
              _m512d, _m512d, __m512i, ffi.Int32)>>('_mm512_fixupimm_pd');
  late final __mm512_fixupimm_pd = __mm512_fixupimm_pdPtr
      .asFunction<_m512d Function(_m512d, _m512d, __m512i, int)>();

  _m512d _mm512_mask_fixupimm_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
    __m512i arg3,
    int arg4,
  ) {
    return __mm512_mask_fixupimm_pd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_fixupimm_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(_m512d, __mmask8, _m512d, __m512i,
              ffi.Int32)>>('_mm512_mask_fixupimm_pd');
  late final __mm512_mask_fixupimm_pd = __mm512_mask_fixupimm_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d, __m512i, int)>();

  _m512d _mm512_maskz_fixupimm_pd(
    int arg0,
    _m512d arg1,
    _m512d arg2,
    __m512i arg3,
    int arg4,
  ) {
    return __mm512_maskz_fixupimm_pd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_maskz_fixupimm_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(__mmask8, _m512d, _m512d, __m512i,
              ffi.Int32)>>('_mm512_maskz_fixupimm_pd');
  late final __mm512_maskz_fixupimm_pd = __mm512_maskz_fixupimm_pdPtr
      .asFunction<_m512d Function(int, _m512d, _m512d, __m512i, int)>();

  _m512d _mm512_fixupimm_round_pd(
    _m512d arg0,
    _m512d arg1,
    __m512i arg2,
    int arg3,
    int arg4,
  ) {
    return __mm512_fixupimm_round_pd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_fixupimm_round_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(_m512d, _m512d, __m512i, ffi.Int32,
              ffi.Int32)>>('_mm512_fixupimm_round_pd');
  late final __mm512_fixupimm_round_pd = __mm512_fixupimm_round_pdPtr
      .asFunction<_m512d Function(_m512d, _m512d, __m512i, int, int)>();

  _m512d _mm512_mask_fixupimm_round_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
    __m512i arg3,
    int arg4,
    int arg5,
  ) {
    return __mm512_mask_fixupimm_round_pd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
      arg5,
    );
  }

  late final __mm512_mask_fixupimm_round_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(_m512d, __mmask8, _m512d, __m512i, ffi.Int32,
              ffi.Int32)>>('_mm512_mask_fixupimm_round_pd');
  late final __mm512_mask_fixupimm_round_pd = __mm512_mask_fixupimm_round_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d, __m512i, int, int)>();

  _m512d _mm512_maskz_fixupimm_round_pd(
    int arg0,
    _m512d arg1,
    _m512d arg2,
    __m512i arg3,
    int arg4,
    int arg5,
  ) {
    return __mm512_maskz_fixupimm_round_pd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
      arg5,
    );
  }

  late final __mm512_maskz_fixupimm_round_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(__mmask8, _m512d, _m512d, __m512i, ffi.Int32,
              ffi.Int32)>>('_mm512_maskz_fixupimm_round_pd');
  late final __mm512_maskz_fixupimm_round_pd =
      __mm512_maskz_fixupimm_round_pdPtr.asFunction<
          _m512d Function(int, _m512d, _m512d, __m512i, int, int)>();

  __m512 _mm512_fixupimm_ps(
    __m512 arg0,
    __m512 arg1,
    __m512i arg2,
    int arg3,
  ) {
    return __mm512_fixupimm_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_fixupimm_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(
              __m512, __m512, __m512i, ffi.Int32)>>('_mm512_fixupimm_ps');
  late final __mm512_fixupimm_ps = __mm512_fixupimm_psPtr
      .asFunction<__m512 Function(__m512, __m512, __m512i, int)>();

  __m512 _mm512_mask_fixupimm_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
    __m512i arg3,
    int arg4,
  ) {
    return __mm512_mask_fixupimm_ps(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_fixupimm_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__m512, __mmask16, __m512, __m512i,
              ffi.Int32)>>('_mm512_mask_fixupimm_ps');
  late final __mm512_mask_fixupimm_ps = __mm512_mask_fixupimm_psPtr
      .asFunction<__m512 Function(__m512, int, __m512, __m512i, int)>();

  __m512 _mm512_maskz_fixupimm_ps(
    int arg0,
    __m512 arg1,
    __m512 arg2,
    __m512i arg3,
    int arg4,
  ) {
    return __mm512_maskz_fixupimm_ps(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_maskz_fixupimm_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__mmask16, __m512, __m512, __m512i,
              ffi.Int32)>>('_mm512_maskz_fixupimm_ps');
  late final __mm512_maskz_fixupimm_ps = __mm512_maskz_fixupimm_psPtr
      .asFunction<__m512 Function(int, __m512, __m512, __m512i, int)>();

  __m512 _mm512_fixupimm_round_ps(
    __m512 arg0,
    __m512 arg1,
    __m512i arg2,
    int arg3,
    int arg4,
  ) {
    return __mm512_fixupimm_round_ps(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_fixupimm_round_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__m512, __m512, __m512i, ffi.Int32,
              ffi.Int32)>>('_mm512_fixupimm_round_ps');
  late final __mm512_fixupimm_round_ps = __mm512_fixupimm_round_psPtr
      .asFunction<__m512 Function(__m512, __m512, __m512i, int, int)>();

  __m512 _mm512_mask_fixupimm_round_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
    __m512i arg3,
    int arg4,
    int arg5,
  ) {
    return __mm512_mask_fixupimm_round_ps(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
      arg5,
    );
  }

  late final __mm512_mask_fixupimm_round_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__m512, __mmask16, __m512, __m512i, ffi.Int32,
              ffi.Int32)>>('_mm512_mask_fixupimm_round_ps');
  late final __mm512_mask_fixupimm_round_ps = __mm512_mask_fixupimm_round_psPtr
      .asFunction<__m512 Function(__m512, int, __m512, __m512i, int, int)>();

  __m512 _mm512_maskz_fixupimm_round_ps(
    int arg0,
    __m512 arg1,
    __m512 arg2,
    __m512i arg3,
    int arg4,
    int arg5,
  ) {
    return __mm512_maskz_fixupimm_round_ps(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
      arg5,
    );
  }

  late final __mm512_maskz_fixupimm_round_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__mmask16, __m512, __m512, __m512i, ffi.Int32,
              ffi.Int32)>>('_mm512_maskz_fixupimm_round_ps');
  late final __mm512_maskz_fixupimm_round_ps =
      __mm512_maskz_fixupimm_round_psPtr.asFunction<
          __m512 Function(int, __m512, __m512, __m512i, int, int)>();

  void _mm512_stream_pd(
    ffi.Pointer<ffi.Void> arg0,
    _m512d arg1,
  ) {
    return __mm512_stream_pd(
      arg0,
      arg1,
    );
  }

  late final __mm512_stream_pdPtr = _lookup<
          ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ffi.Void>, _m512d)>>(
      '_mm512_stream_pd');
  late final __mm512_stream_pd = __mm512_stream_pdPtr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, _m512d)>();

  void _mm512_stream_ps(
    ffi.Pointer<ffi.Void> arg0,
    __m512 arg1,
  ) {
    return __mm512_stream_ps(
      arg0,
      arg1,
    );
  }

  late final __mm512_stream_psPtr = _lookup<
          ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ffi.Void>, __m512)>>(
      '_mm512_stream_ps');
  late final __mm512_stream_ps = __mm512_stream_psPtr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, __m512)>();

  void _mm512_stream_si512(
    ffi.Pointer<ffi.Void> arg0,
    __m512i arg1,
  ) {
    return __mm512_stream_si512(
      arg0,
      arg1,
    );
  }

  late final __mm512_stream_si512Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<ffi.Void>, __m512i)>>('_mm512_stream_si512');
  late final __mm512_stream_si512 = __mm512_stream_si512Ptr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, __m512i)>();

  __m512i _mm512_stream_load_si512(
    ffi.Pointer<ffi.Void> arg0,
  ) {
    return __mm512_stream_load_si512(
      arg0,
    );
  }

  late final __mm512_stream_load_si512Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(ffi.Pointer<ffi.Void>)>>(
          '_mm512_stream_load_si512');
  late final __mm512_stream_load_si512 = __mm512_stream_load_si512Ptr
      .asFunction<__m512i Function(ffi.Pointer<ffi.Void>)>();

  _m128d _mm512_castpd512_pd128(
    _m512d arg0,
  ) {
    return __mm512_castpd512_pd128(
      arg0,
    );
  }

  late final __mm512_castpd512_pd128Ptr =
      _lookup<ffi.NativeFunction<_m128d Function(_m512d)>>(
          '_mm512_castpd512_pd128');
  late final __mm512_castpd512_pd128 =
      __mm512_castpd512_pd128Ptr.asFunction<_m128d Function(_m512d)>();

  __m128 _mm512_castps512_ps128(
    __m512 arg0,
  ) {
    return __mm512_castps512_ps128(
      arg0,
    );
  }

  late final __mm512_castps512_ps128Ptr =
      _lookup<ffi.NativeFunction<__m128 Function(__m512)>>(
          '_mm512_castps512_ps128');
  late final __mm512_castps512_ps128 =
      __mm512_castps512_ps128Ptr.asFunction<__m128 Function(__m512)>();

  __m128i _mm512_castsi512_si128(
    __m512i arg0,
  ) {
    return __mm512_castsi512_si128(
      arg0,
    );
  }

  late final __mm512_castsi512_si128Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m512i)>>(
          '_mm512_castsi512_si128');
  late final __mm512_castsi512_si128 =
      __mm512_castsi512_si128Ptr.asFunction<__m128i Function(__m512i)>();

  __m512i _mm512_castsi128_si512(
    __m128i arg0,
  ) {
    return __mm512_castsi128_si512(
      arg0,
    );
  }

  late final __mm512_castsi128_si512Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m128i)>>(
          '_mm512_castsi128_si512');
  late final __mm512_castsi128_si512 =
      __mm512_castsi128_si512Ptr.asFunction<__m512i Function(__m128i)>();

  int _mm512_fpclass_ps_mask(
    __m512 arg0,
    int arg1,
  ) {
    return __mm512_fpclass_ps_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_fpclass_ps_maskPtr =
      _lookup<ffi.NativeFunction<__mmask16 Function(__m512, ffi.Int32)>>(
          '_mm512_fpclass_ps_mask');
  late final __mm512_fpclass_ps_mask =
      __mm512_fpclass_ps_maskPtr.asFunction<int Function(__m512, int)>();

  int _mm512_mask_fpclass_ps_mask(
    int arg0,
    __m512 arg1,
    int arg2,
  ) {
    return __mm512_mask_fpclass_ps_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_fpclass_ps_maskPtr = _lookup<
          ffi.NativeFunction<__mmask16 Function(__mmask16, __m512, ffi.Int32)>>(
      '_mm512_mask_fpclass_ps_mask');
  late final __mm512_mask_fpclass_ps_mask = __mm512_mask_fpclass_ps_maskPtr
      .asFunction<int Function(int, __m512, int)>();

  int _mm512_fpclass_pd_mask(
    _m512d arg0,
    int arg1,
  ) {
    return __mm512_fpclass_pd_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_fpclass_pd_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(_m512d, ffi.Int32)>>(
          '_mm512_fpclass_pd_mask');
  late final __mm512_fpclass_pd_mask =
      __mm512_fpclass_pd_maskPtr.asFunction<int Function(_m512d, int)>();

  int _mm512_mask_fpclass_pd_mask(
    int arg0,
    _m512d arg1,
    int arg2,
  ) {
    return __mm512_mask_fpclass_pd_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_fpclass_pd_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, _m512d, ffi.Int32)>>(
      '_mm512_mask_fpclass_pd_mask');
  late final __mm512_mask_fpclass_pd_mask = __mm512_mask_fpclass_pd_maskPtr
      .asFunction<int Function(int, _m512d, int)>();

  _m512d _mm512_range_pd(
    _m512d arg0,
    _m512d arg1,
    int arg2,
  ) {
    return __mm512_range_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_range_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, _m512d, ffi.Int32)>>(
          '_mm512_range_pd');
  late final __mm512_range_pd =
      __mm512_range_pdPtr.asFunction<_m512d Function(_m512d, _m512d, int)>();

  _m512d _mm512_mask_range_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
    _m512d arg3,
    int arg4,
  ) {
    return __mm512_mask_range_pd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_range_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(_m512d, __mmask8, _m512d, _m512d,
              ffi.Int32)>>('_mm512_mask_range_pd');
  late final __mm512_mask_range_pd = __mm512_mask_range_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d, _m512d, int)>();

  _m512d _mm512_maskz_range_pd(
    int arg0,
    _m512d arg1,
    _m512d arg2,
    int arg3,
  ) {
    return __mm512_maskz_range_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_range_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(
              __mmask8, _m512d, _m512d, ffi.Int32)>>('_mm512_maskz_range_pd');
  late final __mm512_maskz_range_pd = __mm512_maskz_range_pdPtr
      .asFunction<_m512d Function(int, _m512d, _m512d, int)>();

  _m512d _mm512_range_round_pd(
    _m512d arg0,
    _m512d arg1,
    int arg2,
    int arg3,
  ) {
    return __mm512_range_round_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_range_round_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(
              _m512d, _m512d, ffi.Int32, ffi.Int32)>>('_mm512_range_round_pd');
  late final __mm512_range_round_pd = __mm512_range_round_pdPtr
      .asFunction<_m512d Function(_m512d, _m512d, int, int)>();

  _m512d _mm512_mask_range_round_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
    _m512d arg3,
    int arg4,
    int arg5,
  ) {
    return __mm512_mask_range_round_pd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
      arg5,
    );
  }

  late final __mm512_mask_range_round_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(_m512d, __mmask8, _m512d, _m512d, ffi.Int32,
              ffi.Int32)>>('_mm512_mask_range_round_pd');
  late final __mm512_mask_range_round_pd = __mm512_mask_range_round_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d, _m512d, int, int)>();

  _m512d _mm512_maskz_range_round_pd(
    int arg0,
    _m512d arg1,
    _m512d arg2,
    int arg3,
    int arg4,
  ) {
    return __mm512_maskz_range_round_pd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_maskz_range_round_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(__mmask8, _m512d, _m512d, ffi.Int32,
              ffi.Int32)>>('_mm512_maskz_range_round_pd');
  late final __mm512_maskz_range_round_pd = __mm512_maskz_range_round_pdPtr
      .asFunction<_m512d Function(int, _m512d, _m512d, int, int)>();

  __m512 _mm512_range_ps(
    __m512 arg0,
    __m512 arg1,
    int arg2,
  ) {
    return __mm512_range_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_range_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __m512, ffi.Int32)>>(
          '_mm512_range_ps');
  late final __mm512_range_ps =
      __mm512_range_psPtr.asFunction<__m512 Function(__m512, __m512, int)>();

  __m512 _mm512_mask_range_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
    __m512 arg3,
    int arg4,
  ) {
    return __mm512_mask_range_ps(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_range_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__m512, __mmask16, __m512, __m512,
              ffi.Int32)>>('_mm512_mask_range_ps');
  late final __mm512_mask_range_ps = __mm512_mask_range_psPtr
      .asFunction<__m512 Function(__m512, int, __m512, __m512, int)>();

  __m512 _mm512_maskz_range_ps(
    int arg0,
    __m512 arg1,
    __m512 arg2,
    int arg3,
  ) {
    return __mm512_maskz_range_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_range_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(
              __mmask16, __m512, __m512, ffi.Int32)>>('_mm512_maskz_range_ps');
  late final __mm512_maskz_range_ps = __mm512_maskz_range_psPtr
      .asFunction<__m512 Function(int, __m512, __m512, int)>();

  __m512 _mm512_range_round_ps(
    __m512 arg0,
    __m512 arg1,
    int arg2,
    int arg3,
  ) {
    return __mm512_range_round_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_range_round_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(
              __m512, __m512, ffi.Int32, ffi.Int32)>>('_mm512_range_round_ps');
  late final __mm512_range_round_ps = __mm512_range_round_psPtr
      .asFunction<__m512 Function(__m512, __m512, int, int)>();

  __m512 _mm512_mask_range_round_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
    __m512 arg3,
    int arg4,
    int arg5,
  ) {
    return __mm512_mask_range_round_ps(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
      arg5,
    );
  }

  late final __mm512_mask_range_round_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__m512, __mmask16, __m512, __m512, ffi.Int32,
              ffi.Int32)>>('_mm512_mask_range_round_ps');
  late final __mm512_mask_range_round_ps = __mm512_mask_range_round_psPtr
      .asFunction<__m512 Function(__m512, int, __m512, __m512, int, int)>();

  __m512 _mm512_maskz_range_round_ps(
    int arg0,
    __m512 arg1,
    __m512 arg2,
    int arg3,
    int arg4,
  ) {
    return __mm512_maskz_range_round_ps(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_maskz_range_round_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__mmask16, __m512, __m512, ffi.Int32,
              ffi.Int32)>>('_mm512_maskz_range_round_ps');
  late final __mm512_maskz_range_round_ps = __mm512_maskz_range_round_psPtr
      .asFunction<__m512 Function(int, __m512, __m512, int, int)>();

  __m512i _mm512_madd_epi16(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_madd_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm512_madd_epi16Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_madd_epi16');
  late final __mm512_madd_epi16 =
      __mm512_madd_epi16Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_madd_epi16(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_madd_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_madd_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask16, __m512i, __m512i)>>('_mm512_mask_madd_epi16');
  late final __mm512_mask_madd_epi16 = __mm512_mask_madd_epi16Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_madd_epi16(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_madd_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_madd_epi16Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask16, __m512i, __m512i)>>(
      '_mm512_maskz_madd_epi16');
  late final __mm512_maskz_madd_epi16 = __mm512_maskz_madd_epi16Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_maddubs_epi16(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_maddubs_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm512_maddubs_epi16Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_maddubs_epi16');
  late final __mm512_maddubs_epi16 =
      __mm512_maddubs_epi16Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_maddubs_epi16(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_maddubs_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_maddubs_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask32, __m512i,
              __m512i)>>('_mm512_mask_maddubs_epi16');
  late final __mm512_mask_maddubs_epi16 = __mm512_mask_maddubs_epi16Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_maddubs_epi16(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_maddubs_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_maddubs_epi16Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask32, __m512i, __m512i)>>(
      '_mm512_maskz_maddubs_epi16');
  late final __mm512_maskz_maddubs_epi16 = __mm512_maskz_maddubs_epi16Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_packs_epi16(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_packs_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm512_packs_epi16Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_packs_epi16');
  late final __mm512_packs_epi16 =
      __mm512_packs_epi16Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_packs_epi16(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_packs_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_packs_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask64, __m512i,
              __m512i)>>('_mm512_mask_packs_epi16');
  late final __mm512_mask_packs_epi16 = __mm512_mask_packs_epi16Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_packs_epi16(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_packs_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_packs_epi16Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask64, __m512i, __m512i)>>(
      '_mm512_maskz_packs_epi16');
  late final __mm512_maskz_packs_epi16 = __mm512_maskz_packs_epi16Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_packs_epi32(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_packs_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_packs_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_packs_epi32');
  late final __mm512_packs_epi32 =
      __mm512_packs_epi32Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_packs_epi32(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_packs_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_packs_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask32, __m512i,
              __m512i)>>('_mm512_mask_packs_epi32');
  late final __mm512_mask_packs_epi32 = __mm512_mask_packs_epi32Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_packs_epi32(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_packs_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_packs_epi32Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask32, __m512i, __m512i)>>(
      '_mm512_maskz_packs_epi32');
  late final __mm512_maskz_packs_epi32 = __mm512_maskz_packs_epi32Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_packus_epi16(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_packus_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm512_packus_epi16Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_packus_epi16');
  late final __mm512_packus_epi16 =
      __mm512_packus_epi16Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_packus_epi16(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_packus_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_packus_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask64, __m512i,
              __m512i)>>('_mm512_mask_packus_epi16');
  late final __mm512_mask_packus_epi16 = __mm512_mask_packus_epi16Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_packus_epi16(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_packus_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_packus_epi16Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask64, __m512i, __m512i)>>(
      '_mm512_maskz_packus_epi16');
  late final __mm512_maskz_packus_epi16 = __mm512_maskz_packus_epi16Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m512i _mm512_packus_epi32(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_packus_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_packus_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_packus_epi32');
  late final __mm512_packus_epi32 =
      __mm512_packus_epi32Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_packus_epi32(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_packus_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_packus_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask32, __m512i,
              __m512i)>>('_mm512_mask_packus_epi32');
  late final __mm512_mask_packus_epi32 = __mm512_mask_packus_epi32Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_packus_epi32(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_packus_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_packus_epi32Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask32, __m512i, __m512i)>>(
      '_mm512_maskz_packus_epi32');
  late final __mm512_maskz_packus_epi32 = __mm512_maskz_packus_epi32Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  int _mm512_cmp_epi8_mask(
    __m512i arg0,
    __m512i arg1,
    int arg2,
  ) {
    return __mm512_cmp_epi8_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_cmp_epi8_maskPtr = _lookup<
          ffi.NativeFunction<__mmask64 Function(__m512i, __m512i, ffi.Int32)>>(
      '_mm512_cmp_epi8_mask');
  late final __mm512_cmp_epi8_mask = __mm512_cmp_epi8_maskPtr
      .asFunction<int Function(__m512i, __m512i, int)>();

  int _mm512_mask_cmp_epi8_mask(
    int arg0,
    __m512i arg1,
    __m512i arg2,
    int arg3,
  ) {
    return __mm512_mask_cmp_epi8_mask(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_cmp_epi8_maskPtr = _lookup<
      ffi.NativeFunction<
          __mmask64 Function(__mmask64, __m512i, __m512i,
              ffi.Int32)>>('_mm512_mask_cmp_epi8_mask');
  late final __mm512_mask_cmp_epi8_mask = __mm512_mask_cmp_epi8_maskPtr
      .asFunction<int Function(int, __m512i, __m512i, int)>();

  int _mm512_cmp_epi16_mask(
    __m512i arg0,
    __m512i arg1,
    int arg2,
  ) {
    return __mm512_cmp_epi16_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_cmp_epi16_maskPtr = _lookup<
          ffi.NativeFunction<__mmask32 Function(__m512i, __m512i, ffi.Int32)>>(
      '_mm512_cmp_epi16_mask');
  late final __mm512_cmp_epi16_mask = __mm512_cmp_epi16_maskPtr
      .asFunction<int Function(__m512i, __m512i, int)>();

  int _mm512_mask_cmp_epi16_mask(
    int arg0,
    __m512i arg1,
    __m512i arg2,
    int arg3,
  ) {
    return __mm512_mask_cmp_epi16_mask(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_cmp_epi16_maskPtr = _lookup<
      ffi.NativeFunction<
          __mmask32 Function(__mmask32, __m512i, __m512i,
              ffi.Int32)>>('_mm512_mask_cmp_epi16_mask');
  late final __mm512_mask_cmp_epi16_mask = __mm512_mask_cmp_epi16_maskPtr
      .asFunction<int Function(int, __m512i, __m512i, int)>();

  int _mm512_cmp_epi32_mask(
    __m512i arg0,
    __m512i arg1,
    int arg2,
  ) {
    return __mm512_cmp_epi32_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_cmp_epi32_maskPtr = _lookup<
          ffi.NativeFunction<__mmask16 Function(__m512i, __m512i, ffi.Int32)>>(
      '_mm512_cmp_epi32_mask');
  late final __mm512_cmp_epi32_mask = __mm512_cmp_epi32_maskPtr
      .asFunction<int Function(__m512i, __m512i, int)>();

  int _mm512_mask_cmp_epi32_mask(
    int arg0,
    __m512i arg1,
    __m512i arg2,
    int arg3,
  ) {
    return __mm512_mask_cmp_epi32_mask(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_cmp_epi32_maskPtr = _lookup<
      ffi.NativeFunction<
          __mmask16 Function(__mmask16, __m512i, __m512i,
              ffi.Int32)>>('_mm512_mask_cmp_epi32_mask');
  late final __mm512_mask_cmp_epi32_mask = __mm512_mask_cmp_epi32_maskPtr
      .asFunction<int Function(int, __m512i, __m512i, int)>();

  int _mm512_cmp_epi64_mask(
    __m512i arg0,
    __m512i arg1,
    int arg2,
  ) {
    return __mm512_cmp_epi64_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_cmp_epi64_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__m512i, __m512i, ffi.Int32)>>(
      '_mm512_cmp_epi64_mask');
  late final __mm512_cmp_epi64_mask = __mm512_cmp_epi64_maskPtr
      .asFunction<int Function(__m512i, __m512i, int)>();

  int _mm512_mask_cmp_epi64_mask(
    int arg0,
    __m512i arg1,
    __m512i arg2,
    int arg3,
  ) {
    return __mm512_mask_cmp_epi64_mask(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_cmp_epi64_maskPtr = _lookup<
      ffi.NativeFunction<
          __mmask8 Function(__mmask8, __m512i, __m512i,
              ffi.Int32)>>('_mm512_mask_cmp_epi64_mask');
  late final __mm512_mask_cmp_epi64_mask = __mm512_mask_cmp_epi64_maskPtr
      .asFunction<int Function(int, __m512i, __m512i, int)>();

  int _mm512_cmp_epu8_mask(
    __m512i arg0,
    __m512i arg1,
    int arg2,
  ) {
    return __mm512_cmp_epu8_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_cmp_epu8_maskPtr = _lookup<
          ffi.NativeFunction<__mmask64 Function(__m512i, __m512i, ffi.Int32)>>(
      '_mm512_cmp_epu8_mask');
  late final __mm512_cmp_epu8_mask = __mm512_cmp_epu8_maskPtr
      .asFunction<int Function(__m512i, __m512i, int)>();

  int _mm512_mask_cmp_epu8_mask(
    int arg0,
    __m512i arg1,
    __m512i arg2,
    int arg3,
  ) {
    return __mm512_mask_cmp_epu8_mask(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_cmp_epu8_maskPtr = _lookup<
      ffi.NativeFunction<
          __mmask64 Function(__mmask64, __m512i, __m512i,
              ffi.Int32)>>('_mm512_mask_cmp_epu8_mask');
  late final __mm512_mask_cmp_epu8_mask = __mm512_mask_cmp_epu8_maskPtr
      .asFunction<int Function(int, __m512i, __m512i, int)>();

  int _mm512_cmp_epu16_mask(
    __m512i arg0,
    __m512i arg1,
    int arg2,
  ) {
    return __mm512_cmp_epu16_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_cmp_epu16_maskPtr = _lookup<
          ffi.NativeFunction<__mmask32 Function(__m512i, __m512i, ffi.Int32)>>(
      '_mm512_cmp_epu16_mask');
  late final __mm512_cmp_epu16_mask = __mm512_cmp_epu16_maskPtr
      .asFunction<int Function(__m512i, __m512i, int)>();

  int _mm512_mask_cmp_epu16_mask(
    int arg0,
    __m512i arg1,
    __m512i arg2,
    int arg3,
  ) {
    return __mm512_mask_cmp_epu16_mask(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_cmp_epu16_maskPtr = _lookup<
      ffi.NativeFunction<
          __mmask32 Function(__mmask32, __m512i, __m512i,
              ffi.Int32)>>('_mm512_mask_cmp_epu16_mask');
  late final __mm512_mask_cmp_epu16_mask = __mm512_mask_cmp_epu16_maskPtr
      .asFunction<int Function(int, __m512i, __m512i, int)>();

  int _mm512_cmp_epu32_mask(
    __m512i arg0,
    __m512i arg1,
    int arg2,
  ) {
    return __mm512_cmp_epu32_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_cmp_epu32_maskPtr = _lookup<
          ffi.NativeFunction<__mmask16 Function(__m512i, __m512i, ffi.Int32)>>(
      '_mm512_cmp_epu32_mask');
  late final __mm512_cmp_epu32_mask = __mm512_cmp_epu32_maskPtr
      .asFunction<int Function(__m512i, __m512i, int)>();

  int _mm512_mask_cmp_epu32_mask(
    int arg0,
    __m512i arg1,
    __m512i arg2,
    int arg3,
  ) {
    return __mm512_mask_cmp_epu32_mask(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_cmp_epu32_maskPtr = _lookup<
      ffi.NativeFunction<
          __mmask16 Function(__mmask16, __m512i, __m512i,
              ffi.Int32)>>('_mm512_mask_cmp_epu32_mask');
  late final __mm512_mask_cmp_epu32_mask = __mm512_mask_cmp_epu32_maskPtr
      .asFunction<int Function(int, __m512i, __m512i, int)>();

  int _mm512_cmp_epu64_mask(
    __m512i arg0,
    __m512i arg1,
    int arg2,
  ) {
    return __mm512_cmp_epu64_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_cmp_epu64_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__m512i, __m512i, ffi.Int32)>>(
      '_mm512_cmp_epu64_mask');
  late final __mm512_cmp_epu64_mask = __mm512_cmp_epu64_maskPtr
      .asFunction<int Function(__m512i, __m512i, int)>();

  int _mm512_mask_cmp_epu64_mask(
    int arg0,
    __m512i arg1,
    __m512i arg2,
    int arg3,
  ) {
    return __mm512_mask_cmp_epu64_mask(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_cmp_epu64_maskPtr = _lookup<
      ffi.NativeFunction<
          __mmask8 Function(__mmask8, __m512i, __m512i,
              ffi.Int32)>>('_mm512_mask_cmp_epu64_mask');
  late final __mm512_mask_cmp_epu64_mask = __mm512_mask_cmp_epu64_maskPtr
      .asFunction<int Function(int, __m512i, __m512i, int)>();

  int _mm512_test_epi8_mask(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_test_epi8_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_test_epi8_maskPtr =
      _lookup<ffi.NativeFunction<__mmask64 Function(__m512i, __m512i)>>(
          '_mm512_test_epi8_mask');
  late final __mm512_test_epi8_mask =
      __mm512_test_epi8_maskPtr.asFunction<int Function(__m512i, __m512i)>();

  int _mm512_mask_test_epi8_mask(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_test_epi8_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_test_epi8_maskPtr = _lookup<
          ffi.NativeFunction<__mmask64 Function(__mmask64, __m512i, __m512i)>>(
      '_mm512_mask_test_epi8_mask');
  late final __mm512_mask_test_epi8_mask = __mm512_mask_test_epi8_maskPtr
      .asFunction<int Function(int, __m512i, __m512i)>();

  int _mm512_test_epi16_mask(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_test_epi16_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_test_epi16_maskPtr =
      _lookup<ffi.NativeFunction<__mmask32 Function(__m512i, __m512i)>>(
          '_mm512_test_epi16_mask');
  late final __mm512_test_epi16_mask =
      __mm512_test_epi16_maskPtr.asFunction<int Function(__m512i, __m512i)>();

  int _mm512_mask_test_epi16_mask(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_test_epi16_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_test_epi16_maskPtr = _lookup<
          ffi.NativeFunction<__mmask32 Function(__mmask32, __m512i, __m512i)>>(
      '_mm512_mask_test_epi16_mask');
  late final __mm512_mask_test_epi16_mask = __mm512_mask_test_epi16_maskPtr
      .asFunction<int Function(int, __m512i, __m512i)>();

  int _mm512_testn_epi8_mask(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_testn_epi8_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_testn_epi8_maskPtr =
      _lookup<ffi.NativeFunction<__mmask64 Function(__m512i, __m512i)>>(
          '_mm512_testn_epi8_mask');
  late final __mm512_testn_epi8_mask =
      __mm512_testn_epi8_maskPtr.asFunction<int Function(__m512i, __m512i)>();

  int _mm512_mask_testn_epi8_mask(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_testn_epi8_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_testn_epi8_maskPtr = _lookup<
          ffi.NativeFunction<__mmask64 Function(__mmask64, __m512i, __m512i)>>(
      '_mm512_mask_testn_epi8_mask');
  late final __mm512_mask_testn_epi8_mask = __mm512_mask_testn_epi8_maskPtr
      .asFunction<int Function(int, __m512i, __m512i)>();

  int _mm512_testn_epi16_mask(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_testn_epi16_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_testn_epi16_maskPtr =
      _lookup<ffi.NativeFunction<__mmask32 Function(__m512i, __m512i)>>(
          '_mm512_testn_epi16_mask');
  late final __mm512_testn_epi16_mask =
      __mm512_testn_epi16_maskPtr.asFunction<int Function(__m512i, __m512i)>();

  int _mm512_mask_testn_epi16_mask(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_testn_epi16_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_testn_epi16_maskPtr = _lookup<
          ffi.NativeFunction<__mmask32 Function(__mmask32, __m512i, __m512i)>>(
      '_mm512_mask_testn_epi16_mask');
  late final __mm512_mask_testn_epi16_mask = __mm512_mask_testn_epi16_maskPtr
      .asFunction<int Function(int, __m512i, __m512i)>();

  int _mm512_test_epi32_mask(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_test_epi32_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_test_epi32_maskPtr =
      _lookup<ffi.NativeFunction<__mmask16 Function(__m512i, __m512i)>>(
          '_mm512_test_epi32_mask');
  late final __mm512_test_epi32_mask =
      __mm512_test_epi32_maskPtr.asFunction<int Function(__m512i, __m512i)>();

  int _mm512_mask_test_epi32_mask(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_test_epi32_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_test_epi32_maskPtr = _lookup<
          ffi.NativeFunction<__mmask16 Function(__mmask16, __m512i, __m512i)>>(
      '_mm512_mask_test_epi32_mask');
  late final __mm512_mask_test_epi32_mask = __mm512_mask_test_epi32_maskPtr
      .asFunction<int Function(int, __m512i, __m512i)>();

  int _mm512_test_epi64_mask(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_test_epi64_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_test_epi64_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m512i, __m512i)>>(
          '_mm512_test_epi64_mask');
  late final __mm512_test_epi64_mask =
      __mm512_test_epi64_maskPtr.asFunction<int Function(__m512i, __m512i)>();

  int _mm512_mask_test_epi64_mask(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_test_epi64_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_test_epi64_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m512i, __m512i)>>(
      '_mm512_mask_test_epi64_mask');
  late final __mm512_mask_test_epi64_mask = __mm512_mask_test_epi64_maskPtr
      .asFunction<int Function(int, __m512i, __m512i)>();

  int _mm512_testn_epi32_mask(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_testn_epi32_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_testn_epi32_maskPtr =
      _lookup<ffi.NativeFunction<__mmask16 Function(__m512i, __m512i)>>(
          '_mm512_testn_epi32_mask');
  late final __mm512_testn_epi32_mask =
      __mm512_testn_epi32_maskPtr.asFunction<int Function(__m512i, __m512i)>();

  int _mm512_mask_testn_epi32_mask(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_testn_epi32_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_testn_epi32_maskPtr = _lookup<
          ffi.NativeFunction<__mmask16 Function(__mmask16, __m512i, __m512i)>>(
      '_mm512_mask_testn_epi32_mask');
  late final __mm512_mask_testn_epi32_mask = __mm512_mask_testn_epi32_maskPtr
      .asFunction<int Function(int, __m512i, __m512i)>();

  int _mm512_testn_epi64_mask(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_testn_epi64_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_testn_epi64_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m512i, __m512i)>>(
          '_mm512_testn_epi64_mask');
  late final __mm512_testn_epi64_mask =
      __mm512_testn_epi64_maskPtr.asFunction<int Function(__m512i, __m512i)>();

  int _mm512_mask_testn_epi64_mask(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_testn_epi64_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_testn_epi64_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m512i, __m512i)>>(
      '_mm512_mask_testn_epi64_mask');
  late final __mm512_mask_testn_epi64_mask = __mm512_mask_testn_epi64_maskPtr
      .asFunction<int Function(int, __m512i, __m512i)>();

  int _mm512_kunpackb(
    int arg0,
    int arg1,
  ) {
    return __mm512_kunpackb(
      arg0,
      arg1,
    );
  }

  late final __mm512_kunpackbPtr =
      _lookup<ffi.NativeFunction<__mmask16 Function(__mmask16, __mmask16)>>(
          '_mm512_kunpackb');
  late final __mm512_kunpackb =
      __mm512_kunpackbPtr.asFunction<int Function(int, int)>();

  int _mm512_kunpackw(
    int arg0,
    int arg1,
  ) {
    return __mm512_kunpackw(
      arg0,
      arg1,
    );
  }

  late final __mm512_kunpackwPtr =
      _lookup<ffi.NativeFunction<__mmask32 Function(__mmask32, __mmask32)>>(
          '_mm512_kunpackw');
  late final __mm512_kunpackw =
      __mm512_kunpackwPtr.asFunction<int Function(int, int)>();

  int _mm512_kunpackd(
    int arg0,
    int arg1,
  ) {
    return __mm512_kunpackd(
      arg0,
      arg1,
    );
  }

  late final __mm512_kunpackdPtr =
      _lookup<ffi.NativeFunction<__mmask64 Function(__mmask64, __mmask64)>>(
          '_mm512_kunpackd');
  late final __mm512_kunpackd =
      __mm512_kunpackdPtr.asFunction<int Function(int, int)>();

  int _mm512_testz_and_mask8(
    int arg0,
    int arg1,
  ) {
    return __mm512_testz_and_mask8(
      arg0,
      arg1,
    );
  }

  late final __mm512_testz_and_mask8Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint8 Function(__mmask8, __mmask8)>>(
          '_mm512_testz_and_mask8');
  late final __mm512_testz_and_mask8 =
      __mm512_testz_and_mask8Ptr.asFunction<int Function(int, int)>();

  int _mm512_testz_and_mask16(
    int arg0,
    int arg1,
  ) {
    return __mm512_testz_and_mask16(
      arg0,
      arg1,
    );
  }

  late final __mm512_testz_and_mask16Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint8 Function(__mmask16, __mmask16)>>(
          '_mm512_testz_and_mask16');
  late final __mm512_testz_and_mask16 =
      __mm512_testz_and_mask16Ptr.asFunction<int Function(int, int)>();

  int _mm512_testz_and_mask32(
    int arg0,
    int arg1,
  ) {
    return __mm512_testz_and_mask32(
      arg0,
      arg1,
    );
  }

  late final __mm512_testz_and_mask32Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint8 Function(__mmask32, __mmask32)>>(
          '_mm512_testz_and_mask32');
  late final __mm512_testz_and_mask32 =
      __mm512_testz_and_mask32Ptr.asFunction<int Function(int, int)>();

  int _mm512_testz_and_mask64(
    int arg0,
    int arg1,
  ) {
    return __mm512_testz_and_mask64(
      arg0,
      arg1,
    );
  }

  late final __mm512_testz_and_mask64Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint8 Function(__mmask64, __mmask64)>>(
          '_mm512_testz_and_mask64');
  late final __mm512_testz_and_mask64 =
      __mm512_testz_and_mask64Ptr.asFunction<int Function(int, int)>();

  int _mm512_testz_andn_mask8(
    int arg0,
    int arg1,
  ) {
    return __mm512_testz_andn_mask8(
      arg0,
      arg1,
    );
  }

  late final __mm512_testz_andn_mask8Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint8 Function(__mmask8, __mmask8)>>(
          '_mm512_testz_andn_mask8');
  late final __mm512_testz_andn_mask8 =
      __mm512_testz_andn_mask8Ptr.asFunction<int Function(int, int)>();

  int _mm512_testz_andn_mask16(
    int arg0,
    int arg1,
  ) {
    return __mm512_testz_andn_mask16(
      arg0,
      arg1,
    );
  }

  late final __mm512_testz_andn_mask16Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint8 Function(__mmask16, __mmask16)>>(
          '_mm512_testz_andn_mask16');
  late final __mm512_testz_andn_mask16 =
      __mm512_testz_andn_mask16Ptr.asFunction<int Function(int, int)>();

  int _mm512_testz_andn_mask32(
    int arg0,
    int arg1,
  ) {
    return __mm512_testz_andn_mask32(
      arg0,
      arg1,
    );
  }

  late final __mm512_testz_andn_mask32Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint8 Function(__mmask32, __mmask32)>>(
          '_mm512_testz_andn_mask32');
  late final __mm512_testz_andn_mask32 =
      __mm512_testz_andn_mask32Ptr.asFunction<int Function(int, int)>();

  int _mm512_testz_andn_mask64(
    int arg0,
    int arg1,
  ) {
    return __mm512_testz_andn_mask64(
      arg0,
      arg1,
    );
  }

  late final __mm512_testz_andn_mask64Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint8 Function(__mmask64, __mmask64)>>(
          '_mm512_testz_andn_mask64');
  late final __mm512_testz_andn_mask64 =
      __mm512_testz_andn_mask64Ptr.asFunction<int Function(int, int)>();

  int _mm512_testz_or_mask8(
    int arg0,
    int arg1,
  ) {
    return __mm512_testz_or_mask8(
      arg0,
      arg1,
    );
  }

  late final __mm512_testz_or_mask8Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint8 Function(__mmask8, __mmask8)>>(
          '_mm512_testz_or_mask8');
  late final __mm512_testz_or_mask8 =
      __mm512_testz_or_mask8Ptr.asFunction<int Function(int, int)>();

  int _mm512_testz_or_mask16(
    int arg0,
    int arg1,
  ) {
    return __mm512_testz_or_mask16(
      arg0,
      arg1,
    );
  }

  late final __mm512_testz_or_mask16Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint8 Function(__mmask16, __mmask16)>>(
          '_mm512_testz_or_mask16');
  late final __mm512_testz_or_mask16 =
      __mm512_testz_or_mask16Ptr.asFunction<int Function(int, int)>();

  int _mm512_testz_or_mask32(
    int arg0,
    int arg1,
  ) {
    return __mm512_testz_or_mask32(
      arg0,
      arg1,
    );
  }

  late final __mm512_testz_or_mask32Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint8 Function(__mmask32, __mmask32)>>(
          '_mm512_testz_or_mask32');
  late final __mm512_testz_or_mask32 =
      __mm512_testz_or_mask32Ptr.asFunction<int Function(int, int)>();

  int _mm512_testz_or_mask64(
    int arg0,
    int arg1,
  ) {
    return __mm512_testz_or_mask64(
      arg0,
      arg1,
    );
  }

  late final __mm512_testz_or_mask64Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint8 Function(__mmask64, __mmask64)>>(
          '_mm512_testz_or_mask64');
  late final __mm512_testz_or_mask64 =
      __mm512_testz_or_mask64Ptr.asFunction<int Function(int, int)>();

  int _mm512_testz_nor_mask8(
    int arg0,
    int arg1,
  ) {
    return __mm512_testz_nor_mask8(
      arg0,
      arg1,
    );
  }

  late final __mm512_testz_nor_mask8Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint8 Function(__mmask8, __mmask8)>>(
          '_mm512_testz_nor_mask8');
  late final __mm512_testz_nor_mask8 =
      __mm512_testz_nor_mask8Ptr.asFunction<int Function(int, int)>();

  int _mm512_testz_nor_mask16(
    int arg0,
    int arg1,
  ) {
    return __mm512_testz_nor_mask16(
      arg0,
      arg1,
    );
  }

  late final __mm512_testz_nor_mask16Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint8 Function(__mmask16, __mmask16)>>(
          '_mm512_testz_nor_mask16');
  late final __mm512_testz_nor_mask16 =
      __mm512_testz_nor_mask16Ptr.asFunction<int Function(int, int)>();

  int _mm512_testz_nor_mask32(
    int arg0,
    int arg1,
  ) {
    return __mm512_testz_nor_mask32(
      arg0,
      arg1,
    );
  }

  late final __mm512_testz_nor_mask32Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint8 Function(__mmask32, __mmask32)>>(
          '_mm512_testz_nor_mask32');
  late final __mm512_testz_nor_mask32 =
      __mm512_testz_nor_mask32Ptr.asFunction<int Function(int, int)>();

  int _mm512_testz_nor_mask64(
    int arg0,
    int arg1,
  ) {
    return __mm512_testz_nor_mask64(
      arg0,
      arg1,
    );
  }

  late final __mm512_testz_nor_mask64Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint8 Function(__mmask64, __mmask64)>>(
          '_mm512_testz_nor_mask64');
  late final __mm512_testz_nor_mask64 =
      __mm512_testz_nor_mask64Ptr.asFunction<int Function(int, int)>();

  __m512 _mm512_i32gather_ps(
    __m512i arg0,
    ffi.Pointer<ffi.Void> arg1,
    int arg2,
  ) {
    return __mm512_i32gather_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_i32gather_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__m512i, ffi.Pointer<ffi.Void>,
              ffi.Int32)>>('_mm512_i32gather_ps');
  late final __mm512_i32gather_ps = __mm512_i32gather_psPtr
      .asFunction<__m512 Function(__m512i, ffi.Pointer<ffi.Void>, int)>();

  __m512 _mm512_mask_i32gather_ps(
    __m512 arg0,
    int arg1,
    __m512i arg2,
    ffi.Pointer<ffi.Void> arg3,
    int arg4,
  ) {
    return __mm512_mask_i32gather_ps(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_i32gather_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__m512, __mmask16, __m512i, ffi.Pointer<ffi.Void>,
              ffi.Int32)>>('_mm512_mask_i32gather_ps');
  late final __mm512_mask_i32gather_ps =
      __mm512_mask_i32gather_psPtr.asFunction<
          __m512 Function(__m512, int, __m512i, ffi.Pointer<ffi.Void>, int)>();

  void _mm512_i32scatter_ps(
    ffi.Pointer<ffi.Void> arg0,
    __m512i arg1,
    __m512 arg2,
    int arg3,
  ) {
    return __mm512_i32scatter_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_i32scatter_psPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __m512i, __m512,
              ffi.Int32)>>('_mm512_i32scatter_ps');
  late final __mm512_i32scatter_ps = __mm512_i32scatter_psPtr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, __m512i, __m512, int)>();

  void _mm512_mask_i32scatter_ps(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m512i arg2,
    __m512 arg3,
    int arg4,
  ) {
    return __mm512_mask_i32scatter_ps(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_i32scatter_psPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask16, __m512i, __m512,
              ffi.Int32)>>('_mm512_mask_i32scatter_ps');
  late final __mm512_mask_i32scatter_ps =
      __mm512_mask_i32scatter_psPtr.asFunction<
          void Function(ffi.Pointer<ffi.Void>, int, __m512i, __m512, int)>();

  _m512d _mm512_i64gather_pd(
    __m512i arg0,
    ffi.Pointer<ffi.Void> arg1,
    int arg2,
  ) {
    return __mm512_i64gather_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_i64gather_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(__m512i, ffi.Pointer<ffi.Void>,
              ffi.Int32)>>('_mm512_i64gather_pd');
  late final __mm512_i64gather_pd = __mm512_i64gather_pdPtr
      .asFunction<_m512d Function(__m512i, ffi.Pointer<ffi.Void>, int)>();

  _m512d _mm512_mask_i64gather_pd(
    _m512d arg0,
    int arg1,
    __m512i arg2,
    ffi.Pointer<ffi.Void> arg3,
    int arg4,
  ) {
    return __mm512_mask_i64gather_pd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_i64gather_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(_m512d, __mmask8, __m512i, ffi.Pointer<ffi.Void>,
              ffi.Int32)>>('_mm512_mask_i64gather_pd');
  late final __mm512_mask_i64gather_pd =
      __mm512_mask_i64gather_pdPtr.asFunction<
          _m512d Function(_m512d, int, __m512i, ffi.Pointer<ffi.Void>, int)>();

  void _mm512_i64scatter_pd(
    ffi.Pointer<ffi.Void> arg0,
    __m512i arg1,
    _m512d arg2,
    int arg3,
  ) {
    return __mm512_i64scatter_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_i64scatter_pdPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __m512i, _m512d,
              ffi.Int32)>>('_mm512_i64scatter_pd');
  late final __mm512_i64scatter_pd = __mm512_i64scatter_pdPtr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, __m512i, _m512d, int)>();

  void _mm512_mask_i64scatter_pd(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m512i arg2,
    _m512d arg3,
    int arg4,
  ) {
    return __mm512_mask_i64scatter_pd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_i64scatter_pdPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8, __m512i, _m512d,
              ffi.Int32)>>('_mm512_mask_i64scatter_pd');
  late final __mm512_mask_i64scatter_pd =
      __mm512_mask_i64scatter_pdPtr.asFunction<
          void Function(ffi.Pointer<ffi.Void>, int, __m512i, _m512d, int)>();

  _m512d _mm512_i32gather_pd(
    __m256i arg0,
    ffi.Pointer<ffi.Void> arg1,
    int arg2,
  ) {
    return __mm512_i32gather_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_i32gather_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(__m256i, ffi.Pointer<ffi.Void>,
              ffi.Int32)>>('_mm512_i32gather_pd');
  late final __mm512_i32gather_pd = __mm512_i32gather_pdPtr
      .asFunction<_m512d Function(__m256i, ffi.Pointer<ffi.Void>, int)>();

  _m512d _mm512_mask_i32gather_pd(
    _m512d arg0,
    int arg1,
    __m256i arg2,
    ffi.Pointer<ffi.Void> arg3,
    int arg4,
  ) {
    return __mm512_mask_i32gather_pd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_i32gather_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(_m512d, __mmask8, __m256i, ffi.Pointer<ffi.Void>,
              ffi.Int32)>>('_mm512_mask_i32gather_pd');
  late final __mm512_mask_i32gather_pd =
      __mm512_mask_i32gather_pdPtr.asFunction<
          _m512d Function(_m512d, int, __m256i, ffi.Pointer<ffi.Void>, int)>();

  void _mm512_i32scatter_pd(
    ffi.Pointer<ffi.Void> arg0,
    __m256i arg1,
    _m512d arg2,
    int arg3,
  ) {
    return __mm512_i32scatter_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_i32scatter_pdPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __m256i, _m512d,
              ffi.Int32)>>('_mm512_i32scatter_pd');
  late final __mm512_i32scatter_pd = __mm512_i32scatter_pdPtr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, __m256i, _m512d, int)>();

  void _mm512_mask_i32scatter_pd(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m256i arg2,
    _m512d arg3,
    int arg4,
  ) {
    return __mm512_mask_i32scatter_pd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_i32scatter_pdPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8, __m256i, _m512d,
              ffi.Int32)>>('_mm512_mask_i32scatter_pd');
  late final __mm512_mask_i32scatter_pd =
      __mm512_mask_i32scatter_pdPtr.asFunction<
          void Function(ffi.Pointer<ffi.Void>, int, __m256i, _m512d, int)>();

  __m512i _mm512_i32gather_epi32(
    __m512i arg0,
    ffi.Pointer<ffi.Void> arg1,
    int arg2,
  ) {
    return __mm512_i32gather_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_i32gather_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, ffi.Pointer<ffi.Void>,
              ffi.Int32)>>('_mm512_i32gather_epi32');
  late final __mm512_i32gather_epi32 = __mm512_i32gather_epi32Ptr
      .asFunction<__m512i Function(__m512i, ffi.Pointer<ffi.Void>, int)>();

  __m512i _mm512_mask_i32gather_epi32(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    ffi.Pointer<ffi.Void> arg3,
    int arg4,
  ) {
    return __mm512_mask_i32gather_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_i32gather_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask16, __m512i, ffi.Pointer<ffi.Void>,
              ffi.Int32)>>('_mm512_mask_i32gather_epi32');
  late final __mm512_mask_i32gather_epi32 =
      __mm512_mask_i32gather_epi32Ptr.asFunction<
          __m512i Function(
              __m512i, int, __m512i, ffi.Pointer<ffi.Void>, int)>();

  void _mm512_i32scatter_epi32(
    ffi.Pointer<ffi.Void> arg0,
    __m512i arg1,
    __m512i arg2,
    int arg3,
  ) {
    return __mm512_i32scatter_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_i32scatter_epi32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __m512i, __m512i,
              ffi.Int32)>>('_mm512_i32scatter_epi32');
  late final __mm512_i32scatter_epi32 = __mm512_i32scatter_epi32Ptr.asFunction<
      void Function(ffi.Pointer<ffi.Void>, __m512i, __m512i, int)>();

  void _mm512_mask_i32scatter_epi32(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
    int arg4,
  ) {
    return __mm512_mask_i32scatter_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_i32scatter_epi32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask16, __m512i, __m512i,
              ffi.Int32)>>('_mm512_mask_i32scatter_epi32');
  late final __mm512_mask_i32scatter_epi32 =
      __mm512_mask_i32scatter_epi32Ptr.asFunction<
          void Function(ffi.Pointer<ffi.Void>, int, __m512i, __m512i, int)>();

  __m512i _mm512_i32gather_epi64(
    __m256i arg0,
    ffi.Pointer<ffi.Void> arg1,
    int arg2,
  ) {
    return __mm512_i32gather_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_i32gather_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m256i, ffi.Pointer<ffi.Void>,
              ffi.Int32)>>('_mm512_i32gather_epi64');
  late final __mm512_i32gather_epi64 = __mm512_i32gather_epi64Ptr
      .asFunction<__m512i Function(__m256i, ffi.Pointer<ffi.Void>, int)>();

  __m512i _mm512_mask_i32gather_epi64(
    __m512i arg0,
    int arg1,
    __m256i arg2,
    ffi.Pointer<ffi.Void> arg3,
    int arg4,
  ) {
    return __mm512_mask_i32gather_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_i32gather_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask8, __m256i, ffi.Pointer<ffi.Void>,
              ffi.Int32)>>('_mm512_mask_i32gather_epi64');
  late final __mm512_mask_i32gather_epi64 =
      __mm512_mask_i32gather_epi64Ptr.asFunction<
          __m512i Function(
              __m512i, int, __m256i, ffi.Pointer<ffi.Void>, int)>();

  __m512i _mm512_i64gather_epi64(
    __m512i arg0,
    ffi.Pointer<ffi.Void> arg1,
    int arg2,
  ) {
    return __mm512_i64gather_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_i64gather_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, ffi.Pointer<ffi.Void>,
              ffi.Int32)>>('_mm512_i64gather_epi64');
  late final __mm512_i64gather_epi64 = __mm512_i64gather_epi64Ptr
      .asFunction<__m512i Function(__m512i, ffi.Pointer<ffi.Void>, int)>();

  __m512i _mm512_mask_i64gather_epi64(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    ffi.Pointer<ffi.Void> arg3,
    int arg4,
  ) {
    return __mm512_mask_i64gather_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_i64gather_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask8, __m512i, ffi.Pointer<ffi.Void>,
              ffi.Int32)>>('_mm512_mask_i64gather_epi64');
  late final __mm512_mask_i64gather_epi64 =
      __mm512_mask_i64gather_epi64Ptr.asFunction<
          __m512i Function(
              __m512i, int, __m512i, ffi.Pointer<ffi.Void>, int)>();

  void _mm512_i32scatter_epi64(
    ffi.Pointer<ffi.Void> arg0,
    __m256i arg1,
    __m512i arg2,
    int arg3,
  ) {
    return __mm512_i32scatter_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_i32scatter_epi64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __m256i, __m512i,
              ffi.Int32)>>('_mm512_i32scatter_epi64');
  late final __mm512_i32scatter_epi64 = __mm512_i32scatter_epi64Ptr.asFunction<
      void Function(ffi.Pointer<ffi.Void>, __m256i, __m512i, int)>();

  void _mm512_mask_i32scatter_epi64(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m256i arg2,
    __m512i arg3,
    int arg4,
  ) {
    return __mm512_mask_i32scatter_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_i32scatter_epi64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8, __m256i, __m512i,
              ffi.Int32)>>('_mm512_mask_i32scatter_epi64');
  late final __mm512_mask_i32scatter_epi64 =
      __mm512_mask_i32scatter_epi64Ptr.asFunction<
          void Function(ffi.Pointer<ffi.Void>, int, __m256i, __m512i, int)>();

  void _mm512_i64scatter_epi64(
    ffi.Pointer<ffi.Void> arg0,
    __m512i arg1,
    __m512i arg2,
    int arg3,
  ) {
    return __mm512_i64scatter_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_i64scatter_epi64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __m512i, __m512i,
              ffi.Int32)>>('_mm512_i64scatter_epi64');
  late final __mm512_i64scatter_epi64 = __mm512_i64scatter_epi64Ptr.asFunction<
      void Function(ffi.Pointer<ffi.Void>, __m512i, __m512i, int)>();

  void _mm512_mask_i64scatter_epi64(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
    int arg4,
  ) {
    return __mm512_mask_i64scatter_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_i64scatter_epi64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8, __m512i, __m512i,
              ffi.Int32)>>('_mm512_mask_i64scatter_epi64');
  late final __mm512_mask_i64scatter_epi64 =
      __mm512_mask_i64scatter_epi64Ptr.asFunction<
          void Function(ffi.Pointer<ffi.Void>, int, __m512i, __m512i, int)>();

  __m256 _mm512_i64gather_ps(
    __m512i arg0,
    ffi.Pointer<ffi.Void> arg1,
    int arg2,
  ) {
    return __mm512_i64gather_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_i64gather_psPtr = _lookup<
      ffi.NativeFunction<
          __m256 Function(__m512i, ffi.Pointer<ffi.Void>,
              ffi.Int32)>>('_mm512_i64gather_ps');
  late final __mm512_i64gather_ps = __mm512_i64gather_psPtr
      .asFunction<__m256 Function(__m512i, ffi.Pointer<ffi.Void>, int)>();

  __m256 _mm512_mask_i64gather_ps(
    __m256 arg0,
    int arg1,
    __m512i arg2,
    ffi.Pointer<ffi.Void> arg3,
    int arg4,
  ) {
    return __mm512_mask_i64gather_ps(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_i64gather_psPtr = _lookup<
      ffi.NativeFunction<
          __m256 Function(__m256, __mmask8, __m512i, ffi.Pointer<ffi.Void>,
              ffi.Int32)>>('_mm512_mask_i64gather_ps');
  late final __mm512_mask_i64gather_ps =
      __mm512_mask_i64gather_psPtr.asFunction<
          __m256 Function(__m256, int, __m512i, ffi.Pointer<ffi.Void>, int)>();

  void _mm512_i64scatter_ps(
    ffi.Pointer<ffi.Void> arg0,
    __m512i arg1,
    __m256 arg2,
    int arg3,
  ) {
    return __mm512_i64scatter_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_i64scatter_psPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __m512i, __m256,
              ffi.Int32)>>('_mm512_i64scatter_ps');
  late final __mm512_i64scatter_ps = __mm512_i64scatter_psPtr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, __m512i, __m256, int)>();

  void _mm512_mask_i64scatter_ps(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m512i arg2,
    __m256 arg3,
    int arg4,
  ) {
    return __mm512_mask_i64scatter_ps(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_i64scatter_psPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8, __m512i, __m256,
              ffi.Int32)>>('_mm512_mask_i64scatter_ps');
  late final __mm512_mask_i64scatter_ps =
      __mm512_mask_i64scatter_psPtr.asFunction<
          void Function(ffi.Pointer<ffi.Void>, int, __m512i, __m256, int)>();

  __m256i _mm512_i64gather_epi32(
    __m512i arg0,
    ffi.Pointer<ffi.Void> arg1,
    int arg2,
  ) {
    return __mm512_i64gather_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_i64gather_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m512i, ffi.Pointer<ffi.Void>,
              ffi.Int32)>>('_mm512_i64gather_epi32');
  late final __mm512_i64gather_epi32 = __mm512_i64gather_epi32Ptr
      .asFunction<__m256i Function(__m512i, ffi.Pointer<ffi.Void>, int)>();

  __m256i _mm512_mask_i64gather_epi32(
    __m256i arg0,
    int arg1,
    __m512i arg2,
    ffi.Pointer<ffi.Void> arg3,
    int arg4,
  ) {
    return __mm512_mask_i64gather_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_i64gather_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask8, __m512i, ffi.Pointer<ffi.Void>,
              ffi.Int32)>>('_mm512_mask_i64gather_epi32');
  late final __mm512_mask_i64gather_epi32 =
      __mm512_mask_i64gather_epi32Ptr.asFunction<
          __m256i Function(
              __m256i, int, __m512i, ffi.Pointer<ffi.Void>, int)>();

  void _mm512_i64scatter_epi32(
    ffi.Pointer<ffi.Void> arg0,
    __m512i arg1,
    __m256i arg2,
    int arg3,
  ) {
    return __mm512_i64scatter_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_i64scatter_epi32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __m512i, __m256i,
              ffi.Int32)>>('_mm512_i64scatter_epi32');
  late final __mm512_i64scatter_epi32 = __mm512_i64scatter_epi32Ptr.asFunction<
      void Function(ffi.Pointer<ffi.Void>, __m512i, __m256i, int)>();

  void _mm512_mask_i64scatter_epi32(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m512i arg2,
    __m256i arg3,
    int arg4,
  ) {
    return __mm512_mask_i64scatter_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_i64scatter_epi32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8, __m512i, __m256i,
              ffi.Int32)>>('_mm512_mask_i64scatter_epi32');
  late final __mm512_mask_i64scatter_epi32 =
      __mm512_mask_i64scatter_epi32Ptr.asFunction<
          void Function(ffi.Pointer<ffi.Void>, int, __m512i, __m256i, int)>();

  _m512d _mm512_cvtpslo_pd(
    __m512 arg0,
  ) {
    return __mm512_cvtpslo_pd(
      arg0,
    );
  }

  late final __mm512_cvtpslo_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(__m512)>>('_mm512_cvtpslo_pd');
  late final __mm512_cvtpslo_pd =
      __mm512_cvtpslo_pdPtr.asFunction<_m512d Function(__m512)>();

  _m512d _mm512_mask_cvtpslo_pd(
    _m512d arg0,
    int arg1,
    __m512 arg2,
  ) {
    return __mm512_mask_cvtpslo_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtpslo_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, __mmask8, __m512)>>(
          '_mm512_mask_cvtpslo_pd');
  late final __mm512_mask_cvtpslo_pd = __mm512_mask_cvtpslo_pdPtr
      .asFunction<_m512d Function(_m512d, int, __m512)>();

  _m512d _mm512_cvtepi32lo_pd(
    __m512i arg0,
  ) {
    return __mm512_cvtepi32lo_pd(
      arg0,
    );
  }

  late final __mm512_cvtepi32lo_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(__m512i)>>(
          '_mm512_cvtepi32lo_pd');
  late final __mm512_cvtepi32lo_pd =
      __mm512_cvtepi32lo_pdPtr.asFunction<_m512d Function(__m512i)>();

  _m512d _mm512_mask_cvtepi32lo_pd(
    _m512d arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cvtepi32lo_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtepi32lo_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, __mmask8, __m512i)>>(
          '_mm512_mask_cvtepi32lo_pd');
  late final __mm512_mask_cvtepi32lo_pd = __mm512_mask_cvtepi32lo_pdPtr
      .asFunction<_m512d Function(_m512d, int, __m512i)>();

  _m512d _mm512_cvtepu32lo_pd(
    __m512i arg0,
  ) {
    return __mm512_cvtepu32lo_pd(
      arg0,
    );
  }

  late final __mm512_cvtepu32lo_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(__m512i)>>(
          '_mm512_cvtepu32lo_pd');
  late final __mm512_cvtepu32lo_pd =
      __mm512_cvtepu32lo_pdPtr.asFunction<_m512d Function(__m512i)>();

  _m512d _mm512_mask_cvtepu32lo_pd(
    _m512d arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cvtepu32lo_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtepu32lo_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, __mmask8, __m512i)>>(
          '_mm512_mask_cvtepu32lo_pd');
  late final __mm512_mask_cvtepu32lo_pd = __mm512_mask_cvtepu32lo_pdPtr
      .asFunction<_m512d Function(_m512d, int, __m512i)>();

  _m512d _mm512_cvtepi32_pd(
    __m256i arg0,
  ) {
    return __mm512_cvtepi32_pd(
      arg0,
    );
  }

  late final __mm512_cvtepi32_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(__m256i)>>(
          '_mm512_cvtepi32_pd');
  late final __mm512_cvtepi32_pd =
      __mm512_cvtepi32_pdPtr.asFunction<_m512d Function(__m256i)>();

  _m512d _mm512_mask_cvtepi32_pd(
    _m512d arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm512_mask_cvtepi32_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtepi32_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, __mmask8, __m256i)>>(
          '_mm512_mask_cvtepi32_pd');
  late final __mm512_mask_cvtepi32_pd = __mm512_mask_cvtepi32_pdPtr
      .asFunction<_m512d Function(_m512d, int, __m256i)>();

  _m512d _mm512_maskz_cvtepi32_pd(
    int arg0,
    __m256i arg1,
  ) {
    return __mm512_maskz_cvtepi32_pd(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvtepi32_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(__mmask8, __m256i)>>(
          '_mm512_maskz_cvtepi32_pd');
  late final __mm512_maskz_cvtepi32_pd =
      __mm512_maskz_cvtepi32_pdPtr.asFunction<_m512d Function(int, __m256i)>();

  _m512d _mm512_cvtepu32_pd(
    __m256i arg0,
  ) {
    return __mm512_cvtepu32_pd(
      arg0,
    );
  }

  late final __mm512_cvtepu32_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(__m256i)>>(
          '_mm512_cvtepu32_pd');
  late final __mm512_cvtepu32_pd =
      __mm512_cvtepu32_pdPtr.asFunction<_m512d Function(__m256i)>();

  _m512d _mm512_mask_cvtepu32_pd(
    _m512d arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm512_mask_cvtepu32_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtepu32_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, __mmask8, __m256i)>>(
          '_mm512_mask_cvtepu32_pd');
  late final __mm512_mask_cvtepu32_pd = __mm512_mask_cvtepu32_pdPtr
      .asFunction<_m512d Function(_m512d, int, __m256i)>();

  _m512d _mm512_maskz_cvtepu32_pd(
    int arg0,
    __m256i arg1,
  ) {
    return __mm512_maskz_cvtepu32_pd(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvtepu32_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(__mmask8, __m256i)>>(
          '_mm512_maskz_cvtepu32_pd');
  late final __mm512_maskz_cvtepu32_pd =
      __mm512_maskz_cvtepu32_pdPtr.asFunction<_m512d Function(int, __m256i)>();

  __m512 _mm512_cvtepi32_ps(
    __m512i arg0,
  ) {
    return __mm512_cvtepi32_ps(
      arg0,
    );
  }

  late final __mm512_cvtepi32_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512i)>>(
          '_mm512_cvtepi32_ps');
  late final __mm512_cvtepi32_ps =
      __mm512_cvtepi32_psPtr.asFunction<__m512 Function(__m512i)>();

  __m512 _mm512_mask_cvtepi32_ps(
    __m512 arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cvtepi32_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtepi32_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __mmask16, __m512i)>>(
          '_mm512_mask_cvtepi32_ps');
  late final __mm512_mask_cvtepi32_ps = __mm512_mask_cvtepi32_psPtr
      .asFunction<__m512 Function(__m512, int, __m512i)>();

  __m512 _mm512_maskz_cvtepi32_ps(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_maskz_cvtepi32_ps(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvtepi32_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__mmask16, __m512i)>>(
          '_mm512_maskz_cvtepi32_ps');
  late final __mm512_maskz_cvtepi32_ps =
      __mm512_maskz_cvtepi32_psPtr.asFunction<__m512 Function(int, __m512i)>();

  __m512 _mm512_cvt_roundepi32_ps(
    __m512i arg0,
    int arg1,
  ) {
    return __mm512_cvt_roundepi32_ps(
      arg0,
      arg1,
    );
  }

  late final __mm512_cvt_roundepi32_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512i, ffi.Int32)>>(
          '_mm512_cvt_roundepi32_ps');
  late final __mm512_cvt_roundepi32_ps =
      __mm512_cvt_roundepi32_psPtr.asFunction<__m512 Function(__m512i, int)>();

  __m512 _mm512_mask_cvt_roundepi32_ps(
    __m512 arg0,
    int arg1,
    __m512i arg2,
    int arg3,
  ) {
    return __mm512_mask_cvt_roundepi32_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_cvt_roundepi32_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__m512, __mmask16, __m512i,
              ffi.Int32)>>('_mm512_mask_cvt_roundepi32_ps');
  late final __mm512_mask_cvt_roundepi32_ps = __mm512_mask_cvt_roundepi32_psPtr
      .asFunction<__m512 Function(__m512, int, __m512i, int)>();

  __m512 _mm512_maskz_cvt_roundepi32_ps(
    int arg0,
    __m512i arg1,
    int arg2,
  ) {
    return __mm512_maskz_cvt_roundepi32_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_cvt_roundepi32_psPtr = _lookup<
          ffi.NativeFunction<__m512 Function(__mmask16, __m512i, ffi.Int32)>>(
      '_mm512_maskz_cvt_roundepi32_ps');
  late final __mm512_maskz_cvt_roundepi32_ps =
      __mm512_maskz_cvt_roundepi32_psPtr
          .asFunction<__m512 Function(int, __m512i, int)>();

  __m512 _mm512_cvtepu32_ps(
    __m512i arg0,
  ) {
    return __mm512_cvtepu32_ps(
      arg0,
    );
  }

  late final __mm512_cvtepu32_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512i)>>(
          '_mm512_cvtepu32_ps');
  late final __mm512_cvtepu32_ps =
      __mm512_cvtepu32_psPtr.asFunction<__m512 Function(__m512i)>();

  __m512 _mm512_mask_cvtepu32_ps(
    __m512 arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cvtepu32_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtepu32_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __mmask16, __m512i)>>(
          '_mm512_mask_cvtepu32_ps');
  late final __mm512_mask_cvtepu32_ps = __mm512_mask_cvtepu32_psPtr
      .asFunction<__m512 Function(__m512, int, __m512i)>();

  __m512 _mm512_maskz_cvtepu32_ps(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_maskz_cvtepu32_ps(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvtepu32_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__mmask16, __m512i)>>(
          '_mm512_maskz_cvtepu32_ps');
  late final __mm512_maskz_cvtepu32_ps =
      __mm512_maskz_cvtepu32_psPtr.asFunction<__m512 Function(int, __m512i)>();

  __m512 _mm512_cvt_roundepu32_ps(
    __m512i arg0,
    int arg1,
  ) {
    return __mm512_cvt_roundepu32_ps(
      arg0,
      arg1,
    );
  }

  late final __mm512_cvt_roundepu32_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512i, ffi.Int32)>>(
          '_mm512_cvt_roundepu32_ps');
  late final __mm512_cvt_roundepu32_ps =
      __mm512_cvt_roundepu32_psPtr.asFunction<__m512 Function(__m512i, int)>();

  __m512 _mm512_mask_cvt_roundepu32_ps(
    __m512 arg0,
    int arg1,
    __m512i arg2,
    int arg3,
  ) {
    return __mm512_mask_cvt_roundepu32_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_cvt_roundepu32_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__m512, __mmask16, __m512i,
              ffi.Int32)>>('_mm512_mask_cvt_roundepu32_ps');
  late final __mm512_mask_cvt_roundepu32_ps = __mm512_mask_cvt_roundepu32_psPtr
      .asFunction<__m512 Function(__m512, int, __m512i, int)>();

  __m512 _mm512_maskz_cvt_roundepu32_ps(
    int arg0,
    __m512i arg1,
    int arg2,
  ) {
    return __mm512_maskz_cvt_roundepu32_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_cvt_roundepu32_psPtr = _lookup<
          ffi.NativeFunction<__m512 Function(__mmask16, __m512i, ffi.Int32)>>(
      '_mm512_maskz_cvt_roundepu32_ps');
  late final __mm512_maskz_cvt_roundepu32_ps =
      __mm512_maskz_cvt_roundepu32_psPtr
          .asFunction<__m512 Function(int, __m512i, int)>();

  __m512 _mm512_cvtph_ps(
    __m256i arg0,
  ) {
    return __mm512_cvtph_ps(
      arg0,
    );
  }

  late final __mm512_cvtph_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m256i)>>('_mm512_cvtph_ps');
  late final __mm512_cvtph_ps =
      __mm512_cvtph_psPtr.asFunction<__m512 Function(__m256i)>();

  __m512 _mm512_mask_cvtph_ps(
    __m512 arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm512_mask_cvtph_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtph_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __mmask16, __m256i)>>(
          '_mm512_mask_cvtph_ps');
  late final __mm512_mask_cvtph_ps = __mm512_mask_cvtph_psPtr
      .asFunction<__m512 Function(__m512, int, __m256i)>();

  __m512 _mm512_maskz_cvtph_ps(
    int arg0,
    __m256i arg1,
  ) {
    return __mm512_maskz_cvtph_ps(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvtph_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__mmask16, __m256i)>>(
          '_mm512_maskz_cvtph_ps');
  late final __mm512_maskz_cvtph_ps =
      __mm512_maskz_cvtph_psPtr.asFunction<__m512 Function(int, __m256i)>();

  __m512 _mm512_cvt_roundph_ps(
    __m256i arg0,
    int arg1,
  ) {
    return __mm512_cvt_roundph_ps(
      arg0,
      arg1,
    );
  }

  late final __mm512_cvt_roundph_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m256i, ffi.Int32)>>(
          '_mm512_cvt_roundph_ps');
  late final __mm512_cvt_roundph_ps =
      __mm512_cvt_roundph_psPtr.asFunction<__m512 Function(__m256i, int)>();

  __m512 _mm512_mask_cvt_roundph_ps(
    __m512 arg0,
    int arg1,
    __m256i arg2,
    int arg3,
  ) {
    return __mm512_mask_cvt_roundph_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_cvt_roundph_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__m512, __mmask16, __m256i,
              ffi.Int32)>>('_mm512_mask_cvt_roundph_ps');
  late final __mm512_mask_cvt_roundph_ps = __mm512_mask_cvt_roundph_psPtr
      .asFunction<__m512 Function(__m512, int, __m256i, int)>();

  __m512 _mm512_maskz_cvt_roundph_ps(
    int arg0,
    __m256i arg1,
    int arg2,
  ) {
    return __mm512_maskz_cvt_roundph_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_cvt_roundph_psPtr = _lookup<
          ffi.NativeFunction<__m512 Function(__mmask16, __m256i, ffi.Int32)>>(
      '_mm512_maskz_cvt_roundph_ps');
  late final __mm512_maskz_cvt_roundph_ps = __mm512_maskz_cvt_roundph_psPtr
      .asFunction<__m512 Function(int, __m256i, int)>();

  __m256i _mm512_cvtps_ph(
    __m512 arg0,
    int arg1,
  ) {
    return __mm512_cvtps_ph(
      arg0,
      arg1,
    );
  }

  late final __mm512_cvtps_phPtr =
      _lookup<ffi.NativeFunction<__m256i Function(__m512, ffi.Int32)>>(
          '_mm512_cvtps_ph');
  late final __mm512_cvtps_ph =
      __mm512_cvtps_phPtr.asFunction<__m256i Function(__m512, int)>();

  __m256i _mm512_mask_cvtps_ph(
    __m256i arg0,
    int arg1,
    __m512 arg2,
    int arg3,
  ) {
    return __mm512_mask_cvtps_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_cvtps_phPtr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask16, __m512, ffi.Int32)>>('_mm512_mask_cvtps_ph');
  late final __mm512_mask_cvtps_ph = __mm512_mask_cvtps_phPtr
      .asFunction<__m256i Function(__m256i, int, __m512, int)>();

  __m256i _mm512_maskz_cvtps_ph(
    int arg0,
    __m512 arg1,
    int arg2,
  ) {
    return __mm512_maskz_cvtps_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_cvtps_phPtr = _lookup<
          ffi.NativeFunction<__m256i Function(__mmask16, __m512, ffi.Int32)>>(
      '_mm512_maskz_cvtps_ph');
  late final __mm512_maskz_cvtps_ph = __mm512_maskz_cvtps_phPtr
      .asFunction<__m256i Function(int, __m512, int)>();

  __m256i _mm512_cvt_roundps_ph(
    __m512 arg0,
    int arg1,
  ) {
    return __mm512_cvt_roundps_ph(
      arg0,
      arg1,
    );
  }

  late final __mm512_cvt_roundps_phPtr =
      _lookup<ffi.NativeFunction<__m256i Function(__m512, ffi.Int32)>>(
          '_mm512_cvt_roundps_ph');
  late final __mm512_cvt_roundps_ph =
      __mm512_cvt_roundps_phPtr.asFunction<__m256i Function(__m512, int)>();

  __m256i _mm512_mask_cvt_roundps_ph(
    __m256i arg0,
    int arg1,
    __m512 arg2,
    int arg3,
  ) {
    return __mm512_mask_cvt_roundps_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_cvt_roundps_phPtr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask16, __m512,
              ffi.Int32)>>('_mm512_mask_cvt_roundps_ph');
  late final __mm512_mask_cvt_roundps_ph = __mm512_mask_cvt_roundps_phPtr
      .asFunction<__m256i Function(__m256i, int, __m512, int)>();

  __m256i _mm512_maskz_cvt_roundps_ph(
    int arg0,
    __m512 arg1,
    int arg2,
  ) {
    return __mm512_maskz_cvt_roundps_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_cvt_roundps_phPtr = _lookup<
          ffi.NativeFunction<__m256i Function(__mmask16, __m512, ffi.Int32)>>(
      '_mm512_maskz_cvt_roundps_ph');
  late final __mm512_maskz_cvt_roundps_ph = __mm512_maskz_cvt_roundps_phPtr
      .asFunction<__m256i Function(int, __m512, int)>();

  __m256 _mm512_cvtepi64_ps(
    __m512i arg0,
  ) {
    return __mm512_cvtepi64_ps(
      arg0,
    );
  }

  late final __mm512_cvtepi64_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m512i)>>(
          '_mm512_cvtepi64_ps');
  late final __mm512_cvtepi64_ps =
      __mm512_cvtepi64_psPtr.asFunction<__m256 Function(__m512i)>();

  __m256 _mm512_mask_cvtepi64_ps(
    __m256 arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cvtepi64_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtepi64_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256, __mmask8, __m512i)>>(
          '_mm512_mask_cvtepi64_ps');
  late final __mm512_mask_cvtepi64_ps = __mm512_mask_cvtepi64_psPtr
      .asFunction<__m256 Function(__m256, int, __m512i)>();

  __m256 _mm512_maskz_cvtepi64_ps(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_maskz_cvtepi64_ps(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvtepi64_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__mmask8, __m512i)>>(
          '_mm512_maskz_cvtepi64_ps');
  late final __mm512_maskz_cvtepi64_ps =
      __mm512_maskz_cvtepi64_psPtr.asFunction<__m256 Function(int, __m512i)>();

  __m256 _mm512_cvt_roundepi64_ps(
    __m512i arg0,
    int arg1,
  ) {
    return __mm512_cvt_roundepi64_ps(
      arg0,
      arg1,
    );
  }

  late final __mm512_cvt_roundepi64_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m512i, ffi.Int32)>>(
          '_mm512_cvt_roundepi64_ps');
  late final __mm512_cvt_roundepi64_ps =
      __mm512_cvt_roundepi64_psPtr.asFunction<__m256 Function(__m512i, int)>();

  __m256 _mm512_mask_cvt_roundepi64_ps(
    __m256 arg0,
    int arg1,
    __m512i arg2,
    int arg3,
  ) {
    return __mm512_mask_cvt_roundepi64_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_cvt_roundepi64_psPtr = _lookup<
      ffi.NativeFunction<
          __m256 Function(__m256, __mmask8, __m512i,
              ffi.Int32)>>('_mm512_mask_cvt_roundepi64_ps');
  late final __mm512_mask_cvt_roundepi64_ps = __mm512_mask_cvt_roundepi64_psPtr
      .asFunction<__m256 Function(__m256, int, __m512i, int)>();

  __m256 _mm512_maskz_cvt_roundepi64_ps(
    int arg0,
    __m512i arg1,
    int arg2,
  ) {
    return __mm512_maskz_cvt_roundepi64_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_cvt_roundepi64_psPtr = _lookup<
          ffi.NativeFunction<__m256 Function(__mmask8, __m512i, ffi.Int32)>>(
      '_mm512_maskz_cvt_roundepi64_ps');
  late final __mm512_maskz_cvt_roundepi64_ps =
      __mm512_maskz_cvt_roundepi64_psPtr
          .asFunction<__m256 Function(int, __m512i, int)>();

  __m256 _mm512_cvtepu64_ps(
    __m512i arg0,
  ) {
    return __mm512_cvtepu64_ps(
      arg0,
    );
  }

  late final __mm512_cvtepu64_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m512i)>>(
          '_mm512_cvtepu64_ps');
  late final __mm512_cvtepu64_ps =
      __mm512_cvtepu64_psPtr.asFunction<__m256 Function(__m512i)>();

  __m256 _mm512_mask_cvtepu64_ps(
    __m256 arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cvtepu64_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtepu64_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256, __mmask8, __m512i)>>(
          '_mm512_mask_cvtepu64_ps');
  late final __mm512_mask_cvtepu64_ps = __mm512_mask_cvtepu64_psPtr
      .asFunction<__m256 Function(__m256, int, __m512i)>();

  __m256 _mm512_maskz_cvtepu64_ps(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_maskz_cvtepu64_ps(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvtepu64_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__mmask8, __m512i)>>(
          '_mm512_maskz_cvtepu64_ps');
  late final __mm512_maskz_cvtepu64_ps =
      __mm512_maskz_cvtepu64_psPtr.asFunction<__m256 Function(int, __m512i)>();

  __m256 _mm512_cvt_roundepu64_ps(
    __m512i arg0,
    int arg1,
  ) {
    return __mm512_cvt_roundepu64_ps(
      arg0,
      arg1,
    );
  }

  late final __mm512_cvt_roundepu64_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m512i, ffi.Int32)>>(
          '_mm512_cvt_roundepu64_ps');
  late final __mm512_cvt_roundepu64_ps =
      __mm512_cvt_roundepu64_psPtr.asFunction<__m256 Function(__m512i, int)>();

  __m256 _mm512_mask_cvt_roundepu64_ps(
    __m256 arg0,
    int arg1,
    __m512i arg2,
    int arg3,
  ) {
    return __mm512_mask_cvt_roundepu64_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_cvt_roundepu64_psPtr = _lookup<
      ffi.NativeFunction<
          __m256 Function(__m256, __mmask8, __m512i,
              ffi.Int32)>>('_mm512_mask_cvt_roundepu64_ps');
  late final __mm512_mask_cvt_roundepu64_ps = __mm512_mask_cvt_roundepu64_psPtr
      .asFunction<__m256 Function(__m256, int, __m512i, int)>();

  __m256 _mm512_maskz_cvt_roundepu64_ps(
    int arg0,
    __m512i arg1,
    int arg2,
  ) {
    return __mm512_maskz_cvt_roundepu64_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_cvt_roundepu64_psPtr = _lookup<
          ffi.NativeFunction<__m256 Function(__mmask8, __m512i, ffi.Int32)>>(
      '_mm512_maskz_cvt_roundepu64_ps');
  late final __mm512_maskz_cvt_roundepu64_ps =
      __mm512_maskz_cvt_roundepu64_psPtr
          .asFunction<__m256 Function(int, __m512i, int)>();

  __m512i _mm512_cvtepi8_epi32(
    __m128i arg0,
  ) {
    return __mm512_cvtepi8_epi32(
      arg0,
    );
  }

  late final __mm512_cvtepi8_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m128i)>>(
          '_mm512_cvtepi8_epi32');
  late final __mm512_cvtepi8_epi32 =
      __mm512_cvtepi8_epi32Ptr.asFunction<__m512i Function(__m128i)>();

  __m512i _mm512_mask_cvtepi8_epi32(
    __m512i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm512_mask_cvtepi8_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtepi8_epi32Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__m512i, __mmask16, __m128i)>>(
      '_mm512_mask_cvtepi8_epi32');
  late final __mm512_mask_cvtepi8_epi32 = __mm512_mask_cvtepi8_epi32Ptr
      .asFunction<__m512i Function(__m512i, int, __m128i)>();

  __m512i _mm512_maskz_cvtepi8_epi32(
    int arg0,
    __m128i arg1,
  ) {
    return __mm512_maskz_cvtepi8_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvtepi8_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask16, __m128i)>>(
          '_mm512_maskz_cvtepi8_epi32');
  late final __mm512_maskz_cvtepi8_epi32 = __mm512_maskz_cvtepi8_epi32Ptr
      .asFunction<__m512i Function(int, __m128i)>();

  __m512i _mm512_cvtepi8_epi64(
    __m128i arg0,
  ) {
    return __mm512_cvtepi8_epi64(
      arg0,
    );
  }

  late final __mm512_cvtepi8_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m128i)>>(
          '_mm512_cvtepi8_epi64');
  late final __mm512_cvtepi8_epi64 =
      __mm512_cvtepi8_epi64Ptr.asFunction<__m512i Function(__m128i)>();

  __m512i _mm512_mask_cvtepi8_epi64(
    __m512i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm512_mask_cvtepi8_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtepi8_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __mmask8, __m128i)>>(
          '_mm512_mask_cvtepi8_epi64');
  late final __mm512_mask_cvtepi8_epi64 = __mm512_mask_cvtepi8_epi64Ptr
      .asFunction<__m512i Function(__m512i, int, __m128i)>();

  __m512i _mm512_maskz_cvtepi8_epi64(
    int arg0,
    __m128i arg1,
  ) {
    return __mm512_maskz_cvtepi8_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvtepi8_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask8, __m128i)>>(
          '_mm512_maskz_cvtepi8_epi64');
  late final __mm512_maskz_cvtepi8_epi64 = __mm512_maskz_cvtepi8_epi64Ptr
      .asFunction<__m512i Function(int, __m128i)>();

  __m512i _mm512_cvtepi16_epi32(
    __m256i arg0,
  ) {
    return __mm512_cvtepi16_epi32(
      arg0,
    );
  }

  late final __mm512_cvtepi16_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m256i)>>(
          '_mm512_cvtepi16_epi32');
  late final __mm512_cvtepi16_epi32 =
      __mm512_cvtepi16_epi32Ptr.asFunction<__m512i Function(__m256i)>();

  __m512i _mm512_mask_cvtepi16_epi32(
    __m512i arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm512_mask_cvtepi16_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtepi16_epi32Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__m512i, __mmask16, __m256i)>>(
      '_mm512_mask_cvtepi16_epi32');
  late final __mm512_mask_cvtepi16_epi32 = __mm512_mask_cvtepi16_epi32Ptr
      .asFunction<__m512i Function(__m512i, int, __m256i)>();

  __m512i _mm512_maskz_cvtepi16_epi32(
    int arg0,
    __m256i arg1,
  ) {
    return __mm512_maskz_cvtepi16_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvtepi16_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask16, __m256i)>>(
          '_mm512_maskz_cvtepi16_epi32');
  late final __mm512_maskz_cvtepi16_epi32 = __mm512_maskz_cvtepi16_epi32Ptr
      .asFunction<__m512i Function(int, __m256i)>();

  __m512i _mm512_cvtepi16_epi64(
    __m128i arg0,
  ) {
    return __mm512_cvtepi16_epi64(
      arg0,
    );
  }

  late final __mm512_cvtepi16_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m128i)>>(
          '_mm512_cvtepi16_epi64');
  late final __mm512_cvtepi16_epi64 =
      __mm512_cvtepi16_epi64Ptr.asFunction<__m512i Function(__m128i)>();

  __m512i _mm512_mask_cvtepi16_epi64(
    __m512i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm512_mask_cvtepi16_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtepi16_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __mmask8, __m128i)>>(
          '_mm512_mask_cvtepi16_epi64');
  late final __mm512_mask_cvtepi16_epi64 = __mm512_mask_cvtepi16_epi64Ptr
      .asFunction<__m512i Function(__m512i, int, __m128i)>();

  __m512i _mm512_maskz_cvtepi16_epi64(
    int arg0,
    __m128i arg1,
  ) {
    return __mm512_maskz_cvtepi16_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvtepi16_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask8, __m128i)>>(
          '_mm512_maskz_cvtepi16_epi64');
  late final __mm512_maskz_cvtepi16_epi64 = __mm512_maskz_cvtepi16_epi64Ptr
      .asFunction<__m512i Function(int, __m128i)>();

  __m128i _mm512_cvtepi32_epi8(
    __m512i arg0,
  ) {
    return __mm512_cvtepi32_epi8(
      arg0,
    );
  }

  late final __mm512_cvtepi32_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m512i)>>(
          '_mm512_cvtepi32_epi8');
  late final __mm512_cvtepi32_epi8 =
      __mm512_cvtepi32_epi8Ptr.asFunction<__m128i Function(__m512i)>();

  __m128i _mm512_mask_cvtepi32_epi8(
    __m128i arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cvtepi32_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtepi32_epi8Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__m128i, __mmask16, __m512i)>>(
      '_mm512_mask_cvtepi32_epi8');
  late final __mm512_mask_cvtepi32_epi8 = __mm512_mask_cvtepi32_epi8Ptr
      .asFunction<__m128i Function(__m128i, int, __m512i)>();

  __m128i _mm512_maskz_cvtepi32_epi8(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_maskz_cvtepi32_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvtepi32_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask16, __m512i)>>(
          '_mm512_maskz_cvtepi32_epi8');
  late final __mm512_maskz_cvtepi32_epi8 = __mm512_maskz_cvtepi32_epi8Ptr
      .asFunction<__m128i Function(int, __m512i)>();

  void _mm512_mask_cvtepi32_storeu_epi8(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cvtepi32_storeu_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtepi32_storeu_epi8Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask16,
              __m512i)>>('_mm512_mask_cvtepi32_storeu_epi8');
  late final __mm512_mask_cvtepi32_storeu_epi8 =
      __mm512_mask_cvtepi32_storeu_epi8Ptr
          .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m512i)>();

  __m128i _mm512_cvtsepi32_epi8(
    __m512i arg0,
  ) {
    return __mm512_cvtsepi32_epi8(
      arg0,
    );
  }

  late final __mm512_cvtsepi32_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m512i)>>(
          '_mm512_cvtsepi32_epi8');
  late final __mm512_cvtsepi32_epi8 =
      __mm512_cvtsepi32_epi8Ptr.asFunction<__m128i Function(__m512i)>();

  __m128i _mm512_mask_cvtsepi32_epi8(
    __m128i arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cvtsepi32_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtsepi32_epi8Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__m128i, __mmask16, __m512i)>>(
      '_mm512_mask_cvtsepi32_epi8');
  late final __mm512_mask_cvtsepi32_epi8 = __mm512_mask_cvtsepi32_epi8Ptr
      .asFunction<__m128i Function(__m128i, int, __m512i)>();

  __m128i _mm512_maskz_cvtsepi32_epi8(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_maskz_cvtsepi32_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvtsepi32_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask16, __m512i)>>(
          '_mm512_maskz_cvtsepi32_epi8');
  late final __mm512_maskz_cvtsepi32_epi8 = __mm512_maskz_cvtsepi32_epi8Ptr
      .asFunction<__m128i Function(int, __m512i)>();

  void _mm512_mask_cvtsepi32_storeu_epi8(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cvtsepi32_storeu_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtsepi32_storeu_epi8Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask16,
              __m512i)>>('_mm512_mask_cvtsepi32_storeu_epi8');
  late final __mm512_mask_cvtsepi32_storeu_epi8 =
      __mm512_mask_cvtsepi32_storeu_epi8Ptr
          .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m512i)>();

  __m128i _mm512_cvtusepi32_epi8(
    __m512i arg0,
  ) {
    return __mm512_cvtusepi32_epi8(
      arg0,
    );
  }

  late final __mm512_cvtusepi32_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m512i)>>(
          '_mm512_cvtusepi32_epi8');
  late final __mm512_cvtusepi32_epi8 =
      __mm512_cvtusepi32_epi8Ptr.asFunction<__m128i Function(__m512i)>();

  __m128i _mm512_mask_cvtusepi32_epi8(
    __m128i arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cvtusepi32_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtusepi32_epi8Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__m128i, __mmask16, __m512i)>>(
      '_mm512_mask_cvtusepi32_epi8');
  late final __mm512_mask_cvtusepi32_epi8 = __mm512_mask_cvtusepi32_epi8Ptr
      .asFunction<__m128i Function(__m128i, int, __m512i)>();

  __m128i _mm512_maskz_cvtusepi32_epi8(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_maskz_cvtusepi32_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvtusepi32_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask16, __m512i)>>(
          '_mm512_maskz_cvtusepi32_epi8');
  late final __mm512_maskz_cvtusepi32_epi8 = __mm512_maskz_cvtusepi32_epi8Ptr
      .asFunction<__m128i Function(int, __m512i)>();

  void _mm512_mask_cvtusepi32_storeu_epi8(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cvtusepi32_storeu_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtusepi32_storeu_epi8Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask16,
              __m512i)>>('_mm512_mask_cvtusepi32_storeu_epi8');
  late final __mm512_mask_cvtusepi32_storeu_epi8 =
      __mm512_mask_cvtusepi32_storeu_epi8Ptr
          .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m512i)>();

  __m256i _mm512_cvtepi32_epi16(
    __m512i arg0,
  ) {
    return __mm512_cvtepi32_epi16(
      arg0,
    );
  }

  late final __mm512_cvtepi32_epi16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m512i)>>(
          '_mm512_cvtepi32_epi16');
  late final __mm512_cvtepi32_epi16 =
      __mm512_cvtepi32_epi16Ptr.asFunction<__m256i Function(__m512i)>();

  __m256i _mm512_mask_cvtepi32_epi16(
    __m256i arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cvtepi32_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtepi32_epi16Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__m256i, __mmask16, __m512i)>>(
      '_mm512_mask_cvtepi32_epi16');
  late final __mm512_mask_cvtepi32_epi16 = __mm512_mask_cvtepi32_epi16Ptr
      .asFunction<__m256i Function(__m256i, int, __m512i)>();

  __m256i _mm512_maskz_cvtepi32_epi16(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_maskz_cvtepi32_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvtepi32_epi16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask16, __m512i)>>(
          '_mm512_maskz_cvtepi32_epi16');
  late final __mm512_maskz_cvtepi32_epi16 = __mm512_maskz_cvtepi32_epi16Ptr
      .asFunction<__m256i Function(int, __m512i)>();

  void _mm512_mask_cvtepi32_storeu_epi16(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cvtepi32_storeu_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtepi32_storeu_epi16Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask16,
              __m512i)>>('_mm512_mask_cvtepi32_storeu_epi16');
  late final __mm512_mask_cvtepi32_storeu_epi16 =
      __mm512_mask_cvtepi32_storeu_epi16Ptr
          .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m512i)>();

  __m256i _mm512_cvtsepi32_epi16(
    __m512i arg0,
  ) {
    return __mm512_cvtsepi32_epi16(
      arg0,
    );
  }

  late final __mm512_cvtsepi32_epi16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m512i)>>(
          '_mm512_cvtsepi32_epi16');
  late final __mm512_cvtsepi32_epi16 =
      __mm512_cvtsepi32_epi16Ptr.asFunction<__m256i Function(__m512i)>();

  __m256i _mm512_mask_cvtsepi32_epi16(
    __m256i arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cvtsepi32_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtsepi32_epi16Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__m256i, __mmask16, __m512i)>>(
      '_mm512_mask_cvtsepi32_epi16');
  late final __mm512_mask_cvtsepi32_epi16 = __mm512_mask_cvtsepi32_epi16Ptr
      .asFunction<__m256i Function(__m256i, int, __m512i)>();

  __m256i _mm512_maskz_cvtsepi32_epi16(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_maskz_cvtsepi32_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvtsepi32_epi16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask16, __m512i)>>(
          '_mm512_maskz_cvtsepi32_epi16');
  late final __mm512_maskz_cvtsepi32_epi16 = __mm512_maskz_cvtsepi32_epi16Ptr
      .asFunction<__m256i Function(int, __m512i)>();

  void _mm512_mask_cvtsepi32_storeu_epi16(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cvtsepi32_storeu_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtsepi32_storeu_epi16Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask16,
              __m512i)>>('_mm512_mask_cvtsepi32_storeu_epi16');
  late final __mm512_mask_cvtsepi32_storeu_epi16 =
      __mm512_mask_cvtsepi32_storeu_epi16Ptr
          .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m512i)>();

  __m256i _mm512_cvtusepi32_epi16(
    __m512i arg0,
  ) {
    return __mm512_cvtusepi32_epi16(
      arg0,
    );
  }

  late final __mm512_cvtusepi32_epi16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m512i)>>(
          '_mm512_cvtusepi32_epi16');
  late final __mm512_cvtusepi32_epi16 =
      __mm512_cvtusepi32_epi16Ptr.asFunction<__m256i Function(__m512i)>();

  __m256i _mm512_mask_cvtusepi32_epi16(
    __m256i arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cvtusepi32_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtusepi32_epi16Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__m256i, __mmask16, __m512i)>>(
      '_mm512_mask_cvtusepi32_epi16');
  late final __mm512_mask_cvtusepi32_epi16 = __mm512_mask_cvtusepi32_epi16Ptr
      .asFunction<__m256i Function(__m256i, int, __m512i)>();

  __m256i _mm512_maskz_cvtusepi32_epi16(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_maskz_cvtusepi32_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvtusepi32_epi16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask16, __m512i)>>(
          '_mm512_maskz_cvtusepi32_epi16');
  late final __mm512_maskz_cvtusepi32_epi16 = __mm512_maskz_cvtusepi32_epi16Ptr
      .asFunction<__m256i Function(int, __m512i)>();

  void _mm512_mask_cvtusepi32_storeu_epi16(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cvtusepi32_storeu_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtusepi32_storeu_epi16Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask16,
              __m512i)>>('_mm512_mask_cvtusepi32_storeu_epi16');
  late final __mm512_mask_cvtusepi32_storeu_epi16 =
      __mm512_mask_cvtusepi32_storeu_epi16Ptr
          .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m512i)>();

  __m512i _mm512_cvtepi32_epi64(
    __m256i arg0,
  ) {
    return __mm512_cvtepi32_epi64(
      arg0,
    );
  }

  late final __mm512_cvtepi32_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m256i)>>(
          '_mm512_cvtepi32_epi64');
  late final __mm512_cvtepi32_epi64 =
      __mm512_cvtepi32_epi64Ptr.asFunction<__m512i Function(__m256i)>();

  __m512i _mm512_mask_cvtepi32_epi64(
    __m512i arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm512_mask_cvtepi32_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtepi32_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __mmask8, __m256i)>>(
          '_mm512_mask_cvtepi32_epi64');
  late final __mm512_mask_cvtepi32_epi64 = __mm512_mask_cvtepi32_epi64Ptr
      .asFunction<__m512i Function(__m512i, int, __m256i)>();

  __m512i _mm512_maskz_cvtepi32_epi64(
    int arg0,
    __m256i arg1,
  ) {
    return __mm512_maskz_cvtepi32_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvtepi32_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask8, __m256i)>>(
          '_mm512_maskz_cvtepi32_epi64');
  late final __mm512_maskz_cvtepi32_epi64 = __mm512_maskz_cvtepi32_epi64Ptr
      .asFunction<__m512i Function(int, __m256i)>();

  __m128i _mm512_cvtepi64_epi8(
    __m512i arg0,
  ) {
    return __mm512_cvtepi64_epi8(
      arg0,
    );
  }

  late final __mm512_cvtepi64_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m512i)>>(
          '_mm512_cvtepi64_epi8');
  late final __mm512_cvtepi64_epi8 =
      __mm512_cvtepi64_epi8Ptr.asFunction<__m128i Function(__m512i)>();

  __m128i _mm512_mask_cvtepi64_epi8(
    __m128i arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cvtepi64_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtepi64_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m512i)>>(
          '_mm512_mask_cvtepi64_epi8');
  late final __mm512_mask_cvtepi64_epi8 = __mm512_mask_cvtepi64_epi8Ptr
      .asFunction<__m128i Function(__m128i, int, __m512i)>();

  __m128i _mm512_maskz_cvtepi64_epi8(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_maskz_cvtepi64_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvtepi64_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m512i)>>(
          '_mm512_maskz_cvtepi64_epi8');
  late final __mm512_maskz_cvtepi64_epi8 = __mm512_maskz_cvtepi64_epi8Ptr
      .asFunction<__m128i Function(int, __m512i)>();

  void _mm512_mask_cvtepi64_storeu_epi8(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cvtepi64_storeu_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtepi64_storeu_epi8Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8,
              __m512i)>>('_mm512_mask_cvtepi64_storeu_epi8');
  late final __mm512_mask_cvtepi64_storeu_epi8 =
      __mm512_mask_cvtepi64_storeu_epi8Ptr
          .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m512i)>();

  __m128i _mm512_cvtsepi64_epi8(
    __m512i arg0,
  ) {
    return __mm512_cvtsepi64_epi8(
      arg0,
    );
  }

  late final __mm512_cvtsepi64_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m512i)>>(
          '_mm512_cvtsepi64_epi8');
  late final __mm512_cvtsepi64_epi8 =
      __mm512_cvtsepi64_epi8Ptr.asFunction<__m128i Function(__m512i)>();

  __m128i _mm512_mask_cvtsepi64_epi8(
    __m128i arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cvtsepi64_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtsepi64_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m512i)>>(
          '_mm512_mask_cvtsepi64_epi8');
  late final __mm512_mask_cvtsepi64_epi8 = __mm512_mask_cvtsepi64_epi8Ptr
      .asFunction<__m128i Function(__m128i, int, __m512i)>();

  __m128i _mm512_maskz_cvtsepi64_epi8(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_maskz_cvtsepi64_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvtsepi64_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m512i)>>(
          '_mm512_maskz_cvtsepi64_epi8');
  late final __mm512_maskz_cvtsepi64_epi8 = __mm512_maskz_cvtsepi64_epi8Ptr
      .asFunction<__m128i Function(int, __m512i)>();

  void _mm512_mask_cvtsepi64_storeu_epi8(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cvtsepi64_storeu_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtsepi64_storeu_epi8Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8,
              __m512i)>>('_mm512_mask_cvtsepi64_storeu_epi8');
  late final __mm512_mask_cvtsepi64_storeu_epi8 =
      __mm512_mask_cvtsepi64_storeu_epi8Ptr
          .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m512i)>();

  __m128i _mm512_cvtusepi64_epi8(
    __m512i arg0,
  ) {
    return __mm512_cvtusepi64_epi8(
      arg0,
    );
  }

  late final __mm512_cvtusepi64_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m512i)>>(
          '_mm512_cvtusepi64_epi8');
  late final __mm512_cvtusepi64_epi8 =
      __mm512_cvtusepi64_epi8Ptr.asFunction<__m128i Function(__m512i)>();

  __m128i _mm512_mask_cvtusepi64_epi8(
    __m128i arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cvtusepi64_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtusepi64_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m512i)>>(
          '_mm512_mask_cvtusepi64_epi8');
  late final __mm512_mask_cvtusepi64_epi8 = __mm512_mask_cvtusepi64_epi8Ptr
      .asFunction<__m128i Function(__m128i, int, __m512i)>();

  __m128i _mm512_maskz_cvtusepi64_epi8(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_maskz_cvtusepi64_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvtusepi64_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m512i)>>(
          '_mm512_maskz_cvtusepi64_epi8');
  late final __mm512_maskz_cvtusepi64_epi8 = __mm512_maskz_cvtusepi64_epi8Ptr
      .asFunction<__m128i Function(int, __m512i)>();

  void _mm512_mask_cvtusepi64_storeu_epi8(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cvtusepi64_storeu_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtusepi64_storeu_epi8Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8,
              __m512i)>>('_mm512_mask_cvtusepi64_storeu_epi8');
  late final __mm512_mask_cvtusepi64_storeu_epi8 =
      __mm512_mask_cvtusepi64_storeu_epi8Ptr
          .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m512i)>();

  __m128i _mm512_cvtepi64_epi16(
    __m512i arg0,
  ) {
    return __mm512_cvtepi64_epi16(
      arg0,
    );
  }

  late final __mm512_cvtepi64_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m512i)>>(
          '_mm512_cvtepi64_epi16');
  late final __mm512_cvtepi64_epi16 =
      __mm512_cvtepi64_epi16Ptr.asFunction<__m128i Function(__m512i)>();

  __m128i _mm512_mask_cvtepi64_epi16(
    __m128i arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cvtepi64_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtepi64_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m512i)>>(
          '_mm512_mask_cvtepi64_epi16');
  late final __mm512_mask_cvtepi64_epi16 = __mm512_mask_cvtepi64_epi16Ptr
      .asFunction<__m128i Function(__m128i, int, __m512i)>();

  __m128i _mm512_maskz_cvtepi64_epi16(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_maskz_cvtepi64_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvtepi64_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m512i)>>(
          '_mm512_maskz_cvtepi64_epi16');
  late final __mm512_maskz_cvtepi64_epi16 = __mm512_maskz_cvtepi64_epi16Ptr
      .asFunction<__m128i Function(int, __m512i)>();

  void _mm512_mask_cvtepi64_storeu_epi16(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cvtepi64_storeu_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtepi64_storeu_epi16Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8,
              __m512i)>>('_mm512_mask_cvtepi64_storeu_epi16');
  late final __mm512_mask_cvtepi64_storeu_epi16 =
      __mm512_mask_cvtepi64_storeu_epi16Ptr
          .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m512i)>();

  __m128i _mm512_cvtsepi64_epi16(
    __m512i arg0,
  ) {
    return __mm512_cvtsepi64_epi16(
      arg0,
    );
  }

  late final __mm512_cvtsepi64_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m512i)>>(
          '_mm512_cvtsepi64_epi16');
  late final __mm512_cvtsepi64_epi16 =
      __mm512_cvtsepi64_epi16Ptr.asFunction<__m128i Function(__m512i)>();

  __m128i _mm512_mask_cvtsepi64_epi16(
    __m128i arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cvtsepi64_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtsepi64_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m512i)>>(
          '_mm512_mask_cvtsepi64_epi16');
  late final __mm512_mask_cvtsepi64_epi16 = __mm512_mask_cvtsepi64_epi16Ptr
      .asFunction<__m128i Function(__m128i, int, __m512i)>();

  __m128i _mm512_maskz_cvtsepi64_epi16(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_maskz_cvtsepi64_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvtsepi64_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m512i)>>(
          '_mm512_maskz_cvtsepi64_epi16');
  late final __mm512_maskz_cvtsepi64_epi16 = __mm512_maskz_cvtsepi64_epi16Ptr
      .asFunction<__m128i Function(int, __m512i)>();

  void _mm512_mask_cvtsepi64_storeu_epi16(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cvtsepi64_storeu_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtsepi64_storeu_epi16Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8,
              __m512i)>>('_mm512_mask_cvtsepi64_storeu_epi16');
  late final __mm512_mask_cvtsepi64_storeu_epi16 =
      __mm512_mask_cvtsepi64_storeu_epi16Ptr
          .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m512i)>();

  __m128i _mm512_cvtusepi64_epi16(
    __m512i arg0,
  ) {
    return __mm512_cvtusepi64_epi16(
      arg0,
    );
  }

  late final __mm512_cvtusepi64_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m512i)>>(
          '_mm512_cvtusepi64_epi16');
  late final __mm512_cvtusepi64_epi16 =
      __mm512_cvtusepi64_epi16Ptr.asFunction<__m128i Function(__m512i)>();

  __m128i _mm512_mask_cvtusepi64_epi16(
    __m128i arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cvtusepi64_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtusepi64_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m512i)>>(
          '_mm512_mask_cvtusepi64_epi16');
  late final __mm512_mask_cvtusepi64_epi16 = __mm512_mask_cvtusepi64_epi16Ptr
      .asFunction<__m128i Function(__m128i, int, __m512i)>();

  __m128i _mm512_maskz_cvtusepi64_epi16(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_maskz_cvtusepi64_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvtusepi64_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m512i)>>(
          '_mm512_maskz_cvtusepi64_epi16');
  late final __mm512_maskz_cvtusepi64_epi16 = __mm512_maskz_cvtusepi64_epi16Ptr
      .asFunction<__m128i Function(int, __m512i)>();

  void _mm512_mask_cvtusepi64_storeu_epi16(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cvtusepi64_storeu_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtusepi64_storeu_epi16Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8,
              __m512i)>>('_mm512_mask_cvtusepi64_storeu_epi16');
  late final __mm512_mask_cvtusepi64_storeu_epi16 =
      __mm512_mask_cvtusepi64_storeu_epi16Ptr
          .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m512i)>();

  __m256i _mm512_cvtepi64_epi32(
    __m512i arg0,
  ) {
    return __mm512_cvtepi64_epi32(
      arg0,
    );
  }

  late final __mm512_cvtepi64_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m512i)>>(
          '_mm512_cvtepi64_epi32');
  late final __mm512_cvtepi64_epi32 =
      __mm512_cvtepi64_epi32Ptr.asFunction<__m256i Function(__m512i)>();

  __m256i _mm512_mask_cvtepi64_epi32(
    __m256i arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cvtepi64_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtepi64_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __mmask8, __m512i)>>(
          '_mm512_mask_cvtepi64_epi32');
  late final __mm512_mask_cvtepi64_epi32 = __mm512_mask_cvtepi64_epi32Ptr
      .asFunction<__m256i Function(__m256i, int, __m512i)>();

  __m256i _mm512_maskz_cvtepi64_epi32(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_maskz_cvtepi64_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvtepi64_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m512i)>>(
          '_mm512_maskz_cvtepi64_epi32');
  late final __mm512_maskz_cvtepi64_epi32 = __mm512_maskz_cvtepi64_epi32Ptr
      .asFunction<__m256i Function(int, __m512i)>();

  void _mm512_mask_cvtepi64_storeu_epi32(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cvtepi64_storeu_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtepi64_storeu_epi32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8,
              __m512i)>>('_mm512_mask_cvtepi64_storeu_epi32');
  late final __mm512_mask_cvtepi64_storeu_epi32 =
      __mm512_mask_cvtepi64_storeu_epi32Ptr
          .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m512i)>();

  __m256i _mm512_cvtsepi64_epi32(
    __m512i arg0,
  ) {
    return __mm512_cvtsepi64_epi32(
      arg0,
    );
  }

  late final __mm512_cvtsepi64_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m512i)>>(
          '_mm512_cvtsepi64_epi32');
  late final __mm512_cvtsepi64_epi32 =
      __mm512_cvtsepi64_epi32Ptr.asFunction<__m256i Function(__m512i)>();

  __m256i _mm512_mask_cvtsepi64_epi32(
    __m256i arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cvtsepi64_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtsepi64_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __mmask8, __m512i)>>(
          '_mm512_mask_cvtsepi64_epi32');
  late final __mm512_mask_cvtsepi64_epi32 = __mm512_mask_cvtsepi64_epi32Ptr
      .asFunction<__m256i Function(__m256i, int, __m512i)>();

  __m256i _mm512_maskz_cvtsepi64_epi32(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_maskz_cvtsepi64_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvtsepi64_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m512i)>>(
          '_mm512_maskz_cvtsepi64_epi32');
  late final __mm512_maskz_cvtsepi64_epi32 = __mm512_maskz_cvtsepi64_epi32Ptr
      .asFunction<__m256i Function(int, __m512i)>();

  void _mm512_mask_cvtsepi64_storeu_epi32(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cvtsepi64_storeu_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtsepi64_storeu_epi32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8,
              __m512i)>>('_mm512_mask_cvtsepi64_storeu_epi32');
  late final __mm512_mask_cvtsepi64_storeu_epi32 =
      __mm512_mask_cvtsepi64_storeu_epi32Ptr
          .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m512i)>();

  __m256i _mm512_cvtusepi64_epi32(
    __m512i arg0,
  ) {
    return __mm512_cvtusepi64_epi32(
      arg0,
    );
  }

  late final __mm512_cvtusepi64_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m512i)>>(
          '_mm512_cvtusepi64_epi32');
  late final __mm512_cvtusepi64_epi32 =
      __mm512_cvtusepi64_epi32Ptr.asFunction<__m256i Function(__m512i)>();

  __m256i _mm512_mask_cvtusepi64_epi32(
    __m256i arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cvtusepi64_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtusepi64_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __mmask8, __m512i)>>(
          '_mm512_mask_cvtusepi64_epi32');
  late final __mm512_mask_cvtusepi64_epi32 = __mm512_mask_cvtusepi64_epi32Ptr
      .asFunction<__m256i Function(__m256i, int, __m512i)>();

  __m256i _mm512_maskz_cvtusepi64_epi32(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_maskz_cvtusepi64_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvtusepi64_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m512i)>>(
          '_mm512_maskz_cvtusepi64_epi32');
  late final __mm512_maskz_cvtusepi64_epi32 = __mm512_maskz_cvtusepi64_epi32Ptr
      .asFunction<__m256i Function(int, __m512i)>();

  void _mm512_mask_cvtusepi64_storeu_epi32(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cvtusepi64_storeu_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtusepi64_storeu_epi32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8,
              __m512i)>>('_mm512_mask_cvtusepi64_storeu_epi32');
  late final __mm512_mask_cvtusepi64_storeu_epi32 =
      __mm512_mask_cvtusepi64_storeu_epi32Ptr
          .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m512i)>();

  __m512i _mm512_cvtepu8_epi32(
    __m128i arg0,
  ) {
    return __mm512_cvtepu8_epi32(
      arg0,
    );
  }

  late final __mm512_cvtepu8_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m128i)>>(
          '_mm512_cvtepu8_epi32');
  late final __mm512_cvtepu8_epi32 =
      __mm512_cvtepu8_epi32Ptr.asFunction<__m512i Function(__m128i)>();

  __m512i _mm512_mask_cvtepu8_epi32(
    __m512i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm512_mask_cvtepu8_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtepu8_epi32Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__m512i, __mmask16, __m128i)>>(
      '_mm512_mask_cvtepu8_epi32');
  late final __mm512_mask_cvtepu8_epi32 = __mm512_mask_cvtepu8_epi32Ptr
      .asFunction<__m512i Function(__m512i, int, __m128i)>();

  __m512i _mm512_maskz_cvtepu8_epi32(
    int arg0,
    __m128i arg1,
  ) {
    return __mm512_maskz_cvtepu8_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvtepu8_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask16, __m128i)>>(
          '_mm512_maskz_cvtepu8_epi32');
  late final __mm512_maskz_cvtepu8_epi32 = __mm512_maskz_cvtepu8_epi32Ptr
      .asFunction<__m512i Function(int, __m128i)>();

  __m512i _mm512_cvtepu8_epi64(
    __m128i arg0,
  ) {
    return __mm512_cvtepu8_epi64(
      arg0,
    );
  }

  late final __mm512_cvtepu8_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m128i)>>(
          '_mm512_cvtepu8_epi64');
  late final __mm512_cvtepu8_epi64 =
      __mm512_cvtepu8_epi64Ptr.asFunction<__m512i Function(__m128i)>();

  __m512i _mm512_mask_cvtepu8_epi64(
    __m512i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm512_mask_cvtepu8_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtepu8_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __mmask8, __m128i)>>(
          '_mm512_mask_cvtepu8_epi64');
  late final __mm512_mask_cvtepu8_epi64 = __mm512_mask_cvtepu8_epi64Ptr
      .asFunction<__m512i Function(__m512i, int, __m128i)>();

  __m512i _mm512_maskz_cvtepu8_epi64(
    int arg0,
    __m128i arg1,
  ) {
    return __mm512_maskz_cvtepu8_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvtepu8_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask8, __m128i)>>(
          '_mm512_maskz_cvtepu8_epi64');
  late final __mm512_maskz_cvtepu8_epi64 = __mm512_maskz_cvtepu8_epi64Ptr
      .asFunction<__m512i Function(int, __m128i)>();

  __m512i _mm512_cvtepu16_epi32(
    __m256i arg0,
  ) {
    return __mm512_cvtepu16_epi32(
      arg0,
    );
  }

  late final __mm512_cvtepu16_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m256i)>>(
          '_mm512_cvtepu16_epi32');
  late final __mm512_cvtepu16_epi32 =
      __mm512_cvtepu16_epi32Ptr.asFunction<__m512i Function(__m256i)>();

  __m512i _mm512_mask_cvtepu16_epi32(
    __m512i arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm512_mask_cvtepu16_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtepu16_epi32Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__m512i, __mmask16, __m256i)>>(
      '_mm512_mask_cvtepu16_epi32');
  late final __mm512_mask_cvtepu16_epi32 = __mm512_mask_cvtepu16_epi32Ptr
      .asFunction<__m512i Function(__m512i, int, __m256i)>();

  __m512i _mm512_maskz_cvtepu16_epi32(
    int arg0,
    __m256i arg1,
  ) {
    return __mm512_maskz_cvtepu16_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvtepu16_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask16, __m256i)>>(
          '_mm512_maskz_cvtepu16_epi32');
  late final __mm512_maskz_cvtepu16_epi32 = __mm512_maskz_cvtepu16_epi32Ptr
      .asFunction<__m512i Function(int, __m256i)>();

  __m512i _mm512_cvtepu16_epi64(
    __m128i arg0,
  ) {
    return __mm512_cvtepu16_epi64(
      arg0,
    );
  }

  late final __mm512_cvtepu16_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m128i)>>(
          '_mm512_cvtepu16_epi64');
  late final __mm512_cvtepu16_epi64 =
      __mm512_cvtepu16_epi64Ptr.asFunction<__m512i Function(__m128i)>();

  __m512i _mm512_mask_cvtepu16_epi64(
    __m512i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm512_mask_cvtepu16_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtepu16_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __mmask8, __m128i)>>(
          '_mm512_mask_cvtepu16_epi64');
  late final __mm512_mask_cvtepu16_epi64 = __mm512_mask_cvtepu16_epi64Ptr
      .asFunction<__m512i Function(__m512i, int, __m128i)>();

  __m512i _mm512_maskz_cvtepu16_epi64(
    int arg0,
    __m128i arg1,
  ) {
    return __mm512_maskz_cvtepu16_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvtepu16_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask8, __m128i)>>(
          '_mm512_maskz_cvtepu16_epi64');
  late final __mm512_maskz_cvtepu16_epi64 = __mm512_maskz_cvtepu16_epi64Ptr
      .asFunction<__m512i Function(int, __m128i)>();

  __m512i _mm512_cvtepu32_epi64(
    __m256i arg0,
  ) {
    return __mm512_cvtepu32_epi64(
      arg0,
    );
  }

  late final __mm512_cvtepu32_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m256i)>>(
          '_mm512_cvtepu32_epi64');
  late final __mm512_cvtepu32_epi64 =
      __mm512_cvtepu32_epi64Ptr.asFunction<__m512i Function(__m256i)>();

  __m512i _mm512_mask_cvtepu32_epi64(
    __m512i arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm512_mask_cvtepu32_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtepu32_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __mmask8, __m256i)>>(
          '_mm512_mask_cvtepu32_epi64');
  late final __mm512_mask_cvtepu32_epi64 = __mm512_mask_cvtepu32_epi64Ptr
      .asFunction<__m512i Function(__m512i, int, __m256i)>();

  __m512i _mm512_maskz_cvtepu32_epi64(
    int arg0,
    __m256i arg1,
  ) {
    return __mm512_maskz_cvtepu32_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvtepu32_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask8, __m256i)>>(
          '_mm512_maskz_cvtepu32_epi64');
  late final __mm512_maskz_cvtepu32_epi64 = __mm512_maskz_cvtepu32_epi64Ptr
      .asFunction<__m512i Function(int, __m256i)>();

  __m512i _mm512_cvtps_epi32(
    __m512 arg0,
  ) {
    return __mm512_cvtps_epi32(
      arg0,
    );
  }

  late final __mm512_cvtps_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512)>>(
          '_mm512_cvtps_epi32');
  late final __mm512_cvtps_epi32 =
      __mm512_cvtps_epi32Ptr.asFunction<__m512i Function(__m512)>();

  __m512i _mm512_mask_cvtps_epi32(
    __m512i arg0,
    int arg1,
    __m512 arg2,
  ) {
    return __mm512_mask_cvtps_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtps_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __mmask16, __m512)>>(
          '_mm512_mask_cvtps_epi32');
  late final __mm512_mask_cvtps_epi32 = __mm512_mask_cvtps_epi32Ptr
      .asFunction<__m512i Function(__m512i, int, __m512)>();

  __m512i _mm512_maskz_cvtps_epi32(
    int arg0,
    __m512 arg1,
  ) {
    return __mm512_maskz_cvtps_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvtps_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask16, __m512)>>(
          '_mm512_maskz_cvtps_epi32');
  late final __mm512_maskz_cvtps_epi32 =
      __mm512_maskz_cvtps_epi32Ptr.asFunction<__m512i Function(int, __m512)>();

  __m512i _mm512_cvt_roundps_epi32(
    __m512 arg0,
    int arg1,
  ) {
    return __mm512_cvt_roundps_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_cvt_roundps_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512, ffi.Int32)>>(
          '_mm512_cvt_roundps_epi32');
  late final __mm512_cvt_roundps_epi32 =
      __mm512_cvt_roundps_epi32Ptr.asFunction<__m512i Function(__m512, int)>();

  __m512i _mm512_mask_cvt_roundps_epi32(
    __m512i arg0,
    int arg1,
    __m512 arg2,
    int arg3,
  ) {
    return __mm512_mask_cvt_roundps_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_cvt_roundps_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask16, __m512,
              ffi.Int32)>>('_mm512_mask_cvt_roundps_epi32');
  late final __mm512_mask_cvt_roundps_epi32 = __mm512_mask_cvt_roundps_epi32Ptr
      .asFunction<__m512i Function(__m512i, int, __m512, int)>();

  __m512i _mm512_maskz_cvt_roundps_epi32(
    int arg0,
    __m512 arg1,
    int arg2,
  ) {
    return __mm512_maskz_cvt_roundps_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_cvt_roundps_epi32Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask16, __m512, ffi.Int32)>>(
      '_mm512_maskz_cvt_roundps_epi32');
  late final __mm512_maskz_cvt_roundps_epi32 =
      __mm512_maskz_cvt_roundps_epi32Ptr
          .asFunction<__m512i Function(int, __m512, int)>();

  __m512i _mm512_cvttps_epi32(
    __m512 arg0,
  ) {
    return __mm512_cvttps_epi32(
      arg0,
    );
  }

  late final __mm512_cvttps_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512)>>(
          '_mm512_cvttps_epi32');
  late final __mm512_cvttps_epi32 =
      __mm512_cvttps_epi32Ptr.asFunction<__m512i Function(__m512)>();

  __m512i _mm512_mask_cvttps_epi32(
    __m512i arg0,
    int arg1,
    __m512 arg2,
  ) {
    return __mm512_mask_cvttps_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvttps_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __mmask16, __m512)>>(
          '_mm512_mask_cvttps_epi32');
  late final __mm512_mask_cvttps_epi32 = __mm512_mask_cvttps_epi32Ptr
      .asFunction<__m512i Function(__m512i, int, __m512)>();

  __m512i _mm512_maskz_cvttps_epi32(
    int arg0,
    __m512 arg1,
  ) {
    return __mm512_maskz_cvttps_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvttps_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask16, __m512)>>(
          '_mm512_maskz_cvttps_epi32');
  late final __mm512_maskz_cvttps_epi32 =
      __mm512_maskz_cvttps_epi32Ptr.asFunction<__m512i Function(int, __m512)>();

  __m512i _mm512_cvtt_roundps_epi32(
    __m512 arg0,
    int arg1,
  ) {
    return __mm512_cvtt_roundps_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_cvtt_roundps_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512, ffi.Int32)>>(
          '_mm512_cvtt_roundps_epi32');
  late final __mm512_cvtt_roundps_epi32 =
      __mm512_cvtt_roundps_epi32Ptr.asFunction<__m512i Function(__m512, int)>();

  __m512i _mm512_mask_cvtt_roundps_epi32(
    __m512i arg0,
    int arg1,
    __m512 arg2,
    int arg3,
  ) {
    return __mm512_mask_cvtt_roundps_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_cvtt_roundps_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask16, __m512,
              ffi.Int32)>>('_mm512_mask_cvtt_roundps_epi32');
  late final __mm512_mask_cvtt_roundps_epi32 =
      __mm512_mask_cvtt_roundps_epi32Ptr
          .asFunction<__m512i Function(__m512i, int, __m512, int)>();

  __m512i _mm512_maskz_cvtt_roundps_epi32(
    int arg0,
    __m512 arg1,
    int arg2,
  ) {
    return __mm512_maskz_cvtt_roundps_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_cvtt_roundps_epi32Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask16, __m512, ffi.Int32)>>(
      '_mm512_maskz_cvtt_roundps_epi32');
  late final __mm512_maskz_cvtt_roundps_epi32 =
      __mm512_maskz_cvtt_roundps_epi32Ptr
          .asFunction<__m512i Function(int, __m512, int)>();

  __m512i _mm512_cvtps_epu32(
    __m512 arg0,
  ) {
    return __mm512_cvtps_epu32(
      arg0,
    );
  }

  late final __mm512_cvtps_epu32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512)>>(
          '_mm512_cvtps_epu32');
  late final __mm512_cvtps_epu32 =
      __mm512_cvtps_epu32Ptr.asFunction<__m512i Function(__m512)>();

  __m512i _mm512_mask_cvtps_epu32(
    __m512i arg0,
    int arg1,
    __m512 arg2,
  ) {
    return __mm512_mask_cvtps_epu32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtps_epu32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __mmask16, __m512)>>(
          '_mm512_mask_cvtps_epu32');
  late final __mm512_mask_cvtps_epu32 = __mm512_mask_cvtps_epu32Ptr
      .asFunction<__m512i Function(__m512i, int, __m512)>();

  __m512i _mm512_maskz_cvtps_epu32(
    int arg0,
    __m512 arg1,
  ) {
    return __mm512_maskz_cvtps_epu32(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvtps_epu32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask16, __m512)>>(
          '_mm512_maskz_cvtps_epu32');
  late final __mm512_maskz_cvtps_epu32 =
      __mm512_maskz_cvtps_epu32Ptr.asFunction<__m512i Function(int, __m512)>();

  __m512i _mm512_cvt_roundps_epu32(
    __m512 arg0,
    int arg1,
  ) {
    return __mm512_cvt_roundps_epu32(
      arg0,
      arg1,
    );
  }

  late final __mm512_cvt_roundps_epu32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512, ffi.Int32)>>(
          '_mm512_cvt_roundps_epu32');
  late final __mm512_cvt_roundps_epu32 =
      __mm512_cvt_roundps_epu32Ptr.asFunction<__m512i Function(__m512, int)>();

  __m512i _mm512_mask_cvt_roundps_epu32(
    __m512i arg0,
    int arg1,
    __m512 arg2,
    int arg3,
  ) {
    return __mm512_mask_cvt_roundps_epu32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_cvt_roundps_epu32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask16, __m512,
              ffi.Int32)>>('_mm512_mask_cvt_roundps_epu32');
  late final __mm512_mask_cvt_roundps_epu32 = __mm512_mask_cvt_roundps_epu32Ptr
      .asFunction<__m512i Function(__m512i, int, __m512, int)>();

  __m512i _mm512_maskz_cvt_roundps_epu32(
    int arg0,
    __m512 arg1,
    int arg2,
  ) {
    return __mm512_maskz_cvt_roundps_epu32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_cvt_roundps_epu32Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask16, __m512, ffi.Int32)>>(
      '_mm512_maskz_cvt_roundps_epu32');
  late final __mm512_maskz_cvt_roundps_epu32 =
      __mm512_maskz_cvt_roundps_epu32Ptr
          .asFunction<__m512i Function(int, __m512, int)>();

  __m512i _mm512_cvttps_epu32(
    __m512 arg0,
  ) {
    return __mm512_cvttps_epu32(
      arg0,
    );
  }

  late final __mm512_cvttps_epu32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512)>>(
          '_mm512_cvttps_epu32');
  late final __mm512_cvttps_epu32 =
      __mm512_cvttps_epu32Ptr.asFunction<__m512i Function(__m512)>();

  __m512i _mm512_mask_cvttps_epu32(
    __m512i arg0,
    int arg1,
    __m512 arg2,
  ) {
    return __mm512_mask_cvttps_epu32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvttps_epu32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __mmask16, __m512)>>(
          '_mm512_mask_cvttps_epu32');
  late final __mm512_mask_cvttps_epu32 = __mm512_mask_cvttps_epu32Ptr
      .asFunction<__m512i Function(__m512i, int, __m512)>();

  __m512i _mm512_maskz_cvttps_epu32(
    int arg0,
    __m512 arg1,
  ) {
    return __mm512_maskz_cvttps_epu32(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvttps_epu32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask16, __m512)>>(
          '_mm512_maskz_cvttps_epu32');
  late final __mm512_maskz_cvttps_epu32 =
      __mm512_maskz_cvttps_epu32Ptr.asFunction<__m512i Function(int, __m512)>();

  __m512i _mm512_cvtt_roundps_epu32(
    __m512 arg0,
    int arg1,
  ) {
    return __mm512_cvtt_roundps_epu32(
      arg0,
      arg1,
    );
  }

  late final __mm512_cvtt_roundps_epu32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512, ffi.Int32)>>(
          '_mm512_cvtt_roundps_epu32');
  late final __mm512_cvtt_roundps_epu32 =
      __mm512_cvtt_roundps_epu32Ptr.asFunction<__m512i Function(__m512, int)>();

  __m512i _mm512_mask_cvtt_roundps_epu32(
    __m512i arg0,
    int arg1,
    __m512 arg2,
    int arg3,
  ) {
    return __mm512_mask_cvtt_roundps_epu32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_cvtt_roundps_epu32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask16, __m512,
              ffi.Int32)>>('_mm512_mask_cvtt_roundps_epu32');
  late final __mm512_mask_cvtt_roundps_epu32 =
      __mm512_mask_cvtt_roundps_epu32Ptr
          .asFunction<__m512i Function(__m512i, int, __m512, int)>();

  __m512i _mm512_maskz_cvtt_roundps_epu32(
    int arg0,
    __m512 arg1,
    int arg2,
  ) {
    return __mm512_maskz_cvtt_roundps_epu32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_cvtt_roundps_epu32Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask16, __m512, ffi.Int32)>>(
      '_mm512_maskz_cvtt_roundps_epu32');
  late final __mm512_maskz_cvtt_roundps_epu32 =
      __mm512_maskz_cvtt_roundps_epu32Ptr
          .asFunction<__m512i Function(int, __m512, int)>();

  __m256i _mm512_cvtpd_epi32(
    _m512d arg0,
  ) {
    return __mm512_cvtpd_epi32(
      arg0,
    );
  }

  late final __mm512_cvtpd_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(_m512d)>>(
          '_mm512_cvtpd_epi32');
  late final __mm512_cvtpd_epi32 =
      __mm512_cvtpd_epi32Ptr.asFunction<__m256i Function(_m512d)>();

  __m256i _mm512_mask_cvtpd_epi32(
    __m256i arg0,
    int arg1,
    _m512d arg2,
  ) {
    return __mm512_mask_cvtpd_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtpd_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __mmask8, _m512d)>>(
          '_mm512_mask_cvtpd_epi32');
  late final __mm512_mask_cvtpd_epi32 = __mm512_mask_cvtpd_epi32Ptr
      .asFunction<__m256i Function(__m256i, int, _m512d)>();

  __m256i _mm512_maskz_cvtpd_epi32(
    int arg0,
    _m512d arg1,
  ) {
    return __mm512_maskz_cvtpd_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvtpd_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, _m512d)>>(
          '_mm512_maskz_cvtpd_epi32');
  late final __mm512_maskz_cvtpd_epi32 =
      __mm512_maskz_cvtpd_epi32Ptr.asFunction<__m256i Function(int, _m512d)>();

  __m256i _mm512_cvt_roundpd_epi32(
    _m512d arg0,
    int arg1,
  ) {
    return __mm512_cvt_roundpd_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_cvt_roundpd_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(_m512d, ffi.Int32)>>(
          '_mm512_cvt_roundpd_epi32');
  late final __mm512_cvt_roundpd_epi32 =
      __mm512_cvt_roundpd_epi32Ptr.asFunction<__m256i Function(_m512d, int)>();

  __m256i _mm512_mask_cvt_roundpd_epi32(
    __m256i arg0,
    int arg1,
    _m512d arg2,
    int arg3,
  ) {
    return __mm512_mask_cvt_roundpd_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_cvt_roundpd_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask8, _m512d,
              ffi.Int32)>>('_mm512_mask_cvt_roundpd_epi32');
  late final __mm512_mask_cvt_roundpd_epi32 = __mm512_mask_cvt_roundpd_epi32Ptr
      .asFunction<__m256i Function(__m256i, int, _m512d, int)>();

  __m256i _mm512_maskz_cvt_roundpd_epi32(
    int arg0,
    _m512d arg1,
    int arg2,
  ) {
    return __mm512_maskz_cvt_roundpd_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_cvt_roundpd_epi32Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__mmask8, _m512d, ffi.Int32)>>(
      '_mm512_maskz_cvt_roundpd_epi32');
  late final __mm512_maskz_cvt_roundpd_epi32 =
      __mm512_maskz_cvt_roundpd_epi32Ptr
          .asFunction<__m256i Function(int, _m512d, int)>();

  __m256i _mm512_cvttpd_epi32(
    _m512d arg0,
  ) {
    return __mm512_cvttpd_epi32(
      arg0,
    );
  }

  late final __mm512_cvttpd_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(_m512d)>>(
          '_mm512_cvttpd_epi32');
  late final __mm512_cvttpd_epi32 =
      __mm512_cvttpd_epi32Ptr.asFunction<__m256i Function(_m512d)>();

  __m256i _mm512_mask_cvttpd_epi32(
    __m256i arg0,
    int arg1,
    _m512d arg2,
  ) {
    return __mm512_mask_cvttpd_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvttpd_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __mmask8, _m512d)>>(
          '_mm512_mask_cvttpd_epi32');
  late final __mm512_mask_cvttpd_epi32 = __mm512_mask_cvttpd_epi32Ptr
      .asFunction<__m256i Function(__m256i, int, _m512d)>();

  __m256i _mm512_maskz_cvttpd_epi32(
    int arg0,
    _m512d arg1,
  ) {
    return __mm512_maskz_cvttpd_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvttpd_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, _m512d)>>(
          '_mm512_maskz_cvttpd_epi32');
  late final __mm512_maskz_cvttpd_epi32 =
      __mm512_maskz_cvttpd_epi32Ptr.asFunction<__m256i Function(int, _m512d)>();

  __m256i _mm512_cvtt_roundpd_epi32(
    _m512d arg0,
    int arg1,
  ) {
    return __mm512_cvtt_roundpd_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_cvtt_roundpd_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(_m512d, ffi.Int32)>>(
          '_mm512_cvtt_roundpd_epi32');
  late final __mm512_cvtt_roundpd_epi32 =
      __mm512_cvtt_roundpd_epi32Ptr.asFunction<__m256i Function(_m512d, int)>();

  __m256i _mm512_mask_cvtt_roundpd_epi32(
    __m256i arg0,
    int arg1,
    _m512d arg2,
    int arg3,
  ) {
    return __mm512_mask_cvtt_roundpd_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_cvtt_roundpd_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask8, _m512d,
              ffi.Int32)>>('_mm512_mask_cvtt_roundpd_epi32');
  late final __mm512_mask_cvtt_roundpd_epi32 =
      __mm512_mask_cvtt_roundpd_epi32Ptr
          .asFunction<__m256i Function(__m256i, int, _m512d, int)>();

  __m256i _mm512_maskz_cvtt_roundpd_epi32(
    int arg0,
    _m512d arg1,
    int arg2,
  ) {
    return __mm512_maskz_cvtt_roundpd_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_cvtt_roundpd_epi32Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__mmask8, _m512d, ffi.Int32)>>(
      '_mm512_maskz_cvtt_roundpd_epi32');
  late final __mm512_maskz_cvtt_roundpd_epi32 =
      __mm512_maskz_cvtt_roundpd_epi32Ptr
          .asFunction<__m256i Function(int, _m512d, int)>();

  __m256i _mm512_cvtpd_epu32(
    _m512d arg0,
  ) {
    return __mm512_cvtpd_epu32(
      arg0,
    );
  }

  late final __mm512_cvtpd_epu32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(_m512d)>>(
          '_mm512_cvtpd_epu32');
  late final __mm512_cvtpd_epu32 =
      __mm512_cvtpd_epu32Ptr.asFunction<__m256i Function(_m512d)>();

  __m256i _mm512_mask_cvtpd_epu32(
    __m256i arg0,
    int arg1,
    _m512d arg2,
  ) {
    return __mm512_mask_cvtpd_epu32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtpd_epu32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __mmask8, _m512d)>>(
          '_mm512_mask_cvtpd_epu32');
  late final __mm512_mask_cvtpd_epu32 = __mm512_mask_cvtpd_epu32Ptr
      .asFunction<__m256i Function(__m256i, int, _m512d)>();

  __m256i _mm512_maskz_cvtpd_epu32(
    int arg0,
    _m512d arg1,
  ) {
    return __mm512_maskz_cvtpd_epu32(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvtpd_epu32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, _m512d)>>(
          '_mm512_maskz_cvtpd_epu32');
  late final __mm512_maskz_cvtpd_epu32 =
      __mm512_maskz_cvtpd_epu32Ptr.asFunction<__m256i Function(int, _m512d)>();

  __m256i _mm512_cvt_roundpd_epu32(
    _m512d arg0,
    int arg1,
  ) {
    return __mm512_cvt_roundpd_epu32(
      arg0,
      arg1,
    );
  }

  late final __mm512_cvt_roundpd_epu32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(_m512d, ffi.Int32)>>(
          '_mm512_cvt_roundpd_epu32');
  late final __mm512_cvt_roundpd_epu32 =
      __mm512_cvt_roundpd_epu32Ptr.asFunction<__m256i Function(_m512d, int)>();

  __m256i _mm512_mask_cvt_roundpd_epu32(
    __m256i arg0,
    int arg1,
    _m512d arg2,
    int arg3,
  ) {
    return __mm512_mask_cvt_roundpd_epu32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_cvt_roundpd_epu32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask8, _m512d,
              ffi.Int32)>>('_mm512_mask_cvt_roundpd_epu32');
  late final __mm512_mask_cvt_roundpd_epu32 = __mm512_mask_cvt_roundpd_epu32Ptr
      .asFunction<__m256i Function(__m256i, int, _m512d, int)>();

  __m256i _mm512_maskz_cvt_roundpd_epu32(
    int arg0,
    _m512d arg1,
    int arg2,
  ) {
    return __mm512_maskz_cvt_roundpd_epu32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_cvt_roundpd_epu32Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__mmask8, _m512d, ffi.Int32)>>(
      '_mm512_maskz_cvt_roundpd_epu32');
  late final __mm512_maskz_cvt_roundpd_epu32 =
      __mm512_maskz_cvt_roundpd_epu32Ptr
          .asFunction<__m256i Function(int, _m512d, int)>();

  __m256i _mm512_cvttpd_epu32(
    _m512d arg0,
  ) {
    return __mm512_cvttpd_epu32(
      arg0,
    );
  }

  late final __mm512_cvttpd_epu32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(_m512d)>>(
          '_mm512_cvttpd_epu32');
  late final __mm512_cvttpd_epu32 =
      __mm512_cvttpd_epu32Ptr.asFunction<__m256i Function(_m512d)>();

  __m256i _mm512_mask_cvttpd_epu32(
    __m256i arg0,
    int arg1,
    _m512d arg2,
  ) {
    return __mm512_mask_cvttpd_epu32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvttpd_epu32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __mmask8, _m512d)>>(
          '_mm512_mask_cvttpd_epu32');
  late final __mm512_mask_cvttpd_epu32 = __mm512_mask_cvttpd_epu32Ptr
      .asFunction<__m256i Function(__m256i, int, _m512d)>();

  __m256i _mm512_maskz_cvttpd_epu32(
    int arg0,
    _m512d arg1,
  ) {
    return __mm512_maskz_cvttpd_epu32(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvttpd_epu32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, _m512d)>>(
          '_mm512_maskz_cvttpd_epu32');
  late final __mm512_maskz_cvttpd_epu32 =
      __mm512_maskz_cvttpd_epu32Ptr.asFunction<__m256i Function(int, _m512d)>();

  __m256i _mm512_cvtt_roundpd_epu32(
    _m512d arg0,
    int arg1,
  ) {
    return __mm512_cvtt_roundpd_epu32(
      arg0,
      arg1,
    );
  }

  late final __mm512_cvtt_roundpd_epu32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(_m512d, ffi.Int32)>>(
          '_mm512_cvtt_roundpd_epu32');
  late final __mm512_cvtt_roundpd_epu32 =
      __mm512_cvtt_roundpd_epu32Ptr.asFunction<__m256i Function(_m512d, int)>();

  __m256i _mm512_mask_cvtt_roundpd_epu32(
    __m256i arg0,
    int arg1,
    _m512d arg2,
    int arg3,
  ) {
    return __mm512_mask_cvtt_roundpd_epu32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_cvtt_roundpd_epu32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask8, _m512d,
              ffi.Int32)>>('_mm512_mask_cvtt_roundpd_epu32');
  late final __mm512_mask_cvtt_roundpd_epu32 =
      __mm512_mask_cvtt_roundpd_epu32Ptr
          .asFunction<__m256i Function(__m256i, int, _m512d, int)>();

  __m256i _mm512_maskz_cvtt_roundpd_epu32(
    int arg0,
    _m512d arg1,
    int arg2,
  ) {
    return __mm512_maskz_cvtt_roundpd_epu32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_cvtt_roundpd_epu32Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__mmask8, _m512d, ffi.Int32)>>(
      '_mm512_maskz_cvtt_roundpd_epu32');
  late final __mm512_maskz_cvtt_roundpd_epu32 =
      __mm512_maskz_cvtt_roundpd_epu32Ptr
          .asFunction<__m256i Function(int, _m512d, int)>();

  __m512i _mm512_cvtepi8_epi16(
    __m256i arg0,
  ) {
    return __mm512_cvtepi8_epi16(
      arg0,
    );
  }

  late final __mm512_cvtepi8_epi16Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m256i)>>(
          '_mm512_cvtepi8_epi16');
  late final __mm512_cvtepi8_epi16 =
      __mm512_cvtepi8_epi16Ptr.asFunction<__m512i Function(__m256i)>();

  __m512i _mm512_mask_cvtepi8_epi16(
    __m512i arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm512_mask_cvtepi8_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtepi8_epi16Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__m512i, __mmask32, __m256i)>>(
      '_mm512_mask_cvtepi8_epi16');
  late final __mm512_mask_cvtepi8_epi16 = __mm512_mask_cvtepi8_epi16Ptr
      .asFunction<__m512i Function(__m512i, int, __m256i)>();

  __m512i _mm512_maskz_cvtepi8_epi16(
    int arg0,
    __m256i arg1,
  ) {
    return __mm512_maskz_cvtepi8_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvtepi8_epi16Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask32, __m256i)>>(
          '_mm512_maskz_cvtepi8_epi16');
  late final __mm512_maskz_cvtepi8_epi16 = __mm512_maskz_cvtepi8_epi16Ptr
      .asFunction<__m512i Function(int, __m256i)>();

  __m512i _mm512_cvtepu8_epi16(
    __m256i arg0,
  ) {
    return __mm512_cvtepu8_epi16(
      arg0,
    );
  }

  late final __mm512_cvtepu8_epi16Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m256i)>>(
          '_mm512_cvtepu8_epi16');
  late final __mm512_cvtepu8_epi16 =
      __mm512_cvtepu8_epi16Ptr.asFunction<__m512i Function(__m256i)>();

  __m512i _mm512_mask_cvtepu8_epi16(
    __m512i arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm512_mask_cvtepu8_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtepu8_epi16Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__m512i, __mmask32, __m256i)>>(
      '_mm512_mask_cvtepu8_epi16');
  late final __mm512_mask_cvtepu8_epi16 = __mm512_mask_cvtepu8_epi16Ptr
      .asFunction<__m512i Function(__m512i, int, __m256i)>();

  __m512i _mm512_maskz_cvtepu8_epi16(
    int arg0,
    __m256i arg1,
  ) {
    return __mm512_maskz_cvtepu8_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvtepu8_epi16Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask32, __m256i)>>(
          '_mm512_maskz_cvtepu8_epi16');
  late final __mm512_maskz_cvtepu8_epi16 = __mm512_maskz_cvtepu8_epi16Ptr
      .asFunction<__m512i Function(int, __m256i)>();

  __m256i _mm512_cvtepi16_epi8(
    __m512i arg0,
  ) {
    return __mm512_cvtepi16_epi8(
      arg0,
    );
  }

  late final __mm512_cvtepi16_epi8Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m512i)>>(
          '_mm512_cvtepi16_epi8');
  late final __mm512_cvtepi16_epi8 =
      __mm512_cvtepi16_epi8Ptr.asFunction<__m256i Function(__m512i)>();

  __m256i _mm512_mask_cvtepi16_epi8(
    __m256i arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cvtepi16_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtepi16_epi8Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__m256i, __mmask32, __m512i)>>(
      '_mm512_mask_cvtepi16_epi8');
  late final __mm512_mask_cvtepi16_epi8 = __mm512_mask_cvtepi16_epi8Ptr
      .asFunction<__m256i Function(__m256i, int, __m512i)>();

  __m256i _mm512_maskz_cvtepi16_epi8(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_maskz_cvtepi16_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvtepi16_epi8Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask32, __m512i)>>(
          '_mm512_maskz_cvtepi16_epi8');
  late final __mm512_maskz_cvtepi16_epi8 = __mm512_maskz_cvtepi16_epi8Ptr
      .asFunction<__m256i Function(int, __m512i)>();

  void _mm512_mask_cvtepi16_storeu_epi8(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cvtepi16_storeu_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtepi16_storeu_epi8Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask32,
              __m512i)>>('_mm512_mask_cvtepi16_storeu_epi8');
  late final __mm512_mask_cvtepi16_storeu_epi8 =
      __mm512_mask_cvtepi16_storeu_epi8Ptr
          .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m512i)>();

  __m256i _mm512_cvtsepi16_epi8(
    __m512i arg0,
  ) {
    return __mm512_cvtsepi16_epi8(
      arg0,
    );
  }

  late final __mm512_cvtsepi16_epi8Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m512i)>>(
          '_mm512_cvtsepi16_epi8');
  late final __mm512_cvtsepi16_epi8 =
      __mm512_cvtsepi16_epi8Ptr.asFunction<__m256i Function(__m512i)>();

  __m256i _mm512_mask_cvtsepi16_epi8(
    __m256i arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cvtsepi16_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtsepi16_epi8Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__m256i, __mmask32, __m512i)>>(
      '_mm512_mask_cvtsepi16_epi8');
  late final __mm512_mask_cvtsepi16_epi8 = __mm512_mask_cvtsepi16_epi8Ptr
      .asFunction<__m256i Function(__m256i, int, __m512i)>();

  __m256i _mm512_maskz_cvtsepi16_epi8(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_maskz_cvtsepi16_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvtsepi16_epi8Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask32, __m512i)>>(
          '_mm512_maskz_cvtsepi16_epi8');
  late final __mm512_maskz_cvtsepi16_epi8 = __mm512_maskz_cvtsepi16_epi8Ptr
      .asFunction<__m256i Function(int, __m512i)>();

  void _mm512_mask_cvtsepi16_storeu_epi8(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cvtsepi16_storeu_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtsepi16_storeu_epi8Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask32,
              __m512i)>>('_mm512_mask_cvtsepi16_storeu_epi8');
  late final __mm512_mask_cvtsepi16_storeu_epi8 =
      __mm512_mask_cvtsepi16_storeu_epi8Ptr
          .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m512i)>();

  __m256i _mm512_cvtusepi16_epi8(
    __m512i arg0,
  ) {
    return __mm512_cvtusepi16_epi8(
      arg0,
    );
  }

  late final __mm512_cvtusepi16_epi8Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m512i)>>(
          '_mm512_cvtusepi16_epi8');
  late final __mm512_cvtusepi16_epi8 =
      __mm512_cvtusepi16_epi8Ptr.asFunction<__m256i Function(__m512i)>();

  __m256i _mm512_mask_cvtusepi16_epi8(
    __m256i arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cvtusepi16_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtusepi16_epi8Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__m256i, __mmask32, __m512i)>>(
      '_mm512_mask_cvtusepi16_epi8');
  late final __mm512_mask_cvtusepi16_epi8 = __mm512_mask_cvtusepi16_epi8Ptr
      .asFunction<__m256i Function(__m256i, int, __m512i)>();

  __m256i _mm512_maskz_cvtusepi16_epi8(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_maskz_cvtusepi16_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvtusepi16_epi8Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask32, __m512i)>>(
          '_mm512_maskz_cvtusepi16_epi8');
  late final __mm512_maskz_cvtusepi16_epi8 = __mm512_maskz_cvtusepi16_epi8Ptr
      .asFunction<__m256i Function(int, __m512i)>();

  void _mm512_mask_cvtusepi16_storeu_epi8(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cvtusepi16_storeu_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtusepi16_storeu_epi8Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask32,
              __m512i)>>('_mm512_mask_cvtusepi16_storeu_epi8');
  late final __mm512_mask_cvtusepi16_storeu_epi8 =
      __mm512_mask_cvtusepi16_storeu_epi8Ptr
          .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m512i)>();

  _m512d _mm512_cvtepi64_pd(
    __m512i arg0,
  ) {
    return __mm512_cvtepi64_pd(
      arg0,
    );
  }

  late final __mm512_cvtepi64_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(__m512i)>>(
          '_mm512_cvtepi64_pd');
  late final __mm512_cvtepi64_pd =
      __mm512_cvtepi64_pdPtr.asFunction<_m512d Function(__m512i)>();

  _m512d _mm512_mask_cvtepi64_pd(
    _m512d arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cvtepi64_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtepi64_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, __mmask8, __m512i)>>(
          '_mm512_mask_cvtepi64_pd');
  late final __mm512_mask_cvtepi64_pd = __mm512_mask_cvtepi64_pdPtr
      .asFunction<_m512d Function(_m512d, int, __m512i)>();

  _m512d _mm512_maskz_cvtepi64_pd(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_maskz_cvtepi64_pd(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvtepi64_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(__mmask8, __m512i)>>(
          '_mm512_maskz_cvtepi64_pd');
  late final __mm512_maskz_cvtepi64_pd =
      __mm512_maskz_cvtepi64_pdPtr.asFunction<_m512d Function(int, __m512i)>();

  _m512d _mm512_cvt_roundepi64_pd(
    __m512i arg0,
    int arg1,
  ) {
    return __mm512_cvt_roundepi64_pd(
      arg0,
      arg1,
    );
  }

  late final __mm512_cvt_roundepi64_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(__m512i, ffi.Int32)>>(
          '_mm512_cvt_roundepi64_pd');
  late final __mm512_cvt_roundepi64_pd =
      __mm512_cvt_roundepi64_pdPtr.asFunction<_m512d Function(__m512i, int)>();

  _m512d _mm512_mask_cvt_roundepi64_pd(
    _m512d arg0,
    int arg1,
    __m512i arg2,
    int arg3,
  ) {
    return __mm512_mask_cvt_roundepi64_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_cvt_roundepi64_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(_m512d, __mmask8, __m512i,
              ffi.Int32)>>('_mm512_mask_cvt_roundepi64_pd');
  late final __mm512_mask_cvt_roundepi64_pd = __mm512_mask_cvt_roundepi64_pdPtr
      .asFunction<_m512d Function(_m512d, int, __m512i, int)>();

  _m512d _mm512_maskz_cvt_roundepi64_pd(
    int arg0,
    __m512i arg1,
    int arg2,
  ) {
    return __mm512_maskz_cvt_roundepi64_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_cvt_roundepi64_pdPtr = _lookup<
          ffi.NativeFunction<_m512d Function(__mmask8, __m512i, ffi.Int32)>>(
      '_mm512_maskz_cvt_roundepi64_pd');
  late final __mm512_maskz_cvt_roundepi64_pd =
      __mm512_maskz_cvt_roundepi64_pdPtr
          .asFunction<_m512d Function(int, __m512i, int)>();

  _m512d _mm512_cvtepu64_pd(
    __m512i arg0,
  ) {
    return __mm512_cvtepu64_pd(
      arg0,
    );
  }

  late final __mm512_cvtepu64_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(__m512i)>>(
          '_mm512_cvtepu64_pd');
  late final __mm512_cvtepu64_pd =
      __mm512_cvtepu64_pdPtr.asFunction<_m512d Function(__m512i)>();

  _m512d _mm512_mask_cvtepu64_pd(
    _m512d arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cvtepu64_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtepu64_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, __mmask8, __m512i)>>(
          '_mm512_mask_cvtepu64_pd');
  late final __mm512_mask_cvtepu64_pd = __mm512_mask_cvtepu64_pdPtr
      .asFunction<_m512d Function(_m512d, int, __m512i)>();

  _m512d _mm512_maskz_cvtepu64_pd(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_maskz_cvtepu64_pd(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvtepu64_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(__mmask8, __m512i)>>(
          '_mm512_maskz_cvtepu64_pd');
  late final __mm512_maskz_cvtepu64_pd =
      __mm512_maskz_cvtepu64_pdPtr.asFunction<_m512d Function(int, __m512i)>();

  _m512d _mm512_cvt_roundepu64_pd(
    __m512i arg0,
    int arg1,
  ) {
    return __mm512_cvt_roundepu64_pd(
      arg0,
      arg1,
    );
  }

  late final __mm512_cvt_roundepu64_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(__m512i, ffi.Int32)>>(
          '_mm512_cvt_roundepu64_pd');
  late final __mm512_cvt_roundepu64_pd =
      __mm512_cvt_roundepu64_pdPtr.asFunction<_m512d Function(__m512i, int)>();

  _m512d _mm512_mask_cvt_roundepu64_pd(
    _m512d arg0,
    int arg1,
    __m512i arg2,
    int arg3,
  ) {
    return __mm512_mask_cvt_roundepu64_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_cvt_roundepu64_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(_m512d, __mmask8, __m512i,
              ffi.Int32)>>('_mm512_mask_cvt_roundepu64_pd');
  late final __mm512_mask_cvt_roundepu64_pd = __mm512_mask_cvt_roundepu64_pdPtr
      .asFunction<_m512d Function(_m512d, int, __m512i, int)>();

  _m512d _mm512_maskz_cvt_roundepu64_pd(
    int arg0,
    __m512i arg1,
    int arg2,
  ) {
    return __mm512_maskz_cvt_roundepu64_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_cvt_roundepu64_pdPtr = _lookup<
          ffi.NativeFunction<_m512d Function(__mmask8, __m512i, ffi.Int32)>>(
      '_mm512_maskz_cvt_roundepu64_pd');
  late final __mm512_maskz_cvt_roundepu64_pd =
      __mm512_maskz_cvt_roundepu64_pdPtr
          .asFunction<_m512d Function(int, __m512i, int)>();

  __m512i _mm512_cvtpd_epi64(
    _m512d arg0,
  ) {
    return __mm512_cvtpd_epi64(
      arg0,
    );
  }

  late final __mm512_cvtpd_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(_m512d)>>(
          '_mm512_cvtpd_epi64');
  late final __mm512_cvtpd_epi64 =
      __mm512_cvtpd_epi64Ptr.asFunction<__m512i Function(_m512d)>();

  __m512i _mm512_mask_cvtpd_epi64(
    __m512i arg0,
    int arg1,
    _m512d arg2,
  ) {
    return __mm512_mask_cvtpd_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtpd_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __mmask8, _m512d)>>(
          '_mm512_mask_cvtpd_epi64');
  late final __mm512_mask_cvtpd_epi64 = __mm512_mask_cvtpd_epi64Ptr
      .asFunction<__m512i Function(__m512i, int, _m512d)>();

  __m512i _mm512_maskz_cvtpd_epi64(
    int arg0,
    _m512d arg1,
  ) {
    return __mm512_maskz_cvtpd_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvtpd_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask8, _m512d)>>(
          '_mm512_maskz_cvtpd_epi64');
  late final __mm512_maskz_cvtpd_epi64 =
      __mm512_maskz_cvtpd_epi64Ptr.asFunction<__m512i Function(int, _m512d)>();

  __m512i _mm512_cvt_roundpd_epi64(
    _m512d arg0,
    int arg1,
  ) {
    return __mm512_cvt_roundpd_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm512_cvt_roundpd_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(_m512d, ffi.Int32)>>(
          '_mm512_cvt_roundpd_epi64');
  late final __mm512_cvt_roundpd_epi64 =
      __mm512_cvt_roundpd_epi64Ptr.asFunction<__m512i Function(_m512d, int)>();

  __m512i _mm512_mask_cvt_roundpd_epi64(
    __m512i arg0,
    int arg1,
    _m512d arg2,
    int arg3,
  ) {
    return __mm512_mask_cvt_roundpd_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_cvt_roundpd_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask8, _m512d,
              ffi.Int32)>>('_mm512_mask_cvt_roundpd_epi64');
  late final __mm512_mask_cvt_roundpd_epi64 = __mm512_mask_cvt_roundpd_epi64Ptr
      .asFunction<__m512i Function(__m512i, int, _m512d, int)>();

  __m512i _mm512_maskz_cvt_roundpd_epi64(
    int arg0,
    _m512d arg1,
    int arg2,
  ) {
    return __mm512_maskz_cvt_roundpd_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_cvt_roundpd_epi64Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask8, _m512d, ffi.Int32)>>(
      '_mm512_maskz_cvt_roundpd_epi64');
  late final __mm512_maskz_cvt_roundpd_epi64 =
      __mm512_maskz_cvt_roundpd_epi64Ptr
          .asFunction<__m512i Function(int, _m512d, int)>();

  __m512i _mm512_cvtpd_epu64(
    _m512d arg0,
  ) {
    return __mm512_cvtpd_epu64(
      arg0,
    );
  }

  late final __mm512_cvtpd_epu64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(_m512d)>>(
          '_mm512_cvtpd_epu64');
  late final __mm512_cvtpd_epu64 =
      __mm512_cvtpd_epu64Ptr.asFunction<__m512i Function(_m512d)>();

  __m512i _mm512_mask_cvtpd_epu64(
    __m512i arg0,
    int arg1,
    _m512d arg2,
  ) {
    return __mm512_mask_cvtpd_epu64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtpd_epu64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __mmask8, _m512d)>>(
          '_mm512_mask_cvtpd_epu64');
  late final __mm512_mask_cvtpd_epu64 = __mm512_mask_cvtpd_epu64Ptr
      .asFunction<__m512i Function(__m512i, int, _m512d)>();

  __m512i _mm512_maskz_cvtpd_epu64(
    int arg0,
    _m512d arg1,
  ) {
    return __mm512_maskz_cvtpd_epu64(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvtpd_epu64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask8, _m512d)>>(
          '_mm512_maskz_cvtpd_epu64');
  late final __mm512_maskz_cvtpd_epu64 =
      __mm512_maskz_cvtpd_epu64Ptr.asFunction<__m512i Function(int, _m512d)>();

  __m512i _mm512_cvt_roundpd_epu64(
    _m512d arg0,
    int arg1,
  ) {
    return __mm512_cvt_roundpd_epu64(
      arg0,
      arg1,
    );
  }

  late final __mm512_cvt_roundpd_epu64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(_m512d, ffi.Int32)>>(
          '_mm512_cvt_roundpd_epu64');
  late final __mm512_cvt_roundpd_epu64 =
      __mm512_cvt_roundpd_epu64Ptr.asFunction<__m512i Function(_m512d, int)>();

  __m512i _mm512_mask_cvt_roundpd_epu64(
    __m512i arg0,
    int arg1,
    _m512d arg2,
    int arg3,
  ) {
    return __mm512_mask_cvt_roundpd_epu64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_cvt_roundpd_epu64Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask8, _m512d,
              ffi.Int32)>>('_mm512_mask_cvt_roundpd_epu64');
  late final __mm512_mask_cvt_roundpd_epu64 = __mm512_mask_cvt_roundpd_epu64Ptr
      .asFunction<__m512i Function(__m512i, int, _m512d, int)>();

  __m512i _mm512_maskz_cvt_roundpd_epu64(
    int arg0,
    _m512d arg1,
    int arg2,
  ) {
    return __mm512_maskz_cvt_roundpd_epu64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_cvt_roundpd_epu64Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask8, _m512d, ffi.Int32)>>(
      '_mm512_maskz_cvt_roundpd_epu64');
  late final __mm512_maskz_cvt_roundpd_epu64 =
      __mm512_maskz_cvt_roundpd_epu64Ptr
          .asFunction<__m512i Function(int, _m512d, int)>();

  __m512i _mm512_cvttpd_epi64(
    _m512d arg0,
  ) {
    return __mm512_cvttpd_epi64(
      arg0,
    );
  }

  late final __mm512_cvttpd_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(_m512d)>>(
          '_mm512_cvttpd_epi64');
  late final __mm512_cvttpd_epi64 =
      __mm512_cvttpd_epi64Ptr.asFunction<__m512i Function(_m512d)>();

  __m512i _mm512_mask_cvttpd_epi64(
    __m512i arg0,
    int arg1,
    _m512d arg2,
  ) {
    return __mm512_mask_cvttpd_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvttpd_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __mmask8, _m512d)>>(
          '_mm512_mask_cvttpd_epi64');
  late final __mm512_mask_cvttpd_epi64 = __mm512_mask_cvttpd_epi64Ptr
      .asFunction<__m512i Function(__m512i, int, _m512d)>();

  __m512i _mm512_maskz_cvttpd_epi64(
    int arg0,
    _m512d arg1,
  ) {
    return __mm512_maskz_cvttpd_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvttpd_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask8, _m512d)>>(
          '_mm512_maskz_cvttpd_epi64');
  late final __mm512_maskz_cvttpd_epi64 =
      __mm512_maskz_cvttpd_epi64Ptr.asFunction<__m512i Function(int, _m512d)>();

  __m512i _mm512_cvtt_roundpd_epi64(
    _m512d arg0,
    int arg1,
  ) {
    return __mm512_cvtt_roundpd_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm512_cvtt_roundpd_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(_m512d, ffi.Int32)>>(
          '_mm512_cvtt_roundpd_epi64');
  late final __mm512_cvtt_roundpd_epi64 =
      __mm512_cvtt_roundpd_epi64Ptr.asFunction<__m512i Function(_m512d, int)>();

  __m512i _mm512_mask_cvtt_roundpd_epi64(
    __m512i arg0,
    int arg1,
    _m512d arg2,
    int arg3,
  ) {
    return __mm512_mask_cvtt_roundpd_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_cvtt_roundpd_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask8, _m512d,
              ffi.Int32)>>('_mm512_mask_cvtt_roundpd_epi64');
  late final __mm512_mask_cvtt_roundpd_epi64 =
      __mm512_mask_cvtt_roundpd_epi64Ptr
          .asFunction<__m512i Function(__m512i, int, _m512d, int)>();

  __m512i _mm512_maskz_cvtt_roundpd_epi64(
    int arg0,
    _m512d arg1,
    int arg2,
  ) {
    return __mm512_maskz_cvtt_roundpd_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_cvtt_roundpd_epi64Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask8, _m512d, ffi.Int32)>>(
      '_mm512_maskz_cvtt_roundpd_epi64');
  late final __mm512_maskz_cvtt_roundpd_epi64 =
      __mm512_maskz_cvtt_roundpd_epi64Ptr
          .asFunction<__m512i Function(int, _m512d, int)>();

  __m512i _mm512_cvttpd_epu64(
    _m512d arg0,
  ) {
    return __mm512_cvttpd_epu64(
      arg0,
    );
  }

  late final __mm512_cvttpd_epu64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(_m512d)>>(
          '_mm512_cvttpd_epu64');
  late final __mm512_cvttpd_epu64 =
      __mm512_cvttpd_epu64Ptr.asFunction<__m512i Function(_m512d)>();

  __m512i _mm512_mask_cvttpd_epu64(
    __m512i arg0,
    int arg1,
    _m512d arg2,
  ) {
    return __mm512_mask_cvttpd_epu64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvttpd_epu64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __mmask8, _m512d)>>(
          '_mm512_mask_cvttpd_epu64');
  late final __mm512_mask_cvttpd_epu64 = __mm512_mask_cvttpd_epu64Ptr
      .asFunction<__m512i Function(__m512i, int, _m512d)>();

  __m512i _mm512_maskz_cvttpd_epu64(
    int arg0,
    _m512d arg1,
  ) {
    return __mm512_maskz_cvttpd_epu64(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvttpd_epu64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask8, _m512d)>>(
          '_mm512_maskz_cvttpd_epu64');
  late final __mm512_maskz_cvttpd_epu64 =
      __mm512_maskz_cvttpd_epu64Ptr.asFunction<__m512i Function(int, _m512d)>();

  __m512i _mm512_cvtt_roundpd_epu64(
    _m512d arg0,
    int arg1,
  ) {
    return __mm512_cvtt_roundpd_epu64(
      arg0,
      arg1,
    );
  }

  late final __mm512_cvtt_roundpd_epu64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(_m512d, ffi.Int32)>>(
          '_mm512_cvtt_roundpd_epu64');
  late final __mm512_cvtt_roundpd_epu64 =
      __mm512_cvtt_roundpd_epu64Ptr.asFunction<__m512i Function(_m512d, int)>();

  __m512i _mm512_mask_cvtt_roundpd_epu64(
    __m512i arg0,
    int arg1,
    _m512d arg2,
    int arg3,
  ) {
    return __mm512_mask_cvtt_roundpd_epu64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_cvtt_roundpd_epu64Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask8, _m512d,
              ffi.Int32)>>('_mm512_mask_cvtt_roundpd_epu64');
  late final __mm512_mask_cvtt_roundpd_epu64 =
      __mm512_mask_cvtt_roundpd_epu64Ptr
          .asFunction<__m512i Function(__m512i, int, _m512d, int)>();

  __m512i _mm512_maskz_cvtt_roundpd_epu64(
    int arg0,
    _m512d arg1,
    int arg2,
  ) {
    return __mm512_maskz_cvtt_roundpd_epu64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_cvtt_roundpd_epu64Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask8, _m512d, ffi.Int32)>>(
      '_mm512_maskz_cvtt_roundpd_epu64');
  late final __mm512_maskz_cvtt_roundpd_epu64 =
      __mm512_maskz_cvtt_roundpd_epu64Ptr
          .asFunction<__m512i Function(int, _m512d, int)>();

  __m512i _mm512_cvtps_epi64(
    __m256 arg0,
  ) {
    return __mm512_cvtps_epi64(
      arg0,
    );
  }

  late final __mm512_cvtps_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m256)>>(
          '_mm512_cvtps_epi64');
  late final __mm512_cvtps_epi64 =
      __mm512_cvtps_epi64Ptr.asFunction<__m512i Function(__m256)>();

  __m512i _mm512_mask_cvtps_epi64(
    __m512i arg0,
    int arg1,
    __m256 arg2,
  ) {
    return __mm512_mask_cvtps_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtps_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __mmask8, __m256)>>(
          '_mm512_mask_cvtps_epi64');
  late final __mm512_mask_cvtps_epi64 = __mm512_mask_cvtps_epi64Ptr
      .asFunction<__m512i Function(__m512i, int, __m256)>();

  __m512i _mm512_maskz_cvtps_epi64(
    int arg0,
    __m256 arg1,
  ) {
    return __mm512_maskz_cvtps_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvtps_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask8, __m256)>>(
          '_mm512_maskz_cvtps_epi64');
  late final __mm512_maskz_cvtps_epi64 =
      __mm512_maskz_cvtps_epi64Ptr.asFunction<__m512i Function(int, __m256)>();

  __m512i _mm512_cvt_roundps_epi64(
    __m256 arg0,
    int arg1,
  ) {
    return __mm512_cvt_roundps_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm512_cvt_roundps_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m256, ffi.Int32)>>(
          '_mm512_cvt_roundps_epi64');
  late final __mm512_cvt_roundps_epi64 =
      __mm512_cvt_roundps_epi64Ptr.asFunction<__m512i Function(__m256, int)>();

  __m512i _mm512_mask_cvt_roundps_epi64(
    __m512i arg0,
    int arg1,
    __m256 arg2,
    int arg3,
  ) {
    return __mm512_mask_cvt_roundps_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_cvt_roundps_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask8, __m256,
              ffi.Int32)>>('_mm512_mask_cvt_roundps_epi64');
  late final __mm512_mask_cvt_roundps_epi64 = __mm512_mask_cvt_roundps_epi64Ptr
      .asFunction<__m512i Function(__m512i, int, __m256, int)>();

  __m512i _mm512_maskz_cvt_roundps_epi64(
    int arg0,
    __m256 arg1,
    int arg2,
  ) {
    return __mm512_maskz_cvt_roundps_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_cvt_roundps_epi64Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask8, __m256, ffi.Int32)>>(
      '_mm512_maskz_cvt_roundps_epi64');
  late final __mm512_maskz_cvt_roundps_epi64 =
      __mm512_maskz_cvt_roundps_epi64Ptr
          .asFunction<__m512i Function(int, __m256, int)>();

  __m512i _mm512_cvtps_epu64(
    __m256 arg0,
  ) {
    return __mm512_cvtps_epu64(
      arg0,
    );
  }

  late final __mm512_cvtps_epu64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m256)>>(
          '_mm512_cvtps_epu64');
  late final __mm512_cvtps_epu64 =
      __mm512_cvtps_epu64Ptr.asFunction<__m512i Function(__m256)>();

  __m512i _mm512_mask_cvtps_epu64(
    __m512i arg0,
    int arg1,
    __m256 arg2,
  ) {
    return __mm512_mask_cvtps_epu64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtps_epu64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __mmask8, __m256)>>(
          '_mm512_mask_cvtps_epu64');
  late final __mm512_mask_cvtps_epu64 = __mm512_mask_cvtps_epu64Ptr
      .asFunction<__m512i Function(__m512i, int, __m256)>();

  __m512i _mm512_maskz_cvtps_epu64(
    int arg0,
    __m256 arg1,
  ) {
    return __mm512_maskz_cvtps_epu64(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvtps_epu64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask8, __m256)>>(
          '_mm512_maskz_cvtps_epu64');
  late final __mm512_maskz_cvtps_epu64 =
      __mm512_maskz_cvtps_epu64Ptr.asFunction<__m512i Function(int, __m256)>();

  __m512i _mm512_cvt_roundps_epu64(
    __m256 arg0,
    int arg1,
  ) {
    return __mm512_cvt_roundps_epu64(
      arg0,
      arg1,
    );
  }

  late final __mm512_cvt_roundps_epu64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m256, ffi.Int32)>>(
          '_mm512_cvt_roundps_epu64');
  late final __mm512_cvt_roundps_epu64 =
      __mm512_cvt_roundps_epu64Ptr.asFunction<__m512i Function(__m256, int)>();

  __m512i _mm512_mask_cvt_roundps_epu64(
    __m512i arg0,
    int arg1,
    __m256 arg2,
    int arg3,
  ) {
    return __mm512_mask_cvt_roundps_epu64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_cvt_roundps_epu64Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask8, __m256,
              ffi.Int32)>>('_mm512_mask_cvt_roundps_epu64');
  late final __mm512_mask_cvt_roundps_epu64 = __mm512_mask_cvt_roundps_epu64Ptr
      .asFunction<__m512i Function(__m512i, int, __m256, int)>();

  __m512i _mm512_maskz_cvt_roundps_epu64(
    int arg0,
    __m256 arg1,
    int arg2,
  ) {
    return __mm512_maskz_cvt_roundps_epu64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_cvt_roundps_epu64Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask8, __m256, ffi.Int32)>>(
      '_mm512_maskz_cvt_roundps_epu64');
  late final __mm512_maskz_cvt_roundps_epu64 =
      __mm512_maskz_cvt_roundps_epu64Ptr
          .asFunction<__m512i Function(int, __m256, int)>();

  __m512i _mm512_cvttps_epi64(
    __m256 arg0,
  ) {
    return __mm512_cvttps_epi64(
      arg0,
    );
  }

  late final __mm512_cvttps_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m256)>>(
          '_mm512_cvttps_epi64');
  late final __mm512_cvttps_epi64 =
      __mm512_cvttps_epi64Ptr.asFunction<__m512i Function(__m256)>();

  __m512i _mm512_mask_cvttps_epi64(
    __m512i arg0,
    int arg1,
    __m256 arg2,
  ) {
    return __mm512_mask_cvttps_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvttps_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __mmask8, __m256)>>(
          '_mm512_mask_cvttps_epi64');
  late final __mm512_mask_cvttps_epi64 = __mm512_mask_cvttps_epi64Ptr
      .asFunction<__m512i Function(__m512i, int, __m256)>();

  __m512i _mm512_maskz_cvttps_epi64(
    int arg0,
    __m256 arg1,
  ) {
    return __mm512_maskz_cvttps_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvttps_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask8, __m256)>>(
          '_mm512_maskz_cvttps_epi64');
  late final __mm512_maskz_cvttps_epi64 =
      __mm512_maskz_cvttps_epi64Ptr.asFunction<__m512i Function(int, __m256)>();

  __m512i _mm512_cvtt_roundps_epi64(
    __m256 arg0,
    int arg1,
  ) {
    return __mm512_cvtt_roundps_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm512_cvtt_roundps_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m256, ffi.Int32)>>(
          '_mm512_cvtt_roundps_epi64');
  late final __mm512_cvtt_roundps_epi64 =
      __mm512_cvtt_roundps_epi64Ptr.asFunction<__m512i Function(__m256, int)>();

  __m512i _mm512_mask_cvtt_roundps_epi64(
    __m512i arg0,
    int arg1,
    __m256 arg2,
    int arg3,
  ) {
    return __mm512_mask_cvtt_roundps_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_cvtt_roundps_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask8, __m256,
              ffi.Int32)>>('_mm512_mask_cvtt_roundps_epi64');
  late final __mm512_mask_cvtt_roundps_epi64 =
      __mm512_mask_cvtt_roundps_epi64Ptr
          .asFunction<__m512i Function(__m512i, int, __m256, int)>();

  __m512i _mm512_maskz_cvtt_roundps_epi64(
    int arg0,
    __m256 arg1,
    int arg2,
  ) {
    return __mm512_maskz_cvtt_roundps_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_cvtt_roundps_epi64Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask8, __m256, ffi.Int32)>>(
      '_mm512_maskz_cvtt_roundps_epi64');
  late final __mm512_maskz_cvtt_roundps_epi64 =
      __mm512_maskz_cvtt_roundps_epi64Ptr
          .asFunction<__m512i Function(int, __m256, int)>();

  __m512i _mm512_cvttps_epu64(
    __m256 arg0,
  ) {
    return __mm512_cvttps_epu64(
      arg0,
    );
  }

  late final __mm512_cvttps_epu64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m256)>>(
          '_mm512_cvttps_epu64');
  late final __mm512_cvttps_epu64 =
      __mm512_cvttps_epu64Ptr.asFunction<__m512i Function(__m256)>();

  __m512i _mm512_mask_cvttps_epu64(
    __m512i arg0,
    int arg1,
    __m256 arg2,
  ) {
    return __mm512_mask_cvttps_epu64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvttps_epu64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __mmask8, __m256)>>(
          '_mm512_mask_cvttps_epu64');
  late final __mm512_mask_cvttps_epu64 = __mm512_mask_cvttps_epu64Ptr
      .asFunction<__m512i Function(__m512i, int, __m256)>();

  __m512i _mm512_maskz_cvttps_epu64(
    int arg0,
    __m256 arg1,
  ) {
    return __mm512_maskz_cvttps_epu64(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvttps_epu64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask8, __m256)>>(
          '_mm512_maskz_cvttps_epu64');
  late final __mm512_maskz_cvttps_epu64 =
      __mm512_maskz_cvttps_epu64Ptr.asFunction<__m512i Function(int, __m256)>();

  __m512i _mm512_cvtt_roundps_epu64(
    __m256 arg0,
    int arg1,
  ) {
    return __mm512_cvtt_roundps_epu64(
      arg0,
      arg1,
    );
  }

  late final __mm512_cvtt_roundps_epu64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m256, ffi.Int32)>>(
          '_mm512_cvtt_roundps_epu64');
  late final __mm512_cvtt_roundps_epu64 =
      __mm512_cvtt_roundps_epu64Ptr.asFunction<__m512i Function(__m256, int)>();

  __m512i _mm512_mask_cvtt_roundps_epu64(
    __m512i arg0,
    int arg1,
    __m256 arg2,
    int arg3,
  ) {
    return __mm512_mask_cvtt_roundps_epu64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_cvtt_roundps_epu64Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask8, __m256,
              ffi.Int32)>>('_mm512_mask_cvtt_roundps_epu64');
  late final __mm512_mask_cvtt_roundps_epu64 =
      __mm512_mask_cvtt_roundps_epu64Ptr
          .asFunction<__m512i Function(__m512i, int, __m256, int)>();

  __m512i _mm512_maskz_cvtt_roundps_epu64(
    int arg0,
    __m256 arg1,
    int arg2,
  ) {
    return __mm512_maskz_cvtt_roundps_epu64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_cvtt_roundps_epu64Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask8, __m256, ffi.Int32)>>(
      '_mm512_maskz_cvtt_roundps_epu64');
  late final __mm512_maskz_cvtt_roundps_epu64 =
      __mm512_maskz_cvtt_roundps_epu64Ptr
          .asFunction<__m512i Function(int, __m256, int)>();

  int _mm512_cmpeq_epi8_mask(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_cmpeq_epi8_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_cmpeq_epi8_maskPtr =
      _lookup<ffi.NativeFunction<__mmask64 Function(__m512i, __m512i)>>(
          '_mm512_cmpeq_epi8_mask');
  late final __mm512_cmpeq_epi8_mask =
      __mm512_cmpeq_epi8_maskPtr.asFunction<int Function(__m512i, __m512i)>();

  int _mm512_cmpge_epi8_mask(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_cmpge_epi8_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_cmpge_epi8_maskPtr =
      _lookup<ffi.NativeFunction<__mmask64 Function(__m512i, __m512i)>>(
          '_mm512_cmpge_epi8_mask');
  late final __mm512_cmpge_epi8_mask =
      __mm512_cmpge_epi8_maskPtr.asFunction<int Function(__m512i, __m512i)>();

  int _mm512_cmpgt_epi8_mask(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_cmpgt_epi8_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_cmpgt_epi8_maskPtr =
      _lookup<ffi.NativeFunction<__mmask64 Function(__m512i, __m512i)>>(
          '_mm512_cmpgt_epi8_mask');
  late final __mm512_cmpgt_epi8_mask =
      __mm512_cmpgt_epi8_maskPtr.asFunction<int Function(__m512i, __m512i)>();

  int _mm512_cmple_epi8_mask(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_cmple_epi8_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_cmple_epi8_maskPtr =
      _lookup<ffi.NativeFunction<__mmask64 Function(__m512i, __m512i)>>(
          '_mm512_cmple_epi8_mask');
  late final __mm512_cmple_epi8_mask =
      __mm512_cmple_epi8_maskPtr.asFunction<int Function(__m512i, __m512i)>();

  int _mm512_cmplt_epi8_mask(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_cmplt_epi8_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_cmplt_epi8_maskPtr =
      _lookup<ffi.NativeFunction<__mmask64 Function(__m512i, __m512i)>>(
          '_mm512_cmplt_epi8_mask');
  late final __mm512_cmplt_epi8_mask =
      __mm512_cmplt_epi8_maskPtr.asFunction<int Function(__m512i, __m512i)>();

  int _mm512_cmpneq_epi8_mask(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_cmpneq_epi8_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_cmpneq_epi8_maskPtr =
      _lookup<ffi.NativeFunction<__mmask64 Function(__m512i, __m512i)>>(
          '_mm512_cmpneq_epi8_mask');
  late final __mm512_cmpneq_epi8_mask =
      __mm512_cmpneq_epi8_maskPtr.asFunction<int Function(__m512i, __m512i)>();

  int _mm512_cmpeq_epu8_mask(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_cmpeq_epu8_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_cmpeq_epu8_maskPtr =
      _lookup<ffi.NativeFunction<__mmask64 Function(__m512i, __m512i)>>(
          '_mm512_cmpeq_epu8_mask');
  late final __mm512_cmpeq_epu8_mask =
      __mm512_cmpeq_epu8_maskPtr.asFunction<int Function(__m512i, __m512i)>();

  int _mm512_cmpge_epu8_mask(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_cmpge_epu8_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_cmpge_epu8_maskPtr =
      _lookup<ffi.NativeFunction<__mmask64 Function(__m512i, __m512i)>>(
          '_mm512_cmpge_epu8_mask');
  late final __mm512_cmpge_epu8_mask =
      __mm512_cmpge_epu8_maskPtr.asFunction<int Function(__m512i, __m512i)>();

  int _mm512_cmpgt_epu8_mask(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_cmpgt_epu8_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_cmpgt_epu8_maskPtr =
      _lookup<ffi.NativeFunction<__mmask64 Function(__m512i, __m512i)>>(
          '_mm512_cmpgt_epu8_mask');
  late final __mm512_cmpgt_epu8_mask =
      __mm512_cmpgt_epu8_maskPtr.asFunction<int Function(__m512i, __m512i)>();

  int _mm512_cmple_epu8_mask(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_cmple_epu8_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_cmple_epu8_maskPtr =
      _lookup<ffi.NativeFunction<__mmask64 Function(__m512i, __m512i)>>(
          '_mm512_cmple_epu8_mask');
  late final __mm512_cmple_epu8_mask =
      __mm512_cmple_epu8_maskPtr.asFunction<int Function(__m512i, __m512i)>();

  int _mm512_cmplt_epu8_mask(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_cmplt_epu8_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_cmplt_epu8_maskPtr =
      _lookup<ffi.NativeFunction<__mmask64 Function(__m512i, __m512i)>>(
          '_mm512_cmplt_epu8_mask');
  late final __mm512_cmplt_epu8_mask =
      __mm512_cmplt_epu8_maskPtr.asFunction<int Function(__m512i, __m512i)>();

  int _mm512_cmpneq_epu8_mask(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_cmpneq_epu8_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_cmpneq_epu8_maskPtr =
      _lookup<ffi.NativeFunction<__mmask64 Function(__m512i, __m512i)>>(
          '_mm512_cmpneq_epu8_mask');
  late final __mm512_cmpneq_epu8_mask =
      __mm512_cmpneq_epu8_maskPtr.asFunction<int Function(__m512i, __m512i)>();

  int _mm512_mask_cmpeq_epi8_mask(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cmpeq_epi8_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cmpeq_epi8_maskPtr = _lookup<
          ffi.NativeFunction<__mmask64 Function(__mmask64, __m512i, __m512i)>>(
      '_mm512_mask_cmpeq_epi8_mask');
  late final __mm512_mask_cmpeq_epi8_mask = __mm512_mask_cmpeq_epi8_maskPtr
      .asFunction<int Function(int, __m512i, __m512i)>();

  int _mm512_mask_cmpge_epi8_mask(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cmpge_epi8_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cmpge_epi8_maskPtr = _lookup<
          ffi.NativeFunction<__mmask64 Function(__mmask64, __m512i, __m512i)>>(
      '_mm512_mask_cmpge_epi8_mask');
  late final __mm512_mask_cmpge_epi8_mask = __mm512_mask_cmpge_epi8_maskPtr
      .asFunction<int Function(int, __m512i, __m512i)>();

  int _mm512_mask_cmpgt_epi8_mask(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cmpgt_epi8_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cmpgt_epi8_maskPtr = _lookup<
          ffi.NativeFunction<__mmask64 Function(__mmask64, __m512i, __m512i)>>(
      '_mm512_mask_cmpgt_epi8_mask');
  late final __mm512_mask_cmpgt_epi8_mask = __mm512_mask_cmpgt_epi8_maskPtr
      .asFunction<int Function(int, __m512i, __m512i)>();

  int _mm512_mask_cmple_epi8_mask(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cmple_epi8_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cmple_epi8_maskPtr = _lookup<
          ffi.NativeFunction<__mmask64 Function(__mmask64, __m512i, __m512i)>>(
      '_mm512_mask_cmple_epi8_mask');
  late final __mm512_mask_cmple_epi8_mask = __mm512_mask_cmple_epi8_maskPtr
      .asFunction<int Function(int, __m512i, __m512i)>();

  int _mm512_mask_cmplt_epi8_mask(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cmplt_epi8_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cmplt_epi8_maskPtr = _lookup<
          ffi.NativeFunction<__mmask64 Function(__mmask64, __m512i, __m512i)>>(
      '_mm512_mask_cmplt_epi8_mask');
  late final __mm512_mask_cmplt_epi8_mask = __mm512_mask_cmplt_epi8_maskPtr
      .asFunction<int Function(int, __m512i, __m512i)>();

  int _mm512_mask_cmpneq_epi8_mask(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cmpneq_epi8_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cmpneq_epi8_maskPtr = _lookup<
          ffi.NativeFunction<__mmask64 Function(__mmask64, __m512i, __m512i)>>(
      '_mm512_mask_cmpneq_epi8_mask');
  late final __mm512_mask_cmpneq_epi8_mask = __mm512_mask_cmpneq_epi8_maskPtr
      .asFunction<int Function(int, __m512i, __m512i)>();

  int _mm512_mask_cmpeq_epu8_mask(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cmpeq_epu8_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cmpeq_epu8_maskPtr = _lookup<
          ffi.NativeFunction<__mmask64 Function(__mmask64, __m512i, __m512i)>>(
      '_mm512_mask_cmpeq_epu8_mask');
  late final __mm512_mask_cmpeq_epu8_mask = __mm512_mask_cmpeq_epu8_maskPtr
      .asFunction<int Function(int, __m512i, __m512i)>();

  int _mm512_mask_cmpge_epu8_mask(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cmpge_epu8_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cmpge_epu8_maskPtr = _lookup<
          ffi.NativeFunction<__mmask64 Function(__mmask64, __m512i, __m512i)>>(
      '_mm512_mask_cmpge_epu8_mask');
  late final __mm512_mask_cmpge_epu8_mask = __mm512_mask_cmpge_epu8_maskPtr
      .asFunction<int Function(int, __m512i, __m512i)>();

  int _mm512_mask_cmpgt_epu8_mask(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cmpgt_epu8_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cmpgt_epu8_maskPtr = _lookup<
          ffi.NativeFunction<__mmask64 Function(__mmask64, __m512i, __m512i)>>(
      '_mm512_mask_cmpgt_epu8_mask');
  late final __mm512_mask_cmpgt_epu8_mask = __mm512_mask_cmpgt_epu8_maskPtr
      .asFunction<int Function(int, __m512i, __m512i)>();

  int _mm512_mask_cmple_epu8_mask(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cmple_epu8_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cmple_epu8_maskPtr = _lookup<
          ffi.NativeFunction<__mmask64 Function(__mmask64, __m512i, __m512i)>>(
      '_mm512_mask_cmple_epu8_mask');
  late final __mm512_mask_cmple_epu8_mask = __mm512_mask_cmple_epu8_maskPtr
      .asFunction<int Function(int, __m512i, __m512i)>();

  int _mm512_mask_cmplt_epu8_mask(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cmplt_epu8_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cmplt_epu8_maskPtr = _lookup<
          ffi.NativeFunction<__mmask64 Function(__mmask64, __m512i, __m512i)>>(
      '_mm512_mask_cmplt_epu8_mask');
  late final __mm512_mask_cmplt_epu8_mask = __mm512_mask_cmplt_epu8_maskPtr
      .asFunction<int Function(int, __m512i, __m512i)>();

  int _mm512_mask_cmpneq_epu8_mask(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cmpneq_epu8_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cmpneq_epu8_maskPtr = _lookup<
          ffi.NativeFunction<__mmask64 Function(__mmask64, __m512i, __m512i)>>(
      '_mm512_mask_cmpneq_epu8_mask');
  late final __mm512_mask_cmpneq_epu8_mask = __mm512_mask_cmpneq_epu8_maskPtr
      .asFunction<int Function(int, __m512i, __m512i)>();

  int _mm512_cmpeq_epi16_mask(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_cmpeq_epi16_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_cmpeq_epi16_maskPtr =
      _lookup<ffi.NativeFunction<__mmask32 Function(__m512i, __m512i)>>(
          '_mm512_cmpeq_epi16_mask');
  late final __mm512_cmpeq_epi16_mask =
      __mm512_cmpeq_epi16_maskPtr.asFunction<int Function(__m512i, __m512i)>();

  int _mm512_cmpge_epi16_mask(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_cmpge_epi16_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_cmpge_epi16_maskPtr =
      _lookup<ffi.NativeFunction<__mmask32 Function(__m512i, __m512i)>>(
          '_mm512_cmpge_epi16_mask');
  late final __mm512_cmpge_epi16_mask =
      __mm512_cmpge_epi16_maskPtr.asFunction<int Function(__m512i, __m512i)>();

  int _mm512_cmpgt_epi16_mask(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_cmpgt_epi16_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_cmpgt_epi16_maskPtr =
      _lookup<ffi.NativeFunction<__mmask32 Function(__m512i, __m512i)>>(
          '_mm512_cmpgt_epi16_mask');
  late final __mm512_cmpgt_epi16_mask =
      __mm512_cmpgt_epi16_maskPtr.asFunction<int Function(__m512i, __m512i)>();

  int _mm512_cmple_epi16_mask(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_cmple_epi16_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_cmple_epi16_maskPtr =
      _lookup<ffi.NativeFunction<__mmask32 Function(__m512i, __m512i)>>(
          '_mm512_cmple_epi16_mask');
  late final __mm512_cmple_epi16_mask =
      __mm512_cmple_epi16_maskPtr.asFunction<int Function(__m512i, __m512i)>();

  int _mm512_cmplt_epi16_mask(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_cmplt_epi16_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_cmplt_epi16_maskPtr =
      _lookup<ffi.NativeFunction<__mmask32 Function(__m512i, __m512i)>>(
          '_mm512_cmplt_epi16_mask');
  late final __mm512_cmplt_epi16_mask =
      __mm512_cmplt_epi16_maskPtr.asFunction<int Function(__m512i, __m512i)>();

  int _mm512_cmpneq_epi16_mask(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_cmpneq_epi16_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_cmpneq_epi16_maskPtr =
      _lookup<ffi.NativeFunction<__mmask32 Function(__m512i, __m512i)>>(
          '_mm512_cmpneq_epi16_mask');
  late final __mm512_cmpneq_epi16_mask =
      __mm512_cmpneq_epi16_maskPtr.asFunction<int Function(__m512i, __m512i)>();

  int _mm512_cmpeq_epu16_mask(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_cmpeq_epu16_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_cmpeq_epu16_maskPtr =
      _lookup<ffi.NativeFunction<__mmask32 Function(__m512i, __m512i)>>(
          '_mm512_cmpeq_epu16_mask');
  late final __mm512_cmpeq_epu16_mask =
      __mm512_cmpeq_epu16_maskPtr.asFunction<int Function(__m512i, __m512i)>();

  int _mm512_cmpge_epu16_mask(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_cmpge_epu16_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_cmpge_epu16_maskPtr =
      _lookup<ffi.NativeFunction<__mmask32 Function(__m512i, __m512i)>>(
          '_mm512_cmpge_epu16_mask');
  late final __mm512_cmpge_epu16_mask =
      __mm512_cmpge_epu16_maskPtr.asFunction<int Function(__m512i, __m512i)>();

  int _mm512_cmpgt_epu16_mask(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_cmpgt_epu16_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_cmpgt_epu16_maskPtr =
      _lookup<ffi.NativeFunction<__mmask32 Function(__m512i, __m512i)>>(
          '_mm512_cmpgt_epu16_mask');
  late final __mm512_cmpgt_epu16_mask =
      __mm512_cmpgt_epu16_maskPtr.asFunction<int Function(__m512i, __m512i)>();

  int _mm512_cmple_epu16_mask(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_cmple_epu16_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_cmple_epu16_maskPtr =
      _lookup<ffi.NativeFunction<__mmask32 Function(__m512i, __m512i)>>(
          '_mm512_cmple_epu16_mask');
  late final __mm512_cmple_epu16_mask =
      __mm512_cmple_epu16_maskPtr.asFunction<int Function(__m512i, __m512i)>();

  int _mm512_cmplt_epu16_mask(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_cmplt_epu16_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_cmplt_epu16_maskPtr =
      _lookup<ffi.NativeFunction<__mmask32 Function(__m512i, __m512i)>>(
          '_mm512_cmplt_epu16_mask');
  late final __mm512_cmplt_epu16_mask =
      __mm512_cmplt_epu16_maskPtr.asFunction<int Function(__m512i, __m512i)>();

  int _mm512_cmpneq_epu16_mask(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_cmpneq_epu16_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_cmpneq_epu16_maskPtr =
      _lookup<ffi.NativeFunction<__mmask32 Function(__m512i, __m512i)>>(
          '_mm512_cmpneq_epu16_mask');
  late final __mm512_cmpneq_epu16_mask =
      __mm512_cmpneq_epu16_maskPtr.asFunction<int Function(__m512i, __m512i)>();

  int _mm512_mask_cmpeq_epi16_mask(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cmpeq_epi16_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cmpeq_epi16_maskPtr = _lookup<
          ffi.NativeFunction<__mmask32 Function(__mmask32, __m512i, __m512i)>>(
      '_mm512_mask_cmpeq_epi16_mask');
  late final __mm512_mask_cmpeq_epi16_mask = __mm512_mask_cmpeq_epi16_maskPtr
      .asFunction<int Function(int, __m512i, __m512i)>();

  int _mm512_mask_cmpge_epi16_mask(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cmpge_epi16_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cmpge_epi16_maskPtr = _lookup<
          ffi.NativeFunction<__mmask32 Function(__mmask32, __m512i, __m512i)>>(
      '_mm512_mask_cmpge_epi16_mask');
  late final __mm512_mask_cmpge_epi16_mask = __mm512_mask_cmpge_epi16_maskPtr
      .asFunction<int Function(int, __m512i, __m512i)>();

  int _mm512_mask_cmpgt_epi16_mask(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cmpgt_epi16_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cmpgt_epi16_maskPtr = _lookup<
          ffi.NativeFunction<__mmask32 Function(__mmask32, __m512i, __m512i)>>(
      '_mm512_mask_cmpgt_epi16_mask');
  late final __mm512_mask_cmpgt_epi16_mask = __mm512_mask_cmpgt_epi16_maskPtr
      .asFunction<int Function(int, __m512i, __m512i)>();

  int _mm512_mask_cmple_epi16_mask(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cmple_epi16_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cmple_epi16_maskPtr = _lookup<
          ffi.NativeFunction<__mmask32 Function(__mmask32, __m512i, __m512i)>>(
      '_mm512_mask_cmple_epi16_mask');
  late final __mm512_mask_cmple_epi16_mask = __mm512_mask_cmple_epi16_maskPtr
      .asFunction<int Function(int, __m512i, __m512i)>();

  int _mm512_mask_cmplt_epi16_mask(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cmplt_epi16_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cmplt_epi16_maskPtr = _lookup<
          ffi.NativeFunction<__mmask32 Function(__mmask32, __m512i, __m512i)>>(
      '_mm512_mask_cmplt_epi16_mask');
  late final __mm512_mask_cmplt_epi16_mask = __mm512_mask_cmplt_epi16_maskPtr
      .asFunction<int Function(int, __m512i, __m512i)>();

  int _mm512_mask_cmpneq_epi16_mask(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cmpneq_epi16_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cmpneq_epi16_maskPtr = _lookup<
          ffi.NativeFunction<__mmask32 Function(__mmask32, __m512i, __m512i)>>(
      '_mm512_mask_cmpneq_epi16_mask');
  late final __mm512_mask_cmpneq_epi16_mask = __mm512_mask_cmpneq_epi16_maskPtr
      .asFunction<int Function(int, __m512i, __m512i)>();

  int _mm512_mask_cmpeq_epu16_mask(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cmpeq_epu16_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cmpeq_epu16_maskPtr = _lookup<
          ffi.NativeFunction<__mmask32 Function(__mmask32, __m512i, __m512i)>>(
      '_mm512_mask_cmpeq_epu16_mask');
  late final __mm512_mask_cmpeq_epu16_mask = __mm512_mask_cmpeq_epu16_maskPtr
      .asFunction<int Function(int, __m512i, __m512i)>();

  int _mm512_mask_cmpge_epu16_mask(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cmpge_epu16_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cmpge_epu16_maskPtr = _lookup<
          ffi.NativeFunction<__mmask32 Function(__mmask32, __m512i, __m512i)>>(
      '_mm512_mask_cmpge_epu16_mask');
  late final __mm512_mask_cmpge_epu16_mask = __mm512_mask_cmpge_epu16_maskPtr
      .asFunction<int Function(int, __m512i, __m512i)>();

  int _mm512_mask_cmpgt_epu16_mask(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cmpgt_epu16_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cmpgt_epu16_maskPtr = _lookup<
          ffi.NativeFunction<__mmask32 Function(__mmask32, __m512i, __m512i)>>(
      '_mm512_mask_cmpgt_epu16_mask');
  late final __mm512_mask_cmpgt_epu16_mask = __mm512_mask_cmpgt_epu16_maskPtr
      .asFunction<int Function(int, __m512i, __m512i)>();

  int _mm512_mask_cmple_epu16_mask(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cmple_epu16_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cmple_epu16_maskPtr = _lookup<
          ffi.NativeFunction<__mmask32 Function(__mmask32, __m512i, __m512i)>>(
      '_mm512_mask_cmple_epu16_mask');
  late final __mm512_mask_cmple_epu16_mask = __mm512_mask_cmple_epu16_maskPtr
      .asFunction<int Function(int, __m512i, __m512i)>();

  int _mm512_mask_cmplt_epu16_mask(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cmplt_epu16_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cmplt_epu16_maskPtr = _lookup<
          ffi.NativeFunction<__mmask32 Function(__mmask32, __m512i, __m512i)>>(
      '_mm512_mask_cmplt_epu16_mask');
  late final __mm512_mask_cmplt_epu16_mask = __mm512_mask_cmplt_epu16_maskPtr
      .asFunction<int Function(int, __m512i, __m512i)>();

  int _mm512_mask_cmpneq_epu16_mask(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cmpneq_epu16_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cmpneq_epu16_maskPtr = _lookup<
          ffi.NativeFunction<__mmask32 Function(__mmask32, __m512i, __m512i)>>(
      '_mm512_mask_cmpneq_epu16_mask');
  late final __mm512_mask_cmpneq_epu16_mask = __mm512_mask_cmpneq_epu16_maskPtr
      .asFunction<int Function(int, __m512i, __m512i)>();

  int _mm512_cmpeq_epi32_mask(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_cmpeq_epi32_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_cmpeq_epi32_maskPtr =
      _lookup<ffi.NativeFunction<__mmask16 Function(__m512i, __m512i)>>(
          '_mm512_cmpeq_epi32_mask');
  late final __mm512_cmpeq_epi32_mask =
      __mm512_cmpeq_epi32_maskPtr.asFunction<int Function(__m512i, __m512i)>();

  int _mm512_cmpge_epi32_mask(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_cmpge_epi32_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_cmpge_epi32_maskPtr =
      _lookup<ffi.NativeFunction<__mmask16 Function(__m512i, __m512i)>>(
          '_mm512_cmpge_epi32_mask');
  late final __mm512_cmpge_epi32_mask =
      __mm512_cmpge_epi32_maskPtr.asFunction<int Function(__m512i, __m512i)>();

  int _mm512_cmpgt_epi32_mask(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_cmpgt_epi32_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_cmpgt_epi32_maskPtr =
      _lookup<ffi.NativeFunction<__mmask16 Function(__m512i, __m512i)>>(
          '_mm512_cmpgt_epi32_mask');
  late final __mm512_cmpgt_epi32_mask =
      __mm512_cmpgt_epi32_maskPtr.asFunction<int Function(__m512i, __m512i)>();

  int _mm512_cmple_epi32_mask(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_cmple_epi32_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_cmple_epi32_maskPtr =
      _lookup<ffi.NativeFunction<__mmask16 Function(__m512i, __m512i)>>(
          '_mm512_cmple_epi32_mask');
  late final __mm512_cmple_epi32_mask =
      __mm512_cmple_epi32_maskPtr.asFunction<int Function(__m512i, __m512i)>();

  int _mm512_cmplt_epi32_mask(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_cmplt_epi32_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_cmplt_epi32_maskPtr =
      _lookup<ffi.NativeFunction<__mmask16 Function(__m512i, __m512i)>>(
          '_mm512_cmplt_epi32_mask');
  late final __mm512_cmplt_epi32_mask =
      __mm512_cmplt_epi32_maskPtr.asFunction<int Function(__m512i, __m512i)>();

  int _mm512_cmpneq_epi32_mask(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_cmpneq_epi32_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_cmpneq_epi32_maskPtr =
      _lookup<ffi.NativeFunction<__mmask16 Function(__m512i, __m512i)>>(
          '_mm512_cmpneq_epi32_mask');
  late final __mm512_cmpneq_epi32_mask =
      __mm512_cmpneq_epi32_maskPtr.asFunction<int Function(__m512i, __m512i)>();

  int _mm512_cmpeq_epu32_mask(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_cmpeq_epu32_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_cmpeq_epu32_maskPtr =
      _lookup<ffi.NativeFunction<__mmask16 Function(__m512i, __m512i)>>(
          '_mm512_cmpeq_epu32_mask');
  late final __mm512_cmpeq_epu32_mask =
      __mm512_cmpeq_epu32_maskPtr.asFunction<int Function(__m512i, __m512i)>();

  int _mm512_cmpge_epu32_mask(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_cmpge_epu32_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_cmpge_epu32_maskPtr =
      _lookup<ffi.NativeFunction<__mmask16 Function(__m512i, __m512i)>>(
          '_mm512_cmpge_epu32_mask');
  late final __mm512_cmpge_epu32_mask =
      __mm512_cmpge_epu32_maskPtr.asFunction<int Function(__m512i, __m512i)>();

  int _mm512_cmpgt_epu32_mask(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_cmpgt_epu32_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_cmpgt_epu32_maskPtr =
      _lookup<ffi.NativeFunction<__mmask16 Function(__m512i, __m512i)>>(
          '_mm512_cmpgt_epu32_mask');
  late final __mm512_cmpgt_epu32_mask =
      __mm512_cmpgt_epu32_maskPtr.asFunction<int Function(__m512i, __m512i)>();

  int _mm512_cmple_epu32_mask(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_cmple_epu32_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_cmple_epu32_maskPtr =
      _lookup<ffi.NativeFunction<__mmask16 Function(__m512i, __m512i)>>(
          '_mm512_cmple_epu32_mask');
  late final __mm512_cmple_epu32_mask =
      __mm512_cmple_epu32_maskPtr.asFunction<int Function(__m512i, __m512i)>();

  int _mm512_cmplt_epu32_mask(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_cmplt_epu32_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_cmplt_epu32_maskPtr =
      _lookup<ffi.NativeFunction<__mmask16 Function(__m512i, __m512i)>>(
          '_mm512_cmplt_epu32_mask');
  late final __mm512_cmplt_epu32_mask =
      __mm512_cmplt_epu32_maskPtr.asFunction<int Function(__m512i, __m512i)>();

  int _mm512_cmpneq_epu32_mask(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_cmpneq_epu32_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_cmpneq_epu32_maskPtr =
      _lookup<ffi.NativeFunction<__mmask16 Function(__m512i, __m512i)>>(
          '_mm512_cmpneq_epu32_mask');
  late final __mm512_cmpneq_epu32_mask =
      __mm512_cmpneq_epu32_maskPtr.asFunction<int Function(__m512i, __m512i)>();

  int _mm512_mask_cmpeq_epi32_mask(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cmpeq_epi32_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cmpeq_epi32_maskPtr = _lookup<
          ffi.NativeFunction<__mmask16 Function(__mmask16, __m512i, __m512i)>>(
      '_mm512_mask_cmpeq_epi32_mask');
  late final __mm512_mask_cmpeq_epi32_mask = __mm512_mask_cmpeq_epi32_maskPtr
      .asFunction<int Function(int, __m512i, __m512i)>();

  int _mm512_mask_cmpge_epi32_mask(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cmpge_epi32_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cmpge_epi32_maskPtr = _lookup<
          ffi.NativeFunction<__mmask16 Function(__mmask16, __m512i, __m512i)>>(
      '_mm512_mask_cmpge_epi32_mask');
  late final __mm512_mask_cmpge_epi32_mask = __mm512_mask_cmpge_epi32_maskPtr
      .asFunction<int Function(int, __m512i, __m512i)>();

  int _mm512_mask_cmpgt_epi32_mask(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cmpgt_epi32_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cmpgt_epi32_maskPtr = _lookup<
          ffi.NativeFunction<__mmask16 Function(__mmask16, __m512i, __m512i)>>(
      '_mm512_mask_cmpgt_epi32_mask');
  late final __mm512_mask_cmpgt_epi32_mask = __mm512_mask_cmpgt_epi32_maskPtr
      .asFunction<int Function(int, __m512i, __m512i)>();

  int _mm512_mask_cmple_epi32_mask(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cmple_epi32_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cmple_epi32_maskPtr = _lookup<
          ffi.NativeFunction<__mmask16 Function(__mmask16, __m512i, __m512i)>>(
      '_mm512_mask_cmple_epi32_mask');
  late final __mm512_mask_cmple_epi32_mask = __mm512_mask_cmple_epi32_maskPtr
      .asFunction<int Function(int, __m512i, __m512i)>();

  int _mm512_mask_cmplt_epi32_mask(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cmplt_epi32_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cmplt_epi32_maskPtr = _lookup<
          ffi.NativeFunction<__mmask16 Function(__mmask16, __m512i, __m512i)>>(
      '_mm512_mask_cmplt_epi32_mask');
  late final __mm512_mask_cmplt_epi32_mask = __mm512_mask_cmplt_epi32_maskPtr
      .asFunction<int Function(int, __m512i, __m512i)>();

  int _mm512_mask_cmpneq_epi32_mask(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cmpneq_epi32_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cmpneq_epi32_maskPtr = _lookup<
          ffi.NativeFunction<__mmask16 Function(__mmask16, __m512i, __m512i)>>(
      '_mm512_mask_cmpneq_epi32_mask');
  late final __mm512_mask_cmpneq_epi32_mask = __mm512_mask_cmpneq_epi32_maskPtr
      .asFunction<int Function(int, __m512i, __m512i)>();

  int _mm512_mask_cmpeq_epu32_mask(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cmpeq_epu32_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cmpeq_epu32_maskPtr = _lookup<
          ffi.NativeFunction<__mmask16 Function(__mmask16, __m512i, __m512i)>>(
      '_mm512_mask_cmpeq_epu32_mask');
  late final __mm512_mask_cmpeq_epu32_mask = __mm512_mask_cmpeq_epu32_maskPtr
      .asFunction<int Function(int, __m512i, __m512i)>();

  int _mm512_mask_cmpge_epu32_mask(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cmpge_epu32_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cmpge_epu32_maskPtr = _lookup<
          ffi.NativeFunction<__mmask16 Function(__mmask16, __m512i, __m512i)>>(
      '_mm512_mask_cmpge_epu32_mask');
  late final __mm512_mask_cmpge_epu32_mask = __mm512_mask_cmpge_epu32_maskPtr
      .asFunction<int Function(int, __m512i, __m512i)>();

  int _mm512_mask_cmpgt_epu32_mask(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cmpgt_epu32_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cmpgt_epu32_maskPtr = _lookup<
          ffi.NativeFunction<__mmask16 Function(__mmask16, __m512i, __m512i)>>(
      '_mm512_mask_cmpgt_epu32_mask');
  late final __mm512_mask_cmpgt_epu32_mask = __mm512_mask_cmpgt_epu32_maskPtr
      .asFunction<int Function(int, __m512i, __m512i)>();

  int _mm512_mask_cmple_epu32_mask(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cmple_epu32_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cmple_epu32_maskPtr = _lookup<
          ffi.NativeFunction<__mmask16 Function(__mmask16, __m512i, __m512i)>>(
      '_mm512_mask_cmple_epu32_mask');
  late final __mm512_mask_cmple_epu32_mask = __mm512_mask_cmple_epu32_maskPtr
      .asFunction<int Function(int, __m512i, __m512i)>();

  int _mm512_mask_cmplt_epu32_mask(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cmplt_epu32_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cmplt_epu32_maskPtr = _lookup<
          ffi.NativeFunction<__mmask16 Function(__mmask16, __m512i, __m512i)>>(
      '_mm512_mask_cmplt_epu32_mask');
  late final __mm512_mask_cmplt_epu32_mask = __mm512_mask_cmplt_epu32_maskPtr
      .asFunction<int Function(int, __m512i, __m512i)>();

  int _mm512_mask_cmpneq_epu32_mask(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cmpneq_epu32_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cmpneq_epu32_maskPtr = _lookup<
          ffi.NativeFunction<__mmask16 Function(__mmask16, __m512i, __m512i)>>(
      '_mm512_mask_cmpneq_epu32_mask');
  late final __mm512_mask_cmpneq_epu32_mask = __mm512_mask_cmpneq_epu32_maskPtr
      .asFunction<int Function(int, __m512i, __m512i)>();

  int _mm512_cmpeq_epi64_mask(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_cmpeq_epi64_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_cmpeq_epi64_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m512i, __m512i)>>(
          '_mm512_cmpeq_epi64_mask');
  late final __mm512_cmpeq_epi64_mask =
      __mm512_cmpeq_epi64_maskPtr.asFunction<int Function(__m512i, __m512i)>();

  int _mm512_cmpge_epi64_mask(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_cmpge_epi64_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_cmpge_epi64_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m512i, __m512i)>>(
          '_mm512_cmpge_epi64_mask');
  late final __mm512_cmpge_epi64_mask =
      __mm512_cmpge_epi64_maskPtr.asFunction<int Function(__m512i, __m512i)>();

  int _mm512_cmpgt_epi64_mask(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_cmpgt_epi64_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_cmpgt_epi64_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m512i, __m512i)>>(
          '_mm512_cmpgt_epi64_mask');
  late final __mm512_cmpgt_epi64_mask =
      __mm512_cmpgt_epi64_maskPtr.asFunction<int Function(__m512i, __m512i)>();

  int _mm512_cmple_epi64_mask(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_cmple_epi64_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_cmple_epi64_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m512i, __m512i)>>(
          '_mm512_cmple_epi64_mask');
  late final __mm512_cmple_epi64_mask =
      __mm512_cmple_epi64_maskPtr.asFunction<int Function(__m512i, __m512i)>();

  int _mm512_cmplt_epi64_mask(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_cmplt_epi64_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_cmplt_epi64_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m512i, __m512i)>>(
          '_mm512_cmplt_epi64_mask');
  late final __mm512_cmplt_epi64_mask =
      __mm512_cmplt_epi64_maskPtr.asFunction<int Function(__m512i, __m512i)>();

  int _mm512_cmpneq_epi64_mask(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_cmpneq_epi64_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_cmpneq_epi64_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m512i, __m512i)>>(
          '_mm512_cmpneq_epi64_mask');
  late final __mm512_cmpneq_epi64_mask =
      __mm512_cmpneq_epi64_maskPtr.asFunction<int Function(__m512i, __m512i)>();

  int _mm512_cmpeq_epu64_mask(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_cmpeq_epu64_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_cmpeq_epu64_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m512i, __m512i)>>(
          '_mm512_cmpeq_epu64_mask');
  late final __mm512_cmpeq_epu64_mask =
      __mm512_cmpeq_epu64_maskPtr.asFunction<int Function(__m512i, __m512i)>();

  int _mm512_cmpge_epu64_mask(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_cmpge_epu64_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_cmpge_epu64_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m512i, __m512i)>>(
          '_mm512_cmpge_epu64_mask');
  late final __mm512_cmpge_epu64_mask =
      __mm512_cmpge_epu64_maskPtr.asFunction<int Function(__m512i, __m512i)>();

  int _mm512_cmpgt_epu64_mask(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_cmpgt_epu64_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_cmpgt_epu64_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m512i, __m512i)>>(
          '_mm512_cmpgt_epu64_mask');
  late final __mm512_cmpgt_epu64_mask =
      __mm512_cmpgt_epu64_maskPtr.asFunction<int Function(__m512i, __m512i)>();

  int _mm512_cmple_epu64_mask(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_cmple_epu64_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_cmple_epu64_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m512i, __m512i)>>(
          '_mm512_cmple_epu64_mask');
  late final __mm512_cmple_epu64_mask =
      __mm512_cmple_epu64_maskPtr.asFunction<int Function(__m512i, __m512i)>();

  int _mm512_cmplt_epu64_mask(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_cmplt_epu64_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_cmplt_epu64_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m512i, __m512i)>>(
          '_mm512_cmplt_epu64_mask');
  late final __mm512_cmplt_epu64_mask =
      __mm512_cmplt_epu64_maskPtr.asFunction<int Function(__m512i, __m512i)>();

  int _mm512_cmpneq_epu64_mask(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_cmpneq_epu64_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_cmpneq_epu64_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m512i, __m512i)>>(
          '_mm512_cmpneq_epu64_mask');
  late final __mm512_cmpneq_epu64_mask =
      __mm512_cmpneq_epu64_maskPtr.asFunction<int Function(__m512i, __m512i)>();

  int _mm512_mask_cmpeq_epi64_mask(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cmpeq_epi64_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cmpeq_epi64_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m512i, __m512i)>>(
      '_mm512_mask_cmpeq_epi64_mask');
  late final __mm512_mask_cmpeq_epi64_mask = __mm512_mask_cmpeq_epi64_maskPtr
      .asFunction<int Function(int, __m512i, __m512i)>();

  int _mm512_mask_cmpge_epi64_mask(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cmpge_epi64_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cmpge_epi64_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m512i, __m512i)>>(
      '_mm512_mask_cmpge_epi64_mask');
  late final __mm512_mask_cmpge_epi64_mask = __mm512_mask_cmpge_epi64_maskPtr
      .asFunction<int Function(int, __m512i, __m512i)>();

  int _mm512_mask_cmpgt_epi64_mask(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cmpgt_epi64_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cmpgt_epi64_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m512i, __m512i)>>(
      '_mm512_mask_cmpgt_epi64_mask');
  late final __mm512_mask_cmpgt_epi64_mask = __mm512_mask_cmpgt_epi64_maskPtr
      .asFunction<int Function(int, __m512i, __m512i)>();

  int _mm512_mask_cmple_epi64_mask(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cmple_epi64_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cmple_epi64_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m512i, __m512i)>>(
      '_mm512_mask_cmple_epi64_mask');
  late final __mm512_mask_cmple_epi64_mask = __mm512_mask_cmple_epi64_maskPtr
      .asFunction<int Function(int, __m512i, __m512i)>();

  int _mm512_mask_cmplt_epi64_mask(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cmplt_epi64_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cmplt_epi64_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m512i, __m512i)>>(
      '_mm512_mask_cmplt_epi64_mask');
  late final __mm512_mask_cmplt_epi64_mask = __mm512_mask_cmplt_epi64_maskPtr
      .asFunction<int Function(int, __m512i, __m512i)>();

  int _mm512_mask_cmpneq_epi64_mask(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cmpneq_epi64_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cmpneq_epi64_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m512i, __m512i)>>(
      '_mm512_mask_cmpneq_epi64_mask');
  late final __mm512_mask_cmpneq_epi64_mask = __mm512_mask_cmpneq_epi64_maskPtr
      .asFunction<int Function(int, __m512i, __m512i)>();

  int _mm512_mask_cmpeq_epu64_mask(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cmpeq_epu64_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cmpeq_epu64_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m512i, __m512i)>>(
      '_mm512_mask_cmpeq_epu64_mask');
  late final __mm512_mask_cmpeq_epu64_mask = __mm512_mask_cmpeq_epu64_maskPtr
      .asFunction<int Function(int, __m512i, __m512i)>();

  int _mm512_mask_cmpge_epu64_mask(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cmpge_epu64_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cmpge_epu64_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m512i, __m512i)>>(
      '_mm512_mask_cmpge_epu64_mask');
  late final __mm512_mask_cmpge_epu64_mask = __mm512_mask_cmpge_epu64_maskPtr
      .asFunction<int Function(int, __m512i, __m512i)>();

  int _mm512_mask_cmpgt_epu64_mask(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cmpgt_epu64_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cmpgt_epu64_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m512i, __m512i)>>(
      '_mm512_mask_cmpgt_epu64_mask');
  late final __mm512_mask_cmpgt_epu64_mask = __mm512_mask_cmpgt_epu64_maskPtr
      .asFunction<int Function(int, __m512i, __m512i)>();

  int _mm512_mask_cmple_epu64_mask(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cmple_epu64_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cmple_epu64_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m512i, __m512i)>>(
      '_mm512_mask_cmple_epu64_mask');
  late final __mm512_mask_cmple_epu64_mask = __mm512_mask_cmple_epu64_maskPtr
      .asFunction<int Function(int, __m512i, __m512i)>();

  int _mm512_mask_cmplt_epu64_mask(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cmplt_epu64_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cmplt_epu64_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m512i, __m512i)>>(
      '_mm512_mask_cmplt_epu64_mask');
  late final __mm512_mask_cmplt_epu64_mask = __mm512_mask_cmplt_epu64_maskPtr
      .asFunction<int Function(int, __m512i, __m512i)>();

  int _mm512_mask_cmpneq_epu64_mask(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cmpneq_epu64_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cmpneq_epu64_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m512i, __m512i)>>(
      '_mm512_mask_cmpneq_epu64_mask');
  late final __mm512_mask_cmpneq_epu64_mask = __mm512_mask_cmpneq_epu64_maskPtr
      .asFunction<int Function(int, __m512i, __m512i)>();

  __m128i _mm_mask_abs_epi16(
    __m128i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_abs_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_abs_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m128i)>>(
          '_mm_mask_abs_epi16');
  late final __mm_mask_abs_epi16 = __mm_mask_abs_epi16Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i)>();

  __m128i _mm_maskz_abs_epi16(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_abs_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_abs_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i)>>(
          '_mm_maskz_abs_epi16');
  late final __mm_maskz_abs_epi16 =
      __mm_maskz_abs_epi16Ptr.asFunction<__m128i Function(int, __m128i)>();

  __m256i _mm256_mask_abs_epi16(
    __m256i arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_abs_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_abs_epi16Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__m256i, __mmask16, __m256i)>>(
      '_mm256_mask_abs_epi16');
  late final __mm256_mask_abs_epi16 = __mm256_mask_abs_epi16Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i)>();

  __m256i _mm256_maskz_abs_epi16(
    int arg0,
    __m256i arg1,
  ) {
    return __mm256_maskz_abs_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_abs_epi16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask16, __m256i)>>(
          '_mm256_maskz_abs_epi16');
  late final __mm256_maskz_abs_epi16 =
      __mm256_maskz_abs_epi16Ptr.asFunction<__m256i Function(int, __m256i)>();

  __m128i _mm_mask_abs_epi32(
    __m128i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_abs_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_abs_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m128i)>>(
          '_mm_mask_abs_epi32');
  late final __mm_mask_abs_epi32 = __mm_mask_abs_epi32Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i)>();

  __m128i _mm_maskz_abs_epi32(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_abs_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_abs_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i)>>(
          '_mm_maskz_abs_epi32');
  late final __mm_maskz_abs_epi32 =
      __mm_maskz_abs_epi32Ptr.asFunction<__m128i Function(int, __m128i)>();

  __m256i _mm256_mask_abs_epi32(
    __m256i arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_abs_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_abs_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __mmask8, __m256i)>>(
          '_mm256_mask_abs_epi32');
  late final __mm256_mask_abs_epi32 = __mm256_mask_abs_epi32Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i)>();

  __m256i _mm256_maskz_abs_epi32(
    int arg0,
    __m256i arg1,
  ) {
    return __mm256_maskz_abs_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_abs_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m256i)>>(
          '_mm256_maskz_abs_epi32');
  late final __mm256_maskz_abs_epi32 =
      __mm256_maskz_abs_epi32Ptr.asFunction<__m256i Function(int, __m256i)>();

  __m128i _mm_abs_epi64(
    __m128i arg0,
  ) {
    return __mm_abs_epi64(
      arg0,
    );
  }

  late final __mm_abs_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i)>>('_mm_abs_epi64');
  late final __mm_abs_epi64 =
      __mm_abs_epi64Ptr.asFunction<__m128i Function(__m128i)>();

  __m128i _mm_mask_abs_epi64(
    __m128i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_abs_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_abs_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m128i)>>(
          '_mm_mask_abs_epi64');
  late final __mm_mask_abs_epi64 = __mm_mask_abs_epi64Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i)>();

  __m128i _mm_maskz_abs_epi64(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_abs_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_abs_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i)>>(
          '_mm_maskz_abs_epi64');
  late final __mm_maskz_abs_epi64 =
      __mm_maskz_abs_epi64Ptr.asFunction<__m128i Function(int, __m128i)>();

  __m256i _mm256_abs_epi64(
    __m256i arg0,
  ) {
    return __mm256_abs_epi64(
      arg0,
    );
  }

  late final __mm256_abs_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i)>>(
          '_mm256_abs_epi64');
  late final __mm256_abs_epi64 =
      __mm256_abs_epi64Ptr.asFunction<__m256i Function(__m256i)>();

  __m256i _mm256_mask_abs_epi64(
    __m256i arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_abs_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_abs_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __mmask8, __m256i)>>(
          '_mm256_mask_abs_epi64');
  late final __mm256_mask_abs_epi64 = __mm256_mask_abs_epi64Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i)>();

  __m256i _mm256_maskz_abs_epi64(
    int arg0,
    __m256i arg1,
  ) {
    return __mm256_maskz_abs_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_abs_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m256i)>>(
          '_mm256_maskz_abs_epi64');
  late final __mm256_maskz_abs_epi64 =
      __mm256_maskz_abs_epi64Ptr.asFunction<__m256i Function(int, __m256i)>();

  __m128i _mm_mask_abs_epi8(
    __m128i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_abs_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_abs_epi8Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__m128i, __mmask16, __m128i)>>(
      '_mm_mask_abs_epi8');
  late final __mm_mask_abs_epi8 = __mm_mask_abs_epi8Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i)>();

  __m128i _mm_maskz_abs_epi8(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_abs_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_abs_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask16, __m128i)>>(
          '_mm_maskz_abs_epi8');
  late final __mm_maskz_abs_epi8 =
      __mm_maskz_abs_epi8Ptr.asFunction<__m128i Function(int, __m128i)>();

  __m256i _mm256_mask_abs_epi8(
    __m256i arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_abs_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_abs_epi8Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__m256i, __mmask32, __m256i)>>(
      '_mm256_mask_abs_epi8');
  late final __mm256_mask_abs_epi8 = __mm256_mask_abs_epi8Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i)>();

  __m256i _mm256_maskz_abs_epi8(
    int arg0,
    __m256i arg1,
  ) {
    return __mm256_maskz_abs_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_abs_epi8Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask32, __m256i)>>(
          '_mm256_maskz_abs_epi8');
  late final __mm256_maskz_abs_epi8 =
      __mm256_maskz_abs_epi8Ptr.asFunction<__m256i Function(int, __m256i)>();

  __m128i _mm_mask_add_epi16(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_add_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_add_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_add_epi16');
  late final __mm_mask_add_epi16 = __mm_mask_add_epi16Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_add_epi16(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_add_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_add_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_maskz_add_epi16');
  late final __mm_maskz_add_epi16 = __mm_maskz_add_epi16Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_mask_add_epi16(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_add_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_add_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask16, __m256i, __m256i)>>('_mm256_mask_add_epi16');
  late final __mm256_mask_add_epi16 = __mm256_mask_add_epi16Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_add_epi16(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_add_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_add_epi16Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__mmask16, __m256i, __m256i)>>(
      '_mm256_maskz_add_epi16');
  late final __mm256_maskz_add_epi16 = __mm256_maskz_add_epi16Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  __m128i _mm_mask_add_epi32(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_add_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_add_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_add_epi32');
  late final __mm_mask_add_epi32 = __mm_mask_add_epi32Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_add_epi32(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_add_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_add_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_maskz_add_epi32');
  late final __mm_maskz_add_epi32 = __mm_maskz_add_epi32Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_mask_add_epi32(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_add_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_add_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask8, __m256i, __m256i)>>('_mm256_mask_add_epi32');
  late final __mm256_mask_add_epi32 = __mm256_mask_add_epi32Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_add_epi32(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_add_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_add_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m256i, __m256i)>>(
          '_mm256_maskz_add_epi32');
  late final __mm256_maskz_add_epi32 = __mm256_maskz_add_epi32Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  __m128i _mm_mask_add_epi64(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_add_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_add_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_add_epi64');
  late final __mm_mask_add_epi64 = __mm_mask_add_epi64Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_add_epi64(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_add_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_add_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_maskz_add_epi64');
  late final __mm_maskz_add_epi64 = __mm_maskz_add_epi64Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_mask_add_epi64(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_add_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_add_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask8, __m256i, __m256i)>>('_mm256_mask_add_epi64');
  late final __mm256_mask_add_epi64 = __mm256_mask_add_epi64Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_add_epi64(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_add_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_add_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m256i, __m256i)>>(
          '_mm256_maskz_add_epi64');
  late final __mm256_maskz_add_epi64 = __mm256_maskz_add_epi64Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  __m128i _mm_mask_add_epi8(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_add_epi8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_add_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask16, __m128i, __m128i)>>('_mm_mask_add_epi8');
  late final __mm_mask_add_epi8 = __mm_mask_add_epi8Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_add_epi8(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_add_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_add_epi8Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__mmask16, __m128i, __m128i)>>(
      '_mm_maskz_add_epi8');
  late final __mm_maskz_add_epi8 = __mm_maskz_add_epi8Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_mask_add_epi8(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_add_epi8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_add_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask32, __m256i, __m256i)>>('_mm256_mask_add_epi8');
  late final __mm256_mask_add_epi8 = __mm256_mask_add_epi8Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_add_epi8(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_add_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_add_epi8Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__mmask32, __m256i, __m256i)>>(
      '_mm256_maskz_add_epi8');
  late final __mm256_maskz_add_epi8 = __mm256_maskz_add_epi8Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  _m128d _mm_mask_add_pd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    _m128d arg3,
  ) {
    return __mm_mask_add_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_add_pdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              _m128d, __mmask8, _m128d, _m128d)>>('_mm_mask_add_pd');
  late final __mm_mask_add_pd = __mm_mask_add_pdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d, _m128d)>();

  _m128d _mm_maskz_add_pd(
    int arg0,
    _m128d arg1,
    _m128d arg2,
  ) {
    return __mm_maskz_add_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_add_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(__mmask8, _m128d, _m128d)>>(
          '_mm_maskz_add_pd');
  late final __mm_maskz_add_pd =
      __mm_maskz_add_pdPtr.asFunction<_m128d Function(int, _m128d, _m128d)>();

  _m256d _mm256_mask_add_pd(
    _m256d arg0,
    int arg1,
    _m256d arg2,
    _m256d arg3,
  ) {
    return __mm256_mask_add_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_add_pdPtr = _lookup<
      ffi.NativeFunction<
          _m256d Function(
              _m256d, __mmask8, _m256d, _m256d)>>('_mm256_mask_add_pd');
  late final __mm256_mask_add_pd = __mm256_mask_add_pdPtr
      .asFunction<_m256d Function(_m256d, int, _m256d, _m256d)>();

  _m256d _mm256_maskz_add_pd(
    int arg0,
    _m256d arg1,
    _m256d arg2,
  ) {
    return __mm256_maskz_add_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_add_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(__mmask8, _m256d, _m256d)>>(
          '_mm256_maskz_add_pd');
  late final __mm256_maskz_add_pd = __mm256_maskz_add_pdPtr
      .asFunction<_m256d Function(int, _m256d, _m256d)>();

  __m128 _mm_mask_add_ps(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    __m128 arg3,
  ) {
    return __mm_mask_add_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_add_psPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __m128, __mmask8, __m128, __m128)>>('_mm_mask_add_ps');
  late final __mm_mask_add_ps = __mm_mask_add_psPtr
      .asFunction<__m128 Function(__m128, int, __m128, __m128)>();

  __m128 _mm_maskz_add_ps(
    int arg0,
    __m128 arg1,
    __m128 arg2,
  ) {
    return __mm_maskz_add_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_add_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__mmask8, __m128, __m128)>>(
          '_mm_maskz_add_ps');
  late final __mm_maskz_add_ps =
      __mm_maskz_add_psPtr.asFunction<__m128 Function(int, __m128, __m128)>();

  __m256 _mm256_mask_add_ps(
    __m256 arg0,
    int arg1,
    __m256 arg2,
    __m256 arg3,
  ) {
    return __mm256_mask_add_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_add_psPtr = _lookup<
      ffi.NativeFunction<
          __m256 Function(
              __m256, __mmask8, __m256, __m256)>>('_mm256_mask_add_ps');
  late final __mm256_mask_add_ps = __mm256_mask_add_psPtr
      .asFunction<__m256 Function(__m256, int, __m256, __m256)>();

  __m256 _mm256_maskz_add_ps(
    int arg0,
    __m256 arg1,
    __m256 arg2,
  ) {
    return __mm256_maskz_add_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_add_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__mmask8, __m256, __m256)>>(
          '_mm256_maskz_add_ps');
  late final __mm256_maskz_add_ps = __mm256_maskz_add_psPtr
      .asFunction<__m256 Function(int, __m256, __m256)>();

  __m128i _mm_mask_adds_epi16(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_adds_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_adds_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_adds_epi16');
  late final __mm_mask_adds_epi16 = __mm_mask_adds_epi16Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_adds_epi16(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_adds_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_adds_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_maskz_adds_epi16');
  late final __mm_maskz_adds_epi16 = __mm_maskz_adds_epi16Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_mask_adds_epi16(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_adds_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_adds_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask16, __m256i, __m256i)>>('_mm256_mask_adds_epi16');
  late final __mm256_mask_adds_epi16 = __mm256_mask_adds_epi16Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_adds_epi16(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_adds_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_adds_epi16Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__mmask16, __m256i, __m256i)>>(
      '_mm256_maskz_adds_epi16');
  late final __mm256_maskz_adds_epi16 = __mm256_maskz_adds_epi16Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  __m128i _mm_mask_adds_epi8(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_adds_epi8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_adds_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask16, __m128i, __m128i)>>('_mm_mask_adds_epi8');
  late final __mm_mask_adds_epi8 = __mm_mask_adds_epi8Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_adds_epi8(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_adds_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_adds_epi8Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__mmask16, __m128i, __m128i)>>(
      '_mm_maskz_adds_epi8');
  late final __mm_maskz_adds_epi8 = __mm_maskz_adds_epi8Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_mask_adds_epi8(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_adds_epi8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_adds_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask32, __m256i, __m256i)>>('_mm256_mask_adds_epi8');
  late final __mm256_mask_adds_epi8 = __mm256_mask_adds_epi8Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_adds_epi8(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_adds_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_adds_epi8Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__mmask32, __m256i, __m256i)>>(
      '_mm256_maskz_adds_epi8');
  late final __mm256_maskz_adds_epi8 = __mm256_maskz_adds_epi8Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  __m128i _mm_mask_adds_epu16(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_adds_epu16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_adds_epu16Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_adds_epu16');
  late final __mm_mask_adds_epu16 = __mm_mask_adds_epu16Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_adds_epu16(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_adds_epu16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_adds_epu16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_maskz_adds_epu16');
  late final __mm_maskz_adds_epu16 = __mm_maskz_adds_epu16Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_mask_adds_epu16(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_adds_epu16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_adds_epu16Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask16, __m256i, __m256i)>>('_mm256_mask_adds_epu16');
  late final __mm256_mask_adds_epu16 = __mm256_mask_adds_epu16Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_adds_epu16(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_adds_epu16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_adds_epu16Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__mmask16, __m256i, __m256i)>>(
      '_mm256_maskz_adds_epu16');
  late final __mm256_maskz_adds_epu16 = __mm256_maskz_adds_epu16Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  __m128i _mm_mask_adds_epu8(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_adds_epu8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_adds_epu8Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask16, __m128i, __m128i)>>('_mm_mask_adds_epu8');
  late final __mm_mask_adds_epu8 = __mm_mask_adds_epu8Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_adds_epu8(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_adds_epu8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_adds_epu8Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__mmask16, __m128i, __m128i)>>(
      '_mm_maskz_adds_epu8');
  late final __mm_maskz_adds_epu8 = __mm_maskz_adds_epu8Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_mask_adds_epu8(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_adds_epu8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_adds_epu8Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask32, __m256i, __m256i)>>('_mm256_mask_adds_epu8');
  late final __mm256_mask_adds_epu8 = __mm256_mask_adds_epu8Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_adds_epu8(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_adds_epu8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_adds_epu8Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__mmask32, __m256i, __m256i)>>(
      '_mm256_maskz_adds_epu8');
  late final __mm256_maskz_adds_epu8 = __mm256_maskz_adds_epu8Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  __m128i _mm_alignr_epi32(
    __m128i arg0,
    __m128i arg1,
    int arg2,
  ) {
    return __mm_alignr_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_alignr_epi32Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__m128i, __m128i, ffi.Int32)>>(
      '_mm_alignr_epi32');
  late final __mm_alignr_epi32 = __mm_alignr_epi32Ptr
      .asFunction<__m128i Function(__m128i, __m128i, int)>();

  __m128i _mm_mask_alignr_epi32(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
    int arg4,
  ) {
    return __mm_mask_alignr_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_alignr_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(__m128i, __mmask8, __m128i, __m128i,
              ffi.Int32)>>('_mm_mask_alignr_epi32');
  late final __mm_mask_alignr_epi32 = __mm_mask_alignr_epi32Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i, int)>();

  __m128i _mm_maskz_alignr_epi32(
    int arg0,
    __m128i arg1,
    __m128i arg2,
    int arg3,
  ) {
    return __mm_maskz_alignr_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_alignr_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(__mmask8, __m128i, __m128i,
              ffi.Int32)>>('_mm_maskz_alignr_epi32');
  late final __mm_maskz_alignr_epi32 = __mm_maskz_alignr_epi32Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i, int)>();

  __m256i _mm256_alignr_epi32(
    __m256i arg0,
    __m256i arg1,
    int arg2,
  ) {
    return __mm256_alignr_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_alignr_epi32Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__m256i, __m256i, ffi.Int32)>>(
      '_mm256_alignr_epi32');
  late final __mm256_alignr_epi32 = __mm256_alignr_epi32Ptr
      .asFunction<__m256i Function(__m256i, __m256i, int)>();

  __m256i _mm256_mask_alignr_epi32(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
    int arg4,
  ) {
    return __mm256_mask_alignr_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm256_mask_alignr_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask8, __m256i, __m256i,
              ffi.Int32)>>('_mm256_mask_alignr_epi32');
  late final __mm256_mask_alignr_epi32 = __mm256_mask_alignr_epi32Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i, int)>();

  __m256i _mm256_maskz_alignr_epi32(
    int arg0,
    __m256i arg1,
    __m256i arg2,
    int arg3,
  ) {
    return __mm256_maskz_alignr_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_maskz_alignr_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__mmask8, __m256i, __m256i,
              ffi.Int32)>>('_mm256_maskz_alignr_epi32');
  late final __mm256_maskz_alignr_epi32 = __mm256_maskz_alignr_epi32Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i, int)>();

  __m128i _mm_alignr_epi64(
    __m128i arg0,
    __m128i arg1,
    int arg2,
  ) {
    return __mm_alignr_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_alignr_epi64Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__m128i, __m128i, ffi.Int32)>>(
      '_mm_alignr_epi64');
  late final __mm_alignr_epi64 = __mm_alignr_epi64Ptr
      .asFunction<__m128i Function(__m128i, __m128i, int)>();

  __m128i _mm_mask_alignr_epi64(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
    int arg4,
  ) {
    return __mm_mask_alignr_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_alignr_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(__m128i, __mmask8, __m128i, __m128i,
              ffi.Int32)>>('_mm_mask_alignr_epi64');
  late final __mm_mask_alignr_epi64 = __mm_mask_alignr_epi64Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i, int)>();

  __m128i _mm_maskz_alignr_epi64(
    int arg0,
    __m128i arg1,
    __m128i arg2,
    int arg3,
  ) {
    return __mm_maskz_alignr_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_alignr_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(__mmask8, __m128i, __m128i,
              ffi.Int32)>>('_mm_maskz_alignr_epi64');
  late final __mm_maskz_alignr_epi64 = __mm_maskz_alignr_epi64Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i, int)>();

  __m256i _mm256_alignr_epi64(
    __m256i arg0,
    __m256i arg1,
    int arg2,
  ) {
    return __mm256_alignr_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_alignr_epi64Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__m256i, __m256i, ffi.Int32)>>(
      '_mm256_alignr_epi64');
  late final __mm256_alignr_epi64 = __mm256_alignr_epi64Ptr
      .asFunction<__m256i Function(__m256i, __m256i, int)>();

  __m256i _mm256_mask_alignr_epi64(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
    int arg4,
  ) {
    return __mm256_mask_alignr_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm256_mask_alignr_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask8, __m256i, __m256i,
              ffi.Int32)>>('_mm256_mask_alignr_epi64');
  late final __mm256_mask_alignr_epi64 = __mm256_mask_alignr_epi64Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i, int)>();

  __m256i _mm256_maskz_alignr_epi64(
    int arg0,
    __m256i arg1,
    __m256i arg2,
    int arg3,
  ) {
    return __mm256_maskz_alignr_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_maskz_alignr_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__mmask8, __m256i, __m256i,
              ffi.Int32)>>('_mm256_maskz_alignr_epi64');
  late final __mm256_maskz_alignr_epi64 = __mm256_maskz_alignr_epi64Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i, int)>();

  __m128i _mm_mask_alignr_epi8(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
    int arg4,
  ) {
    return __mm_mask_alignr_epi8(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_alignr_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(__m128i, __mmask16, __m128i, __m128i,
              ffi.Int32)>>('_mm_mask_alignr_epi8');
  late final __mm_mask_alignr_epi8 = __mm_mask_alignr_epi8Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i, int)>();

  __m128i _mm_maskz_alignr_epi8(
    int arg0,
    __m128i arg1,
    __m128i arg2,
    int arg3,
  ) {
    return __mm_maskz_alignr_epi8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_alignr_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(__mmask16, __m128i, __m128i,
              ffi.Int32)>>('_mm_maskz_alignr_epi8');
  late final __mm_maskz_alignr_epi8 = __mm_maskz_alignr_epi8Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i, int)>();

  __m256i _mm256_mask_alignr_epi8(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
    int arg4,
  ) {
    return __mm256_mask_alignr_epi8(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm256_mask_alignr_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask32, __m256i, __m256i,
              ffi.Int32)>>('_mm256_mask_alignr_epi8');
  late final __mm256_mask_alignr_epi8 = __mm256_mask_alignr_epi8Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i, int)>();

  __m256i _mm256_maskz_alignr_epi8(
    int arg0,
    __m256i arg1,
    __m256i arg2,
    int arg3,
  ) {
    return __mm256_maskz_alignr_epi8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_maskz_alignr_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__mmask32, __m256i, __m256i,
              ffi.Int32)>>('_mm256_maskz_alignr_epi8');
  late final __mm256_maskz_alignr_epi8 = __mm256_maskz_alignr_epi8Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i, int)>();

  __m128i _mm_and_epi32(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_and_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm_and_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_and_epi32');
  late final __mm_and_epi32 =
      __mm_and_epi32Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_mask_and_epi32(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_and_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_and_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_and_epi32');
  late final __mm_mask_and_epi32 = __mm_mask_and_epi32Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_and_epi32(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_and_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_and_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_maskz_and_epi32');
  late final __mm_maskz_and_epi32 = __mm_maskz_and_epi32Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_and_epi32(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_and_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm256_and_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_and_epi32');
  late final __mm256_and_epi32 =
      __mm256_and_epi32Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_mask_and_epi32(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_and_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_and_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask8, __m256i, __m256i)>>('_mm256_mask_and_epi32');
  late final __mm256_mask_and_epi32 = __mm256_mask_and_epi32Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_and_epi32(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_and_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_and_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m256i, __m256i)>>(
          '_mm256_maskz_and_epi32');
  late final __mm256_maskz_and_epi32 = __mm256_maskz_and_epi32Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  __m128i _mm_and_epi64(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_and_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm_and_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_and_epi64');
  late final __mm_and_epi64 =
      __mm_and_epi64Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_mask_and_epi64(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_and_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_and_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_and_epi64');
  late final __mm_mask_and_epi64 = __mm_mask_and_epi64Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_and_epi64(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_and_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_and_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_maskz_and_epi64');
  late final __mm_maskz_and_epi64 = __mm_maskz_and_epi64Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_and_epi64(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_and_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm256_and_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_and_epi64');
  late final __mm256_and_epi64 =
      __mm256_and_epi64Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_mask_and_epi64(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_and_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_and_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask8, __m256i, __m256i)>>('_mm256_mask_and_epi64');
  late final __mm256_mask_and_epi64 = __mm256_mask_and_epi64Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_and_epi64(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_and_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_and_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m256i, __m256i)>>(
          '_mm256_maskz_and_epi64');
  late final __mm256_maskz_and_epi64 = __mm256_maskz_and_epi64Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  _m128d _mm_mask_and_pd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    _m128d arg3,
  ) {
    return __mm_mask_and_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_and_pdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              _m128d, __mmask8, _m128d, _m128d)>>('_mm_mask_and_pd');
  late final __mm_mask_and_pd = __mm_mask_and_pdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d, _m128d)>();

  _m128d _mm_maskz_and_pd(
    int arg0,
    _m128d arg1,
    _m128d arg2,
  ) {
    return __mm_maskz_and_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_and_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(__mmask8, _m128d, _m128d)>>(
          '_mm_maskz_and_pd');
  late final __mm_maskz_and_pd =
      __mm_maskz_and_pdPtr.asFunction<_m128d Function(int, _m128d, _m128d)>();

  _m256d _mm256_mask_and_pd(
    _m256d arg0,
    int arg1,
    _m256d arg2,
    _m256d arg3,
  ) {
    return __mm256_mask_and_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_and_pdPtr = _lookup<
      ffi.NativeFunction<
          _m256d Function(
              _m256d, __mmask8, _m256d, _m256d)>>('_mm256_mask_and_pd');
  late final __mm256_mask_and_pd = __mm256_mask_and_pdPtr
      .asFunction<_m256d Function(_m256d, int, _m256d, _m256d)>();

  _m256d _mm256_maskz_and_pd(
    int arg0,
    _m256d arg1,
    _m256d arg2,
  ) {
    return __mm256_maskz_and_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_and_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(__mmask8, _m256d, _m256d)>>(
          '_mm256_maskz_and_pd');
  late final __mm256_maskz_and_pd = __mm256_maskz_and_pdPtr
      .asFunction<_m256d Function(int, _m256d, _m256d)>();

  __m128 _mm_mask_and_ps(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    __m128 arg3,
  ) {
    return __mm_mask_and_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_and_psPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __m128, __mmask8, __m128, __m128)>>('_mm_mask_and_ps');
  late final __mm_mask_and_ps = __mm_mask_and_psPtr
      .asFunction<__m128 Function(__m128, int, __m128, __m128)>();

  __m128 _mm_maskz_and_ps(
    int arg0,
    __m128 arg1,
    __m128 arg2,
  ) {
    return __mm_maskz_and_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_and_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__mmask8, __m128, __m128)>>(
          '_mm_maskz_and_ps');
  late final __mm_maskz_and_ps =
      __mm_maskz_and_psPtr.asFunction<__m128 Function(int, __m128, __m128)>();

  __m256 _mm256_mask_and_ps(
    __m256 arg0,
    int arg1,
    __m256 arg2,
    __m256 arg3,
  ) {
    return __mm256_mask_and_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_and_psPtr = _lookup<
      ffi.NativeFunction<
          __m256 Function(
              __m256, __mmask8, __m256, __m256)>>('_mm256_mask_and_ps');
  late final __mm256_mask_and_ps = __mm256_mask_and_psPtr
      .asFunction<__m256 Function(__m256, int, __m256, __m256)>();

  __m256 _mm256_maskz_and_ps(
    int arg0,
    __m256 arg1,
    __m256 arg2,
  ) {
    return __mm256_maskz_and_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_and_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__mmask8, __m256, __m256)>>(
          '_mm256_maskz_and_ps');
  late final __mm256_maskz_and_ps = __mm256_maskz_and_psPtr
      .asFunction<__m256 Function(int, __m256, __m256)>();

  __m128i _mm_andnot_epi32(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_andnot_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm_andnot_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_andnot_epi32');
  late final __mm_andnot_epi32 =
      __mm_andnot_epi32Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_mask_andnot_epi32(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_andnot_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_andnot_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_andnot_epi32');
  late final __mm_mask_andnot_epi32 = __mm_mask_andnot_epi32Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_andnot_epi32(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_andnot_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_andnot_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_maskz_andnot_epi32');
  late final __mm_maskz_andnot_epi32 = __mm_maskz_andnot_epi32Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_andnot_epi32(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_andnot_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm256_andnot_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_andnot_epi32');
  late final __mm256_andnot_epi32 =
      __mm256_andnot_epi32Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_mask_andnot_epi32(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_andnot_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_andnot_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask8, __m256i,
              __m256i)>>('_mm256_mask_andnot_epi32');
  late final __mm256_mask_andnot_epi32 = __mm256_mask_andnot_epi32Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_andnot_epi32(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_andnot_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_andnot_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m256i, __m256i)>>(
          '_mm256_maskz_andnot_epi32');
  late final __mm256_maskz_andnot_epi32 = __mm256_maskz_andnot_epi32Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  __m128i _mm_andnot_epi64(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_andnot_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm_andnot_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_andnot_epi64');
  late final __mm_andnot_epi64 =
      __mm_andnot_epi64Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_mask_andnot_epi64(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_andnot_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_andnot_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_andnot_epi64');
  late final __mm_mask_andnot_epi64 = __mm_mask_andnot_epi64Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_andnot_epi64(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_andnot_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_andnot_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_maskz_andnot_epi64');
  late final __mm_maskz_andnot_epi64 = __mm_maskz_andnot_epi64Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_andnot_epi64(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_andnot_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm256_andnot_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_andnot_epi64');
  late final __mm256_andnot_epi64 =
      __mm256_andnot_epi64Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_mask_andnot_epi64(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_andnot_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_andnot_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask8, __m256i,
              __m256i)>>('_mm256_mask_andnot_epi64');
  late final __mm256_mask_andnot_epi64 = __mm256_mask_andnot_epi64Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_andnot_epi64(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_andnot_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_andnot_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m256i, __m256i)>>(
          '_mm256_maskz_andnot_epi64');
  late final __mm256_maskz_andnot_epi64 = __mm256_maskz_andnot_epi64Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  _m128d _mm_mask_andnot_pd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    _m128d arg3,
  ) {
    return __mm_mask_andnot_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_andnot_pdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              _m128d, __mmask8, _m128d, _m128d)>>('_mm_mask_andnot_pd');
  late final __mm_mask_andnot_pd = __mm_mask_andnot_pdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d, _m128d)>();

  _m128d _mm_maskz_andnot_pd(
    int arg0,
    _m128d arg1,
    _m128d arg2,
  ) {
    return __mm_maskz_andnot_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_andnot_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(__mmask8, _m128d, _m128d)>>(
          '_mm_maskz_andnot_pd');
  late final __mm_maskz_andnot_pd = __mm_maskz_andnot_pdPtr
      .asFunction<_m128d Function(int, _m128d, _m128d)>();

  _m256d _mm256_mask_andnot_pd(
    _m256d arg0,
    int arg1,
    _m256d arg2,
    _m256d arg3,
  ) {
    return __mm256_mask_andnot_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_andnot_pdPtr = _lookup<
      ffi.NativeFunction<
          _m256d Function(
              _m256d, __mmask8, _m256d, _m256d)>>('_mm256_mask_andnot_pd');
  late final __mm256_mask_andnot_pd = __mm256_mask_andnot_pdPtr
      .asFunction<_m256d Function(_m256d, int, _m256d, _m256d)>();

  _m256d _mm256_maskz_andnot_pd(
    int arg0,
    _m256d arg1,
    _m256d arg2,
  ) {
    return __mm256_maskz_andnot_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_andnot_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(__mmask8, _m256d, _m256d)>>(
          '_mm256_maskz_andnot_pd');
  late final __mm256_maskz_andnot_pd = __mm256_maskz_andnot_pdPtr
      .asFunction<_m256d Function(int, _m256d, _m256d)>();

  __m128 _mm_mask_andnot_ps(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    __m128 arg3,
  ) {
    return __mm_mask_andnot_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_andnot_psPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __m128, __mmask8, __m128, __m128)>>('_mm_mask_andnot_ps');
  late final __mm_mask_andnot_ps = __mm_mask_andnot_psPtr
      .asFunction<__m128 Function(__m128, int, __m128, __m128)>();

  __m128 _mm_maskz_andnot_ps(
    int arg0,
    __m128 arg1,
    __m128 arg2,
  ) {
    return __mm_maskz_andnot_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_andnot_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__mmask8, __m128, __m128)>>(
          '_mm_maskz_andnot_ps');
  late final __mm_maskz_andnot_ps = __mm_maskz_andnot_psPtr
      .asFunction<__m128 Function(int, __m128, __m128)>();

  __m256 _mm256_mask_andnot_ps(
    __m256 arg0,
    int arg1,
    __m256 arg2,
    __m256 arg3,
  ) {
    return __mm256_mask_andnot_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_andnot_psPtr = _lookup<
      ffi.NativeFunction<
          __m256 Function(
              __m256, __mmask8, __m256, __m256)>>('_mm256_mask_andnot_ps');
  late final __mm256_mask_andnot_ps = __mm256_mask_andnot_psPtr
      .asFunction<__m256 Function(__m256, int, __m256, __m256)>();

  __m256 _mm256_maskz_andnot_ps(
    int arg0,
    __m256 arg1,
    __m256 arg2,
  ) {
    return __mm256_maskz_andnot_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_andnot_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__mmask8, __m256, __m256)>>(
          '_mm256_maskz_andnot_ps');
  late final __mm256_maskz_andnot_ps = __mm256_maskz_andnot_psPtr
      .asFunction<__m256 Function(int, __m256, __m256)>();

  __m128i _mm_mask_avg_epu16(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_avg_epu16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_avg_epu16Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_avg_epu16');
  late final __mm_mask_avg_epu16 = __mm_mask_avg_epu16Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_avg_epu16(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_avg_epu16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_avg_epu16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_maskz_avg_epu16');
  late final __mm_maskz_avg_epu16 = __mm_maskz_avg_epu16Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_mask_avg_epu16(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_avg_epu16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_avg_epu16Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask16, __m256i, __m256i)>>('_mm256_mask_avg_epu16');
  late final __mm256_mask_avg_epu16 = __mm256_mask_avg_epu16Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_avg_epu16(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_avg_epu16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_avg_epu16Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__mmask16, __m256i, __m256i)>>(
      '_mm256_maskz_avg_epu16');
  late final __mm256_maskz_avg_epu16 = __mm256_maskz_avg_epu16Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  __m128i _mm_mask_avg_epu8(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_avg_epu8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_avg_epu8Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask16, __m128i, __m128i)>>('_mm_mask_avg_epu8');
  late final __mm_mask_avg_epu8 = __mm_mask_avg_epu8Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_avg_epu8(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_avg_epu8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_avg_epu8Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__mmask16, __m128i, __m128i)>>(
      '_mm_maskz_avg_epu8');
  late final __mm_maskz_avg_epu8 = __mm_maskz_avg_epu8Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_mask_avg_epu8(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_avg_epu8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_avg_epu8Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask32, __m256i, __m256i)>>('_mm256_mask_avg_epu8');
  late final __mm256_mask_avg_epu8 = __mm256_mask_avg_epu8Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_avg_epu8(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_avg_epu8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_avg_epu8Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__mmask32, __m256i, __m256i)>>(
      '_mm256_maskz_avg_epu8');
  late final __mm256_maskz_avg_epu8 = __mm256_maskz_avg_epu8Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  __m128i _mm_mask_blend_epi16(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_mask_blend_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_blend_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_mask_blend_epi16');
  late final __mm_mask_blend_epi16 = __mm_mask_blend_epi16Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_mask_blend_epi16(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_blend_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_blend_epi16Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__mmask16, __m256i, __m256i)>>(
      '_mm256_mask_blend_epi16');
  late final __mm256_mask_blend_epi16 = __mm256_mask_blend_epi16Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  __m128i _mm_mask_blend_epi32(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_mask_blend_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_blend_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_mask_blend_epi32');
  late final __mm_mask_blend_epi32 = __mm_mask_blend_epi32Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_mask_blend_epi32(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_blend_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_blend_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m256i, __m256i)>>(
          '_mm256_mask_blend_epi32');
  late final __mm256_mask_blend_epi32 = __mm256_mask_blend_epi32Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  __m128i _mm_mask_blend_epi64(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_mask_blend_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_blend_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_mask_blend_epi64');
  late final __mm_mask_blend_epi64 = __mm_mask_blend_epi64Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_mask_blend_epi64(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_blend_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_blend_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m256i, __m256i)>>(
          '_mm256_mask_blend_epi64');
  late final __mm256_mask_blend_epi64 = __mm256_mask_blend_epi64Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  __m128i _mm_mask_blend_epi8(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_mask_blend_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_blend_epi8Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__mmask16, __m128i, __m128i)>>(
      '_mm_mask_blend_epi8');
  late final __mm_mask_blend_epi8 = __mm_mask_blend_epi8Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_mask_blend_epi8(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_blend_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_blend_epi8Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__mmask32, __m256i, __m256i)>>(
      '_mm256_mask_blend_epi8');
  late final __mm256_mask_blend_epi8 = __mm256_mask_blend_epi8Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  _m128d _mm_mask_blend_pd(
    int arg0,
    _m128d arg1,
    _m128d arg2,
  ) {
    return __mm_mask_blend_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_blend_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(__mmask8, _m128d, _m128d)>>(
          '_mm_mask_blend_pd');
  late final __mm_mask_blend_pd =
      __mm_mask_blend_pdPtr.asFunction<_m128d Function(int, _m128d, _m128d)>();

  _m256d _mm256_mask_blend_pd(
    int arg0,
    _m256d arg1,
    _m256d arg2,
  ) {
    return __mm256_mask_blend_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_blend_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(__mmask8, _m256d, _m256d)>>(
          '_mm256_mask_blend_pd');
  late final __mm256_mask_blend_pd = __mm256_mask_blend_pdPtr
      .asFunction<_m256d Function(int, _m256d, _m256d)>();

  __m128 _mm_mask_blend_ps(
    int arg0,
    __m128 arg1,
    __m128 arg2,
  ) {
    return __mm_mask_blend_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_blend_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__mmask8, __m128, __m128)>>(
          '_mm_mask_blend_ps');
  late final __mm_mask_blend_ps =
      __mm_mask_blend_psPtr.asFunction<__m128 Function(int, __m128, __m128)>();

  __m256 _mm256_mask_blend_ps(
    int arg0,
    __m256 arg1,
    __m256 arg2,
  ) {
    return __mm256_mask_blend_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_blend_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__mmask8, __m256, __m256)>>(
          '_mm256_mask_blend_ps');
  late final __mm256_mask_blend_ps = __mm256_mask_blend_psPtr
      .asFunction<__m256 Function(int, __m256, __m256)>();

  __m256 _mm256_broadcast_f32x2(
    __m128 arg0,
  ) {
    return __mm256_broadcast_f32x2(
      arg0,
    );
  }

  late final __mm256_broadcast_f32x2Ptr =
      _lookup<ffi.NativeFunction<__m256 Function(__m128)>>(
          '_mm256_broadcast_f32x2');
  late final __mm256_broadcast_f32x2 =
      __mm256_broadcast_f32x2Ptr.asFunction<__m256 Function(__m128)>();

  __m256 _mm256_mask_broadcast_f32x2(
    __m256 arg0,
    int arg1,
    __m128 arg2,
  ) {
    return __mm256_mask_broadcast_f32x2(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_broadcast_f32x2Ptr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256, __mmask8, __m128)>>(
          '_mm256_mask_broadcast_f32x2');
  late final __mm256_mask_broadcast_f32x2 = __mm256_mask_broadcast_f32x2Ptr
      .asFunction<__m256 Function(__m256, int, __m128)>();

  __m256 _mm256_maskz_broadcast_f32x2(
    int arg0,
    __m128 arg1,
  ) {
    return __mm256_maskz_broadcast_f32x2(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_broadcast_f32x2Ptr =
      _lookup<ffi.NativeFunction<__m256 Function(__mmask8, __m128)>>(
          '_mm256_maskz_broadcast_f32x2');
  late final __mm256_maskz_broadcast_f32x2 = __mm256_maskz_broadcast_f32x2Ptr
      .asFunction<__m256 Function(int, __m128)>();

  __m256 _mm256_broadcast_f32x4(
    __m128 arg0,
  ) {
    return __mm256_broadcast_f32x4(
      arg0,
    );
  }

  late final __mm256_broadcast_f32x4Ptr =
      _lookup<ffi.NativeFunction<__m256 Function(__m128)>>(
          '_mm256_broadcast_f32x4');
  late final __mm256_broadcast_f32x4 =
      __mm256_broadcast_f32x4Ptr.asFunction<__m256 Function(__m128)>();

  __m256 _mm256_mask_broadcast_f32x4(
    __m256 arg0,
    int arg1,
    __m128 arg2,
  ) {
    return __mm256_mask_broadcast_f32x4(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_broadcast_f32x4Ptr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256, __mmask8, __m128)>>(
          '_mm256_mask_broadcast_f32x4');
  late final __mm256_mask_broadcast_f32x4 = __mm256_mask_broadcast_f32x4Ptr
      .asFunction<__m256 Function(__m256, int, __m128)>();

  __m256 _mm256_maskz_broadcast_f32x4(
    int arg0,
    __m128 arg1,
  ) {
    return __mm256_maskz_broadcast_f32x4(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_broadcast_f32x4Ptr =
      _lookup<ffi.NativeFunction<__m256 Function(__mmask8, __m128)>>(
          '_mm256_maskz_broadcast_f32x4');
  late final __mm256_maskz_broadcast_f32x4 = __mm256_maskz_broadcast_f32x4Ptr
      .asFunction<__m256 Function(int, __m128)>();

  _m256d _mm256_broadcast_f64x2(
    _m128d arg0,
  ) {
    return __mm256_broadcast_f64x2(
      arg0,
    );
  }

  late final __mm256_broadcast_f64x2Ptr =
      _lookup<ffi.NativeFunction<_m256d Function(_m128d)>>(
          '_mm256_broadcast_f64x2');
  late final __mm256_broadcast_f64x2 =
      __mm256_broadcast_f64x2Ptr.asFunction<_m256d Function(_m128d)>();

  _m256d _mm256_mask_broadcast_f64x2(
    _m256d arg0,
    int arg1,
    _m128d arg2,
  ) {
    return __mm256_mask_broadcast_f64x2(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_broadcast_f64x2Ptr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d, __mmask8, _m128d)>>(
          '_mm256_mask_broadcast_f64x2');
  late final __mm256_mask_broadcast_f64x2 = __mm256_mask_broadcast_f64x2Ptr
      .asFunction<_m256d Function(_m256d, int, _m128d)>();

  _m256d _mm256_maskz_broadcast_f64x2(
    int arg0,
    _m128d arg1,
  ) {
    return __mm256_maskz_broadcast_f64x2(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_broadcast_f64x2Ptr =
      _lookup<ffi.NativeFunction<_m256d Function(__mmask8, _m128d)>>(
          '_mm256_maskz_broadcast_f64x2');
  late final __mm256_maskz_broadcast_f64x2 = __mm256_maskz_broadcast_f64x2Ptr
      .asFunction<_m256d Function(int, _m128d)>();

  __m128i _mm_broadcast_i32x2(
    __m128i arg0,
  ) {
    return __mm_broadcast_i32x2(
      arg0,
    );
  }

  late final __mm_broadcast_i32x2Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i)>>(
          '_mm_broadcast_i32x2');
  late final __mm_broadcast_i32x2 =
      __mm_broadcast_i32x2Ptr.asFunction<__m128i Function(__m128i)>();

  __m128i _mm_mask_broadcast_i32x2(
    __m128i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_broadcast_i32x2(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_broadcast_i32x2Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m128i)>>(
          '_mm_mask_broadcast_i32x2');
  late final __mm_mask_broadcast_i32x2 = __mm_mask_broadcast_i32x2Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i)>();

  __m128i _mm_maskz_broadcast_i32x2(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_broadcast_i32x2(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_broadcast_i32x2Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i)>>(
          '_mm_maskz_broadcast_i32x2');
  late final __mm_maskz_broadcast_i32x2 = __mm_maskz_broadcast_i32x2Ptr
      .asFunction<__m128i Function(int, __m128i)>();

  __m256i _mm256_broadcast_i32x2(
    __m128i arg0,
  ) {
    return __mm256_broadcast_i32x2(
      arg0,
    );
  }

  late final __mm256_broadcast_i32x2Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m128i)>>(
          '_mm256_broadcast_i32x2');
  late final __mm256_broadcast_i32x2 =
      __mm256_broadcast_i32x2Ptr.asFunction<__m256i Function(__m128i)>();

  __m256i _mm256_mask_broadcast_i32x2(
    __m256i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm256_mask_broadcast_i32x2(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_broadcast_i32x2Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __mmask8, __m128i)>>(
          '_mm256_mask_broadcast_i32x2');
  late final __mm256_mask_broadcast_i32x2 = __mm256_mask_broadcast_i32x2Ptr
      .asFunction<__m256i Function(__m256i, int, __m128i)>();

  __m256i _mm256_maskz_broadcast_i32x2(
    int arg0,
    __m128i arg1,
  ) {
    return __mm256_maskz_broadcast_i32x2(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_broadcast_i32x2Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m128i)>>(
          '_mm256_maskz_broadcast_i32x2');
  late final __mm256_maskz_broadcast_i32x2 = __mm256_maskz_broadcast_i32x2Ptr
      .asFunction<__m256i Function(int, __m128i)>();

  __m256i _mm256_broadcast_i32x4(
    __m128i arg0,
  ) {
    return __mm256_broadcast_i32x4(
      arg0,
    );
  }

  late final __mm256_broadcast_i32x4Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m128i)>>(
          '_mm256_broadcast_i32x4');
  late final __mm256_broadcast_i32x4 =
      __mm256_broadcast_i32x4Ptr.asFunction<__m256i Function(__m128i)>();

  __m256i _mm256_mask_broadcast_i32x4(
    __m256i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm256_mask_broadcast_i32x4(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_broadcast_i32x4Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __mmask8, __m128i)>>(
          '_mm256_mask_broadcast_i32x4');
  late final __mm256_mask_broadcast_i32x4 = __mm256_mask_broadcast_i32x4Ptr
      .asFunction<__m256i Function(__m256i, int, __m128i)>();

  __m256i _mm256_maskz_broadcast_i32x4(
    int arg0,
    __m128i arg1,
  ) {
    return __mm256_maskz_broadcast_i32x4(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_broadcast_i32x4Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m128i)>>(
          '_mm256_maskz_broadcast_i32x4');
  late final __mm256_maskz_broadcast_i32x4 = __mm256_maskz_broadcast_i32x4Ptr
      .asFunction<__m256i Function(int, __m128i)>();

  __m256i _mm256_broadcast_i64x2(
    __m128i arg0,
  ) {
    return __mm256_broadcast_i64x2(
      arg0,
    );
  }

  late final __mm256_broadcast_i64x2Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m128i)>>(
          '_mm256_broadcast_i64x2');
  late final __mm256_broadcast_i64x2 =
      __mm256_broadcast_i64x2Ptr.asFunction<__m256i Function(__m128i)>();

  __m256i _mm256_mask_broadcast_i64x2(
    __m256i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm256_mask_broadcast_i64x2(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_broadcast_i64x2Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __mmask8, __m128i)>>(
          '_mm256_mask_broadcast_i64x2');
  late final __mm256_mask_broadcast_i64x2 = __mm256_mask_broadcast_i64x2Ptr
      .asFunction<__m256i Function(__m256i, int, __m128i)>();

  __m256i _mm256_maskz_broadcast_i64x2(
    int arg0,
    __m128i arg1,
  ) {
    return __mm256_maskz_broadcast_i64x2(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_broadcast_i64x2Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m128i)>>(
          '_mm256_maskz_broadcast_i64x2');
  late final __mm256_maskz_broadcast_i64x2 = __mm256_maskz_broadcast_i64x2Ptr
      .asFunction<__m256i Function(int, __m128i)>();

  __m128i _mm_mask_broadcastb_epi8(
    __m128i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_broadcastb_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_broadcastb_epi8Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__m128i, __mmask16, __m128i)>>(
      '_mm_mask_broadcastb_epi8');
  late final __mm_mask_broadcastb_epi8 = __mm_mask_broadcastb_epi8Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i)>();

  __m128i _mm_maskz_broadcastb_epi8(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_broadcastb_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_broadcastb_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask16, __m128i)>>(
          '_mm_maskz_broadcastb_epi8');
  late final __mm_maskz_broadcastb_epi8 = __mm_maskz_broadcastb_epi8Ptr
      .asFunction<__m128i Function(int, __m128i)>();

  __m256i _mm256_mask_broadcastb_epi8(
    __m256i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm256_mask_broadcastb_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_broadcastb_epi8Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__m256i, __mmask32, __m128i)>>(
      '_mm256_mask_broadcastb_epi8');
  late final __mm256_mask_broadcastb_epi8 = __mm256_mask_broadcastb_epi8Ptr
      .asFunction<__m256i Function(__m256i, int, __m128i)>();

  __m256i _mm256_maskz_broadcastb_epi8(
    int arg0,
    __m128i arg1,
  ) {
    return __mm256_maskz_broadcastb_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_broadcastb_epi8Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask32, __m128i)>>(
          '_mm256_maskz_broadcastb_epi8');
  late final __mm256_maskz_broadcastb_epi8 = __mm256_maskz_broadcastb_epi8Ptr
      .asFunction<__m256i Function(int, __m128i)>();

  __m128i _mm_mask_broadcastd_epi32(
    __m128i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_broadcastd_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_broadcastd_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m128i)>>(
          '_mm_mask_broadcastd_epi32');
  late final __mm_mask_broadcastd_epi32 = __mm_mask_broadcastd_epi32Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i)>();

  __m128i _mm_maskz_broadcastd_epi32(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_broadcastd_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_broadcastd_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i)>>(
          '_mm_maskz_broadcastd_epi32');
  late final __mm_maskz_broadcastd_epi32 = __mm_maskz_broadcastd_epi32Ptr
      .asFunction<__m128i Function(int, __m128i)>();

  __m256i _mm256_mask_broadcastd_epi32(
    __m256i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm256_mask_broadcastd_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_broadcastd_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __mmask8, __m128i)>>(
          '_mm256_mask_broadcastd_epi32');
  late final __mm256_mask_broadcastd_epi32 = __mm256_mask_broadcastd_epi32Ptr
      .asFunction<__m256i Function(__m256i, int, __m128i)>();

  __m256i _mm256_maskz_broadcastd_epi32(
    int arg0,
    __m128i arg1,
  ) {
    return __mm256_maskz_broadcastd_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_broadcastd_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m128i)>>(
          '_mm256_maskz_broadcastd_epi32');
  late final __mm256_maskz_broadcastd_epi32 = __mm256_maskz_broadcastd_epi32Ptr
      .asFunction<__m256i Function(int, __m128i)>();

  __m128i _mm_broadcastmb_epi64(
    int arg0,
  ) {
    return __mm_broadcastmb_epi64(
      arg0,
    );
  }

  late final __mm_broadcastmb_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8)>>(
          '_mm_broadcastmb_epi64');
  late final __mm_broadcastmb_epi64 =
      __mm_broadcastmb_epi64Ptr.asFunction<__m128i Function(int)>();

  __m256i _mm256_broadcastmb_epi64(
    int arg0,
  ) {
    return __mm256_broadcastmb_epi64(
      arg0,
    );
  }

  late final __mm256_broadcastmb_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8)>>(
          '_mm256_broadcastmb_epi64');
  late final __mm256_broadcastmb_epi64 =
      __mm256_broadcastmb_epi64Ptr.asFunction<__m256i Function(int)>();

  __m128i _mm_broadcastmw_epi32(
    int arg0,
  ) {
    return __mm_broadcastmw_epi32(
      arg0,
    );
  }

  late final __mm_broadcastmw_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask16)>>(
          '_mm_broadcastmw_epi32');
  late final __mm_broadcastmw_epi32 =
      __mm_broadcastmw_epi32Ptr.asFunction<__m128i Function(int)>();

  __m256i _mm256_broadcastmw_epi32(
    int arg0,
  ) {
    return __mm256_broadcastmw_epi32(
      arg0,
    );
  }

  late final __mm256_broadcastmw_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask16)>>(
          '_mm256_broadcastmw_epi32');
  late final __mm256_broadcastmw_epi32 =
      __mm256_broadcastmw_epi32Ptr.asFunction<__m256i Function(int)>();

  __m128i _mm_mask_broadcastq_epi64(
    __m128i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_broadcastq_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_broadcastq_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m128i)>>(
          '_mm_mask_broadcastq_epi64');
  late final __mm_mask_broadcastq_epi64 = __mm_mask_broadcastq_epi64Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i)>();

  __m128i _mm_maskz_broadcastq_epi64(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_broadcastq_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_broadcastq_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i)>>(
          '_mm_maskz_broadcastq_epi64');
  late final __mm_maskz_broadcastq_epi64 = __mm_maskz_broadcastq_epi64Ptr
      .asFunction<__m128i Function(int, __m128i)>();

  __m256i _mm256_mask_broadcastq_epi64(
    __m256i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm256_mask_broadcastq_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_broadcastq_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __mmask8, __m128i)>>(
          '_mm256_mask_broadcastq_epi64');
  late final __mm256_mask_broadcastq_epi64 = __mm256_mask_broadcastq_epi64Ptr
      .asFunction<__m256i Function(__m256i, int, __m128i)>();

  __m256i _mm256_maskz_broadcastq_epi64(
    int arg0,
    __m128i arg1,
  ) {
    return __mm256_maskz_broadcastq_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_broadcastq_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m128i)>>(
          '_mm256_maskz_broadcastq_epi64');
  late final __mm256_maskz_broadcastq_epi64 = __mm256_maskz_broadcastq_epi64Ptr
      .asFunction<__m256i Function(int, __m128i)>();

  _m256d _mm256_mask_broadcastsd_pd(
    _m256d arg0,
    int arg1,
    _m128d arg2,
  ) {
    return __mm256_mask_broadcastsd_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_broadcastsd_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d, __mmask8, _m128d)>>(
          '_mm256_mask_broadcastsd_pd');
  late final __mm256_mask_broadcastsd_pd = __mm256_mask_broadcastsd_pdPtr
      .asFunction<_m256d Function(_m256d, int, _m128d)>();

  _m256d _mm256_maskz_broadcastsd_pd(
    int arg0,
    _m128d arg1,
  ) {
    return __mm256_maskz_broadcastsd_pd(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_broadcastsd_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(__mmask8, _m128d)>>(
          '_mm256_maskz_broadcastsd_pd');
  late final __mm256_maskz_broadcastsd_pd = __mm256_maskz_broadcastsd_pdPtr
      .asFunction<_m256d Function(int, _m128d)>();

  __m128 _mm_mask_broadcastss_ps(
    __m128 arg0,
    int arg1,
    __m128 arg2,
  ) {
    return __mm_mask_broadcastss_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_broadcastss_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __mmask8, __m128)>>(
          '_mm_mask_broadcastss_ps');
  late final __mm_mask_broadcastss_ps = __mm_mask_broadcastss_psPtr
      .asFunction<__m128 Function(__m128, int, __m128)>();

  __m128 _mm_maskz_broadcastss_ps(
    int arg0,
    __m128 arg1,
  ) {
    return __mm_maskz_broadcastss_ps(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_broadcastss_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__mmask8, __m128)>>(
          '_mm_maskz_broadcastss_ps');
  late final __mm_maskz_broadcastss_ps =
      __mm_maskz_broadcastss_psPtr.asFunction<__m128 Function(int, __m128)>();

  __m256 _mm256_mask_broadcastss_ps(
    __m256 arg0,
    int arg1,
    __m128 arg2,
  ) {
    return __mm256_mask_broadcastss_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_broadcastss_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256, __mmask8, __m128)>>(
          '_mm256_mask_broadcastss_ps');
  late final __mm256_mask_broadcastss_ps = __mm256_mask_broadcastss_psPtr
      .asFunction<__m256 Function(__m256, int, __m128)>();

  __m256 _mm256_maskz_broadcastss_ps(
    int arg0,
    __m128 arg1,
  ) {
    return __mm256_maskz_broadcastss_ps(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_broadcastss_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__mmask8, __m128)>>(
          '_mm256_maskz_broadcastss_ps');
  late final __mm256_maskz_broadcastss_ps = __mm256_maskz_broadcastss_psPtr
      .asFunction<__m256 Function(int, __m128)>();

  __m128i _mm_mask_broadcastw_epi16(
    __m128i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_broadcastw_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_broadcastw_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m128i)>>(
          '_mm_mask_broadcastw_epi16');
  late final __mm_mask_broadcastw_epi16 = __mm_mask_broadcastw_epi16Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i)>();

  __m128i _mm_maskz_broadcastw_epi16(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_broadcastw_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_broadcastw_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i)>>(
          '_mm_maskz_broadcastw_epi16');
  late final __mm_maskz_broadcastw_epi16 = __mm_maskz_broadcastw_epi16Ptr
      .asFunction<__m128i Function(int, __m128i)>();

  __m256i _mm256_mask_broadcastw_epi16(
    __m256i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm256_mask_broadcastw_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_broadcastw_epi16Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__m256i, __mmask16, __m128i)>>(
      '_mm256_mask_broadcastw_epi16');
  late final __mm256_mask_broadcastw_epi16 = __mm256_mask_broadcastw_epi16Ptr
      .asFunction<__m256i Function(__m256i, int, __m128i)>();

  __m256i _mm256_maskz_broadcastw_epi16(
    int arg0,
    __m128i arg1,
  ) {
    return __mm256_maskz_broadcastw_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_broadcastw_epi16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask16, __m128i)>>(
          '_mm256_maskz_broadcastw_epi16');
  late final __mm256_maskz_broadcastw_epi16 = __mm256_maskz_broadcastw_epi16Ptr
      .asFunction<__m256i Function(int, __m128i)>();

  int _mm_cmp_epi16_mask(
    __m128i arg0,
    __m128i arg1,
    int arg2,
  ) {
    return __mm_cmp_epi16_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_cmp_epi16_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__m128i, __m128i, ffi.Int32)>>(
      '_mm_cmp_epi16_mask');
  late final __mm_cmp_epi16_mask =
      __mm_cmp_epi16_maskPtr.asFunction<int Function(__m128i, __m128i, int)>();

  int _mm_mask_cmp_epi16_mask(
    int arg0,
    __m128i arg1,
    __m128i arg2,
    int arg3,
  ) {
    return __mm_mask_cmp_epi16_mask(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_cmp_epi16_maskPtr = _lookup<
      ffi.NativeFunction<
          __mmask8 Function(__mmask8, __m128i, __m128i,
              ffi.Int32)>>('_mm_mask_cmp_epi16_mask');
  late final __mm_mask_cmp_epi16_mask = __mm_mask_cmp_epi16_maskPtr
      .asFunction<int Function(int, __m128i, __m128i, int)>();

  int _mm256_cmp_epi16_mask(
    __m256i arg0,
    __m256i arg1,
    int arg2,
  ) {
    return __mm256_cmp_epi16_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_cmp_epi16_maskPtr = _lookup<
          ffi.NativeFunction<__mmask16 Function(__m256i, __m256i, ffi.Int32)>>(
      '_mm256_cmp_epi16_mask');
  late final __mm256_cmp_epi16_mask = __mm256_cmp_epi16_maskPtr
      .asFunction<int Function(__m256i, __m256i, int)>();

  int _mm256_mask_cmp_epi16_mask(
    int arg0,
    __m256i arg1,
    __m256i arg2,
    int arg3,
  ) {
    return __mm256_mask_cmp_epi16_mask(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_cmp_epi16_maskPtr = _lookup<
      ffi.NativeFunction<
          __mmask16 Function(__mmask16, __m256i, __m256i,
              ffi.Int32)>>('_mm256_mask_cmp_epi16_mask');
  late final __mm256_mask_cmp_epi16_mask = __mm256_mask_cmp_epi16_maskPtr
      .asFunction<int Function(int, __m256i, __m256i, int)>();

  int _mm_cmp_epi32_mask(
    __m128i arg0,
    __m128i arg1,
    int arg2,
  ) {
    return __mm_cmp_epi32_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_cmp_epi32_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__m128i, __m128i, ffi.Int32)>>(
      '_mm_cmp_epi32_mask');
  late final __mm_cmp_epi32_mask =
      __mm_cmp_epi32_maskPtr.asFunction<int Function(__m128i, __m128i, int)>();

  int _mm_mask_cmp_epi32_mask(
    int arg0,
    __m128i arg1,
    __m128i arg2,
    int arg3,
  ) {
    return __mm_mask_cmp_epi32_mask(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_cmp_epi32_maskPtr = _lookup<
      ffi.NativeFunction<
          __mmask8 Function(__mmask8, __m128i, __m128i,
              ffi.Int32)>>('_mm_mask_cmp_epi32_mask');
  late final __mm_mask_cmp_epi32_mask = __mm_mask_cmp_epi32_maskPtr
      .asFunction<int Function(int, __m128i, __m128i, int)>();

  int _mm256_cmp_epi32_mask(
    __m256i arg0,
    __m256i arg1,
    int arg2,
  ) {
    return __mm256_cmp_epi32_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_cmp_epi32_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__m256i, __m256i, ffi.Int32)>>(
      '_mm256_cmp_epi32_mask');
  late final __mm256_cmp_epi32_mask = __mm256_cmp_epi32_maskPtr
      .asFunction<int Function(__m256i, __m256i, int)>();

  int _mm256_mask_cmp_epi32_mask(
    int arg0,
    __m256i arg1,
    __m256i arg2,
    int arg3,
  ) {
    return __mm256_mask_cmp_epi32_mask(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_cmp_epi32_maskPtr = _lookup<
      ffi.NativeFunction<
          __mmask8 Function(__mmask8, __m256i, __m256i,
              ffi.Int32)>>('_mm256_mask_cmp_epi32_mask');
  late final __mm256_mask_cmp_epi32_mask = __mm256_mask_cmp_epi32_maskPtr
      .asFunction<int Function(int, __m256i, __m256i, int)>();

  int _mm_cmp_epi64_mask(
    __m128i arg0,
    __m128i arg1,
    int arg2,
  ) {
    return __mm_cmp_epi64_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_cmp_epi64_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__m128i, __m128i, ffi.Int32)>>(
      '_mm_cmp_epi64_mask');
  late final __mm_cmp_epi64_mask =
      __mm_cmp_epi64_maskPtr.asFunction<int Function(__m128i, __m128i, int)>();

  int _mm_mask_cmp_epi64_mask(
    int arg0,
    __m128i arg1,
    __m128i arg2,
    int arg3,
  ) {
    return __mm_mask_cmp_epi64_mask(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_cmp_epi64_maskPtr = _lookup<
      ffi.NativeFunction<
          __mmask8 Function(__mmask8, __m128i, __m128i,
              ffi.Int32)>>('_mm_mask_cmp_epi64_mask');
  late final __mm_mask_cmp_epi64_mask = __mm_mask_cmp_epi64_maskPtr
      .asFunction<int Function(int, __m128i, __m128i, int)>();

  int _mm256_cmp_epi64_mask(
    __m256i arg0,
    __m256i arg1,
    int arg2,
  ) {
    return __mm256_cmp_epi64_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_cmp_epi64_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__m256i, __m256i, ffi.Int32)>>(
      '_mm256_cmp_epi64_mask');
  late final __mm256_cmp_epi64_mask = __mm256_cmp_epi64_maskPtr
      .asFunction<int Function(__m256i, __m256i, int)>();

  int _mm256_mask_cmp_epi64_mask(
    int arg0,
    __m256i arg1,
    __m256i arg2,
    int arg3,
  ) {
    return __mm256_mask_cmp_epi64_mask(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_cmp_epi64_maskPtr = _lookup<
      ffi.NativeFunction<
          __mmask8 Function(__mmask8, __m256i, __m256i,
              ffi.Int32)>>('_mm256_mask_cmp_epi64_mask');
  late final __mm256_mask_cmp_epi64_mask = __mm256_mask_cmp_epi64_maskPtr
      .asFunction<int Function(int, __m256i, __m256i, int)>();

  int _mm_cmp_epi8_mask(
    __m128i arg0,
    __m128i arg1,
    int arg2,
  ) {
    return __mm_cmp_epi8_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_cmp_epi8_maskPtr = _lookup<
          ffi.NativeFunction<__mmask16 Function(__m128i, __m128i, ffi.Int32)>>(
      '_mm_cmp_epi8_mask');
  late final __mm_cmp_epi8_mask =
      __mm_cmp_epi8_maskPtr.asFunction<int Function(__m128i, __m128i, int)>();

  int _mm_mask_cmp_epi8_mask(
    int arg0,
    __m128i arg1,
    __m128i arg2,
    int arg3,
  ) {
    return __mm_mask_cmp_epi8_mask(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_cmp_epi8_maskPtr = _lookup<
      ffi.NativeFunction<
          __mmask16 Function(__mmask16, __m128i, __m128i,
              ffi.Int32)>>('_mm_mask_cmp_epi8_mask');
  late final __mm_mask_cmp_epi8_mask = __mm_mask_cmp_epi8_maskPtr
      .asFunction<int Function(int, __m128i, __m128i, int)>();

  int _mm256_cmp_epi8_mask(
    __m256i arg0,
    __m256i arg1,
    int arg2,
  ) {
    return __mm256_cmp_epi8_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_cmp_epi8_maskPtr = _lookup<
          ffi.NativeFunction<__mmask32 Function(__m256i, __m256i, ffi.Int32)>>(
      '_mm256_cmp_epi8_mask');
  late final __mm256_cmp_epi8_mask = __mm256_cmp_epi8_maskPtr
      .asFunction<int Function(__m256i, __m256i, int)>();

  int _mm256_mask_cmp_epi8_mask(
    int arg0,
    __m256i arg1,
    __m256i arg2,
    int arg3,
  ) {
    return __mm256_mask_cmp_epi8_mask(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_cmp_epi8_maskPtr = _lookup<
      ffi.NativeFunction<
          __mmask32 Function(__mmask32, __m256i, __m256i,
              ffi.Int32)>>('_mm256_mask_cmp_epi8_mask');
  late final __mm256_mask_cmp_epi8_mask = __mm256_mask_cmp_epi8_maskPtr
      .asFunction<int Function(int, __m256i, __m256i, int)>();

  int _mm_cmp_epu16_mask(
    __m128i arg0,
    __m128i arg1,
    int arg2,
  ) {
    return __mm_cmp_epu16_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_cmp_epu16_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__m128i, __m128i, ffi.Int32)>>(
      '_mm_cmp_epu16_mask');
  late final __mm_cmp_epu16_mask =
      __mm_cmp_epu16_maskPtr.asFunction<int Function(__m128i, __m128i, int)>();

  int _mm_mask_cmp_epu16_mask(
    int arg0,
    __m128i arg1,
    __m128i arg2,
    int arg3,
  ) {
    return __mm_mask_cmp_epu16_mask(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_cmp_epu16_maskPtr = _lookup<
      ffi.NativeFunction<
          __mmask8 Function(__mmask8, __m128i, __m128i,
              ffi.Int32)>>('_mm_mask_cmp_epu16_mask');
  late final __mm_mask_cmp_epu16_mask = __mm_mask_cmp_epu16_maskPtr
      .asFunction<int Function(int, __m128i, __m128i, int)>();

  int _mm256_cmp_epu16_mask(
    __m256i arg0,
    __m256i arg1,
    int arg2,
  ) {
    return __mm256_cmp_epu16_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_cmp_epu16_maskPtr = _lookup<
          ffi.NativeFunction<__mmask16 Function(__m256i, __m256i, ffi.Int32)>>(
      '_mm256_cmp_epu16_mask');
  late final __mm256_cmp_epu16_mask = __mm256_cmp_epu16_maskPtr
      .asFunction<int Function(__m256i, __m256i, int)>();

  int _mm256_mask_cmp_epu16_mask(
    int arg0,
    __m256i arg1,
    __m256i arg2,
    int arg3,
  ) {
    return __mm256_mask_cmp_epu16_mask(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_cmp_epu16_maskPtr = _lookup<
      ffi.NativeFunction<
          __mmask16 Function(__mmask16, __m256i, __m256i,
              ffi.Int32)>>('_mm256_mask_cmp_epu16_mask');
  late final __mm256_mask_cmp_epu16_mask = __mm256_mask_cmp_epu16_maskPtr
      .asFunction<int Function(int, __m256i, __m256i, int)>();

  int _mm_cmp_epu32_mask(
    __m128i arg0,
    __m128i arg1,
    int arg2,
  ) {
    return __mm_cmp_epu32_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_cmp_epu32_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__m128i, __m128i, ffi.Int32)>>(
      '_mm_cmp_epu32_mask');
  late final __mm_cmp_epu32_mask =
      __mm_cmp_epu32_maskPtr.asFunction<int Function(__m128i, __m128i, int)>();

  int _mm_mask_cmp_epu32_mask(
    int arg0,
    __m128i arg1,
    __m128i arg2,
    int arg3,
  ) {
    return __mm_mask_cmp_epu32_mask(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_cmp_epu32_maskPtr = _lookup<
      ffi.NativeFunction<
          __mmask8 Function(__mmask8, __m128i, __m128i,
              ffi.Int32)>>('_mm_mask_cmp_epu32_mask');
  late final __mm_mask_cmp_epu32_mask = __mm_mask_cmp_epu32_maskPtr
      .asFunction<int Function(int, __m128i, __m128i, int)>();

  int _mm256_cmp_epu32_mask(
    __m256i arg0,
    __m256i arg1,
    int arg2,
  ) {
    return __mm256_cmp_epu32_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_cmp_epu32_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__m256i, __m256i, ffi.Int32)>>(
      '_mm256_cmp_epu32_mask');
  late final __mm256_cmp_epu32_mask = __mm256_cmp_epu32_maskPtr
      .asFunction<int Function(__m256i, __m256i, int)>();

  int _mm256_mask_cmp_epu32_mask(
    int arg0,
    __m256i arg1,
    __m256i arg2,
    int arg3,
  ) {
    return __mm256_mask_cmp_epu32_mask(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_cmp_epu32_maskPtr = _lookup<
      ffi.NativeFunction<
          __mmask8 Function(__mmask8, __m256i, __m256i,
              ffi.Int32)>>('_mm256_mask_cmp_epu32_mask');
  late final __mm256_mask_cmp_epu32_mask = __mm256_mask_cmp_epu32_maskPtr
      .asFunction<int Function(int, __m256i, __m256i, int)>();

  int _mm_cmp_epu64_mask(
    __m128i arg0,
    __m128i arg1,
    int arg2,
  ) {
    return __mm_cmp_epu64_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_cmp_epu64_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__m128i, __m128i, ffi.Int32)>>(
      '_mm_cmp_epu64_mask');
  late final __mm_cmp_epu64_mask =
      __mm_cmp_epu64_maskPtr.asFunction<int Function(__m128i, __m128i, int)>();

  int _mm_mask_cmp_epu64_mask(
    int arg0,
    __m128i arg1,
    __m128i arg2,
    int arg3,
  ) {
    return __mm_mask_cmp_epu64_mask(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_cmp_epu64_maskPtr = _lookup<
      ffi.NativeFunction<
          __mmask8 Function(__mmask8, __m128i, __m128i,
              ffi.Int32)>>('_mm_mask_cmp_epu64_mask');
  late final __mm_mask_cmp_epu64_mask = __mm_mask_cmp_epu64_maskPtr
      .asFunction<int Function(int, __m128i, __m128i, int)>();

  int _mm256_cmp_epu64_mask(
    __m256i arg0,
    __m256i arg1,
    int arg2,
  ) {
    return __mm256_cmp_epu64_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_cmp_epu64_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__m256i, __m256i, ffi.Int32)>>(
      '_mm256_cmp_epu64_mask');
  late final __mm256_cmp_epu64_mask = __mm256_cmp_epu64_maskPtr
      .asFunction<int Function(__m256i, __m256i, int)>();

  int _mm256_mask_cmp_epu64_mask(
    int arg0,
    __m256i arg1,
    __m256i arg2,
    int arg3,
  ) {
    return __mm256_mask_cmp_epu64_mask(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_cmp_epu64_maskPtr = _lookup<
      ffi.NativeFunction<
          __mmask8 Function(__mmask8, __m256i, __m256i,
              ffi.Int32)>>('_mm256_mask_cmp_epu64_mask');
  late final __mm256_mask_cmp_epu64_mask = __mm256_mask_cmp_epu64_maskPtr
      .asFunction<int Function(int, __m256i, __m256i, int)>();

  int _mm_cmp_epu8_mask(
    __m128i arg0,
    __m128i arg1,
    int arg2,
  ) {
    return __mm_cmp_epu8_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_cmp_epu8_maskPtr = _lookup<
          ffi.NativeFunction<__mmask16 Function(__m128i, __m128i, ffi.Int32)>>(
      '_mm_cmp_epu8_mask');
  late final __mm_cmp_epu8_mask =
      __mm_cmp_epu8_maskPtr.asFunction<int Function(__m128i, __m128i, int)>();

  int _mm_mask_cmp_epu8_mask(
    int arg0,
    __m128i arg1,
    __m128i arg2,
    int arg3,
  ) {
    return __mm_mask_cmp_epu8_mask(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_cmp_epu8_maskPtr = _lookup<
      ffi.NativeFunction<
          __mmask16 Function(__mmask16, __m128i, __m128i,
              ffi.Int32)>>('_mm_mask_cmp_epu8_mask');
  late final __mm_mask_cmp_epu8_mask = __mm_mask_cmp_epu8_maskPtr
      .asFunction<int Function(int, __m128i, __m128i, int)>();

  int _mm256_cmp_epu8_mask(
    __m256i arg0,
    __m256i arg1,
    int arg2,
  ) {
    return __mm256_cmp_epu8_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_cmp_epu8_maskPtr = _lookup<
          ffi.NativeFunction<__mmask32 Function(__m256i, __m256i, ffi.Int32)>>(
      '_mm256_cmp_epu8_mask');
  late final __mm256_cmp_epu8_mask = __mm256_cmp_epu8_maskPtr
      .asFunction<int Function(__m256i, __m256i, int)>();

  int _mm256_mask_cmp_epu8_mask(
    int arg0,
    __m256i arg1,
    __m256i arg2,
    int arg3,
  ) {
    return __mm256_mask_cmp_epu8_mask(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_cmp_epu8_maskPtr = _lookup<
      ffi.NativeFunction<
          __mmask32 Function(__mmask32, __m256i, __m256i,
              ffi.Int32)>>('_mm256_mask_cmp_epu8_mask');
  late final __mm256_mask_cmp_epu8_mask = __mm256_mask_cmp_epu8_maskPtr
      .asFunction<int Function(int, __m256i, __m256i, int)>();

  int _mm_cmp_pd_mask(
    _m128d arg0,
    _m128d arg1,
    int arg2,
  ) {
    return __mm_cmp_pd_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_cmp_pd_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(_m128d, _m128d, ffi.Int32)>>(
          '_mm_cmp_pd_mask');
  late final __mm_cmp_pd_mask =
      __mm_cmp_pd_maskPtr.asFunction<int Function(_m128d, _m128d, int)>();

  int _mm_mask_cmp_pd_mask(
    int arg0,
    _m128d arg1,
    _m128d arg2,
    int arg3,
  ) {
    return __mm_mask_cmp_pd_mask(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_cmp_pd_maskPtr = _lookup<
      ffi.NativeFunction<
          __mmask8 Function(
              __mmask8, _m128d, _m128d, ffi.Int32)>>('_mm_mask_cmp_pd_mask');
  late final __mm_mask_cmp_pd_mask = __mm_mask_cmp_pd_maskPtr
      .asFunction<int Function(int, _m128d, _m128d, int)>();

  int _mm256_cmp_pd_mask(
    _m256d arg0,
    _m256d arg1,
    int arg2,
  ) {
    return __mm256_cmp_pd_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_cmp_pd_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(_m256d, _m256d, ffi.Int32)>>(
          '_mm256_cmp_pd_mask');
  late final __mm256_cmp_pd_mask =
      __mm256_cmp_pd_maskPtr.asFunction<int Function(_m256d, _m256d, int)>();

  int _mm256_mask_cmp_pd_mask(
    int arg0,
    _m256d arg1,
    _m256d arg2,
    int arg3,
  ) {
    return __mm256_mask_cmp_pd_mask(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_cmp_pd_maskPtr = _lookup<
      ffi.NativeFunction<
          __mmask8 Function(
              __mmask8, _m256d, _m256d, ffi.Int32)>>('_mm256_mask_cmp_pd_mask');
  late final __mm256_mask_cmp_pd_mask = __mm256_mask_cmp_pd_maskPtr
      .asFunction<int Function(int, _m256d, _m256d, int)>();

  int _mm_cmp_ps_mask(
    __m128 arg0,
    __m128 arg1,
    int arg2,
  ) {
    return __mm_cmp_ps_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_cmp_ps_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m128, __m128, ffi.Int32)>>(
          '_mm_cmp_ps_mask');
  late final __mm_cmp_ps_mask =
      __mm_cmp_ps_maskPtr.asFunction<int Function(__m128, __m128, int)>();

  int _mm_mask_cmp_ps_mask(
    int arg0,
    __m128 arg1,
    __m128 arg2,
    int arg3,
  ) {
    return __mm_mask_cmp_ps_mask(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_cmp_ps_maskPtr = _lookup<
      ffi.NativeFunction<
          __mmask8 Function(
              __mmask8, __m128, __m128, ffi.Int32)>>('_mm_mask_cmp_ps_mask');
  late final __mm_mask_cmp_ps_mask = __mm_mask_cmp_ps_maskPtr
      .asFunction<int Function(int, __m128, __m128, int)>();

  int _mm256_cmp_ps_mask(
    __m256 arg0,
    __m256 arg1,
    int arg2,
  ) {
    return __mm256_cmp_ps_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_cmp_ps_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m256, __m256, ffi.Int32)>>(
          '_mm256_cmp_ps_mask');
  late final __mm256_cmp_ps_mask =
      __mm256_cmp_ps_maskPtr.asFunction<int Function(__m256, __m256, int)>();

  int _mm256_mask_cmp_ps_mask(
    int arg0,
    __m256 arg1,
    __m256 arg2,
    int arg3,
  ) {
    return __mm256_mask_cmp_ps_mask(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_cmp_ps_maskPtr = _lookup<
      ffi.NativeFunction<
          __mmask8 Function(
              __mmask8, __m256, __m256, ffi.Int32)>>('_mm256_mask_cmp_ps_mask');
  late final __mm256_mask_cmp_ps_mask = __mm256_mask_cmp_ps_maskPtr
      .asFunction<int Function(int, __m256, __m256, int)>();

  __m128i _mm_mask_compress_epi8(
    __m128i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_compress_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_compress_epi8Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__m128i, __mmask16, __m128i)>>(
      '_mm_mask_compress_epi8');
  late final __mm_mask_compress_epi8 = __mm_mask_compress_epi8Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i)>();

  __m128i _mm_maskz_compress_epi8(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_compress_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_compress_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask16, __m128i)>>(
          '_mm_maskz_compress_epi8');
  late final __mm_maskz_compress_epi8 =
      __mm_maskz_compress_epi8Ptr.asFunction<__m128i Function(int, __m128i)>();

  __m256i _mm256_mask_compress_epi8(
    __m256i arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_compress_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_compress_epi8Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__m256i, __mmask32, __m256i)>>(
      '_mm256_mask_compress_epi8');
  late final __mm256_mask_compress_epi8 = __mm256_mask_compress_epi8Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i)>();

  __m256i _mm256_maskz_compress_epi8(
    int arg0,
    __m256i arg1,
  ) {
    return __mm256_maskz_compress_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_compress_epi8Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask32, __m256i)>>(
          '_mm256_maskz_compress_epi8');
  late final __mm256_maskz_compress_epi8 = __mm256_maskz_compress_epi8Ptr
      .asFunction<__m256i Function(int, __m256i)>();

  __m128i _mm_mask_compress_epi16(
    __m128i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_compress_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_compress_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m128i)>>(
          '_mm_mask_compress_epi16');
  late final __mm_mask_compress_epi16 = __mm_mask_compress_epi16Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i)>();

  __m128i _mm_maskz_compress_epi16(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_compress_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_compress_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i)>>(
          '_mm_maskz_compress_epi16');
  late final __mm_maskz_compress_epi16 =
      __mm_maskz_compress_epi16Ptr.asFunction<__m128i Function(int, __m128i)>();

  __m256i _mm256_mask_compress_epi16(
    __m256i arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_compress_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_compress_epi16Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__m256i, __mmask16, __m256i)>>(
      '_mm256_mask_compress_epi16');
  late final __mm256_mask_compress_epi16 = __mm256_mask_compress_epi16Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i)>();

  __m256i _mm256_maskz_compress_epi16(
    int arg0,
    __m256i arg1,
  ) {
    return __mm256_maskz_compress_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_compress_epi16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask16, __m256i)>>(
          '_mm256_maskz_compress_epi16');
  late final __mm256_maskz_compress_epi16 = __mm256_maskz_compress_epi16Ptr
      .asFunction<__m256i Function(int, __m256i)>();

  __m128i _mm_mask_compress_epi32(
    __m128i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_compress_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_compress_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m128i)>>(
          '_mm_mask_compress_epi32');
  late final __mm_mask_compress_epi32 = __mm_mask_compress_epi32Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i)>();

  __m128i _mm_maskz_compress_epi32(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_compress_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_compress_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i)>>(
          '_mm_maskz_compress_epi32');
  late final __mm_maskz_compress_epi32 =
      __mm_maskz_compress_epi32Ptr.asFunction<__m128i Function(int, __m128i)>();

  __m256i _mm256_mask_compress_epi32(
    __m256i arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_compress_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_compress_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __mmask8, __m256i)>>(
          '_mm256_mask_compress_epi32');
  late final __mm256_mask_compress_epi32 = __mm256_mask_compress_epi32Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i)>();

  __m256i _mm256_maskz_compress_epi32(
    int arg0,
    __m256i arg1,
  ) {
    return __mm256_maskz_compress_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_compress_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m256i)>>(
          '_mm256_maskz_compress_epi32');
  late final __mm256_maskz_compress_epi32 = __mm256_maskz_compress_epi32Ptr
      .asFunction<__m256i Function(int, __m256i)>();

  __m128i _mm_mask_compress_epi64(
    __m128i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_compress_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_compress_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m128i)>>(
          '_mm_mask_compress_epi64');
  late final __mm_mask_compress_epi64 = __mm_mask_compress_epi64Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i)>();

  __m128i _mm_maskz_compress_epi64(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_compress_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_compress_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i)>>(
          '_mm_maskz_compress_epi64');
  late final __mm_maskz_compress_epi64 =
      __mm_maskz_compress_epi64Ptr.asFunction<__m128i Function(int, __m128i)>();

  __m256i _mm256_mask_compress_epi64(
    __m256i arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_compress_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_compress_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __mmask8, __m256i)>>(
          '_mm256_mask_compress_epi64');
  late final __mm256_mask_compress_epi64 = __mm256_mask_compress_epi64Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i)>();

  __m256i _mm256_maskz_compress_epi64(
    int arg0,
    __m256i arg1,
  ) {
    return __mm256_maskz_compress_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_compress_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m256i)>>(
          '_mm256_maskz_compress_epi64');
  late final __mm256_maskz_compress_epi64 = __mm256_maskz_compress_epi64Ptr
      .asFunction<__m256i Function(int, __m256i)>();

  _m128d _mm_mask_compress_pd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
  ) {
    return __mm_mask_compress_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_compress_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, __mmask8, _m128d)>>(
          '_mm_mask_compress_pd');
  late final __mm_mask_compress_pd = __mm_mask_compress_pdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d)>();

  _m128d _mm_maskz_compress_pd(
    int arg0,
    _m128d arg1,
  ) {
    return __mm_maskz_compress_pd(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_compress_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(__mmask8, _m128d)>>(
          '_mm_maskz_compress_pd');
  late final __mm_maskz_compress_pd =
      __mm_maskz_compress_pdPtr.asFunction<_m128d Function(int, _m128d)>();

  _m256d _mm256_mask_compress_pd(
    _m256d arg0,
    int arg1,
    _m256d arg2,
  ) {
    return __mm256_mask_compress_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_compress_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d, __mmask8, _m256d)>>(
          '_mm256_mask_compress_pd');
  late final __mm256_mask_compress_pd = __mm256_mask_compress_pdPtr
      .asFunction<_m256d Function(_m256d, int, _m256d)>();

  _m256d _mm256_maskz_compress_pd(
    int arg0,
    _m256d arg1,
  ) {
    return __mm256_maskz_compress_pd(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_compress_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(__mmask8, _m256d)>>(
          '_mm256_maskz_compress_pd');
  late final __mm256_maskz_compress_pd =
      __mm256_maskz_compress_pdPtr.asFunction<_m256d Function(int, _m256d)>();

  __m128 _mm_mask_compress_ps(
    __m128 arg0,
    int arg1,
    __m128 arg2,
  ) {
    return __mm_mask_compress_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_compress_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __mmask8, __m128)>>(
          '_mm_mask_compress_ps');
  late final __mm_mask_compress_ps = __mm_mask_compress_psPtr
      .asFunction<__m128 Function(__m128, int, __m128)>();

  __m128 _mm_maskz_compress_ps(
    int arg0,
    __m128 arg1,
  ) {
    return __mm_maskz_compress_ps(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_compress_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__mmask8, __m128)>>(
          '_mm_maskz_compress_ps');
  late final __mm_maskz_compress_ps =
      __mm_maskz_compress_psPtr.asFunction<__m128 Function(int, __m128)>();

  __m256 _mm256_mask_compress_ps(
    __m256 arg0,
    int arg1,
    __m256 arg2,
  ) {
    return __mm256_mask_compress_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_compress_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256, __mmask8, __m256)>>(
          '_mm256_mask_compress_ps');
  late final __mm256_mask_compress_ps = __mm256_mask_compress_psPtr
      .asFunction<__m256 Function(__m256, int, __m256)>();

  __m256 _mm256_maskz_compress_ps(
    int arg0,
    __m256 arg1,
  ) {
    return __mm256_maskz_compress_ps(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_compress_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__mmask8, __m256)>>(
          '_mm256_maskz_compress_ps');
  late final __mm256_maskz_compress_ps =
      __mm256_maskz_compress_psPtr.asFunction<__m256 Function(int, __m256)>();

  void _mm_mask_compressstoreu_epi8(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_compressstoreu_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_compressstoreu_epi8Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask16,
              __m128i)>>('_mm_mask_compressstoreu_epi8');
  late final __mm_mask_compressstoreu_epi8 = __mm_mask_compressstoreu_epi8Ptr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m128i)>();

  void _mm256_mask_compressstoreu_epi8(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_compressstoreu_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_compressstoreu_epi8Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask32,
              __m256i)>>('_mm256_mask_compressstoreu_epi8');
  late final __mm256_mask_compressstoreu_epi8 =
      __mm256_mask_compressstoreu_epi8Ptr
          .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m256i)>();

  void _mm_mask_compressstoreu_epi16(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_compressstoreu_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_compressstoreu_epi16Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8,
              __m128i)>>('_mm_mask_compressstoreu_epi16');
  late final __mm_mask_compressstoreu_epi16 = __mm_mask_compressstoreu_epi16Ptr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m128i)>();

  void _mm256_mask_compressstoreu_epi16(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_compressstoreu_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_compressstoreu_epi16Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask16,
              __m256i)>>('_mm256_mask_compressstoreu_epi16');
  late final __mm256_mask_compressstoreu_epi16 =
      __mm256_mask_compressstoreu_epi16Ptr
          .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m256i)>();

  void _mm_mask_compressstoreu_epi32(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_compressstoreu_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_compressstoreu_epi32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8,
              __m128i)>>('_mm_mask_compressstoreu_epi32');
  late final __mm_mask_compressstoreu_epi32 = __mm_mask_compressstoreu_epi32Ptr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m128i)>();

  void _mm256_mask_compressstoreu_epi32(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_compressstoreu_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_compressstoreu_epi32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8,
              __m256i)>>('_mm256_mask_compressstoreu_epi32');
  late final __mm256_mask_compressstoreu_epi32 =
      __mm256_mask_compressstoreu_epi32Ptr
          .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m256i)>();

  void _mm_mask_compressstoreu_epi64(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_compressstoreu_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_compressstoreu_epi64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8,
              __m128i)>>('_mm_mask_compressstoreu_epi64');
  late final __mm_mask_compressstoreu_epi64 = __mm_mask_compressstoreu_epi64Ptr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m128i)>();

  void _mm256_mask_compressstoreu_epi64(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_compressstoreu_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_compressstoreu_epi64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8,
              __m256i)>>('_mm256_mask_compressstoreu_epi64');
  late final __mm256_mask_compressstoreu_epi64 =
      __mm256_mask_compressstoreu_epi64Ptr
          .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m256i)>();

  void _mm_mask_compressstoreu_pd(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    _m128d arg2,
  ) {
    return __mm_mask_compressstoreu_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_compressstoreu_pdPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8,
              _m128d)>>('_mm_mask_compressstoreu_pd');
  late final __mm_mask_compressstoreu_pd = __mm_mask_compressstoreu_pdPtr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, int, _m128d)>();

  void _mm256_mask_compressstoreu_pd(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    _m256d arg2,
  ) {
    return __mm256_mask_compressstoreu_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_compressstoreu_pdPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8,
              _m256d)>>('_mm256_mask_compressstoreu_pd');
  late final __mm256_mask_compressstoreu_pd = __mm256_mask_compressstoreu_pdPtr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, int, _m256d)>();

  void _mm_mask_compressstoreu_ps(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m128 arg2,
  ) {
    return __mm_mask_compressstoreu_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_compressstoreu_psPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8,
              __m128)>>('_mm_mask_compressstoreu_ps');
  late final __mm_mask_compressstoreu_ps = __mm_mask_compressstoreu_psPtr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m128)>();

  void _mm256_mask_compressstoreu_ps(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m256 arg2,
  ) {
    return __mm256_mask_compressstoreu_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_compressstoreu_psPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8,
              __m256)>>('_mm256_mask_compressstoreu_ps');
  late final __mm256_mask_compressstoreu_ps = __mm256_mask_compressstoreu_psPtr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m256)>();

  __m128i _mm_conflict_epi32(
    __m128i arg0,
  ) {
    return __mm_conflict_epi32(
      arg0,
    );
  }

  late final __mm_conflict_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i)>>(
          '_mm_conflict_epi32');
  late final __mm_conflict_epi32 =
      __mm_conflict_epi32Ptr.asFunction<__m128i Function(__m128i)>();

  __m128i _mm_mask_conflict_epi32(
    __m128i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_conflict_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_conflict_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m128i)>>(
          '_mm_mask_conflict_epi32');
  late final __mm_mask_conflict_epi32 = __mm_mask_conflict_epi32Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i)>();

  __m128i _mm_maskz_conflict_epi32(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_conflict_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_conflict_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i)>>(
          '_mm_maskz_conflict_epi32');
  late final __mm_maskz_conflict_epi32 =
      __mm_maskz_conflict_epi32Ptr.asFunction<__m128i Function(int, __m128i)>();

  __m256i _mm256_conflict_epi32(
    __m256i arg0,
  ) {
    return __mm256_conflict_epi32(
      arg0,
    );
  }

  late final __mm256_conflict_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i)>>(
          '_mm256_conflict_epi32');
  late final __mm256_conflict_epi32 =
      __mm256_conflict_epi32Ptr.asFunction<__m256i Function(__m256i)>();

  __m256i _mm256_mask_conflict_epi32(
    __m256i arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_conflict_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_conflict_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __mmask8, __m256i)>>(
          '_mm256_mask_conflict_epi32');
  late final __mm256_mask_conflict_epi32 = __mm256_mask_conflict_epi32Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i)>();

  __m256i _mm256_maskz_conflict_epi32(
    int arg0,
    __m256i arg1,
  ) {
    return __mm256_maskz_conflict_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_conflict_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m256i)>>(
          '_mm256_maskz_conflict_epi32');
  late final __mm256_maskz_conflict_epi32 = __mm256_maskz_conflict_epi32Ptr
      .asFunction<__m256i Function(int, __m256i)>();

  __m128i _mm_conflict_epi64(
    __m128i arg0,
  ) {
    return __mm_conflict_epi64(
      arg0,
    );
  }

  late final __mm_conflict_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i)>>(
          '_mm_conflict_epi64');
  late final __mm_conflict_epi64 =
      __mm_conflict_epi64Ptr.asFunction<__m128i Function(__m128i)>();

  __m128i _mm_mask_conflict_epi64(
    __m128i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_conflict_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_conflict_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m128i)>>(
          '_mm_mask_conflict_epi64');
  late final __mm_mask_conflict_epi64 = __mm_mask_conflict_epi64Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i)>();

  __m128i _mm_maskz_conflict_epi64(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_conflict_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_conflict_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i)>>(
          '_mm_maskz_conflict_epi64');
  late final __mm_maskz_conflict_epi64 =
      __mm_maskz_conflict_epi64Ptr.asFunction<__m128i Function(int, __m128i)>();

  __m256i _mm256_conflict_epi64(
    __m256i arg0,
  ) {
    return __mm256_conflict_epi64(
      arg0,
    );
  }

  late final __mm256_conflict_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i)>>(
          '_mm256_conflict_epi64');
  late final __mm256_conflict_epi64 =
      __mm256_conflict_epi64Ptr.asFunction<__m256i Function(__m256i)>();

  __m256i _mm256_mask_conflict_epi64(
    __m256i arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_conflict_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_conflict_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __mmask8, __m256i)>>(
          '_mm256_mask_conflict_epi64');
  late final __mm256_mask_conflict_epi64 = __mm256_mask_conflict_epi64Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i)>();

  __m256i _mm256_maskz_conflict_epi64(
    int arg0,
    __m256i arg1,
  ) {
    return __mm256_maskz_conflict_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_conflict_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m256i)>>(
          '_mm256_maskz_conflict_epi64');
  late final __mm256_maskz_conflict_epi64 = __mm256_maskz_conflict_epi64Ptr
      .asFunction<__m256i Function(int, __m256i)>();

  __m128i _mm_mask_cvtps_ph(
    __m128i arg0,
    int arg1,
    __m128 arg2,
    int arg3,
  ) {
    return __mm_mask_cvtps_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_cvtps_phPtr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128, ffi.Int32)>>('_mm_mask_cvtps_ph');
  late final __mm_mask_cvtps_ph = __mm_mask_cvtps_phPtr
      .asFunction<__m128i Function(__m128i, int, __m128, int)>();

  __m128i _mm_maskz_cvtps_ph(
    int arg0,
    __m128 arg1,
    int arg2,
  ) {
    return __mm_maskz_cvtps_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_cvtps_phPtr = _lookup<
          ffi.NativeFunction<__m128i Function(__mmask8, __m128, ffi.Int32)>>(
      '_mm_maskz_cvtps_ph');
  late final __mm_maskz_cvtps_ph =
      __mm_maskz_cvtps_phPtr.asFunction<__m128i Function(int, __m128, int)>();

  __m128i _mm_mask_cvt_roundps_ph(
    __m128i arg0,
    int arg1,
    __m128 arg2,
    int arg3,
  ) {
    return __mm_mask_cvt_roundps_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_cvt_roundps_phPtr = _lookup<
      ffi.NativeFunction<
          __m128i Function(__m128i, __mmask8, __m128,
              ffi.Int32)>>('_mm_mask_cvt_roundps_ph');
  late final __mm_mask_cvt_roundps_ph = __mm_mask_cvt_roundps_phPtr
      .asFunction<__m128i Function(__m128i, int, __m128, int)>();

  __m128i _mm_maskz_cvt_roundps_ph(
    int arg0,
    __m128 arg1,
    int arg2,
  ) {
    return __mm_maskz_cvt_roundps_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_cvt_roundps_phPtr = _lookup<
          ffi.NativeFunction<__m128i Function(__mmask8, __m128, ffi.Int32)>>(
      '_mm_maskz_cvt_roundps_ph');
  late final __mm_maskz_cvt_roundps_ph = __mm_maskz_cvt_roundps_phPtr
      .asFunction<__m128i Function(int, __m128, int)>();

  __m128i _mm256_mask_cvtps_ph(
    __m128i arg0,
    int arg1,
    __m256 arg2,
    int arg3,
  ) {
    return __mm256_mask_cvtps_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_cvtps_phPtr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m256, ffi.Int32)>>('_mm256_mask_cvtps_ph');
  late final __mm256_mask_cvtps_ph = __mm256_mask_cvtps_phPtr
      .asFunction<__m128i Function(__m128i, int, __m256, int)>();

  __m128i _mm256_maskz_cvtps_ph(
    int arg0,
    __m256 arg1,
    int arg2,
  ) {
    return __mm256_maskz_cvtps_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_cvtps_phPtr = _lookup<
          ffi.NativeFunction<__m128i Function(__mmask8, __m256, ffi.Int32)>>(
      '_mm256_maskz_cvtps_ph');
  late final __mm256_maskz_cvtps_ph = __mm256_maskz_cvtps_phPtr
      .asFunction<__m128i Function(int, __m256, int)>();

  __m128i _mm256_mask_cvt_roundps_ph(
    __m128i arg0,
    int arg1,
    __m256 arg2,
    int arg3,
  ) {
    return __mm256_mask_cvt_roundps_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_cvt_roundps_phPtr = _lookup<
      ffi.NativeFunction<
          __m128i Function(__m128i, __mmask8, __m256,
              ffi.Int32)>>('_mm256_mask_cvt_roundps_ph');
  late final __mm256_mask_cvt_roundps_ph = __mm256_mask_cvt_roundps_phPtr
      .asFunction<__m128i Function(__m128i, int, __m256, int)>();

  __m128i _mm256_maskz_cvt_roundps_ph(
    int arg0,
    __m256 arg1,
    int arg2,
  ) {
    return __mm256_maskz_cvt_roundps_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_cvt_roundps_phPtr = _lookup<
          ffi.NativeFunction<__m128i Function(__mmask8, __m256, ffi.Int32)>>(
      '_mm256_maskz_cvt_roundps_ph');
  late final __mm256_maskz_cvt_roundps_ph = __mm256_maskz_cvt_roundps_phPtr
      .asFunction<__m128i Function(int, __m256, int)>();

  __m128i _mm_mask_cvtepi16_epi32(
    __m128i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cvtepi16_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtepi16_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m128i)>>(
          '_mm_mask_cvtepi16_epi32');
  late final __mm_mask_cvtepi16_epi32 = __mm_mask_cvtepi16_epi32Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i)>();

  __m128i _mm_maskz_cvtepi16_epi32(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_cvtepi16_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvtepi16_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i)>>(
          '_mm_maskz_cvtepi16_epi32');
  late final __mm_maskz_cvtepi16_epi32 =
      __mm_maskz_cvtepi16_epi32Ptr.asFunction<__m128i Function(int, __m128i)>();

  __m256i _mm256_mask_cvtepi16_epi32(
    __m256i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm256_mask_cvtepi16_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtepi16_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __mmask8, __m128i)>>(
          '_mm256_mask_cvtepi16_epi32');
  late final __mm256_mask_cvtepi16_epi32 = __mm256_mask_cvtepi16_epi32Ptr
      .asFunction<__m256i Function(__m256i, int, __m128i)>();

  __m256i _mm256_maskz_cvtepi16_epi32(
    int arg0,
    __m128i arg1,
  ) {
    return __mm256_maskz_cvtepi16_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvtepi16_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m128i)>>(
          '_mm256_maskz_cvtepi16_epi32');
  late final __mm256_maskz_cvtepi16_epi32 = __mm256_maskz_cvtepi16_epi32Ptr
      .asFunction<__m256i Function(int, __m128i)>();

  __m128i _mm_mask_cvtepi16_epi64(
    __m128i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cvtepi16_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtepi16_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m128i)>>(
          '_mm_mask_cvtepi16_epi64');
  late final __mm_mask_cvtepi16_epi64 = __mm_mask_cvtepi16_epi64Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i)>();

  __m128i _mm_maskz_cvtepi16_epi64(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_cvtepi16_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvtepi16_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i)>>(
          '_mm_maskz_cvtepi16_epi64');
  late final __mm_maskz_cvtepi16_epi64 =
      __mm_maskz_cvtepi16_epi64Ptr.asFunction<__m128i Function(int, __m128i)>();

  __m256i _mm256_mask_cvtepi16_epi64(
    __m256i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm256_mask_cvtepi16_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtepi16_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __mmask8, __m128i)>>(
          '_mm256_mask_cvtepi16_epi64');
  late final __mm256_mask_cvtepi16_epi64 = __mm256_mask_cvtepi16_epi64Ptr
      .asFunction<__m256i Function(__m256i, int, __m128i)>();

  __m256i _mm256_maskz_cvtepi16_epi64(
    int arg0,
    __m128i arg1,
  ) {
    return __mm256_maskz_cvtepi16_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvtepi16_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m128i)>>(
          '_mm256_maskz_cvtepi16_epi64');
  late final __mm256_maskz_cvtepi16_epi64 = __mm256_maskz_cvtepi16_epi64Ptr
      .asFunction<__m256i Function(int, __m128i)>();

  __m128i _mm_cvtepi16_epi8(
    __m128i arg0,
  ) {
    return __mm_cvtepi16_epi8(
      arg0,
    );
  }

  late final __mm_cvtepi16_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i)>>(
          '_mm_cvtepi16_epi8');
  late final __mm_cvtepi16_epi8 =
      __mm_cvtepi16_epi8Ptr.asFunction<__m128i Function(__m128i)>();

  __m128i _mm_mask_cvtepi16_epi8(
    __m128i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cvtepi16_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtepi16_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m128i)>>(
          '_mm_mask_cvtepi16_epi8');
  late final __mm_mask_cvtepi16_epi8 = __mm_mask_cvtepi16_epi8Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i)>();

  __m128i _mm_maskz_cvtepi16_epi8(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_cvtepi16_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvtepi16_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i)>>(
          '_mm_maskz_cvtepi16_epi8');
  late final __mm_maskz_cvtepi16_epi8 =
      __mm_maskz_cvtepi16_epi8Ptr.asFunction<__m128i Function(int, __m128i)>();

  __m128i _mm256_cvtepi16_epi8(
    __m256i arg0,
  ) {
    return __mm256_cvtepi16_epi8(
      arg0,
    );
  }

  late final __mm256_cvtepi16_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m256i)>>(
          '_mm256_cvtepi16_epi8');
  late final __mm256_cvtepi16_epi8 =
      __mm256_cvtepi16_epi8Ptr.asFunction<__m128i Function(__m256i)>();

  __m128i _mm256_mask_cvtepi16_epi8(
    __m128i arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cvtepi16_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtepi16_epi8Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__m128i, __mmask16, __m256i)>>(
      '_mm256_mask_cvtepi16_epi8');
  late final __mm256_mask_cvtepi16_epi8 = __mm256_mask_cvtepi16_epi8Ptr
      .asFunction<__m128i Function(__m128i, int, __m256i)>();

  __m128i _mm256_maskz_cvtepi16_epi8(
    int arg0,
    __m256i arg1,
  ) {
    return __mm256_maskz_cvtepi16_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvtepi16_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask16, __m256i)>>(
          '_mm256_maskz_cvtepi16_epi8');
  late final __mm256_maskz_cvtepi16_epi8 = __mm256_maskz_cvtepi16_epi8Ptr
      .asFunction<__m128i Function(int, __m256i)>();

  void _mm_mask_cvtepi16_storeu_epi8(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cvtepi16_storeu_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtepi16_storeu_epi8Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8,
              __m128i)>>('_mm_mask_cvtepi16_storeu_epi8');
  late final __mm_mask_cvtepi16_storeu_epi8 = __mm_mask_cvtepi16_storeu_epi8Ptr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m128i)>();

  void _mm256_mask_cvtepi16_storeu_epi8(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cvtepi16_storeu_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtepi16_storeu_epi8Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask16,
              __m256i)>>('_mm256_mask_cvtepi16_storeu_epi8');
  late final __mm256_mask_cvtepi16_storeu_epi8 =
      __mm256_mask_cvtepi16_storeu_epi8Ptr
          .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m256i)>();

  __m128i _mm_cvtepi32_epi16(
    __m128i arg0,
  ) {
    return __mm_cvtepi32_epi16(
      arg0,
    );
  }

  late final __mm_cvtepi32_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i)>>(
          '_mm_cvtepi32_epi16');
  late final __mm_cvtepi32_epi16 =
      __mm_cvtepi32_epi16Ptr.asFunction<__m128i Function(__m128i)>();

  __m128i _mm_mask_cvtepi32_epi16(
    __m128i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cvtepi32_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtepi32_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m128i)>>(
          '_mm_mask_cvtepi32_epi16');
  late final __mm_mask_cvtepi32_epi16 = __mm_mask_cvtepi32_epi16Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i)>();

  __m128i _mm_maskz_cvtepi32_epi16(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_cvtepi32_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvtepi32_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i)>>(
          '_mm_maskz_cvtepi32_epi16');
  late final __mm_maskz_cvtepi32_epi16 =
      __mm_maskz_cvtepi32_epi16Ptr.asFunction<__m128i Function(int, __m128i)>();

  __m128i _mm256_cvtepi32_epi16(
    __m256i arg0,
  ) {
    return __mm256_cvtepi32_epi16(
      arg0,
    );
  }

  late final __mm256_cvtepi32_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m256i)>>(
          '_mm256_cvtepi32_epi16');
  late final __mm256_cvtepi32_epi16 =
      __mm256_cvtepi32_epi16Ptr.asFunction<__m128i Function(__m256i)>();

  __m128i _mm256_mask_cvtepi32_epi16(
    __m128i arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cvtepi32_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtepi32_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m256i)>>(
          '_mm256_mask_cvtepi32_epi16');
  late final __mm256_mask_cvtepi32_epi16 = __mm256_mask_cvtepi32_epi16Ptr
      .asFunction<__m128i Function(__m128i, int, __m256i)>();

  __m128i _mm256_maskz_cvtepi32_epi16(
    int arg0,
    __m256i arg1,
  ) {
    return __mm256_maskz_cvtepi32_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvtepi32_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m256i)>>(
          '_mm256_maskz_cvtepi32_epi16');
  late final __mm256_maskz_cvtepi32_epi16 = __mm256_maskz_cvtepi32_epi16Ptr
      .asFunction<__m128i Function(int, __m256i)>();

  __m128i _mm_mask_cvtepi32_epi64(
    __m128i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cvtepi32_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtepi32_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m128i)>>(
          '_mm_mask_cvtepi32_epi64');
  late final __mm_mask_cvtepi32_epi64 = __mm_mask_cvtepi32_epi64Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i)>();

  __m128i _mm_maskz_cvtepi32_epi64(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_cvtepi32_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvtepi32_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i)>>(
          '_mm_maskz_cvtepi32_epi64');
  late final __mm_maskz_cvtepi32_epi64 =
      __mm_maskz_cvtepi32_epi64Ptr.asFunction<__m128i Function(int, __m128i)>();

  __m256i _mm256_mask_cvtepi32_epi64(
    __m256i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm256_mask_cvtepi32_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtepi32_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __mmask8, __m128i)>>(
          '_mm256_mask_cvtepi32_epi64');
  late final __mm256_mask_cvtepi32_epi64 = __mm256_mask_cvtepi32_epi64Ptr
      .asFunction<__m256i Function(__m256i, int, __m128i)>();

  __m256i _mm256_maskz_cvtepi32_epi64(
    int arg0,
    __m128i arg1,
  ) {
    return __mm256_maskz_cvtepi32_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvtepi32_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m128i)>>(
          '_mm256_maskz_cvtepi32_epi64');
  late final __mm256_maskz_cvtepi32_epi64 = __mm256_maskz_cvtepi32_epi64Ptr
      .asFunction<__m256i Function(int, __m128i)>();

  __m128i _mm_cvtepi32_epi8(
    __m128i arg0,
  ) {
    return __mm_cvtepi32_epi8(
      arg0,
    );
  }

  late final __mm_cvtepi32_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i)>>(
          '_mm_cvtepi32_epi8');
  late final __mm_cvtepi32_epi8 =
      __mm_cvtepi32_epi8Ptr.asFunction<__m128i Function(__m128i)>();

  __m128i _mm_mask_cvtepi32_epi8(
    __m128i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cvtepi32_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtepi32_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m128i)>>(
          '_mm_mask_cvtepi32_epi8');
  late final __mm_mask_cvtepi32_epi8 = __mm_mask_cvtepi32_epi8Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i)>();

  __m128i _mm_maskz_cvtepi32_epi8(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_cvtepi32_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvtepi32_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i)>>(
          '_mm_maskz_cvtepi32_epi8');
  late final __mm_maskz_cvtepi32_epi8 =
      __mm_maskz_cvtepi32_epi8Ptr.asFunction<__m128i Function(int, __m128i)>();

  __m128i _mm256_cvtepi32_epi8(
    __m256i arg0,
  ) {
    return __mm256_cvtepi32_epi8(
      arg0,
    );
  }

  late final __mm256_cvtepi32_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m256i)>>(
          '_mm256_cvtepi32_epi8');
  late final __mm256_cvtepi32_epi8 =
      __mm256_cvtepi32_epi8Ptr.asFunction<__m128i Function(__m256i)>();

  __m128i _mm256_mask_cvtepi32_epi8(
    __m128i arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cvtepi32_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtepi32_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m256i)>>(
          '_mm256_mask_cvtepi32_epi8');
  late final __mm256_mask_cvtepi32_epi8 = __mm256_mask_cvtepi32_epi8Ptr
      .asFunction<__m128i Function(__m128i, int, __m256i)>();

  __m128i _mm256_maskz_cvtepi32_epi8(
    int arg0,
    __m256i arg1,
  ) {
    return __mm256_maskz_cvtepi32_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvtepi32_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m256i)>>(
          '_mm256_maskz_cvtepi32_epi8');
  late final __mm256_maskz_cvtepi32_epi8 = __mm256_maskz_cvtepi32_epi8Ptr
      .asFunction<__m128i Function(int, __m256i)>();

  _m128d _mm_mask_cvtepi32_pd(
    _m128d arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cvtepi32_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtepi32_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, __mmask8, __m128i)>>(
          '_mm_mask_cvtepi32_pd');
  late final __mm_mask_cvtepi32_pd = __mm_mask_cvtepi32_pdPtr
      .asFunction<_m128d Function(_m128d, int, __m128i)>();

  _m128d _mm_maskz_cvtepi32_pd(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_cvtepi32_pd(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvtepi32_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(__mmask8, __m128i)>>(
          '_mm_maskz_cvtepi32_pd');
  late final __mm_maskz_cvtepi32_pd =
      __mm_maskz_cvtepi32_pdPtr.asFunction<_m128d Function(int, __m128i)>();

  _m256d _mm256_mask_cvtepi32_pd(
    _m256d arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm256_mask_cvtepi32_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtepi32_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d, __mmask8, __m128i)>>(
          '_mm256_mask_cvtepi32_pd');
  late final __mm256_mask_cvtepi32_pd = __mm256_mask_cvtepi32_pdPtr
      .asFunction<_m256d Function(_m256d, int, __m128i)>();

  _m256d _mm256_maskz_cvtepi32_pd(
    int arg0,
    __m128i arg1,
  ) {
    return __mm256_maskz_cvtepi32_pd(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvtepi32_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(__mmask8, __m128i)>>(
          '_mm256_maskz_cvtepi32_pd');
  late final __mm256_maskz_cvtepi32_pd =
      __mm256_maskz_cvtepi32_pdPtr.asFunction<_m256d Function(int, __m128i)>();

  __m128 _mm_mask_cvtepi32_ps(
    __m128 arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cvtepi32_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtepi32_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __mmask8, __m128i)>>(
          '_mm_mask_cvtepi32_ps');
  late final __mm_mask_cvtepi32_ps = __mm_mask_cvtepi32_psPtr
      .asFunction<__m128 Function(__m128, int, __m128i)>();

  __m128 _mm_maskz_cvtepi32_ps(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_cvtepi32_ps(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvtepi32_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__mmask8, __m128i)>>(
          '_mm_maskz_cvtepi32_ps');
  late final __mm_maskz_cvtepi32_ps =
      __mm_maskz_cvtepi32_psPtr.asFunction<__m128 Function(int, __m128i)>();

  __m256 _mm256_mask_cvtepi32_ps(
    __m256 arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cvtepi32_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtepi32_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256, __mmask8, __m256i)>>(
          '_mm256_mask_cvtepi32_ps');
  late final __mm256_mask_cvtepi32_ps = __mm256_mask_cvtepi32_psPtr
      .asFunction<__m256 Function(__m256, int, __m256i)>();

  __m256 _mm256_maskz_cvtepi32_ps(
    int arg0,
    __m256i arg1,
  ) {
    return __mm256_maskz_cvtepi32_ps(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvtepi32_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__mmask8, __m256i)>>(
          '_mm256_maskz_cvtepi32_ps');
  late final __mm256_maskz_cvtepi32_ps =
      __mm256_maskz_cvtepi32_psPtr.asFunction<__m256 Function(int, __m256i)>();

  void _mm_mask_cvtepi32_storeu_epi16(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cvtepi32_storeu_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtepi32_storeu_epi16Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8,
              __m128i)>>('_mm_mask_cvtepi32_storeu_epi16');
  late final __mm_mask_cvtepi32_storeu_epi16 =
      __mm_mask_cvtepi32_storeu_epi16Ptr
          .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m128i)>();

  void _mm256_mask_cvtepi32_storeu_epi16(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cvtepi32_storeu_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtepi32_storeu_epi16Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8,
              __m256i)>>('_mm256_mask_cvtepi32_storeu_epi16');
  late final __mm256_mask_cvtepi32_storeu_epi16 =
      __mm256_mask_cvtepi32_storeu_epi16Ptr
          .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m256i)>();

  void _mm_mask_cvtepi32_storeu_epi8(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cvtepi32_storeu_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtepi32_storeu_epi8Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8,
              __m128i)>>('_mm_mask_cvtepi32_storeu_epi8');
  late final __mm_mask_cvtepi32_storeu_epi8 = __mm_mask_cvtepi32_storeu_epi8Ptr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m128i)>();

  void _mm256_mask_cvtepi32_storeu_epi8(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cvtepi32_storeu_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtepi32_storeu_epi8Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8,
              __m256i)>>('_mm256_mask_cvtepi32_storeu_epi8');
  late final __mm256_mask_cvtepi32_storeu_epi8 =
      __mm256_mask_cvtepi32_storeu_epi8Ptr
          .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m256i)>();

  __m128i _mm_cvtepi64_epi16(
    __m128i arg0,
  ) {
    return __mm_cvtepi64_epi16(
      arg0,
    );
  }

  late final __mm_cvtepi64_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i)>>(
          '_mm_cvtepi64_epi16');
  late final __mm_cvtepi64_epi16 =
      __mm_cvtepi64_epi16Ptr.asFunction<__m128i Function(__m128i)>();

  __m128i _mm_mask_cvtepi64_epi16(
    __m128i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cvtepi64_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtepi64_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m128i)>>(
          '_mm_mask_cvtepi64_epi16');
  late final __mm_mask_cvtepi64_epi16 = __mm_mask_cvtepi64_epi16Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i)>();

  __m128i _mm_maskz_cvtepi64_epi16(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_cvtepi64_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvtepi64_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i)>>(
          '_mm_maskz_cvtepi64_epi16');
  late final __mm_maskz_cvtepi64_epi16 =
      __mm_maskz_cvtepi64_epi16Ptr.asFunction<__m128i Function(int, __m128i)>();

  __m128i _mm256_cvtepi64_epi16(
    __m256i arg0,
  ) {
    return __mm256_cvtepi64_epi16(
      arg0,
    );
  }

  late final __mm256_cvtepi64_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m256i)>>(
          '_mm256_cvtepi64_epi16');
  late final __mm256_cvtepi64_epi16 =
      __mm256_cvtepi64_epi16Ptr.asFunction<__m128i Function(__m256i)>();

  __m128i _mm256_mask_cvtepi64_epi16(
    __m128i arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cvtepi64_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtepi64_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m256i)>>(
          '_mm256_mask_cvtepi64_epi16');
  late final __mm256_mask_cvtepi64_epi16 = __mm256_mask_cvtepi64_epi16Ptr
      .asFunction<__m128i Function(__m128i, int, __m256i)>();

  __m128i _mm256_maskz_cvtepi64_epi16(
    int arg0,
    __m256i arg1,
  ) {
    return __mm256_maskz_cvtepi64_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvtepi64_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m256i)>>(
          '_mm256_maskz_cvtepi64_epi16');
  late final __mm256_maskz_cvtepi64_epi16 = __mm256_maskz_cvtepi64_epi16Ptr
      .asFunction<__m128i Function(int, __m256i)>();

  __m128i _mm_cvtepi64_epi32(
    __m128i arg0,
  ) {
    return __mm_cvtepi64_epi32(
      arg0,
    );
  }

  late final __mm_cvtepi64_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i)>>(
          '_mm_cvtepi64_epi32');
  late final __mm_cvtepi64_epi32 =
      __mm_cvtepi64_epi32Ptr.asFunction<__m128i Function(__m128i)>();

  __m128i _mm_mask_cvtepi64_epi32(
    __m128i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cvtepi64_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtepi64_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m128i)>>(
          '_mm_mask_cvtepi64_epi32');
  late final __mm_mask_cvtepi64_epi32 = __mm_mask_cvtepi64_epi32Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i)>();

  __m128i _mm_maskz_cvtepi64_epi32(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_cvtepi64_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvtepi64_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i)>>(
          '_mm_maskz_cvtepi64_epi32');
  late final __mm_maskz_cvtepi64_epi32 =
      __mm_maskz_cvtepi64_epi32Ptr.asFunction<__m128i Function(int, __m128i)>();

  __m128i _mm256_cvtepi64_epi32(
    __m256i arg0,
  ) {
    return __mm256_cvtepi64_epi32(
      arg0,
    );
  }

  late final __mm256_cvtepi64_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m256i)>>(
          '_mm256_cvtepi64_epi32');
  late final __mm256_cvtepi64_epi32 =
      __mm256_cvtepi64_epi32Ptr.asFunction<__m128i Function(__m256i)>();

  __m128i _mm256_mask_cvtepi64_epi32(
    __m128i arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cvtepi64_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtepi64_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m256i)>>(
          '_mm256_mask_cvtepi64_epi32');
  late final __mm256_mask_cvtepi64_epi32 = __mm256_mask_cvtepi64_epi32Ptr
      .asFunction<__m128i Function(__m128i, int, __m256i)>();

  __m128i _mm256_maskz_cvtepi64_epi32(
    int arg0,
    __m256i arg1,
  ) {
    return __mm256_maskz_cvtepi64_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvtepi64_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m256i)>>(
          '_mm256_maskz_cvtepi64_epi32');
  late final __mm256_maskz_cvtepi64_epi32 = __mm256_maskz_cvtepi64_epi32Ptr
      .asFunction<__m128i Function(int, __m256i)>();

  __m128i _mm_cvtepi64_epi8(
    __m128i arg0,
  ) {
    return __mm_cvtepi64_epi8(
      arg0,
    );
  }

  late final __mm_cvtepi64_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i)>>(
          '_mm_cvtepi64_epi8');
  late final __mm_cvtepi64_epi8 =
      __mm_cvtepi64_epi8Ptr.asFunction<__m128i Function(__m128i)>();

  __m128i _mm_mask_cvtepi64_epi8(
    __m128i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cvtepi64_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtepi64_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m128i)>>(
          '_mm_mask_cvtepi64_epi8');
  late final __mm_mask_cvtepi64_epi8 = __mm_mask_cvtepi64_epi8Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i)>();

  __m128i _mm_maskz_cvtepi64_epi8(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_cvtepi64_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvtepi64_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i)>>(
          '_mm_maskz_cvtepi64_epi8');
  late final __mm_maskz_cvtepi64_epi8 =
      __mm_maskz_cvtepi64_epi8Ptr.asFunction<__m128i Function(int, __m128i)>();

  __m128i _mm256_cvtepi64_epi8(
    __m256i arg0,
  ) {
    return __mm256_cvtepi64_epi8(
      arg0,
    );
  }

  late final __mm256_cvtepi64_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m256i)>>(
          '_mm256_cvtepi64_epi8');
  late final __mm256_cvtepi64_epi8 =
      __mm256_cvtepi64_epi8Ptr.asFunction<__m128i Function(__m256i)>();

  __m128i _mm256_mask_cvtepi64_epi8(
    __m128i arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cvtepi64_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtepi64_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m256i)>>(
          '_mm256_mask_cvtepi64_epi8');
  late final __mm256_mask_cvtepi64_epi8 = __mm256_mask_cvtepi64_epi8Ptr
      .asFunction<__m128i Function(__m128i, int, __m256i)>();

  __m128i _mm256_maskz_cvtepi64_epi8(
    int arg0,
    __m256i arg1,
  ) {
    return __mm256_maskz_cvtepi64_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvtepi64_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m256i)>>(
          '_mm256_maskz_cvtepi64_epi8');
  late final __mm256_maskz_cvtepi64_epi8 = __mm256_maskz_cvtepi64_epi8Ptr
      .asFunction<__m128i Function(int, __m256i)>();

  _m128d _mm_cvtepi64_pd(
    __m128i arg0,
  ) {
    return __mm_cvtepi64_pd(
      arg0,
    );
  }

  late final __mm_cvtepi64_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(__m128i)>>('_mm_cvtepi64_pd');
  late final __mm_cvtepi64_pd =
      __mm_cvtepi64_pdPtr.asFunction<_m128d Function(__m128i)>();

  _m128d _mm_mask_cvtepi64_pd(
    _m128d arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cvtepi64_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtepi64_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, __mmask8, __m128i)>>(
          '_mm_mask_cvtepi64_pd');
  late final __mm_mask_cvtepi64_pd = __mm_mask_cvtepi64_pdPtr
      .asFunction<_m128d Function(_m128d, int, __m128i)>();

  _m128d _mm_maskz_cvtepi64_pd(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_cvtepi64_pd(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvtepi64_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(__mmask8, __m128i)>>(
          '_mm_maskz_cvtepi64_pd');
  late final __mm_maskz_cvtepi64_pd =
      __mm_maskz_cvtepi64_pdPtr.asFunction<_m128d Function(int, __m128i)>();

  _m256d _mm256_cvtepi64_pd(
    __m256i arg0,
  ) {
    return __mm256_cvtepi64_pd(
      arg0,
    );
  }

  late final __mm256_cvtepi64_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(__m256i)>>(
          '_mm256_cvtepi64_pd');
  late final __mm256_cvtepi64_pd =
      __mm256_cvtepi64_pdPtr.asFunction<_m256d Function(__m256i)>();

  _m256d _mm256_mask_cvtepi64_pd(
    _m256d arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cvtepi64_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtepi64_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d, __mmask8, __m256i)>>(
          '_mm256_mask_cvtepi64_pd');
  late final __mm256_mask_cvtepi64_pd = __mm256_mask_cvtepi64_pdPtr
      .asFunction<_m256d Function(_m256d, int, __m256i)>();

  _m256d _mm256_maskz_cvtepi64_pd(
    int arg0,
    __m256i arg1,
  ) {
    return __mm256_maskz_cvtepi64_pd(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvtepi64_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(__mmask8, __m256i)>>(
          '_mm256_maskz_cvtepi64_pd');
  late final __mm256_maskz_cvtepi64_pd =
      __mm256_maskz_cvtepi64_pdPtr.asFunction<_m256d Function(int, __m256i)>();

  __m128 _mm_cvtepi64_ps(
    __m128i arg0,
  ) {
    return __mm_cvtepi64_ps(
      arg0,
    );
  }

  late final __mm_cvtepi64_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128i)>>('_mm_cvtepi64_ps');
  late final __mm_cvtepi64_ps =
      __mm_cvtepi64_psPtr.asFunction<__m128 Function(__m128i)>();

  __m128 _mm_mask_cvtepi64_ps(
    __m128 arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cvtepi64_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtepi64_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __mmask8, __m128i)>>(
          '_mm_mask_cvtepi64_ps');
  late final __mm_mask_cvtepi64_ps = __mm_mask_cvtepi64_psPtr
      .asFunction<__m128 Function(__m128, int, __m128i)>();

  __m128 _mm_maskz_cvtepi64_ps(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_cvtepi64_ps(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvtepi64_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__mmask8, __m128i)>>(
          '_mm_maskz_cvtepi64_ps');
  late final __mm_maskz_cvtepi64_ps =
      __mm_maskz_cvtepi64_psPtr.asFunction<__m128 Function(int, __m128i)>();

  __m128 _mm256_cvtepi64_ps(
    __m256i arg0,
  ) {
    return __mm256_cvtepi64_ps(
      arg0,
    );
  }

  late final __mm256_cvtepi64_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m256i)>>(
          '_mm256_cvtepi64_ps');
  late final __mm256_cvtepi64_ps =
      __mm256_cvtepi64_psPtr.asFunction<__m128 Function(__m256i)>();

  __m128 _mm256_mask_cvtepi64_ps(
    __m128 arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cvtepi64_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtepi64_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __mmask8, __m256i)>>(
          '_mm256_mask_cvtepi64_ps');
  late final __mm256_mask_cvtepi64_ps = __mm256_mask_cvtepi64_psPtr
      .asFunction<__m128 Function(__m128, int, __m256i)>();

  __m128 _mm256_maskz_cvtepi64_ps(
    int arg0,
    __m256i arg1,
  ) {
    return __mm256_maskz_cvtepi64_ps(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvtepi64_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__mmask8, __m256i)>>(
          '_mm256_maskz_cvtepi64_ps');
  late final __mm256_maskz_cvtepi64_ps =
      __mm256_maskz_cvtepi64_psPtr.asFunction<__m128 Function(int, __m256i)>();

  void _mm_mask_cvtepi64_storeu_epi16(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cvtepi64_storeu_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtepi64_storeu_epi16Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8,
              __m128i)>>('_mm_mask_cvtepi64_storeu_epi16');
  late final __mm_mask_cvtepi64_storeu_epi16 =
      __mm_mask_cvtepi64_storeu_epi16Ptr
          .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m128i)>();

  void _mm256_mask_cvtepi64_storeu_epi16(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cvtepi64_storeu_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtepi64_storeu_epi16Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8,
              __m256i)>>('_mm256_mask_cvtepi64_storeu_epi16');
  late final __mm256_mask_cvtepi64_storeu_epi16 =
      __mm256_mask_cvtepi64_storeu_epi16Ptr
          .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m256i)>();

  void _mm_mask_cvtepi64_storeu_epi32(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cvtepi64_storeu_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtepi64_storeu_epi32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8,
              __m128i)>>('_mm_mask_cvtepi64_storeu_epi32');
  late final __mm_mask_cvtepi64_storeu_epi32 =
      __mm_mask_cvtepi64_storeu_epi32Ptr
          .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m128i)>();

  void _mm256_mask_cvtepi64_storeu_epi32(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cvtepi64_storeu_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtepi64_storeu_epi32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8,
              __m256i)>>('_mm256_mask_cvtepi64_storeu_epi32');
  late final __mm256_mask_cvtepi64_storeu_epi32 =
      __mm256_mask_cvtepi64_storeu_epi32Ptr
          .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m256i)>();

  void _mm_mask_cvtepi64_storeu_epi8(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cvtepi64_storeu_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtepi64_storeu_epi8Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8,
              __m128i)>>('_mm_mask_cvtepi64_storeu_epi8');
  late final __mm_mask_cvtepi64_storeu_epi8 = __mm_mask_cvtepi64_storeu_epi8Ptr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m128i)>();

  void _mm256_mask_cvtepi64_storeu_epi8(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cvtepi64_storeu_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtepi64_storeu_epi8Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8,
              __m256i)>>('_mm256_mask_cvtepi64_storeu_epi8');
  late final __mm256_mask_cvtepi64_storeu_epi8 =
      __mm256_mask_cvtepi64_storeu_epi8Ptr
          .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m256i)>();

  __m128i _mm_mask_cvtepi8_epi16(
    __m128i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cvtepi8_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtepi8_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m128i)>>(
          '_mm_mask_cvtepi8_epi16');
  late final __mm_mask_cvtepi8_epi16 = __mm_mask_cvtepi8_epi16Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i)>();

  __m128i _mm_maskz_cvtepi8_epi16(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_cvtepi8_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvtepi8_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i)>>(
          '_mm_maskz_cvtepi8_epi16');
  late final __mm_maskz_cvtepi8_epi16 =
      __mm_maskz_cvtepi8_epi16Ptr.asFunction<__m128i Function(int, __m128i)>();

  __m256i _mm256_mask_cvtepi8_epi16(
    __m256i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm256_mask_cvtepi8_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtepi8_epi16Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__m256i, __mmask16, __m128i)>>(
      '_mm256_mask_cvtepi8_epi16');
  late final __mm256_mask_cvtepi8_epi16 = __mm256_mask_cvtepi8_epi16Ptr
      .asFunction<__m256i Function(__m256i, int, __m128i)>();

  __m256i _mm256_maskz_cvtepi8_epi16(
    int arg0,
    __m128i arg1,
  ) {
    return __mm256_maskz_cvtepi8_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvtepi8_epi16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask16, __m128i)>>(
          '_mm256_maskz_cvtepi8_epi16');
  late final __mm256_maskz_cvtepi8_epi16 = __mm256_maskz_cvtepi8_epi16Ptr
      .asFunction<__m256i Function(int, __m128i)>();

  __m128i _mm_mask_cvtepi8_epi32(
    __m128i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cvtepi8_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtepi8_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m128i)>>(
          '_mm_mask_cvtepi8_epi32');
  late final __mm_mask_cvtepi8_epi32 = __mm_mask_cvtepi8_epi32Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i)>();

  __m128i _mm_maskz_cvtepi8_epi32(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_cvtepi8_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvtepi8_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i)>>(
          '_mm_maskz_cvtepi8_epi32');
  late final __mm_maskz_cvtepi8_epi32 =
      __mm_maskz_cvtepi8_epi32Ptr.asFunction<__m128i Function(int, __m128i)>();

  __m256i _mm256_mask_cvtepi8_epi32(
    __m256i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm256_mask_cvtepi8_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtepi8_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __mmask8, __m128i)>>(
          '_mm256_mask_cvtepi8_epi32');
  late final __mm256_mask_cvtepi8_epi32 = __mm256_mask_cvtepi8_epi32Ptr
      .asFunction<__m256i Function(__m256i, int, __m128i)>();

  __m256i _mm256_maskz_cvtepi8_epi32(
    int arg0,
    __m128i arg1,
  ) {
    return __mm256_maskz_cvtepi8_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvtepi8_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m128i)>>(
          '_mm256_maskz_cvtepi8_epi32');
  late final __mm256_maskz_cvtepi8_epi32 = __mm256_maskz_cvtepi8_epi32Ptr
      .asFunction<__m256i Function(int, __m128i)>();

  __m128i _mm_mask_cvtepi8_epi64(
    __m128i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cvtepi8_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtepi8_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m128i)>>(
          '_mm_mask_cvtepi8_epi64');
  late final __mm_mask_cvtepi8_epi64 = __mm_mask_cvtepi8_epi64Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i)>();

  __m128i _mm_maskz_cvtepi8_epi64(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_cvtepi8_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvtepi8_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i)>>(
          '_mm_maskz_cvtepi8_epi64');
  late final __mm_maskz_cvtepi8_epi64 =
      __mm_maskz_cvtepi8_epi64Ptr.asFunction<__m128i Function(int, __m128i)>();

  __m256i _mm256_mask_cvtepi8_epi64(
    __m256i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm256_mask_cvtepi8_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtepi8_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __mmask8, __m128i)>>(
          '_mm256_mask_cvtepi8_epi64');
  late final __mm256_mask_cvtepi8_epi64 = __mm256_mask_cvtepi8_epi64Ptr
      .asFunction<__m256i Function(__m256i, int, __m128i)>();

  __m256i _mm256_maskz_cvtepi8_epi64(
    int arg0,
    __m128i arg1,
  ) {
    return __mm256_maskz_cvtepi8_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvtepi8_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m128i)>>(
          '_mm256_maskz_cvtepi8_epi64');
  late final __mm256_maskz_cvtepi8_epi64 = __mm256_maskz_cvtepi8_epi64Ptr
      .asFunction<__m256i Function(int, __m128i)>();

  __m128i _mm_mask_cvtepu16_epi32(
    __m128i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cvtepu16_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtepu16_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m128i)>>(
          '_mm_mask_cvtepu16_epi32');
  late final __mm_mask_cvtepu16_epi32 = __mm_mask_cvtepu16_epi32Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i)>();

  __m128i _mm_maskz_cvtepu16_epi32(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_cvtepu16_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvtepu16_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i)>>(
          '_mm_maskz_cvtepu16_epi32');
  late final __mm_maskz_cvtepu16_epi32 =
      __mm_maskz_cvtepu16_epi32Ptr.asFunction<__m128i Function(int, __m128i)>();

  __m256i _mm256_mask_cvtepu16_epi32(
    __m256i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm256_mask_cvtepu16_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtepu16_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __mmask8, __m128i)>>(
          '_mm256_mask_cvtepu16_epi32');
  late final __mm256_mask_cvtepu16_epi32 = __mm256_mask_cvtepu16_epi32Ptr
      .asFunction<__m256i Function(__m256i, int, __m128i)>();

  __m256i _mm256_maskz_cvtepu16_epi32(
    int arg0,
    __m128i arg1,
  ) {
    return __mm256_maskz_cvtepu16_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvtepu16_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m128i)>>(
          '_mm256_maskz_cvtepu16_epi32');
  late final __mm256_maskz_cvtepu16_epi32 = __mm256_maskz_cvtepu16_epi32Ptr
      .asFunction<__m256i Function(int, __m128i)>();

  __m128i _mm_mask_cvtepu16_epi64(
    __m128i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cvtepu16_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtepu16_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m128i)>>(
          '_mm_mask_cvtepu16_epi64');
  late final __mm_mask_cvtepu16_epi64 = __mm_mask_cvtepu16_epi64Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i)>();

  __m128i _mm_maskz_cvtepu16_epi64(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_cvtepu16_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvtepu16_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i)>>(
          '_mm_maskz_cvtepu16_epi64');
  late final __mm_maskz_cvtepu16_epi64 =
      __mm_maskz_cvtepu16_epi64Ptr.asFunction<__m128i Function(int, __m128i)>();

  __m256i _mm256_mask_cvtepu16_epi64(
    __m256i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm256_mask_cvtepu16_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtepu16_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __mmask8, __m128i)>>(
          '_mm256_mask_cvtepu16_epi64');
  late final __mm256_mask_cvtepu16_epi64 = __mm256_mask_cvtepu16_epi64Ptr
      .asFunction<__m256i Function(__m256i, int, __m128i)>();

  __m256i _mm256_maskz_cvtepu16_epi64(
    int arg0,
    __m128i arg1,
  ) {
    return __mm256_maskz_cvtepu16_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvtepu16_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m128i)>>(
          '_mm256_maskz_cvtepu16_epi64');
  late final __mm256_maskz_cvtepu16_epi64 = __mm256_maskz_cvtepu16_epi64Ptr
      .asFunction<__m256i Function(int, __m128i)>();

  __m128i _mm_mask_cvtepu32_epi64(
    __m128i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cvtepu32_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtepu32_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m128i)>>(
          '_mm_mask_cvtepu32_epi64');
  late final __mm_mask_cvtepu32_epi64 = __mm_mask_cvtepu32_epi64Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i)>();

  __m128i _mm_maskz_cvtepu32_epi64(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_cvtepu32_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvtepu32_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i)>>(
          '_mm_maskz_cvtepu32_epi64');
  late final __mm_maskz_cvtepu32_epi64 =
      __mm_maskz_cvtepu32_epi64Ptr.asFunction<__m128i Function(int, __m128i)>();

  __m256i _mm256_mask_cvtepu32_epi64(
    __m256i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm256_mask_cvtepu32_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtepu32_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __mmask8, __m128i)>>(
          '_mm256_mask_cvtepu32_epi64');
  late final __mm256_mask_cvtepu32_epi64 = __mm256_mask_cvtepu32_epi64Ptr
      .asFunction<__m256i Function(__m256i, int, __m128i)>();

  __m256i _mm256_maskz_cvtepu32_epi64(
    int arg0,
    __m128i arg1,
  ) {
    return __mm256_maskz_cvtepu32_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvtepu32_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m128i)>>(
          '_mm256_maskz_cvtepu32_epi64');
  late final __mm256_maskz_cvtepu32_epi64 = __mm256_maskz_cvtepu32_epi64Ptr
      .asFunction<__m256i Function(int, __m128i)>();

  __m128 _mm_cvtepu32_ps(
    __m128i arg0,
  ) {
    return __mm_cvtepu32_ps(
      arg0,
    );
  }

  late final __mm_cvtepu32_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128i)>>('_mm_cvtepu32_ps');
  late final __mm_cvtepu32_ps =
      __mm_cvtepu32_psPtr.asFunction<__m128 Function(__m128i)>();

  __m128 _mm_mask_cvtepu32_ps(
    __m128 arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cvtepu32_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtepu32_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __mmask8, __m128i)>>(
          '_mm_mask_cvtepu32_ps');
  late final __mm_mask_cvtepu32_ps = __mm_mask_cvtepu32_psPtr
      .asFunction<__m128 Function(__m128, int, __m128i)>();

  __m128 _mm_maskz_cvtepu32_ps(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_cvtepu32_ps(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvtepu32_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__mmask8, __m128i)>>(
          '_mm_maskz_cvtepu32_ps');
  late final __mm_maskz_cvtepu32_ps =
      __mm_maskz_cvtepu32_psPtr.asFunction<__m128 Function(int, __m128i)>();

  __m256 _mm256_cvtepu32_ps(
    __m256i arg0,
  ) {
    return __mm256_cvtepu32_ps(
      arg0,
    );
  }

  late final __mm256_cvtepu32_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256i)>>(
          '_mm256_cvtepu32_ps');
  late final __mm256_cvtepu32_ps =
      __mm256_cvtepu32_psPtr.asFunction<__m256 Function(__m256i)>();

  __m256 _mm256_mask_cvtepu32_ps(
    __m256 arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cvtepu32_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtepu32_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256, __mmask8, __m256i)>>(
          '_mm256_mask_cvtepu32_ps');
  late final __mm256_mask_cvtepu32_ps = __mm256_mask_cvtepu32_psPtr
      .asFunction<__m256 Function(__m256, int, __m256i)>();

  __m256 _mm256_maskz_cvtepu32_ps(
    int arg0,
    __m256i arg1,
  ) {
    return __mm256_maskz_cvtepu32_ps(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvtepu32_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__mmask8, __m256i)>>(
          '_mm256_maskz_cvtepu32_ps');
  late final __mm256_maskz_cvtepu32_ps =
      __mm256_maskz_cvtepu32_psPtr.asFunction<__m256 Function(int, __m256i)>();

  _m128d _mm_cvtepu32_pd(
    __m128i arg0,
  ) {
    return __mm_cvtepu32_pd(
      arg0,
    );
  }

  late final __mm_cvtepu32_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(__m128i)>>('_mm_cvtepu32_pd');
  late final __mm_cvtepu32_pd =
      __mm_cvtepu32_pdPtr.asFunction<_m128d Function(__m128i)>();

  _m128d _mm_mask_cvtepu32_pd(
    _m128d arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cvtepu32_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtepu32_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, __mmask8, __m128i)>>(
          '_mm_mask_cvtepu32_pd');
  late final __mm_mask_cvtepu32_pd = __mm_mask_cvtepu32_pdPtr
      .asFunction<_m128d Function(_m128d, int, __m128i)>();

  _m128d _mm_maskz_cvtepu32_pd(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_cvtepu32_pd(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvtepu32_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(__mmask8, __m128i)>>(
          '_mm_maskz_cvtepu32_pd');
  late final __mm_maskz_cvtepu32_pd =
      __mm_maskz_cvtepu32_pdPtr.asFunction<_m128d Function(int, __m128i)>();

  _m256d _mm256_cvtepu32_pd(
    __m128i arg0,
  ) {
    return __mm256_cvtepu32_pd(
      arg0,
    );
  }

  late final __mm256_cvtepu32_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(__m128i)>>(
          '_mm256_cvtepu32_pd');
  late final __mm256_cvtepu32_pd =
      __mm256_cvtepu32_pdPtr.asFunction<_m256d Function(__m128i)>();

  _m256d _mm256_mask_cvtepu32_pd(
    _m256d arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm256_mask_cvtepu32_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtepu32_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d, __mmask8, __m128i)>>(
          '_mm256_mask_cvtepu32_pd');
  late final __mm256_mask_cvtepu32_pd = __mm256_mask_cvtepu32_pdPtr
      .asFunction<_m256d Function(_m256d, int, __m128i)>();

  _m256d _mm256_maskz_cvtepu32_pd(
    int arg0,
    __m128i arg1,
  ) {
    return __mm256_maskz_cvtepu32_pd(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvtepu32_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(__mmask8, __m128i)>>(
          '_mm256_maskz_cvtepu32_pd');
  late final __mm256_maskz_cvtepu32_pd =
      __mm256_maskz_cvtepu32_pdPtr.asFunction<_m256d Function(int, __m128i)>();

  _m128d _mm_cvtepu64_pd(
    __m128i arg0,
  ) {
    return __mm_cvtepu64_pd(
      arg0,
    );
  }

  late final __mm_cvtepu64_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(__m128i)>>('_mm_cvtepu64_pd');
  late final __mm_cvtepu64_pd =
      __mm_cvtepu64_pdPtr.asFunction<_m128d Function(__m128i)>();

  _m128d _mm_mask_cvtepu64_pd(
    _m128d arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cvtepu64_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtepu64_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, __mmask8, __m128i)>>(
          '_mm_mask_cvtepu64_pd');
  late final __mm_mask_cvtepu64_pd = __mm_mask_cvtepu64_pdPtr
      .asFunction<_m128d Function(_m128d, int, __m128i)>();

  _m128d _mm_maskz_cvtepu64_pd(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_cvtepu64_pd(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvtepu64_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(__mmask8, __m128i)>>(
          '_mm_maskz_cvtepu64_pd');
  late final __mm_maskz_cvtepu64_pd =
      __mm_maskz_cvtepu64_pdPtr.asFunction<_m128d Function(int, __m128i)>();

  _m256d _mm256_cvtepu64_pd(
    __m256i arg0,
  ) {
    return __mm256_cvtepu64_pd(
      arg0,
    );
  }

  late final __mm256_cvtepu64_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(__m256i)>>(
          '_mm256_cvtepu64_pd');
  late final __mm256_cvtepu64_pd =
      __mm256_cvtepu64_pdPtr.asFunction<_m256d Function(__m256i)>();

  _m256d _mm256_mask_cvtepu64_pd(
    _m256d arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cvtepu64_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtepu64_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d, __mmask8, __m256i)>>(
          '_mm256_mask_cvtepu64_pd');
  late final __mm256_mask_cvtepu64_pd = __mm256_mask_cvtepu64_pdPtr
      .asFunction<_m256d Function(_m256d, int, __m256i)>();

  _m256d _mm256_maskz_cvtepu64_pd(
    int arg0,
    __m256i arg1,
  ) {
    return __mm256_maskz_cvtepu64_pd(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvtepu64_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(__mmask8, __m256i)>>(
          '_mm256_maskz_cvtepu64_pd');
  late final __mm256_maskz_cvtepu64_pd =
      __mm256_maskz_cvtepu64_pdPtr.asFunction<_m256d Function(int, __m256i)>();

  __m128 _mm_cvtepu64_ps(
    __m128i arg0,
  ) {
    return __mm_cvtepu64_ps(
      arg0,
    );
  }

  late final __mm_cvtepu64_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128i)>>('_mm_cvtepu64_ps');
  late final __mm_cvtepu64_ps =
      __mm_cvtepu64_psPtr.asFunction<__m128 Function(__m128i)>();

  __m128 _mm_mask_cvtepu64_ps(
    __m128 arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cvtepu64_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtepu64_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __mmask8, __m128i)>>(
          '_mm_mask_cvtepu64_ps');
  late final __mm_mask_cvtepu64_ps = __mm_mask_cvtepu64_psPtr
      .asFunction<__m128 Function(__m128, int, __m128i)>();

  __m128 _mm_maskz_cvtepu64_ps(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_cvtepu64_ps(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvtepu64_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__mmask8, __m128i)>>(
          '_mm_maskz_cvtepu64_ps');
  late final __mm_maskz_cvtepu64_ps =
      __mm_maskz_cvtepu64_psPtr.asFunction<__m128 Function(int, __m128i)>();

  __m128 _mm256_cvtepu64_ps(
    __m256i arg0,
  ) {
    return __mm256_cvtepu64_ps(
      arg0,
    );
  }

  late final __mm256_cvtepu64_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m256i)>>(
          '_mm256_cvtepu64_ps');
  late final __mm256_cvtepu64_ps =
      __mm256_cvtepu64_psPtr.asFunction<__m128 Function(__m256i)>();

  __m128 _mm256_mask_cvtepu64_ps(
    __m128 arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cvtepu64_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtepu64_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __mmask8, __m256i)>>(
          '_mm256_mask_cvtepu64_ps');
  late final __mm256_mask_cvtepu64_ps = __mm256_mask_cvtepu64_psPtr
      .asFunction<__m128 Function(__m128, int, __m256i)>();

  __m128 _mm256_maskz_cvtepu64_ps(
    int arg0,
    __m256i arg1,
  ) {
    return __mm256_maskz_cvtepu64_ps(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvtepu64_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__mmask8, __m256i)>>(
          '_mm256_maskz_cvtepu64_ps');
  late final __mm256_maskz_cvtepu64_ps =
      __mm256_maskz_cvtepu64_psPtr.asFunction<__m128 Function(int, __m256i)>();

  __m128i _mm_mask_cvtepu8_epi16(
    __m128i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cvtepu8_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtepu8_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m128i)>>(
          '_mm_mask_cvtepu8_epi16');
  late final __mm_mask_cvtepu8_epi16 = __mm_mask_cvtepu8_epi16Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i)>();

  __m128i _mm_maskz_cvtepu8_epi16(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_cvtepu8_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvtepu8_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i)>>(
          '_mm_maskz_cvtepu8_epi16');
  late final __mm_maskz_cvtepu8_epi16 =
      __mm_maskz_cvtepu8_epi16Ptr.asFunction<__m128i Function(int, __m128i)>();

  __m256i _mm256_mask_cvtepu8_epi16(
    __m256i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm256_mask_cvtepu8_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtepu8_epi16Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__m256i, __mmask16, __m128i)>>(
      '_mm256_mask_cvtepu8_epi16');
  late final __mm256_mask_cvtepu8_epi16 = __mm256_mask_cvtepu8_epi16Ptr
      .asFunction<__m256i Function(__m256i, int, __m128i)>();

  __m256i _mm256_maskz_cvtepu8_epi16(
    int arg0,
    __m128i arg1,
  ) {
    return __mm256_maskz_cvtepu8_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvtepu8_epi16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask16, __m128i)>>(
          '_mm256_maskz_cvtepu8_epi16');
  late final __mm256_maskz_cvtepu8_epi16 = __mm256_maskz_cvtepu8_epi16Ptr
      .asFunction<__m256i Function(int, __m128i)>();

  __m128i _mm_mask_cvtepu8_epi32(
    __m128i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cvtepu8_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtepu8_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m128i)>>(
          '_mm_mask_cvtepu8_epi32');
  late final __mm_mask_cvtepu8_epi32 = __mm_mask_cvtepu8_epi32Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i)>();

  __m128i _mm_maskz_cvtepu8_epi32(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_cvtepu8_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvtepu8_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i)>>(
          '_mm_maskz_cvtepu8_epi32');
  late final __mm_maskz_cvtepu8_epi32 =
      __mm_maskz_cvtepu8_epi32Ptr.asFunction<__m128i Function(int, __m128i)>();

  __m256i _mm256_mask_cvtepu8_epi32(
    __m256i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm256_mask_cvtepu8_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtepu8_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __mmask8, __m128i)>>(
          '_mm256_mask_cvtepu8_epi32');
  late final __mm256_mask_cvtepu8_epi32 = __mm256_mask_cvtepu8_epi32Ptr
      .asFunction<__m256i Function(__m256i, int, __m128i)>();

  __m256i _mm256_maskz_cvtepu8_epi32(
    int arg0,
    __m128i arg1,
  ) {
    return __mm256_maskz_cvtepu8_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvtepu8_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m128i)>>(
          '_mm256_maskz_cvtepu8_epi32');
  late final __mm256_maskz_cvtepu8_epi32 = __mm256_maskz_cvtepu8_epi32Ptr
      .asFunction<__m256i Function(int, __m128i)>();

  __m128i _mm_mask_cvtepu8_epi64(
    __m128i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cvtepu8_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtepu8_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m128i)>>(
          '_mm_mask_cvtepu8_epi64');
  late final __mm_mask_cvtepu8_epi64 = __mm_mask_cvtepu8_epi64Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i)>();

  __m128i _mm_maskz_cvtepu8_epi64(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_cvtepu8_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvtepu8_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i)>>(
          '_mm_maskz_cvtepu8_epi64');
  late final __mm_maskz_cvtepu8_epi64 =
      __mm_maskz_cvtepu8_epi64Ptr.asFunction<__m128i Function(int, __m128i)>();

  __m256i _mm256_mask_cvtepu8_epi64(
    __m256i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm256_mask_cvtepu8_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtepu8_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __mmask8, __m128i)>>(
          '_mm256_mask_cvtepu8_epi64');
  late final __mm256_mask_cvtepu8_epi64 = __mm256_mask_cvtepu8_epi64Ptr
      .asFunction<__m256i Function(__m256i, int, __m128i)>();

  __m256i _mm256_maskz_cvtepu8_epi64(
    int arg0,
    __m128i arg1,
  ) {
    return __mm256_maskz_cvtepu8_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvtepu8_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m128i)>>(
          '_mm256_maskz_cvtepu8_epi64');
  late final __mm256_maskz_cvtepu8_epi64 = __mm256_maskz_cvtepu8_epi64Ptr
      .asFunction<__m256i Function(int, __m128i)>();

  __m128i _mm_mask_cvtpd_epi32(
    __m128i arg0,
    int arg1,
    _m128d arg2,
  ) {
    return __mm_mask_cvtpd_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtpd_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, _m128d)>>(
          '_mm_mask_cvtpd_epi32');
  late final __mm_mask_cvtpd_epi32 = __mm_mask_cvtpd_epi32Ptr
      .asFunction<__m128i Function(__m128i, int, _m128d)>();

  __m128i _mm_maskz_cvtpd_epi32(
    int arg0,
    _m128d arg1,
  ) {
    return __mm_maskz_cvtpd_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvtpd_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, _m128d)>>(
          '_mm_maskz_cvtpd_epi32');
  late final __mm_maskz_cvtpd_epi32 =
      __mm_maskz_cvtpd_epi32Ptr.asFunction<__m128i Function(int, _m128d)>();

  __m128i _mm256_mask_cvtpd_epi32(
    __m128i arg0,
    int arg1,
    _m256d arg2,
  ) {
    return __mm256_mask_cvtpd_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtpd_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, _m256d)>>(
          '_mm256_mask_cvtpd_epi32');
  late final __mm256_mask_cvtpd_epi32 = __mm256_mask_cvtpd_epi32Ptr
      .asFunction<__m128i Function(__m128i, int, _m256d)>();

  __m128i _mm256_maskz_cvtpd_epi32(
    int arg0,
    _m256d arg1,
  ) {
    return __mm256_maskz_cvtpd_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvtpd_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, _m256d)>>(
          '_mm256_maskz_cvtpd_epi32');
  late final __mm256_maskz_cvtpd_epi32 =
      __mm256_maskz_cvtpd_epi32Ptr.asFunction<__m128i Function(int, _m256d)>();

  __m128i _mm_cvtpd_epi64(
    _m128d arg0,
  ) {
    return __mm_cvtpd_epi64(
      arg0,
    );
  }

  late final __mm_cvtpd_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(_m128d)>>('_mm_cvtpd_epi64');
  late final __mm_cvtpd_epi64 =
      __mm_cvtpd_epi64Ptr.asFunction<__m128i Function(_m128d)>();

  __m128i _mm_mask_cvtpd_epi64(
    __m128i arg0,
    int arg1,
    _m128d arg2,
  ) {
    return __mm_mask_cvtpd_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtpd_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, _m128d)>>(
          '_mm_mask_cvtpd_epi64');
  late final __mm_mask_cvtpd_epi64 = __mm_mask_cvtpd_epi64Ptr
      .asFunction<__m128i Function(__m128i, int, _m128d)>();

  __m128i _mm_maskz_cvtpd_epi64(
    int arg0,
    _m128d arg1,
  ) {
    return __mm_maskz_cvtpd_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvtpd_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, _m128d)>>(
          '_mm_maskz_cvtpd_epi64');
  late final __mm_maskz_cvtpd_epi64 =
      __mm_maskz_cvtpd_epi64Ptr.asFunction<__m128i Function(int, _m128d)>();

  __m256i _mm256_cvtpd_epi64(
    _m256d arg0,
  ) {
    return __mm256_cvtpd_epi64(
      arg0,
    );
  }

  late final __mm256_cvtpd_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(_m256d)>>(
          '_mm256_cvtpd_epi64');
  late final __mm256_cvtpd_epi64 =
      __mm256_cvtpd_epi64Ptr.asFunction<__m256i Function(_m256d)>();

  __m256i _mm256_mask_cvtpd_epi64(
    __m256i arg0,
    int arg1,
    _m256d arg2,
  ) {
    return __mm256_mask_cvtpd_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtpd_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __mmask8, _m256d)>>(
          '_mm256_mask_cvtpd_epi64');
  late final __mm256_mask_cvtpd_epi64 = __mm256_mask_cvtpd_epi64Ptr
      .asFunction<__m256i Function(__m256i, int, _m256d)>();

  __m256i _mm256_maskz_cvtpd_epi64(
    int arg0,
    _m256d arg1,
  ) {
    return __mm256_maskz_cvtpd_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvtpd_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, _m256d)>>(
          '_mm256_maskz_cvtpd_epi64');
  late final __mm256_maskz_cvtpd_epi64 =
      __mm256_maskz_cvtpd_epi64Ptr.asFunction<__m256i Function(int, _m256d)>();

  __m128i _mm_cvtpd_epu32(
    _m128d arg0,
  ) {
    return __mm_cvtpd_epu32(
      arg0,
    );
  }

  late final __mm_cvtpd_epu32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(_m128d)>>('_mm_cvtpd_epu32');
  late final __mm_cvtpd_epu32 =
      __mm_cvtpd_epu32Ptr.asFunction<__m128i Function(_m128d)>();

  __m128i _mm_mask_cvtpd_epu32(
    __m128i arg0,
    int arg1,
    _m128d arg2,
  ) {
    return __mm_mask_cvtpd_epu32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtpd_epu32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, _m128d)>>(
          '_mm_mask_cvtpd_epu32');
  late final __mm_mask_cvtpd_epu32 = __mm_mask_cvtpd_epu32Ptr
      .asFunction<__m128i Function(__m128i, int, _m128d)>();

  __m128i _mm_maskz_cvtpd_epu32(
    int arg0,
    _m128d arg1,
  ) {
    return __mm_maskz_cvtpd_epu32(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvtpd_epu32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, _m128d)>>(
          '_mm_maskz_cvtpd_epu32');
  late final __mm_maskz_cvtpd_epu32 =
      __mm_maskz_cvtpd_epu32Ptr.asFunction<__m128i Function(int, _m128d)>();

  __m128i _mm256_cvtpd_epu32(
    _m256d arg0,
  ) {
    return __mm256_cvtpd_epu32(
      arg0,
    );
  }

  late final __mm256_cvtpd_epu32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(_m256d)>>(
          '_mm256_cvtpd_epu32');
  late final __mm256_cvtpd_epu32 =
      __mm256_cvtpd_epu32Ptr.asFunction<__m128i Function(_m256d)>();

  __m128i _mm256_mask_cvtpd_epu32(
    __m128i arg0,
    int arg1,
    _m256d arg2,
  ) {
    return __mm256_mask_cvtpd_epu32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtpd_epu32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, _m256d)>>(
          '_mm256_mask_cvtpd_epu32');
  late final __mm256_mask_cvtpd_epu32 = __mm256_mask_cvtpd_epu32Ptr
      .asFunction<__m128i Function(__m128i, int, _m256d)>();

  __m128i _mm256_maskz_cvtpd_epu32(
    int arg0,
    _m256d arg1,
  ) {
    return __mm256_maskz_cvtpd_epu32(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvtpd_epu32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, _m256d)>>(
          '_mm256_maskz_cvtpd_epu32');
  late final __mm256_maskz_cvtpd_epu32 =
      __mm256_maskz_cvtpd_epu32Ptr.asFunction<__m128i Function(int, _m256d)>();

  __m128i _mm_cvtpd_epu64(
    _m128d arg0,
  ) {
    return __mm_cvtpd_epu64(
      arg0,
    );
  }

  late final __mm_cvtpd_epu64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(_m128d)>>('_mm_cvtpd_epu64');
  late final __mm_cvtpd_epu64 =
      __mm_cvtpd_epu64Ptr.asFunction<__m128i Function(_m128d)>();

  __m128i _mm_mask_cvtpd_epu64(
    __m128i arg0,
    int arg1,
    _m128d arg2,
  ) {
    return __mm_mask_cvtpd_epu64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtpd_epu64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, _m128d)>>(
          '_mm_mask_cvtpd_epu64');
  late final __mm_mask_cvtpd_epu64 = __mm_mask_cvtpd_epu64Ptr
      .asFunction<__m128i Function(__m128i, int, _m128d)>();

  __m128i _mm_maskz_cvtpd_epu64(
    int arg0,
    _m128d arg1,
  ) {
    return __mm_maskz_cvtpd_epu64(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvtpd_epu64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, _m128d)>>(
          '_mm_maskz_cvtpd_epu64');
  late final __mm_maskz_cvtpd_epu64 =
      __mm_maskz_cvtpd_epu64Ptr.asFunction<__m128i Function(int, _m128d)>();

  __m256i _mm256_cvtpd_epu64(
    _m256d arg0,
  ) {
    return __mm256_cvtpd_epu64(
      arg0,
    );
  }

  late final __mm256_cvtpd_epu64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(_m256d)>>(
          '_mm256_cvtpd_epu64');
  late final __mm256_cvtpd_epu64 =
      __mm256_cvtpd_epu64Ptr.asFunction<__m256i Function(_m256d)>();

  __m256i _mm256_mask_cvtpd_epu64(
    __m256i arg0,
    int arg1,
    _m256d arg2,
  ) {
    return __mm256_mask_cvtpd_epu64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtpd_epu64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __mmask8, _m256d)>>(
          '_mm256_mask_cvtpd_epu64');
  late final __mm256_mask_cvtpd_epu64 = __mm256_mask_cvtpd_epu64Ptr
      .asFunction<__m256i Function(__m256i, int, _m256d)>();

  __m256i _mm256_maskz_cvtpd_epu64(
    int arg0,
    _m256d arg1,
  ) {
    return __mm256_maskz_cvtpd_epu64(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvtpd_epu64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, _m256d)>>(
          '_mm256_maskz_cvtpd_epu64');
  late final __mm256_maskz_cvtpd_epu64 =
      __mm256_maskz_cvtpd_epu64Ptr.asFunction<__m256i Function(int, _m256d)>();

  __m128 _mm_mask_cvtpd_ps(
    __m128 arg0,
    int arg1,
    _m128d arg2,
  ) {
    return __mm_mask_cvtpd_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtpd_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __mmask8, _m128d)>>(
          '_mm_mask_cvtpd_ps');
  late final __mm_mask_cvtpd_ps =
      __mm_mask_cvtpd_psPtr.asFunction<__m128 Function(__m128, int, _m128d)>();

  __m128 _mm_maskz_cvtpd_ps(
    int arg0,
    _m128d arg1,
  ) {
    return __mm_maskz_cvtpd_ps(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvtpd_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__mmask8, _m128d)>>(
          '_mm_maskz_cvtpd_ps');
  late final __mm_maskz_cvtpd_ps =
      __mm_maskz_cvtpd_psPtr.asFunction<__m128 Function(int, _m128d)>();

  __m128 _mm256_mask_cvtpd_ps(
    __m128 arg0,
    int arg1,
    _m256d arg2,
  ) {
    return __mm256_mask_cvtpd_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtpd_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __mmask8, _m256d)>>(
          '_mm256_mask_cvtpd_ps');
  late final __mm256_mask_cvtpd_ps = __mm256_mask_cvtpd_psPtr
      .asFunction<__m128 Function(__m128, int, _m256d)>();

  __m128 _mm256_maskz_cvtpd_ps(
    int arg0,
    _m256d arg1,
  ) {
    return __mm256_maskz_cvtpd_ps(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvtpd_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__mmask8, _m256d)>>(
          '_mm256_maskz_cvtpd_ps');
  late final __mm256_maskz_cvtpd_ps =
      __mm256_maskz_cvtpd_psPtr.asFunction<__m128 Function(int, _m256d)>();

  __m128 _mm_mask_cvtph_ps(
    __m128 arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cvtph_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtph_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __mmask8, __m128i)>>(
          '_mm_mask_cvtph_ps');
  late final __mm_mask_cvtph_ps =
      __mm_mask_cvtph_psPtr.asFunction<__m128 Function(__m128, int, __m128i)>();

  __m128 _mm_maskz_cvtph_ps(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_cvtph_ps(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvtph_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__mmask8, __m128i)>>(
          '_mm_maskz_cvtph_ps');
  late final __mm_maskz_cvtph_ps =
      __mm_maskz_cvtph_psPtr.asFunction<__m128 Function(int, __m128i)>();

  __m256 _mm256_mask_cvtph_ps(
    __m256 arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm256_mask_cvtph_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtph_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256, __mmask8, __m128i)>>(
          '_mm256_mask_cvtph_ps');
  late final __mm256_mask_cvtph_ps = __mm256_mask_cvtph_psPtr
      .asFunction<__m256 Function(__m256, int, __m128i)>();

  __m256 _mm256_maskz_cvtph_ps(
    int arg0,
    __m128i arg1,
  ) {
    return __mm256_maskz_cvtph_ps(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvtph_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__mmask8, __m128i)>>(
          '_mm256_maskz_cvtph_ps');
  late final __mm256_maskz_cvtph_ps =
      __mm256_maskz_cvtph_psPtr.asFunction<__m256 Function(int, __m128i)>();

  __m128i _mm_mask_cvtps_epi32(
    __m128i arg0,
    int arg1,
    __m128 arg2,
  ) {
    return __mm_mask_cvtps_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtps_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m128)>>(
          '_mm_mask_cvtps_epi32');
  late final __mm_mask_cvtps_epi32 = __mm_mask_cvtps_epi32Ptr
      .asFunction<__m128i Function(__m128i, int, __m128)>();

  __m128i _mm_maskz_cvtps_epi32(
    int arg0,
    __m128 arg1,
  ) {
    return __mm_maskz_cvtps_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvtps_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128)>>(
          '_mm_maskz_cvtps_epi32');
  late final __mm_maskz_cvtps_epi32 =
      __mm_maskz_cvtps_epi32Ptr.asFunction<__m128i Function(int, __m128)>();

  __m256i _mm256_mask_cvtps_epi32(
    __m256i arg0,
    int arg1,
    __m256 arg2,
  ) {
    return __mm256_mask_cvtps_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtps_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __mmask8, __m256)>>(
          '_mm256_mask_cvtps_epi32');
  late final __mm256_mask_cvtps_epi32 = __mm256_mask_cvtps_epi32Ptr
      .asFunction<__m256i Function(__m256i, int, __m256)>();

  __m256i _mm256_maskz_cvtps_epi32(
    int arg0,
    __m256 arg1,
  ) {
    return __mm256_maskz_cvtps_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvtps_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m256)>>(
          '_mm256_maskz_cvtps_epi32');
  late final __mm256_maskz_cvtps_epi32 =
      __mm256_maskz_cvtps_epi32Ptr.asFunction<__m256i Function(int, __m256)>();

  __m128i _mm_cvtps_epi64(
    __m128 arg0,
  ) {
    return __mm_cvtps_epi64(
      arg0,
    );
  }

  late final __mm_cvtps_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128)>>('_mm_cvtps_epi64');
  late final __mm_cvtps_epi64 =
      __mm_cvtps_epi64Ptr.asFunction<__m128i Function(__m128)>();

  __m128i _mm_mask_cvtps_epi64(
    __m128i arg0,
    int arg1,
    __m128 arg2,
  ) {
    return __mm_mask_cvtps_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtps_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m128)>>(
          '_mm_mask_cvtps_epi64');
  late final __mm_mask_cvtps_epi64 = __mm_mask_cvtps_epi64Ptr
      .asFunction<__m128i Function(__m128i, int, __m128)>();

  __m128i _mm_maskz_cvtps_epi64(
    int arg0,
    __m128 arg1,
  ) {
    return __mm_maskz_cvtps_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvtps_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128)>>(
          '_mm_maskz_cvtps_epi64');
  late final __mm_maskz_cvtps_epi64 =
      __mm_maskz_cvtps_epi64Ptr.asFunction<__m128i Function(int, __m128)>();

  __m256i _mm256_cvtps_epi64(
    __m128 arg0,
  ) {
    return __mm256_cvtps_epi64(
      arg0,
    );
  }

  late final __mm256_cvtps_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m128)>>(
          '_mm256_cvtps_epi64');
  late final __mm256_cvtps_epi64 =
      __mm256_cvtps_epi64Ptr.asFunction<__m256i Function(__m128)>();

  __m256i _mm256_mask_cvtps_epi64(
    __m256i arg0,
    int arg1,
    __m128 arg2,
  ) {
    return __mm256_mask_cvtps_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtps_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __mmask8, __m128)>>(
          '_mm256_mask_cvtps_epi64');
  late final __mm256_mask_cvtps_epi64 = __mm256_mask_cvtps_epi64Ptr
      .asFunction<__m256i Function(__m256i, int, __m128)>();

  __m256i _mm256_maskz_cvtps_epi64(
    int arg0,
    __m128 arg1,
  ) {
    return __mm256_maskz_cvtps_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvtps_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m128)>>(
          '_mm256_maskz_cvtps_epi64');
  late final __mm256_maskz_cvtps_epi64 =
      __mm256_maskz_cvtps_epi64Ptr.asFunction<__m256i Function(int, __m128)>();

  __m128i _mm_cvtps_epu32(
    __m128 arg0,
  ) {
    return __mm_cvtps_epu32(
      arg0,
    );
  }

  late final __mm_cvtps_epu32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128)>>('_mm_cvtps_epu32');
  late final __mm_cvtps_epu32 =
      __mm_cvtps_epu32Ptr.asFunction<__m128i Function(__m128)>();

  __m128i _mm_mask_cvtps_epu32(
    __m128i arg0,
    int arg1,
    __m128 arg2,
  ) {
    return __mm_mask_cvtps_epu32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtps_epu32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m128)>>(
          '_mm_mask_cvtps_epu32');
  late final __mm_mask_cvtps_epu32 = __mm_mask_cvtps_epu32Ptr
      .asFunction<__m128i Function(__m128i, int, __m128)>();

  __m128i _mm_maskz_cvtps_epu32(
    int arg0,
    __m128 arg1,
  ) {
    return __mm_maskz_cvtps_epu32(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvtps_epu32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128)>>(
          '_mm_maskz_cvtps_epu32');
  late final __mm_maskz_cvtps_epu32 =
      __mm_maskz_cvtps_epu32Ptr.asFunction<__m128i Function(int, __m128)>();

  __m256i _mm256_cvtps_epu32(
    __m256 arg0,
  ) {
    return __mm256_cvtps_epu32(
      arg0,
    );
  }

  late final __mm256_cvtps_epu32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256)>>(
          '_mm256_cvtps_epu32');
  late final __mm256_cvtps_epu32 =
      __mm256_cvtps_epu32Ptr.asFunction<__m256i Function(__m256)>();

  __m256i _mm256_mask_cvtps_epu32(
    __m256i arg0,
    int arg1,
    __m256 arg2,
  ) {
    return __mm256_mask_cvtps_epu32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtps_epu32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __mmask8, __m256)>>(
          '_mm256_mask_cvtps_epu32');
  late final __mm256_mask_cvtps_epu32 = __mm256_mask_cvtps_epu32Ptr
      .asFunction<__m256i Function(__m256i, int, __m256)>();

  __m256i _mm256_maskz_cvtps_epu32(
    int arg0,
    __m256 arg1,
  ) {
    return __mm256_maskz_cvtps_epu32(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvtps_epu32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m256)>>(
          '_mm256_maskz_cvtps_epu32');
  late final __mm256_maskz_cvtps_epu32 =
      __mm256_maskz_cvtps_epu32Ptr.asFunction<__m256i Function(int, __m256)>();

  __m128i _mm_cvtps_epu64(
    __m128 arg0,
  ) {
    return __mm_cvtps_epu64(
      arg0,
    );
  }

  late final __mm_cvtps_epu64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128)>>('_mm_cvtps_epu64');
  late final __mm_cvtps_epu64 =
      __mm_cvtps_epu64Ptr.asFunction<__m128i Function(__m128)>();

  __m128i _mm_mask_cvtps_epu64(
    __m128i arg0,
    int arg1,
    __m128 arg2,
  ) {
    return __mm_mask_cvtps_epu64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtps_epu64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m128)>>(
          '_mm_mask_cvtps_epu64');
  late final __mm_mask_cvtps_epu64 = __mm_mask_cvtps_epu64Ptr
      .asFunction<__m128i Function(__m128i, int, __m128)>();

  __m128i _mm_maskz_cvtps_epu64(
    int arg0,
    __m128 arg1,
  ) {
    return __mm_maskz_cvtps_epu64(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvtps_epu64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128)>>(
          '_mm_maskz_cvtps_epu64');
  late final __mm_maskz_cvtps_epu64 =
      __mm_maskz_cvtps_epu64Ptr.asFunction<__m128i Function(int, __m128)>();

  __m256i _mm256_cvtps_epu64(
    __m128 arg0,
  ) {
    return __mm256_cvtps_epu64(
      arg0,
    );
  }

  late final __mm256_cvtps_epu64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m128)>>(
          '_mm256_cvtps_epu64');
  late final __mm256_cvtps_epu64 =
      __mm256_cvtps_epu64Ptr.asFunction<__m256i Function(__m128)>();

  __m256i _mm256_mask_cvtps_epu64(
    __m256i arg0,
    int arg1,
    __m128 arg2,
  ) {
    return __mm256_mask_cvtps_epu64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtps_epu64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __mmask8, __m128)>>(
          '_mm256_mask_cvtps_epu64');
  late final __mm256_mask_cvtps_epu64 = __mm256_mask_cvtps_epu64Ptr
      .asFunction<__m256i Function(__m256i, int, __m128)>();

  __m256i _mm256_maskz_cvtps_epu64(
    int arg0,
    __m128 arg1,
  ) {
    return __mm256_maskz_cvtps_epu64(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvtps_epu64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m128)>>(
          '_mm256_maskz_cvtps_epu64');
  late final __mm256_maskz_cvtps_epu64 =
      __mm256_maskz_cvtps_epu64Ptr.asFunction<__m256i Function(int, __m128)>();

  _m128d _mm_mask_cvtps_pd(
    _m128d arg0,
    int arg1,
    __m128 arg2,
  ) {
    return __mm_mask_cvtps_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtps_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, __mmask8, __m128)>>(
          '_mm_mask_cvtps_pd');
  late final __mm_mask_cvtps_pd =
      __mm_mask_cvtps_pdPtr.asFunction<_m128d Function(_m128d, int, __m128)>();

  _m128d _mm_maskz_cvtps_pd(
    int arg0,
    __m128 arg1,
  ) {
    return __mm_maskz_cvtps_pd(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvtps_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(__mmask8, __m128)>>(
          '_mm_maskz_cvtps_pd');
  late final __mm_maskz_cvtps_pd =
      __mm_maskz_cvtps_pdPtr.asFunction<_m128d Function(int, __m128)>();

  _m256d _mm256_mask_cvtps_pd(
    _m256d arg0,
    int arg1,
    __m128 arg2,
  ) {
    return __mm256_mask_cvtps_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtps_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d, __mmask8, __m128)>>(
          '_mm256_mask_cvtps_pd');
  late final __mm256_mask_cvtps_pd = __mm256_mask_cvtps_pdPtr
      .asFunction<_m256d Function(_m256d, int, __m128)>();

  _m256d _mm256_maskz_cvtps_pd(
    int arg0,
    __m128 arg1,
  ) {
    return __mm256_maskz_cvtps_pd(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvtps_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(__mmask8, __m128)>>(
          '_mm256_maskz_cvtps_pd');
  late final __mm256_maskz_cvtps_pd =
      __mm256_maskz_cvtps_pdPtr.asFunction<_m256d Function(int, __m128)>();

  __m128i _mm_cvtsepi16_epi8(
    __m128i arg0,
  ) {
    return __mm_cvtsepi16_epi8(
      arg0,
    );
  }

  late final __mm_cvtsepi16_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i)>>(
          '_mm_cvtsepi16_epi8');
  late final __mm_cvtsepi16_epi8 =
      __mm_cvtsepi16_epi8Ptr.asFunction<__m128i Function(__m128i)>();

  __m128i _mm_mask_cvtsepi16_epi8(
    __m128i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cvtsepi16_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtsepi16_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m128i)>>(
          '_mm_mask_cvtsepi16_epi8');
  late final __mm_mask_cvtsepi16_epi8 = __mm_mask_cvtsepi16_epi8Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i)>();

  __m128i _mm_maskz_cvtsepi16_epi8(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_cvtsepi16_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvtsepi16_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i)>>(
          '_mm_maskz_cvtsepi16_epi8');
  late final __mm_maskz_cvtsepi16_epi8 =
      __mm_maskz_cvtsepi16_epi8Ptr.asFunction<__m128i Function(int, __m128i)>();

  __m128i _mm256_cvtsepi16_epi8(
    __m256i arg0,
  ) {
    return __mm256_cvtsepi16_epi8(
      arg0,
    );
  }

  late final __mm256_cvtsepi16_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m256i)>>(
          '_mm256_cvtsepi16_epi8');
  late final __mm256_cvtsepi16_epi8 =
      __mm256_cvtsepi16_epi8Ptr.asFunction<__m128i Function(__m256i)>();

  __m128i _mm256_mask_cvtsepi16_epi8(
    __m128i arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cvtsepi16_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtsepi16_epi8Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__m128i, __mmask16, __m256i)>>(
      '_mm256_mask_cvtsepi16_epi8');
  late final __mm256_mask_cvtsepi16_epi8 = __mm256_mask_cvtsepi16_epi8Ptr
      .asFunction<__m128i Function(__m128i, int, __m256i)>();

  __m128i _mm256_maskz_cvtsepi16_epi8(
    int arg0,
    __m256i arg1,
  ) {
    return __mm256_maskz_cvtsepi16_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvtsepi16_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask16, __m256i)>>(
          '_mm256_maskz_cvtsepi16_epi8');
  late final __mm256_maskz_cvtsepi16_epi8 = __mm256_maskz_cvtsepi16_epi8Ptr
      .asFunction<__m128i Function(int, __m256i)>();

  void _mm_mask_cvtsepi16_storeu_epi8(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cvtsepi16_storeu_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtsepi16_storeu_epi8Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8,
              __m128i)>>('_mm_mask_cvtsepi16_storeu_epi8');
  late final __mm_mask_cvtsepi16_storeu_epi8 =
      __mm_mask_cvtsepi16_storeu_epi8Ptr
          .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m128i)>();

  void _mm256_mask_cvtsepi16_storeu_epi8(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cvtsepi16_storeu_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtsepi16_storeu_epi8Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask16,
              __m256i)>>('_mm256_mask_cvtsepi16_storeu_epi8');
  late final __mm256_mask_cvtsepi16_storeu_epi8 =
      __mm256_mask_cvtsepi16_storeu_epi8Ptr
          .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m256i)>();

  __m128i _mm_cvtsepi32_epi16(
    __m128i arg0,
  ) {
    return __mm_cvtsepi32_epi16(
      arg0,
    );
  }

  late final __mm_cvtsepi32_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i)>>(
          '_mm_cvtsepi32_epi16');
  late final __mm_cvtsepi32_epi16 =
      __mm_cvtsepi32_epi16Ptr.asFunction<__m128i Function(__m128i)>();

  __m128i _mm_mask_cvtsepi32_epi16(
    __m128i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cvtsepi32_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtsepi32_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m128i)>>(
          '_mm_mask_cvtsepi32_epi16');
  late final __mm_mask_cvtsepi32_epi16 = __mm_mask_cvtsepi32_epi16Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i)>();

  __m128i _mm_maskz_cvtsepi32_epi16(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_cvtsepi32_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvtsepi32_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i)>>(
          '_mm_maskz_cvtsepi32_epi16');
  late final __mm_maskz_cvtsepi32_epi16 = __mm_maskz_cvtsepi32_epi16Ptr
      .asFunction<__m128i Function(int, __m128i)>();

  __m128i _mm256_cvtsepi32_epi16(
    __m256i arg0,
  ) {
    return __mm256_cvtsepi32_epi16(
      arg0,
    );
  }

  late final __mm256_cvtsepi32_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m256i)>>(
          '_mm256_cvtsepi32_epi16');
  late final __mm256_cvtsepi32_epi16 =
      __mm256_cvtsepi32_epi16Ptr.asFunction<__m128i Function(__m256i)>();

  __m128i _mm256_mask_cvtsepi32_epi16(
    __m128i arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cvtsepi32_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtsepi32_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m256i)>>(
          '_mm256_mask_cvtsepi32_epi16');
  late final __mm256_mask_cvtsepi32_epi16 = __mm256_mask_cvtsepi32_epi16Ptr
      .asFunction<__m128i Function(__m128i, int, __m256i)>();

  __m128i _mm256_maskz_cvtsepi32_epi16(
    int arg0,
    __m256i arg1,
  ) {
    return __mm256_maskz_cvtsepi32_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvtsepi32_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m256i)>>(
          '_mm256_maskz_cvtsepi32_epi16');
  late final __mm256_maskz_cvtsepi32_epi16 = __mm256_maskz_cvtsepi32_epi16Ptr
      .asFunction<__m128i Function(int, __m256i)>();

  __m128i _mm_cvtsepi32_epi8(
    __m128i arg0,
  ) {
    return __mm_cvtsepi32_epi8(
      arg0,
    );
  }

  late final __mm_cvtsepi32_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i)>>(
          '_mm_cvtsepi32_epi8');
  late final __mm_cvtsepi32_epi8 =
      __mm_cvtsepi32_epi8Ptr.asFunction<__m128i Function(__m128i)>();

  __m128i _mm_mask_cvtsepi32_epi8(
    __m128i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cvtsepi32_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtsepi32_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m128i)>>(
          '_mm_mask_cvtsepi32_epi8');
  late final __mm_mask_cvtsepi32_epi8 = __mm_mask_cvtsepi32_epi8Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i)>();

  __m128i _mm_maskz_cvtsepi32_epi8(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_cvtsepi32_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvtsepi32_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i)>>(
          '_mm_maskz_cvtsepi32_epi8');
  late final __mm_maskz_cvtsepi32_epi8 =
      __mm_maskz_cvtsepi32_epi8Ptr.asFunction<__m128i Function(int, __m128i)>();

  __m128i _mm256_cvtsepi32_epi8(
    __m256i arg0,
  ) {
    return __mm256_cvtsepi32_epi8(
      arg0,
    );
  }

  late final __mm256_cvtsepi32_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m256i)>>(
          '_mm256_cvtsepi32_epi8');
  late final __mm256_cvtsepi32_epi8 =
      __mm256_cvtsepi32_epi8Ptr.asFunction<__m128i Function(__m256i)>();

  __m128i _mm256_mask_cvtsepi32_epi8(
    __m128i arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cvtsepi32_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtsepi32_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m256i)>>(
          '_mm256_mask_cvtsepi32_epi8');
  late final __mm256_mask_cvtsepi32_epi8 = __mm256_mask_cvtsepi32_epi8Ptr
      .asFunction<__m128i Function(__m128i, int, __m256i)>();

  __m128i _mm256_maskz_cvtsepi32_epi8(
    int arg0,
    __m256i arg1,
  ) {
    return __mm256_maskz_cvtsepi32_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvtsepi32_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m256i)>>(
          '_mm256_maskz_cvtsepi32_epi8');
  late final __mm256_maskz_cvtsepi32_epi8 = __mm256_maskz_cvtsepi32_epi8Ptr
      .asFunction<__m128i Function(int, __m256i)>();

  void _mm_mask_cvtsepi32_storeu_epi16(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cvtsepi32_storeu_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtsepi32_storeu_epi16Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8,
              __m128i)>>('_mm_mask_cvtsepi32_storeu_epi16');
  late final __mm_mask_cvtsepi32_storeu_epi16 =
      __mm_mask_cvtsepi32_storeu_epi16Ptr
          .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m128i)>();

  void _mm256_mask_cvtsepi32_storeu_epi16(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cvtsepi32_storeu_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtsepi32_storeu_epi16Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8,
              __m256i)>>('_mm256_mask_cvtsepi32_storeu_epi16');
  late final __mm256_mask_cvtsepi32_storeu_epi16 =
      __mm256_mask_cvtsepi32_storeu_epi16Ptr
          .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m256i)>();

  void _mm_mask_cvtsepi32_storeu_epi8(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cvtsepi32_storeu_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtsepi32_storeu_epi8Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8,
              __m128i)>>('_mm_mask_cvtsepi32_storeu_epi8');
  late final __mm_mask_cvtsepi32_storeu_epi8 =
      __mm_mask_cvtsepi32_storeu_epi8Ptr
          .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m128i)>();

  void _mm256_mask_cvtsepi32_storeu_epi8(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cvtsepi32_storeu_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtsepi32_storeu_epi8Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8,
              __m256i)>>('_mm256_mask_cvtsepi32_storeu_epi8');
  late final __mm256_mask_cvtsepi32_storeu_epi8 =
      __mm256_mask_cvtsepi32_storeu_epi8Ptr
          .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m256i)>();

  __m128i _mm_cvtsepi64_epi16(
    __m128i arg0,
  ) {
    return __mm_cvtsepi64_epi16(
      arg0,
    );
  }

  late final __mm_cvtsepi64_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i)>>(
          '_mm_cvtsepi64_epi16');
  late final __mm_cvtsepi64_epi16 =
      __mm_cvtsepi64_epi16Ptr.asFunction<__m128i Function(__m128i)>();

  __m128i _mm_mask_cvtsepi64_epi16(
    __m128i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cvtsepi64_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtsepi64_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m128i)>>(
          '_mm_mask_cvtsepi64_epi16');
  late final __mm_mask_cvtsepi64_epi16 = __mm_mask_cvtsepi64_epi16Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i)>();

  __m128i _mm_maskz_cvtsepi64_epi16(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_cvtsepi64_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvtsepi64_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i)>>(
          '_mm_maskz_cvtsepi64_epi16');
  late final __mm_maskz_cvtsepi64_epi16 = __mm_maskz_cvtsepi64_epi16Ptr
      .asFunction<__m128i Function(int, __m128i)>();

  __m128i _mm256_cvtsepi64_epi16(
    __m256i arg0,
  ) {
    return __mm256_cvtsepi64_epi16(
      arg0,
    );
  }

  late final __mm256_cvtsepi64_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m256i)>>(
          '_mm256_cvtsepi64_epi16');
  late final __mm256_cvtsepi64_epi16 =
      __mm256_cvtsepi64_epi16Ptr.asFunction<__m128i Function(__m256i)>();

  __m128i _mm256_mask_cvtsepi64_epi16(
    __m128i arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cvtsepi64_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtsepi64_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m256i)>>(
          '_mm256_mask_cvtsepi64_epi16');
  late final __mm256_mask_cvtsepi64_epi16 = __mm256_mask_cvtsepi64_epi16Ptr
      .asFunction<__m128i Function(__m128i, int, __m256i)>();

  __m128i _mm256_maskz_cvtsepi64_epi16(
    int arg0,
    __m256i arg1,
  ) {
    return __mm256_maskz_cvtsepi64_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvtsepi64_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m256i)>>(
          '_mm256_maskz_cvtsepi64_epi16');
  late final __mm256_maskz_cvtsepi64_epi16 = __mm256_maskz_cvtsepi64_epi16Ptr
      .asFunction<__m128i Function(int, __m256i)>();

  __m128i _mm_cvtsepi64_epi32(
    __m128i arg0,
  ) {
    return __mm_cvtsepi64_epi32(
      arg0,
    );
  }

  late final __mm_cvtsepi64_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i)>>(
          '_mm_cvtsepi64_epi32');
  late final __mm_cvtsepi64_epi32 =
      __mm_cvtsepi64_epi32Ptr.asFunction<__m128i Function(__m128i)>();

  __m128i _mm_mask_cvtsepi64_epi32(
    __m128i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cvtsepi64_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtsepi64_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m128i)>>(
          '_mm_mask_cvtsepi64_epi32');
  late final __mm_mask_cvtsepi64_epi32 = __mm_mask_cvtsepi64_epi32Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i)>();

  __m128i _mm_maskz_cvtsepi64_epi32(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_cvtsepi64_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvtsepi64_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i)>>(
          '_mm_maskz_cvtsepi64_epi32');
  late final __mm_maskz_cvtsepi64_epi32 = __mm_maskz_cvtsepi64_epi32Ptr
      .asFunction<__m128i Function(int, __m128i)>();

  __m128i _mm256_cvtsepi64_epi32(
    __m256i arg0,
  ) {
    return __mm256_cvtsepi64_epi32(
      arg0,
    );
  }

  late final __mm256_cvtsepi64_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m256i)>>(
          '_mm256_cvtsepi64_epi32');
  late final __mm256_cvtsepi64_epi32 =
      __mm256_cvtsepi64_epi32Ptr.asFunction<__m128i Function(__m256i)>();

  __m128i _mm256_mask_cvtsepi64_epi32(
    __m128i arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cvtsepi64_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtsepi64_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m256i)>>(
          '_mm256_mask_cvtsepi64_epi32');
  late final __mm256_mask_cvtsepi64_epi32 = __mm256_mask_cvtsepi64_epi32Ptr
      .asFunction<__m128i Function(__m128i, int, __m256i)>();

  __m128i _mm256_maskz_cvtsepi64_epi32(
    int arg0,
    __m256i arg1,
  ) {
    return __mm256_maskz_cvtsepi64_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvtsepi64_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m256i)>>(
          '_mm256_maskz_cvtsepi64_epi32');
  late final __mm256_maskz_cvtsepi64_epi32 = __mm256_maskz_cvtsepi64_epi32Ptr
      .asFunction<__m128i Function(int, __m256i)>();

  __m128i _mm_cvtsepi64_epi8(
    __m128i arg0,
  ) {
    return __mm_cvtsepi64_epi8(
      arg0,
    );
  }

  late final __mm_cvtsepi64_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i)>>(
          '_mm_cvtsepi64_epi8');
  late final __mm_cvtsepi64_epi8 =
      __mm_cvtsepi64_epi8Ptr.asFunction<__m128i Function(__m128i)>();

  __m128i _mm_mask_cvtsepi64_epi8(
    __m128i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cvtsepi64_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtsepi64_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m128i)>>(
          '_mm_mask_cvtsepi64_epi8');
  late final __mm_mask_cvtsepi64_epi8 = __mm_mask_cvtsepi64_epi8Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i)>();

  __m128i _mm_maskz_cvtsepi64_epi8(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_cvtsepi64_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvtsepi64_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i)>>(
          '_mm_maskz_cvtsepi64_epi8');
  late final __mm_maskz_cvtsepi64_epi8 =
      __mm_maskz_cvtsepi64_epi8Ptr.asFunction<__m128i Function(int, __m128i)>();

  __m128i _mm256_cvtsepi64_epi8(
    __m256i arg0,
  ) {
    return __mm256_cvtsepi64_epi8(
      arg0,
    );
  }

  late final __mm256_cvtsepi64_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m256i)>>(
          '_mm256_cvtsepi64_epi8');
  late final __mm256_cvtsepi64_epi8 =
      __mm256_cvtsepi64_epi8Ptr.asFunction<__m128i Function(__m256i)>();

  __m128i _mm256_mask_cvtsepi64_epi8(
    __m128i arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cvtsepi64_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtsepi64_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m256i)>>(
          '_mm256_mask_cvtsepi64_epi8');
  late final __mm256_mask_cvtsepi64_epi8 = __mm256_mask_cvtsepi64_epi8Ptr
      .asFunction<__m128i Function(__m128i, int, __m256i)>();

  __m128i _mm256_maskz_cvtsepi64_epi8(
    int arg0,
    __m256i arg1,
  ) {
    return __mm256_maskz_cvtsepi64_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvtsepi64_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m256i)>>(
          '_mm256_maskz_cvtsepi64_epi8');
  late final __mm256_maskz_cvtsepi64_epi8 = __mm256_maskz_cvtsepi64_epi8Ptr
      .asFunction<__m128i Function(int, __m256i)>();

  void _mm_mask_cvtsepi64_storeu_epi16(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cvtsepi64_storeu_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtsepi64_storeu_epi16Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8,
              __m128i)>>('_mm_mask_cvtsepi64_storeu_epi16');
  late final __mm_mask_cvtsepi64_storeu_epi16 =
      __mm_mask_cvtsepi64_storeu_epi16Ptr
          .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m128i)>();

  void _mm256_mask_cvtsepi64_storeu_epi16(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cvtsepi64_storeu_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtsepi64_storeu_epi16Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8,
              __m256i)>>('_mm256_mask_cvtsepi64_storeu_epi16');
  late final __mm256_mask_cvtsepi64_storeu_epi16 =
      __mm256_mask_cvtsepi64_storeu_epi16Ptr
          .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m256i)>();

  void _mm_mask_cvtsepi64_storeu_epi32(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cvtsepi64_storeu_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtsepi64_storeu_epi32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8,
              __m128i)>>('_mm_mask_cvtsepi64_storeu_epi32');
  late final __mm_mask_cvtsepi64_storeu_epi32 =
      __mm_mask_cvtsepi64_storeu_epi32Ptr
          .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m128i)>();

  void _mm256_mask_cvtsepi64_storeu_epi32(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cvtsepi64_storeu_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtsepi64_storeu_epi32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8,
              __m256i)>>('_mm256_mask_cvtsepi64_storeu_epi32');
  late final __mm256_mask_cvtsepi64_storeu_epi32 =
      __mm256_mask_cvtsepi64_storeu_epi32Ptr
          .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m256i)>();

  void _mm_mask_cvtsepi64_storeu_epi8(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cvtsepi64_storeu_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtsepi64_storeu_epi8Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8,
              __m128i)>>('_mm_mask_cvtsepi64_storeu_epi8');
  late final __mm_mask_cvtsepi64_storeu_epi8 =
      __mm_mask_cvtsepi64_storeu_epi8Ptr
          .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m128i)>();

  void _mm256_mask_cvtsepi64_storeu_epi8(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cvtsepi64_storeu_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtsepi64_storeu_epi8Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8,
              __m256i)>>('_mm256_mask_cvtsepi64_storeu_epi8');
  late final __mm256_mask_cvtsepi64_storeu_epi8 =
      __mm256_mask_cvtsepi64_storeu_epi8Ptr
          .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m256i)>();

  __m128i _mm_mask_cvttpd_epi32(
    __m128i arg0,
    int arg1,
    _m128d arg2,
  ) {
    return __mm_mask_cvttpd_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvttpd_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, _m128d)>>(
          '_mm_mask_cvttpd_epi32');
  late final __mm_mask_cvttpd_epi32 = __mm_mask_cvttpd_epi32Ptr
      .asFunction<__m128i Function(__m128i, int, _m128d)>();

  __m128i _mm_maskz_cvttpd_epi32(
    int arg0,
    _m128d arg1,
  ) {
    return __mm_maskz_cvttpd_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvttpd_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, _m128d)>>(
          '_mm_maskz_cvttpd_epi32');
  late final __mm_maskz_cvttpd_epi32 =
      __mm_maskz_cvttpd_epi32Ptr.asFunction<__m128i Function(int, _m128d)>();

  __m128i _mm256_mask_cvttpd_epi32(
    __m128i arg0,
    int arg1,
    _m256d arg2,
  ) {
    return __mm256_mask_cvttpd_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvttpd_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, _m256d)>>(
          '_mm256_mask_cvttpd_epi32');
  late final __mm256_mask_cvttpd_epi32 = __mm256_mask_cvttpd_epi32Ptr
      .asFunction<__m128i Function(__m128i, int, _m256d)>();

  __m128i _mm256_maskz_cvttpd_epi32(
    int arg0,
    _m256d arg1,
  ) {
    return __mm256_maskz_cvttpd_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvttpd_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, _m256d)>>(
          '_mm256_maskz_cvttpd_epi32');
  late final __mm256_maskz_cvttpd_epi32 =
      __mm256_maskz_cvttpd_epi32Ptr.asFunction<__m128i Function(int, _m256d)>();

  __m128i _mm_cvttpd_epi64(
    _m128d arg0,
  ) {
    return __mm_cvttpd_epi64(
      arg0,
    );
  }

  late final __mm_cvttpd_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(_m128d)>>('_mm_cvttpd_epi64');
  late final __mm_cvttpd_epi64 =
      __mm_cvttpd_epi64Ptr.asFunction<__m128i Function(_m128d)>();

  __m128i _mm_mask_cvttpd_epi64(
    __m128i arg0,
    int arg1,
    _m128d arg2,
  ) {
    return __mm_mask_cvttpd_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvttpd_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, _m128d)>>(
          '_mm_mask_cvttpd_epi64');
  late final __mm_mask_cvttpd_epi64 = __mm_mask_cvttpd_epi64Ptr
      .asFunction<__m128i Function(__m128i, int, _m128d)>();

  __m128i _mm_maskz_cvttpd_epi64(
    int arg0,
    _m128d arg1,
  ) {
    return __mm_maskz_cvttpd_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvttpd_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, _m128d)>>(
          '_mm_maskz_cvttpd_epi64');
  late final __mm_maskz_cvttpd_epi64 =
      __mm_maskz_cvttpd_epi64Ptr.asFunction<__m128i Function(int, _m128d)>();

  __m256i _mm256_cvttpd_epi64(
    _m256d arg0,
  ) {
    return __mm256_cvttpd_epi64(
      arg0,
    );
  }

  late final __mm256_cvttpd_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(_m256d)>>(
          '_mm256_cvttpd_epi64');
  late final __mm256_cvttpd_epi64 =
      __mm256_cvttpd_epi64Ptr.asFunction<__m256i Function(_m256d)>();

  __m256i _mm256_mask_cvttpd_epi64(
    __m256i arg0,
    int arg1,
    _m256d arg2,
  ) {
    return __mm256_mask_cvttpd_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvttpd_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __mmask8, _m256d)>>(
          '_mm256_mask_cvttpd_epi64');
  late final __mm256_mask_cvttpd_epi64 = __mm256_mask_cvttpd_epi64Ptr
      .asFunction<__m256i Function(__m256i, int, _m256d)>();

  __m256i _mm256_maskz_cvttpd_epi64(
    int arg0,
    _m256d arg1,
  ) {
    return __mm256_maskz_cvttpd_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvttpd_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, _m256d)>>(
          '_mm256_maskz_cvttpd_epi64');
  late final __mm256_maskz_cvttpd_epi64 =
      __mm256_maskz_cvttpd_epi64Ptr.asFunction<__m256i Function(int, _m256d)>();

  __m128i _mm_cvttpd_epu32(
    _m128d arg0,
  ) {
    return __mm_cvttpd_epu32(
      arg0,
    );
  }

  late final __mm_cvttpd_epu32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(_m128d)>>('_mm_cvttpd_epu32');
  late final __mm_cvttpd_epu32 =
      __mm_cvttpd_epu32Ptr.asFunction<__m128i Function(_m128d)>();

  __m128i _mm_mask_cvttpd_epu32(
    __m128i arg0,
    int arg1,
    _m128d arg2,
  ) {
    return __mm_mask_cvttpd_epu32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvttpd_epu32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, _m128d)>>(
          '_mm_mask_cvttpd_epu32');
  late final __mm_mask_cvttpd_epu32 = __mm_mask_cvttpd_epu32Ptr
      .asFunction<__m128i Function(__m128i, int, _m128d)>();

  __m128i _mm_maskz_cvttpd_epu32(
    int arg0,
    _m128d arg1,
  ) {
    return __mm_maskz_cvttpd_epu32(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvttpd_epu32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, _m128d)>>(
          '_mm_maskz_cvttpd_epu32');
  late final __mm_maskz_cvttpd_epu32 =
      __mm_maskz_cvttpd_epu32Ptr.asFunction<__m128i Function(int, _m128d)>();

  __m128i _mm256_cvttpd_epu32(
    _m256d arg0,
  ) {
    return __mm256_cvttpd_epu32(
      arg0,
    );
  }

  late final __mm256_cvttpd_epu32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(_m256d)>>(
          '_mm256_cvttpd_epu32');
  late final __mm256_cvttpd_epu32 =
      __mm256_cvttpd_epu32Ptr.asFunction<__m128i Function(_m256d)>();

  __m128i _mm256_mask_cvttpd_epu32(
    __m128i arg0,
    int arg1,
    _m256d arg2,
  ) {
    return __mm256_mask_cvttpd_epu32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvttpd_epu32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, _m256d)>>(
          '_mm256_mask_cvttpd_epu32');
  late final __mm256_mask_cvttpd_epu32 = __mm256_mask_cvttpd_epu32Ptr
      .asFunction<__m128i Function(__m128i, int, _m256d)>();

  __m128i _mm256_maskz_cvttpd_epu32(
    int arg0,
    _m256d arg1,
  ) {
    return __mm256_maskz_cvttpd_epu32(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvttpd_epu32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, _m256d)>>(
          '_mm256_maskz_cvttpd_epu32');
  late final __mm256_maskz_cvttpd_epu32 =
      __mm256_maskz_cvttpd_epu32Ptr.asFunction<__m128i Function(int, _m256d)>();

  __m128i _mm_cvttpd_epu64(
    _m128d arg0,
  ) {
    return __mm_cvttpd_epu64(
      arg0,
    );
  }

  late final __mm_cvttpd_epu64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(_m128d)>>('_mm_cvttpd_epu64');
  late final __mm_cvttpd_epu64 =
      __mm_cvttpd_epu64Ptr.asFunction<__m128i Function(_m128d)>();

  __m128i _mm_mask_cvttpd_epu64(
    __m128i arg0,
    int arg1,
    _m128d arg2,
  ) {
    return __mm_mask_cvttpd_epu64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvttpd_epu64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, _m128d)>>(
          '_mm_mask_cvttpd_epu64');
  late final __mm_mask_cvttpd_epu64 = __mm_mask_cvttpd_epu64Ptr
      .asFunction<__m128i Function(__m128i, int, _m128d)>();

  __m128i _mm_maskz_cvttpd_epu64(
    int arg0,
    _m128d arg1,
  ) {
    return __mm_maskz_cvttpd_epu64(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvttpd_epu64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, _m128d)>>(
          '_mm_maskz_cvttpd_epu64');
  late final __mm_maskz_cvttpd_epu64 =
      __mm_maskz_cvttpd_epu64Ptr.asFunction<__m128i Function(int, _m128d)>();

  __m256i _mm256_cvttpd_epu64(
    _m256d arg0,
  ) {
    return __mm256_cvttpd_epu64(
      arg0,
    );
  }

  late final __mm256_cvttpd_epu64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(_m256d)>>(
          '_mm256_cvttpd_epu64');
  late final __mm256_cvttpd_epu64 =
      __mm256_cvttpd_epu64Ptr.asFunction<__m256i Function(_m256d)>();

  __m256i _mm256_mask_cvttpd_epu64(
    __m256i arg0,
    int arg1,
    _m256d arg2,
  ) {
    return __mm256_mask_cvttpd_epu64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvttpd_epu64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __mmask8, _m256d)>>(
          '_mm256_mask_cvttpd_epu64');
  late final __mm256_mask_cvttpd_epu64 = __mm256_mask_cvttpd_epu64Ptr
      .asFunction<__m256i Function(__m256i, int, _m256d)>();

  __m256i _mm256_maskz_cvttpd_epu64(
    int arg0,
    _m256d arg1,
  ) {
    return __mm256_maskz_cvttpd_epu64(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvttpd_epu64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, _m256d)>>(
          '_mm256_maskz_cvttpd_epu64');
  late final __mm256_maskz_cvttpd_epu64 =
      __mm256_maskz_cvttpd_epu64Ptr.asFunction<__m256i Function(int, _m256d)>();

  __m128i _mm_mask_cvttps_epi32(
    __m128i arg0,
    int arg1,
    __m128 arg2,
  ) {
    return __mm_mask_cvttps_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvttps_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m128)>>(
          '_mm_mask_cvttps_epi32');
  late final __mm_mask_cvttps_epi32 = __mm_mask_cvttps_epi32Ptr
      .asFunction<__m128i Function(__m128i, int, __m128)>();

  __m128i _mm_maskz_cvttps_epi32(
    int arg0,
    __m128 arg1,
  ) {
    return __mm_maskz_cvttps_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvttps_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128)>>(
          '_mm_maskz_cvttps_epi32');
  late final __mm_maskz_cvttps_epi32 =
      __mm_maskz_cvttps_epi32Ptr.asFunction<__m128i Function(int, __m128)>();

  __m256i _mm256_mask_cvttps_epi32(
    __m256i arg0,
    int arg1,
    __m256 arg2,
  ) {
    return __mm256_mask_cvttps_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvttps_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __mmask8, __m256)>>(
          '_mm256_mask_cvttps_epi32');
  late final __mm256_mask_cvttps_epi32 = __mm256_mask_cvttps_epi32Ptr
      .asFunction<__m256i Function(__m256i, int, __m256)>();

  __m256i _mm256_maskz_cvttps_epi32(
    int arg0,
    __m256 arg1,
  ) {
    return __mm256_maskz_cvttps_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvttps_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m256)>>(
          '_mm256_maskz_cvttps_epi32');
  late final __mm256_maskz_cvttps_epi32 =
      __mm256_maskz_cvttps_epi32Ptr.asFunction<__m256i Function(int, __m256)>();

  __m128i _mm_cvttps_epi64(
    __m128 arg0,
  ) {
    return __mm_cvttps_epi64(
      arg0,
    );
  }

  late final __mm_cvttps_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128)>>('_mm_cvttps_epi64');
  late final __mm_cvttps_epi64 =
      __mm_cvttps_epi64Ptr.asFunction<__m128i Function(__m128)>();

  __m128i _mm_mask_cvttps_epi64(
    __m128i arg0,
    int arg1,
    __m128 arg2,
  ) {
    return __mm_mask_cvttps_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvttps_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m128)>>(
          '_mm_mask_cvttps_epi64');
  late final __mm_mask_cvttps_epi64 = __mm_mask_cvttps_epi64Ptr
      .asFunction<__m128i Function(__m128i, int, __m128)>();

  __m128i _mm_maskz_cvttps_epi64(
    int arg0,
    __m128 arg1,
  ) {
    return __mm_maskz_cvttps_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvttps_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128)>>(
          '_mm_maskz_cvttps_epi64');
  late final __mm_maskz_cvttps_epi64 =
      __mm_maskz_cvttps_epi64Ptr.asFunction<__m128i Function(int, __m128)>();

  __m256i _mm256_cvttps_epi64(
    __m128 arg0,
  ) {
    return __mm256_cvttps_epi64(
      arg0,
    );
  }

  late final __mm256_cvttps_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m128)>>(
          '_mm256_cvttps_epi64');
  late final __mm256_cvttps_epi64 =
      __mm256_cvttps_epi64Ptr.asFunction<__m256i Function(__m128)>();

  __m256i _mm256_mask_cvttps_epi64(
    __m256i arg0,
    int arg1,
    __m128 arg2,
  ) {
    return __mm256_mask_cvttps_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvttps_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __mmask8, __m128)>>(
          '_mm256_mask_cvttps_epi64');
  late final __mm256_mask_cvttps_epi64 = __mm256_mask_cvttps_epi64Ptr
      .asFunction<__m256i Function(__m256i, int, __m128)>();

  __m256i _mm256_maskz_cvttps_epi64(
    int arg0,
    __m128 arg1,
  ) {
    return __mm256_maskz_cvttps_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvttps_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m128)>>(
          '_mm256_maskz_cvttps_epi64');
  late final __mm256_maskz_cvttps_epi64 =
      __mm256_maskz_cvttps_epi64Ptr.asFunction<__m256i Function(int, __m128)>();

  __m128i _mm_cvttps_epu32(
    __m128 arg0,
  ) {
    return __mm_cvttps_epu32(
      arg0,
    );
  }

  late final __mm_cvttps_epu32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128)>>('_mm_cvttps_epu32');
  late final __mm_cvttps_epu32 =
      __mm_cvttps_epu32Ptr.asFunction<__m128i Function(__m128)>();

  __m128i _mm_mask_cvttps_epu32(
    __m128i arg0,
    int arg1,
    __m128 arg2,
  ) {
    return __mm_mask_cvttps_epu32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvttps_epu32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m128)>>(
          '_mm_mask_cvttps_epu32');
  late final __mm_mask_cvttps_epu32 = __mm_mask_cvttps_epu32Ptr
      .asFunction<__m128i Function(__m128i, int, __m128)>();

  __m128i _mm_maskz_cvttps_epu32(
    int arg0,
    __m128 arg1,
  ) {
    return __mm_maskz_cvttps_epu32(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvttps_epu32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128)>>(
          '_mm_maskz_cvttps_epu32');
  late final __mm_maskz_cvttps_epu32 =
      __mm_maskz_cvttps_epu32Ptr.asFunction<__m128i Function(int, __m128)>();

  __m256i _mm256_cvttps_epu32(
    __m256 arg0,
  ) {
    return __mm256_cvttps_epu32(
      arg0,
    );
  }

  late final __mm256_cvttps_epu32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256)>>(
          '_mm256_cvttps_epu32');
  late final __mm256_cvttps_epu32 =
      __mm256_cvttps_epu32Ptr.asFunction<__m256i Function(__m256)>();

  __m256i _mm256_mask_cvttps_epu32(
    __m256i arg0,
    int arg1,
    __m256 arg2,
  ) {
    return __mm256_mask_cvttps_epu32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvttps_epu32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __mmask8, __m256)>>(
          '_mm256_mask_cvttps_epu32');
  late final __mm256_mask_cvttps_epu32 = __mm256_mask_cvttps_epu32Ptr
      .asFunction<__m256i Function(__m256i, int, __m256)>();

  __m256i _mm256_maskz_cvttps_epu32(
    int arg0,
    __m256 arg1,
  ) {
    return __mm256_maskz_cvttps_epu32(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvttps_epu32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m256)>>(
          '_mm256_maskz_cvttps_epu32');
  late final __mm256_maskz_cvttps_epu32 =
      __mm256_maskz_cvttps_epu32Ptr.asFunction<__m256i Function(int, __m256)>();

  __m128i _mm_cvttps_epu64(
    __m128 arg0,
  ) {
    return __mm_cvttps_epu64(
      arg0,
    );
  }

  late final __mm_cvttps_epu64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128)>>('_mm_cvttps_epu64');
  late final __mm_cvttps_epu64 =
      __mm_cvttps_epu64Ptr.asFunction<__m128i Function(__m128)>();

  __m128i _mm_mask_cvttps_epu64(
    __m128i arg0,
    int arg1,
    __m128 arg2,
  ) {
    return __mm_mask_cvttps_epu64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvttps_epu64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m128)>>(
          '_mm_mask_cvttps_epu64');
  late final __mm_mask_cvttps_epu64 = __mm_mask_cvttps_epu64Ptr
      .asFunction<__m128i Function(__m128i, int, __m128)>();

  __m128i _mm_maskz_cvttps_epu64(
    int arg0,
    __m128 arg1,
  ) {
    return __mm_maskz_cvttps_epu64(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvttps_epu64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128)>>(
          '_mm_maskz_cvttps_epu64');
  late final __mm_maskz_cvttps_epu64 =
      __mm_maskz_cvttps_epu64Ptr.asFunction<__m128i Function(int, __m128)>();

  __m256i _mm256_cvttps_epu64(
    __m128 arg0,
  ) {
    return __mm256_cvttps_epu64(
      arg0,
    );
  }

  late final __mm256_cvttps_epu64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m128)>>(
          '_mm256_cvttps_epu64');
  late final __mm256_cvttps_epu64 =
      __mm256_cvttps_epu64Ptr.asFunction<__m256i Function(__m128)>();

  __m256i _mm256_mask_cvttps_epu64(
    __m256i arg0,
    int arg1,
    __m128 arg2,
  ) {
    return __mm256_mask_cvttps_epu64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvttps_epu64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __mmask8, __m128)>>(
          '_mm256_mask_cvttps_epu64');
  late final __mm256_mask_cvttps_epu64 = __mm256_mask_cvttps_epu64Ptr
      .asFunction<__m256i Function(__m256i, int, __m128)>();

  __m256i _mm256_maskz_cvttps_epu64(
    int arg0,
    __m128 arg1,
  ) {
    return __mm256_maskz_cvttps_epu64(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvttps_epu64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m128)>>(
          '_mm256_maskz_cvttps_epu64');
  late final __mm256_maskz_cvttps_epu64 =
      __mm256_maskz_cvttps_epu64Ptr.asFunction<__m256i Function(int, __m128)>();

  __m128i _mm_cvtusepi16_epi8(
    __m128i arg0,
  ) {
    return __mm_cvtusepi16_epi8(
      arg0,
    );
  }

  late final __mm_cvtusepi16_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i)>>(
          '_mm_cvtusepi16_epi8');
  late final __mm_cvtusepi16_epi8 =
      __mm_cvtusepi16_epi8Ptr.asFunction<__m128i Function(__m128i)>();

  __m128i _mm_mask_cvtusepi16_epi8(
    __m128i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cvtusepi16_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtusepi16_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m128i)>>(
          '_mm_mask_cvtusepi16_epi8');
  late final __mm_mask_cvtusepi16_epi8 = __mm_mask_cvtusepi16_epi8Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i)>();

  __m128i _mm_maskz_cvtusepi16_epi8(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_cvtusepi16_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvtusepi16_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i)>>(
          '_mm_maskz_cvtusepi16_epi8');
  late final __mm_maskz_cvtusepi16_epi8 = __mm_maskz_cvtusepi16_epi8Ptr
      .asFunction<__m128i Function(int, __m128i)>();

  __m128i _mm256_cvtusepi16_epi8(
    __m256i arg0,
  ) {
    return __mm256_cvtusepi16_epi8(
      arg0,
    );
  }

  late final __mm256_cvtusepi16_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m256i)>>(
          '_mm256_cvtusepi16_epi8');
  late final __mm256_cvtusepi16_epi8 =
      __mm256_cvtusepi16_epi8Ptr.asFunction<__m128i Function(__m256i)>();

  __m128i _mm256_mask_cvtusepi16_epi8(
    __m128i arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cvtusepi16_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtusepi16_epi8Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__m128i, __mmask16, __m256i)>>(
      '_mm256_mask_cvtusepi16_epi8');
  late final __mm256_mask_cvtusepi16_epi8 = __mm256_mask_cvtusepi16_epi8Ptr
      .asFunction<__m128i Function(__m128i, int, __m256i)>();

  __m128i _mm256_maskz_cvtusepi16_epi8(
    int arg0,
    __m256i arg1,
  ) {
    return __mm256_maskz_cvtusepi16_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvtusepi16_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask16, __m256i)>>(
          '_mm256_maskz_cvtusepi16_epi8');
  late final __mm256_maskz_cvtusepi16_epi8 = __mm256_maskz_cvtusepi16_epi8Ptr
      .asFunction<__m128i Function(int, __m256i)>();

  void _mm_mask_cvtusepi16_storeu_epi8(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cvtusepi16_storeu_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtusepi16_storeu_epi8Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8,
              __m128i)>>('_mm_mask_cvtusepi16_storeu_epi8');
  late final __mm_mask_cvtusepi16_storeu_epi8 =
      __mm_mask_cvtusepi16_storeu_epi8Ptr
          .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m128i)>();

  void _mm256_mask_cvtusepi16_storeu_epi8(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cvtusepi16_storeu_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtusepi16_storeu_epi8Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask16,
              __m256i)>>('_mm256_mask_cvtusepi16_storeu_epi8');
  late final __mm256_mask_cvtusepi16_storeu_epi8 =
      __mm256_mask_cvtusepi16_storeu_epi8Ptr
          .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m256i)>();

  __m128i _mm_cvtusepi32_epi16(
    __m128i arg0,
  ) {
    return __mm_cvtusepi32_epi16(
      arg0,
    );
  }

  late final __mm_cvtusepi32_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i)>>(
          '_mm_cvtusepi32_epi16');
  late final __mm_cvtusepi32_epi16 =
      __mm_cvtusepi32_epi16Ptr.asFunction<__m128i Function(__m128i)>();

  __m128i _mm_mask_cvtusepi32_epi16(
    __m128i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cvtusepi32_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtusepi32_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m128i)>>(
          '_mm_mask_cvtusepi32_epi16');
  late final __mm_mask_cvtusepi32_epi16 = __mm_mask_cvtusepi32_epi16Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i)>();

  __m128i _mm_maskz_cvtusepi32_epi16(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_cvtusepi32_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvtusepi32_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i)>>(
          '_mm_maskz_cvtusepi32_epi16');
  late final __mm_maskz_cvtusepi32_epi16 = __mm_maskz_cvtusepi32_epi16Ptr
      .asFunction<__m128i Function(int, __m128i)>();

  __m128i _mm256_cvtusepi32_epi16(
    __m256i arg0,
  ) {
    return __mm256_cvtusepi32_epi16(
      arg0,
    );
  }

  late final __mm256_cvtusepi32_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m256i)>>(
          '_mm256_cvtusepi32_epi16');
  late final __mm256_cvtusepi32_epi16 =
      __mm256_cvtusepi32_epi16Ptr.asFunction<__m128i Function(__m256i)>();

  __m128i _mm256_mask_cvtusepi32_epi16(
    __m128i arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cvtusepi32_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtusepi32_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m256i)>>(
          '_mm256_mask_cvtusepi32_epi16');
  late final __mm256_mask_cvtusepi32_epi16 = __mm256_mask_cvtusepi32_epi16Ptr
      .asFunction<__m128i Function(__m128i, int, __m256i)>();

  __m128i _mm256_maskz_cvtusepi32_epi16(
    int arg0,
    __m256i arg1,
  ) {
    return __mm256_maskz_cvtusepi32_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvtusepi32_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m256i)>>(
          '_mm256_maskz_cvtusepi32_epi16');
  late final __mm256_maskz_cvtusepi32_epi16 = __mm256_maskz_cvtusepi32_epi16Ptr
      .asFunction<__m128i Function(int, __m256i)>();

  __m128i _mm_cvtusepi32_epi8(
    __m128i arg0,
  ) {
    return __mm_cvtusepi32_epi8(
      arg0,
    );
  }

  late final __mm_cvtusepi32_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i)>>(
          '_mm_cvtusepi32_epi8');
  late final __mm_cvtusepi32_epi8 =
      __mm_cvtusepi32_epi8Ptr.asFunction<__m128i Function(__m128i)>();

  __m128i _mm_mask_cvtusepi32_epi8(
    __m128i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cvtusepi32_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtusepi32_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m128i)>>(
          '_mm_mask_cvtusepi32_epi8');
  late final __mm_mask_cvtusepi32_epi8 = __mm_mask_cvtusepi32_epi8Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i)>();

  __m128i _mm_maskz_cvtusepi32_epi8(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_cvtusepi32_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvtusepi32_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i)>>(
          '_mm_maskz_cvtusepi32_epi8');
  late final __mm_maskz_cvtusepi32_epi8 = __mm_maskz_cvtusepi32_epi8Ptr
      .asFunction<__m128i Function(int, __m128i)>();

  __m128i _mm256_cvtusepi32_epi8(
    __m256i arg0,
  ) {
    return __mm256_cvtusepi32_epi8(
      arg0,
    );
  }

  late final __mm256_cvtusepi32_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m256i)>>(
          '_mm256_cvtusepi32_epi8');
  late final __mm256_cvtusepi32_epi8 =
      __mm256_cvtusepi32_epi8Ptr.asFunction<__m128i Function(__m256i)>();

  __m128i _mm256_mask_cvtusepi32_epi8(
    __m128i arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cvtusepi32_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtusepi32_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m256i)>>(
          '_mm256_mask_cvtusepi32_epi8');
  late final __mm256_mask_cvtusepi32_epi8 = __mm256_mask_cvtusepi32_epi8Ptr
      .asFunction<__m128i Function(__m128i, int, __m256i)>();

  __m128i _mm256_maskz_cvtusepi32_epi8(
    int arg0,
    __m256i arg1,
  ) {
    return __mm256_maskz_cvtusepi32_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvtusepi32_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m256i)>>(
          '_mm256_maskz_cvtusepi32_epi8');
  late final __mm256_maskz_cvtusepi32_epi8 = __mm256_maskz_cvtusepi32_epi8Ptr
      .asFunction<__m128i Function(int, __m256i)>();

  void _mm_mask_cvtusepi32_storeu_epi16(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cvtusepi32_storeu_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtusepi32_storeu_epi16Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8,
              __m128i)>>('_mm_mask_cvtusepi32_storeu_epi16');
  late final __mm_mask_cvtusepi32_storeu_epi16 =
      __mm_mask_cvtusepi32_storeu_epi16Ptr
          .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m128i)>();

  void _mm256_mask_cvtusepi32_storeu_epi16(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cvtusepi32_storeu_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtusepi32_storeu_epi16Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8,
              __m256i)>>('_mm256_mask_cvtusepi32_storeu_epi16');
  late final __mm256_mask_cvtusepi32_storeu_epi16 =
      __mm256_mask_cvtusepi32_storeu_epi16Ptr
          .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m256i)>();

  void _mm_mask_cvtusepi32_storeu_epi8(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cvtusepi32_storeu_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtusepi32_storeu_epi8Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8,
              __m128i)>>('_mm_mask_cvtusepi32_storeu_epi8');
  late final __mm_mask_cvtusepi32_storeu_epi8 =
      __mm_mask_cvtusepi32_storeu_epi8Ptr
          .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m128i)>();

  void _mm256_mask_cvtusepi32_storeu_epi8(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cvtusepi32_storeu_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtusepi32_storeu_epi8Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8,
              __m256i)>>('_mm256_mask_cvtusepi32_storeu_epi8');
  late final __mm256_mask_cvtusepi32_storeu_epi8 =
      __mm256_mask_cvtusepi32_storeu_epi8Ptr
          .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m256i)>();

  __m128i _mm_cvtusepi64_epi16(
    __m128i arg0,
  ) {
    return __mm_cvtusepi64_epi16(
      arg0,
    );
  }

  late final __mm_cvtusepi64_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i)>>(
          '_mm_cvtusepi64_epi16');
  late final __mm_cvtusepi64_epi16 =
      __mm_cvtusepi64_epi16Ptr.asFunction<__m128i Function(__m128i)>();

  __m128i _mm_mask_cvtusepi64_epi16(
    __m128i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cvtusepi64_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtusepi64_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m128i)>>(
          '_mm_mask_cvtusepi64_epi16');
  late final __mm_mask_cvtusepi64_epi16 = __mm_mask_cvtusepi64_epi16Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i)>();

  __m128i _mm_maskz_cvtusepi64_epi16(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_cvtusepi64_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvtusepi64_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i)>>(
          '_mm_maskz_cvtusepi64_epi16');
  late final __mm_maskz_cvtusepi64_epi16 = __mm_maskz_cvtusepi64_epi16Ptr
      .asFunction<__m128i Function(int, __m128i)>();

  __m128i _mm256_cvtusepi64_epi16(
    __m256i arg0,
  ) {
    return __mm256_cvtusepi64_epi16(
      arg0,
    );
  }

  late final __mm256_cvtusepi64_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m256i)>>(
          '_mm256_cvtusepi64_epi16');
  late final __mm256_cvtusepi64_epi16 =
      __mm256_cvtusepi64_epi16Ptr.asFunction<__m128i Function(__m256i)>();

  __m128i _mm256_mask_cvtusepi64_epi16(
    __m128i arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cvtusepi64_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtusepi64_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m256i)>>(
          '_mm256_mask_cvtusepi64_epi16');
  late final __mm256_mask_cvtusepi64_epi16 = __mm256_mask_cvtusepi64_epi16Ptr
      .asFunction<__m128i Function(__m128i, int, __m256i)>();

  __m128i _mm256_maskz_cvtusepi64_epi16(
    int arg0,
    __m256i arg1,
  ) {
    return __mm256_maskz_cvtusepi64_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvtusepi64_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m256i)>>(
          '_mm256_maskz_cvtusepi64_epi16');
  late final __mm256_maskz_cvtusepi64_epi16 = __mm256_maskz_cvtusepi64_epi16Ptr
      .asFunction<__m128i Function(int, __m256i)>();

  __m128i _mm_cvtusepi64_epi32(
    __m128i arg0,
  ) {
    return __mm_cvtusepi64_epi32(
      arg0,
    );
  }

  late final __mm_cvtusepi64_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i)>>(
          '_mm_cvtusepi64_epi32');
  late final __mm_cvtusepi64_epi32 =
      __mm_cvtusepi64_epi32Ptr.asFunction<__m128i Function(__m128i)>();

  __m128i _mm_mask_cvtusepi64_epi32(
    __m128i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cvtusepi64_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtusepi64_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m128i)>>(
          '_mm_mask_cvtusepi64_epi32');
  late final __mm_mask_cvtusepi64_epi32 = __mm_mask_cvtusepi64_epi32Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i)>();

  __m128i _mm_maskz_cvtusepi64_epi32(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_cvtusepi64_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvtusepi64_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i)>>(
          '_mm_maskz_cvtusepi64_epi32');
  late final __mm_maskz_cvtusepi64_epi32 = __mm_maskz_cvtusepi64_epi32Ptr
      .asFunction<__m128i Function(int, __m128i)>();

  __m128i _mm256_cvtusepi64_epi32(
    __m256i arg0,
  ) {
    return __mm256_cvtusepi64_epi32(
      arg0,
    );
  }

  late final __mm256_cvtusepi64_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m256i)>>(
          '_mm256_cvtusepi64_epi32');
  late final __mm256_cvtusepi64_epi32 =
      __mm256_cvtusepi64_epi32Ptr.asFunction<__m128i Function(__m256i)>();

  __m128i _mm256_mask_cvtusepi64_epi32(
    __m128i arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cvtusepi64_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtusepi64_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m256i)>>(
          '_mm256_mask_cvtusepi64_epi32');
  late final __mm256_mask_cvtusepi64_epi32 = __mm256_mask_cvtusepi64_epi32Ptr
      .asFunction<__m128i Function(__m128i, int, __m256i)>();

  __m128i _mm256_maskz_cvtusepi64_epi32(
    int arg0,
    __m256i arg1,
  ) {
    return __mm256_maskz_cvtusepi64_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvtusepi64_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m256i)>>(
          '_mm256_maskz_cvtusepi64_epi32');
  late final __mm256_maskz_cvtusepi64_epi32 = __mm256_maskz_cvtusepi64_epi32Ptr
      .asFunction<__m128i Function(int, __m256i)>();

  __m128i _mm_cvtusepi64_epi8(
    __m128i arg0,
  ) {
    return __mm_cvtusepi64_epi8(
      arg0,
    );
  }

  late final __mm_cvtusepi64_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i)>>(
          '_mm_cvtusepi64_epi8');
  late final __mm_cvtusepi64_epi8 =
      __mm_cvtusepi64_epi8Ptr.asFunction<__m128i Function(__m128i)>();

  __m128i _mm_mask_cvtusepi64_epi8(
    __m128i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cvtusepi64_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtusepi64_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m128i)>>(
          '_mm_mask_cvtusepi64_epi8');
  late final __mm_mask_cvtusepi64_epi8 = __mm_mask_cvtusepi64_epi8Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i)>();

  __m128i _mm_maskz_cvtusepi64_epi8(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_cvtusepi64_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvtusepi64_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i)>>(
          '_mm_maskz_cvtusepi64_epi8');
  late final __mm_maskz_cvtusepi64_epi8 = __mm_maskz_cvtusepi64_epi8Ptr
      .asFunction<__m128i Function(int, __m128i)>();

  __m128i _mm256_cvtusepi64_epi8(
    __m256i arg0,
  ) {
    return __mm256_cvtusepi64_epi8(
      arg0,
    );
  }

  late final __mm256_cvtusepi64_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m256i)>>(
          '_mm256_cvtusepi64_epi8');
  late final __mm256_cvtusepi64_epi8 =
      __mm256_cvtusepi64_epi8Ptr.asFunction<__m128i Function(__m256i)>();

  __m128i _mm256_mask_cvtusepi64_epi8(
    __m128i arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cvtusepi64_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtusepi64_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m256i)>>(
          '_mm256_mask_cvtusepi64_epi8');
  late final __mm256_mask_cvtusepi64_epi8 = __mm256_mask_cvtusepi64_epi8Ptr
      .asFunction<__m128i Function(__m128i, int, __m256i)>();

  __m128i _mm256_maskz_cvtusepi64_epi8(
    int arg0,
    __m256i arg1,
  ) {
    return __mm256_maskz_cvtusepi64_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvtusepi64_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m256i)>>(
          '_mm256_maskz_cvtusepi64_epi8');
  late final __mm256_maskz_cvtusepi64_epi8 = __mm256_maskz_cvtusepi64_epi8Ptr
      .asFunction<__m128i Function(int, __m256i)>();

  void _mm_mask_cvtusepi64_storeu_epi16(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cvtusepi64_storeu_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtusepi64_storeu_epi16Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8,
              __m128i)>>('_mm_mask_cvtusepi64_storeu_epi16');
  late final __mm_mask_cvtusepi64_storeu_epi16 =
      __mm_mask_cvtusepi64_storeu_epi16Ptr
          .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m128i)>();

  void _mm256_mask_cvtusepi64_storeu_epi16(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cvtusepi64_storeu_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtusepi64_storeu_epi16Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8,
              __m256i)>>('_mm256_mask_cvtusepi64_storeu_epi16');
  late final __mm256_mask_cvtusepi64_storeu_epi16 =
      __mm256_mask_cvtusepi64_storeu_epi16Ptr
          .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m256i)>();

  void _mm_mask_cvtusepi64_storeu_epi32(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cvtusepi64_storeu_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtusepi64_storeu_epi32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8,
              __m128i)>>('_mm_mask_cvtusepi64_storeu_epi32');
  late final __mm_mask_cvtusepi64_storeu_epi32 =
      __mm_mask_cvtusepi64_storeu_epi32Ptr
          .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m128i)>();

  void _mm256_mask_cvtusepi64_storeu_epi32(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cvtusepi64_storeu_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtusepi64_storeu_epi32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8,
              __m256i)>>('_mm256_mask_cvtusepi64_storeu_epi32');
  late final __mm256_mask_cvtusepi64_storeu_epi32 =
      __mm256_mask_cvtusepi64_storeu_epi32Ptr
          .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m256i)>();

  void _mm_mask_cvtusepi64_storeu_epi8(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cvtusepi64_storeu_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtusepi64_storeu_epi8Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8,
              __m128i)>>('_mm_mask_cvtusepi64_storeu_epi8');
  late final __mm_mask_cvtusepi64_storeu_epi8 =
      __mm_mask_cvtusepi64_storeu_epi8Ptr
          .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m128i)>();

  void _mm256_mask_cvtusepi64_storeu_epi8(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cvtusepi64_storeu_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtusepi64_storeu_epi8Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8,
              __m256i)>>('_mm256_mask_cvtusepi64_storeu_epi8');
  late final __mm256_mask_cvtusepi64_storeu_epi8 =
      __mm256_mask_cvtusepi64_storeu_epi8Ptr
          .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m256i)>();

  __m128i _mm_dbsad_epu8(
    __m128i arg0,
    __m128i arg1,
    int arg2,
  ) {
    return __mm_dbsad_epu8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_dbsad_epu8Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__m128i, __m128i, ffi.Int32)>>(
      '_mm_dbsad_epu8');
  late final __mm_dbsad_epu8 =
      __mm_dbsad_epu8Ptr.asFunction<__m128i Function(__m128i, __m128i, int)>();

  __m128i _mm_mask_dbsad_epu8(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
    int arg4,
  ) {
    return __mm_mask_dbsad_epu8(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_dbsad_epu8Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(__m128i, __mmask8, __m128i, __m128i,
              ffi.Int32)>>('_mm_mask_dbsad_epu8');
  late final __mm_mask_dbsad_epu8 = __mm_mask_dbsad_epu8Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i, int)>();

  __m128i _mm_maskz_dbsad_epu8(
    int arg0,
    __m128i arg1,
    __m128i arg2,
    int arg3,
  ) {
    return __mm_maskz_dbsad_epu8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_dbsad_epu8Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __mmask8, __m128i, __m128i, ffi.Int32)>>('_mm_maskz_dbsad_epu8');
  late final __mm_maskz_dbsad_epu8 = __mm_maskz_dbsad_epu8Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i, int)>();

  __m256i _mm256_dbsad_epu8(
    __m256i arg0,
    __m256i arg1,
    int arg2,
  ) {
    return __mm256_dbsad_epu8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_dbsad_epu8Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__m256i, __m256i, ffi.Int32)>>(
      '_mm256_dbsad_epu8');
  late final __mm256_dbsad_epu8 = __mm256_dbsad_epu8Ptr
      .asFunction<__m256i Function(__m256i, __m256i, int)>();

  __m256i _mm256_mask_dbsad_epu8(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
    int arg4,
  ) {
    return __mm256_mask_dbsad_epu8(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm256_mask_dbsad_epu8Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask16, __m256i, __m256i,
              ffi.Int32)>>('_mm256_mask_dbsad_epu8');
  late final __mm256_mask_dbsad_epu8 = __mm256_mask_dbsad_epu8Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i, int)>();

  __m256i _mm256_maskz_dbsad_epu8(
    int arg0,
    __m256i arg1,
    __m256i arg2,
    int arg3,
  ) {
    return __mm256_maskz_dbsad_epu8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_maskz_dbsad_epu8Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__mmask16, __m256i, __m256i,
              ffi.Int32)>>('_mm256_maskz_dbsad_epu8');
  late final __mm256_maskz_dbsad_epu8 = __mm256_maskz_dbsad_epu8Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i, int)>();

  _m128d _mm_mask_div_pd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    _m128d arg3,
  ) {
    return __mm_mask_div_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_div_pdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              _m128d, __mmask8, _m128d, _m128d)>>('_mm_mask_div_pd');
  late final __mm_mask_div_pd = __mm_mask_div_pdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d, _m128d)>();

  _m128d _mm_maskz_div_pd(
    int arg0,
    _m128d arg1,
    _m128d arg2,
  ) {
    return __mm_maskz_div_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_div_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(__mmask8, _m128d, _m128d)>>(
          '_mm_maskz_div_pd');
  late final __mm_maskz_div_pd =
      __mm_maskz_div_pdPtr.asFunction<_m128d Function(int, _m128d, _m128d)>();

  _m256d _mm256_mask_div_pd(
    _m256d arg0,
    int arg1,
    _m256d arg2,
    _m256d arg3,
  ) {
    return __mm256_mask_div_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_div_pdPtr = _lookup<
      ffi.NativeFunction<
          _m256d Function(
              _m256d, __mmask8, _m256d, _m256d)>>('_mm256_mask_div_pd');
  late final __mm256_mask_div_pd = __mm256_mask_div_pdPtr
      .asFunction<_m256d Function(_m256d, int, _m256d, _m256d)>();

  _m256d _mm256_maskz_div_pd(
    int arg0,
    _m256d arg1,
    _m256d arg2,
  ) {
    return __mm256_maskz_div_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_div_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(__mmask8, _m256d, _m256d)>>(
          '_mm256_maskz_div_pd');
  late final __mm256_maskz_div_pd = __mm256_maskz_div_pdPtr
      .asFunction<_m256d Function(int, _m256d, _m256d)>();

  __m128 _mm_mask_div_ps(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    __m128 arg3,
  ) {
    return __mm_mask_div_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_div_psPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __m128, __mmask8, __m128, __m128)>>('_mm_mask_div_ps');
  late final __mm_mask_div_ps = __mm_mask_div_psPtr
      .asFunction<__m128 Function(__m128, int, __m128, __m128)>();

  __m128 _mm_maskz_div_ps(
    int arg0,
    __m128 arg1,
    __m128 arg2,
  ) {
    return __mm_maskz_div_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_div_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__mmask8, __m128, __m128)>>(
          '_mm_maskz_div_ps');
  late final __mm_maskz_div_ps =
      __mm_maskz_div_psPtr.asFunction<__m128 Function(int, __m128, __m128)>();

  __m256 _mm256_mask_div_ps(
    __m256 arg0,
    int arg1,
    __m256 arg2,
    __m256 arg3,
  ) {
    return __mm256_mask_div_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_div_psPtr = _lookup<
      ffi.NativeFunction<
          __m256 Function(
              __m256, __mmask8, __m256, __m256)>>('_mm256_mask_div_ps');
  late final __mm256_mask_div_ps = __mm256_mask_div_psPtr
      .asFunction<__m256 Function(__m256, int, __m256, __m256)>();

  __m256 _mm256_maskz_div_ps(
    int arg0,
    __m256 arg1,
    __m256 arg2,
  ) {
    return __mm256_maskz_div_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_div_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__mmask8, __m256, __m256)>>(
          '_mm256_maskz_div_ps');
  late final __mm256_maskz_div_ps = __mm256_maskz_div_psPtr
      .asFunction<__m256 Function(int, __m256, __m256)>();

  __m128i _mm_mask_expand_epi8(
    __m128i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_expand_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_expand_epi8Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__m128i, __mmask16, __m128i)>>(
      '_mm_mask_expand_epi8');
  late final __mm_mask_expand_epi8 = __mm_mask_expand_epi8Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i)>();

  __m128i _mm_maskz_expand_epi8(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_expand_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_expand_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask16, __m128i)>>(
          '_mm_maskz_expand_epi8');
  late final __mm_maskz_expand_epi8 =
      __mm_maskz_expand_epi8Ptr.asFunction<__m128i Function(int, __m128i)>();

  __m256i _mm256_mask_expand_epi8(
    __m256i arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_expand_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_expand_epi8Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__m256i, __mmask32, __m256i)>>(
      '_mm256_mask_expand_epi8');
  late final __mm256_mask_expand_epi8 = __mm256_mask_expand_epi8Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i)>();

  __m256i _mm256_maskz_expand_epi8(
    int arg0,
    __m256i arg1,
  ) {
    return __mm256_maskz_expand_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_expand_epi8Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask32, __m256i)>>(
          '_mm256_maskz_expand_epi8');
  late final __mm256_maskz_expand_epi8 =
      __mm256_maskz_expand_epi8Ptr.asFunction<__m256i Function(int, __m256i)>();

  __m128i _mm_mask_expand_epi16(
    __m128i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_expand_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_expand_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m128i)>>(
          '_mm_mask_expand_epi16');
  late final __mm_mask_expand_epi16 = __mm_mask_expand_epi16Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i)>();

  __m128i _mm_maskz_expand_epi16(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_expand_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_expand_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i)>>(
          '_mm_maskz_expand_epi16');
  late final __mm_maskz_expand_epi16 =
      __mm_maskz_expand_epi16Ptr.asFunction<__m128i Function(int, __m128i)>();

  __m256i _mm256_mask_expand_epi16(
    __m256i arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_expand_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_expand_epi16Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__m256i, __mmask16, __m256i)>>(
      '_mm256_mask_expand_epi16');
  late final __mm256_mask_expand_epi16 = __mm256_mask_expand_epi16Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i)>();

  __m256i _mm256_maskz_expand_epi16(
    int arg0,
    __m256i arg1,
  ) {
    return __mm256_maskz_expand_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_expand_epi16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask16, __m256i)>>(
          '_mm256_maskz_expand_epi16');
  late final __mm256_maskz_expand_epi16 = __mm256_maskz_expand_epi16Ptr
      .asFunction<__m256i Function(int, __m256i)>();

  __m128i _mm_mask_expand_epi32(
    __m128i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_expand_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_expand_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m128i)>>(
          '_mm_mask_expand_epi32');
  late final __mm_mask_expand_epi32 = __mm_mask_expand_epi32Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i)>();

  __m128i _mm_maskz_expand_epi32(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_expand_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_expand_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i)>>(
          '_mm_maskz_expand_epi32');
  late final __mm_maskz_expand_epi32 =
      __mm_maskz_expand_epi32Ptr.asFunction<__m128i Function(int, __m128i)>();

  __m256i _mm256_mask_expand_epi32(
    __m256i arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_expand_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_expand_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __mmask8, __m256i)>>(
          '_mm256_mask_expand_epi32');
  late final __mm256_mask_expand_epi32 = __mm256_mask_expand_epi32Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i)>();

  __m256i _mm256_maskz_expand_epi32(
    int arg0,
    __m256i arg1,
  ) {
    return __mm256_maskz_expand_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_expand_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m256i)>>(
          '_mm256_maskz_expand_epi32');
  late final __mm256_maskz_expand_epi32 = __mm256_maskz_expand_epi32Ptr
      .asFunction<__m256i Function(int, __m256i)>();

  __m128i _mm_mask_expand_epi64(
    __m128i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_expand_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_expand_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m128i)>>(
          '_mm_mask_expand_epi64');
  late final __mm_mask_expand_epi64 = __mm_mask_expand_epi64Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i)>();

  __m128i _mm_maskz_expand_epi64(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_expand_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_expand_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i)>>(
          '_mm_maskz_expand_epi64');
  late final __mm_maskz_expand_epi64 =
      __mm_maskz_expand_epi64Ptr.asFunction<__m128i Function(int, __m128i)>();

  __m256i _mm256_mask_expand_epi64(
    __m256i arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_expand_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_expand_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __mmask8, __m256i)>>(
          '_mm256_mask_expand_epi64');
  late final __mm256_mask_expand_epi64 = __mm256_mask_expand_epi64Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i)>();

  __m256i _mm256_maskz_expand_epi64(
    int arg0,
    __m256i arg1,
  ) {
    return __mm256_maskz_expand_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_expand_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m256i)>>(
          '_mm256_maskz_expand_epi64');
  late final __mm256_maskz_expand_epi64 = __mm256_maskz_expand_epi64Ptr
      .asFunction<__m256i Function(int, __m256i)>();

  _m128d _mm_mask_expand_pd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
  ) {
    return __mm_mask_expand_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_expand_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, __mmask8, _m128d)>>(
          '_mm_mask_expand_pd');
  late final __mm_mask_expand_pd =
      __mm_mask_expand_pdPtr.asFunction<_m128d Function(_m128d, int, _m128d)>();

  _m128d _mm_maskz_expand_pd(
    int arg0,
    _m128d arg1,
  ) {
    return __mm_maskz_expand_pd(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_expand_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(__mmask8, _m128d)>>(
          '_mm_maskz_expand_pd');
  late final __mm_maskz_expand_pd =
      __mm_maskz_expand_pdPtr.asFunction<_m128d Function(int, _m128d)>();

  _m256d _mm256_mask_expand_pd(
    _m256d arg0,
    int arg1,
    _m256d arg2,
  ) {
    return __mm256_mask_expand_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_expand_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d, __mmask8, _m256d)>>(
          '_mm256_mask_expand_pd');
  late final __mm256_mask_expand_pd = __mm256_mask_expand_pdPtr
      .asFunction<_m256d Function(_m256d, int, _m256d)>();

  _m256d _mm256_maskz_expand_pd(
    int arg0,
    _m256d arg1,
  ) {
    return __mm256_maskz_expand_pd(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_expand_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(__mmask8, _m256d)>>(
          '_mm256_maskz_expand_pd');
  late final __mm256_maskz_expand_pd =
      __mm256_maskz_expand_pdPtr.asFunction<_m256d Function(int, _m256d)>();

  __m128 _mm_mask_expand_ps(
    __m128 arg0,
    int arg1,
    __m128 arg2,
  ) {
    return __mm_mask_expand_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_expand_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __mmask8, __m128)>>(
          '_mm_mask_expand_ps');
  late final __mm_mask_expand_ps =
      __mm_mask_expand_psPtr.asFunction<__m128 Function(__m128, int, __m128)>();

  __m128 _mm_maskz_expand_ps(
    int arg0,
    __m128 arg1,
  ) {
    return __mm_maskz_expand_ps(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_expand_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__mmask8, __m128)>>(
          '_mm_maskz_expand_ps');
  late final __mm_maskz_expand_ps =
      __mm_maskz_expand_psPtr.asFunction<__m128 Function(int, __m128)>();

  __m256 _mm256_mask_expand_ps(
    __m256 arg0,
    int arg1,
    __m256 arg2,
  ) {
    return __mm256_mask_expand_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_expand_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256, __mmask8, __m256)>>(
          '_mm256_mask_expand_ps');
  late final __mm256_mask_expand_ps = __mm256_mask_expand_psPtr
      .asFunction<__m256 Function(__m256, int, __m256)>();

  __m256 _mm256_maskz_expand_ps(
    int arg0,
    __m256 arg1,
  ) {
    return __mm256_maskz_expand_ps(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_expand_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__mmask8, __m256)>>(
          '_mm256_maskz_expand_ps');
  late final __mm256_maskz_expand_ps =
      __mm256_maskz_expand_psPtr.asFunction<__m256 Function(int, __m256)>();

  __m128i _mm_mask_expandloadu_epi8(
    __m128i arg0,
    int arg1,
    ffi.Pointer<ffi.Void> arg2,
  ) {
    return __mm_mask_expandloadu_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_expandloadu_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(__m128i, __mmask16,
              ffi.Pointer<ffi.Void>)>>('_mm_mask_expandloadu_epi8');
  late final __mm_mask_expandloadu_epi8 = __mm_mask_expandloadu_epi8Ptr
      .asFunction<__m128i Function(__m128i, int, ffi.Pointer<ffi.Void>)>();

  __m128i _mm_maskz_expandloadu_epi8(
    int arg0,
    ffi.Pointer<ffi.Void> arg1,
  ) {
    return __mm_maskz_expandloadu_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_expandloadu_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __mmask16, ffi.Pointer<ffi.Void>)>>('_mm_maskz_expandloadu_epi8');
  late final __mm_maskz_expandloadu_epi8 = __mm_maskz_expandloadu_epi8Ptr
      .asFunction<__m128i Function(int, ffi.Pointer<ffi.Void>)>();

  __m256i _mm256_mask_expandloadu_epi8(
    __m256i arg0,
    int arg1,
    ffi.Pointer<ffi.Void> arg2,
  ) {
    return __mm256_mask_expandloadu_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_expandloadu_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask32,
              ffi.Pointer<ffi.Void>)>>('_mm256_mask_expandloadu_epi8');
  late final __mm256_mask_expandloadu_epi8 = __mm256_mask_expandloadu_epi8Ptr
      .asFunction<__m256i Function(__m256i, int, ffi.Pointer<ffi.Void>)>();

  __m256i _mm256_maskz_expandloadu_epi8(
    int arg0,
    ffi.Pointer<ffi.Void> arg1,
  ) {
    return __mm256_maskz_expandloadu_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_expandloadu_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__mmask32,
              ffi.Pointer<ffi.Void>)>>('_mm256_maskz_expandloadu_epi8');
  late final __mm256_maskz_expandloadu_epi8 = __mm256_maskz_expandloadu_epi8Ptr
      .asFunction<__m256i Function(int, ffi.Pointer<ffi.Void>)>();

  __m128i _mm_mask_expandloadu_epi16(
    __m128i arg0,
    int arg1,
    ffi.Pointer<ffi.Void> arg2,
  ) {
    return __mm_mask_expandloadu_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_expandloadu_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(__m128i, __mmask8,
              ffi.Pointer<ffi.Void>)>>('_mm_mask_expandloadu_epi16');
  late final __mm_mask_expandloadu_epi16 = __mm_mask_expandloadu_epi16Ptr
      .asFunction<__m128i Function(__m128i, int, ffi.Pointer<ffi.Void>)>();

  __m128i _mm_maskz_expandloadu_epi16(
    int arg0,
    ffi.Pointer<ffi.Void> arg1,
  ) {
    return __mm_maskz_expandloadu_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_expandloadu_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __mmask8, ffi.Pointer<ffi.Void>)>>('_mm_maskz_expandloadu_epi16');
  late final __mm_maskz_expandloadu_epi16 = __mm_maskz_expandloadu_epi16Ptr
      .asFunction<__m128i Function(int, ffi.Pointer<ffi.Void>)>();

  __m256i _mm256_mask_expandloadu_epi16(
    __m256i arg0,
    int arg1,
    ffi.Pointer<ffi.Void> arg2,
  ) {
    return __mm256_mask_expandloadu_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_expandloadu_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask16,
              ffi.Pointer<ffi.Void>)>>('_mm256_mask_expandloadu_epi16');
  late final __mm256_mask_expandloadu_epi16 = __mm256_mask_expandloadu_epi16Ptr
      .asFunction<__m256i Function(__m256i, int, ffi.Pointer<ffi.Void>)>();

  __m256i _mm256_maskz_expandloadu_epi16(
    int arg0,
    ffi.Pointer<ffi.Void> arg1,
  ) {
    return __mm256_maskz_expandloadu_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_expandloadu_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__mmask16,
              ffi.Pointer<ffi.Void>)>>('_mm256_maskz_expandloadu_epi16');
  late final __mm256_maskz_expandloadu_epi16 =
      __mm256_maskz_expandloadu_epi16Ptr
          .asFunction<__m256i Function(int, ffi.Pointer<ffi.Void>)>();

  __m128i _mm_mask_expandloadu_epi32(
    __m128i arg0,
    int arg1,
    ffi.Pointer<ffi.Void> arg2,
  ) {
    return __mm_mask_expandloadu_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_expandloadu_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(__m128i, __mmask8,
              ffi.Pointer<ffi.Void>)>>('_mm_mask_expandloadu_epi32');
  late final __mm_mask_expandloadu_epi32 = __mm_mask_expandloadu_epi32Ptr
      .asFunction<__m128i Function(__m128i, int, ffi.Pointer<ffi.Void>)>();

  __m128i _mm_maskz_expandloadu_epi32(
    int arg0,
    ffi.Pointer<ffi.Void> arg1,
  ) {
    return __mm_maskz_expandloadu_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_expandloadu_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __mmask8, ffi.Pointer<ffi.Void>)>>('_mm_maskz_expandloadu_epi32');
  late final __mm_maskz_expandloadu_epi32 = __mm_maskz_expandloadu_epi32Ptr
      .asFunction<__m128i Function(int, ffi.Pointer<ffi.Void>)>();

  __m256i _mm256_mask_expandloadu_epi32(
    __m256i arg0,
    int arg1,
    ffi.Pointer<ffi.Void> arg2,
  ) {
    return __mm256_mask_expandloadu_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_expandloadu_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask8,
              ffi.Pointer<ffi.Void>)>>('_mm256_mask_expandloadu_epi32');
  late final __mm256_mask_expandloadu_epi32 = __mm256_mask_expandloadu_epi32Ptr
      .asFunction<__m256i Function(__m256i, int, ffi.Pointer<ffi.Void>)>();

  __m256i _mm256_maskz_expandloadu_epi32(
    int arg0,
    ffi.Pointer<ffi.Void> arg1,
  ) {
    return __mm256_maskz_expandloadu_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_expandloadu_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__mmask8,
              ffi.Pointer<ffi.Void>)>>('_mm256_maskz_expandloadu_epi32');
  late final __mm256_maskz_expandloadu_epi32 =
      __mm256_maskz_expandloadu_epi32Ptr
          .asFunction<__m256i Function(int, ffi.Pointer<ffi.Void>)>();

  __m128i _mm_mask_expandloadu_epi64(
    __m128i arg0,
    int arg1,
    ffi.Pointer<ffi.Void> arg2,
  ) {
    return __mm_mask_expandloadu_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_expandloadu_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(__m128i, __mmask8,
              ffi.Pointer<ffi.Void>)>>('_mm_mask_expandloadu_epi64');
  late final __mm_mask_expandloadu_epi64 = __mm_mask_expandloadu_epi64Ptr
      .asFunction<__m128i Function(__m128i, int, ffi.Pointer<ffi.Void>)>();

  __m128i _mm_maskz_expandloadu_epi64(
    int arg0,
    ffi.Pointer<ffi.Void> arg1,
  ) {
    return __mm_maskz_expandloadu_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_expandloadu_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __mmask8, ffi.Pointer<ffi.Void>)>>('_mm_maskz_expandloadu_epi64');
  late final __mm_maskz_expandloadu_epi64 = __mm_maskz_expandloadu_epi64Ptr
      .asFunction<__m128i Function(int, ffi.Pointer<ffi.Void>)>();

  __m256i _mm256_mask_expandloadu_epi64(
    __m256i arg0,
    int arg1,
    ffi.Pointer<ffi.Void> arg2,
  ) {
    return __mm256_mask_expandloadu_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_expandloadu_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask8,
              ffi.Pointer<ffi.Void>)>>('_mm256_mask_expandloadu_epi64');
  late final __mm256_mask_expandloadu_epi64 = __mm256_mask_expandloadu_epi64Ptr
      .asFunction<__m256i Function(__m256i, int, ffi.Pointer<ffi.Void>)>();

  __m256i _mm256_maskz_expandloadu_epi64(
    int arg0,
    ffi.Pointer<ffi.Void> arg1,
  ) {
    return __mm256_maskz_expandloadu_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_expandloadu_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__mmask8,
              ffi.Pointer<ffi.Void>)>>('_mm256_maskz_expandloadu_epi64');
  late final __mm256_maskz_expandloadu_epi64 =
      __mm256_maskz_expandloadu_epi64Ptr
          .asFunction<__m256i Function(int, ffi.Pointer<ffi.Void>)>();

  _m128d _mm_mask_expandloadu_pd(
    _m128d arg0,
    int arg1,
    ffi.Pointer<ffi.Void> arg2,
  ) {
    return __mm_mask_expandloadu_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_expandloadu_pdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(_m128d, __mmask8,
              ffi.Pointer<ffi.Void>)>>('_mm_mask_expandloadu_pd');
  late final __mm_mask_expandloadu_pd = __mm_mask_expandloadu_pdPtr
      .asFunction<_m128d Function(_m128d, int, ffi.Pointer<ffi.Void>)>();

  _m128d _mm_maskz_expandloadu_pd(
    int arg0,
    ffi.Pointer<ffi.Void> arg1,
  ) {
    return __mm_maskz_expandloadu_pd(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_expandloadu_pdPtr = _lookup<
          ffi.NativeFunction<_m128d Function(__mmask8, ffi.Pointer<ffi.Void>)>>(
      '_mm_maskz_expandloadu_pd');
  late final __mm_maskz_expandloadu_pd = __mm_maskz_expandloadu_pdPtr
      .asFunction<_m128d Function(int, ffi.Pointer<ffi.Void>)>();

  _m256d _mm256_mask_expandloadu_pd(
    _m256d arg0,
    int arg1,
    ffi.Pointer<ffi.Void> arg2,
  ) {
    return __mm256_mask_expandloadu_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_expandloadu_pdPtr = _lookup<
      ffi.NativeFunction<
          _m256d Function(_m256d, __mmask8,
              ffi.Pointer<ffi.Void>)>>('_mm256_mask_expandloadu_pd');
  late final __mm256_mask_expandloadu_pd = __mm256_mask_expandloadu_pdPtr
      .asFunction<_m256d Function(_m256d, int, ffi.Pointer<ffi.Void>)>();

  _m256d _mm256_maskz_expandloadu_pd(
    int arg0,
    ffi.Pointer<ffi.Void> arg1,
  ) {
    return __mm256_maskz_expandloadu_pd(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_expandloadu_pdPtr = _lookup<
          ffi.NativeFunction<_m256d Function(__mmask8, ffi.Pointer<ffi.Void>)>>(
      '_mm256_maskz_expandloadu_pd');
  late final __mm256_maskz_expandloadu_pd = __mm256_maskz_expandloadu_pdPtr
      .asFunction<_m256d Function(int, ffi.Pointer<ffi.Void>)>();

  __m128 _mm_mask_expandloadu_ps(
    __m128 arg0,
    int arg1,
    ffi.Pointer<ffi.Void> arg2,
  ) {
    return __mm_mask_expandloadu_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_expandloadu_psPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(__m128, __mmask8,
              ffi.Pointer<ffi.Void>)>>('_mm_mask_expandloadu_ps');
  late final __mm_mask_expandloadu_ps = __mm_mask_expandloadu_psPtr
      .asFunction<__m128 Function(__m128, int, ffi.Pointer<ffi.Void>)>();

  __m128 _mm_maskz_expandloadu_ps(
    int arg0,
    ffi.Pointer<ffi.Void> arg1,
  ) {
    return __mm_maskz_expandloadu_ps(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_expandloadu_psPtr = _lookup<
          ffi.NativeFunction<__m128 Function(__mmask8, ffi.Pointer<ffi.Void>)>>(
      '_mm_maskz_expandloadu_ps');
  late final __mm_maskz_expandloadu_ps = __mm_maskz_expandloadu_psPtr
      .asFunction<__m128 Function(int, ffi.Pointer<ffi.Void>)>();

  __m256 _mm256_mask_expandloadu_ps(
    __m256 arg0,
    int arg1,
    ffi.Pointer<ffi.Void> arg2,
  ) {
    return __mm256_mask_expandloadu_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_expandloadu_psPtr = _lookup<
      ffi.NativeFunction<
          __m256 Function(__m256, __mmask8,
              ffi.Pointer<ffi.Void>)>>('_mm256_mask_expandloadu_ps');
  late final __mm256_mask_expandloadu_ps = __mm256_mask_expandloadu_psPtr
      .asFunction<__m256 Function(__m256, int, ffi.Pointer<ffi.Void>)>();

  __m256 _mm256_maskz_expandloadu_ps(
    int arg0,
    ffi.Pointer<ffi.Void> arg1,
  ) {
    return __mm256_maskz_expandloadu_ps(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_expandloadu_psPtr = _lookup<
          ffi.NativeFunction<__m256 Function(__mmask8, ffi.Pointer<ffi.Void>)>>(
      '_mm256_maskz_expandloadu_ps');
  late final __mm256_maskz_expandloadu_ps = __mm256_maskz_expandloadu_psPtr
      .asFunction<__m256 Function(int, ffi.Pointer<ffi.Void>)>();

  __m128 _mm256_extractf32x4_ps(
    __m256 arg0,
    int arg1,
  ) {
    return __mm256_extractf32x4_ps(
      arg0,
      arg1,
    );
  }

  late final __mm256_extractf32x4_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m256, ffi.Int32)>>(
          '_mm256_extractf32x4_ps');
  late final __mm256_extractf32x4_ps =
      __mm256_extractf32x4_psPtr.asFunction<__m128 Function(__m256, int)>();

  __m128 _mm256_mask_extractf32x4_ps(
    __m128 arg0,
    int arg1,
    __m256 arg2,
    int arg3,
  ) {
    return __mm256_mask_extractf32x4_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_extractf32x4_psPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(__m128, __mmask8, __m256,
              ffi.Int32)>>('_mm256_mask_extractf32x4_ps');
  late final __mm256_mask_extractf32x4_ps = __mm256_mask_extractf32x4_psPtr
      .asFunction<__m128 Function(__m128, int, __m256, int)>();

  __m128 _mm256_maskz_extractf32x4_ps(
    int arg0,
    __m256 arg1,
    int arg2,
  ) {
    return __mm256_maskz_extractf32x4_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_extractf32x4_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__mmask8, __m256, ffi.Int32)>>(
          '_mm256_maskz_extractf32x4_ps');
  late final __mm256_maskz_extractf32x4_ps = __mm256_maskz_extractf32x4_psPtr
      .asFunction<__m128 Function(int, __m256, int)>();

  _m128d _mm256_extractf64x2_pd(
    _m256d arg0,
    int arg1,
  ) {
    return __mm256_extractf64x2_pd(
      arg0,
      arg1,
    );
  }

  late final __mm256_extractf64x2_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m256d, ffi.Int32)>>(
          '_mm256_extractf64x2_pd');
  late final __mm256_extractf64x2_pd =
      __mm256_extractf64x2_pdPtr.asFunction<_m128d Function(_m256d, int)>();

  _m128d _mm256_mask_extractf64x2_pd(
    _m128d arg0,
    int arg1,
    _m256d arg2,
    int arg3,
  ) {
    return __mm256_mask_extractf64x2_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_extractf64x2_pdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(_m128d, __mmask8, _m256d,
              ffi.Int32)>>('_mm256_mask_extractf64x2_pd');
  late final __mm256_mask_extractf64x2_pd = __mm256_mask_extractf64x2_pdPtr
      .asFunction<_m128d Function(_m128d, int, _m256d, int)>();

  _m128d _mm256_maskz_extractf64x2_pd(
    int arg0,
    _m256d arg1,
    int arg2,
  ) {
    return __mm256_maskz_extractf64x2_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_extractf64x2_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(__mmask8, _m256d, ffi.Int32)>>(
          '_mm256_maskz_extractf64x2_pd');
  late final __mm256_maskz_extractf64x2_pd = __mm256_maskz_extractf64x2_pdPtr
      .asFunction<_m128d Function(int, _m256d, int)>();

  __m128i _mm256_extracti32x4_epi32(
    __m256i arg0,
    int arg1,
  ) {
    return __mm256_extracti32x4_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm256_extracti32x4_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m256i, ffi.Int32)>>(
          '_mm256_extracti32x4_epi32');
  late final __mm256_extracti32x4_epi32 = __mm256_extracti32x4_epi32Ptr
      .asFunction<__m128i Function(__m256i, int)>();

  __m128i _mm256_mask_extracti32x4_epi32(
    __m128i arg0,
    int arg1,
    __m256i arg2,
    int arg3,
  ) {
    return __mm256_mask_extracti32x4_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_extracti32x4_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(__m128i, __mmask8, __m256i,
              ffi.Int32)>>('_mm256_mask_extracti32x4_epi32');
  late final __mm256_mask_extracti32x4_epi32 =
      __mm256_mask_extracti32x4_epi32Ptr
          .asFunction<__m128i Function(__m128i, int, __m256i, int)>();

  __m128i _mm256_maskz_extracti32x4_epi32(
    int arg0,
    __m256i arg1,
    int arg2,
  ) {
    return __mm256_maskz_extracti32x4_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_extracti32x4_epi32Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__mmask8, __m256i, ffi.Int32)>>(
      '_mm256_maskz_extracti32x4_epi32');
  late final __mm256_maskz_extracti32x4_epi32 =
      __mm256_maskz_extracti32x4_epi32Ptr
          .asFunction<__m128i Function(int, __m256i, int)>();

  __m128i _mm256_extracti64x2_epi64(
    __m256i arg0,
    int arg1,
  ) {
    return __mm256_extracti64x2_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm256_extracti64x2_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m256i, ffi.Int32)>>(
          '_mm256_extracti64x2_epi64');
  late final __mm256_extracti64x2_epi64 = __mm256_extracti64x2_epi64Ptr
      .asFunction<__m128i Function(__m256i, int)>();

  __m128i _mm256_mask_extracti64x2_epi64(
    __m128i arg0,
    int arg1,
    __m256i arg2,
    int arg3,
  ) {
    return __mm256_mask_extracti64x2_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_extracti64x2_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(__m128i, __mmask8, __m256i,
              ffi.Int32)>>('_mm256_mask_extracti64x2_epi64');
  late final __mm256_mask_extracti64x2_epi64 =
      __mm256_mask_extracti64x2_epi64Ptr
          .asFunction<__m128i Function(__m128i, int, __m256i, int)>();

  __m128i _mm256_maskz_extracti64x2_epi64(
    int arg0,
    __m256i arg1,
    int arg2,
  ) {
    return __mm256_maskz_extracti64x2_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_extracti64x2_epi64Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__mmask8, __m256i, ffi.Int32)>>(
      '_mm256_maskz_extracti64x2_epi64');
  late final __mm256_maskz_extracti64x2_epi64 =
      __mm256_maskz_extracti64x2_epi64Ptr
          .asFunction<__m128i Function(int, __m256i, int)>();

  _m128d _mm_fixupimm_pd(
    _m128d arg0,
    _m128d arg1,
    __m128i arg2,
    int arg3,
  ) {
    return __mm_fixupimm_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_fixupimm_pdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              _m128d, _m128d, __m128i, ffi.Int32)>>('_mm_fixupimm_pd');
  late final __mm_fixupimm_pd = __mm_fixupimm_pdPtr
      .asFunction<_m128d Function(_m128d, _m128d, __m128i, int)>();

  _m128d _mm_mask_fixupimm_pd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    __m128i arg3,
    int arg4,
  ) {
    return __mm_mask_fixupimm_pd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_fixupimm_pdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(_m128d, __mmask8, _m128d, __m128i,
              ffi.Int32)>>('_mm_mask_fixupimm_pd');
  late final __mm_mask_fixupimm_pd = __mm_mask_fixupimm_pdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d, __m128i, int)>();

  _m128d _mm_maskz_fixupimm_pd(
    int arg0,
    _m128d arg1,
    _m128d arg2,
    __m128i arg3,
    int arg4,
  ) {
    return __mm_maskz_fixupimm_pd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_maskz_fixupimm_pdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(__mmask8, _m128d, _m128d, __m128i,
              ffi.Int32)>>('_mm_maskz_fixupimm_pd');
  late final __mm_maskz_fixupimm_pd = __mm_maskz_fixupimm_pdPtr
      .asFunction<_m128d Function(int, _m128d, _m128d, __m128i, int)>();

  _m256d _mm256_fixupimm_pd(
    _m256d arg0,
    _m256d arg1,
    __m256i arg2,
    int arg3,
  ) {
    return __mm256_fixupimm_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_fixupimm_pdPtr = _lookup<
      ffi.NativeFunction<
          _m256d Function(
              _m256d, _m256d, __m256i, ffi.Int32)>>('_mm256_fixupimm_pd');
  late final __mm256_fixupimm_pd = __mm256_fixupimm_pdPtr
      .asFunction<_m256d Function(_m256d, _m256d, __m256i, int)>();

  _m256d _mm256_mask_fixupimm_pd(
    _m256d arg0,
    int arg1,
    _m256d arg2,
    __m256i arg3,
    int arg4,
  ) {
    return __mm256_mask_fixupimm_pd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm256_mask_fixupimm_pdPtr = _lookup<
      ffi.NativeFunction<
          _m256d Function(_m256d, __mmask8, _m256d, __m256i,
              ffi.Int32)>>('_mm256_mask_fixupimm_pd');
  late final __mm256_mask_fixupimm_pd = __mm256_mask_fixupimm_pdPtr
      .asFunction<_m256d Function(_m256d, int, _m256d, __m256i, int)>();

  _m256d _mm256_maskz_fixupimm_pd(
    int arg0,
    _m256d arg1,
    _m256d arg2,
    __m256i arg3,
    int arg4,
  ) {
    return __mm256_maskz_fixupimm_pd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm256_maskz_fixupimm_pdPtr = _lookup<
      ffi.NativeFunction<
          _m256d Function(__mmask8, _m256d, _m256d, __m256i,
              ffi.Int32)>>('_mm256_maskz_fixupimm_pd');
  late final __mm256_maskz_fixupimm_pd = __mm256_maskz_fixupimm_pdPtr
      .asFunction<_m256d Function(int, _m256d, _m256d, __m256i, int)>();

  __m128 _mm_fixupimm_ps(
    __m128 arg0,
    __m128 arg1,
    __m128i arg2,
    int arg3,
  ) {
    return __mm_fixupimm_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_fixupimm_psPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __m128, __m128, __m128i, ffi.Int32)>>('_mm_fixupimm_ps');
  late final __mm_fixupimm_ps = __mm_fixupimm_psPtr
      .asFunction<__m128 Function(__m128, __m128, __m128i, int)>();

  __m128 _mm_mask_fixupimm_ps(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    __m128i arg3,
    int arg4,
  ) {
    return __mm_mask_fixupimm_ps(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_fixupimm_psPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(__m128, __mmask8, __m128, __m128i,
              ffi.Int32)>>('_mm_mask_fixupimm_ps');
  late final __mm_mask_fixupimm_ps = __mm_mask_fixupimm_psPtr
      .asFunction<__m128 Function(__m128, int, __m128, __m128i, int)>();

  __m128 _mm_maskz_fixupimm_ps(
    int arg0,
    __m128 arg1,
    __m128 arg2,
    __m128i arg3,
    int arg4,
  ) {
    return __mm_maskz_fixupimm_ps(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_maskz_fixupimm_psPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(__mmask8, __m128, __m128, __m128i,
              ffi.Int32)>>('_mm_maskz_fixupimm_ps');
  late final __mm_maskz_fixupimm_ps = __mm_maskz_fixupimm_psPtr
      .asFunction<__m128 Function(int, __m128, __m128, __m128i, int)>();

  __m256 _mm256_fixupimm_ps(
    __m256 arg0,
    __m256 arg1,
    __m256i arg2,
    int arg3,
  ) {
    return __mm256_fixupimm_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_fixupimm_psPtr = _lookup<
      ffi.NativeFunction<
          __m256 Function(
              __m256, __m256, __m256i, ffi.Int32)>>('_mm256_fixupimm_ps');
  late final __mm256_fixupimm_ps = __mm256_fixupimm_psPtr
      .asFunction<__m256 Function(__m256, __m256, __m256i, int)>();

  __m256 _mm256_mask_fixupimm_ps(
    __m256 arg0,
    int arg1,
    __m256 arg2,
    __m256i arg3,
    int arg4,
  ) {
    return __mm256_mask_fixupimm_ps(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm256_mask_fixupimm_psPtr = _lookup<
      ffi.NativeFunction<
          __m256 Function(__m256, __mmask8, __m256, __m256i,
              ffi.Int32)>>('_mm256_mask_fixupimm_ps');
  late final __mm256_mask_fixupimm_ps = __mm256_mask_fixupimm_psPtr
      .asFunction<__m256 Function(__m256, int, __m256, __m256i, int)>();

  __m256 _mm256_maskz_fixupimm_ps(
    int arg0,
    __m256 arg1,
    __m256 arg2,
    __m256i arg3,
    int arg4,
  ) {
    return __mm256_maskz_fixupimm_ps(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm256_maskz_fixupimm_psPtr = _lookup<
      ffi.NativeFunction<
          __m256 Function(__mmask8, __m256, __m256, __m256i,
              ffi.Int32)>>('_mm256_maskz_fixupimm_ps');
  late final __mm256_maskz_fixupimm_ps = __mm256_maskz_fixupimm_psPtr
      .asFunction<__m256 Function(int, __m256, __m256, __m256i, int)>();

  _m128d _mm_mask_fmadd_pd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    _m128d arg3,
  ) {
    return __mm_mask_fmadd_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_fmadd_pdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              _m128d, __mmask8, _m128d, _m128d)>>('_mm_mask_fmadd_pd');
  late final __mm_mask_fmadd_pd = __mm_mask_fmadd_pdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d, _m128d)>();

  _m128d _mm_mask3_fmadd_pd(
    _m128d arg0,
    _m128d arg1,
    _m128d arg2,
    int arg3,
  ) {
    return __mm_mask3_fmadd_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask3_fmadd_pdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              _m128d, _m128d, _m128d, __mmask8)>>('_mm_mask3_fmadd_pd');
  late final __mm_mask3_fmadd_pd = __mm_mask3_fmadd_pdPtr
      .asFunction<_m128d Function(_m128d, _m128d, _m128d, int)>();

  _m128d _mm_maskz_fmadd_pd(
    int arg0,
    _m128d arg1,
    _m128d arg2,
    _m128d arg3,
  ) {
    return __mm_maskz_fmadd_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_fmadd_pdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              __mmask8, _m128d, _m128d, _m128d)>>('_mm_maskz_fmadd_pd');
  late final __mm_maskz_fmadd_pd = __mm_maskz_fmadd_pdPtr
      .asFunction<_m128d Function(int, _m128d, _m128d, _m128d)>();

  _m256d _mm256_mask_fmadd_pd(
    _m256d arg0,
    int arg1,
    _m256d arg2,
    _m256d arg3,
  ) {
    return __mm256_mask_fmadd_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_fmadd_pdPtr = _lookup<
      ffi.NativeFunction<
          _m256d Function(
              _m256d, __mmask8, _m256d, _m256d)>>('_mm256_mask_fmadd_pd');
  late final __mm256_mask_fmadd_pd = __mm256_mask_fmadd_pdPtr
      .asFunction<_m256d Function(_m256d, int, _m256d, _m256d)>();

  _m256d _mm256_mask3_fmadd_pd(
    _m256d arg0,
    _m256d arg1,
    _m256d arg2,
    int arg3,
  ) {
    return __mm256_mask3_fmadd_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask3_fmadd_pdPtr = _lookup<
      ffi.NativeFunction<
          _m256d Function(
              _m256d, _m256d, _m256d, __mmask8)>>('_mm256_mask3_fmadd_pd');
  late final __mm256_mask3_fmadd_pd = __mm256_mask3_fmadd_pdPtr
      .asFunction<_m256d Function(_m256d, _m256d, _m256d, int)>();

  _m256d _mm256_maskz_fmadd_pd(
    int arg0,
    _m256d arg1,
    _m256d arg2,
    _m256d arg3,
  ) {
    return __mm256_maskz_fmadd_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_maskz_fmadd_pdPtr = _lookup<
      ffi.NativeFunction<
          _m256d Function(
              __mmask8, _m256d, _m256d, _m256d)>>('_mm256_maskz_fmadd_pd');
  late final __mm256_maskz_fmadd_pd = __mm256_maskz_fmadd_pdPtr
      .asFunction<_m256d Function(int, _m256d, _m256d, _m256d)>();

  __m128 _mm_mask_fmadd_ps(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    __m128 arg3,
  ) {
    return __mm_mask_fmadd_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_fmadd_psPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __m128, __mmask8, __m128, __m128)>>('_mm_mask_fmadd_ps');
  late final __mm_mask_fmadd_ps = __mm_mask_fmadd_psPtr
      .asFunction<__m128 Function(__m128, int, __m128, __m128)>();

  __m128 _mm_mask3_fmadd_ps(
    __m128 arg0,
    __m128 arg1,
    __m128 arg2,
    int arg3,
  ) {
    return __mm_mask3_fmadd_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask3_fmadd_psPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __m128, __m128, __m128, __mmask8)>>('_mm_mask3_fmadd_ps');
  late final __mm_mask3_fmadd_ps = __mm_mask3_fmadd_psPtr
      .asFunction<__m128 Function(__m128, __m128, __m128, int)>();

  __m128 _mm_maskz_fmadd_ps(
    int arg0,
    __m128 arg1,
    __m128 arg2,
    __m128 arg3,
  ) {
    return __mm_maskz_fmadd_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_fmadd_psPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __mmask8, __m128, __m128, __m128)>>('_mm_maskz_fmadd_ps');
  late final __mm_maskz_fmadd_ps = __mm_maskz_fmadd_psPtr
      .asFunction<__m128 Function(int, __m128, __m128, __m128)>();

  __m256 _mm256_mask_fmadd_ps(
    __m256 arg0,
    int arg1,
    __m256 arg2,
    __m256 arg3,
  ) {
    return __mm256_mask_fmadd_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_fmadd_psPtr = _lookup<
      ffi.NativeFunction<
          __m256 Function(
              __m256, __mmask8, __m256, __m256)>>('_mm256_mask_fmadd_ps');
  late final __mm256_mask_fmadd_ps = __mm256_mask_fmadd_psPtr
      .asFunction<__m256 Function(__m256, int, __m256, __m256)>();

  __m256 _mm256_mask3_fmadd_ps(
    __m256 arg0,
    __m256 arg1,
    __m256 arg2,
    int arg3,
  ) {
    return __mm256_mask3_fmadd_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask3_fmadd_psPtr = _lookup<
      ffi.NativeFunction<
          __m256 Function(
              __m256, __m256, __m256, __mmask8)>>('_mm256_mask3_fmadd_ps');
  late final __mm256_mask3_fmadd_ps = __mm256_mask3_fmadd_psPtr
      .asFunction<__m256 Function(__m256, __m256, __m256, int)>();

  __m256 _mm256_maskz_fmadd_ps(
    int arg0,
    __m256 arg1,
    __m256 arg2,
    __m256 arg3,
  ) {
    return __mm256_maskz_fmadd_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_maskz_fmadd_psPtr = _lookup<
      ffi.NativeFunction<
          __m256 Function(
              __mmask8, __m256, __m256, __m256)>>('_mm256_maskz_fmadd_ps');
  late final __mm256_maskz_fmadd_ps = __mm256_maskz_fmadd_psPtr
      .asFunction<__m256 Function(int, __m256, __m256, __m256)>();

  _m128d _mm_mask_fmaddsub_pd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    _m128d arg3,
  ) {
    return __mm_mask_fmaddsub_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_fmaddsub_pdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              _m128d, __mmask8, _m128d, _m128d)>>('_mm_mask_fmaddsub_pd');
  late final __mm_mask_fmaddsub_pd = __mm_mask_fmaddsub_pdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d, _m128d)>();

  _m128d _mm_mask3_fmaddsub_pd(
    _m128d arg0,
    _m128d arg1,
    _m128d arg2,
    int arg3,
  ) {
    return __mm_mask3_fmaddsub_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask3_fmaddsub_pdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              _m128d, _m128d, _m128d, __mmask8)>>('_mm_mask3_fmaddsub_pd');
  late final __mm_mask3_fmaddsub_pd = __mm_mask3_fmaddsub_pdPtr
      .asFunction<_m128d Function(_m128d, _m128d, _m128d, int)>();

  _m128d _mm_maskz_fmaddsub_pd(
    int arg0,
    _m128d arg1,
    _m128d arg2,
    _m128d arg3,
  ) {
    return __mm_maskz_fmaddsub_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_fmaddsub_pdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              __mmask8, _m128d, _m128d, _m128d)>>('_mm_maskz_fmaddsub_pd');
  late final __mm_maskz_fmaddsub_pd = __mm_maskz_fmaddsub_pdPtr
      .asFunction<_m128d Function(int, _m128d, _m128d, _m128d)>();

  _m256d _mm256_mask_fmaddsub_pd(
    _m256d arg0,
    int arg1,
    _m256d arg2,
    _m256d arg3,
  ) {
    return __mm256_mask_fmaddsub_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_fmaddsub_pdPtr = _lookup<
      ffi.NativeFunction<
          _m256d Function(
              _m256d, __mmask8, _m256d, _m256d)>>('_mm256_mask_fmaddsub_pd');
  late final __mm256_mask_fmaddsub_pd = __mm256_mask_fmaddsub_pdPtr
      .asFunction<_m256d Function(_m256d, int, _m256d, _m256d)>();

  _m256d _mm256_mask3_fmaddsub_pd(
    _m256d arg0,
    _m256d arg1,
    _m256d arg2,
    int arg3,
  ) {
    return __mm256_mask3_fmaddsub_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask3_fmaddsub_pdPtr = _lookup<
      ffi.NativeFunction<
          _m256d Function(
              _m256d, _m256d, _m256d, __mmask8)>>('_mm256_mask3_fmaddsub_pd');
  late final __mm256_mask3_fmaddsub_pd = __mm256_mask3_fmaddsub_pdPtr
      .asFunction<_m256d Function(_m256d, _m256d, _m256d, int)>();

  _m256d _mm256_maskz_fmaddsub_pd(
    int arg0,
    _m256d arg1,
    _m256d arg2,
    _m256d arg3,
  ) {
    return __mm256_maskz_fmaddsub_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_maskz_fmaddsub_pdPtr = _lookup<
      ffi.NativeFunction<
          _m256d Function(
              __mmask8, _m256d, _m256d, _m256d)>>('_mm256_maskz_fmaddsub_pd');
  late final __mm256_maskz_fmaddsub_pd = __mm256_maskz_fmaddsub_pdPtr
      .asFunction<_m256d Function(int, _m256d, _m256d, _m256d)>();

  __m128 _mm_mask_fmaddsub_ps(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    __m128 arg3,
  ) {
    return __mm_mask_fmaddsub_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_fmaddsub_psPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __m128, __mmask8, __m128, __m128)>>('_mm_mask_fmaddsub_ps');
  late final __mm_mask_fmaddsub_ps = __mm_mask_fmaddsub_psPtr
      .asFunction<__m128 Function(__m128, int, __m128, __m128)>();

  __m128 _mm_mask3_fmaddsub_ps(
    __m128 arg0,
    __m128 arg1,
    __m128 arg2,
    int arg3,
  ) {
    return __mm_mask3_fmaddsub_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask3_fmaddsub_psPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __m128, __m128, __m128, __mmask8)>>('_mm_mask3_fmaddsub_ps');
  late final __mm_mask3_fmaddsub_ps = __mm_mask3_fmaddsub_psPtr
      .asFunction<__m128 Function(__m128, __m128, __m128, int)>();

  __m128 _mm_maskz_fmaddsub_ps(
    int arg0,
    __m128 arg1,
    __m128 arg2,
    __m128 arg3,
  ) {
    return __mm_maskz_fmaddsub_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_fmaddsub_psPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __mmask8, __m128, __m128, __m128)>>('_mm_maskz_fmaddsub_ps');
  late final __mm_maskz_fmaddsub_ps = __mm_maskz_fmaddsub_psPtr
      .asFunction<__m128 Function(int, __m128, __m128, __m128)>();

  __m256 _mm256_mask_fmaddsub_ps(
    __m256 arg0,
    int arg1,
    __m256 arg2,
    __m256 arg3,
  ) {
    return __mm256_mask_fmaddsub_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_fmaddsub_psPtr = _lookup<
      ffi.NativeFunction<
          __m256 Function(
              __m256, __mmask8, __m256, __m256)>>('_mm256_mask_fmaddsub_ps');
  late final __mm256_mask_fmaddsub_ps = __mm256_mask_fmaddsub_psPtr
      .asFunction<__m256 Function(__m256, int, __m256, __m256)>();

  __m256 _mm256_mask3_fmaddsub_ps(
    __m256 arg0,
    __m256 arg1,
    __m256 arg2,
    int arg3,
  ) {
    return __mm256_mask3_fmaddsub_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask3_fmaddsub_psPtr = _lookup<
      ffi.NativeFunction<
          __m256 Function(
              __m256, __m256, __m256, __mmask8)>>('_mm256_mask3_fmaddsub_ps');
  late final __mm256_mask3_fmaddsub_ps = __mm256_mask3_fmaddsub_psPtr
      .asFunction<__m256 Function(__m256, __m256, __m256, int)>();

  __m256 _mm256_maskz_fmaddsub_ps(
    int arg0,
    __m256 arg1,
    __m256 arg2,
    __m256 arg3,
  ) {
    return __mm256_maskz_fmaddsub_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_maskz_fmaddsub_psPtr = _lookup<
      ffi.NativeFunction<
          __m256 Function(
              __mmask8, __m256, __m256, __m256)>>('_mm256_maskz_fmaddsub_ps');
  late final __mm256_maskz_fmaddsub_ps = __mm256_maskz_fmaddsub_psPtr
      .asFunction<__m256 Function(int, __m256, __m256, __m256)>();

  _m128d _mm_mask_fmsub_pd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    _m128d arg3,
  ) {
    return __mm_mask_fmsub_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_fmsub_pdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              _m128d, __mmask8, _m128d, _m128d)>>('_mm_mask_fmsub_pd');
  late final __mm_mask_fmsub_pd = __mm_mask_fmsub_pdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d, _m128d)>();

  _m128d _mm_mask3_fmsub_pd(
    _m128d arg0,
    _m128d arg1,
    _m128d arg2,
    int arg3,
  ) {
    return __mm_mask3_fmsub_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask3_fmsub_pdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              _m128d, _m128d, _m128d, __mmask8)>>('_mm_mask3_fmsub_pd');
  late final __mm_mask3_fmsub_pd = __mm_mask3_fmsub_pdPtr
      .asFunction<_m128d Function(_m128d, _m128d, _m128d, int)>();

  _m128d _mm_maskz_fmsub_pd(
    int arg0,
    _m128d arg1,
    _m128d arg2,
    _m128d arg3,
  ) {
    return __mm_maskz_fmsub_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_fmsub_pdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              __mmask8, _m128d, _m128d, _m128d)>>('_mm_maskz_fmsub_pd');
  late final __mm_maskz_fmsub_pd = __mm_maskz_fmsub_pdPtr
      .asFunction<_m128d Function(int, _m128d, _m128d, _m128d)>();

  _m256d _mm256_mask_fmsub_pd(
    _m256d arg0,
    int arg1,
    _m256d arg2,
    _m256d arg3,
  ) {
    return __mm256_mask_fmsub_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_fmsub_pdPtr = _lookup<
      ffi.NativeFunction<
          _m256d Function(
              _m256d, __mmask8, _m256d, _m256d)>>('_mm256_mask_fmsub_pd');
  late final __mm256_mask_fmsub_pd = __mm256_mask_fmsub_pdPtr
      .asFunction<_m256d Function(_m256d, int, _m256d, _m256d)>();

  _m256d _mm256_mask3_fmsub_pd(
    _m256d arg0,
    _m256d arg1,
    _m256d arg2,
    int arg3,
  ) {
    return __mm256_mask3_fmsub_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask3_fmsub_pdPtr = _lookup<
      ffi.NativeFunction<
          _m256d Function(
              _m256d, _m256d, _m256d, __mmask8)>>('_mm256_mask3_fmsub_pd');
  late final __mm256_mask3_fmsub_pd = __mm256_mask3_fmsub_pdPtr
      .asFunction<_m256d Function(_m256d, _m256d, _m256d, int)>();

  _m256d _mm256_maskz_fmsub_pd(
    int arg0,
    _m256d arg1,
    _m256d arg2,
    _m256d arg3,
  ) {
    return __mm256_maskz_fmsub_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_maskz_fmsub_pdPtr = _lookup<
      ffi.NativeFunction<
          _m256d Function(
              __mmask8, _m256d, _m256d, _m256d)>>('_mm256_maskz_fmsub_pd');
  late final __mm256_maskz_fmsub_pd = __mm256_maskz_fmsub_pdPtr
      .asFunction<_m256d Function(int, _m256d, _m256d, _m256d)>();

  __m128 _mm_mask_fmsub_ps(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    __m128 arg3,
  ) {
    return __mm_mask_fmsub_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_fmsub_psPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __m128, __mmask8, __m128, __m128)>>('_mm_mask_fmsub_ps');
  late final __mm_mask_fmsub_ps = __mm_mask_fmsub_psPtr
      .asFunction<__m128 Function(__m128, int, __m128, __m128)>();

  __m128 _mm_mask3_fmsub_ps(
    __m128 arg0,
    __m128 arg1,
    __m128 arg2,
    int arg3,
  ) {
    return __mm_mask3_fmsub_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask3_fmsub_psPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __m128, __m128, __m128, __mmask8)>>('_mm_mask3_fmsub_ps');
  late final __mm_mask3_fmsub_ps = __mm_mask3_fmsub_psPtr
      .asFunction<__m128 Function(__m128, __m128, __m128, int)>();

  __m128 _mm_maskz_fmsub_ps(
    int arg0,
    __m128 arg1,
    __m128 arg2,
    __m128 arg3,
  ) {
    return __mm_maskz_fmsub_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_fmsub_psPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __mmask8, __m128, __m128, __m128)>>('_mm_maskz_fmsub_ps');
  late final __mm_maskz_fmsub_ps = __mm_maskz_fmsub_psPtr
      .asFunction<__m128 Function(int, __m128, __m128, __m128)>();

  __m256 _mm256_mask_fmsub_ps(
    __m256 arg0,
    int arg1,
    __m256 arg2,
    __m256 arg3,
  ) {
    return __mm256_mask_fmsub_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_fmsub_psPtr = _lookup<
      ffi.NativeFunction<
          __m256 Function(
              __m256, __mmask8, __m256, __m256)>>('_mm256_mask_fmsub_ps');
  late final __mm256_mask_fmsub_ps = __mm256_mask_fmsub_psPtr
      .asFunction<__m256 Function(__m256, int, __m256, __m256)>();

  __m256 _mm256_mask3_fmsub_ps(
    __m256 arg0,
    __m256 arg1,
    __m256 arg2,
    int arg3,
  ) {
    return __mm256_mask3_fmsub_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask3_fmsub_psPtr = _lookup<
      ffi.NativeFunction<
          __m256 Function(
              __m256, __m256, __m256, __mmask8)>>('_mm256_mask3_fmsub_ps');
  late final __mm256_mask3_fmsub_ps = __mm256_mask3_fmsub_psPtr
      .asFunction<__m256 Function(__m256, __m256, __m256, int)>();

  __m256 _mm256_maskz_fmsub_ps(
    int arg0,
    __m256 arg1,
    __m256 arg2,
    __m256 arg3,
  ) {
    return __mm256_maskz_fmsub_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_maskz_fmsub_psPtr = _lookup<
      ffi.NativeFunction<
          __m256 Function(
              __mmask8, __m256, __m256, __m256)>>('_mm256_maskz_fmsub_ps');
  late final __mm256_maskz_fmsub_ps = __mm256_maskz_fmsub_psPtr
      .asFunction<__m256 Function(int, __m256, __m256, __m256)>();

  _m128d _mm_mask_fmsubadd_pd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    _m128d arg3,
  ) {
    return __mm_mask_fmsubadd_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_fmsubadd_pdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              _m128d, __mmask8, _m128d, _m128d)>>('_mm_mask_fmsubadd_pd');
  late final __mm_mask_fmsubadd_pd = __mm_mask_fmsubadd_pdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d, _m128d)>();

  _m128d _mm_mask3_fmsubadd_pd(
    _m128d arg0,
    _m128d arg1,
    _m128d arg2,
    int arg3,
  ) {
    return __mm_mask3_fmsubadd_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask3_fmsubadd_pdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              _m128d, _m128d, _m128d, __mmask8)>>('_mm_mask3_fmsubadd_pd');
  late final __mm_mask3_fmsubadd_pd = __mm_mask3_fmsubadd_pdPtr
      .asFunction<_m128d Function(_m128d, _m128d, _m128d, int)>();

  _m128d _mm_maskz_fmsubadd_pd(
    int arg0,
    _m128d arg1,
    _m128d arg2,
    _m128d arg3,
  ) {
    return __mm_maskz_fmsubadd_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_fmsubadd_pdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              __mmask8, _m128d, _m128d, _m128d)>>('_mm_maskz_fmsubadd_pd');
  late final __mm_maskz_fmsubadd_pd = __mm_maskz_fmsubadd_pdPtr
      .asFunction<_m128d Function(int, _m128d, _m128d, _m128d)>();

  _m256d _mm256_mask_fmsubadd_pd(
    _m256d arg0,
    int arg1,
    _m256d arg2,
    _m256d arg3,
  ) {
    return __mm256_mask_fmsubadd_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_fmsubadd_pdPtr = _lookup<
      ffi.NativeFunction<
          _m256d Function(
              _m256d, __mmask8, _m256d, _m256d)>>('_mm256_mask_fmsubadd_pd');
  late final __mm256_mask_fmsubadd_pd = __mm256_mask_fmsubadd_pdPtr
      .asFunction<_m256d Function(_m256d, int, _m256d, _m256d)>();

  _m256d _mm256_mask3_fmsubadd_pd(
    _m256d arg0,
    _m256d arg1,
    _m256d arg2,
    int arg3,
  ) {
    return __mm256_mask3_fmsubadd_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask3_fmsubadd_pdPtr = _lookup<
      ffi.NativeFunction<
          _m256d Function(
              _m256d, _m256d, _m256d, __mmask8)>>('_mm256_mask3_fmsubadd_pd');
  late final __mm256_mask3_fmsubadd_pd = __mm256_mask3_fmsubadd_pdPtr
      .asFunction<_m256d Function(_m256d, _m256d, _m256d, int)>();

  _m256d _mm256_maskz_fmsubadd_pd(
    int arg0,
    _m256d arg1,
    _m256d arg2,
    _m256d arg3,
  ) {
    return __mm256_maskz_fmsubadd_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_maskz_fmsubadd_pdPtr = _lookup<
      ffi.NativeFunction<
          _m256d Function(
              __mmask8, _m256d, _m256d, _m256d)>>('_mm256_maskz_fmsubadd_pd');
  late final __mm256_maskz_fmsubadd_pd = __mm256_maskz_fmsubadd_pdPtr
      .asFunction<_m256d Function(int, _m256d, _m256d, _m256d)>();

  __m128 _mm_mask_fmsubadd_ps(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    __m128 arg3,
  ) {
    return __mm_mask_fmsubadd_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_fmsubadd_psPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __m128, __mmask8, __m128, __m128)>>('_mm_mask_fmsubadd_ps');
  late final __mm_mask_fmsubadd_ps = __mm_mask_fmsubadd_psPtr
      .asFunction<__m128 Function(__m128, int, __m128, __m128)>();

  __m128 _mm_mask3_fmsubadd_ps(
    __m128 arg0,
    __m128 arg1,
    __m128 arg2,
    int arg3,
  ) {
    return __mm_mask3_fmsubadd_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask3_fmsubadd_psPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __m128, __m128, __m128, __mmask8)>>('_mm_mask3_fmsubadd_ps');
  late final __mm_mask3_fmsubadd_ps = __mm_mask3_fmsubadd_psPtr
      .asFunction<__m128 Function(__m128, __m128, __m128, int)>();

  __m128 _mm_maskz_fmsubadd_ps(
    int arg0,
    __m128 arg1,
    __m128 arg2,
    __m128 arg3,
  ) {
    return __mm_maskz_fmsubadd_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_fmsubadd_psPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __mmask8, __m128, __m128, __m128)>>('_mm_maskz_fmsubadd_ps');
  late final __mm_maskz_fmsubadd_ps = __mm_maskz_fmsubadd_psPtr
      .asFunction<__m128 Function(int, __m128, __m128, __m128)>();

  __m256 _mm256_mask_fmsubadd_ps(
    __m256 arg0,
    int arg1,
    __m256 arg2,
    __m256 arg3,
  ) {
    return __mm256_mask_fmsubadd_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_fmsubadd_psPtr = _lookup<
      ffi.NativeFunction<
          __m256 Function(
              __m256, __mmask8, __m256, __m256)>>('_mm256_mask_fmsubadd_ps');
  late final __mm256_mask_fmsubadd_ps = __mm256_mask_fmsubadd_psPtr
      .asFunction<__m256 Function(__m256, int, __m256, __m256)>();

  __m256 _mm256_mask3_fmsubadd_ps(
    __m256 arg0,
    __m256 arg1,
    __m256 arg2,
    int arg3,
  ) {
    return __mm256_mask3_fmsubadd_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask3_fmsubadd_psPtr = _lookup<
      ffi.NativeFunction<
          __m256 Function(
              __m256, __m256, __m256, __mmask8)>>('_mm256_mask3_fmsubadd_ps');
  late final __mm256_mask3_fmsubadd_ps = __mm256_mask3_fmsubadd_psPtr
      .asFunction<__m256 Function(__m256, __m256, __m256, int)>();

  __m256 _mm256_maskz_fmsubadd_ps(
    int arg0,
    __m256 arg1,
    __m256 arg2,
    __m256 arg3,
  ) {
    return __mm256_maskz_fmsubadd_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_maskz_fmsubadd_psPtr = _lookup<
      ffi.NativeFunction<
          __m256 Function(
              __mmask8, __m256, __m256, __m256)>>('_mm256_maskz_fmsubadd_ps');
  late final __mm256_maskz_fmsubadd_ps = __mm256_maskz_fmsubadd_psPtr
      .asFunction<__m256 Function(int, __m256, __m256, __m256)>();

  _m128d _mm_mask_fnmadd_pd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    _m128d arg3,
  ) {
    return __mm_mask_fnmadd_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_fnmadd_pdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              _m128d, __mmask8, _m128d, _m128d)>>('_mm_mask_fnmadd_pd');
  late final __mm_mask_fnmadd_pd = __mm_mask_fnmadd_pdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d, _m128d)>();

  _m128d _mm_mask3_fnmadd_pd(
    _m128d arg0,
    _m128d arg1,
    _m128d arg2,
    int arg3,
  ) {
    return __mm_mask3_fnmadd_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask3_fnmadd_pdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              _m128d, _m128d, _m128d, __mmask8)>>('_mm_mask3_fnmadd_pd');
  late final __mm_mask3_fnmadd_pd = __mm_mask3_fnmadd_pdPtr
      .asFunction<_m128d Function(_m128d, _m128d, _m128d, int)>();

  _m128d _mm_maskz_fnmadd_pd(
    int arg0,
    _m128d arg1,
    _m128d arg2,
    _m128d arg3,
  ) {
    return __mm_maskz_fnmadd_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_fnmadd_pdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              __mmask8, _m128d, _m128d, _m128d)>>('_mm_maskz_fnmadd_pd');
  late final __mm_maskz_fnmadd_pd = __mm_maskz_fnmadd_pdPtr
      .asFunction<_m128d Function(int, _m128d, _m128d, _m128d)>();

  _m256d _mm256_mask_fnmadd_pd(
    _m256d arg0,
    int arg1,
    _m256d arg2,
    _m256d arg3,
  ) {
    return __mm256_mask_fnmadd_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_fnmadd_pdPtr = _lookup<
      ffi.NativeFunction<
          _m256d Function(
              _m256d, __mmask8, _m256d, _m256d)>>('_mm256_mask_fnmadd_pd');
  late final __mm256_mask_fnmadd_pd = __mm256_mask_fnmadd_pdPtr
      .asFunction<_m256d Function(_m256d, int, _m256d, _m256d)>();

  _m256d _mm256_mask3_fnmadd_pd(
    _m256d arg0,
    _m256d arg1,
    _m256d arg2,
    int arg3,
  ) {
    return __mm256_mask3_fnmadd_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask3_fnmadd_pdPtr = _lookup<
      ffi.NativeFunction<
          _m256d Function(
              _m256d, _m256d, _m256d, __mmask8)>>('_mm256_mask3_fnmadd_pd');
  late final __mm256_mask3_fnmadd_pd = __mm256_mask3_fnmadd_pdPtr
      .asFunction<_m256d Function(_m256d, _m256d, _m256d, int)>();

  _m256d _mm256_maskz_fnmadd_pd(
    int arg0,
    _m256d arg1,
    _m256d arg2,
    _m256d arg3,
  ) {
    return __mm256_maskz_fnmadd_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_maskz_fnmadd_pdPtr = _lookup<
      ffi.NativeFunction<
          _m256d Function(
              __mmask8, _m256d, _m256d, _m256d)>>('_mm256_maskz_fnmadd_pd');
  late final __mm256_maskz_fnmadd_pd = __mm256_maskz_fnmadd_pdPtr
      .asFunction<_m256d Function(int, _m256d, _m256d, _m256d)>();

  __m128 _mm_mask_fnmadd_ps(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    __m128 arg3,
  ) {
    return __mm_mask_fnmadd_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_fnmadd_psPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __m128, __mmask8, __m128, __m128)>>('_mm_mask_fnmadd_ps');
  late final __mm_mask_fnmadd_ps = __mm_mask_fnmadd_psPtr
      .asFunction<__m128 Function(__m128, int, __m128, __m128)>();

  __m128 _mm_mask3_fnmadd_ps(
    __m128 arg0,
    __m128 arg1,
    __m128 arg2,
    int arg3,
  ) {
    return __mm_mask3_fnmadd_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask3_fnmadd_psPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __m128, __m128, __m128, __mmask8)>>('_mm_mask3_fnmadd_ps');
  late final __mm_mask3_fnmadd_ps = __mm_mask3_fnmadd_psPtr
      .asFunction<__m128 Function(__m128, __m128, __m128, int)>();

  __m128 _mm_maskz_fnmadd_ps(
    int arg0,
    __m128 arg1,
    __m128 arg2,
    __m128 arg3,
  ) {
    return __mm_maskz_fnmadd_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_fnmadd_psPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __mmask8, __m128, __m128, __m128)>>('_mm_maskz_fnmadd_ps');
  late final __mm_maskz_fnmadd_ps = __mm_maskz_fnmadd_psPtr
      .asFunction<__m128 Function(int, __m128, __m128, __m128)>();

  __m256 _mm256_mask_fnmadd_ps(
    __m256 arg0,
    int arg1,
    __m256 arg2,
    __m256 arg3,
  ) {
    return __mm256_mask_fnmadd_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_fnmadd_psPtr = _lookup<
      ffi.NativeFunction<
          __m256 Function(
              __m256, __mmask8, __m256, __m256)>>('_mm256_mask_fnmadd_ps');
  late final __mm256_mask_fnmadd_ps = __mm256_mask_fnmadd_psPtr
      .asFunction<__m256 Function(__m256, int, __m256, __m256)>();

  __m256 _mm256_mask3_fnmadd_ps(
    __m256 arg0,
    __m256 arg1,
    __m256 arg2,
    int arg3,
  ) {
    return __mm256_mask3_fnmadd_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask3_fnmadd_psPtr = _lookup<
      ffi.NativeFunction<
          __m256 Function(
              __m256, __m256, __m256, __mmask8)>>('_mm256_mask3_fnmadd_ps');
  late final __mm256_mask3_fnmadd_ps = __mm256_mask3_fnmadd_psPtr
      .asFunction<__m256 Function(__m256, __m256, __m256, int)>();

  __m256 _mm256_maskz_fnmadd_ps(
    int arg0,
    __m256 arg1,
    __m256 arg2,
    __m256 arg3,
  ) {
    return __mm256_maskz_fnmadd_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_maskz_fnmadd_psPtr = _lookup<
      ffi.NativeFunction<
          __m256 Function(
              __mmask8, __m256, __m256, __m256)>>('_mm256_maskz_fnmadd_ps');
  late final __mm256_maskz_fnmadd_ps = __mm256_maskz_fnmadd_psPtr
      .asFunction<__m256 Function(int, __m256, __m256, __m256)>();

  _m128d _mm_mask_fnmsub_pd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    _m128d arg3,
  ) {
    return __mm_mask_fnmsub_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_fnmsub_pdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              _m128d, __mmask8, _m128d, _m128d)>>('_mm_mask_fnmsub_pd');
  late final __mm_mask_fnmsub_pd = __mm_mask_fnmsub_pdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d, _m128d)>();

  _m128d _mm_mask3_fnmsub_pd(
    _m128d arg0,
    _m128d arg1,
    _m128d arg2,
    int arg3,
  ) {
    return __mm_mask3_fnmsub_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask3_fnmsub_pdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              _m128d, _m128d, _m128d, __mmask8)>>('_mm_mask3_fnmsub_pd');
  late final __mm_mask3_fnmsub_pd = __mm_mask3_fnmsub_pdPtr
      .asFunction<_m128d Function(_m128d, _m128d, _m128d, int)>();

  _m128d _mm_maskz_fnmsub_pd(
    int arg0,
    _m128d arg1,
    _m128d arg2,
    _m128d arg3,
  ) {
    return __mm_maskz_fnmsub_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_fnmsub_pdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              __mmask8, _m128d, _m128d, _m128d)>>('_mm_maskz_fnmsub_pd');
  late final __mm_maskz_fnmsub_pd = __mm_maskz_fnmsub_pdPtr
      .asFunction<_m128d Function(int, _m128d, _m128d, _m128d)>();

  _m256d _mm256_mask_fnmsub_pd(
    _m256d arg0,
    int arg1,
    _m256d arg2,
    _m256d arg3,
  ) {
    return __mm256_mask_fnmsub_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_fnmsub_pdPtr = _lookup<
      ffi.NativeFunction<
          _m256d Function(
              _m256d, __mmask8, _m256d, _m256d)>>('_mm256_mask_fnmsub_pd');
  late final __mm256_mask_fnmsub_pd = __mm256_mask_fnmsub_pdPtr
      .asFunction<_m256d Function(_m256d, int, _m256d, _m256d)>();

  _m256d _mm256_mask3_fnmsub_pd(
    _m256d arg0,
    _m256d arg1,
    _m256d arg2,
    int arg3,
  ) {
    return __mm256_mask3_fnmsub_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask3_fnmsub_pdPtr = _lookup<
      ffi.NativeFunction<
          _m256d Function(
              _m256d, _m256d, _m256d, __mmask8)>>('_mm256_mask3_fnmsub_pd');
  late final __mm256_mask3_fnmsub_pd = __mm256_mask3_fnmsub_pdPtr
      .asFunction<_m256d Function(_m256d, _m256d, _m256d, int)>();

  _m256d _mm256_maskz_fnmsub_pd(
    int arg0,
    _m256d arg1,
    _m256d arg2,
    _m256d arg3,
  ) {
    return __mm256_maskz_fnmsub_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_maskz_fnmsub_pdPtr = _lookup<
      ffi.NativeFunction<
          _m256d Function(
              __mmask8, _m256d, _m256d, _m256d)>>('_mm256_maskz_fnmsub_pd');
  late final __mm256_maskz_fnmsub_pd = __mm256_maskz_fnmsub_pdPtr
      .asFunction<_m256d Function(int, _m256d, _m256d, _m256d)>();

  __m128 _mm_mask_fnmsub_ps(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    __m128 arg3,
  ) {
    return __mm_mask_fnmsub_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_fnmsub_psPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __m128, __mmask8, __m128, __m128)>>('_mm_mask_fnmsub_ps');
  late final __mm_mask_fnmsub_ps = __mm_mask_fnmsub_psPtr
      .asFunction<__m128 Function(__m128, int, __m128, __m128)>();

  __m128 _mm_mask3_fnmsub_ps(
    __m128 arg0,
    __m128 arg1,
    __m128 arg2,
    int arg3,
  ) {
    return __mm_mask3_fnmsub_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask3_fnmsub_psPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __m128, __m128, __m128, __mmask8)>>('_mm_mask3_fnmsub_ps');
  late final __mm_mask3_fnmsub_ps = __mm_mask3_fnmsub_psPtr
      .asFunction<__m128 Function(__m128, __m128, __m128, int)>();

  __m128 _mm_maskz_fnmsub_ps(
    int arg0,
    __m128 arg1,
    __m128 arg2,
    __m128 arg3,
  ) {
    return __mm_maskz_fnmsub_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_fnmsub_psPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __mmask8, __m128, __m128, __m128)>>('_mm_maskz_fnmsub_ps');
  late final __mm_maskz_fnmsub_ps = __mm_maskz_fnmsub_psPtr
      .asFunction<__m128 Function(int, __m128, __m128, __m128)>();

  __m256 _mm256_mask_fnmsub_ps(
    __m256 arg0,
    int arg1,
    __m256 arg2,
    __m256 arg3,
  ) {
    return __mm256_mask_fnmsub_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_fnmsub_psPtr = _lookup<
      ffi.NativeFunction<
          __m256 Function(
              __m256, __mmask8, __m256, __m256)>>('_mm256_mask_fnmsub_ps');
  late final __mm256_mask_fnmsub_ps = __mm256_mask_fnmsub_psPtr
      .asFunction<__m256 Function(__m256, int, __m256, __m256)>();

  __m256 _mm256_mask3_fnmsub_ps(
    __m256 arg0,
    __m256 arg1,
    __m256 arg2,
    int arg3,
  ) {
    return __mm256_mask3_fnmsub_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask3_fnmsub_psPtr = _lookup<
      ffi.NativeFunction<
          __m256 Function(
              __m256, __m256, __m256, __mmask8)>>('_mm256_mask3_fnmsub_ps');
  late final __mm256_mask3_fnmsub_ps = __mm256_mask3_fnmsub_psPtr
      .asFunction<__m256 Function(__m256, __m256, __m256, int)>();

  __m256 _mm256_maskz_fnmsub_ps(
    int arg0,
    __m256 arg1,
    __m256 arg2,
    __m256 arg3,
  ) {
    return __mm256_maskz_fnmsub_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_maskz_fnmsub_psPtr = _lookup<
      ffi.NativeFunction<
          __m256 Function(
              __mmask8, __m256, __m256, __m256)>>('_mm256_maskz_fnmsub_ps');
  late final __mm256_maskz_fnmsub_ps = __mm256_maskz_fnmsub_psPtr
      .asFunction<__m256 Function(int, __m256, __m256, __m256)>();

  int _mm_fpclass_pd_mask(
    _m128d arg0,
    int arg1,
  ) {
    return __mm_fpclass_pd_mask(
      arg0,
      arg1,
    );
  }

  late final __mm_fpclass_pd_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(_m128d, ffi.Int32)>>(
          '_mm_fpclass_pd_mask');
  late final __mm_fpclass_pd_mask =
      __mm_fpclass_pd_maskPtr.asFunction<int Function(_m128d, int)>();

  int _mm_mask_fpclass_pd_mask(
    int arg0,
    _m128d arg1,
    int arg2,
  ) {
    return __mm_mask_fpclass_pd_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_fpclass_pd_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, _m128d, ffi.Int32)>>(
      '_mm_mask_fpclass_pd_mask');
  late final __mm_mask_fpclass_pd_mask =
      __mm_mask_fpclass_pd_maskPtr.asFunction<int Function(int, _m128d, int)>();

  int _mm256_fpclass_pd_mask(
    _m256d arg0,
    int arg1,
  ) {
    return __mm256_fpclass_pd_mask(
      arg0,
      arg1,
    );
  }

  late final __mm256_fpclass_pd_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(_m256d, ffi.Int32)>>(
          '_mm256_fpclass_pd_mask');
  late final __mm256_fpclass_pd_mask =
      __mm256_fpclass_pd_maskPtr.asFunction<int Function(_m256d, int)>();

  int _mm256_mask_fpclass_pd_mask(
    int arg0,
    _m256d arg1,
    int arg2,
  ) {
    return __mm256_mask_fpclass_pd_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_fpclass_pd_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, _m256d, ffi.Int32)>>(
      '_mm256_mask_fpclass_pd_mask');
  late final __mm256_mask_fpclass_pd_mask = __mm256_mask_fpclass_pd_maskPtr
      .asFunction<int Function(int, _m256d, int)>();

  int _mm_fpclass_ps_mask(
    __m128 arg0,
    int arg1,
  ) {
    return __mm_fpclass_ps_mask(
      arg0,
      arg1,
    );
  }

  late final __mm_fpclass_ps_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m128, ffi.Int32)>>(
          '_mm_fpclass_ps_mask');
  late final __mm_fpclass_ps_mask =
      __mm_fpclass_ps_maskPtr.asFunction<int Function(__m128, int)>();

  int _mm_mask_fpclass_ps_mask(
    int arg0,
    __m128 arg1,
    int arg2,
  ) {
    return __mm_mask_fpclass_ps_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_fpclass_ps_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m128, ffi.Int32)>>(
      '_mm_mask_fpclass_ps_mask');
  late final __mm_mask_fpclass_ps_mask =
      __mm_mask_fpclass_ps_maskPtr.asFunction<int Function(int, __m128, int)>();

  int _mm256_fpclass_ps_mask(
    __m256 arg0,
    int arg1,
  ) {
    return __mm256_fpclass_ps_mask(
      arg0,
      arg1,
    );
  }

  late final __mm256_fpclass_ps_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m256, ffi.Int32)>>(
          '_mm256_fpclass_ps_mask');
  late final __mm256_fpclass_ps_mask =
      __mm256_fpclass_ps_maskPtr.asFunction<int Function(__m256, int)>();

  int _mm256_mask_fpclass_ps_mask(
    int arg0,
    __m256 arg1,
    int arg2,
  ) {
    return __mm256_mask_fpclass_ps_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_fpclass_ps_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m256, ffi.Int32)>>(
      '_mm256_mask_fpclass_ps_mask');
  late final __mm256_mask_fpclass_ps_mask = __mm256_mask_fpclass_ps_maskPtr
      .asFunction<int Function(int, __m256, int)>();

  _m128d _mm_getexp_pd(
    _m128d arg0,
  ) {
    return __mm_getexp_pd(
      arg0,
    );
  }

  late final __mm_getexp_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d)>>('_mm_getexp_pd');
  late final __mm_getexp_pd =
      __mm_getexp_pdPtr.asFunction<_m128d Function(_m128d)>();

  _m128d _mm_mask_getexp_pd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
  ) {
    return __mm_mask_getexp_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_getexp_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, __mmask8, _m128d)>>(
          '_mm_mask_getexp_pd');
  late final __mm_mask_getexp_pd =
      __mm_mask_getexp_pdPtr.asFunction<_m128d Function(_m128d, int, _m128d)>();

  _m128d _mm_maskz_getexp_pd(
    int arg0,
    _m128d arg1,
  ) {
    return __mm_maskz_getexp_pd(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_getexp_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(__mmask8, _m128d)>>(
          '_mm_maskz_getexp_pd');
  late final __mm_maskz_getexp_pd =
      __mm_maskz_getexp_pdPtr.asFunction<_m128d Function(int, _m128d)>();

  _m256d _mm256_getexp_pd(
    _m256d arg0,
  ) {
    return __mm256_getexp_pd(
      arg0,
    );
  }

  late final __mm256_getexp_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d)>>('_mm256_getexp_pd');
  late final __mm256_getexp_pd =
      __mm256_getexp_pdPtr.asFunction<_m256d Function(_m256d)>();

  _m256d _mm256_mask_getexp_pd(
    _m256d arg0,
    int arg1,
    _m256d arg2,
  ) {
    return __mm256_mask_getexp_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_getexp_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d, __mmask8, _m256d)>>(
          '_mm256_mask_getexp_pd');
  late final __mm256_mask_getexp_pd = __mm256_mask_getexp_pdPtr
      .asFunction<_m256d Function(_m256d, int, _m256d)>();

  _m256d _mm256_maskz_getexp_pd(
    int arg0,
    _m256d arg1,
  ) {
    return __mm256_maskz_getexp_pd(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_getexp_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(__mmask8, _m256d)>>(
          '_mm256_maskz_getexp_pd');
  late final __mm256_maskz_getexp_pd =
      __mm256_maskz_getexp_pdPtr.asFunction<_m256d Function(int, _m256d)>();

  __m128 _mm_getexp_ps(
    __m128 arg0,
  ) {
    return __mm_getexp_ps(
      arg0,
    );
  }

  late final __mm_getexp_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128)>>('_mm_getexp_ps');
  late final __mm_getexp_ps =
      __mm_getexp_psPtr.asFunction<__m128 Function(__m128)>();

  __m128 _mm_mask_getexp_ps(
    __m128 arg0,
    int arg1,
    __m128 arg2,
  ) {
    return __mm_mask_getexp_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_getexp_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __mmask8, __m128)>>(
          '_mm_mask_getexp_ps');
  late final __mm_mask_getexp_ps =
      __mm_mask_getexp_psPtr.asFunction<__m128 Function(__m128, int, __m128)>();

  __m128 _mm_maskz_getexp_ps(
    int arg0,
    __m128 arg1,
  ) {
    return __mm_maskz_getexp_ps(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_getexp_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__mmask8, __m128)>>(
          '_mm_maskz_getexp_ps');
  late final __mm_maskz_getexp_ps =
      __mm_maskz_getexp_psPtr.asFunction<__m128 Function(int, __m128)>();

  __m256 _mm256_getexp_ps(
    __m256 arg0,
  ) {
    return __mm256_getexp_ps(
      arg0,
    );
  }

  late final __mm256_getexp_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256)>>('_mm256_getexp_ps');
  late final __mm256_getexp_ps =
      __mm256_getexp_psPtr.asFunction<__m256 Function(__m256)>();

  __m256 _mm256_mask_getexp_ps(
    __m256 arg0,
    int arg1,
    __m256 arg2,
  ) {
    return __mm256_mask_getexp_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_getexp_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256, __mmask8, __m256)>>(
          '_mm256_mask_getexp_ps');
  late final __mm256_mask_getexp_ps = __mm256_mask_getexp_psPtr
      .asFunction<__m256 Function(__m256, int, __m256)>();

  __m256 _mm256_maskz_getexp_ps(
    int arg0,
    __m256 arg1,
  ) {
    return __mm256_maskz_getexp_ps(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_getexp_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__mmask8, __m256)>>(
          '_mm256_maskz_getexp_ps');
  late final __mm256_maskz_getexp_ps =
      __mm256_maskz_getexp_psPtr.asFunction<__m256 Function(int, __m256)>();

  _m128d _mm_getmant_pd(
    _m128d arg0,
    int arg1,
    int arg2,
  ) {
    return __mm_getmant_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_getmant_pdPtr = _lookup<
          ffi.NativeFunction<_m128d Function(_m128d, ffi.Int32, ffi.Int32)>>(
      '_mm_getmant_pd');
  late final __mm_getmant_pd =
      __mm_getmant_pdPtr.asFunction<_m128d Function(_m128d, int, int)>();

  _m128d _mm_mask_getmant_pd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    int arg3,
    int arg4,
  ) {
    return __mm_mask_getmant_pd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_getmant_pdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(_m128d, __mmask8, _m128d, ffi.Int32,
              ffi.Int32)>>('_mm_mask_getmant_pd');
  late final __mm_mask_getmant_pd = __mm_mask_getmant_pdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d, int, int)>();

  _m128d _mm_maskz_getmant_pd(
    int arg0,
    _m128d arg1,
    int arg2,
    int arg3,
  ) {
    return __mm_maskz_getmant_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_getmant_pdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              __mmask8, _m128d, ffi.Int32, ffi.Int32)>>('_mm_maskz_getmant_pd');
  late final __mm_maskz_getmant_pd = __mm_maskz_getmant_pdPtr
      .asFunction<_m128d Function(int, _m128d, int, int)>();

  _m256d _mm256_getmant_pd(
    _m256d arg0,
    int arg1,
    int arg2,
  ) {
    return __mm256_getmant_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_getmant_pdPtr = _lookup<
          ffi.NativeFunction<_m256d Function(_m256d, ffi.Int32, ffi.Int32)>>(
      '_mm256_getmant_pd');
  late final __mm256_getmant_pd =
      __mm256_getmant_pdPtr.asFunction<_m256d Function(_m256d, int, int)>();

  _m256d _mm256_mask_getmant_pd(
    _m256d arg0,
    int arg1,
    _m256d arg2,
    int arg3,
    int arg4,
  ) {
    return __mm256_mask_getmant_pd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm256_mask_getmant_pdPtr = _lookup<
      ffi.NativeFunction<
          _m256d Function(_m256d, __mmask8, _m256d, ffi.Int32,
              ffi.Int32)>>('_mm256_mask_getmant_pd');
  late final __mm256_mask_getmant_pd = __mm256_mask_getmant_pdPtr
      .asFunction<_m256d Function(_m256d, int, _m256d, int, int)>();

  _m256d _mm256_maskz_getmant_pd(
    int arg0,
    _m256d arg1,
    int arg2,
    int arg3,
  ) {
    return __mm256_maskz_getmant_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_maskz_getmant_pdPtr = _lookup<
      ffi.NativeFunction<
          _m256d Function(__mmask8, _m256d, ffi.Int32,
              ffi.Int32)>>('_mm256_maskz_getmant_pd');
  late final __mm256_maskz_getmant_pd = __mm256_maskz_getmant_pdPtr
      .asFunction<_m256d Function(int, _m256d, int, int)>();

  __m128 _mm_getmant_ps(
    __m128 arg0,
    int arg1,
    int arg2,
  ) {
    return __mm_getmant_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_getmant_psPtr = _lookup<
          ffi.NativeFunction<__m128 Function(__m128, ffi.Int32, ffi.Int32)>>(
      '_mm_getmant_ps');
  late final __mm_getmant_ps =
      __mm_getmant_psPtr.asFunction<__m128 Function(__m128, int, int)>();

  __m128 _mm_mask_getmant_ps(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    int arg3,
    int arg4,
  ) {
    return __mm_mask_getmant_ps(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_getmant_psPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(__m128, __mmask8, __m128, ffi.Int32,
              ffi.Int32)>>('_mm_mask_getmant_ps');
  late final __mm_mask_getmant_ps = __mm_mask_getmant_psPtr
      .asFunction<__m128 Function(__m128, int, __m128, int, int)>();

  __m128 _mm_maskz_getmant_ps(
    int arg0,
    __m128 arg1,
    int arg2,
    int arg3,
  ) {
    return __mm_maskz_getmant_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_getmant_psPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __mmask8, __m128, ffi.Int32, ffi.Int32)>>('_mm_maskz_getmant_ps');
  late final __mm_maskz_getmant_ps = __mm_maskz_getmant_psPtr
      .asFunction<__m128 Function(int, __m128, int, int)>();

  __m256 _mm256_getmant_ps(
    __m256 arg0,
    int arg1,
    int arg2,
  ) {
    return __mm256_getmant_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_getmant_psPtr = _lookup<
          ffi.NativeFunction<__m256 Function(__m256, ffi.Int32, ffi.Int32)>>(
      '_mm256_getmant_ps');
  late final __mm256_getmant_ps =
      __mm256_getmant_psPtr.asFunction<__m256 Function(__m256, int, int)>();

  __m256 _mm256_mask_getmant_ps(
    __m256 arg0,
    int arg1,
    __m256 arg2,
    int arg3,
    int arg4,
  ) {
    return __mm256_mask_getmant_ps(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm256_mask_getmant_psPtr = _lookup<
      ffi.NativeFunction<
          __m256 Function(__m256, __mmask8, __m256, ffi.Int32,
              ffi.Int32)>>('_mm256_mask_getmant_ps');
  late final __mm256_mask_getmant_ps = __mm256_mask_getmant_psPtr
      .asFunction<__m256 Function(__m256, int, __m256, int, int)>();

  __m256 _mm256_maskz_getmant_ps(
    int arg0,
    __m256 arg1,
    int arg2,
    int arg3,
  ) {
    return __mm256_maskz_getmant_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_maskz_getmant_psPtr = _lookup<
      ffi.NativeFunction<
          __m256 Function(__mmask8, __m256, ffi.Int32,
              ffi.Int32)>>('_mm256_maskz_getmant_ps');
  late final __mm256_maskz_getmant_ps = __mm256_maskz_getmant_psPtr
      .asFunction<__m256 Function(int, __m256, int, int)>();

  __m128i _mm_mmask_i32gather_epi32(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    ffi.Pointer<ffi.Void> arg3,
    int arg4,
  ) {
    return __mm_mmask_i32gather_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mmask_i32gather_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(__m128i, __mmask8, __m128i, ffi.Pointer<ffi.Void>,
              ffi.Int32)>>('_mm_mmask_i32gather_epi32');
  late final __mm_mmask_i32gather_epi32 =
      __mm_mmask_i32gather_epi32Ptr.asFunction<
          __m128i Function(
              __m128i, int, __m128i, ffi.Pointer<ffi.Void>, int)>();

  __m256i _mm256_mmask_i32gather_epi32(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    ffi.Pointer<ffi.Void> arg3,
    int arg4,
  ) {
    return __mm256_mmask_i32gather_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm256_mmask_i32gather_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask8, __m256i, ffi.Pointer<ffi.Void>,
              ffi.Int32)>>('_mm256_mmask_i32gather_epi32');
  late final __mm256_mmask_i32gather_epi32 =
      __mm256_mmask_i32gather_epi32Ptr.asFunction<
          __m256i Function(
              __m256i, int, __m256i, ffi.Pointer<ffi.Void>, int)>();

  __m128i _mm_mmask_i32gather_epi64(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    ffi.Pointer<ffi.Void> arg3,
    int arg4,
  ) {
    return __mm_mmask_i32gather_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mmask_i32gather_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(__m128i, __mmask8, __m128i, ffi.Pointer<ffi.Void>,
              ffi.Int32)>>('_mm_mmask_i32gather_epi64');
  late final __mm_mmask_i32gather_epi64 =
      __mm_mmask_i32gather_epi64Ptr.asFunction<
          __m128i Function(
              __m128i, int, __m128i, ffi.Pointer<ffi.Void>, int)>();

  __m256i _mm256_mmask_i32gather_epi64(
    __m256i arg0,
    int arg1,
    __m128i arg2,
    ffi.Pointer<ffi.Void> arg3,
    int arg4,
  ) {
    return __mm256_mmask_i32gather_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm256_mmask_i32gather_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask8, __m128i, ffi.Pointer<ffi.Void>,
              ffi.Int32)>>('_mm256_mmask_i32gather_epi64');
  late final __mm256_mmask_i32gather_epi64 =
      __mm256_mmask_i32gather_epi64Ptr.asFunction<
          __m256i Function(
              __m256i, int, __m128i, ffi.Pointer<ffi.Void>, int)>();

  _m128d _mm_mmask_i32gather_pd(
    _m128d arg0,
    int arg1,
    __m128i arg2,
    ffi.Pointer<ffi.Void> arg3,
    int arg4,
  ) {
    return __mm_mmask_i32gather_pd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mmask_i32gather_pdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(_m128d, __mmask8, __m128i, ffi.Pointer<ffi.Void>,
              ffi.Int32)>>('_mm_mmask_i32gather_pd');
  late final __mm_mmask_i32gather_pd = __mm_mmask_i32gather_pdPtr.asFunction<
      _m128d Function(_m128d, int, __m128i, ffi.Pointer<ffi.Void>, int)>();

  _m256d _mm256_mmask_i32gather_pd(
    _m256d arg0,
    int arg1,
    __m128i arg2,
    ffi.Pointer<ffi.Void> arg3,
    int arg4,
  ) {
    return __mm256_mmask_i32gather_pd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm256_mmask_i32gather_pdPtr = _lookup<
      ffi.NativeFunction<
          _m256d Function(_m256d, __mmask8, __m128i, ffi.Pointer<ffi.Void>,
              ffi.Int32)>>('_mm256_mmask_i32gather_pd');
  late final __mm256_mmask_i32gather_pd =
      __mm256_mmask_i32gather_pdPtr.asFunction<
          _m256d Function(_m256d, int, __m128i, ffi.Pointer<ffi.Void>, int)>();

  __m128 _mm_mmask_i32gather_ps(
    __m128 arg0,
    int arg1,
    __m128i arg2,
    ffi.Pointer<ffi.Void> arg3,
    int arg4,
  ) {
    return __mm_mmask_i32gather_ps(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mmask_i32gather_psPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(__m128, __mmask8, __m128i, ffi.Pointer<ffi.Void>,
              ffi.Int32)>>('_mm_mmask_i32gather_ps');
  late final __mm_mmask_i32gather_ps = __mm_mmask_i32gather_psPtr.asFunction<
      __m128 Function(__m128, int, __m128i, ffi.Pointer<ffi.Void>, int)>();

  __m256 _mm256_mmask_i32gather_ps(
    __m256 arg0,
    int arg1,
    __m256i arg2,
    ffi.Pointer<ffi.Void> arg3,
    int arg4,
  ) {
    return __mm256_mmask_i32gather_ps(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm256_mmask_i32gather_psPtr = _lookup<
      ffi.NativeFunction<
          __m256 Function(__m256, __mmask8, __m256i, ffi.Pointer<ffi.Void>,
              ffi.Int32)>>('_mm256_mmask_i32gather_ps');
  late final __mm256_mmask_i32gather_ps =
      __mm256_mmask_i32gather_psPtr.asFunction<
          __m256 Function(__m256, int, __m256i, ffi.Pointer<ffi.Void>, int)>();

  void _mm_i32scatter_epi32(
    ffi.Pointer<ffi.Void> arg0,
    __m128i arg1,
    __m128i arg2,
    int arg3,
  ) {
    return __mm_i32scatter_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_i32scatter_epi32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __m128i, __m128i,
              ffi.Int32)>>('_mm_i32scatter_epi32');
  late final __mm_i32scatter_epi32 = __mm_i32scatter_epi32Ptr.asFunction<
      void Function(ffi.Pointer<ffi.Void>, __m128i, __m128i, int)>();

  void _mm_mask_i32scatter_epi32(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
    int arg4,
  ) {
    return __mm_mask_i32scatter_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_i32scatter_epi32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8, __m128i, __m128i,
              ffi.Int32)>>('_mm_mask_i32scatter_epi32');
  late final __mm_mask_i32scatter_epi32 =
      __mm_mask_i32scatter_epi32Ptr.asFunction<
          void Function(ffi.Pointer<ffi.Void>, int, __m128i, __m128i, int)>();

  void _mm256_i32scatter_epi32(
    ffi.Pointer<ffi.Void> arg0,
    __m256i arg1,
    __m256i arg2,
    int arg3,
  ) {
    return __mm256_i32scatter_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_i32scatter_epi32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __m256i, __m256i,
              ffi.Int32)>>('_mm256_i32scatter_epi32');
  late final __mm256_i32scatter_epi32 = __mm256_i32scatter_epi32Ptr.asFunction<
      void Function(ffi.Pointer<ffi.Void>, __m256i, __m256i, int)>();

  void _mm256_mask_i32scatter_epi32(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
    int arg4,
  ) {
    return __mm256_mask_i32scatter_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm256_mask_i32scatter_epi32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8, __m256i, __m256i,
              ffi.Int32)>>('_mm256_mask_i32scatter_epi32');
  late final __mm256_mask_i32scatter_epi32 =
      __mm256_mask_i32scatter_epi32Ptr.asFunction<
          void Function(ffi.Pointer<ffi.Void>, int, __m256i, __m256i, int)>();

  void _mm_i32scatter_epi64(
    ffi.Pointer<ffi.Void> arg0,
    __m128i arg1,
    __m128i arg2,
    int arg3,
  ) {
    return __mm_i32scatter_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_i32scatter_epi64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __m128i, __m128i,
              ffi.Int32)>>('_mm_i32scatter_epi64');
  late final __mm_i32scatter_epi64 = __mm_i32scatter_epi64Ptr.asFunction<
      void Function(ffi.Pointer<ffi.Void>, __m128i, __m128i, int)>();

  void _mm_mask_i32scatter_epi64(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
    int arg4,
  ) {
    return __mm_mask_i32scatter_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_i32scatter_epi64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8, __m128i, __m128i,
              ffi.Int32)>>('_mm_mask_i32scatter_epi64');
  late final __mm_mask_i32scatter_epi64 =
      __mm_mask_i32scatter_epi64Ptr.asFunction<
          void Function(ffi.Pointer<ffi.Void>, int, __m128i, __m128i, int)>();

  void _mm256_i32scatter_epi64(
    ffi.Pointer<ffi.Void> arg0,
    __m128i arg1,
    __m256i arg2,
    int arg3,
  ) {
    return __mm256_i32scatter_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_i32scatter_epi64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __m128i, __m256i,
              ffi.Int32)>>('_mm256_i32scatter_epi64');
  late final __mm256_i32scatter_epi64 = __mm256_i32scatter_epi64Ptr.asFunction<
      void Function(ffi.Pointer<ffi.Void>, __m128i, __m256i, int)>();

  void _mm256_mask_i32scatter_epi64(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m128i arg2,
    __m256i arg3,
    int arg4,
  ) {
    return __mm256_mask_i32scatter_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm256_mask_i32scatter_epi64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8, __m128i, __m256i,
              ffi.Int32)>>('_mm256_mask_i32scatter_epi64');
  late final __mm256_mask_i32scatter_epi64 =
      __mm256_mask_i32scatter_epi64Ptr.asFunction<
          void Function(ffi.Pointer<ffi.Void>, int, __m128i, __m256i, int)>();

  void _mm_i32scatter_pd(
    ffi.Pointer<ffi.Void> arg0,
    __m128i arg1,
    _m128d arg2,
    int arg3,
  ) {
    return __mm_i32scatter_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_i32scatter_pdPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __m128i, _m128d,
              ffi.Int32)>>('_mm_i32scatter_pd');
  late final __mm_i32scatter_pd = __mm_i32scatter_pdPtr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, __m128i, _m128d, int)>();

  void _mm_mask_i32scatter_pd(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m128i arg2,
    _m128d arg3,
    int arg4,
  ) {
    return __mm_mask_i32scatter_pd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_i32scatter_pdPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8, __m128i, _m128d,
              ffi.Int32)>>('_mm_mask_i32scatter_pd');
  late final __mm_mask_i32scatter_pd = __mm_mask_i32scatter_pdPtr.asFunction<
      void Function(ffi.Pointer<ffi.Void>, int, __m128i, _m128d, int)>();

  void _mm256_i32scatter_pd(
    ffi.Pointer<ffi.Void> arg0,
    __m128i arg1,
    _m256d arg2,
    int arg3,
  ) {
    return __mm256_i32scatter_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_i32scatter_pdPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __m128i, _m256d,
              ffi.Int32)>>('_mm256_i32scatter_pd');
  late final __mm256_i32scatter_pd = __mm256_i32scatter_pdPtr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, __m128i, _m256d, int)>();

  void _mm256_mask_i32scatter_pd(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m128i arg2,
    _m256d arg3,
    int arg4,
  ) {
    return __mm256_mask_i32scatter_pd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm256_mask_i32scatter_pdPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8, __m128i, _m256d,
              ffi.Int32)>>('_mm256_mask_i32scatter_pd');
  late final __mm256_mask_i32scatter_pd =
      __mm256_mask_i32scatter_pdPtr.asFunction<
          void Function(ffi.Pointer<ffi.Void>, int, __m128i, _m256d, int)>();

  void _mm_i32scatter_ps(
    ffi.Pointer<ffi.Void> arg0,
    __m128i arg1,
    __m128 arg2,
    int arg3,
  ) {
    return __mm_i32scatter_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_i32scatter_psPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __m128i, __m128,
              ffi.Int32)>>('_mm_i32scatter_ps');
  late final __mm_i32scatter_ps = __mm_i32scatter_psPtr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, __m128i, __m128, int)>();

  void _mm_mask_i32scatter_ps(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m128i arg2,
    __m128 arg3,
    int arg4,
  ) {
    return __mm_mask_i32scatter_ps(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_i32scatter_psPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8, __m128i, __m128,
              ffi.Int32)>>('_mm_mask_i32scatter_ps');
  late final __mm_mask_i32scatter_ps = __mm_mask_i32scatter_psPtr.asFunction<
      void Function(ffi.Pointer<ffi.Void>, int, __m128i, __m128, int)>();

  void _mm256_i32scatter_ps(
    ffi.Pointer<ffi.Void> arg0,
    __m256i arg1,
    __m256 arg2,
    int arg3,
  ) {
    return __mm256_i32scatter_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_i32scatter_psPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __m256i, __m256,
              ffi.Int32)>>('_mm256_i32scatter_ps');
  late final __mm256_i32scatter_ps = __mm256_i32scatter_psPtr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, __m256i, __m256, int)>();

  void _mm256_mask_i32scatter_ps(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m256i arg2,
    __m256 arg3,
    int arg4,
  ) {
    return __mm256_mask_i32scatter_ps(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm256_mask_i32scatter_psPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8, __m256i, __m256,
              ffi.Int32)>>('_mm256_mask_i32scatter_ps');
  late final __mm256_mask_i32scatter_ps =
      __mm256_mask_i32scatter_psPtr.asFunction<
          void Function(ffi.Pointer<ffi.Void>, int, __m256i, __m256, int)>();

  __m128i _mm_mmask_i64gather_epi32(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    ffi.Pointer<ffi.Void> arg3,
    int arg4,
  ) {
    return __mm_mmask_i64gather_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mmask_i64gather_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(__m128i, __mmask8, __m128i, ffi.Pointer<ffi.Void>,
              ffi.Int32)>>('_mm_mmask_i64gather_epi32');
  late final __mm_mmask_i64gather_epi32 =
      __mm_mmask_i64gather_epi32Ptr.asFunction<
          __m128i Function(
              __m128i, int, __m128i, ffi.Pointer<ffi.Void>, int)>();

  __m128i _mm256_mmask_i64gather_epi32(
    __m128i arg0,
    int arg1,
    __m256i arg2,
    ffi.Pointer<ffi.Void> arg3,
    int arg4,
  ) {
    return __mm256_mmask_i64gather_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm256_mmask_i64gather_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(__m128i, __mmask8, __m256i, ffi.Pointer<ffi.Void>,
              ffi.Int32)>>('_mm256_mmask_i64gather_epi32');
  late final __mm256_mmask_i64gather_epi32 =
      __mm256_mmask_i64gather_epi32Ptr.asFunction<
          __m128i Function(
              __m128i, int, __m256i, ffi.Pointer<ffi.Void>, int)>();

  __m128i _mm_mmask_i64gather_epi64(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    ffi.Pointer<ffi.Void> arg3,
    int arg4,
  ) {
    return __mm_mmask_i64gather_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mmask_i64gather_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(__m128i, __mmask8, __m128i, ffi.Pointer<ffi.Void>,
              ffi.Int32)>>('_mm_mmask_i64gather_epi64');
  late final __mm_mmask_i64gather_epi64 =
      __mm_mmask_i64gather_epi64Ptr.asFunction<
          __m128i Function(
              __m128i, int, __m128i, ffi.Pointer<ffi.Void>, int)>();

  __m256i _mm256_mmask_i64gather_epi64(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    ffi.Pointer<ffi.Void> arg3,
    int arg4,
  ) {
    return __mm256_mmask_i64gather_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm256_mmask_i64gather_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask8, __m256i, ffi.Pointer<ffi.Void>,
              ffi.Int32)>>('_mm256_mmask_i64gather_epi64');
  late final __mm256_mmask_i64gather_epi64 =
      __mm256_mmask_i64gather_epi64Ptr.asFunction<
          __m256i Function(
              __m256i, int, __m256i, ffi.Pointer<ffi.Void>, int)>();

  _m128d _mm_mmask_i64gather_pd(
    _m128d arg0,
    int arg1,
    __m128i arg2,
    ffi.Pointer<ffi.Void> arg3,
    int arg4,
  ) {
    return __mm_mmask_i64gather_pd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mmask_i64gather_pdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(_m128d, __mmask8, __m128i, ffi.Pointer<ffi.Void>,
              ffi.Int32)>>('_mm_mmask_i64gather_pd');
  late final __mm_mmask_i64gather_pd = __mm_mmask_i64gather_pdPtr.asFunction<
      _m128d Function(_m128d, int, __m128i, ffi.Pointer<ffi.Void>, int)>();

  _m256d _mm256_mmask_i64gather_pd(
    _m256d arg0,
    int arg1,
    __m256i arg2,
    ffi.Pointer<ffi.Void> arg3,
    int arg4,
  ) {
    return __mm256_mmask_i64gather_pd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm256_mmask_i64gather_pdPtr = _lookup<
      ffi.NativeFunction<
          _m256d Function(_m256d, __mmask8, __m256i, ffi.Pointer<ffi.Void>,
              ffi.Int32)>>('_mm256_mmask_i64gather_pd');
  late final __mm256_mmask_i64gather_pd =
      __mm256_mmask_i64gather_pdPtr.asFunction<
          _m256d Function(_m256d, int, __m256i, ffi.Pointer<ffi.Void>, int)>();

  __m128 _mm_mmask_i64gather_ps(
    __m128 arg0,
    int arg1,
    __m128i arg2,
    ffi.Pointer<ffi.Void> arg3,
    int arg4,
  ) {
    return __mm_mmask_i64gather_ps(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mmask_i64gather_psPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(__m128, __mmask8, __m128i, ffi.Pointer<ffi.Void>,
              ffi.Int32)>>('_mm_mmask_i64gather_ps');
  late final __mm_mmask_i64gather_ps = __mm_mmask_i64gather_psPtr.asFunction<
      __m128 Function(__m128, int, __m128i, ffi.Pointer<ffi.Void>, int)>();

  __m128 _mm256_mmask_i64gather_ps(
    __m128 arg0,
    int arg1,
    __m256i arg2,
    ffi.Pointer<ffi.Void> arg3,
    int arg4,
  ) {
    return __mm256_mmask_i64gather_ps(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm256_mmask_i64gather_psPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(__m128, __mmask8, __m256i, ffi.Pointer<ffi.Void>,
              ffi.Int32)>>('_mm256_mmask_i64gather_ps');
  late final __mm256_mmask_i64gather_ps =
      __mm256_mmask_i64gather_psPtr.asFunction<
          __m128 Function(__m128, int, __m256i, ffi.Pointer<ffi.Void>, int)>();

  void _mm_i64scatter_epi32(
    ffi.Pointer<ffi.Void> arg0,
    __m128i arg1,
    __m128i arg2,
    int arg3,
  ) {
    return __mm_i64scatter_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_i64scatter_epi32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __m128i, __m128i,
              ffi.Int32)>>('_mm_i64scatter_epi32');
  late final __mm_i64scatter_epi32 = __mm_i64scatter_epi32Ptr.asFunction<
      void Function(ffi.Pointer<ffi.Void>, __m128i, __m128i, int)>();

  void _mm_mask_i64scatter_epi32(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
    int arg4,
  ) {
    return __mm_mask_i64scatter_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_i64scatter_epi32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8, __m128i, __m128i,
              ffi.Int32)>>('_mm_mask_i64scatter_epi32');
  late final __mm_mask_i64scatter_epi32 =
      __mm_mask_i64scatter_epi32Ptr.asFunction<
          void Function(ffi.Pointer<ffi.Void>, int, __m128i, __m128i, int)>();

  void _mm256_i64scatter_epi32(
    ffi.Pointer<ffi.Void> arg0,
    __m256i arg1,
    __m128i arg2,
    int arg3,
  ) {
    return __mm256_i64scatter_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_i64scatter_epi32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __m256i, __m128i,
              ffi.Int32)>>('_mm256_i64scatter_epi32');
  late final __mm256_i64scatter_epi32 = __mm256_i64scatter_epi32Ptr.asFunction<
      void Function(ffi.Pointer<ffi.Void>, __m256i, __m128i, int)>();

  void _mm256_mask_i64scatter_epi32(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m256i arg2,
    __m128i arg3,
    int arg4,
  ) {
    return __mm256_mask_i64scatter_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm256_mask_i64scatter_epi32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8, __m256i, __m128i,
              ffi.Int32)>>('_mm256_mask_i64scatter_epi32');
  late final __mm256_mask_i64scatter_epi32 =
      __mm256_mask_i64scatter_epi32Ptr.asFunction<
          void Function(ffi.Pointer<ffi.Void>, int, __m256i, __m128i, int)>();

  void _mm_i64scatter_epi64(
    ffi.Pointer<ffi.Void> arg0,
    __m128i arg1,
    __m128i arg2,
    int arg3,
  ) {
    return __mm_i64scatter_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_i64scatter_epi64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __m128i, __m128i,
              ffi.Int32)>>('_mm_i64scatter_epi64');
  late final __mm_i64scatter_epi64 = __mm_i64scatter_epi64Ptr.asFunction<
      void Function(ffi.Pointer<ffi.Void>, __m128i, __m128i, int)>();

  void _mm_mask_i64scatter_epi64(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
    int arg4,
  ) {
    return __mm_mask_i64scatter_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_i64scatter_epi64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8, __m128i, __m128i,
              ffi.Int32)>>('_mm_mask_i64scatter_epi64');
  late final __mm_mask_i64scatter_epi64 =
      __mm_mask_i64scatter_epi64Ptr.asFunction<
          void Function(ffi.Pointer<ffi.Void>, int, __m128i, __m128i, int)>();

  void _mm256_i64scatter_epi64(
    ffi.Pointer<ffi.Void> arg0,
    __m256i arg1,
    __m256i arg2,
    int arg3,
  ) {
    return __mm256_i64scatter_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_i64scatter_epi64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __m256i, __m256i,
              ffi.Int32)>>('_mm256_i64scatter_epi64');
  late final __mm256_i64scatter_epi64 = __mm256_i64scatter_epi64Ptr.asFunction<
      void Function(ffi.Pointer<ffi.Void>, __m256i, __m256i, int)>();

  void _mm256_mask_i64scatter_epi64(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
    int arg4,
  ) {
    return __mm256_mask_i64scatter_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm256_mask_i64scatter_epi64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8, __m256i, __m256i,
              ffi.Int32)>>('_mm256_mask_i64scatter_epi64');
  late final __mm256_mask_i64scatter_epi64 =
      __mm256_mask_i64scatter_epi64Ptr.asFunction<
          void Function(ffi.Pointer<ffi.Void>, int, __m256i, __m256i, int)>();

  void _mm_i64scatter_pd(
    ffi.Pointer<ffi.Void> arg0,
    __m128i arg1,
    _m128d arg2,
    int arg3,
  ) {
    return __mm_i64scatter_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_i64scatter_pdPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __m128i, _m128d,
              ffi.Int32)>>('_mm_i64scatter_pd');
  late final __mm_i64scatter_pd = __mm_i64scatter_pdPtr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, __m128i, _m128d, int)>();

  void _mm_mask_i64scatter_pd(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m128i arg2,
    _m128d arg3,
    int arg4,
  ) {
    return __mm_mask_i64scatter_pd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_i64scatter_pdPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8, __m128i, _m128d,
              ffi.Int32)>>('_mm_mask_i64scatter_pd');
  late final __mm_mask_i64scatter_pd = __mm_mask_i64scatter_pdPtr.asFunction<
      void Function(ffi.Pointer<ffi.Void>, int, __m128i, _m128d, int)>();

  void _mm256_i64scatter_pd(
    ffi.Pointer<ffi.Void> arg0,
    __m256i arg1,
    _m256d arg2,
    int arg3,
  ) {
    return __mm256_i64scatter_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_i64scatter_pdPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __m256i, _m256d,
              ffi.Int32)>>('_mm256_i64scatter_pd');
  late final __mm256_i64scatter_pd = __mm256_i64scatter_pdPtr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, __m256i, _m256d, int)>();

  void _mm256_mask_i64scatter_pd(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m256i arg2,
    _m256d arg3,
    int arg4,
  ) {
    return __mm256_mask_i64scatter_pd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm256_mask_i64scatter_pdPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8, __m256i, _m256d,
              ffi.Int32)>>('_mm256_mask_i64scatter_pd');
  late final __mm256_mask_i64scatter_pd =
      __mm256_mask_i64scatter_pdPtr.asFunction<
          void Function(ffi.Pointer<ffi.Void>, int, __m256i, _m256d, int)>();

  void _mm_i64scatter_ps(
    ffi.Pointer<ffi.Void> arg0,
    __m128i arg1,
    __m128 arg2,
    int arg3,
  ) {
    return __mm_i64scatter_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_i64scatter_psPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __m128i, __m128,
              ffi.Int32)>>('_mm_i64scatter_ps');
  late final __mm_i64scatter_ps = __mm_i64scatter_psPtr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, __m128i, __m128, int)>();

  void _mm_mask_i64scatter_ps(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m128i arg2,
    __m128 arg3,
    int arg4,
  ) {
    return __mm_mask_i64scatter_ps(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_i64scatter_psPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8, __m128i, __m128,
              ffi.Int32)>>('_mm_mask_i64scatter_ps');
  late final __mm_mask_i64scatter_ps = __mm_mask_i64scatter_psPtr.asFunction<
      void Function(ffi.Pointer<ffi.Void>, int, __m128i, __m128, int)>();

  void _mm256_i64scatter_ps(
    ffi.Pointer<ffi.Void> arg0,
    __m256i arg1,
    __m128 arg2,
    int arg3,
  ) {
    return __mm256_i64scatter_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_i64scatter_psPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __m256i, __m128,
              ffi.Int32)>>('_mm256_i64scatter_ps');
  late final __mm256_i64scatter_ps = __mm256_i64scatter_psPtr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, __m256i, __m128, int)>();

  void _mm256_mask_i64scatter_ps(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m256i arg2,
    __m128 arg3,
    int arg4,
  ) {
    return __mm256_mask_i64scatter_ps(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm256_mask_i64scatter_psPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8, __m256i, __m128,
              ffi.Int32)>>('_mm256_mask_i64scatter_ps');
  late final __mm256_mask_i64scatter_ps =
      __mm256_mask_i64scatter_psPtr.asFunction<
          void Function(ffi.Pointer<ffi.Void>, int, __m256i, __m128, int)>();

  __m256 _mm256_insertf32x4(
    __m256 arg0,
    __m128 arg1,
    int arg2,
  ) {
    return __mm256_insertf32x4(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_insertf32x4Ptr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256, __m128, ffi.Int32)>>(
          '_mm256_insertf32x4');
  late final __mm256_insertf32x4 =
      __mm256_insertf32x4Ptr.asFunction<__m256 Function(__m256, __m128, int)>();

  __m256 _mm256_mask_insertf32x4(
    __m256 arg0,
    int arg1,
    __m256 arg2,
    __m128 arg3,
    int arg4,
  ) {
    return __mm256_mask_insertf32x4(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm256_mask_insertf32x4Ptr = _lookup<
      ffi.NativeFunction<
          __m256 Function(__m256, __mmask8, __m256, __m128,
              ffi.Int32)>>('_mm256_mask_insertf32x4');
  late final __mm256_mask_insertf32x4 = __mm256_mask_insertf32x4Ptr
      .asFunction<__m256 Function(__m256, int, __m256, __m128, int)>();

  __m256 _mm256_maskz_insertf32x4(
    int arg0,
    __m256 arg1,
    __m128 arg2,
    int arg3,
  ) {
    return __mm256_maskz_insertf32x4(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_maskz_insertf32x4Ptr = _lookup<
      ffi.NativeFunction<
          __m256 Function(__mmask8, __m256, __m128,
              ffi.Int32)>>('_mm256_maskz_insertf32x4');
  late final __mm256_maskz_insertf32x4 = __mm256_maskz_insertf32x4Ptr
      .asFunction<__m256 Function(int, __m256, __m128, int)>();

  _m256d _mm256_insertf64x2(
    _m256d arg0,
    _m128d arg1,
    int arg2,
  ) {
    return __mm256_insertf64x2(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_insertf64x2Ptr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d, _m128d, ffi.Int32)>>(
          '_mm256_insertf64x2');
  late final __mm256_insertf64x2 =
      __mm256_insertf64x2Ptr.asFunction<_m256d Function(_m256d, _m128d, int)>();

  _m256d _mm256_mask_insertf64x2(
    _m256d arg0,
    int arg1,
    _m256d arg2,
    _m128d arg3,
    int arg4,
  ) {
    return __mm256_mask_insertf64x2(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm256_mask_insertf64x2Ptr = _lookup<
      ffi.NativeFunction<
          _m256d Function(_m256d, __mmask8, _m256d, _m128d,
              ffi.Int32)>>('_mm256_mask_insertf64x2');
  late final __mm256_mask_insertf64x2 = __mm256_mask_insertf64x2Ptr
      .asFunction<_m256d Function(_m256d, int, _m256d, _m128d, int)>();

  _m256d _mm256_maskz_insertf64x2(
    int arg0,
    _m256d arg1,
    _m128d arg2,
    int arg3,
  ) {
    return __mm256_maskz_insertf64x2(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_maskz_insertf64x2Ptr = _lookup<
      ffi.NativeFunction<
          _m256d Function(__mmask8, _m256d, _m128d,
              ffi.Int32)>>('_mm256_maskz_insertf64x2');
  late final __mm256_maskz_insertf64x2 = __mm256_maskz_insertf64x2Ptr
      .asFunction<_m256d Function(int, _m256d, _m128d, int)>();

  __m256i _mm256_inserti32x4(
    __m256i arg0,
    __m128i arg1,
    int arg2,
  ) {
    return __mm256_inserti32x4(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_inserti32x4Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__m256i, __m128i, ffi.Int32)>>(
      '_mm256_inserti32x4');
  late final __mm256_inserti32x4 = __mm256_inserti32x4Ptr
      .asFunction<__m256i Function(__m256i, __m128i, int)>();

  __m256i _mm256_mask_inserti32x4(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m128i arg3,
    int arg4,
  ) {
    return __mm256_mask_inserti32x4(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm256_mask_inserti32x4Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask8, __m256i, __m128i,
              ffi.Int32)>>('_mm256_mask_inserti32x4');
  late final __mm256_mask_inserti32x4 = __mm256_mask_inserti32x4Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m128i, int)>();

  __m256i _mm256_maskz_inserti32x4(
    int arg0,
    __m256i arg1,
    __m128i arg2,
    int arg3,
  ) {
    return __mm256_maskz_inserti32x4(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_maskz_inserti32x4Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__mmask8, __m256i, __m128i,
              ffi.Int32)>>('_mm256_maskz_inserti32x4');
  late final __mm256_maskz_inserti32x4 = __mm256_maskz_inserti32x4Ptr
      .asFunction<__m256i Function(int, __m256i, __m128i, int)>();

  __m256i _mm256_inserti64x2(
    __m256i arg0,
    __m128i arg1,
    int arg2,
  ) {
    return __mm256_inserti64x2(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_inserti64x2Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__m256i, __m128i, ffi.Int32)>>(
      '_mm256_inserti64x2');
  late final __mm256_inserti64x2 = __mm256_inserti64x2Ptr
      .asFunction<__m256i Function(__m256i, __m128i, int)>();

  __m256i _mm256_mask_inserti64x2(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m128i arg3,
    int arg4,
  ) {
    return __mm256_mask_inserti64x2(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm256_mask_inserti64x2Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask8, __m256i, __m128i,
              ffi.Int32)>>('_mm256_mask_inserti64x2');
  late final __mm256_mask_inserti64x2 = __mm256_mask_inserti64x2Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m128i, int)>();

  __m256i _mm256_maskz_inserti64x2(
    int arg0,
    __m256i arg1,
    __m128i arg2,
    int arg3,
  ) {
    return __mm256_maskz_inserti64x2(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_maskz_inserti64x2Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__mmask8, __m256i, __m128i,
              ffi.Int32)>>('_mm256_maskz_inserti64x2');
  late final __mm256_maskz_inserti64x2 = __mm256_maskz_inserti64x2Ptr
      .asFunction<__m256i Function(int, __m256i, __m128i, int)>();

  __m128i _mm_mask_load_epi32(
    __m128i arg0,
    int arg1,
    ffi.Pointer<ffi.Void> arg2,
  ) {
    return __mm_mask_load_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_load_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(__m128i, __mmask8,
              ffi.Pointer<ffi.Void>)>>('_mm_mask_load_epi32');
  late final __mm_mask_load_epi32 = __mm_mask_load_epi32Ptr
      .asFunction<__m128i Function(__m128i, int, ffi.Pointer<ffi.Void>)>();

  __m128i _mm_maskz_load_epi32(
    int arg0,
    ffi.Pointer<ffi.Void> arg1,
  ) {
    return __mm_maskz_load_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_load_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __mmask8, ffi.Pointer<ffi.Void>)>>('_mm_maskz_load_epi32');
  late final __mm_maskz_load_epi32 = __mm_maskz_load_epi32Ptr
      .asFunction<__m128i Function(int, ffi.Pointer<ffi.Void>)>();

  __m256i _mm256_mask_load_epi32(
    __m256i arg0,
    int arg1,
    ffi.Pointer<ffi.Void> arg2,
  ) {
    return __mm256_mask_load_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_load_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask8,
              ffi.Pointer<ffi.Void>)>>('_mm256_mask_load_epi32');
  late final __mm256_mask_load_epi32 = __mm256_mask_load_epi32Ptr
      .asFunction<__m256i Function(__m256i, int, ffi.Pointer<ffi.Void>)>();

  __m256i _mm256_maskz_load_epi32(
    int arg0,
    ffi.Pointer<ffi.Void> arg1,
  ) {
    return __mm256_maskz_load_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_load_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __mmask8, ffi.Pointer<ffi.Void>)>>('_mm256_maskz_load_epi32');
  late final __mm256_maskz_load_epi32 = __mm256_maskz_load_epi32Ptr
      .asFunction<__m256i Function(int, ffi.Pointer<ffi.Void>)>();

  __m128i _mm_mask_load_epi64(
    __m128i arg0,
    int arg1,
    ffi.Pointer<ffi.Void> arg2,
  ) {
    return __mm_mask_load_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_load_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(__m128i, __mmask8,
              ffi.Pointer<ffi.Void>)>>('_mm_mask_load_epi64');
  late final __mm_mask_load_epi64 = __mm_mask_load_epi64Ptr
      .asFunction<__m128i Function(__m128i, int, ffi.Pointer<ffi.Void>)>();

  __m128i _mm_maskz_load_epi64(
    int arg0,
    ffi.Pointer<ffi.Void> arg1,
  ) {
    return __mm_maskz_load_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_load_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __mmask8, ffi.Pointer<ffi.Void>)>>('_mm_maskz_load_epi64');
  late final __mm_maskz_load_epi64 = __mm_maskz_load_epi64Ptr
      .asFunction<__m128i Function(int, ffi.Pointer<ffi.Void>)>();

  __m256i _mm256_mask_load_epi64(
    __m256i arg0,
    int arg1,
    ffi.Pointer<ffi.Void> arg2,
  ) {
    return __mm256_mask_load_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_load_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask8,
              ffi.Pointer<ffi.Void>)>>('_mm256_mask_load_epi64');
  late final __mm256_mask_load_epi64 = __mm256_mask_load_epi64Ptr
      .asFunction<__m256i Function(__m256i, int, ffi.Pointer<ffi.Void>)>();

  __m256i _mm256_maskz_load_epi64(
    int arg0,
    ffi.Pointer<ffi.Void> arg1,
  ) {
    return __mm256_maskz_load_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_load_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __mmask8, ffi.Pointer<ffi.Void>)>>('_mm256_maskz_load_epi64');
  late final __mm256_maskz_load_epi64 = __mm256_maskz_load_epi64Ptr
      .asFunction<__m256i Function(int, ffi.Pointer<ffi.Void>)>();

  _m128d _mm_mask_load_pd(
    _m128d arg0,
    int arg1,
    ffi.Pointer<ffi.Void> arg2,
  ) {
    return __mm_mask_load_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_load_pdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              _m128d, __mmask8, ffi.Pointer<ffi.Void>)>>('_mm_mask_load_pd');
  late final __mm_mask_load_pd = __mm_mask_load_pdPtr
      .asFunction<_m128d Function(_m128d, int, ffi.Pointer<ffi.Void>)>();

  _m128d _mm_maskz_load_pd(
    int arg0,
    ffi.Pointer<ffi.Void> arg1,
  ) {
    return __mm_maskz_load_pd(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_load_pdPtr = _lookup<
          ffi.NativeFunction<_m128d Function(__mmask8, ffi.Pointer<ffi.Void>)>>(
      '_mm_maskz_load_pd');
  late final __mm_maskz_load_pd = __mm_maskz_load_pdPtr
      .asFunction<_m128d Function(int, ffi.Pointer<ffi.Void>)>();

  _m256d _mm256_mask_load_pd(
    _m256d arg0,
    int arg1,
    ffi.Pointer<ffi.Void> arg2,
  ) {
    return __mm256_mask_load_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_load_pdPtr = _lookup<
      ffi.NativeFunction<
          _m256d Function(
              _m256d, __mmask8, ffi.Pointer<ffi.Void>)>>('_mm256_mask_load_pd');
  late final __mm256_mask_load_pd = __mm256_mask_load_pdPtr
      .asFunction<_m256d Function(_m256d, int, ffi.Pointer<ffi.Void>)>();

  _m256d _mm256_maskz_load_pd(
    int arg0,
    ffi.Pointer<ffi.Void> arg1,
  ) {
    return __mm256_maskz_load_pd(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_load_pdPtr = _lookup<
          ffi.NativeFunction<_m256d Function(__mmask8, ffi.Pointer<ffi.Void>)>>(
      '_mm256_maskz_load_pd');
  late final __mm256_maskz_load_pd = __mm256_maskz_load_pdPtr
      .asFunction<_m256d Function(int, ffi.Pointer<ffi.Void>)>();

  __m128 _mm_mask_load_ps(
    __m128 arg0,
    int arg1,
    ffi.Pointer<ffi.Void> arg2,
  ) {
    return __mm_mask_load_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_load_psPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __m128, __mmask8, ffi.Pointer<ffi.Void>)>>('_mm_mask_load_ps');
  late final __mm_mask_load_ps = __mm_mask_load_psPtr
      .asFunction<__m128 Function(__m128, int, ffi.Pointer<ffi.Void>)>();

  __m128 _mm_maskz_load_ps(
    int arg0,
    ffi.Pointer<ffi.Void> arg1,
  ) {
    return __mm_maskz_load_ps(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_load_psPtr = _lookup<
          ffi.NativeFunction<__m128 Function(__mmask8, ffi.Pointer<ffi.Void>)>>(
      '_mm_maskz_load_ps');
  late final __mm_maskz_load_ps = __mm_maskz_load_psPtr
      .asFunction<__m128 Function(int, ffi.Pointer<ffi.Void>)>();

  __m256 _mm256_mask_load_ps(
    __m256 arg0,
    int arg1,
    ffi.Pointer<ffi.Void> arg2,
  ) {
    return __mm256_mask_load_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_load_psPtr = _lookup<
      ffi.NativeFunction<
          __m256 Function(
              __m256, __mmask8, ffi.Pointer<ffi.Void>)>>('_mm256_mask_load_ps');
  late final __mm256_mask_load_ps = __mm256_mask_load_psPtr
      .asFunction<__m256 Function(__m256, int, ffi.Pointer<ffi.Void>)>();

  __m256 _mm256_maskz_load_ps(
    int arg0,
    ffi.Pointer<ffi.Void> arg1,
  ) {
    return __mm256_maskz_load_ps(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_load_psPtr = _lookup<
          ffi.NativeFunction<__m256 Function(__mmask8, ffi.Pointer<ffi.Void>)>>(
      '_mm256_maskz_load_ps');
  late final __mm256_maskz_load_ps = __mm256_maskz_load_psPtr
      .asFunction<__m256 Function(int, ffi.Pointer<ffi.Void>)>();

  __m128i _mm_loadu_epi16(
    ffi.Pointer<ffi.Void> arg0,
  ) {
    return __mm_loadu_epi16(
      arg0,
    );
  }

  late final __mm_loadu_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(ffi.Pointer<ffi.Void>)>>(
          '_mm_loadu_epi16');
  late final __mm_loadu_epi16 =
      __mm_loadu_epi16Ptr.asFunction<__m128i Function(ffi.Pointer<ffi.Void>)>();

  __m128i _mm_mask_loadu_epi16(
    __m128i arg0,
    int arg1,
    ffi.Pointer<ffi.Void> arg2,
  ) {
    return __mm_mask_loadu_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_loadu_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(__m128i, __mmask8,
              ffi.Pointer<ffi.Void>)>>('_mm_mask_loadu_epi16');
  late final __mm_mask_loadu_epi16 = __mm_mask_loadu_epi16Ptr
      .asFunction<__m128i Function(__m128i, int, ffi.Pointer<ffi.Void>)>();

  __m128i _mm_maskz_loadu_epi16(
    int arg0,
    ffi.Pointer<ffi.Void> arg1,
  ) {
    return __mm_maskz_loadu_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_loadu_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __mmask8, ffi.Pointer<ffi.Void>)>>('_mm_maskz_loadu_epi16');
  late final __mm_maskz_loadu_epi16 = __mm_maskz_loadu_epi16Ptr
      .asFunction<__m128i Function(int, ffi.Pointer<ffi.Void>)>();

  __m256i _mm256_loadu_epi16(
    ffi.Pointer<ffi.Void> arg0,
  ) {
    return __mm256_loadu_epi16(
      arg0,
    );
  }

  late final __mm256_loadu_epi16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(ffi.Pointer<ffi.Void>)>>(
          '_mm256_loadu_epi16');
  late final __mm256_loadu_epi16 = __mm256_loadu_epi16Ptr
      .asFunction<__m256i Function(ffi.Pointer<ffi.Void>)>();

  __m256i _mm256_mask_loadu_epi16(
    __m256i arg0,
    int arg1,
    ffi.Pointer<ffi.Void> arg2,
  ) {
    return __mm256_mask_loadu_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_loadu_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask16,
              ffi.Pointer<ffi.Void>)>>('_mm256_mask_loadu_epi16');
  late final __mm256_mask_loadu_epi16 = __mm256_mask_loadu_epi16Ptr
      .asFunction<__m256i Function(__m256i, int, ffi.Pointer<ffi.Void>)>();

  __m256i _mm256_maskz_loadu_epi16(
    int arg0,
    ffi.Pointer<ffi.Void> arg1,
  ) {
    return __mm256_maskz_loadu_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_loadu_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __mmask16, ffi.Pointer<ffi.Void>)>>('_mm256_maskz_loadu_epi16');
  late final __mm256_maskz_loadu_epi16 = __mm256_maskz_loadu_epi16Ptr
      .asFunction<__m256i Function(int, ffi.Pointer<ffi.Void>)>();

  __m128i _mm_loadu_epi32(
    ffi.Pointer<ffi.Void> arg0,
  ) {
    return __mm_loadu_epi32(
      arg0,
    );
  }

  late final __mm_loadu_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(ffi.Pointer<ffi.Void>)>>(
          '_mm_loadu_epi32');
  late final __mm_loadu_epi32 =
      __mm_loadu_epi32Ptr.asFunction<__m128i Function(ffi.Pointer<ffi.Void>)>();

  __m128i _mm_mask_loadu_epi32(
    __m128i arg0,
    int arg1,
    ffi.Pointer<ffi.Void> arg2,
  ) {
    return __mm_mask_loadu_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_loadu_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(__m128i, __mmask8,
              ffi.Pointer<ffi.Void>)>>('_mm_mask_loadu_epi32');
  late final __mm_mask_loadu_epi32 = __mm_mask_loadu_epi32Ptr
      .asFunction<__m128i Function(__m128i, int, ffi.Pointer<ffi.Void>)>();

  __m128i _mm_maskz_loadu_epi32(
    int arg0,
    ffi.Pointer<ffi.Void> arg1,
  ) {
    return __mm_maskz_loadu_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_loadu_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __mmask8, ffi.Pointer<ffi.Void>)>>('_mm_maskz_loadu_epi32');
  late final __mm_maskz_loadu_epi32 = __mm_maskz_loadu_epi32Ptr
      .asFunction<__m128i Function(int, ffi.Pointer<ffi.Void>)>();

  __m256i _mm256_loadu_epi32(
    ffi.Pointer<ffi.Void> arg0,
  ) {
    return __mm256_loadu_epi32(
      arg0,
    );
  }

  late final __mm256_loadu_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(ffi.Pointer<ffi.Void>)>>(
          '_mm256_loadu_epi32');
  late final __mm256_loadu_epi32 = __mm256_loadu_epi32Ptr
      .asFunction<__m256i Function(ffi.Pointer<ffi.Void>)>();

  __m256i _mm256_mask_loadu_epi32(
    __m256i arg0,
    int arg1,
    ffi.Pointer<ffi.Void> arg2,
  ) {
    return __mm256_mask_loadu_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_loadu_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask8,
              ffi.Pointer<ffi.Void>)>>('_mm256_mask_loadu_epi32');
  late final __mm256_mask_loadu_epi32 = __mm256_mask_loadu_epi32Ptr
      .asFunction<__m256i Function(__m256i, int, ffi.Pointer<ffi.Void>)>();

  __m256i _mm256_maskz_loadu_epi32(
    int arg0,
    ffi.Pointer<ffi.Void> arg1,
  ) {
    return __mm256_maskz_loadu_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_loadu_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __mmask8, ffi.Pointer<ffi.Void>)>>('_mm256_maskz_loadu_epi32');
  late final __mm256_maskz_loadu_epi32 = __mm256_maskz_loadu_epi32Ptr
      .asFunction<__m256i Function(int, ffi.Pointer<ffi.Void>)>();

  __m128i _mm_loadu_epi64(
    ffi.Pointer<ffi.Void> arg0,
  ) {
    return __mm_loadu_epi64(
      arg0,
    );
  }

  late final __mm_loadu_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(ffi.Pointer<ffi.Void>)>>(
          '_mm_loadu_epi64');
  late final __mm_loadu_epi64 =
      __mm_loadu_epi64Ptr.asFunction<__m128i Function(ffi.Pointer<ffi.Void>)>();

  __m128i _mm_mask_loadu_epi64(
    __m128i arg0,
    int arg1,
    ffi.Pointer<ffi.Void> arg2,
  ) {
    return __mm_mask_loadu_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_loadu_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(__m128i, __mmask8,
              ffi.Pointer<ffi.Void>)>>('_mm_mask_loadu_epi64');
  late final __mm_mask_loadu_epi64 = __mm_mask_loadu_epi64Ptr
      .asFunction<__m128i Function(__m128i, int, ffi.Pointer<ffi.Void>)>();

  __m128i _mm_maskz_loadu_epi64(
    int arg0,
    ffi.Pointer<ffi.Void> arg1,
  ) {
    return __mm_maskz_loadu_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_loadu_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __mmask8, ffi.Pointer<ffi.Void>)>>('_mm_maskz_loadu_epi64');
  late final __mm_maskz_loadu_epi64 = __mm_maskz_loadu_epi64Ptr
      .asFunction<__m128i Function(int, ffi.Pointer<ffi.Void>)>();

  __m256i _mm256_loadu_epi64(
    ffi.Pointer<ffi.Void> arg0,
  ) {
    return __mm256_loadu_epi64(
      arg0,
    );
  }

  late final __mm256_loadu_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(ffi.Pointer<ffi.Void>)>>(
          '_mm256_loadu_epi64');
  late final __mm256_loadu_epi64 = __mm256_loadu_epi64Ptr
      .asFunction<__m256i Function(ffi.Pointer<ffi.Void>)>();

  __m256i _mm256_mask_loadu_epi64(
    __m256i arg0,
    int arg1,
    ffi.Pointer<ffi.Void> arg2,
  ) {
    return __mm256_mask_loadu_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_loadu_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask8,
              ffi.Pointer<ffi.Void>)>>('_mm256_mask_loadu_epi64');
  late final __mm256_mask_loadu_epi64 = __mm256_mask_loadu_epi64Ptr
      .asFunction<__m256i Function(__m256i, int, ffi.Pointer<ffi.Void>)>();

  __m256i _mm256_maskz_loadu_epi64(
    int arg0,
    ffi.Pointer<ffi.Void> arg1,
  ) {
    return __mm256_maskz_loadu_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_loadu_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __mmask8, ffi.Pointer<ffi.Void>)>>('_mm256_maskz_loadu_epi64');
  late final __mm256_maskz_loadu_epi64 = __mm256_maskz_loadu_epi64Ptr
      .asFunction<__m256i Function(int, ffi.Pointer<ffi.Void>)>();

  __m128i _mm_loadu_epi8(
    ffi.Pointer<ffi.Void> arg0,
  ) {
    return __mm_loadu_epi8(
      arg0,
    );
  }

  late final __mm_loadu_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(ffi.Pointer<ffi.Void>)>>(
          '_mm_loadu_epi8');
  late final __mm_loadu_epi8 =
      __mm_loadu_epi8Ptr.asFunction<__m128i Function(ffi.Pointer<ffi.Void>)>();

  __m128i _mm_mask_loadu_epi8(
    __m128i arg0,
    int arg1,
    ffi.Pointer<ffi.Void> arg2,
  ) {
    return __mm_mask_loadu_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_loadu_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(__m128i, __mmask16,
              ffi.Pointer<ffi.Void>)>>('_mm_mask_loadu_epi8');
  late final __mm_mask_loadu_epi8 = __mm_mask_loadu_epi8Ptr
      .asFunction<__m128i Function(__m128i, int, ffi.Pointer<ffi.Void>)>();

  __m128i _mm_maskz_loadu_epi8(
    int arg0,
    ffi.Pointer<ffi.Void> arg1,
  ) {
    return __mm_maskz_loadu_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_loadu_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __mmask16, ffi.Pointer<ffi.Void>)>>('_mm_maskz_loadu_epi8');
  late final __mm_maskz_loadu_epi8 = __mm_maskz_loadu_epi8Ptr
      .asFunction<__m128i Function(int, ffi.Pointer<ffi.Void>)>();

  __m256i _mm256_loadu_epi8(
    ffi.Pointer<ffi.Void> arg0,
  ) {
    return __mm256_loadu_epi8(
      arg0,
    );
  }

  late final __mm256_loadu_epi8Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(ffi.Pointer<ffi.Void>)>>(
          '_mm256_loadu_epi8');
  late final __mm256_loadu_epi8 = __mm256_loadu_epi8Ptr
      .asFunction<__m256i Function(ffi.Pointer<ffi.Void>)>();

  __m256i _mm256_mask_loadu_epi8(
    __m256i arg0,
    int arg1,
    ffi.Pointer<ffi.Void> arg2,
  ) {
    return __mm256_mask_loadu_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_loadu_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask32,
              ffi.Pointer<ffi.Void>)>>('_mm256_mask_loadu_epi8');
  late final __mm256_mask_loadu_epi8 = __mm256_mask_loadu_epi8Ptr
      .asFunction<__m256i Function(__m256i, int, ffi.Pointer<ffi.Void>)>();

  __m256i _mm256_maskz_loadu_epi8(
    int arg0,
    ffi.Pointer<ffi.Void> arg1,
  ) {
    return __mm256_maskz_loadu_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_loadu_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __mmask32, ffi.Pointer<ffi.Void>)>>('_mm256_maskz_loadu_epi8');
  late final __mm256_maskz_loadu_epi8 = __mm256_maskz_loadu_epi8Ptr
      .asFunction<__m256i Function(int, ffi.Pointer<ffi.Void>)>();

  _m128d _mm_mask_loadu_pd(
    _m128d arg0,
    int arg1,
    ffi.Pointer<ffi.Void> arg2,
  ) {
    return __mm_mask_loadu_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_loadu_pdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              _m128d, __mmask8, ffi.Pointer<ffi.Void>)>>('_mm_mask_loadu_pd');
  late final __mm_mask_loadu_pd = __mm_mask_loadu_pdPtr
      .asFunction<_m128d Function(_m128d, int, ffi.Pointer<ffi.Void>)>();

  _m128d _mm_maskz_loadu_pd(
    int arg0,
    ffi.Pointer<ffi.Void> arg1,
  ) {
    return __mm_maskz_loadu_pd(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_loadu_pdPtr = _lookup<
          ffi.NativeFunction<_m128d Function(__mmask8, ffi.Pointer<ffi.Void>)>>(
      '_mm_maskz_loadu_pd');
  late final __mm_maskz_loadu_pd = __mm_maskz_loadu_pdPtr
      .asFunction<_m128d Function(int, ffi.Pointer<ffi.Void>)>();

  _m256d _mm256_mask_loadu_pd(
    _m256d arg0,
    int arg1,
    ffi.Pointer<ffi.Void> arg2,
  ) {
    return __mm256_mask_loadu_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_loadu_pdPtr = _lookup<
      ffi.NativeFunction<
          _m256d Function(_m256d, __mmask8,
              ffi.Pointer<ffi.Void>)>>('_mm256_mask_loadu_pd');
  late final __mm256_mask_loadu_pd = __mm256_mask_loadu_pdPtr
      .asFunction<_m256d Function(_m256d, int, ffi.Pointer<ffi.Void>)>();

  _m256d _mm256_maskz_loadu_pd(
    int arg0,
    ffi.Pointer<ffi.Void> arg1,
  ) {
    return __mm256_maskz_loadu_pd(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_loadu_pdPtr = _lookup<
          ffi.NativeFunction<_m256d Function(__mmask8, ffi.Pointer<ffi.Void>)>>(
      '_mm256_maskz_loadu_pd');
  late final __mm256_maskz_loadu_pd = __mm256_maskz_loadu_pdPtr
      .asFunction<_m256d Function(int, ffi.Pointer<ffi.Void>)>();

  __m128 _mm_mask_loadu_ps(
    __m128 arg0,
    int arg1,
    ffi.Pointer<ffi.Void> arg2,
  ) {
    return __mm_mask_loadu_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_loadu_psPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __m128, __mmask8, ffi.Pointer<ffi.Void>)>>('_mm_mask_loadu_ps');
  late final __mm_mask_loadu_ps = __mm_mask_loadu_psPtr
      .asFunction<__m128 Function(__m128, int, ffi.Pointer<ffi.Void>)>();

  __m128 _mm_maskz_loadu_ps(
    int arg0,
    ffi.Pointer<ffi.Void> arg1,
  ) {
    return __mm_maskz_loadu_ps(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_loadu_psPtr = _lookup<
          ffi.NativeFunction<__m128 Function(__mmask8, ffi.Pointer<ffi.Void>)>>(
      '_mm_maskz_loadu_ps');
  late final __mm_maskz_loadu_ps = __mm_maskz_loadu_psPtr
      .asFunction<__m128 Function(int, ffi.Pointer<ffi.Void>)>();

  __m256 _mm256_mask_loadu_ps(
    __m256 arg0,
    int arg1,
    ffi.Pointer<ffi.Void> arg2,
  ) {
    return __mm256_mask_loadu_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_loadu_psPtr = _lookup<
      ffi.NativeFunction<
          __m256 Function(__m256, __mmask8,
              ffi.Pointer<ffi.Void>)>>('_mm256_mask_loadu_ps');
  late final __mm256_mask_loadu_ps = __mm256_mask_loadu_psPtr
      .asFunction<__m256 Function(__m256, int, ffi.Pointer<ffi.Void>)>();

  __m256 _mm256_maskz_loadu_ps(
    int arg0,
    ffi.Pointer<ffi.Void> arg1,
  ) {
    return __mm256_maskz_loadu_ps(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_loadu_psPtr = _lookup<
          ffi.NativeFunction<__m256 Function(__mmask8, ffi.Pointer<ffi.Void>)>>(
      '_mm256_maskz_loadu_ps');
  late final __mm256_maskz_loadu_ps = __mm256_maskz_loadu_psPtr
      .asFunction<__m256 Function(int, ffi.Pointer<ffi.Void>)>();

  __m128i _mm_lzcnt_epi32(
    __m128i arg0,
  ) {
    return __mm_lzcnt_epi32(
      arg0,
    );
  }

  late final __mm_lzcnt_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i)>>('_mm_lzcnt_epi32');
  late final __mm_lzcnt_epi32 =
      __mm_lzcnt_epi32Ptr.asFunction<__m128i Function(__m128i)>();

  __m128i _mm_mask_lzcnt_epi32(
    __m128i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_lzcnt_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_lzcnt_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m128i)>>(
          '_mm_mask_lzcnt_epi32');
  late final __mm_mask_lzcnt_epi32 = __mm_mask_lzcnt_epi32Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i)>();

  __m128i _mm_maskz_lzcnt_epi32(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_lzcnt_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_lzcnt_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i)>>(
          '_mm_maskz_lzcnt_epi32');
  late final __mm_maskz_lzcnt_epi32 =
      __mm_maskz_lzcnt_epi32Ptr.asFunction<__m128i Function(int, __m128i)>();

  __m256i _mm256_lzcnt_epi32(
    __m256i arg0,
  ) {
    return __mm256_lzcnt_epi32(
      arg0,
    );
  }

  late final __mm256_lzcnt_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i)>>(
          '_mm256_lzcnt_epi32');
  late final __mm256_lzcnt_epi32 =
      __mm256_lzcnt_epi32Ptr.asFunction<__m256i Function(__m256i)>();

  __m256i _mm256_mask_lzcnt_epi32(
    __m256i arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_lzcnt_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_lzcnt_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __mmask8, __m256i)>>(
          '_mm256_mask_lzcnt_epi32');
  late final __mm256_mask_lzcnt_epi32 = __mm256_mask_lzcnt_epi32Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i)>();

  __m256i _mm256_maskz_lzcnt_epi32(
    int arg0,
    __m256i arg1,
  ) {
    return __mm256_maskz_lzcnt_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_lzcnt_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m256i)>>(
          '_mm256_maskz_lzcnt_epi32');
  late final __mm256_maskz_lzcnt_epi32 =
      __mm256_maskz_lzcnt_epi32Ptr.asFunction<__m256i Function(int, __m256i)>();

  __m128i _mm_lzcnt_epi64(
    __m128i arg0,
  ) {
    return __mm_lzcnt_epi64(
      arg0,
    );
  }

  late final __mm_lzcnt_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i)>>('_mm_lzcnt_epi64');
  late final __mm_lzcnt_epi64 =
      __mm_lzcnt_epi64Ptr.asFunction<__m128i Function(__m128i)>();

  __m128i _mm_mask_lzcnt_epi64(
    __m128i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_lzcnt_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_lzcnt_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m128i)>>(
          '_mm_mask_lzcnt_epi64');
  late final __mm_mask_lzcnt_epi64 = __mm_mask_lzcnt_epi64Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i)>();

  __m128i _mm_maskz_lzcnt_epi64(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_lzcnt_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_lzcnt_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i)>>(
          '_mm_maskz_lzcnt_epi64');
  late final __mm_maskz_lzcnt_epi64 =
      __mm_maskz_lzcnt_epi64Ptr.asFunction<__m128i Function(int, __m128i)>();

  __m256i _mm256_lzcnt_epi64(
    __m256i arg0,
  ) {
    return __mm256_lzcnt_epi64(
      arg0,
    );
  }

  late final __mm256_lzcnt_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i)>>(
          '_mm256_lzcnt_epi64');
  late final __mm256_lzcnt_epi64 =
      __mm256_lzcnt_epi64Ptr.asFunction<__m256i Function(__m256i)>();

  __m256i _mm256_mask_lzcnt_epi64(
    __m256i arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_lzcnt_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_lzcnt_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __mmask8, __m256i)>>(
          '_mm256_mask_lzcnt_epi64');
  late final __mm256_mask_lzcnt_epi64 = __mm256_mask_lzcnt_epi64Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i)>();

  __m256i _mm256_maskz_lzcnt_epi64(
    int arg0,
    __m256i arg1,
  ) {
    return __mm256_maskz_lzcnt_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_lzcnt_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m256i)>>(
          '_mm256_maskz_lzcnt_epi64');
  late final __mm256_maskz_lzcnt_epi64 =
      __mm256_maskz_lzcnt_epi64Ptr.asFunction<__m256i Function(int, __m256i)>();

  __m128i _mm_mask_madd_epi16(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_madd_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_madd_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_madd_epi16');
  late final __mm_mask_madd_epi16 = __mm_mask_madd_epi16Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_madd_epi16(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_madd_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_madd_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_maskz_madd_epi16');
  late final __mm_maskz_madd_epi16 = __mm_maskz_madd_epi16Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_mask_madd_epi16(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_madd_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_madd_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask8, __m256i, __m256i)>>('_mm256_mask_madd_epi16');
  late final __mm256_mask_madd_epi16 = __mm256_mask_madd_epi16Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_madd_epi16(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_madd_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_madd_epi16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m256i, __m256i)>>(
          '_mm256_maskz_madd_epi16');
  late final __mm256_maskz_madd_epi16 = __mm256_maskz_madd_epi16Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  __m128i _mm_mask_maddubs_epi16(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_maddubs_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_maddubs_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_maddubs_epi16');
  late final __mm_mask_maddubs_epi16 = __mm_mask_maddubs_epi16Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_maddubs_epi16(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_maddubs_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_maddubs_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_maskz_maddubs_epi16');
  late final __mm_maskz_maddubs_epi16 = __mm_maskz_maddubs_epi16Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_mask_maddubs_epi16(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_maddubs_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_maddubs_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask16, __m256i,
              __m256i)>>('_mm256_mask_maddubs_epi16');
  late final __mm256_mask_maddubs_epi16 = __mm256_mask_maddubs_epi16Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_maddubs_epi16(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_maddubs_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_maddubs_epi16Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__mmask16, __m256i, __m256i)>>(
      '_mm256_maskz_maddubs_epi16');
  late final __mm256_maskz_maddubs_epi16 = __mm256_maskz_maddubs_epi16Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  __m128i _mm_mask_max_epi16(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_max_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_max_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_max_epi16');
  late final __mm_mask_max_epi16 = __mm_mask_max_epi16Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_max_epi16(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_max_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_max_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_maskz_max_epi16');
  late final __mm_maskz_max_epi16 = __mm_maskz_max_epi16Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_mask_max_epi16(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_max_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_max_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask16, __m256i, __m256i)>>('_mm256_mask_max_epi16');
  late final __mm256_mask_max_epi16 = __mm256_mask_max_epi16Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_max_epi16(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_max_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_max_epi16Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__mmask16, __m256i, __m256i)>>(
      '_mm256_maskz_max_epi16');
  late final __mm256_maskz_max_epi16 = __mm256_maskz_max_epi16Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  __m128i _mm_mask_max_epi32(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_max_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_max_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_max_epi32');
  late final __mm_mask_max_epi32 = __mm_mask_max_epi32Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_max_epi32(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_max_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_max_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_maskz_max_epi32');
  late final __mm_maskz_max_epi32 = __mm_maskz_max_epi32Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_mask_max_epi32(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_max_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_max_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask8, __m256i, __m256i)>>('_mm256_mask_max_epi32');
  late final __mm256_mask_max_epi32 = __mm256_mask_max_epi32Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_max_epi32(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_max_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_max_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m256i, __m256i)>>(
          '_mm256_maskz_max_epi32');
  late final __mm256_maskz_max_epi32 = __mm256_maskz_max_epi32Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  __m128i _mm_mask_max_epi64(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_max_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_max_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_max_epi64');
  late final __mm_mask_max_epi64 = __mm_mask_max_epi64Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_max_epi64(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_max_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_max_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_maskz_max_epi64');
  late final __mm_maskz_max_epi64 = __mm_maskz_max_epi64Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m128i _mm_max_epi64(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_max_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm_max_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_max_epi64');
  late final __mm_max_epi64 =
      __mm_max_epi64Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m256i _mm256_mask_max_epi64(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_max_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_max_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask8, __m256i, __m256i)>>('_mm256_mask_max_epi64');
  late final __mm256_mask_max_epi64 = __mm256_mask_max_epi64Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_max_epi64(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_max_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_max_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m256i, __m256i)>>(
          '_mm256_maskz_max_epi64');
  late final __mm256_maskz_max_epi64 = __mm256_maskz_max_epi64Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  __m256i _mm256_max_epi64(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_max_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm256_max_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_max_epi64');
  late final __mm256_max_epi64 =
      __mm256_max_epi64Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m128i _mm_mask_max_epi8(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_max_epi8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_max_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask16, __m128i, __m128i)>>('_mm_mask_max_epi8');
  late final __mm_mask_max_epi8 = __mm_mask_max_epi8Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_max_epi8(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_max_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_max_epi8Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__mmask16, __m128i, __m128i)>>(
      '_mm_maskz_max_epi8');
  late final __mm_maskz_max_epi8 = __mm_maskz_max_epi8Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_mask_max_epi8(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_max_epi8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_max_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask32, __m256i, __m256i)>>('_mm256_mask_max_epi8');
  late final __mm256_mask_max_epi8 = __mm256_mask_max_epi8Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_max_epi8(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_max_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_max_epi8Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__mmask32, __m256i, __m256i)>>(
      '_mm256_maskz_max_epi8');
  late final __mm256_maskz_max_epi8 = __mm256_maskz_max_epi8Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  __m128i _mm_mask_max_epu16(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_max_epu16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_max_epu16Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_max_epu16');
  late final __mm_mask_max_epu16 = __mm_mask_max_epu16Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_max_epu16(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_max_epu16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_max_epu16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_maskz_max_epu16');
  late final __mm_maskz_max_epu16 = __mm_maskz_max_epu16Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_mask_max_epu16(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_max_epu16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_max_epu16Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask16, __m256i, __m256i)>>('_mm256_mask_max_epu16');
  late final __mm256_mask_max_epu16 = __mm256_mask_max_epu16Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_max_epu16(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_max_epu16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_max_epu16Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__mmask16, __m256i, __m256i)>>(
      '_mm256_maskz_max_epu16');
  late final __mm256_maskz_max_epu16 = __mm256_maskz_max_epu16Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  __m128i _mm_mask_max_epu32(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_max_epu32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_max_epu32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_max_epu32');
  late final __mm_mask_max_epu32 = __mm_mask_max_epu32Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_max_epu32(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_max_epu32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_max_epu32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_maskz_max_epu32');
  late final __mm_maskz_max_epu32 = __mm_maskz_max_epu32Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_mask_max_epu32(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_max_epu32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_max_epu32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask8, __m256i, __m256i)>>('_mm256_mask_max_epu32');
  late final __mm256_mask_max_epu32 = __mm256_mask_max_epu32Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_max_epu32(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_max_epu32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_max_epu32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m256i, __m256i)>>(
          '_mm256_maskz_max_epu32');
  late final __mm256_maskz_max_epu32 = __mm256_maskz_max_epu32Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  __m128i _mm_mask_max_epu64(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_max_epu64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_max_epu64Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_max_epu64');
  late final __mm_mask_max_epu64 = __mm_mask_max_epu64Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_max_epu64(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_max_epu64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_max_epu64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_maskz_max_epu64');
  late final __mm_maskz_max_epu64 = __mm_maskz_max_epu64Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m128i _mm_max_epu64(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_max_epu64(
      arg0,
      arg1,
    );
  }

  late final __mm_max_epu64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_max_epu64');
  late final __mm_max_epu64 =
      __mm_max_epu64Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m256i _mm256_mask_max_epu64(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_max_epu64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_max_epu64Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask8, __m256i, __m256i)>>('_mm256_mask_max_epu64');
  late final __mm256_mask_max_epu64 = __mm256_mask_max_epu64Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_max_epu64(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_max_epu64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_max_epu64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m256i, __m256i)>>(
          '_mm256_maskz_max_epu64');
  late final __mm256_maskz_max_epu64 = __mm256_maskz_max_epu64Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  __m256i _mm256_max_epu64(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_max_epu64(
      arg0,
      arg1,
    );
  }

  late final __mm256_max_epu64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_max_epu64');
  late final __mm256_max_epu64 =
      __mm256_max_epu64Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m128i _mm_mask_max_epu8(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_max_epu8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_max_epu8Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask16, __m128i, __m128i)>>('_mm_mask_max_epu8');
  late final __mm_mask_max_epu8 = __mm_mask_max_epu8Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_max_epu8(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_max_epu8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_max_epu8Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__mmask16, __m128i, __m128i)>>(
      '_mm_maskz_max_epu8');
  late final __mm_maskz_max_epu8 = __mm_maskz_max_epu8Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_mask_max_epu8(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_max_epu8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_max_epu8Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask32, __m256i, __m256i)>>('_mm256_mask_max_epu8');
  late final __mm256_mask_max_epu8 = __mm256_mask_max_epu8Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_max_epu8(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_max_epu8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_max_epu8Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__mmask32, __m256i, __m256i)>>(
      '_mm256_maskz_max_epu8');
  late final __mm256_maskz_max_epu8 = __mm256_maskz_max_epu8Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  _m128d _mm_mask_max_pd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    _m128d arg3,
  ) {
    return __mm_mask_max_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_max_pdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              _m128d, __mmask8, _m128d, _m128d)>>('_mm_mask_max_pd');
  late final __mm_mask_max_pd = __mm_mask_max_pdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d, _m128d)>();

  _m128d _mm_maskz_max_pd(
    int arg0,
    _m128d arg1,
    _m128d arg2,
  ) {
    return __mm_maskz_max_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_max_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(__mmask8, _m128d, _m128d)>>(
          '_mm_maskz_max_pd');
  late final __mm_maskz_max_pd =
      __mm_maskz_max_pdPtr.asFunction<_m128d Function(int, _m128d, _m128d)>();

  _m256d _mm256_mask_max_pd(
    _m256d arg0,
    int arg1,
    _m256d arg2,
    _m256d arg3,
  ) {
    return __mm256_mask_max_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_max_pdPtr = _lookup<
      ffi.NativeFunction<
          _m256d Function(
              _m256d, __mmask8, _m256d, _m256d)>>('_mm256_mask_max_pd');
  late final __mm256_mask_max_pd = __mm256_mask_max_pdPtr
      .asFunction<_m256d Function(_m256d, int, _m256d, _m256d)>();

  _m256d _mm256_maskz_max_pd(
    int arg0,
    _m256d arg1,
    _m256d arg2,
  ) {
    return __mm256_maskz_max_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_max_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(__mmask8, _m256d, _m256d)>>(
          '_mm256_maskz_max_pd');
  late final __mm256_maskz_max_pd = __mm256_maskz_max_pdPtr
      .asFunction<_m256d Function(int, _m256d, _m256d)>();

  __m128 _mm_mask_max_ps(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    __m128 arg3,
  ) {
    return __mm_mask_max_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_max_psPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __m128, __mmask8, __m128, __m128)>>('_mm_mask_max_ps');
  late final __mm_mask_max_ps = __mm_mask_max_psPtr
      .asFunction<__m128 Function(__m128, int, __m128, __m128)>();

  __m128 _mm_maskz_max_ps(
    int arg0,
    __m128 arg1,
    __m128 arg2,
  ) {
    return __mm_maskz_max_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_max_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__mmask8, __m128, __m128)>>(
          '_mm_maskz_max_ps');
  late final __mm_maskz_max_ps =
      __mm_maskz_max_psPtr.asFunction<__m128 Function(int, __m128, __m128)>();

  __m256 _mm256_mask_max_ps(
    __m256 arg0,
    int arg1,
    __m256 arg2,
    __m256 arg3,
  ) {
    return __mm256_mask_max_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_max_psPtr = _lookup<
      ffi.NativeFunction<
          __m256 Function(
              __m256, __mmask8, __m256, __m256)>>('_mm256_mask_max_ps');
  late final __mm256_mask_max_ps = __mm256_mask_max_psPtr
      .asFunction<__m256 Function(__m256, int, __m256, __m256)>();

  __m256 _mm256_maskz_max_ps(
    int arg0,
    __m256 arg1,
    __m256 arg2,
  ) {
    return __mm256_maskz_max_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_max_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__mmask8, __m256, __m256)>>(
          '_mm256_maskz_max_ps');
  late final __mm256_maskz_max_ps = __mm256_maskz_max_psPtr
      .asFunction<__m256 Function(int, __m256, __m256)>();

  __m128i _mm_mask_min_epi16(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_min_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_min_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_min_epi16');
  late final __mm_mask_min_epi16 = __mm_mask_min_epi16Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_min_epi16(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_min_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_min_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_maskz_min_epi16');
  late final __mm_maskz_min_epi16 = __mm_maskz_min_epi16Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_mask_min_epi16(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_min_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_min_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask16, __m256i, __m256i)>>('_mm256_mask_min_epi16');
  late final __mm256_mask_min_epi16 = __mm256_mask_min_epi16Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_min_epi16(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_min_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_min_epi16Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__mmask16, __m256i, __m256i)>>(
      '_mm256_maskz_min_epi16');
  late final __mm256_maskz_min_epi16 = __mm256_maskz_min_epi16Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  __m128i _mm_mask_min_epi32(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_min_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_min_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_min_epi32');
  late final __mm_mask_min_epi32 = __mm_mask_min_epi32Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_min_epi32(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_min_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_min_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_maskz_min_epi32');
  late final __mm_maskz_min_epi32 = __mm_maskz_min_epi32Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_mask_min_epi32(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_min_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_min_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask8, __m256i, __m256i)>>('_mm256_mask_min_epi32');
  late final __mm256_mask_min_epi32 = __mm256_mask_min_epi32Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_min_epi32(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_min_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_min_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m256i, __m256i)>>(
          '_mm256_maskz_min_epi32');
  late final __mm256_maskz_min_epi32 = __mm256_maskz_min_epi32Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  __m128i _mm_mask_min_epi64(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_min_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_min_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_min_epi64');
  late final __mm_mask_min_epi64 = __mm_mask_min_epi64Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_min_epi64(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_min_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_min_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_maskz_min_epi64');
  late final __mm_maskz_min_epi64 = __mm_maskz_min_epi64Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m128i _mm_min_epi64(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_min_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm_min_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_min_epi64');
  late final __mm_min_epi64 =
      __mm_min_epi64Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m256i _mm256_mask_min_epi64(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_min_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_min_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask8, __m256i, __m256i)>>('_mm256_mask_min_epi64');
  late final __mm256_mask_min_epi64 = __mm256_mask_min_epi64Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_min_epi64(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_min_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_min_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m256i, __m256i)>>(
          '_mm256_maskz_min_epi64');
  late final __mm256_maskz_min_epi64 = __mm256_maskz_min_epi64Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  __m256i _mm256_min_epi64(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_min_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm256_min_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_min_epi64');
  late final __mm256_min_epi64 =
      __mm256_min_epi64Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m128i _mm_mask_min_epi8(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_min_epi8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_min_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask16, __m128i, __m128i)>>('_mm_mask_min_epi8');
  late final __mm_mask_min_epi8 = __mm_mask_min_epi8Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_min_epi8(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_min_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_min_epi8Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__mmask16, __m128i, __m128i)>>(
      '_mm_maskz_min_epi8');
  late final __mm_maskz_min_epi8 = __mm_maskz_min_epi8Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_mask_min_epi8(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_min_epi8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_min_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask32, __m256i, __m256i)>>('_mm256_mask_min_epi8');
  late final __mm256_mask_min_epi8 = __mm256_mask_min_epi8Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_min_epi8(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_min_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_min_epi8Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__mmask32, __m256i, __m256i)>>(
      '_mm256_maskz_min_epi8');
  late final __mm256_maskz_min_epi8 = __mm256_maskz_min_epi8Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  __m128i _mm_mask_min_epu16(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_min_epu16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_min_epu16Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_min_epu16');
  late final __mm_mask_min_epu16 = __mm_mask_min_epu16Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_min_epu16(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_min_epu16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_min_epu16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_maskz_min_epu16');
  late final __mm_maskz_min_epu16 = __mm_maskz_min_epu16Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_mask_min_epu16(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_min_epu16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_min_epu16Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask16, __m256i, __m256i)>>('_mm256_mask_min_epu16');
  late final __mm256_mask_min_epu16 = __mm256_mask_min_epu16Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_min_epu16(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_min_epu16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_min_epu16Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__mmask16, __m256i, __m256i)>>(
      '_mm256_maskz_min_epu16');
  late final __mm256_maskz_min_epu16 = __mm256_maskz_min_epu16Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  __m128i _mm_mask_min_epu32(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_min_epu32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_min_epu32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_min_epu32');
  late final __mm_mask_min_epu32 = __mm_mask_min_epu32Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_min_epu32(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_min_epu32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_min_epu32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_maskz_min_epu32');
  late final __mm_maskz_min_epu32 = __mm_maskz_min_epu32Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_mask_min_epu32(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_min_epu32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_min_epu32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask8, __m256i, __m256i)>>('_mm256_mask_min_epu32');
  late final __mm256_mask_min_epu32 = __mm256_mask_min_epu32Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_min_epu32(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_min_epu32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_min_epu32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m256i, __m256i)>>(
          '_mm256_maskz_min_epu32');
  late final __mm256_maskz_min_epu32 = __mm256_maskz_min_epu32Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  __m128i _mm_mask_min_epu64(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_min_epu64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_min_epu64Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_min_epu64');
  late final __mm_mask_min_epu64 = __mm_mask_min_epu64Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_min_epu64(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_min_epu64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_min_epu64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_maskz_min_epu64');
  late final __mm_maskz_min_epu64 = __mm_maskz_min_epu64Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m128i _mm_min_epu64(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_min_epu64(
      arg0,
      arg1,
    );
  }

  late final __mm_min_epu64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_min_epu64');
  late final __mm_min_epu64 =
      __mm_min_epu64Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m256i _mm256_mask_min_epu64(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_min_epu64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_min_epu64Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask8, __m256i, __m256i)>>('_mm256_mask_min_epu64');
  late final __mm256_mask_min_epu64 = __mm256_mask_min_epu64Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_min_epu64(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_min_epu64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_min_epu64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m256i, __m256i)>>(
          '_mm256_maskz_min_epu64');
  late final __mm256_maskz_min_epu64 = __mm256_maskz_min_epu64Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  __m256i _mm256_min_epu64(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_min_epu64(
      arg0,
      arg1,
    );
  }

  late final __mm256_min_epu64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_min_epu64');
  late final __mm256_min_epu64 =
      __mm256_min_epu64Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m128i _mm_mask_min_epu8(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_min_epu8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_min_epu8Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask16, __m128i, __m128i)>>('_mm_mask_min_epu8');
  late final __mm_mask_min_epu8 = __mm_mask_min_epu8Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_min_epu8(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_min_epu8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_min_epu8Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__mmask16, __m128i, __m128i)>>(
      '_mm_maskz_min_epu8');
  late final __mm_maskz_min_epu8 = __mm_maskz_min_epu8Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_mask_min_epu8(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_min_epu8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_min_epu8Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask32, __m256i, __m256i)>>('_mm256_mask_min_epu8');
  late final __mm256_mask_min_epu8 = __mm256_mask_min_epu8Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_min_epu8(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_min_epu8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_min_epu8Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__mmask32, __m256i, __m256i)>>(
      '_mm256_maskz_min_epu8');
  late final __mm256_maskz_min_epu8 = __mm256_maskz_min_epu8Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  _m128d _mm_mask_min_pd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    _m128d arg3,
  ) {
    return __mm_mask_min_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_min_pdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              _m128d, __mmask8, _m128d, _m128d)>>('_mm_mask_min_pd');
  late final __mm_mask_min_pd = __mm_mask_min_pdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d, _m128d)>();

  _m128d _mm_maskz_min_pd(
    int arg0,
    _m128d arg1,
    _m128d arg2,
  ) {
    return __mm_maskz_min_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_min_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(__mmask8, _m128d, _m128d)>>(
          '_mm_maskz_min_pd');
  late final __mm_maskz_min_pd =
      __mm_maskz_min_pdPtr.asFunction<_m128d Function(int, _m128d, _m128d)>();

  _m256d _mm256_mask_min_pd(
    _m256d arg0,
    int arg1,
    _m256d arg2,
    _m256d arg3,
  ) {
    return __mm256_mask_min_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_min_pdPtr = _lookup<
      ffi.NativeFunction<
          _m256d Function(
              _m256d, __mmask8, _m256d, _m256d)>>('_mm256_mask_min_pd');
  late final __mm256_mask_min_pd = __mm256_mask_min_pdPtr
      .asFunction<_m256d Function(_m256d, int, _m256d, _m256d)>();

  _m256d _mm256_maskz_min_pd(
    int arg0,
    _m256d arg1,
    _m256d arg2,
  ) {
    return __mm256_maskz_min_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_min_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(__mmask8, _m256d, _m256d)>>(
          '_mm256_maskz_min_pd');
  late final __mm256_maskz_min_pd = __mm256_maskz_min_pdPtr
      .asFunction<_m256d Function(int, _m256d, _m256d)>();

  __m128 _mm_mask_min_ps(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    __m128 arg3,
  ) {
    return __mm_mask_min_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_min_psPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __m128, __mmask8, __m128, __m128)>>('_mm_mask_min_ps');
  late final __mm_mask_min_ps = __mm_mask_min_psPtr
      .asFunction<__m128 Function(__m128, int, __m128, __m128)>();

  __m128 _mm_maskz_min_ps(
    int arg0,
    __m128 arg1,
    __m128 arg2,
  ) {
    return __mm_maskz_min_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_min_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__mmask8, __m128, __m128)>>(
          '_mm_maskz_min_ps');
  late final __mm_maskz_min_ps =
      __mm_maskz_min_psPtr.asFunction<__m128 Function(int, __m128, __m128)>();

  __m256 _mm256_mask_min_ps(
    __m256 arg0,
    int arg1,
    __m256 arg2,
    __m256 arg3,
  ) {
    return __mm256_mask_min_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_min_psPtr = _lookup<
      ffi.NativeFunction<
          __m256 Function(
              __m256, __mmask8, __m256, __m256)>>('_mm256_mask_min_ps');
  late final __mm256_mask_min_ps = __mm256_mask_min_psPtr
      .asFunction<__m256 Function(__m256, int, __m256, __m256)>();

  __m256 _mm256_maskz_min_ps(
    int arg0,
    __m256 arg1,
    __m256 arg2,
  ) {
    return __mm256_maskz_min_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_min_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__mmask8, __m256, __m256)>>(
          '_mm256_maskz_min_ps');
  late final __mm256_maskz_min_ps = __mm256_maskz_min_psPtr
      .asFunction<__m256 Function(int, __m256, __m256)>();

  __m128i _mm_mask_mov_epi16(
    __m128i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_mov_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_mov_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m128i)>>(
          '_mm_mask_mov_epi16');
  late final __mm_mask_mov_epi16 = __mm_mask_mov_epi16Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i)>();

  __m128i _mm_maskz_mov_epi16(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_mov_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_mov_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i)>>(
          '_mm_maskz_mov_epi16');
  late final __mm_maskz_mov_epi16 =
      __mm_maskz_mov_epi16Ptr.asFunction<__m128i Function(int, __m128i)>();

  __m256i _mm256_mask_mov_epi16(
    __m256i arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_mov_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_mov_epi16Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__m256i, __mmask16, __m256i)>>(
      '_mm256_mask_mov_epi16');
  late final __mm256_mask_mov_epi16 = __mm256_mask_mov_epi16Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i)>();

  __m256i _mm256_maskz_mov_epi16(
    int arg0,
    __m256i arg1,
  ) {
    return __mm256_maskz_mov_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_mov_epi16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask16, __m256i)>>(
          '_mm256_maskz_mov_epi16');
  late final __mm256_maskz_mov_epi16 =
      __mm256_maskz_mov_epi16Ptr.asFunction<__m256i Function(int, __m256i)>();

  __m128i _mm_mask_mov_epi32(
    __m128i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_mov_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_mov_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m128i)>>(
          '_mm_mask_mov_epi32');
  late final __mm_mask_mov_epi32 = __mm_mask_mov_epi32Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i)>();

  __m128i _mm_maskz_mov_epi32(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_mov_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_mov_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i)>>(
          '_mm_maskz_mov_epi32');
  late final __mm_maskz_mov_epi32 =
      __mm_maskz_mov_epi32Ptr.asFunction<__m128i Function(int, __m128i)>();

  __m256i _mm256_mask_mov_epi32(
    __m256i arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_mov_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_mov_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __mmask8, __m256i)>>(
          '_mm256_mask_mov_epi32');
  late final __mm256_mask_mov_epi32 = __mm256_mask_mov_epi32Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i)>();

  __m256i _mm256_maskz_mov_epi32(
    int arg0,
    __m256i arg1,
  ) {
    return __mm256_maskz_mov_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_mov_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m256i)>>(
          '_mm256_maskz_mov_epi32');
  late final __mm256_maskz_mov_epi32 =
      __mm256_maskz_mov_epi32Ptr.asFunction<__m256i Function(int, __m256i)>();

  __m128i _mm_mask_mov_epi64(
    __m128i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_mov_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_mov_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m128i)>>(
          '_mm_mask_mov_epi64');
  late final __mm_mask_mov_epi64 = __mm_mask_mov_epi64Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i)>();

  __m128i _mm_maskz_mov_epi64(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_mov_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_mov_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i)>>(
          '_mm_maskz_mov_epi64');
  late final __mm_maskz_mov_epi64 =
      __mm_maskz_mov_epi64Ptr.asFunction<__m128i Function(int, __m128i)>();

  __m256i _mm256_mask_mov_epi64(
    __m256i arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_mov_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_mov_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __mmask8, __m256i)>>(
          '_mm256_mask_mov_epi64');
  late final __mm256_mask_mov_epi64 = __mm256_mask_mov_epi64Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i)>();

  __m256i _mm256_maskz_mov_epi64(
    int arg0,
    __m256i arg1,
  ) {
    return __mm256_maskz_mov_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_mov_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m256i)>>(
          '_mm256_maskz_mov_epi64');
  late final __mm256_maskz_mov_epi64 =
      __mm256_maskz_mov_epi64Ptr.asFunction<__m256i Function(int, __m256i)>();

  __m128i _mm_mask_mov_epi8(
    __m128i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_mov_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_mov_epi8Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__m128i, __mmask16, __m128i)>>(
      '_mm_mask_mov_epi8');
  late final __mm_mask_mov_epi8 = __mm_mask_mov_epi8Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i)>();

  __m128i _mm_maskz_mov_epi8(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_mov_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_mov_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask16, __m128i)>>(
          '_mm_maskz_mov_epi8');
  late final __mm_maskz_mov_epi8 =
      __mm_maskz_mov_epi8Ptr.asFunction<__m128i Function(int, __m128i)>();

  __m256i _mm256_mask_mov_epi8(
    __m256i arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_mov_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_mov_epi8Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__m256i, __mmask32, __m256i)>>(
      '_mm256_mask_mov_epi8');
  late final __mm256_mask_mov_epi8 = __mm256_mask_mov_epi8Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i)>();

  __m256i _mm256_maskz_mov_epi8(
    int arg0,
    __m256i arg1,
  ) {
    return __mm256_maskz_mov_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_mov_epi8Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask32, __m256i)>>(
          '_mm256_maskz_mov_epi8');
  late final __mm256_maskz_mov_epi8 =
      __mm256_maskz_mov_epi8Ptr.asFunction<__m256i Function(int, __m256i)>();

  _m128d _mm_mask_mov_pd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
  ) {
    return __mm_mask_mov_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_mov_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, __mmask8, _m128d)>>(
          '_mm_mask_mov_pd');
  late final __mm_mask_mov_pd =
      __mm_mask_mov_pdPtr.asFunction<_m128d Function(_m128d, int, _m128d)>();

  _m128d _mm_maskz_mov_pd(
    int arg0,
    _m128d arg1,
  ) {
    return __mm_maskz_mov_pd(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_mov_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(__mmask8, _m128d)>>(
          '_mm_maskz_mov_pd');
  late final __mm_maskz_mov_pd =
      __mm_maskz_mov_pdPtr.asFunction<_m128d Function(int, _m128d)>();

  _m256d _mm256_mask_mov_pd(
    _m256d arg0,
    int arg1,
    _m256d arg2,
  ) {
    return __mm256_mask_mov_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_mov_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d, __mmask8, _m256d)>>(
          '_mm256_mask_mov_pd');
  late final __mm256_mask_mov_pd =
      __mm256_mask_mov_pdPtr.asFunction<_m256d Function(_m256d, int, _m256d)>();

  _m256d _mm256_maskz_mov_pd(
    int arg0,
    _m256d arg1,
  ) {
    return __mm256_maskz_mov_pd(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_mov_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(__mmask8, _m256d)>>(
          '_mm256_maskz_mov_pd');
  late final __mm256_maskz_mov_pd =
      __mm256_maskz_mov_pdPtr.asFunction<_m256d Function(int, _m256d)>();

  __m128 _mm_mask_mov_ps(
    __m128 arg0,
    int arg1,
    __m128 arg2,
  ) {
    return __mm_mask_mov_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_mov_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __mmask8, __m128)>>(
          '_mm_mask_mov_ps');
  late final __mm_mask_mov_ps =
      __mm_mask_mov_psPtr.asFunction<__m128 Function(__m128, int, __m128)>();

  __m128 _mm_maskz_mov_ps(
    int arg0,
    __m128 arg1,
  ) {
    return __mm_maskz_mov_ps(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_mov_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__mmask8, __m128)>>(
          '_mm_maskz_mov_ps');
  late final __mm_maskz_mov_ps =
      __mm_maskz_mov_psPtr.asFunction<__m128 Function(int, __m128)>();

  __m256 _mm256_mask_mov_ps(
    __m256 arg0,
    int arg1,
    __m256 arg2,
  ) {
    return __mm256_mask_mov_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_mov_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256, __mmask8, __m256)>>(
          '_mm256_mask_mov_ps');
  late final __mm256_mask_mov_ps =
      __mm256_mask_mov_psPtr.asFunction<__m256 Function(__m256, int, __m256)>();

  __m256 _mm256_maskz_mov_ps(
    int arg0,
    __m256 arg1,
  ) {
    return __mm256_maskz_mov_ps(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_mov_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__mmask8, __m256)>>(
          '_mm256_maskz_mov_ps');
  late final __mm256_maskz_mov_ps =
      __mm256_maskz_mov_psPtr.asFunction<__m256 Function(int, __m256)>();

  _m128d _mm_mask_movedup_pd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
  ) {
    return __mm_mask_movedup_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_movedup_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, __mmask8, _m128d)>>(
          '_mm_mask_movedup_pd');
  late final __mm_mask_movedup_pd = __mm_mask_movedup_pdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d)>();

  _m128d _mm_maskz_movedup_pd(
    int arg0,
    _m128d arg1,
  ) {
    return __mm_maskz_movedup_pd(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_movedup_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(__mmask8, _m128d)>>(
          '_mm_maskz_movedup_pd');
  late final __mm_maskz_movedup_pd =
      __mm_maskz_movedup_pdPtr.asFunction<_m128d Function(int, _m128d)>();

  _m256d _mm256_mask_movedup_pd(
    _m256d arg0,
    int arg1,
    _m256d arg2,
  ) {
    return __mm256_mask_movedup_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_movedup_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d, __mmask8, _m256d)>>(
          '_mm256_mask_movedup_pd');
  late final __mm256_mask_movedup_pd = __mm256_mask_movedup_pdPtr
      .asFunction<_m256d Function(_m256d, int, _m256d)>();

  _m256d _mm256_maskz_movedup_pd(
    int arg0,
    _m256d arg1,
  ) {
    return __mm256_maskz_movedup_pd(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_movedup_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(__mmask8, _m256d)>>(
          '_mm256_maskz_movedup_pd');
  late final __mm256_maskz_movedup_pd =
      __mm256_maskz_movedup_pdPtr.asFunction<_m256d Function(int, _m256d)>();

  __m128 _mm_mask_movehdup_ps(
    __m128 arg0,
    int arg1,
    __m128 arg2,
  ) {
    return __mm_mask_movehdup_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_movehdup_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __mmask8, __m128)>>(
          '_mm_mask_movehdup_ps');
  late final __mm_mask_movehdup_ps = __mm_mask_movehdup_psPtr
      .asFunction<__m128 Function(__m128, int, __m128)>();

  __m128 _mm_maskz_movehdup_ps(
    int arg0,
    __m128 arg1,
  ) {
    return __mm_maskz_movehdup_ps(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_movehdup_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__mmask8, __m128)>>(
          '_mm_maskz_movehdup_ps');
  late final __mm_maskz_movehdup_ps =
      __mm_maskz_movehdup_psPtr.asFunction<__m128 Function(int, __m128)>();

  __m256 _mm256_mask_movehdup_ps(
    __m256 arg0,
    int arg1,
    __m256 arg2,
  ) {
    return __mm256_mask_movehdup_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_movehdup_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256, __mmask8, __m256)>>(
          '_mm256_mask_movehdup_ps');
  late final __mm256_mask_movehdup_ps = __mm256_mask_movehdup_psPtr
      .asFunction<__m256 Function(__m256, int, __m256)>();

  __m256 _mm256_maskz_movehdup_ps(
    int arg0,
    __m256 arg1,
  ) {
    return __mm256_maskz_movehdup_ps(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_movehdup_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__mmask8, __m256)>>(
          '_mm256_maskz_movehdup_ps');
  late final __mm256_maskz_movehdup_ps =
      __mm256_maskz_movehdup_psPtr.asFunction<__m256 Function(int, __m256)>();

  __m128 _mm_mask_moveldup_ps(
    __m128 arg0,
    int arg1,
    __m128 arg2,
  ) {
    return __mm_mask_moveldup_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_moveldup_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __mmask8, __m128)>>(
          '_mm_mask_moveldup_ps');
  late final __mm_mask_moveldup_ps = __mm_mask_moveldup_psPtr
      .asFunction<__m128 Function(__m128, int, __m128)>();

  __m128 _mm_maskz_moveldup_ps(
    int arg0,
    __m128 arg1,
  ) {
    return __mm_maskz_moveldup_ps(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_moveldup_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__mmask8, __m128)>>(
          '_mm_maskz_moveldup_ps');
  late final __mm_maskz_moveldup_ps =
      __mm_maskz_moveldup_psPtr.asFunction<__m128 Function(int, __m128)>();

  __m256 _mm256_mask_moveldup_ps(
    __m256 arg0,
    int arg1,
    __m256 arg2,
  ) {
    return __mm256_mask_moveldup_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_moveldup_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256, __mmask8, __m256)>>(
          '_mm256_mask_moveldup_ps');
  late final __mm256_mask_moveldup_ps = __mm256_mask_moveldup_psPtr
      .asFunction<__m256 Function(__m256, int, __m256)>();

  __m256 _mm256_maskz_moveldup_ps(
    int arg0,
    __m256 arg1,
  ) {
    return __mm256_maskz_moveldup_ps(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_moveldup_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__mmask8, __m256)>>(
          '_mm256_maskz_moveldup_ps');
  late final __mm256_maskz_moveldup_ps =
      __mm256_maskz_moveldup_psPtr.asFunction<__m256 Function(int, __m256)>();

  int _mm_movepi16_mask(
    __m128i arg0,
  ) {
    return __mm_movepi16_mask(
      arg0,
    );
  }

  late final __mm_movepi16_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m128i)>>(
          '_mm_movepi16_mask');
  late final __mm_movepi16_mask =
      __mm_movepi16_maskPtr.asFunction<int Function(__m128i)>();

  int _mm256_movepi16_mask(
    __m256i arg0,
  ) {
    return __mm256_movepi16_mask(
      arg0,
    );
  }

  late final __mm256_movepi16_maskPtr =
      _lookup<ffi.NativeFunction<__mmask16 Function(__m256i)>>(
          '_mm256_movepi16_mask');
  late final __mm256_movepi16_mask =
      __mm256_movepi16_maskPtr.asFunction<int Function(__m256i)>();

  int _mm_movepi32_mask(
    __m128i arg0,
  ) {
    return __mm_movepi32_mask(
      arg0,
    );
  }

  late final __mm_movepi32_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m128i)>>(
          '_mm_movepi32_mask');
  late final __mm_movepi32_mask =
      __mm_movepi32_maskPtr.asFunction<int Function(__m128i)>();

  int _mm256_movepi32_mask(
    __m256i arg0,
  ) {
    return __mm256_movepi32_mask(
      arg0,
    );
  }

  late final __mm256_movepi32_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m256i)>>(
          '_mm256_movepi32_mask');
  late final __mm256_movepi32_mask =
      __mm256_movepi32_maskPtr.asFunction<int Function(__m256i)>();

  int _mm_movepi64_mask(
    __m128i arg0,
  ) {
    return __mm_movepi64_mask(
      arg0,
    );
  }

  late final __mm_movepi64_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m128i)>>(
          '_mm_movepi64_mask');
  late final __mm_movepi64_mask =
      __mm_movepi64_maskPtr.asFunction<int Function(__m128i)>();

  int _mm256_movepi64_mask(
    __m256i arg0,
  ) {
    return __mm256_movepi64_mask(
      arg0,
    );
  }

  late final __mm256_movepi64_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m256i)>>(
          '_mm256_movepi64_mask');
  late final __mm256_movepi64_mask =
      __mm256_movepi64_maskPtr.asFunction<int Function(__m256i)>();

  int _mm_movepi8_mask(
    __m128i arg0,
  ) {
    return __mm_movepi8_mask(
      arg0,
    );
  }

  late final __mm_movepi8_maskPtr =
      _lookup<ffi.NativeFunction<__mmask16 Function(__m128i)>>(
          '_mm_movepi8_mask');
  late final __mm_movepi8_mask =
      __mm_movepi8_maskPtr.asFunction<int Function(__m128i)>();

  int _mm256_movepi8_mask(
    __m256i arg0,
  ) {
    return __mm256_movepi8_mask(
      arg0,
    );
  }

  late final __mm256_movepi8_maskPtr =
      _lookup<ffi.NativeFunction<__mmask32 Function(__m256i)>>(
          '_mm256_movepi8_mask');
  late final __mm256_movepi8_mask =
      __mm256_movepi8_maskPtr.asFunction<int Function(__m256i)>();

  __m128i _mm_movm_epi16(
    int arg0,
  ) {
    return __mm_movm_epi16(
      arg0,
    );
  }

  late final __mm_movm_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8)>>('_mm_movm_epi16');
  late final __mm_movm_epi16 =
      __mm_movm_epi16Ptr.asFunction<__m128i Function(int)>();

  __m256i _mm256_movm_epi16(
    int arg0,
  ) {
    return __mm256_movm_epi16(
      arg0,
    );
  }

  late final __mm256_movm_epi16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask16)>>(
          '_mm256_movm_epi16');
  late final __mm256_movm_epi16 =
      __mm256_movm_epi16Ptr.asFunction<__m256i Function(int)>();

  __m128i _mm_movm_epi32(
    int arg0,
  ) {
    return __mm_movm_epi32(
      arg0,
    );
  }

  late final __mm_movm_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8)>>('_mm_movm_epi32');
  late final __mm_movm_epi32 =
      __mm_movm_epi32Ptr.asFunction<__m128i Function(int)>();

  __m256i _mm256_movm_epi32(
    int arg0,
  ) {
    return __mm256_movm_epi32(
      arg0,
    );
  }

  late final __mm256_movm_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8)>>(
          '_mm256_movm_epi32');
  late final __mm256_movm_epi32 =
      __mm256_movm_epi32Ptr.asFunction<__m256i Function(int)>();

  __m128i _mm_movm_epi64(
    int arg0,
  ) {
    return __mm_movm_epi64(
      arg0,
    );
  }

  late final __mm_movm_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8)>>('_mm_movm_epi64');
  late final __mm_movm_epi64 =
      __mm_movm_epi64Ptr.asFunction<__m128i Function(int)>();

  __m256i _mm256_movm_epi64(
    int arg0,
  ) {
    return __mm256_movm_epi64(
      arg0,
    );
  }

  late final __mm256_movm_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8)>>(
          '_mm256_movm_epi64');
  late final __mm256_movm_epi64 =
      __mm256_movm_epi64Ptr.asFunction<__m256i Function(int)>();

  __m128i _mm_movm_epi8(
    int arg0,
  ) {
    return __mm_movm_epi8(
      arg0,
    );
  }

  late final __mm_movm_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask16)>>('_mm_movm_epi8');
  late final __mm_movm_epi8 =
      __mm_movm_epi8Ptr.asFunction<__m128i Function(int)>();

  __m256i _mm256_movm_epi8(
    int arg0,
  ) {
    return __mm256_movm_epi8(
      arg0,
    );
  }

  late final __mm256_movm_epi8Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask32)>>(
          '_mm256_movm_epi8');
  late final __mm256_movm_epi8 =
      __mm256_movm_epi8Ptr.asFunction<__m256i Function(int)>();

  __m128i _mm_mask_mul_epi32(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_mul_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_mul_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_mul_epi32');
  late final __mm_mask_mul_epi32 = __mm_mask_mul_epi32Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_mul_epi32(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_mul_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_mul_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_maskz_mul_epi32');
  late final __mm_maskz_mul_epi32 = __mm_maskz_mul_epi32Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_mask_mul_epi32(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_mul_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_mul_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask8, __m256i, __m256i)>>('_mm256_mask_mul_epi32');
  late final __mm256_mask_mul_epi32 = __mm256_mask_mul_epi32Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_mul_epi32(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_mul_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_mul_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m256i, __m256i)>>(
          '_mm256_maskz_mul_epi32');
  late final __mm256_maskz_mul_epi32 = __mm256_maskz_mul_epi32Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  __m128i _mm_mask_mul_epu32(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_mul_epu32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_mul_epu32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_mul_epu32');
  late final __mm_mask_mul_epu32 = __mm_mask_mul_epu32Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_mul_epu32(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_mul_epu32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_mul_epu32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_maskz_mul_epu32');
  late final __mm_maskz_mul_epu32 = __mm_maskz_mul_epu32Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_mask_mul_epu32(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_mul_epu32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_mul_epu32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask8, __m256i, __m256i)>>('_mm256_mask_mul_epu32');
  late final __mm256_mask_mul_epu32 = __mm256_mask_mul_epu32Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_mul_epu32(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_mul_epu32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_mul_epu32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m256i, __m256i)>>(
          '_mm256_maskz_mul_epu32');
  late final __mm256_maskz_mul_epu32 = __mm256_maskz_mul_epu32Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  _m128d _mm_mask_mul_pd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    _m128d arg3,
  ) {
    return __mm_mask_mul_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_mul_pdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              _m128d, __mmask8, _m128d, _m128d)>>('_mm_mask_mul_pd');
  late final __mm_mask_mul_pd = __mm_mask_mul_pdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d, _m128d)>();

  _m128d _mm_maskz_mul_pd(
    int arg0,
    _m128d arg1,
    _m128d arg2,
  ) {
    return __mm_maskz_mul_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_mul_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(__mmask8, _m128d, _m128d)>>(
          '_mm_maskz_mul_pd');
  late final __mm_maskz_mul_pd =
      __mm_maskz_mul_pdPtr.asFunction<_m128d Function(int, _m128d, _m128d)>();

  _m256d _mm256_mask_mul_pd(
    _m256d arg0,
    int arg1,
    _m256d arg2,
    _m256d arg3,
  ) {
    return __mm256_mask_mul_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_mul_pdPtr = _lookup<
      ffi.NativeFunction<
          _m256d Function(
              _m256d, __mmask8, _m256d, _m256d)>>('_mm256_mask_mul_pd');
  late final __mm256_mask_mul_pd = __mm256_mask_mul_pdPtr
      .asFunction<_m256d Function(_m256d, int, _m256d, _m256d)>();

  _m256d _mm256_maskz_mul_pd(
    int arg0,
    _m256d arg1,
    _m256d arg2,
  ) {
    return __mm256_maskz_mul_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_mul_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(__mmask8, _m256d, _m256d)>>(
          '_mm256_maskz_mul_pd');
  late final __mm256_maskz_mul_pd = __mm256_maskz_mul_pdPtr
      .asFunction<_m256d Function(int, _m256d, _m256d)>();

  __m128 _mm_mask_mul_ps(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    __m128 arg3,
  ) {
    return __mm_mask_mul_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_mul_psPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __m128, __mmask8, __m128, __m128)>>('_mm_mask_mul_ps');
  late final __mm_mask_mul_ps = __mm_mask_mul_psPtr
      .asFunction<__m128 Function(__m128, int, __m128, __m128)>();

  __m128 _mm_maskz_mul_ps(
    int arg0,
    __m128 arg1,
    __m128 arg2,
  ) {
    return __mm_maskz_mul_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_mul_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__mmask8, __m128, __m128)>>(
          '_mm_maskz_mul_ps');
  late final __mm_maskz_mul_ps =
      __mm_maskz_mul_psPtr.asFunction<__m128 Function(int, __m128, __m128)>();

  __m256 _mm256_mask_mul_ps(
    __m256 arg0,
    int arg1,
    __m256 arg2,
    __m256 arg3,
  ) {
    return __mm256_mask_mul_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_mul_psPtr = _lookup<
      ffi.NativeFunction<
          __m256 Function(
              __m256, __mmask8, __m256, __m256)>>('_mm256_mask_mul_ps');
  late final __mm256_mask_mul_ps = __mm256_mask_mul_psPtr
      .asFunction<__m256 Function(__m256, int, __m256, __m256)>();

  __m256 _mm256_maskz_mul_ps(
    int arg0,
    __m256 arg1,
    __m256 arg2,
  ) {
    return __mm256_maskz_mul_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_mul_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__mmask8, __m256, __m256)>>(
          '_mm256_maskz_mul_ps');
  late final __mm256_maskz_mul_ps = __mm256_maskz_mul_psPtr
      .asFunction<__m256 Function(int, __m256, __m256)>();

  __m128i _mm_mask_mulhi_epi16(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_mulhi_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_mulhi_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_mulhi_epi16');
  late final __mm_mask_mulhi_epi16 = __mm_mask_mulhi_epi16Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_mulhi_epi16(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_mulhi_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_mulhi_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_maskz_mulhi_epi16');
  late final __mm_maskz_mulhi_epi16 = __mm_maskz_mulhi_epi16Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_mask_mulhi_epi16(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_mulhi_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_mulhi_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask16, __m256i,
              __m256i)>>('_mm256_mask_mulhi_epi16');
  late final __mm256_mask_mulhi_epi16 = __mm256_mask_mulhi_epi16Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_mulhi_epi16(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_mulhi_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_mulhi_epi16Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__mmask16, __m256i, __m256i)>>(
      '_mm256_maskz_mulhi_epi16');
  late final __mm256_maskz_mulhi_epi16 = __mm256_maskz_mulhi_epi16Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  __m128i _mm_mask_mulhi_epu16(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_mulhi_epu16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_mulhi_epu16Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_mulhi_epu16');
  late final __mm_mask_mulhi_epu16 = __mm_mask_mulhi_epu16Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_mulhi_epu16(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_mulhi_epu16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_mulhi_epu16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_maskz_mulhi_epu16');
  late final __mm_maskz_mulhi_epu16 = __mm_maskz_mulhi_epu16Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_mask_mulhi_epu16(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_mulhi_epu16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_mulhi_epu16Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask16, __m256i,
              __m256i)>>('_mm256_mask_mulhi_epu16');
  late final __mm256_mask_mulhi_epu16 = __mm256_mask_mulhi_epu16Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_mulhi_epu16(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_mulhi_epu16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_mulhi_epu16Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__mmask16, __m256i, __m256i)>>(
      '_mm256_maskz_mulhi_epu16');
  late final __mm256_maskz_mulhi_epu16 = __mm256_maskz_mulhi_epu16Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  __m128i _mm_mask_mulhrs_epi16(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_mulhrs_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_mulhrs_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_mulhrs_epi16');
  late final __mm_mask_mulhrs_epi16 = __mm_mask_mulhrs_epi16Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_mulhrs_epi16(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_mulhrs_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_mulhrs_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_maskz_mulhrs_epi16');
  late final __mm_maskz_mulhrs_epi16 = __mm_maskz_mulhrs_epi16Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_mask_mulhrs_epi16(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_mulhrs_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_mulhrs_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask16, __m256i,
              __m256i)>>('_mm256_mask_mulhrs_epi16');
  late final __mm256_mask_mulhrs_epi16 = __mm256_mask_mulhrs_epi16Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_mulhrs_epi16(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_mulhrs_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_mulhrs_epi16Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__mmask16, __m256i, __m256i)>>(
      '_mm256_maskz_mulhrs_epi16');
  late final __mm256_maskz_mulhrs_epi16 = __mm256_maskz_mulhrs_epi16Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  __m128i _mm_mask_mullo_epi16(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_mullo_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_mullo_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_mullo_epi16');
  late final __mm_mask_mullo_epi16 = __mm_mask_mullo_epi16Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_mullo_epi16(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_mullo_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_mullo_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_maskz_mullo_epi16');
  late final __mm_maskz_mullo_epi16 = __mm_maskz_mullo_epi16Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_mask_mullo_epi16(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_mullo_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_mullo_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask16, __m256i,
              __m256i)>>('_mm256_mask_mullo_epi16');
  late final __mm256_mask_mullo_epi16 = __mm256_mask_mullo_epi16Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_mullo_epi16(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_mullo_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_mullo_epi16Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__mmask16, __m256i, __m256i)>>(
      '_mm256_maskz_mullo_epi16');
  late final __mm256_maskz_mullo_epi16 = __mm256_maskz_mullo_epi16Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  __m128i _mm_mask_mullo_epi32(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_mullo_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_mullo_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_mullo_epi32');
  late final __mm_mask_mullo_epi32 = __mm_mask_mullo_epi32Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_mullo_epi32(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_mullo_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_mullo_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_maskz_mullo_epi32');
  late final __mm_maskz_mullo_epi32 = __mm_maskz_mullo_epi32Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_mask_mullo_epi32(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_mullo_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_mullo_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask8, __m256i, __m256i)>>('_mm256_mask_mullo_epi32');
  late final __mm256_mask_mullo_epi32 = __mm256_mask_mullo_epi32Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_mullo_epi32(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_mullo_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_mullo_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m256i, __m256i)>>(
          '_mm256_maskz_mullo_epi32');
  late final __mm256_maskz_mullo_epi32 = __mm256_maskz_mullo_epi32Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  __m128i _mm_mask_mullo_epi64(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_mullo_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_mullo_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_mullo_epi64');
  late final __mm_mask_mullo_epi64 = __mm_mask_mullo_epi64Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_mullo_epi64(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_mullo_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_mullo_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_maskz_mullo_epi64');
  late final __mm_maskz_mullo_epi64 = __mm_maskz_mullo_epi64Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m128i _mm_mullo_epi64(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_mullo_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm_mullo_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_mullo_epi64');
  late final __mm_mullo_epi64 =
      __mm_mullo_epi64Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m256i _mm256_mask_mullo_epi64(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_mullo_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_mullo_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask8, __m256i, __m256i)>>('_mm256_mask_mullo_epi64');
  late final __mm256_mask_mullo_epi64 = __mm256_mask_mullo_epi64Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_mullo_epi64(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_mullo_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_mullo_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m256i, __m256i)>>(
          '_mm256_maskz_mullo_epi64');
  late final __mm256_maskz_mullo_epi64 = __mm256_maskz_mullo_epi64Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  __m256i _mm256_mullo_epi64(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_mullo_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm256_mullo_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_mullo_epi64');
  late final __mm256_mullo_epi64 =
      __mm256_mullo_epi64Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m128i _mm_or_epi32(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_or_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm_or_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_or_epi32');
  late final __mm_or_epi32 =
      __mm_or_epi32Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_mask_or_epi32(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_or_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_or_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_or_epi32');
  late final __mm_mask_or_epi32 = __mm_mask_or_epi32Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_or_epi32(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_or_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_or_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_maskz_or_epi32');
  late final __mm_maskz_or_epi32 = __mm_maskz_or_epi32Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_or_epi32(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_or_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm256_or_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_or_epi32');
  late final __mm256_or_epi32 =
      __mm256_or_epi32Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_mask_or_epi32(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_or_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_or_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask8, __m256i, __m256i)>>('_mm256_mask_or_epi32');
  late final __mm256_mask_or_epi32 = __mm256_mask_or_epi32Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_or_epi32(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_or_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_or_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m256i, __m256i)>>(
          '_mm256_maskz_or_epi32');
  late final __mm256_maskz_or_epi32 = __mm256_maskz_or_epi32Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  __m128i _mm_or_epi64(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_or_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm_or_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_or_epi64');
  late final __mm_or_epi64 =
      __mm_or_epi64Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_mask_or_epi64(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_or_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_or_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_or_epi64');
  late final __mm_mask_or_epi64 = __mm_mask_or_epi64Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_or_epi64(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_or_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_or_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_maskz_or_epi64');
  late final __mm_maskz_or_epi64 = __mm_maskz_or_epi64Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_or_epi64(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_or_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm256_or_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_or_epi64');
  late final __mm256_or_epi64 =
      __mm256_or_epi64Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_mask_or_epi64(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_or_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_or_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask8, __m256i, __m256i)>>('_mm256_mask_or_epi64');
  late final __mm256_mask_or_epi64 = __mm256_mask_or_epi64Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_or_epi64(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_or_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_or_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m256i, __m256i)>>(
          '_mm256_maskz_or_epi64');
  late final __mm256_maskz_or_epi64 = __mm256_maskz_or_epi64Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  _m128d _mm_mask_or_pd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    _m128d arg3,
  ) {
    return __mm_mask_or_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_or_pdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(_m128d, __mmask8, _m128d, _m128d)>>('_mm_mask_or_pd');
  late final __mm_mask_or_pd = __mm_mask_or_pdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d, _m128d)>();

  _m128d _mm_maskz_or_pd(
    int arg0,
    _m128d arg1,
    _m128d arg2,
  ) {
    return __mm_maskz_or_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_or_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(__mmask8, _m128d, _m128d)>>(
          '_mm_maskz_or_pd');
  late final __mm_maskz_or_pd =
      __mm_maskz_or_pdPtr.asFunction<_m128d Function(int, _m128d, _m128d)>();

  _m256d _mm256_mask_or_pd(
    _m256d arg0,
    int arg1,
    _m256d arg2,
    _m256d arg3,
  ) {
    return __mm256_mask_or_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_or_pdPtr = _lookup<
      ffi.NativeFunction<
          _m256d Function(
              _m256d, __mmask8, _m256d, _m256d)>>('_mm256_mask_or_pd');
  late final __mm256_mask_or_pd = __mm256_mask_or_pdPtr
      .asFunction<_m256d Function(_m256d, int, _m256d, _m256d)>();

  _m256d _mm256_maskz_or_pd(
    int arg0,
    _m256d arg1,
    _m256d arg2,
  ) {
    return __mm256_maskz_or_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_or_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(__mmask8, _m256d, _m256d)>>(
          '_mm256_maskz_or_pd');
  late final __mm256_maskz_or_pd =
      __mm256_maskz_or_pdPtr.asFunction<_m256d Function(int, _m256d, _m256d)>();

  __m128 _mm_mask_or_ps(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    __m128 arg3,
  ) {
    return __mm_mask_or_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_or_psPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(__m128, __mmask8, __m128, __m128)>>('_mm_mask_or_ps');
  late final __mm_mask_or_ps = __mm_mask_or_psPtr
      .asFunction<__m128 Function(__m128, int, __m128, __m128)>();

  __m128 _mm_maskz_or_ps(
    int arg0,
    __m128 arg1,
    __m128 arg2,
  ) {
    return __mm_maskz_or_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_or_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__mmask8, __m128, __m128)>>(
          '_mm_maskz_or_ps');
  late final __mm_maskz_or_ps =
      __mm_maskz_or_psPtr.asFunction<__m128 Function(int, __m128, __m128)>();

  __m256 _mm256_mask_or_ps(
    __m256 arg0,
    int arg1,
    __m256 arg2,
    __m256 arg3,
  ) {
    return __mm256_mask_or_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_or_psPtr = _lookup<
      ffi.NativeFunction<
          __m256 Function(
              __m256, __mmask8, __m256, __m256)>>('_mm256_mask_or_ps');
  late final __mm256_mask_or_ps = __mm256_mask_or_psPtr
      .asFunction<__m256 Function(__m256, int, __m256, __m256)>();

  __m256 _mm256_maskz_or_ps(
    int arg0,
    __m256 arg1,
    __m256 arg2,
  ) {
    return __mm256_maskz_or_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_or_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__mmask8, __m256, __m256)>>(
          '_mm256_maskz_or_ps');
  late final __mm256_maskz_or_ps =
      __mm256_maskz_or_psPtr.asFunction<__m256 Function(int, __m256, __m256)>();

  __m128i _mm_mask_packs_epi16(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_packs_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_packs_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask16, __m128i, __m128i)>>('_mm_mask_packs_epi16');
  late final __mm_mask_packs_epi16 = __mm_mask_packs_epi16Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_packs_epi16(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_packs_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_packs_epi16Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__mmask16, __m128i, __m128i)>>(
      '_mm_maskz_packs_epi16');
  late final __mm_maskz_packs_epi16 = __mm_maskz_packs_epi16Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_mask_packs_epi16(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_packs_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_packs_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask32, __m256i,
              __m256i)>>('_mm256_mask_packs_epi16');
  late final __mm256_mask_packs_epi16 = __mm256_mask_packs_epi16Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_packs_epi16(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_packs_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_packs_epi16Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__mmask32, __m256i, __m256i)>>(
      '_mm256_maskz_packs_epi16');
  late final __mm256_maskz_packs_epi16 = __mm256_maskz_packs_epi16Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  __m128i _mm_mask_packs_epi32(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_packs_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_packs_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_packs_epi32');
  late final __mm_mask_packs_epi32 = __mm_mask_packs_epi32Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_packs_epi32(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_packs_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_packs_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_maskz_packs_epi32');
  late final __mm_maskz_packs_epi32 = __mm_maskz_packs_epi32Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_mask_packs_epi32(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_packs_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_packs_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask16, __m256i,
              __m256i)>>('_mm256_mask_packs_epi32');
  late final __mm256_mask_packs_epi32 = __mm256_mask_packs_epi32Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_packs_epi32(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_packs_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_packs_epi32Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__mmask16, __m256i, __m256i)>>(
      '_mm256_maskz_packs_epi32');
  late final __mm256_maskz_packs_epi32 = __mm256_maskz_packs_epi32Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  __m128i _mm_mask_packus_epi16(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_packus_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_packus_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask16, __m128i, __m128i)>>('_mm_mask_packus_epi16');
  late final __mm_mask_packus_epi16 = __mm_mask_packus_epi16Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_packus_epi16(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_packus_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_packus_epi16Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__mmask16, __m128i, __m128i)>>(
      '_mm_maskz_packus_epi16');
  late final __mm_maskz_packus_epi16 = __mm_maskz_packus_epi16Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_mask_packus_epi16(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_packus_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_packus_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask32, __m256i,
              __m256i)>>('_mm256_mask_packus_epi16');
  late final __mm256_mask_packus_epi16 = __mm256_mask_packus_epi16Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_packus_epi16(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_packus_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_packus_epi16Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__mmask32, __m256i, __m256i)>>(
      '_mm256_maskz_packus_epi16');
  late final __mm256_maskz_packus_epi16 = __mm256_maskz_packus_epi16Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  __m128i _mm_mask_packus_epi32(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_packus_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_packus_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_packus_epi32');
  late final __mm_mask_packus_epi32 = __mm_mask_packus_epi32Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_packus_epi32(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_packus_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_packus_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_maskz_packus_epi32');
  late final __mm_maskz_packus_epi32 = __mm_maskz_packus_epi32Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_mask_packus_epi32(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_packus_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_packus_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask16, __m256i,
              __m256i)>>('_mm256_mask_packus_epi32');
  late final __mm256_mask_packus_epi32 = __mm256_mask_packus_epi32Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_packus_epi32(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_packus_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_packus_epi32Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__mmask16, __m256i, __m256i)>>(
      '_mm256_maskz_packus_epi32');
  late final __mm256_maskz_packus_epi32 = __mm256_maskz_packus_epi32Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  _m128d _mm_mask_permute_pd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    int arg3,
  ) {
    return __mm_mask_permute_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_permute_pdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              _m128d, __mmask8, _m128d, ffi.Int32)>>('_mm_mask_permute_pd');
  late final __mm_mask_permute_pd = __mm_mask_permute_pdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d, int)>();

  _m128d _mm_maskz_permute_pd(
    int arg0,
    _m128d arg1,
    int arg2,
  ) {
    return __mm_maskz_permute_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_permute_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(__mmask8, _m128d, ffi.Int32)>>(
          '_mm_maskz_permute_pd');
  late final __mm_maskz_permute_pd =
      __mm_maskz_permute_pdPtr.asFunction<_m128d Function(int, _m128d, int)>();

  _m256d _mm256_mask_permute_pd(
    _m256d arg0,
    int arg1,
    _m256d arg2,
    int arg3,
  ) {
    return __mm256_mask_permute_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_permute_pdPtr = _lookup<
      ffi.NativeFunction<
          _m256d Function(
              _m256d, __mmask8, _m256d, ffi.Int32)>>('_mm256_mask_permute_pd');
  late final __mm256_mask_permute_pd = __mm256_mask_permute_pdPtr
      .asFunction<_m256d Function(_m256d, int, _m256d, int)>();

  _m256d _mm256_maskz_permute_pd(
    int arg0,
    _m256d arg1,
    int arg2,
  ) {
    return __mm256_maskz_permute_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_permute_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(__mmask8, _m256d, ffi.Int32)>>(
          '_mm256_maskz_permute_pd');
  late final __mm256_maskz_permute_pd = __mm256_maskz_permute_pdPtr
      .asFunction<_m256d Function(int, _m256d, int)>();

  __m128 _mm_mask_permute_ps(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    int arg3,
  ) {
    return __mm_mask_permute_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_permute_psPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __m128, __mmask8, __m128, ffi.Int32)>>('_mm_mask_permute_ps');
  late final __mm_mask_permute_ps = __mm_mask_permute_psPtr
      .asFunction<__m128 Function(__m128, int, __m128, int)>();

  __m128 _mm_maskz_permute_ps(
    int arg0,
    __m128 arg1,
    int arg2,
  ) {
    return __mm_maskz_permute_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_permute_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__mmask8, __m128, ffi.Int32)>>(
          '_mm_maskz_permute_ps');
  late final __mm_maskz_permute_ps =
      __mm_maskz_permute_psPtr.asFunction<__m128 Function(int, __m128, int)>();

  __m256 _mm256_mask_permute_ps(
    __m256 arg0,
    int arg1,
    __m256 arg2,
    int arg3,
  ) {
    return __mm256_mask_permute_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_permute_psPtr = _lookup<
      ffi.NativeFunction<
          __m256 Function(
              __m256, __mmask8, __m256, ffi.Int32)>>('_mm256_mask_permute_ps');
  late final __mm256_mask_permute_ps = __mm256_mask_permute_psPtr
      .asFunction<__m256 Function(__m256, int, __m256, int)>();

  __m256 _mm256_maskz_permute_ps(
    int arg0,
    __m256 arg1,
    int arg2,
  ) {
    return __mm256_maskz_permute_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_permute_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__mmask8, __m256, ffi.Int32)>>(
          '_mm256_maskz_permute_ps');
  late final __mm256_maskz_permute_ps = __mm256_maskz_permute_psPtr
      .asFunction<__m256 Function(int, __m256, int)>();

  _m128d _mm_mask_permutevar_pd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    __m128i arg3,
  ) {
    return __mm_mask_permutevar_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_permutevar_pdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              _m128d, __mmask8, _m128d, __m128i)>>('_mm_mask_permutevar_pd');
  late final __mm_mask_permutevar_pd = __mm_mask_permutevar_pdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d, __m128i)>();

  _m128d _mm_maskz_permutevar_pd(
    int arg0,
    _m128d arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_permutevar_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_permutevar_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(__mmask8, _m128d, __m128i)>>(
          '_mm_maskz_permutevar_pd');
  late final __mm_maskz_permutevar_pd = __mm_maskz_permutevar_pdPtr
      .asFunction<_m128d Function(int, _m128d, __m128i)>();

  _m256d _mm256_mask_permutevar_pd(
    _m256d arg0,
    int arg1,
    _m256d arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_permutevar_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_permutevar_pdPtr = _lookup<
      ffi.NativeFunction<
          _m256d Function(
              _m256d, __mmask8, _m256d, __m256i)>>('_mm256_mask_permutevar_pd');
  late final __mm256_mask_permutevar_pd = __mm256_mask_permutevar_pdPtr
      .asFunction<_m256d Function(_m256d, int, _m256d, __m256i)>();

  _m256d _mm256_maskz_permutevar_pd(
    int arg0,
    _m256d arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_permutevar_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_permutevar_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(__mmask8, _m256d, __m256i)>>(
          '_mm256_maskz_permutevar_pd');
  late final __mm256_maskz_permutevar_pd = __mm256_maskz_permutevar_pdPtr
      .asFunction<_m256d Function(int, _m256d, __m256i)>();

  __m128 _mm_mask_permutevar_ps(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    __m128i arg3,
  ) {
    return __mm_mask_permutevar_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_permutevar_psPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __m128, __mmask8, __m128, __m128i)>>('_mm_mask_permutevar_ps');
  late final __mm_mask_permutevar_ps = __mm_mask_permutevar_psPtr
      .asFunction<__m128 Function(__m128, int, __m128, __m128i)>();

  __m128 _mm_maskz_permutevar_ps(
    int arg0,
    __m128 arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_permutevar_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_permutevar_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__mmask8, __m128, __m128i)>>(
          '_mm_maskz_permutevar_ps');
  late final __mm_maskz_permutevar_ps = __mm_maskz_permutevar_psPtr
      .asFunction<__m128 Function(int, __m128, __m128i)>();

  __m256 _mm256_mask_permutevar_ps(
    __m256 arg0,
    int arg1,
    __m256 arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_permutevar_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_permutevar_psPtr = _lookup<
      ffi.NativeFunction<
          __m256 Function(
              __m256, __mmask8, __m256, __m256i)>>('_mm256_mask_permutevar_ps');
  late final __mm256_mask_permutevar_ps = __mm256_mask_permutevar_psPtr
      .asFunction<__m256 Function(__m256, int, __m256, __m256i)>();

  __m256 _mm256_maskz_permutevar_ps(
    int arg0,
    __m256 arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_permutevar_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_permutevar_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__mmask8, __m256, __m256i)>>(
          '_mm256_maskz_permutevar_ps');
  late final __mm256_maskz_permutevar_ps = __mm256_maskz_permutevar_psPtr
      .asFunction<__m256 Function(int, __m256, __m256i)>();

  __m256i _mm256_mask_permutex_epi64(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    int arg3,
  ) {
    return __mm256_mask_permutex_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_permutex_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask8, __m256i,
              ffi.Int32)>>('_mm256_mask_permutex_epi64');
  late final __mm256_mask_permutex_epi64 = __mm256_mask_permutex_epi64Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, int)>();

  __m256i _mm256_maskz_permutex_epi64(
    int arg0,
    __m256i arg1,
    int arg2,
  ) {
    return __mm256_maskz_permutex_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_permutex_epi64Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__mmask8, __m256i, ffi.Int32)>>(
      '_mm256_maskz_permutex_epi64');
  late final __mm256_maskz_permutex_epi64 = __mm256_maskz_permutex_epi64Ptr
      .asFunction<__m256i Function(int, __m256i, int)>();

  __m256i _mm256_permutex_epi64(
    __m256i arg0,
    int arg1,
  ) {
    return __mm256_permutex_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm256_permutex_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, ffi.Int32)>>(
          '_mm256_permutex_epi64');
  late final __mm256_permutex_epi64 =
      __mm256_permutex_epi64Ptr.asFunction<__m256i Function(__m256i, int)>();

  _m256d _mm256_mask_permutex_pd(
    _m256d arg0,
    int arg1,
    _m256d arg2,
    int arg3,
  ) {
    return __mm256_mask_permutex_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_permutex_pdPtr = _lookup<
      ffi.NativeFunction<
          _m256d Function(
              _m256d, __mmask8, _m256d, ffi.Int32)>>('_mm256_mask_permutex_pd');
  late final __mm256_mask_permutex_pd = __mm256_mask_permutex_pdPtr
      .asFunction<_m256d Function(_m256d, int, _m256d, int)>();

  _m256d _mm256_maskz_permutex_pd(
    int arg0,
    _m256d arg1,
    int arg2,
  ) {
    return __mm256_maskz_permutex_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_permutex_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(__mmask8, _m256d, ffi.Int32)>>(
          '_mm256_maskz_permutex_pd');
  late final __mm256_maskz_permutex_pd = __mm256_maskz_permutex_pdPtr
      .asFunction<_m256d Function(int, _m256d, int)>();

  _m256d _mm256_permutex_pd(
    _m256d arg0,
    int arg1,
  ) {
    return __mm256_permutex_pd(
      arg0,
      arg1,
    );
  }

  late final __mm256_permutex_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d, ffi.Int32)>>(
          '_mm256_permutex_pd');
  late final __mm256_permutex_pd =
      __mm256_permutex_pdPtr.asFunction<_m256d Function(_m256d, int)>();

  __m128i _mm_mask_permutex2var_epi16(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_permutex2var_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_permutex2var_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(__m128i, __mmask8, __m128i,
              __m128i)>>('_mm_mask_permutex2var_epi16');
  late final __mm_mask_permutex2var_epi16 = __mm_mask_permutex2var_epi16Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_mask2_permutex2var_epi16(
    __m128i arg0,
    __m128i arg1,
    int arg2,
    __m128i arg3,
  ) {
    return __mm_mask2_permutex2var_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask2_permutex2var_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(__m128i, __m128i, __mmask8,
              __m128i)>>('_mm_mask2_permutex2var_epi16');
  late final __mm_mask2_permutex2var_epi16 = __mm_mask2_permutex2var_epi16Ptr
      .asFunction<__m128i Function(__m128i, __m128i, int, __m128i)>();

  __m128i _mm_maskz_permutex2var_epi16(
    int arg0,
    __m128i arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_maskz_permutex2var_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_permutex2var_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(__mmask8, __m128i, __m128i,
              __m128i)>>('_mm_maskz_permutex2var_epi16');
  late final __mm_maskz_permutex2var_epi16 = __mm_maskz_permutex2var_epi16Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i, __m128i)>();

  __m128i _mm_permutex2var_epi16(
    __m128i arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_permutex2var_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_permutex2var_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i, __m128i)>>(
          '_mm_permutex2var_epi16');
  late final __mm_permutex2var_epi16 = __mm_permutex2var_epi16Ptr
      .asFunction<__m128i Function(__m128i, __m128i, __m128i)>();

  __m256i _mm256_mask_permutex2var_epi16(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_permutex2var_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_permutex2var_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask16, __m256i,
              __m256i)>>('_mm256_mask_permutex2var_epi16');
  late final __mm256_mask_permutex2var_epi16 =
      __mm256_mask_permutex2var_epi16Ptr
          .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_mask2_permutex2var_epi16(
    __m256i arg0,
    __m256i arg1,
    int arg2,
    __m256i arg3,
  ) {
    return __mm256_mask2_permutex2var_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask2_permutex2var_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __m256i, __mmask16,
              __m256i)>>('_mm256_mask2_permutex2var_epi16');
  late final __mm256_mask2_permutex2var_epi16 =
      __mm256_mask2_permutex2var_epi16Ptr
          .asFunction<__m256i Function(__m256i, __m256i, int, __m256i)>();

  __m256i _mm256_maskz_permutex2var_epi16(
    int arg0,
    __m256i arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_maskz_permutex2var_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_maskz_permutex2var_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__mmask16, __m256i, __m256i,
              __m256i)>>('_mm256_maskz_permutex2var_epi16');
  late final __mm256_maskz_permutex2var_epi16 =
      __mm256_maskz_permutex2var_epi16Ptr
          .asFunction<__m256i Function(int, __m256i, __m256i, __m256i)>();

  __m256i _mm256_permutex2var_epi16(
    __m256i arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_permutex2var_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_permutex2var_epi16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i, __m256i)>>(
          '_mm256_permutex2var_epi16');
  late final __mm256_permutex2var_epi16 = __mm256_permutex2var_epi16Ptr
      .asFunction<__m256i Function(__m256i, __m256i, __m256i)>();

  __m128i _mm_mask_permutex2var_epi32(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_permutex2var_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_permutex2var_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(__m128i, __mmask8, __m128i,
              __m128i)>>('_mm_mask_permutex2var_epi32');
  late final __mm_mask_permutex2var_epi32 = __mm_mask_permutex2var_epi32Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_mask2_permutex2var_epi32(
    __m128i arg0,
    __m128i arg1,
    int arg2,
    __m128i arg3,
  ) {
    return __mm_mask2_permutex2var_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask2_permutex2var_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(__m128i, __m128i, __mmask8,
              __m128i)>>('_mm_mask2_permutex2var_epi32');
  late final __mm_mask2_permutex2var_epi32 = __mm_mask2_permutex2var_epi32Ptr
      .asFunction<__m128i Function(__m128i, __m128i, int, __m128i)>();

  __m128i _mm_maskz_permutex2var_epi32(
    int arg0,
    __m128i arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_maskz_permutex2var_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_permutex2var_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(__mmask8, __m128i, __m128i,
              __m128i)>>('_mm_maskz_permutex2var_epi32');
  late final __mm_maskz_permutex2var_epi32 = __mm_maskz_permutex2var_epi32Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i, __m128i)>();

  __m128i _mm_permutex2var_epi32(
    __m128i arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_permutex2var_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_permutex2var_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i, __m128i)>>(
          '_mm_permutex2var_epi32');
  late final __mm_permutex2var_epi32 = __mm_permutex2var_epi32Ptr
      .asFunction<__m128i Function(__m128i, __m128i, __m128i)>();

  __m256i _mm256_mask_permutex2var_epi32(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_permutex2var_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_permutex2var_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask8, __m256i,
              __m256i)>>('_mm256_mask_permutex2var_epi32');
  late final __mm256_mask_permutex2var_epi32 =
      __mm256_mask_permutex2var_epi32Ptr
          .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_mask2_permutex2var_epi32(
    __m256i arg0,
    __m256i arg1,
    int arg2,
    __m256i arg3,
  ) {
    return __mm256_mask2_permutex2var_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask2_permutex2var_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __m256i, __mmask8,
              __m256i)>>('_mm256_mask2_permutex2var_epi32');
  late final __mm256_mask2_permutex2var_epi32 =
      __mm256_mask2_permutex2var_epi32Ptr
          .asFunction<__m256i Function(__m256i, __m256i, int, __m256i)>();

  __m256i _mm256_maskz_permutex2var_epi32(
    int arg0,
    __m256i arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_maskz_permutex2var_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_maskz_permutex2var_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__mmask8, __m256i, __m256i,
              __m256i)>>('_mm256_maskz_permutex2var_epi32');
  late final __mm256_maskz_permutex2var_epi32 =
      __mm256_maskz_permutex2var_epi32Ptr
          .asFunction<__m256i Function(int, __m256i, __m256i, __m256i)>();

  __m256i _mm256_permutex2var_epi32(
    __m256i arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_permutex2var_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_permutex2var_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i, __m256i)>>(
          '_mm256_permutex2var_epi32');
  late final __mm256_permutex2var_epi32 = __mm256_permutex2var_epi32Ptr
      .asFunction<__m256i Function(__m256i, __m256i, __m256i)>();

  __m128i _mm_mask_permutex2var_epi64(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_permutex2var_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_permutex2var_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(__m128i, __mmask8, __m128i,
              __m128i)>>('_mm_mask_permutex2var_epi64');
  late final __mm_mask_permutex2var_epi64 = __mm_mask_permutex2var_epi64Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_mask2_permutex2var_epi64(
    __m128i arg0,
    __m128i arg1,
    int arg2,
    __m128i arg3,
  ) {
    return __mm_mask2_permutex2var_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask2_permutex2var_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(__m128i, __m128i, __mmask8,
              __m128i)>>('_mm_mask2_permutex2var_epi64');
  late final __mm_mask2_permutex2var_epi64 = __mm_mask2_permutex2var_epi64Ptr
      .asFunction<__m128i Function(__m128i, __m128i, int, __m128i)>();

  __m128i _mm_maskz_permutex2var_epi64(
    int arg0,
    __m128i arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_maskz_permutex2var_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_permutex2var_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(__mmask8, __m128i, __m128i,
              __m128i)>>('_mm_maskz_permutex2var_epi64');
  late final __mm_maskz_permutex2var_epi64 = __mm_maskz_permutex2var_epi64Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i, __m128i)>();

  __m128i _mm_permutex2var_epi64(
    __m128i arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_permutex2var_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_permutex2var_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i, __m128i)>>(
          '_mm_permutex2var_epi64');
  late final __mm_permutex2var_epi64 = __mm_permutex2var_epi64Ptr
      .asFunction<__m128i Function(__m128i, __m128i, __m128i)>();

  __m256i _mm256_mask_permutex2var_epi64(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_permutex2var_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_permutex2var_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask8, __m256i,
              __m256i)>>('_mm256_mask_permutex2var_epi64');
  late final __mm256_mask_permutex2var_epi64 =
      __mm256_mask_permutex2var_epi64Ptr
          .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_mask2_permutex2var_epi64(
    __m256i arg0,
    __m256i arg1,
    int arg2,
    __m256i arg3,
  ) {
    return __mm256_mask2_permutex2var_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask2_permutex2var_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __m256i, __mmask8,
              __m256i)>>('_mm256_mask2_permutex2var_epi64');
  late final __mm256_mask2_permutex2var_epi64 =
      __mm256_mask2_permutex2var_epi64Ptr
          .asFunction<__m256i Function(__m256i, __m256i, int, __m256i)>();

  __m256i _mm256_maskz_permutex2var_epi64(
    int arg0,
    __m256i arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_maskz_permutex2var_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_maskz_permutex2var_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__mmask8, __m256i, __m256i,
              __m256i)>>('_mm256_maskz_permutex2var_epi64');
  late final __mm256_maskz_permutex2var_epi64 =
      __mm256_maskz_permutex2var_epi64Ptr
          .asFunction<__m256i Function(int, __m256i, __m256i, __m256i)>();

  __m256i _mm256_permutex2var_epi64(
    __m256i arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_permutex2var_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_permutex2var_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i, __m256i)>>(
          '_mm256_permutex2var_epi64');
  late final __mm256_permutex2var_epi64 = __mm256_permutex2var_epi64Ptr
      .asFunction<__m256i Function(__m256i, __m256i, __m256i)>();

  _m128d _mm_mask_permutex2var_pd(
    _m128d arg0,
    int arg1,
    __m128i arg2,
    _m128d arg3,
  ) {
    return __mm_mask_permutex2var_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_permutex2var_pdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              _m128d, __mmask8, __m128i, _m128d)>>('_mm_mask_permutex2var_pd');
  late final __mm_mask_permutex2var_pd = __mm_mask_permutex2var_pdPtr
      .asFunction<_m128d Function(_m128d, int, __m128i, _m128d)>();

  _m128d _mm_mask2_permutex2var_pd(
    _m128d arg0,
    __m128i arg1,
    int arg2,
    _m128d arg3,
  ) {
    return __mm_mask2_permutex2var_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask2_permutex2var_pdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              _m128d, __m128i, __mmask8, _m128d)>>('_mm_mask2_permutex2var_pd');
  late final __mm_mask2_permutex2var_pd = __mm_mask2_permutex2var_pdPtr
      .asFunction<_m128d Function(_m128d, __m128i, int, _m128d)>();

  _m128d _mm_maskz_permutex2var_pd(
    int arg0,
    _m128d arg1,
    __m128i arg2,
    _m128d arg3,
  ) {
    return __mm_maskz_permutex2var_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_permutex2var_pdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              __mmask8, _m128d, __m128i, _m128d)>>('_mm_maskz_permutex2var_pd');
  late final __mm_maskz_permutex2var_pd = __mm_maskz_permutex2var_pdPtr
      .asFunction<_m128d Function(int, _m128d, __m128i, _m128d)>();

  _m128d _mm_permutex2var_pd(
    _m128d arg0,
    __m128i arg1,
    _m128d arg2,
  ) {
    return __mm_permutex2var_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_permutex2var_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, __m128i, _m128d)>>(
          '_mm_permutex2var_pd');
  late final __mm_permutex2var_pd = __mm_permutex2var_pdPtr
      .asFunction<_m128d Function(_m128d, __m128i, _m128d)>();

  _m256d _mm256_mask_permutex2var_pd(
    _m256d arg0,
    int arg1,
    __m256i arg2,
    _m256d arg3,
  ) {
    return __mm256_mask_permutex2var_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_permutex2var_pdPtr = _lookup<
      ffi.NativeFunction<
          _m256d Function(_m256d, __mmask8, __m256i,
              _m256d)>>('_mm256_mask_permutex2var_pd');
  late final __mm256_mask_permutex2var_pd = __mm256_mask_permutex2var_pdPtr
      .asFunction<_m256d Function(_m256d, int, __m256i, _m256d)>();

  _m256d _mm256_mask2_permutex2var_pd(
    _m256d arg0,
    __m256i arg1,
    int arg2,
    _m256d arg3,
  ) {
    return __mm256_mask2_permutex2var_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask2_permutex2var_pdPtr = _lookup<
      ffi.NativeFunction<
          _m256d Function(_m256d, __m256i, __mmask8,
              _m256d)>>('_mm256_mask2_permutex2var_pd');
  late final __mm256_mask2_permutex2var_pd = __mm256_mask2_permutex2var_pdPtr
      .asFunction<_m256d Function(_m256d, __m256i, int, _m256d)>();

  _m256d _mm256_maskz_permutex2var_pd(
    int arg0,
    _m256d arg1,
    __m256i arg2,
    _m256d arg3,
  ) {
    return __mm256_maskz_permutex2var_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_maskz_permutex2var_pdPtr = _lookup<
      ffi.NativeFunction<
          _m256d Function(__mmask8, _m256d, __m256i,
              _m256d)>>('_mm256_maskz_permutex2var_pd');
  late final __mm256_maskz_permutex2var_pd = __mm256_maskz_permutex2var_pdPtr
      .asFunction<_m256d Function(int, _m256d, __m256i, _m256d)>();

  _m256d _mm256_permutex2var_pd(
    _m256d arg0,
    __m256i arg1,
    _m256d arg2,
  ) {
    return __mm256_permutex2var_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_permutex2var_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d, __m256i, _m256d)>>(
          '_mm256_permutex2var_pd');
  late final __mm256_permutex2var_pd = __mm256_permutex2var_pdPtr
      .asFunction<_m256d Function(_m256d, __m256i, _m256d)>();

  __m128 _mm_mask_permutex2var_ps(
    __m128 arg0,
    int arg1,
    __m128i arg2,
    __m128 arg3,
  ) {
    return __mm_mask_permutex2var_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_permutex2var_psPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __m128, __mmask8, __m128i, __m128)>>('_mm_mask_permutex2var_ps');
  late final __mm_mask_permutex2var_ps = __mm_mask_permutex2var_psPtr
      .asFunction<__m128 Function(__m128, int, __m128i, __m128)>();

  __m128 _mm_mask2_permutex2var_ps(
    __m128 arg0,
    __m128i arg1,
    int arg2,
    __m128 arg3,
  ) {
    return __mm_mask2_permutex2var_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask2_permutex2var_psPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __m128, __m128i, __mmask8, __m128)>>('_mm_mask2_permutex2var_ps');
  late final __mm_mask2_permutex2var_ps = __mm_mask2_permutex2var_psPtr
      .asFunction<__m128 Function(__m128, __m128i, int, __m128)>();

  __m128 _mm_maskz_permutex2var_ps(
    int arg0,
    __m128 arg1,
    __m128i arg2,
    __m128 arg3,
  ) {
    return __mm_maskz_permutex2var_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_permutex2var_psPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __mmask8, __m128, __m128i, __m128)>>('_mm_maskz_permutex2var_ps');
  late final __mm_maskz_permutex2var_ps = __mm_maskz_permutex2var_psPtr
      .asFunction<__m128 Function(int, __m128, __m128i, __m128)>();

  __m128 _mm_permutex2var_ps(
    __m128 arg0,
    __m128i arg1,
    __m128 arg2,
  ) {
    return __mm_permutex2var_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_permutex2var_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128i, __m128)>>(
          '_mm_permutex2var_ps');
  late final __mm_permutex2var_ps = __mm_permutex2var_psPtr
      .asFunction<__m128 Function(__m128, __m128i, __m128)>();

  __m256 _mm256_mask_permutex2var_ps(
    __m256 arg0,
    int arg1,
    __m256i arg2,
    __m256 arg3,
  ) {
    return __mm256_mask_permutex2var_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_permutex2var_psPtr = _lookup<
      ffi.NativeFunction<
          __m256 Function(__m256, __mmask8, __m256i,
              __m256)>>('_mm256_mask_permutex2var_ps');
  late final __mm256_mask_permutex2var_ps = __mm256_mask_permutex2var_psPtr
      .asFunction<__m256 Function(__m256, int, __m256i, __m256)>();

  __m256 _mm256_mask2_permutex2var_ps(
    __m256 arg0,
    __m256i arg1,
    int arg2,
    __m256 arg3,
  ) {
    return __mm256_mask2_permutex2var_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask2_permutex2var_psPtr = _lookup<
      ffi.NativeFunction<
          __m256 Function(__m256, __m256i, __mmask8,
              __m256)>>('_mm256_mask2_permutex2var_ps');
  late final __mm256_mask2_permutex2var_ps = __mm256_mask2_permutex2var_psPtr
      .asFunction<__m256 Function(__m256, __m256i, int, __m256)>();

  __m256 _mm256_maskz_permutex2var_ps(
    int arg0,
    __m256 arg1,
    __m256i arg2,
    __m256 arg3,
  ) {
    return __mm256_maskz_permutex2var_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_maskz_permutex2var_psPtr = _lookup<
      ffi.NativeFunction<
          __m256 Function(__mmask8, __m256, __m256i,
              __m256)>>('_mm256_maskz_permutex2var_ps');
  late final __mm256_maskz_permutex2var_ps = __mm256_maskz_permutex2var_psPtr
      .asFunction<__m256 Function(int, __m256, __m256i, __m256)>();

  __m256 _mm256_permutex2var_ps(
    __m256 arg0,
    __m256i arg1,
    __m256 arg2,
  ) {
    return __mm256_permutex2var_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_permutex2var_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256, __m256i, __m256)>>(
          '_mm256_permutex2var_ps');
  late final __mm256_permutex2var_ps = __mm256_permutex2var_psPtr
      .asFunction<__m256 Function(__m256, __m256i, __m256)>();

  __m128i _mm_mask_permutexvar_epi16(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_permutexvar_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_permutexvar_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(__m128i, __mmask8, __m128i,
              __m128i)>>('_mm_mask_permutexvar_epi16');
  late final __mm_mask_permutexvar_epi16 = __mm_mask_permutexvar_epi16Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_permutexvar_epi16(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_permutexvar_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_permutexvar_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_maskz_permutexvar_epi16');
  late final __mm_maskz_permutexvar_epi16 = __mm_maskz_permutexvar_epi16Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m128i _mm_permutexvar_epi16(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_permutexvar_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm_permutexvar_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_permutexvar_epi16');
  late final __mm_permutexvar_epi16 = __mm_permutexvar_epi16Ptr
      .asFunction<__m128i Function(__m128i, __m128i)>();

  __m256i _mm256_mask_permutexvar_epi16(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_permutexvar_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_permutexvar_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask16, __m256i,
              __m256i)>>('_mm256_mask_permutexvar_epi16');
  late final __mm256_mask_permutexvar_epi16 = __mm256_mask_permutexvar_epi16Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_permutexvar_epi16(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_permutexvar_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_permutexvar_epi16Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__mmask16, __m256i, __m256i)>>(
      '_mm256_maskz_permutexvar_epi16');
  late final __mm256_maskz_permutexvar_epi16 =
      __mm256_maskz_permutexvar_epi16Ptr
          .asFunction<__m256i Function(int, __m256i, __m256i)>();

  __m256i _mm256_permutexvar_epi16(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_permutexvar_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm256_permutexvar_epi16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_permutexvar_epi16');
  late final __mm256_permutexvar_epi16 = __mm256_permutexvar_epi16Ptr
      .asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_mask_permutexvar_epi32(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_permutexvar_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_permutexvar_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask8, __m256i,
              __m256i)>>('_mm256_mask_permutexvar_epi32');
  late final __mm256_mask_permutexvar_epi32 = __mm256_mask_permutexvar_epi32Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_permutexvar_epi32(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_permutexvar_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_permutexvar_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m256i, __m256i)>>(
          '_mm256_maskz_permutexvar_epi32');
  late final __mm256_maskz_permutexvar_epi32 =
      __mm256_maskz_permutexvar_epi32Ptr
          .asFunction<__m256i Function(int, __m256i, __m256i)>();

  __m256i _mm256_permutexvar_epi32(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_permutexvar_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm256_permutexvar_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_permutexvar_epi32');
  late final __mm256_permutexvar_epi32 = __mm256_permutexvar_epi32Ptr
      .asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_mask_permutexvar_epi64(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_permutexvar_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_permutexvar_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask8, __m256i,
              __m256i)>>('_mm256_mask_permutexvar_epi64');
  late final __mm256_mask_permutexvar_epi64 = __mm256_mask_permutexvar_epi64Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_permutexvar_epi64(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_permutexvar_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_permutexvar_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m256i, __m256i)>>(
          '_mm256_maskz_permutexvar_epi64');
  late final __mm256_maskz_permutexvar_epi64 =
      __mm256_maskz_permutexvar_epi64Ptr
          .asFunction<__m256i Function(int, __m256i, __m256i)>();

  __m256i _mm256_permutexvar_epi64(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_permutexvar_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm256_permutexvar_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_permutexvar_epi64');
  late final __mm256_permutexvar_epi64 = __mm256_permutexvar_epi64Ptr
      .asFunction<__m256i Function(__m256i, __m256i)>();

  _m256d _mm256_mask_permutexvar_pd(
    _m256d arg0,
    int arg1,
    __m256i arg2,
    _m256d arg3,
  ) {
    return __mm256_mask_permutexvar_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_permutexvar_pdPtr = _lookup<
      ffi.NativeFunction<
          _m256d Function(_m256d, __mmask8, __m256i,
              _m256d)>>('_mm256_mask_permutexvar_pd');
  late final __mm256_mask_permutexvar_pd = __mm256_mask_permutexvar_pdPtr
      .asFunction<_m256d Function(_m256d, int, __m256i, _m256d)>();

  _m256d _mm256_maskz_permutexvar_pd(
    int arg0,
    __m256i arg1,
    _m256d arg2,
  ) {
    return __mm256_maskz_permutexvar_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_permutexvar_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(__mmask8, __m256i, _m256d)>>(
          '_mm256_maskz_permutexvar_pd');
  late final __mm256_maskz_permutexvar_pd = __mm256_maskz_permutexvar_pdPtr
      .asFunction<_m256d Function(int, __m256i, _m256d)>();

  _m256d _mm256_permutexvar_pd(
    __m256i arg0,
    _m256d arg1,
  ) {
    return __mm256_permutexvar_pd(
      arg0,
      arg1,
    );
  }

  late final __mm256_permutexvar_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(__m256i, _m256d)>>(
          '_mm256_permutexvar_pd');
  late final __mm256_permutexvar_pd =
      __mm256_permutexvar_pdPtr.asFunction<_m256d Function(__m256i, _m256d)>();

  __m256 _mm256_mask_permutexvar_ps(
    __m256 arg0,
    int arg1,
    __m256i arg2,
    __m256 arg3,
  ) {
    return __mm256_mask_permutexvar_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_permutexvar_psPtr = _lookup<
      ffi.NativeFunction<
          __m256 Function(__m256, __mmask8, __m256i,
              __m256)>>('_mm256_mask_permutexvar_ps');
  late final __mm256_mask_permutexvar_ps = __mm256_mask_permutexvar_psPtr
      .asFunction<__m256 Function(__m256, int, __m256i, __m256)>();

  __m256 _mm256_maskz_permutexvar_ps(
    int arg0,
    __m256i arg1,
    __m256 arg2,
  ) {
    return __mm256_maskz_permutexvar_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_permutexvar_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__mmask8, __m256i, __m256)>>(
          '_mm256_maskz_permutexvar_ps');
  late final __mm256_maskz_permutexvar_ps = __mm256_maskz_permutexvar_psPtr
      .asFunction<__m256 Function(int, __m256i, __m256)>();

  __m256 _mm256_permutexvar_ps(
    __m256i arg0,
    __m256 arg1,
  ) {
    return __mm256_permutexvar_ps(
      arg0,
      arg1,
    );
  }

  late final __mm256_permutexvar_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256i, __m256)>>(
          '_mm256_permutexvar_ps');
  late final __mm256_permutexvar_ps =
      __mm256_permutexvar_psPtr.asFunction<__m256 Function(__m256i, __m256)>();

  _m128d _mm_mask_range_pd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    _m128d arg3,
    int arg4,
  ) {
    return __mm_mask_range_pd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_range_pdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(_m128d, __mmask8, _m128d, _m128d,
              ffi.Int32)>>('_mm_mask_range_pd');
  late final __mm_mask_range_pd = __mm_mask_range_pdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d, _m128d, int)>();

  _m128d _mm_maskz_range_pd(
    int arg0,
    _m128d arg1,
    _m128d arg2,
    int arg3,
  ) {
    return __mm_maskz_range_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_range_pdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              __mmask8, _m128d, _m128d, ffi.Int32)>>('_mm_maskz_range_pd');
  late final __mm_maskz_range_pd = __mm_maskz_range_pdPtr
      .asFunction<_m128d Function(int, _m128d, _m128d, int)>();

  _m128d _mm_range_pd(
    _m128d arg0,
    _m128d arg1,
    int arg2,
  ) {
    return __mm_range_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_range_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d, ffi.Int32)>>(
          '_mm_range_pd');
  late final __mm_range_pd =
      __mm_range_pdPtr.asFunction<_m128d Function(_m128d, _m128d, int)>();

  _m256d _mm256_mask_range_pd(
    _m256d arg0,
    int arg1,
    _m256d arg2,
    _m256d arg3,
    int arg4,
  ) {
    return __mm256_mask_range_pd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm256_mask_range_pdPtr = _lookup<
      ffi.NativeFunction<
          _m256d Function(_m256d, __mmask8, _m256d, _m256d,
              ffi.Int32)>>('_mm256_mask_range_pd');
  late final __mm256_mask_range_pd = __mm256_mask_range_pdPtr
      .asFunction<_m256d Function(_m256d, int, _m256d, _m256d, int)>();

  _m256d _mm256_maskz_range_pd(
    int arg0,
    _m256d arg1,
    _m256d arg2,
    int arg3,
  ) {
    return __mm256_maskz_range_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_maskz_range_pdPtr = _lookup<
      ffi.NativeFunction<
          _m256d Function(
              __mmask8, _m256d, _m256d, ffi.Int32)>>('_mm256_maskz_range_pd');
  late final __mm256_maskz_range_pd = __mm256_maskz_range_pdPtr
      .asFunction<_m256d Function(int, _m256d, _m256d, int)>();

  _m256d _mm256_range_pd(
    _m256d arg0,
    _m256d arg1,
    int arg2,
  ) {
    return __mm256_range_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_range_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d, _m256d, ffi.Int32)>>(
          '_mm256_range_pd');
  late final __mm256_range_pd =
      __mm256_range_pdPtr.asFunction<_m256d Function(_m256d, _m256d, int)>();

  __m128 _mm_mask_range_ps(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    __m128 arg3,
    int arg4,
  ) {
    return __mm_mask_range_ps(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_range_psPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(__m128, __mmask8, __m128, __m128,
              ffi.Int32)>>('_mm_mask_range_ps');
  late final __mm_mask_range_ps = __mm_mask_range_psPtr
      .asFunction<__m128 Function(__m128, int, __m128, __m128, int)>();

  __m128 _mm_maskz_range_ps(
    int arg0,
    __m128 arg1,
    __m128 arg2,
    int arg3,
  ) {
    return __mm_maskz_range_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_range_psPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __mmask8, __m128, __m128, ffi.Int32)>>('_mm_maskz_range_ps');
  late final __mm_maskz_range_ps = __mm_maskz_range_psPtr
      .asFunction<__m128 Function(int, __m128, __m128, int)>();

  __m128 _mm_range_ps(
    __m128 arg0,
    __m128 arg1,
    int arg2,
  ) {
    return __mm_range_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_range_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128, ffi.Int32)>>(
          '_mm_range_ps');
  late final __mm_range_ps =
      __mm_range_psPtr.asFunction<__m128 Function(__m128, __m128, int)>();

  __m256 _mm256_mask_range_ps(
    __m256 arg0,
    int arg1,
    __m256 arg2,
    __m256 arg3,
    int arg4,
  ) {
    return __mm256_mask_range_ps(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm256_mask_range_psPtr = _lookup<
      ffi.NativeFunction<
          __m256 Function(__m256, __mmask8, __m256, __m256,
              ffi.Int32)>>('_mm256_mask_range_ps');
  late final __mm256_mask_range_ps = __mm256_mask_range_psPtr
      .asFunction<__m256 Function(__m256, int, __m256, __m256, int)>();

  __m256 _mm256_maskz_range_ps(
    int arg0,
    __m256 arg1,
    __m256 arg2,
    int arg3,
  ) {
    return __mm256_maskz_range_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_maskz_range_psPtr = _lookup<
      ffi.NativeFunction<
          __m256 Function(
              __mmask8, __m256, __m256, ffi.Int32)>>('_mm256_maskz_range_ps');
  late final __mm256_maskz_range_ps = __mm256_maskz_range_psPtr
      .asFunction<__m256 Function(int, __m256, __m256, int)>();

  __m256 _mm256_range_ps(
    __m256 arg0,
    __m256 arg1,
    int arg2,
  ) {
    return __mm256_range_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_range_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256, __m256, ffi.Int32)>>(
          '_mm256_range_ps');
  late final __mm256_range_ps =
      __mm256_range_psPtr.asFunction<__m256 Function(__m256, __m256, int)>();

  _m128d _mm_mask_rcp14_pd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
  ) {
    return __mm_mask_rcp14_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_rcp14_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, __mmask8, _m128d)>>(
          '_mm_mask_rcp14_pd');
  late final __mm_mask_rcp14_pd =
      __mm_mask_rcp14_pdPtr.asFunction<_m128d Function(_m128d, int, _m128d)>();

  _m128d _mm_maskz_rcp14_pd(
    int arg0,
    _m128d arg1,
  ) {
    return __mm_maskz_rcp14_pd(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_rcp14_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(__mmask8, _m128d)>>(
          '_mm_maskz_rcp14_pd');
  late final __mm_maskz_rcp14_pd =
      __mm_maskz_rcp14_pdPtr.asFunction<_m128d Function(int, _m128d)>();

  _m128d _mm_rcp14_pd(
    _m128d arg0,
  ) {
    return __mm_rcp14_pd(
      arg0,
    );
  }

  late final __mm_rcp14_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d)>>('_mm_rcp14_pd');
  late final __mm_rcp14_pd =
      __mm_rcp14_pdPtr.asFunction<_m128d Function(_m128d)>();

  _m256d _mm256_mask_rcp14_pd(
    _m256d arg0,
    int arg1,
    _m256d arg2,
  ) {
    return __mm256_mask_rcp14_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_rcp14_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d, __mmask8, _m256d)>>(
          '_mm256_mask_rcp14_pd');
  late final __mm256_mask_rcp14_pd = __mm256_mask_rcp14_pdPtr
      .asFunction<_m256d Function(_m256d, int, _m256d)>();

  _m256d _mm256_maskz_rcp14_pd(
    int arg0,
    _m256d arg1,
  ) {
    return __mm256_maskz_rcp14_pd(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_rcp14_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(__mmask8, _m256d)>>(
          '_mm256_maskz_rcp14_pd');
  late final __mm256_maskz_rcp14_pd =
      __mm256_maskz_rcp14_pdPtr.asFunction<_m256d Function(int, _m256d)>();

  _m256d _mm256_rcp14_pd(
    _m256d arg0,
  ) {
    return __mm256_rcp14_pd(
      arg0,
    );
  }

  late final __mm256_rcp14_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d)>>('_mm256_rcp14_pd');
  late final __mm256_rcp14_pd =
      __mm256_rcp14_pdPtr.asFunction<_m256d Function(_m256d)>();

  __m128 _mm_mask_rcp14_ps(
    __m128 arg0,
    int arg1,
    __m128 arg2,
  ) {
    return __mm_mask_rcp14_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_rcp14_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __mmask8, __m128)>>(
          '_mm_mask_rcp14_ps');
  late final __mm_mask_rcp14_ps =
      __mm_mask_rcp14_psPtr.asFunction<__m128 Function(__m128, int, __m128)>();

  __m128 _mm_maskz_rcp14_ps(
    int arg0,
    __m128 arg1,
  ) {
    return __mm_maskz_rcp14_ps(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_rcp14_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__mmask8, __m128)>>(
          '_mm_maskz_rcp14_ps');
  late final __mm_maskz_rcp14_ps =
      __mm_maskz_rcp14_psPtr.asFunction<__m128 Function(int, __m128)>();

  __m128 _mm_rcp14_ps(
    __m128 arg0,
  ) {
    return __mm_rcp14_ps(
      arg0,
    );
  }

  late final __mm_rcp14_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128)>>('_mm_rcp14_ps');
  late final __mm_rcp14_ps =
      __mm_rcp14_psPtr.asFunction<__m128 Function(__m128)>();

  __m256 _mm256_mask_rcp14_ps(
    __m256 arg0,
    int arg1,
    __m256 arg2,
  ) {
    return __mm256_mask_rcp14_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_rcp14_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256, __mmask8, __m256)>>(
          '_mm256_mask_rcp14_ps');
  late final __mm256_mask_rcp14_ps = __mm256_mask_rcp14_psPtr
      .asFunction<__m256 Function(__m256, int, __m256)>();

  __m256 _mm256_maskz_rcp14_ps(
    int arg0,
    __m256 arg1,
  ) {
    return __mm256_maskz_rcp14_ps(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_rcp14_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__mmask8, __m256)>>(
          '_mm256_maskz_rcp14_ps');
  late final __mm256_maskz_rcp14_ps =
      __mm256_maskz_rcp14_psPtr.asFunction<__m256 Function(int, __m256)>();

  __m256 _mm256_rcp14_ps(
    __m256 arg0,
  ) {
    return __mm256_rcp14_ps(
      arg0,
    );
  }

  late final __mm256_rcp14_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256)>>('_mm256_rcp14_ps');
  late final __mm256_rcp14_ps =
      __mm256_rcp14_psPtr.asFunction<__m256 Function(__m256)>();

  _m128d _mm_mask_reduce_pd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    int arg3,
  ) {
    return __mm_mask_reduce_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_reduce_pdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              _m128d, __mmask8, _m128d, ffi.Int32)>>('_mm_mask_reduce_pd');
  late final __mm_mask_reduce_pd = __mm_mask_reduce_pdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d, int)>();

  _m128d _mm_maskz_reduce_pd(
    int arg0,
    _m128d arg1,
    int arg2,
  ) {
    return __mm_maskz_reduce_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_reduce_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(__mmask8, _m128d, ffi.Int32)>>(
          '_mm_maskz_reduce_pd');
  late final __mm_maskz_reduce_pd =
      __mm_maskz_reduce_pdPtr.asFunction<_m128d Function(int, _m128d, int)>();

  _m128d _mm_reduce_pd(
    _m128d arg0,
    int arg1,
  ) {
    return __mm_reduce_pd(
      arg0,
      arg1,
    );
  }

  late final __mm_reduce_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, ffi.Int32)>>(
          '_mm_reduce_pd');
  late final __mm_reduce_pd =
      __mm_reduce_pdPtr.asFunction<_m128d Function(_m128d, int)>();

  _m256d _mm256_mask_reduce_pd(
    _m256d arg0,
    int arg1,
    _m256d arg2,
    int arg3,
  ) {
    return __mm256_mask_reduce_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_reduce_pdPtr = _lookup<
      ffi.NativeFunction<
          _m256d Function(
              _m256d, __mmask8, _m256d, ffi.Int32)>>('_mm256_mask_reduce_pd');
  late final __mm256_mask_reduce_pd = __mm256_mask_reduce_pdPtr
      .asFunction<_m256d Function(_m256d, int, _m256d, int)>();

  _m256d _mm256_maskz_reduce_pd(
    int arg0,
    _m256d arg1,
    int arg2,
  ) {
    return __mm256_maskz_reduce_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_reduce_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(__mmask8, _m256d, ffi.Int32)>>(
          '_mm256_maskz_reduce_pd');
  late final __mm256_maskz_reduce_pd = __mm256_maskz_reduce_pdPtr
      .asFunction<_m256d Function(int, _m256d, int)>();

  _m256d _mm256_reduce_pd(
    _m256d arg0,
    int arg1,
  ) {
    return __mm256_reduce_pd(
      arg0,
      arg1,
    );
  }

  late final __mm256_reduce_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d, ffi.Int32)>>(
          '_mm256_reduce_pd');
  late final __mm256_reduce_pd =
      __mm256_reduce_pdPtr.asFunction<_m256d Function(_m256d, int)>();

  __m128 _mm_mask_reduce_ps(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    int arg3,
  ) {
    return __mm_mask_reduce_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_reduce_psPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __m128, __mmask8, __m128, ffi.Int32)>>('_mm_mask_reduce_ps');
  late final __mm_mask_reduce_ps = __mm_mask_reduce_psPtr
      .asFunction<__m128 Function(__m128, int, __m128, int)>();

  __m128 _mm_maskz_reduce_ps(
    int arg0,
    __m128 arg1,
    int arg2,
  ) {
    return __mm_maskz_reduce_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_reduce_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__mmask8, __m128, ffi.Int32)>>(
          '_mm_maskz_reduce_ps');
  late final __mm_maskz_reduce_ps =
      __mm_maskz_reduce_psPtr.asFunction<__m128 Function(int, __m128, int)>();

  __m128 _mm_reduce_ps(
    __m128 arg0,
    int arg1,
  ) {
    return __mm_reduce_ps(
      arg0,
      arg1,
    );
  }

  late final __mm_reduce_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, ffi.Int32)>>(
          '_mm_reduce_ps');
  late final __mm_reduce_ps =
      __mm_reduce_psPtr.asFunction<__m128 Function(__m128, int)>();

  __m256 _mm256_mask_reduce_ps(
    __m256 arg0,
    int arg1,
    __m256 arg2,
    int arg3,
  ) {
    return __mm256_mask_reduce_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_reduce_psPtr = _lookup<
      ffi.NativeFunction<
          __m256 Function(
              __m256, __mmask8, __m256, ffi.Int32)>>('_mm256_mask_reduce_ps');
  late final __mm256_mask_reduce_ps = __mm256_mask_reduce_psPtr
      .asFunction<__m256 Function(__m256, int, __m256, int)>();

  __m256 _mm256_maskz_reduce_ps(
    int arg0,
    __m256 arg1,
    int arg2,
  ) {
    return __mm256_maskz_reduce_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_reduce_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__mmask8, __m256, ffi.Int32)>>(
          '_mm256_maskz_reduce_ps');
  late final __mm256_maskz_reduce_ps = __mm256_maskz_reduce_psPtr
      .asFunction<__m256 Function(int, __m256, int)>();

  __m256 _mm256_reduce_ps(
    __m256 arg0,
    int arg1,
  ) {
    return __mm256_reduce_ps(
      arg0,
      arg1,
    );
  }

  late final __mm256_reduce_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256, ffi.Int32)>>(
          '_mm256_reduce_ps');
  late final __mm256_reduce_ps =
      __mm256_reduce_psPtr.asFunction<__m256 Function(__m256, int)>();

  __m128i _mm_mask_rol_epi32(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    int arg3,
  ) {
    return __mm_mask_rol_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_rol_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, ffi.Int32)>>('_mm_mask_rol_epi32');
  late final __mm_mask_rol_epi32 = __mm_mask_rol_epi32Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, int)>();

  __m128i _mm_maskz_rol_epi32(
    int arg0,
    __m128i arg1,
    int arg2,
  ) {
    return __mm_maskz_rol_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_rol_epi32Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__mmask8, __m128i, ffi.Int32)>>(
      '_mm_maskz_rol_epi32');
  late final __mm_maskz_rol_epi32 =
      __mm_maskz_rol_epi32Ptr.asFunction<__m128i Function(int, __m128i, int)>();

  __m128i _mm_rol_epi32(
    __m128i arg0,
    int arg1,
  ) {
    return __mm_rol_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm_rol_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, ffi.Int32)>>(
          '_mm_rol_epi32');
  late final __mm_rol_epi32 =
      __mm_rol_epi32Ptr.asFunction<__m128i Function(__m128i, int)>();

  __m256i _mm256_mask_rol_epi32(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    int arg3,
  ) {
    return __mm256_mask_rol_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_rol_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask8, __m256i, ffi.Int32)>>('_mm256_mask_rol_epi32');
  late final __mm256_mask_rol_epi32 = __mm256_mask_rol_epi32Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, int)>();

  __m256i _mm256_maskz_rol_epi32(
    int arg0,
    __m256i arg1,
    int arg2,
  ) {
    return __mm256_maskz_rol_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_rol_epi32Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__mmask8, __m256i, ffi.Int32)>>(
      '_mm256_maskz_rol_epi32');
  late final __mm256_maskz_rol_epi32 = __mm256_maskz_rol_epi32Ptr
      .asFunction<__m256i Function(int, __m256i, int)>();

  __m256i _mm256_rol_epi32(
    __m256i arg0,
    int arg1,
  ) {
    return __mm256_rol_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm256_rol_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, ffi.Int32)>>(
          '_mm256_rol_epi32');
  late final __mm256_rol_epi32 =
      __mm256_rol_epi32Ptr.asFunction<__m256i Function(__m256i, int)>();

  __m128i _mm_mask_rol_epi64(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    int arg3,
  ) {
    return __mm_mask_rol_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_rol_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, ffi.Int32)>>('_mm_mask_rol_epi64');
  late final __mm_mask_rol_epi64 = __mm_mask_rol_epi64Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, int)>();

  __m128i _mm_maskz_rol_epi64(
    int arg0,
    __m128i arg1,
    int arg2,
  ) {
    return __mm_maskz_rol_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_rol_epi64Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__mmask8, __m128i, ffi.Int32)>>(
      '_mm_maskz_rol_epi64');
  late final __mm_maskz_rol_epi64 =
      __mm_maskz_rol_epi64Ptr.asFunction<__m128i Function(int, __m128i, int)>();

  __m128i _mm_rol_epi64(
    __m128i arg0,
    int arg1,
  ) {
    return __mm_rol_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm_rol_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, ffi.Int32)>>(
          '_mm_rol_epi64');
  late final __mm_rol_epi64 =
      __mm_rol_epi64Ptr.asFunction<__m128i Function(__m128i, int)>();

  __m256i _mm256_mask_rol_epi64(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    int arg3,
  ) {
    return __mm256_mask_rol_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_rol_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask8, __m256i, ffi.Int32)>>('_mm256_mask_rol_epi64');
  late final __mm256_mask_rol_epi64 = __mm256_mask_rol_epi64Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, int)>();

  __m256i _mm256_maskz_rol_epi64(
    int arg0,
    __m256i arg1,
    int arg2,
  ) {
    return __mm256_maskz_rol_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_rol_epi64Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__mmask8, __m256i, ffi.Int32)>>(
      '_mm256_maskz_rol_epi64');
  late final __mm256_maskz_rol_epi64 = __mm256_maskz_rol_epi64Ptr
      .asFunction<__m256i Function(int, __m256i, int)>();

  __m256i _mm256_rol_epi64(
    __m256i arg0,
    int arg1,
  ) {
    return __mm256_rol_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm256_rol_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, ffi.Int32)>>(
          '_mm256_rol_epi64');
  late final __mm256_rol_epi64 =
      __mm256_rol_epi64Ptr.asFunction<__m256i Function(__m256i, int)>();

  __m128i _mm_mask_rolv_epi32(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_rolv_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_rolv_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_rolv_epi32');
  late final __mm_mask_rolv_epi32 = __mm_mask_rolv_epi32Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_rolv_epi32(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_rolv_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_rolv_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_maskz_rolv_epi32');
  late final __mm_maskz_rolv_epi32 = __mm_maskz_rolv_epi32Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m128i _mm_rolv_epi32(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_rolv_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm_rolv_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_rolv_epi32');
  late final __mm_rolv_epi32 =
      __mm_rolv_epi32Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m256i _mm256_mask_rolv_epi32(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_rolv_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_rolv_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask8, __m256i, __m256i)>>('_mm256_mask_rolv_epi32');
  late final __mm256_mask_rolv_epi32 = __mm256_mask_rolv_epi32Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_rolv_epi32(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_rolv_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_rolv_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m256i, __m256i)>>(
          '_mm256_maskz_rolv_epi32');
  late final __mm256_maskz_rolv_epi32 = __mm256_maskz_rolv_epi32Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  __m256i _mm256_rolv_epi32(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_rolv_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm256_rolv_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_rolv_epi32');
  late final __mm256_rolv_epi32 =
      __mm256_rolv_epi32Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m128i _mm_mask_rolv_epi64(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_rolv_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_rolv_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_rolv_epi64');
  late final __mm_mask_rolv_epi64 = __mm_mask_rolv_epi64Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_rolv_epi64(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_rolv_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_rolv_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_maskz_rolv_epi64');
  late final __mm_maskz_rolv_epi64 = __mm_maskz_rolv_epi64Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m128i _mm_rolv_epi64(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_rolv_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm_rolv_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_rolv_epi64');
  late final __mm_rolv_epi64 =
      __mm_rolv_epi64Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m256i _mm256_mask_rolv_epi64(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_rolv_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_rolv_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask8, __m256i, __m256i)>>('_mm256_mask_rolv_epi64');
  late final __mm256_mask_rolv_epi64 = __mm256_mask_rolv_epi64Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_rolv_epi64(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_rolv_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_rolv_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m256i, __m256i)>>(
          '_mm256_maskz_rolv_epi64');
  late final __mm256_maskz_rolv_epi64 = __mm256_maskz_rolv_epi64Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  __m256i _mm256_rolv_epi64(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_rolv_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm256_rolv_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_rolv_epi64');
  late final __mm256_rolv_epi64 =
      __mm256_rolv_epi64Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m128i _mm_mask_ror_epi32(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    int arg3,
  ) {
    return __mm_mask_ror_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_ror_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, ffi.Int32)>>('_mm_mask_ror_epi32');
  late final __mm_mask_ror_epi32 = __mm_mask_ror_epi32Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, int)>();

  __m128i _mm_maskz_ror_epi32(
    int arg0,
    __m128i arg1,
    int arg2,
  ) {
    return __mm_maskz_ror_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_ror_epi32Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__mmask8, __m128i, ffi.Int32)>>(
      '_mm_maskz_ror_epi32');
  late final __mm_maskz_ror_epi32 =
      __mm_maskz_ror_epi32Ptr.asFunction<__m128i Function(int, __m128i, int)>();

  __m128i _mm_ror_epi32(
    __m128i arg0,
    int arg1,
  ) {
    return __mm_ror_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm_ror_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, ffi.Int32)>>(
          '_mm_ror_epi32');
  late final __mm_ror_epi32 =
      __mm_ror_epi32Ptr.asFunction<__m128i Function(__m128i, int)>();

  __m256i _mm256_mask_ror_epi32(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    int arg3,
  ) {
    return __mm256_mask_ror_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_ror_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask8, __m256i, ffi.Int32)>>('_mm256_mask_ror_epi32');
  late final __mm256_mask_ror_epi32 = __mm256_mask_ror_epi32Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, int)>();

  __m256i _mm256_maskz_ror_epi32(
    int arg0,
    __m256i arg1,
    int arg2,
  ) {
    return __mm256_maskz_ror_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_ror_epi32Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__mmask8, __m256i, ffi.Int32)>>(
      '_mm256_maskz_ror_epi32');
  late final __mm256_maskz_ror_epi32 = __mm256_maskz_ror_epi32Ptr
      .asFunction<__m256i Function(int, __m256i, int)>();

  __m256i _mm256_ror_epi32(
    __m256i arg0,
    int arg1,
  ) {
    return __mm256_ror_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm256_ror_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, ffi.Int32)>>(
          '_mm256_ror_epi32');
  late final __mm256_ror_epi32 =
      __mm256_ror_epi32Ptr.asFunction<__m256i Function(__m256i, int)>();

  __m128i _mm_mask_ror_epi64(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    int arg3,
  ) {
    return __mm_mask_ror_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_ror_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, ffi.Int32)>>('_mm_mask_ror_epi64');
  late final __mm_mask_ror_epi64 = __mm_mask_ror_epi64Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, int)>();

  __m128i _mm_maskz_ror_epi64(
    int arg0,
    __m128i arg1,
    int arg2,
  ) {
    return __mm_maskz_ror_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_ror_epi64Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__mmask8, __m128i, ffi.Int32)>>(
      '_mm_maskz_ror_epi64');
  late final __mm_maskz_ror_epi64 =
      __mm_maskz_ror_epi64Ptr.asFunction<__m128i Function(int, __m128i, int)>();

  __m128i _mm_ror_epi64(
    __m128i arg0,
    int arg1,
  ) {
    return __mm_ror_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm_ror_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, ffi.Int32)>>(
          '_mm_ror_epi64');
  late final __mm_ror_epi64 =
      __mm_ror_epi64Ptr.asFunction<__m128i Function(__m128i, int)>();

  __m256i _mm256_mask_ror_epi64(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    int arg3,
  ) {
    return __mm256_mask_ror_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_ror_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask8, __m256i, ffi.Int32)>>('_mm256_mask_ror_epi64');
  late final __mm256_mask_ror_epi64 = __mm256_mask_ror_epi64Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, int)>();

  __m256i _mm256_maskz_ror_epi64(
    int arg0,
    __m256i arg1,
    int arg2,
  ) {
    return __mm256_maskz_ror_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_ror_epi64Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__mmask8, __m256i, ffi.Int32)>>(
      '_mm256_maskz_ror_epi64');
  late final __mm256_maskz_ror_epi64 = __mm256_maskz_ror_epi64Ptr
      .asFunction<__m256i Function(int, __m256i, int)>();

  __m256i _mm256_ror_epi64(
    __m256i arg0,
    int arg1,
  ) {
    return __mm256_ror_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm256_ror_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, ffi.Int32)>>(
          '_mm256_ror_epi64');
  late final __mm256_ror_epi64 =
      __mm256_ror_epi64Ptr.asFunction<__m256i Function(__m256i, int)>();

  __m128i _mm_mask_rorv_epi32(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_rorv_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_rorv_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_rorv_epi32');
  late final __mm_mask_rorv_epi32 = __mm_mask_rorv_epi32Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_rorv_epi32(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_rorv_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_rorv_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_maskz_rorv_epi32');
  late final __mm_maskz_rorv_epi32 = __mm_maskz_rorv_epi32Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m128i _mm_rorv_epi32(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_rorv_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm_rorv_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_rorv_epi32');
  late final __mm_rorv_epi32 =
      __mm_rorv_epi32Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m256i _mm256_mask_rorv_epi32(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_rorv_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_rorv_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask8, __m256i, __m256i)>>('_mm256_mask_rorv_epi32');
  late final __mm256_mask_rorv_epi32 = __mm256_mask_rorv_epi32Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_rorv_epi32(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_rorv_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_rorv_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m256i, __m256i)>>(
          '_mm256_maskz_rorv_epi32');
  late final __mm256_maskz_rorv_epi32 = __mm256_maskz_rorv_epi32Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  __m256i _mm256_rorv_epi32(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_rorv_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm256_rorv_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_rorv_epi32');
  late final __mm256_rorv_epi32 =
      __mm256_rorv_epi32Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m128i _mm_mask_rorv_epi64(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_rorv_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_rorv_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_rorv_epi64');
  late final __mm_mask_rorv_epi64 = __mm_mask_rorv_epi64Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_rorv_epi64(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_rorv_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_rorv_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_maskz_rorv_epi64');
  late final __mm_maskz_rorv_epi64 = __mm_maskz_rorv_epi64Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m128i _mm_rorv_epi64(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_rorv_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm_rorv_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_rorv_epi64');
  late final __mm_rorv_epi64 =
      __mm_rorv_epi64Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m256i _mm256_mask_rorv_epi64(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_rorv_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_rorv_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask8, __m256i, __m256i)>>('_mm256_mask_rorv_epi64');
  late final __mm256_mask_rorv_epi64 = __mm256_mask_rorv_epi64Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_rorv_epi64(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_rorv_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_rorv_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m256i, __m256i)>>(
          '_mm256_maskz_rorv_epi64');
  late final __mm256_maskz_rorv_epi64 = __mm256_maskz_rorv_epi64Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  __m256i _mm256_rorv_epi64(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_rorv_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm256_rorv_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_rorv_epi64');
  late final __mm256_rorv_epi64 =
      __mm256_rorv_epi64Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  _m128d _mm_mask_roundscale_pd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    int arg3,
  ) {
    return __mm_mask_roundscale_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_roundscale_pdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              _m128d, __mmask8, _m128d, ffi.Int32)>>('_mm_mask_roundscale_pd');
  late final __mm_mask_roundscale_pd = __mm_mask_roundscale_pdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d, int)>();

  _m128d _mm_maskz_roundscale_pd(
    int arg0,
    _m128d arg1,
    int arg2,
  ) {
    return __mm_maskz_roundscale_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_roundscale_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(__mmask8, _m128d, ffi.Int32)>>(
          '_mm_maskz_roundscale_pd');
  late final __mm_maskz_roundscale_pd = __mm_maskz_roundscale_pdPtr
      .asFunction<_m128d Function(int, _m128d, int)>();

  _m128d _mm_roundscale_pd(
    _m128d arg0,
    int arg1,
  ) {
    return __mm_roundscale_pd(
      arg0,
      arg1,
    );
  }

  late final __mm_roundscale_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, ffi.Int32)>>(
          '_mm_roundscale_pd');
  late final __mm_roundscale_pd =
      __mm_roundscale_pdPtr.asFunction<_m128d Function(_m128d, int)>();

  _m256d _mm256_mask_roundscale_pd(
    _m256d arg0,
    int arg1,
    _m256d arg2,
    int arg3,
  ) {
    return __mm256_mask_roundscale_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_roundscale_pdPtr = _lookup<
      ffi.NativeFunction<
          _m256d Function(_m256d, __mmask8, _m256d,
              ffi.Int32)>>('_mm256_mask_roundscale_pd');
  late final __mm256_mask_roundscale_pd = __mm256_mask_roundscale_pdPtr
      .asFunction<_m256d Function(_m256d, int, _m256d, int)>();

  _m256d _mm256_maskz_roundscale_pd(
    int arg0,
    _m256d arg1,
    int arg2,
  ) {
    return __mm256_maskz_roundscale_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_roundscale_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(__mmask8, _m256d, ffi.Int32)>>(
          '_mm256_maskz_roundscale_pd');
  late final __mm256_maskz_roundscale_pd = __mm256_maskz_roundscale_pdPtr
      .asFunction<_m256d Function(int, _m256d, int)>();

  _m256d _mm256_roundscale_pd(
    _m256d arg0,
    int arg1,
  ) {
    return __mm256_roundscale_pd(
      arg0,
      arg1,
    );
  }

  late final __mm256_roundscale_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d, ffi.Int32)>>(
          '_mm256_roundscale_pd');
  late final __mm256_roundscale_pd =
      __mm256_roundscale_pdPtr.asFunction<_m256d Function(_m256d, int)>();

  __m128 _mm_mask_roundscale_ps(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    int arg3,
  ) {
    return __mm_mask_roundscale_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_roundscale_psPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __m128, __mmask8, __m128, ffi.Int32)>>('_mm_mask_roundscale_ps');
  late final __mm_mask_roundscale_ps = __mm_mask_roundscale_psPtr
      .asFunction<__m128 Function(__m128, int, __m128, int)>();

  __m128 _mm_maskz_roundscale_ps(
    int arg0,
    __m128 arg1,
    int arg2,
  ) {
    return __mm_maskz_roundscale_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_roundscale_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__mmask8, __m128, ffi.Int32)>>(
          '_mm_maskz_roundscale_ps');
  late final __mm_maskz_roundscale_ps = __mm_maskz_roundscale_psPtr
      .asFunction<__m128 Function(int, __m128, int)>();

  __m128 _mm_roundscale_ps(
    __m128 arg0,
    int arg1,
  ) {
    return __mm_roundscale_ps(
      arg0,
      arg1,
    );
  }

  late final __mm_roundscale_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, ffi.Int32)>>(
          '_mm_roundscale_ps');
  late final __mm_roundscale_ps =
      __mm_roundscale_psPtr.asFunction<__m128 Function(__m128, int)>();

  __m256 _mm256_mask_roundscale_ps(
    __m256 arg0,
    int arg1,
    __m256 arg2,
    int arg3,
  ) {
    return __mm256_mask_roundscale_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_roundscale_psPtr = _lookup<
      ffi.NativeFunction<
          __m256 Function(__m256, __mmask8, __m256,
              ffi.Int32)>>('_mm256_mask_roundscale_ps');
  late final __mm256_mask_roundscale_ps = __mm256_mask_roundscale_psPtr
      .asFunction<__m256 Function(__m256, int, __m256, int)>();

  __m256 _mm256_maskz_roundscale_ps(
    int arg0,
    __m256 arg1,
    int arg2,
  ) {
    return __mm256_maskz_roundscale_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_roundscale_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__mmask8, __m256, ffi.Int32)>>(
          '_mm256_maskz_roundscale_ps');
  late final __mm256_maskz_roundscale_ps = __mm256_maskz_roundscale_psPtr
      .asFunction<__m256 Function(int, __m256, int)>();

  __m256 _mm256_roundscale_ps(
    __m256 arg0,
    int arg1,
  ) {
    return __mm256_roundscale_ps(
      arg0,
      arg1,
    );
  }

  late final __mm256_roundscale_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256, ffi.Int32)>>(
          '_mm256_roundscale_ps');
  late final __mm256_roundscale_ps =
      __mm256_roundscale_psPtr.asFunction<__m256 Function(__m256, int)>();

  _m128d _mm_mask_rsqrt14_pd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
  ) {
    return __mm_mask_rsqrt14_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_rsqrt14_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, __mmask8, _m128d)>>(
          '_mm_mask_rsqrt14_pd');
  late final __mm_mask_rsqrt14_pd = __mm_mask_rsqrt14_pdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d)>();

  _m128d _mm_maskz_rsqrt14_pd(
    int arg0,
    _m128d arg1,
  ) {
    return __mm_maskz_rsqrt14_pd(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_rsqrt14_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(__mmask8, _m128d)>>(
          '_mm_maskz_rsqrt14_pd');
  late final __mm_maskz_rsqrt14_pd =
      __mm_maskz_rsqrt14_pdPtr.asFunction<_m128d Function(int, _m128d)>();

  _m256d _mm256_mask_rsqrt14_pd(
    _m256d arg0,
    int arg1,
    _m256d arg2,
  ) {
    return __mm256_mask_rsqrt14_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_rsqrt14_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d, __mmask8, _m256d)>>(
          '_mm256_mask_rsqrt14_pd');
  late final __mm256_mask_rsqrt14_pd = __mm256_mask_rsqrt14_pdPtr
      .asFunction<_m256d Function(_m256d, int, _m256d)>();

  _m256d _mm256_maskz_rsqrt14_pd(
    int arg0,
    _m256d arg1,
  ) {
    return __mm256_maskz_rsqrt14_pd(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_rsqrt14_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(__mmask8, _m256d)>>(
          '_mm256_maskz_rsqrt14_pd');
  late final __mm256_maskz_rsqrt14_pd =
      __mm256_maskz_rsqrt14_pdPtr.asFunction<_m256d Function(int, _m256d)>();

  __m128 _mm_mask_rsqrt14_ps(
    __m128 arg0,
    int arg1,
    __m128 arg2,
  ) {
    return __mm_mask_rsqrt14_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_rsqrt14_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __mmask8, __m128)>>(
          '_mm_mask_rsqrt14_ps');
  late final __mm_mask_rsqrt14_ps = __mm_mask_rsqrt14_psPtr
      .asFunction<__m128 Function(__m128, int, __m128)>();

  __m128 _mm_maskz_rsqrt14_ps(
    int arg0,
    __m128 arg1,
  ) {
    return __mm_maskz_rsqrt14_ps(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_rsqrt14_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__mmask8, __m128)>>(
          '_mm_maskz_rsqrt14_ps');
  late final __mm_maskz_rsqrt14_ps =
      __mm_maskz_rsqrt14_psPtr.asFunction<__m128 Function(int, __m128)>();

  __m256 _mm256_mask_rsqrt14_ps(
    __m256 arg0,
    int arg1,
    __m256 arg2,
  ) {
    return __mm256_mask_rsqrt14_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_rsqrt14_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256, __mmask8, __m256)>>(
          '_mm256_mask_rsqrt14_ps');
  late final __mm256_mask_rsqrt14_ps = __mm256_mask_rsqrt14_psPtr
      .asFunction<__m256 Function(__m256, int, __m256)>();

  __m256 _mm256_maskz_rsqrt14_ps(
    int arg0,
    __m256 arg1,
  ) {
    return __mm256_maskz_rsqrt14_ps(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_rsqrt14_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__mmask8, __m256)>>(
          '_mm256_maskz_rsqrt14_ps');
  late final __mm256_maskz_rsqrt14_ps =
      __mm256_maskz_rsqrt14_psPtr.asFunction<__m256 Function(int, __m256)>();

  _m128d _mm_mask_scalef_pd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    _m128d arg3,
  ) {
    return __mm_mask_scalef_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_scalef_pdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              _m128d, __mmask8, _m128d, _m128d)>>('_mm_mask_scalef_pd');
  late final __mm_mask_scalef_pd = __mm_mask_scalef_pdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d, _m128d)>();

  _m128d _mm_maskz_scalef_pd(
    int arg0,
    _m128d arg1,
    _m128d arg2,
  ) {
    return __mm_maskz_scalef_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_scalef_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(__mmask8, _m128d, _m128d)>>(
          '_mm_maskz_scalef_pd');
  late final __mm_maskz_scalef_pd = __mm_maskz_scalef_pdPtr
      .asFunction<_m128d Function(int, _m128d, _m128d)>();

  _m128d _mm_scalef_pd(
    _m128d arg0,
    _m128d arg1,
  ) {
    return __mm_scalef_pd(
      arg0,
      arg1,
    );
  }

  late final __mm_scalef_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d)>>(
          '_mm_scalef_pd');
  late final __mm_scalef_pd =
      __mm_scalef_pdPtr.asFunction<_m128d Function(_m128d, _m128d)>();

  _m256d _mm256_mask_scalef_pd(
    _m256d arg0,
    int arg1,
    _m256d arg2,
    _m256d arg3,
  ) {
    return __mm256_mask_scalef_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_scalef_pdPtr = _lookup<
      ffi.NativeFunction<
          _m256d Function(
              _m256d, __mmask8, _m256d, _m256d)>>('_mm256_mask_scalef_pd');
  late final __mm256_mask_scalef_pd = __mm256_mask_scalef_pdPtr
      .asFunction<_m256d Function(_m256d, int, _m256d, _m256d)>();

  _m256d _mm256_maskz_scalef_pd(
    int arg0,
    _m256d arg1,
    _m256d arg2,
  ) {
    return __mm256_maskz_scalef_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_scalef_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(__mmask8, _m256d, _m256d)>>(
          '_mm256_maskz_scalef_pd');
  late final __mm256_maskz_scalef_pd = __mm256_maskz_scalef_pdPtr
      .asFunction<_m256d Function(int, _m256d, _m256d)>();

  _m256d _mm256_scalef_pd(
    _m256d arg0,
    _m256d arg1,
  ) {
    return __mm256_scalef_pd(
      arg0,
      arg1,
    );
  }

  late final __mm256_scalef_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d, _m256d)>>(
          '_mm256_scalef_pd');
  late final __mm256_scalef_pd =
      __mm256_scalef_pdPtr.asFunction<_m256d Function(_m256d, _m256d)>();

  __m128 _mm_mask_scalef_ps(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    __m128 arg3,
  ) {
    return __mm_mask_scalef_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_scalef_psPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __m128, __mmask8, __m128, __m128)>>('_mm_mask_scalef_ps');
  late final __mm_mask_scalef_ps = __mm_mask_scalef_psPtr
      .asFunction<__m128 Function(__m128, int, __m128, __m128)>();

  __m128 _mm_maskz_scalef_ps(
    int arg0,
    __m128 arg1,
    __m128 arg2,
  ) {
    return __mm_maskz_scalef_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_scalef_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__mmask8, __m128, __m128)>>(
          '_mm_maskz_scalef_ps');
  late final __mm_maskz_scalef_ps = __mm_maskz_scalef_psPtr
      .asFunction<__m128 Function(int, __m128, __m128)>();

  __m128 _mm_scalef_ps(
    __m128 arg0,
    __m128 arg1,
  ) {
    return __mm_scalef_ps(
      arg0,
      arg1,
    );
  }

  late final __mm_scalef_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128)>>(
          '_mm_scalef_ps');
  late final __mm_scalef_ps =
      __mm_scalef_psPtr.asFunction<__m128 Function(__m128, __m128)>();

  __m256 _mm256_mask_scalef_ps(
    __m256 arg0,
    int arg1,
    __m256 arg2,
    __m256 arg3,
  ) {
    return __mm256_mask_scalef_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_scalef_psPtr = _lookup<
      ffi.NativeFunction<
          __m256 Function(
              __m256, __mmask8, __m256, __m256)>>('_mm256_mask_scalef_ps');
  late final __mm256_mask_scalef_ps = __mm256_mask_scalef_psPtr
      .asFunction<__m256 Function(__m256, int, __m256, __m256)>();

  __m256 _mm256_maskz_scalef_ps(
    int arg0,
    __m256 arg1,
    __m256 arg2,
  ) {
    return __mm256_maskz_scalef_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_scalef_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__mmask8, __m256, __m256)>>(
          '_mm256_maskz_scalef_ps');
  late final __mm256_maskz_scalef_ps = __mm256_maskz_scalef_psPtr
      .asFunction<__m256 Function(int, __m256, __m256)>();

  __m256 _mm256_scalef_ps(
    __m256 arg0,
    __m256 arg1,
  ) {
    return __mm256_scalef_ps(
      arg0,
      arg1,
    );
  }

  late final __mm256_scalef_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256, __m256)>>(
          '_mm256_scalef_ps');
  late final __mm256_scalef_ps =
      __mm256_scalef_psPtr.asFunction<__m256 Function(__m256, __m256)>();

  __m128i _mm_mask_set1_epi16(
    __m128i arg0,
    int arg1,
    int arg2,
  ) {
    return __mm_mask_set1_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_set1_epi16Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__m128i, __mmask8, ffi.Int16)>>(
      '_mm_mask_set1_epi16');
  late final __mm_mask_set1_epi16 =
      __mm_mask_set1_epi16Ptr.asFunction<__m128i Function(__m128i, int, int)>();

  __m128i _mm_maskz_set1_epi16(
    int arg0,
    int arg1,
  ) {
    return __mm_maskz_set1_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_set1_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, ffi.Int16)>>(
          '_mm_maskz_set1_epi16');
  late final __mm_maskz_set1_epi16 =
      __mm_maskz_set1_epi16Ptr.asFunction<__m128i Function(int, int)>();

  __m256i _mm256_mask_set1_epi16(
    __m256i arg0,
    int arg1,
    int arg2,
  ) {
    return __mm256_mask_set1_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_set1_epi16Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__m256i, __mmask16, ffi.Int16)>>(
      '_mm256_mask_set1_epi16');
  late final __mm256_mask_set1_epi16 = __mm256_mask_set1_epi16Ptr
      .asFunction<__m256i Function(__m256i, int, int)>();

  __m256i _mm256_maskz_set1_epi16(
    int arg0,
    int arg1,
  ) {
    return __mm256_maskz_set1_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_set1_epi16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask16, ffi.Int16)>>(
          '_mm256_maskz_set1_epi16');
  late final __mm256_maskz_set1_epi16 =
      __mm256_maskz_set1_epi16Ptr.asFunction<__m256i Function(int, int)>();

  __m128i _mm_mask_set1_epi32(
    __m128i arg0,
    int arg1,
    int arg2,
  ) {
    return __mm_mask_set1_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_set1_epi32Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__m128i, __mmask8, ffi.Int32)>>(
      '_mm_mask_set1_epi32');
  late final __mm_mask_set1_epi32 =
      __mm_mask_set1_epi32Ptr.asFunction<__m128i Function(__m128i, int, int)>();

  __m128i _mm_maskz_set1_epi32(
    int arg0,
    int arg1,
  ) {
    return __mm_maskz_set1_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_set1_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, ffi.Int32)>>(
          '_mm_maskz_set1_epi32');
  late final __mm_maskz_set1_epi32 =
      __mm_maskz_set1_epi32Ptr.asFunction<__m128i Function(int, int)>();

  __m256i _mm256_mask_set1_epi32(
    __m256i arg0,
    int arg1,
    int arg2,
  ) {
    return __mm256_mask_set1_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_set1_epi32Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__m256i, __mmask8, ffi.Int32)>>(
      '_mm256_mask_set1_epi32');
  late final __mm256_mask_set1_epi32 = __mm256_mask_set1_epi32Ptr
      .asFunction<__m256i Function(__m256i, int, int)>();

  __m256i _mm256_maskz_set1_epi32(
    int arg0,
    int arg1,
  ) {
    return __mm256_maskz_set1_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_set1_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, ffi.Int32)>>(
          '_mm256_maskz_set1_epi32');
  late final __mm256_maskz_set1_epi32 =
      __mm256_maskz_set1_epi32Ptr.asFunction<__m256i Function(int, int)>();

  __m128i _mm_mask_set1_epi64(
    __m128i arg0,
    int arg1,
    int arg2,
  ) {
    return __mm_mask_set1_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_set1_epi64Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__m128i, __mmask8, ffi.Int64)>>(
      '_mm_mask_set1_epi64');
  late final __mm_mask_set1_epi64 =
      __mm_mask_set1_epi64Ptr.asFunction<__m128i Function(__m128i, int, int)>();

  __m128i _mm_maskz_set1_epi64(
    int arg0,
    int arg1,
  ) {
    return __mm_maskz_set1_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_set1_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, ffi.Int64)>>(
          '_mm_maskz_set1_epi64');
  late final __mm_maskz_set1_epi64 =
      __mm_maskz_set1_epi64Ptr.asFunction<__m128i Function(int, int)>();

  __m256i _mm256_mask_set1_epi64(
    __m256i arg0,
    int arg1,
    int arg2,
  ) {
    return __mm256_mask_set1_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_set1_epi64Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__m256i, __mmask8, ffi.Int64)>>(
      '_mm256_mask_set1_epi64');
  late final __mm256_mask_set1_epi64 = __mm256_mask_set1_epi64Ptr
      .asFunction<__m256i Function(__m256i, int, int)>();

  __m256i _mm256_maskz_set1_epi64(
    int arg0,
    int arg1,
  ) {
    return __mm256_maskz_set1_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_set1_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, ffi.Int64)>>(
          '_mm256_maskz_set1_epi64');
  late final __mm256_maskz_set1_epi64 =
      __mm256_maskz_set1_epi64Ptr.asFunction<__m256i Function(int, int)>();

  __m128i _mm_mask_set1_epi8(
    __m128i arg0,
    int arg1,
    int arg2,
  ) {
    return __mm_mask_set1_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_set1_epi8Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__m128i, __mmask16, ffi.Int8)>>(
      '_mm_mask_set1_epi8');
  late final __mm_mask_set1_epi8 =
      __mm_mask_set1_epi8Ptr.asFunction<__m128i Function(__m128i, int, int)>();

  __m128i _mm_maskz_set1_epi8(
    int arg0,
    int arg1,
  ) {
    return __mm_maskz_set1_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_set1_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask16, ffi.Int8)>>(
          '_mm_maskz_set1_epi8');
  late final __mm_maskz_set1_epi8 =
      __mm_maskz_set1_epi8Ptr.asFunction<__m128i Function(int, int)>();

  __m256i _mm256_mask_set1_epi8(
    __m256i arg0,
    int arg1,
    int arg2,
  ) {
    return __mm256_mask_set1_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_set1_epi8Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__m256i, __mmask32, ffi.Int8)>>(
      '_mm256_mask_set1_epi8');
  late final __mm256_mask_set1_epi8 = __mm256_mask_set1_epi8Ptr
      .asFunction<__m256i Function(__m256i, int, int)>();

  __m256i _mm256_maskz_set1_epi8(
    int arg0,
    int arg1,
  ) {
    return __mm256_maskz_set1_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_set1_epi8Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask32, ffi.Int8)>>(
          '_mm256_maskz_set1_epi8');
  late final __mm256_maskz_set1_epi8 =
      __mm256_maskz_set1_epi8Ptr.asFunction<__m256i Function(int, int)>();

  __m128i _mm_mask_shuffle_epi32(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    int arg3,
  ) {
    return __mm_mask_shuffle_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_shuffle_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(__m128i, __mmask8, __m128i,
              ffi.Int32)>>('_mm_mask_shuffle_epi32');
  late final __mm_mask_shuffle_epi32 = __mm_mask_shuffle_epi32Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, int)>();

  __m128i _mm_maskz_shuffle_epi32(
    int arg0,
    __m128i arg1,
    int arg2,
  ) {
    return __mm_maskz_shuffle_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_shuffle_epi32Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__mmask8, __m128i, ffi.Int32)>>(
      '_mm_maskz_shuffle_epi32');
  late final __mm_maskz_shuffle_epi32 = __mm_maskz_shuffle_epi32Ptr
      .asFunction<__m128i Function(int, __m128i, int)>();

  __m256i _mm256_mask_shuffle_epi32(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    int arg3,
  ) {
    return __mm256_mask_shuffle_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_shuffle_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask8, __m256i,
              ffi.Int32)>>('_mm256_mask_shuffle_epi32');
  late final __mm256_mask_shuffle_epi32 = __mm256_mask_shuffle_epi32Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, int)>();

  __m256i _mm256_maskz_shuffle_epi32(
    int arg0,
    __m256i arg1,
    int arg2,
  ) {
    return __mm256_maskz_shuffle_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_shuffle_epi32Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__mmask8, __m256i, ffi.Int32)>>(
      '_mm256_maskz_shuffle_epi32');
  late final __mm256_maskz_shuffle_epi32 = __mm256_maskz_shuffle_epi32Ptr
      .asFunction<__m256i Function(int, __m256i, int)>();

  __m128i _mm_mask_shuffle_epi8(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_shuffle_epi8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_shuffle_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask16, __m128i, __m128i)>>('_mm_mask_shuffle_epi8');
  late final __mm_mask_shuffle_epi8 = __mm_mask_shuffle_epi8Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_shuffle_epi8(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_shuffle_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_shuffle_epi8Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__mmask16, __m128i, __m128i)>>(
      '_mm_maskz_shuffle_epi8');
  late final __mm_maskz_shuffle_epi8 = __mm_maskz_shuffle_epi8Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_mask_shuffle_epi8(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_shuffle_epi8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_shuffle_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask32, __m256i,
              __m256i)>>('_mm256_mask_shuffle_epi8');
  late final __mm256_mask_shuffle_epi8 = __mm256_mask_shuffle_epi8Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_shuffle_epi8(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_shuffle_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_shuffle_epi8Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__mmask32, __m256i, __m256i)>>(
      '_mm256_maskz_shuffle_epi8');
  late final __mm256_maskz_shuffle_epi8 = __mm256_maskz_shuffle_epi8Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  __m256 _mm256_mask_shuffle_f32x4(
    __m256 arg0,
    int arg1,
    __m256 arg2,
    __m256 arg3,
    int arg4,
  ) {
    return __mm256_mask_shuffle_f32x4(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm256_mask_shuffle_f32x4Ptr = _lookup<
      ffi.NativeFunction<
          __m256 Function(__m256, __mmask8, __m256, __m256,
              ffi.Int32)>>('_mm256_mask_shuffle_f32x4');
  late final __mm256_mask_shuffle_f32x4 = __mm256_mask_shuffle_f32x4Ptr
      .asFunction<__m256 Function(__m256, int, __m256, __m256, int)>();

  __m256 _mm256_maskz_shuffle_f32x4(
    int arg0,
    __m256 arg1,
    __m256 arg2,
    int arg3,
  ) {
    return __mm256_maskz_shuffle_f32x4(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_maskz_shuffle_f32x4Ptr = _lookup<
      ffi.NativeFunction<
          __m256 Function(__mmask8, __m256, __m256,
              ffi.Int32)>>('_mm256_maskz_shuffle_f32x4');
  late final __mm256_maskz_shuffle_f32x4 = __mm256_maskz_shuffle_f32x4Ptr
      .asFunction<__m256 Function(int, __m256, __m256, int)>();

  __m256 _mm256_shuffle_f32x4(
    __m256 arg0,
    __m256 arg1,
    int arg2,
  ) {
    return __mm256_shuffle_f32x4(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_shuffle_f32x4Ptr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256, __m256, ffi.Int32)>>(
          '_mm256_shuffle_f32x4');
  late final __mm256_shuffle_f32x4 = __mm256_shuffle_f32x4Ptr
      .asFunction<__m256 Function(__m256, __m256, int)>();

  _m256d _mm256_mask_shuffle_f64x2(
    _m256d arg0,
    int arg1,
    _m256d arg2,
    _m256d arg3,
    int arg4,
  ) {
    return __mm256_mask_shuffle_f64x2(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm256_mask_shuffle_f64x2Ptr = _lookup<
      ffi.NativeFunction<
          _m256d Function(_m256d, __mmask8, _m256d, _m256d,
              ffi.Int32)>>('_mm256_mask_shuffle_f64x2');
  late final __mm256_mask_shuffle_f64x2 = __mm256_mask_shuffle_f64x2Ptr
      .asFunction<_m256d Function(_m256d, int, _m256d, _m256d, int)>();

  _m256d _mm256_maskz_shuffle_f64x2(
    int arg0,
    _m256d arg1,
    _m256d arg2,
    int arg3,
  ) {
    return __mm256_maskz_shuffle_f64x2(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_maskz_shuffle_f64x2Ptr = _lookup<
      ffi.NativeFunction<
          _m256d Function(__mmask8, _m256d, _m256d,
              ffi.Int32)>>('_mm256_maskz_shuffle_f64x2');
  late final __mm256_maskz_shuffle_f64x2 = __mm256_maskz_shuffle_f64x2Ptr
      .asFunction<_m256d Function(int, _m256d, _m256d, int)>();

  _m256d _mm256_shuffle_f64x2(
    _m256d arg0,
    _m256d arg1,
    int arg2,
  ) {
    return __mm256_shuffle_f64x2(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_shuffle_f64x2Ptr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d, _m256d, ffi.Int32)>>(
          '_mm256_shuffle_f64x2');
  late final __mm256_shuffle_f64x2 = __mm256_shuffle_f64x2Ptr
      .asFunction<_m256d Function(_m256d, _m256d, int)>();

  __m256i _mm256_mask_shuffle_i32x4(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
    int arg4,
  ) {
    return __mm256_mask_shuffle_i32x4(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm256_mask_shuffle_i32x4Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask8, __m256i, __m256i,
              ffi.Int32)>>('_mm256_mask_shuffle_i32x4');
  late final __mm256_mask_shuffle_i32x4 = __mm256_mask_shuffle_i32x4Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i, int)>();

  __m256i _mm256_maskz_shuffle_i32x4(
    int arg0,
    __m256i arg1,
    __m256i arg2,
    int arg3,
  ) {
    return __mm256_maskz_shuffle_i32x4(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_maskz_shuffle_i32x4Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__mmask8, __m256i, __m256i,
              ffi.Int32)>>('_mm256_maskz_shuffle_i32x4');
  late final __mm256_maskz_shuffle_i32x4 = __mm256_maskz_shuffle_i32x4Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i, int)>();

  __m256i _mm256_shuffle_i32x4(
    __m256i arg0,
    __m256i arg1,
    int arg2,
  ) {
    return __mm256_shuffle_i32x4(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_shuffle_i32x4Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__m256i, __m256i, ffi.Int32)>>(
      '_mm256_shuffle_i32x4');
  late final __mm256_shuffle_i32x4 = __mm256_shuffle_i32x4Ptr
      .asFunction<__m256i Function(__m256i, __m256i, int)>();

  __m256i _mm256_mask_shuffle_i64x2(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
    int arg4,
  ) {
    return __mm256_mask_shuffle_i64x2(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm256_mask_shuffle_i64x2Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask8, __m256i, __m256i,
              ffi.Int32)>>('_mm256_mask_shuffle_i64x2');
  late final __mm256_mask_shuffle_i64x2 = __mm256_mask_shuffle_i64x2Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i, int)>();

  __m256i _mm256_maskz_shuffle_i64x2(
    int arg0,
    __m256i arg1,
    __m256i arg2,
    int arg3,
  ) {
    return __mm256_maskz_shuffle_i64x2(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_maskz_shuffle_i64x2Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__mmask8, __m256i, __m256i,
              ffi.Int32)>>('_mm256_maskz_shuffle_i64x2');
  late final __mm256_maskz_shuffle_i64x2 = __mm256_maskz_shuffle_i64x2Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i, int)>();

  __m256i _mm256_shuffle_i64x2(
    __m256i arg0,
    __m256i arg1,
    int arg2,
  ) {
    return __mm256_shuffle_i64x2(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_shuffle_i64x2Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__m256i, __m256i, ffi.Int32)>>(
      '_mm256_shuffle_i64x2');
  late final __mm256_shuffle_i64x2 = __mm256_shuffle_i64x2Ptr
      .asFunction<__m256i Function(__m256i, __m256i, int)>();

  _m128d _mm_mask_shuffle_pd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    _m128d arg3,
    int arg4,
  ) {
    return __mm_mask_shuffle_pd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_shuffle_pdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(_m128d, __mmask8, _m128d, _m128d,
              ffi.Int32)>>('_mm_mask_shuffle_pd');
  late final __mm_mask_shuffle_pd = __mm_mask_shuffle_pdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d, _m128d, int)>();

  _m128d _mm_maskz_shuffle_pd(
    int arg0,
    _m128d arg1,
    _m128d arg2,
    int arg3,
  ) {
    return __mm_maskz_shuffle_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_shuffle_pdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              __mmask8, _m128d, _m128d, ffi.Int32)>>('_mm_maskz_shuffle_pd');
  late final __mm_maskz_shuffle_pd = __mm_maskz_shuffle_pdPtr
      .asFunction<_m128d Function(int, _m128d, _m128d, int)>();

  _m256d _mm256_mask_shuffle_pd(
    _m256d arg0,
    int arg1,
    _m256d arg2,
    _m256d arg3,
    int arg4,
  ) {
    return __mm256_mask_shuffle_pd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm256_mask_shuffle_pdPtr = _lookup<
      ffi.NativeFunction<
          _m256d Function(_m256d, __mmask8, _m256d, _m256d,
              ffi.Int32)>>('_mm256_mask_shuffle_pd');
  late final __mm256_mask_shuffle_pd = __mm256_mask_shuffle_pdPtr
      .asFunction<_m256d Function(_m256d, int, _m256d, _m256d, int)>();

  _m256d _mm256_maskz_shuffle_pd(
    int arg0,
    _m256d arg1,
    _m256d arg2,
    int arg3,
  ) {
    return __mm256_maskz_shuffle_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_maskz_shuffle_pdPtr = _lookup<
      ffi.NativeFunction<
          _m256d Function(
              __mmask8, _m256d, _m256d, ffi.Int32)>>('_mm256_maskz_shuffle_pd');
  late final __mm256_maskz_shuffle_pd = __mm256_maskz_shuffle_pdPtr
      .asFunction<_m256d Function(int, _m256d, _m256d, int)>();

  __m128 _mm_mask_shuffle_ps(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    __m128 arg3,
    int arg4,
  ) {
    return __mm_mask_shuffle_ps(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_shuffle_psPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(__m128, __mmask8, __m128, __m128,
              ffi.Int32)>>('_mm_mask_shuffle_ps');
  late final __mm_mask_shuffle_ps = __mm_mask_shuffle_psPtr
      .asFunction<__m128 Function(__m128, int, __m128, __m128, int)>();

  __m128 _mm_maskz_shuffle_ps(
    int arg0,
    __m128 arg1,
    __m128 arg2,
    int arg3,
  ) {
    return __mm_maskz_shuffle_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_shuffle_psPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __mmask8, __m128, __m128, ffi.Int32)>>('_mm_maskz_shuffle_ps');
  late final __mm_maskz_shuffle_ps = __mm_maskz_shuffle_psPtr
      .asFunction<__m128 Function(int, __m128, __m128, int)>();

  __m256 _mm256_mask_shuffle_ps(
    __m256 arg0,
    int arg1,
    __m256 arg2,
    __m256 arg3,
    int arg4,
  ) {
    return __mm256_mask_shuffle_ps(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm256_mask_shuffle_psPtr = _lookup<
      ffi.NativeFunction<
          __m256 Function(__m256, __mmask8, __m256, __m256,
              ffi.Int32)>>('_mm256_mask_shuffle_ps');
  late final __mm256_mask_shuffle_ps = __mm256_mask_shuffle_psPtr
      .asFunction<__m256 Function(__m256, int, __m256, __m256, int)>();

  __m256 _mm256_maskz_shuffle_ps(
    int arg0,
    __m256 arg1,
    __m256 arg2,
    int arg3,
  ) {
    return __mm256_maskz_shuffle_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_maskz_shuffle_psPtr = _lookup<
      ffi.NativeFunction<
          __m256 Function(
              __mmask8, __m256, __m256, ffi.Int32)>>('_mm256_maskz_shuffle_ps');
  late final __mm256_maskz_shuffle_ps = __mm256_maskz_shuffle_psPtr
      .asFunction<__m256 Function(int, __m256, __m256, int)>();

  __m128i _mm_mask_shufflehi_epi16(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    int arg3,
  ) {
    return __mm_mask_shufflehi_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_shufflehi_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(__m128i, __mmask8, __m128i,
              ffi.Int32)>>('_mm_mask_shufflehi_epi16');
  late final __mm_mask_shufflehi_epi16 = __mm_mask_shufflehi_epi16Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, int)>();

  __m128i _mm_maskz_shufflehi_epi16(
    int arg0,
    __m128i arg1,
    int arg2,
  ) {
    return __mm_maskz_shufflehi_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_shufflehi_epi16Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__mmask8, __m128i, ffi.Int32)>>(
      '_mm_maskz_shufflehi_epi16');
  late final __mm_maskz_shufflehi_epi16 = __mm_maskz_shufflehi_epi16Ptr
      .asFunction<__m128i Function(int, __m128i, int)>();

  __m256i _mm256_mask_shufflehi_epi16(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    int arg3,
  ) {
    return __mm256_mask_shufflehi_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_shufflehi_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask16, __m256i,
              ffi.Int32)>>('_mm256_mask_shufflehi_epi16');
  late final __mm256_mask_shufflehi_epi16 = __mm256_mask_shufflehi_epi16Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, int)>();

  __m256i _mm256_maskz_shufflehi_epi16(
    int arg0,
    __m256i arg1,
    int arg2,
  ) {
    return __mm256_maskz_shufflehi_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_shufflehi_epi16Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__mmask16, __m256i, ffi.Int32)>>(
      '_mm256_maskz_shufflehi_epi16');
  late final __mm256_maskz_shufflehi_epi16 = __mm256_maskz_shufflehi_epi16Ptr
      .asFunction<__m256i Function(int, __m256i, int)>();

  __m128i _mm_mask_shufflelo_epi16(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    int arg3,
  ) {
    return __mm_mask_shufflelo_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_shufflelo_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(__m128i, __mmask8, __m128i,
              ffi.Int32)>>('_mm_mask_shufflelo_epi16');
  late final __mm_mask_shufflelo_epi16 = __mm_mask_shufflelo_epi16Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, int)>();

  __m128i _mm_maskz_shufflelo_epi16(
    int arg0,
    __m128i arg1,
    int arg2,
  ) {
    return __mm_maskz_shufflelo_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_shufflelo_epi16Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__mmask8, __m128i, ffi.Int32)>>(
      '_mm_maskz_shufflelo_epi16');
  late final __mm_maskz_shufflelo_epi16 = __mm_maskz_shufflelo_epi16Ptr
      .asFunction<__m128i Function(int, __m128i, int)>();

  __m256i _mm256_mask_shufflelo_epi16(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    int arg3,
  ) {
    return __mm256_mask_shufflelo_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_shufflelo_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask16, __m256i,
              ffi.Int32)>>('_mm256_mask_shufflelo_epi16');
  late final __mm256_mask_shufflelo_epi16 = __mm256_mask_shufflelo_epi16Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, int)>();

  __m256i _mm256_maskz_shufflelo_epi16(
    int arg0,
    __m256i arg1,
    int arg2,
  ) {
    return __mm256_maskz_shufflelo_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_shufflelo_epi16Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__mmask16, __m256i, ffi.Int32)>>(
      '_mm256_maskz_shufflelo_epi16');
  late final __mm256_maskz_shufflelo_epi16 = __mm256_maskz_shufflelo_epi16Ptr
      .asFunction<__m256i Function(int, __m256i, int)>();

  __m128i _mm_mask_sll_epi16(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_sll_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_sll_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_sll_epi16');
  late final __mm_mask_sll_epi16 = __mm_mask_sll_epi16Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_sll_epi16(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_sll_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_sll_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_maskz_sll_epi16');
  late final __mm_maskz_sll_epi16 = __mm_maskz_sll_epi16Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_mask_sll_epi16(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m128i arg3,
  ) {
    return __mm256_mask_sll_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_sll_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask16, __m256i, __m128i)>>('_mm256_mask_sll_epi16');
  late final __mm256_mask_sll_epi16 = __mm256_mask_sll_epi16Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m128i)>();

  __m256i _mm256_maskz_sll_epi16(
    int arg0,
    __m256i arg1,
    __m128i arg2,
  ) {
    return __mm256_maskz_sll_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_sll_epi16Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__mmask16, __m256i, __m128i)>>(
      '_mm256_maskz_sll_epi16');
  late final __mm256_maskz_sll_epi16 = __mm256_maskz_sll_epi16Ptr
      .asFunction<__m256i Function(int, __m256i, __m128i)>();

  __m128i _mm_mask_sll_epi32(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_sll_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_sll_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_sll_epi32');
  late final __mm_mask_sll_epi32 = __mm_mask_sll_epi32Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_sll_epi32(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_sll_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_sll_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_maskz_sll_epi32');
  late final __mm_maskz_sll_epi32 = __mm_maskz_sll_epi32Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_mask_sll_epi32(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m128i arg3,
  ) {
    return __mm256_mask_sll_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_sll_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask8, __m256i, __m128i)>>('_mm256_mask_sll_epi32');
  late final __mm256_mask_sll_epi32 = __mm256_mask_sll_epi32Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m128i)>();

  __m256i _mm256_maskz_sll_epi32(
    int arg0,
    __m256i arg1,
    __m128i arg2,
  ) {
    return __mm256_maskz_sll_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_sll_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m256i, __m128i)>>(
          '_mm256_maskz_sll_epi32');
  late final __mm256_maskz_sll_epi32 = __mm256_maskz_sll_epi32Ptr
      .asFunction<__m256i Function(int, __m256i, __m128i)>();

  __m128i _mm_mask_sll_epi64(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_sll_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_sll_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_sll_epi64');
  late final __mm_mask_sll_epi64 = __mm_mask_sll_epi64Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_sll_epi64(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_sll_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_sll_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_maskz_sll_epi64');
  late final __mm_maskz_sll_epi64 = __mm_maskz_sll_epi64Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_mask_sll_epi64(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m128i arg3,
  ) {
    return __mm256_mask_sll_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_sll_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask8, __m256i, __m128i)>>('_mm256_mask_sll_epi64');
  late final __mm256_mask_sll_epi64 = __mm256_mask_sll_epi64Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m128i)>();

  __m256i _mm256_maskz_sll_epi64(
    int arg0,
    __m256i arg1,
    __m128i arg2,
  ) {
    return __mm256_maskz_sll_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_sll_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m256i, __m128i)>>(
          '_mm256_maskz_sll_epi64');
  late final __mm256_maskz_sll_epi64 = __mm256_maskz_sll_epi64Ptr
      .asFunction<__m256i Function(int, __m256i, __m128i)>();

  __m128i _mm_mask_slli_epi16(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    int arg3,
  ) {
    return __mm_mask_slli_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_slli_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, ffi.Uint32)>>('_mm_mask_slli_epi16');
  late final __mm_mask_slli_epi16 = __mm_mask_slli_epi16Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, int)>();

  __m128i _mm_maskz_slli_epi16(
    int arg0,
    __m128i arg1,
    int arg2,
  ) {
    return __mm_maskz_slli_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_slli_epi16Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__mmask8, __m128i, ffi.Uint32)>>(
      '_mm_maskz_slli_epi16');
  late final __mm_maskz_slli_epi16 = __mm_maskz_slli_epi16Ptr
      .asFunction<__m128i Function(int, __m128i, int)>();

  __m256i _mm256_mask_slli_epi16(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    int arg3,
  ) {
    return __mm256_mask_slli_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_slli_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask16, __m256i,
              ffi.Uint32)>>('_mm256_mask_slli_epi16');
  late final __mm256_mask_slli_epi16 = __mm256_mask_slli_epi16Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, int)>();

  __m256i _mm256_maskz_slli_epi16(
    int arg0,
    __m256i arg1,
    int arg2,
  ) {
    return __mm256_maskz_slli_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_slli_epi16Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__mmask16, __m256i, ffi.Uint32)>>(
      '_mm256_maskz_slli_epi16');
  late final __mm256_maskz_slli_epi16 = __mm256_maskz_slli_epi16Ptr
      .asFunction<__m256i Function(int, __m256i, int)>();

  __m128i _mm_mask_slli_epi32(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    int arg3,
  ) {
    return __mm_mask_slli_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_slli_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, ffi.Uint32)>>('_mm_mask_slli_epi32');
  late final __mm_mask_slli_epi32 = __mm_mask_slli_epi32Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, int)>();

  __m128i _mm_maskz_slli_epi32(
    int arg0,
    __m128i arg1,
    int arg2,
  ) {
    return __mm_maskz_slli_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_slli_epi32Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__mmask8, __m128i, ffi.Uint32)>>(
      '_mm_maskz_slli_epi32');
  late final __mm_maskz_slli_epi32 = __mm_maskz_slli_epi32Ptr
      .asFunction<__m128i Function(int, __m128i, int)>();

  __m256i _mm256_mask_slli_epi32(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    int arg3,
  ) {
    return __mm256_mask_slli_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_slli_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask8, __m256i,
              ffi.Uint32)>>('_mm256_mask_slli_epi32');
  late final __mm256_mask_slli_epi32 = __mm256_mask_slli_epi32Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, int)>();

  __m256i _mm256_maskz_slli_epi32(
    int arg0,
    __m256i arg1,
    int arg2,
  ) {
    return __mm256_maskz_slli_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_slli_epi32Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__mmask8, __m256i, ffi.Uint32)>>(
      '_mm256_maskz_slli_epi32');
  late final __mm256_maskz_slli_epi32 = __mm256_maskz_slli_epi32Ptr
      .asFunction<__m256i Function(int, __m256i, int)>();

  __m128i _mm_mask_slli_epi64(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    int arg3,
  ) {
    return __mm_mask_slli_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_slli_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, ffi.Uint32)>>('_mm_mask_slli_epi64');
  late final __mm_mask_slli_epi64 = __mm_mask_slli_epi64Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, int)>();

  __m128i _mm_maskz_slli_epi64(
    int arg0,
    __m128i arg1,
    int arg2,
  ) {
    return __mm_maskz_slli_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_slli_epi64Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__mmask8, __m128i, ffi.Uint32)>>(
      '_mm_maskz_slli_epi64');
  late final __mm_maskz_slli_epi64 = __mm_maskz_slli_epi64Ptr
      .asFunction<__m128i Function(int, __m128i, int)>();

  __m256i _mm256_mask_slli_epi64(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    int arg3,
  ) {
    return __mm256_mask_slli_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_slli_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask8, __m256i,
              ffi.Uint32)>>('_mm256_mask_slli_epi64');
  late final __mm256_mask_slli_epi64 = __mm256_mask_slli_epi64Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, int)>();

  __m256i _mm256_maskz_slli_epi64(
    int arg0,
    __m256i arg1,
    int arg2,
  ) {
    return __mm256_maskz_slli_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_slli_epi64Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__mmask8, __m256i, ffi.Uint32)>>(
      '_mm256_maskz_slli_epi64');
  late final __mm256_maskz_slli_epi64 = __mm256_maskz_slli_epi64Ptr
      .asFunction<__m256i Function(int, __m256i, int)>();

  __m128i _mm_mask_sllv_epi16(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_sllv_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_sllv_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_sllv_epi16');
  late final __mm_mask_sllv_epi16 = __mm_mask_sllv_epi16Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_sllv_epi16(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_sllv_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_sllv_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_maskz_sllv_epi16');
  late final __mm_maskz_sllv_epi16 = __mm_maskz_sllv_epi16Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m128i _mm_sllv_epi16(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_sllv_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm_sllv_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_sllv_epi16');
  late final __mm_sllv_epi16 =
      __mm_sllv_epi16Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m256i _mm256_mask_sllv_epi16(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_sllv_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_sllv_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask16, __m256i, __m256i)>>('_mm256_mask_sllv_epi16');
  late final __mm256_mask_sllv_epi16 = __mm256_mask_sllv_epi16Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_sllv_epi16(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_sllv_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_sllv_epi16Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__mmask16, __m256i, __m256i)>>(
      '_mm256_maskz_sllv_epi16');
  late final __mm256_maskz_sllv_epi16 = __mm256_maskz_sllv_epi16Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  __m256i _mm256_sllv_epi16(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_sllv_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm256_sllv_epi16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_sllv_epi16');
  late final __mm256_sllv_epi16 =
      __mm256_sllv_epi16Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m128i _mm_mask_sllv_epi32(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_sllv_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_sllv_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_sllv_epi32');
  late final __mm_mask_sllv_epi32 = __mm_mask_sllv_epi32Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_sllv_epi32(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_sllv_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_sllv_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_maskz_sllv_epi32');
  late final __mm_maskz_sllv_epi32 = __mm_maskz_sllv_epi32Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_mask_sllv_epi32(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_sllv_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_sllv_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask8, __m256i, __m256i)>>('_mm256_mask_sllv_epi32');
  late final __mm256_mask_sllv_epi32 = __mm256_mask_sllv_epi32Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_sllv_epi32(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_sllv_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_sllv_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m256i, __m256i)>>(
          '_mm256_maskz_sllv_epi32');
  late final __mm256_maskz_sllv_epi32 = __mm256_maskz_sllv_epi32Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  __m128i _mm_mask_sllv_epi64(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_sllv_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_sllv_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_sllv_epi64');
  late final __mm_mask_sllv_epi64 = __mm_mask_sllv_epi64Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_sllv_epi64(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_sllv_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_sllv_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_maskz_sllv_epi64');
  late final __mm_maskz_sllv_epi64 = __mm_maskz_sllv_epi64Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_mask_sllv_epi64(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_sllv_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_sllv_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask8, __m256i, __m256i)>>('_mm256_mask_sllv_epi64');
  late final __mm256_mask_sllv_epi64 = __mm256_mask_sllv_epi64Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_sllv_epi64(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_sllv_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_sllv_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m256i, __m256i)>>(
          '_mm256_maskz_sllv_epi64');
  late final __mm256_maskz_sllv_epi64 = __mm256_maskz_sllv_epi64Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  _m128d _mm_mask_sqrt_pd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
  ) {
    return __mm_mask_sqrt_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_sqrt_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, __mmask8, _m128d)>>(
          '_mm_mask_sqrt_pd');
  late final __mm_mask_sqrt_pd =
      __mm_mask_sqrt_pdPtr.asFunction<_m128d Function(_m128d, int, _m128d)>();

  _m128d _mm_maskz_sqrt_pd(
    int arg0,
    _m128d arg1,
  ) {
    return __mm_maskz_sqrt_pd(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_sqrt_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(__mmask8, _m128d)>>(
          '_mm_maskz_sqrt_pd');
  late final __mm_maskz_sqrt_pd =
      __mm_maskz_sqrt_pdPtr.asFunction<_m128d Function(int, _m128d)>();

  _m256d _mm256_mask_sqrt_pd(
    _m256d arg0,
    int arg1,
    _m256d arg2,
  ) {
    return __mm256_mask_sqrt_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_sqrt_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d, __mmask8, _m256d)>>(
          '_mm256_mask_sqrt_pd');
  late final __mm256_mask_sqrt_pd = __mm256_mask_sqrt_pdPtr
      .asFunction<_m256d Function(_m256d, int, _m256d)>();

  _m256d _mm256_maskz_sqrt_pd(
    int arg0,
    _m256d arg1,
  ) {
    return __mm256_maskz_sqrt_pd(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_sqrt_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(__mmask8, _m256d)>>(
          '_mm256_maskz_sqrt_pd');
  late final __mm256_maskz_sqrt_pd =
      __mm256_maskz_sqrt_pdPtr.asFunction<_m256d Function(int, _m256d)>();

  __m128 _mm_mask_sqrt_ps(
    __m128 arg0,
    int arg1,
    __m128 arg2,
  ) {
    return __mm_mask_sqrt_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_sqrt_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __mmask8, __m128)>>(
          '_mm_mask_sqrt_ps');
  late final __mm_mask_sqrt_ps =
      __mm_mask_sqrt_psPtr.asFunction<__m128 Function(__m128, int, __m128)>();

  __m128 _mm_maskz_sqrt_ps(
    int arg0,
    __m128 arg1,
  ) {
    return __mm_maskz_sqrt_ps(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_sqrt_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__mmask8, __m128)>>(
          '_mm_maskz_sqrt_ps');
  late final __mm_maskz_sqrt_ps =
      __mm_maskz_sqrt_psPtr.asFunction<__m128 Function(int, __m128)>();

  __m256 _mm256_mask_sqrt_ps(
    __m256 arg0,
    int arg1,
    __m256 arg2,
  ) {
    return __mm256_mask_sqrt_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_sqrt_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256, __mmask8, __m256)>>(
          '_mm256_mask_sqrt_ps');
  late final __mm256_mask_sqrt_ps = __mm256_mask_sqrt_psPtr
      .asFunction<__m256 Function(__m256, int, __m256)>();

  __m256 _mm256_maskz_sqrt_ps(
    int arg0,
    __m256 arg1,
  ) {
    return __mm256_maskz_sqrt_ps(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_sqrt_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__mmask8, __m256)>>(
          '_mm256_maskz_sqrt_ps');
  late final __mm256_maskz_sqrt_ps =
      __mm256_maskz_sqrt_psPtr.asFunction<__m256 Function(int, __m256)>();

  __m128i _mm_mask_sra_epi16(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_sra_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_sra_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_sra_epi16');
  late final __mm_mask_sra_epi16 = __mm_mask_sra_epi16Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_sra_epi16(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_sra_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_sra_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_maskz_sra_epi16');
  late final __mm_maskz_sra_epi16 = __mm_maskz_sra_epi16Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_mask_sra_epi16(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m128i arg3,
  ) {
    return __mm256_mask_sra_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_sra_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask16, __m256i, __m128i)>>('_mm256_mask_sra_epi16');
  late final __mm256_mask_sra_epi16 = __mm256_mask_sra_epi16Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m128i)>();

  __m256i _mm256_maskz_sra_epi16(
    int arg0,
    __m256i arg1,
    __m128i arg2,
  ) {
    return __mm256_maskz_sra_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_sra_epi16Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__mmask16, __m256i, __m128i)>>(
      '_mm256_maskz_sra_epi16');
  late final __mm256_maskz_sra_epi16 = __mm256_maskz_sra_epi16Ptr
      .asFunction<__m256i Function(int, __m256i, __m128i)>();

  __m128i _mm_mask_sra_epi32(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_sra_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_sra_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_sra_epi32');
  late final __mm_mask_sra_epi32 = __mm_mask_sra_epi32Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_sra_epi32(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_sra_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_sra_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_maskz_sra_epi32');
  late final __mm_maskz_sra_epi32 = __mm_maskz_sra_epi32Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_mask_sra_epi32(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m128i arg3,
  ) {
    return __mm256_mask_sra_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_sra_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask8, __m256i, __m128i)>>('_mm256_mask_sra_epi32');
  late final __mm256_mask_sra_epi32 = __mm256_mask_sra_epi32Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m128i)>();

  __m256i _mm256_maskz_sra_epi32(
    int arg0,
    __m256i arg1,
    __m128i arg2,
  ) {
    return __mm256_maskz_sra_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_sra_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m256i, __m128i)>>(
          '_mm256_maskz_sra_epi32');
  late final __mm256_maskz_sra_epi32 = __mm256_maskz_sra_epi32Ptr
      .asFunction<__m256i Function(int, __m256i, __m128i)>();

  __m128i _mm_mask_sra_epi64(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_sra_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_sra_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_sra_epi64');
  late final __mm_mask_sra_epi64 = __mm_mask_sra_epi64Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_sra_epi64(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_sra_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_sra_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_maskz_sra_epi64');
  late final __mm_maskz_sra_epi64 = __mm_maskz_sra_epi64Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m128i _mm_sra_epi64(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_sra_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm_sra_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_sra_epi64');
  late final __mm_sra_epi64 =
      __mm_sra_epi64Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m256i _mm256_mask_sra_epi64(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m128i arg3,
  ) {
    return __mm256_mask_sra_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_sra_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask8, __m256i, __m128i)>>('_mm256_mask_sra_epi64');
  late final __mm256_mask_sra_epi64 = __mm256_mask_sra_epi64Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m128i)>();

  __m256i _mm256_maskz_sra_epi64(
    int arg0,
    __m256i arg1,
    __m128i arg2,
  ) {
    return __mm256_maskz_sra_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_sra_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m256i, __m128i)>>(
          '_mm256_maskz_sra_epi64');
  late final __mm256_maskz_sra_epi64 = __mm256_maskz_sra_epi64Ptr
      .asFunction<__m256i Function(int, __m256i, __m128i)>();

  __m256i _mm256_sra_epi64(
    __m256i arg0,
    __m128i arg1,
  ) {
    return __mm256_sra_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm256_sra_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m128i)>>(
          '_mm256_sra_epi64');
  late final __mm256_sra_epi64 =
      __mm256_sra_epi64Ptr.asFunction<__m256i Function(__m256i, __m128i)>();

  __m128i _mm_mask_srai_epi16(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    int arg3,
  ) {
    return __mm_mask_srai_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_srai_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, ffi.Uint32)>>('_mm_mask_srai_epi16');
  late final __mm_mask_srai_epi16 = __mm_mask_srai_epi16Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, int)>();

  __m128i _mm_maskz_srai_epi16(
    int arg0,
    __m128i arg1,
    int arg2,
  ) {
    return __mm_maskz_srai_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_srai_epi16Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__mmask8, __m128i, ffi.Uint32)>>(
      '_mm_maskz_srai_epi16');
  late final __mm_maskz_srai_epi16 = __mm_maskz_srai_epi16Ptr
      .asFunction<__m128i Function(int, __m128i, int)>();

  __m256i _mm256_mask_srai_epi16(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    int arg3,
  ) {
    return __mm256_mask_srai_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_srai_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask16, __m256i,
              ffi.Uint32)>>('_mm256_mask_srai_epi16');
  late final __mm256_mask_srai_epi16 = __mm256_mask_srai_epi16Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, int)>();

  __m256i _mm256_maskz_srai_epi16(
    int arg0,
    __m256i arg1,
    int arg2,
  ) {
    return __mm256_maskz_srai_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_srai_epi16Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__mmask16, __m256i, ffi.Uint32)>>(
      '_mm256_maskz_srai_epi16');
  late final __mm256_maskz_srai_epi16 = __mm256_maskz_srai_epi16Ptr
      .asFunction<__m256i Function(int, __m256i, int)>();

  __m128i _mm_mask_srai_epi32(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    int arg3,
  ) {
    return __mm_mask_srai_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_srai_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, ffi.Uint32)>>('_mm_mask_srai_epi32');
  late final __mm_mask_srai_epi32 = __mm_mask_srai_epi32Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, int)>();

  __m128i _mm_maskz_srai_epi32(
    int arg0,
    __m128i arg1,
    int arg2,
  ) {
    return __mm_maskz_srai_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_srai_epi32Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__mmask8, __m128i, ffi.Uint32)>>(
      '_mm_maskz_srai_epi32');
  late final __mm_maskz_srai_epi32 = __mm_maskz_srai_epi32Ptr
      .asFunction<__m128i Function(int, __m128i, int)>();

  __m256i _mm256_mask_srai_epi32(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    int arg3,
  ) {
    return __mm256_mask_srai_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_srai_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask8, __m256i,
              ffi.Uint32)>>('_mm256_mask_srai_epi32');
  late final __mm256_mask_srai_epi32 = __mm256_mask_srai_epi32Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, int)>();

  __m256i _mm256_maskz_srai_epi32(
    int arg0,
    __m256i arg1,
    int arg2,
  ) {
    return __mm256_maskz_srai_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_srai_epi32Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__mmask8, __m256i, ffi.Uint32)>>(
      '_mm256_maskz_srai_epi32');
  late final __mm256_maskz_srai_epi32 = __mm256_maskz_srai_epi32Ptr
      .asFunction<__m256i Function(int, __m256i, int)>();

  __m128i _mm_mask_srai_epi64(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    int arg3,
  ) {
    return __mm_mask_srai_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_srai_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, ffi.Uint32)>>('_mm_mask_srai_epi64');
  late final __mm_mask_srai_epi64 = __mm_mask_srai_epi64Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, int)>();

  __m128i _mm_maskz_srai_epi64(
    int arg0,
    __m128i arg1,
    int arg2,
  ) {
    return __mm_maskz_srai_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_srai_epi64Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__mmask8, __m128i, ffi.Uint32)>>(
      '_mm_maskz_srai_epi64');
  late final __mm_maskz_srai_epi64 = __mm_maskz_srai_epi64Ptr
      .asFunction<__m128i Function(int, __m128i, int)>();

  __m128i _mm_srai_epi64(
    __m128i arg0,
    int arg1,
  ) {
    return __mm_srai_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm_srai_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, ffi.Uint32)>>(
          '_mm_srai_epi64');
  late final __mm_srai_epi64 =
      __mm_srai_epi64Ptr.asFunction<__m128i Function(__m128i, int)>();

  __m256i _mm256_mask_srai_epi64(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    int arg3,
  ) {
    return __mm256_mask_srai_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_srai_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask8, __m256i,
              ffi.Uint32)>>('_mm256_mask_srai_epi64');
  late final __mm256_mask_srai_epi64 = __mm256_mask_srai_epi64Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, int)>();

  __m256i _mm256_maskz_srai_epi64(
    int arg0,
    __m256i arg1,
    int arg2,
  ) {
    return __mm256_maskz_srai_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_srai_epi64Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__mmask8, __m256i, ffi.Uint32)>>(
      '_mm256_maskz_srai_epi64');
  late final __mm256_maskz_srai_epi64 = __mm256_maskz_srai_epi64Ptr
      .asFunction<__m256i Function(int, __m256i, int)>();

  __m256i _mm256_srai_epi64(
    __m256i arg0,
    int arg1,
  ) {
    return __mm256_srai_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm256_srai_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, ffi.Uint32)>>(
          '_mm256_srai_epi64');
  late final __mm256_srai_epi64 =
      __mm256_srai_epi64Ptr.asFunction<__m256i Function(__m256i, int)>();

  __m128i _mm_mask_srav_epi16(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_srav_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_srav_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_srav_epi16');
  late final __mm_mask_srav_epi16 = __mm_mask_srav_epi16Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_srav_epi16(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_srav_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_srav_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_maskz_srav_epi16');
  late final __mm_maskz_srav_epi16 = __mm_maskz_srav_epi16Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m128i _mm_srav_epi16(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_srav_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm_srav_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_srav_epi16');
  late final __mm_srav_epi16 =
      __mm_srav_epi16Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m256i _mm256_mask_srav_epi16(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_srav_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_srav_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask16, __m256i, __m256i)>>('_mm256_mask_srav_epi16');
  late final __mm256_mask_srav_epi16 = __mm256_mask_srav_epi16Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_srav_epi16(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_srav_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_srav_epi16Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__mmask16, __m256i, __m256i)>>(
      '_mm256_maskz_srav_epi16');
  late final __mm256_maskz_srav_epi16 = __mm256_maskz_srav_epi16Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  __m256i _mm256_srav_epi16(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_srav_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm256_srav_epi16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_srav_epi16');
  late final __mm256_srav_epi16 =
      __mm256_srav_epi16Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m128i _mm_mask_srav_epi32(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_srav_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_srav_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_srav_epi32');
  late final __mm_mask_srav_epi32 = __mm_mask_srav_epi32Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_srav_epi32(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_srav_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_srav_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_maskz_srav_epi32');
  late final __mm_maskz_srav_epi32 = __mm_maskz_srav_epi32Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_mask_srav_epi32(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_srav_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_srav_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask8, __m256i, __m256i)>>('_mm256_mask_srav_epi32');
  late final __mm256_mask_srav_epi32 = __mm256_mask_srav_epi32Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_srav_epi32(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_srav_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_srav_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m256i, __m256i)>>(
          '_mm256_maskz_srav_epi32');
  late final __mm256_maskz_srav_epi32 = __mm256_maskz_srav_epi32Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  __m128i _mm_mask_srav_epi64(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_srav_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_srav_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_srav_epi64');
  late final __mm_mask_srav_epi64 = __mm_mask_srav_epi64Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_srav_epi64(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_srav_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_srav_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_maskz_srav_epi64');
  late final __mm_maskz_srav_epi64 = __mm_maskz_srav_epi64Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m128i _mm_srav_epi64(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_srav_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm_srav_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_srav_epi64');
  late final __mm_srav_epi64 =
      __mm_srav_epi64Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m256i _mm256_mask_srav_epi64(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_srav_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_srav_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask8, __m256i, __m256i)>>('_mm256_mask_srav_epi64');
  late final __mm256_mask_srav_epi64 = __mm256_mask_srav_epi64Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_srav_epi64(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_srav_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_srav_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m256i, __m256i)>>(
          '_mm256_maskz_srav_epi64');
  late final __mm256_maskz_srav_epi64 = __mm256_maskz_srav_epi64Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  __m256i _mm256_srav_epi64(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_srav_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm256_srav_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_srav_epi64');
  late final __mm256_srav_epi64 =
      __mm256_srav_epi64Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m128i _mm_mask_srl_epi16(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_srl_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_srl_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_srl_epi16');
  late final __mm_mask_srl_epi16 = __mm_mask_srl_epi16Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_srl_epi16(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_srl_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_srl_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_maskz_srl_epi16');
  late final __mm_maskz_srl_epi16 = __mm_maskz_srl_epi16Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_mask_srl_epi16(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m128i arg3,
  ) {
    return __mm256_mask_srl_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_srl_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask16, __m256i, __m128i)>>('_mm256_mask_srl_epi16');
  late final __mm256_mask_srl_epi16 = __mm256_mask_srl_epi16Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m128i)>();

  __m256i _mm256_maskz_srl_epi16(
    int arg0,
    __m256i arg1,
    __m128i arg2,
  ) {
    return __mm256_maskz_srl_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_srl_epi16Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__mmask16, __m256i, __m128i)>>(
      '_mm256_maskz_srl_epi16');
  late final __mm256_maskz_srl_epi16 = __mm256_maskz_srl_epi16Ptr
      .asFunction<__m256i Function(int, __m256i, __m128i)>();

  __m128i _mm_mask_srl_epi32(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_srl_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_srl_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_srl_epi32');
  late final __mm_mask_srl_epi32 = __mm_mask_srl_epi32Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_srl_epi32(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_srl_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_srl_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_maskz_srl_epi32');
  late final __mm_maskz_srl_epi32 = __mm_maskz_srl_epi32Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_mask_srl_epi32(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m128i arg3,
  ) {
    return __mm256_mask_srl_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_srl_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask8, __m256i, __m128i)>>('_mm256_mask_srl_epi32');
  late final __mm256_mask_srl_epi32 = __mm256_mask_srl_epi32Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m128i)>();

  __m256i _mm256_maskz_srl_epi32(
    int arg0,
    __m256i arg1,
    __m128i arg2,
  ) {
    return __mm256_maskz_srl_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_srl_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m256i, __m128i)>>(
          '_mm256_maskz_srl_epi32');
  late final __mm256_maskz_srl_epi32 = __mm256_maskz_srl_epi32Ptr
      .asFunction<__m256i Function(int, __m256i, __m128i)>();

  __m128i _mm_mask_srl_epi64(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_srl_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_srl_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_srl_epi64');
  late final __mm_mask_srl_epi64 = __mm_mask_srl_epi64Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_srl_epi64(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_srl_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_srl_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_maskz_srl_epi64');
  late final __mm_maskz_srl_epi64 = __mm_maskz_srl_epi64Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_mask_srl_epi64(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m128i arg3,
  ) {
    return __mm256_mask_srl_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_srl_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask8, __m256i, __m128i)>>('_mm256_mask_srl_epi64');
  late final __mm256_mask_srl_epi64 = __mm256_mask_srl_epi64Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m128i)>();

  __m256i _mm256_maskz_srl_epi64(
    int arg0,
    __m256i arg1,
    __m128i arg2,
  ) {
    return __mm256_maskz_srl_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_srl_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m256i, __m128i)>>(
          '_mm256_maskz_srl_epi64');
  late final __mm256_maskz_srl_epi64 = __mm256_maskz_srl_epi64Ptr
      .asFunction<__m256i Function(int, __m256i, __m128i)>();

  __m128i _mm_mask_srli_epi16(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    int arg3,
  ) {
    return __mm_mask_srli_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_srli_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, ffi.Int32)>>('_mm_mask_srli_epi16');
  late final __mm_mask_srli_epi16 = __mm_mask_srli_epi16Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, int)>();

  __m128i _mm_maskz_srli_epi16(
    int arg0,
    __m128i arg1,
    int arg2,
  ) {
    return __mm_maskz_srli_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_srli_epi16Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__mmask8, __m128i, ffi.Int32)>>(
      '_mm_maskz_srli_epi16');
  late final __mm_maskz_srli_epi16 = __mm_maskz_srli_epi16Ptr
      .asFunction<__m128i Function(int, __m128i, int)>();

  __m256i _mm256_mask_srli_epi16(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    int arg3,
  ) {
    return __mm256_mask_srli_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_srli_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask16, __m256i,
              ffi.Int32)>>('_mm256_mask_srli_epi16');
  late final __mm256_mask_srli_epi16 = __mm256_mask_srli_epi16Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, int)>();

  __m256i _mm256_maskz_srli_epi16(
    int arg0,
    __m256i arg1,
    int arg2,
  ) {
    return __mm256_maskz_srli_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_srli_epi16Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__mmask16, __m256i, ffi.Int32)>>(
      '_mm256_maskz_srli_epi16');
  late final __mm256_maskz_srli_epi16 = __mm256_maskz_srli_epi16Ptr
      .asFunction<__m256i Function(int, __m256i, int)>();

  __m128i _mm_mask_srli_epi32(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    int arg3,
  ) {
    return __mm_mask_srli_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_srli_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, ffi.Uint32)>>('_mm_mask_srli_epi32');
  late final __mm_mask_srli_epi32 = __mm_mask_srli_epi32Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, int)>();

  __m128i _mm_maskz_srli_epi32(
    int arg0,
    __m128i arg1,
    int arg2,
  ) {
    return __mm_maskz_srli_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_srli_epi32Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__mmask8, __m128i, ffi.Uint32)>>(
      '_mm_maskz_srli_epi32');
  late final __mm_maskz_srli_epi32 = __mm_maskz_srli_epi32Ptr
      .asFunction<__m128i Function(int, __m128i, int)>();

  __m256i _mm256_mask_srli_epi32(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    int arg3,
  ) {
    return __mm256_mask_srli_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_srli_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask8, __m256i,
              ffi.Uint32)>>('_mm256_mask_srli_epi32');
  late final __mm256_mask_srli_epi32 = __mm256_mask_srli_epi32Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, int)>();

  __m256i _mm256_maskz_srli_epi32(
    int arg0,
    __m256i arg1,
    int arg2,
  ) {
    return __mm256_maskz_srli_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_srli_epi32Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__mmask8, __m256i, ffi.Uint32)>>(
      '_mm256_maskz_srli_epi32');
  late final __mm256_maskz_srli_epi32 = __mm256_maskz_srli_epi32Ptr
      .asFunction<__m256i Function(int, __m256i, int)>();

  __m128i _mm_mask_srli_epi64(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    int arg3,
  ) {
    return __mm_mask_srli_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_srli_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, ffi.Uint32)>>('_mm_mask_srli_epi64');
  late final __mm_mask_srli_epi64 = __mm_mask_srli_epi64Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, int)>();

  __m128i _mm_maskz_srli_epi64(
    int arg0,
    __m128i arg1,
    int arg2,
  ) {
    return __mm_maskz_srli_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_srli_epi64Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__mmask8, __m128i, ffi.Uint32)>>(
      '_mm_maskz_srli_epi64');
  late final __mm_maskz_srli_epi64 = __mm_maskz_srli_epi64Ptr
      .asFunction<__m128i Function(int, __m128i, int)>();

  __m256i _mm256_mask_srli_epi64(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    int arg3,
  ) {
    return __mm256_mask_srli_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_srli_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask8, __m256i,
              ffi.Uint32)>>('_mm256_mask_srli_epi64');
  late final __mm256_mask_srli_epi64 = __mm256_mask_srli_epi64Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, int)>();

  __m256i _mm256_maskz_srli_epi64(
    int arg0,
    __m256i arg1,
    int arg2,
  ) {
    return __mm256_maskz_srli_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_srli_epi64Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__mmask8, __m256i, ffi.Uint32)>>(
      '_mm256_maskz_srli_epi64');
  late final __mm256_maskz_srli_epi64 = __mm256_maskz_srli_epi64Ptr
      .asFunction<__m256i Function(int, __m256i, int)>();

  __m128i _mm_mask_srlv_epi16(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_srlv_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_srlv_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_srlv_epi16');
  late final __mm_mask_srlv_epi16 = __mm_mask_srlv_epi16Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_srlv_epi16(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_srlv_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_srlv_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_maskz_srlv_epi16');
  late final __mm_maskz_srlv_epi16 = __mm_maskz_srlv_epi16Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m128i _mm_srlv_epi16(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_srlv_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm_srlv_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_srlv_epi16');
  late final __mm_srlv_epi16 =
      __mm_srlv_epi16Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m256i _mm256_mask_srlv_epi16(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_srlv_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_srlv_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask16, __m256i, __m256i)>>('_mm256_mask_srlv_epi16');
  late final __mm256_mask_srlv_epi16 = __mm256_mask_srlv_epi16Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_srlv_epi16(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_srlv_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_srlv_epi16Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__mmask16, __m256i, __m256i)>>(
      '_mm256_maskz_srlv_epi16');
  late final __mm256_maskz_srlv_epi16 = __mm256_maskz_srlv_epi16Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  __m256i _mm256_srlv_epi16(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_srlv_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm256_srlv_epi16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_srlv_epi16');
  late final __mm256_srlv_epi16 =
      __mm256_srlv_epi16Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m128i _mm_mask_srlv_epi32(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_srlv_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_srlv_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_srlv_epi32');
  late final __mm_mask_srlv_epi32 = __mm_mask_srlv_epi32Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_srlv_epi32(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_srlv_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_srlv_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_maskz_srlv_epi32');
  late final __mm_maskz_srlv_epi32 = __mm_maskz_srlv_epi32Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_mask_srlv_epi32(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_srlv_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_srlv_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask8, __m256i, __m256i)>>('_mm256_mask_srlv_epi32');
  late final __mm256_mask_srlv_epi32 = __mm256_mask_srlv_epi32Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_srlv_epi32(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_srlv_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_srlv_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m256i, __m256i)>>(
          '_mm256_maskz_srlv_epi32');
  late final __mm256_maskz_srlv_epi32 = __mm256_maskz_srlv_epi32Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  __m128i _mm_mask_srlv_epi64(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_srlv_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_srlv_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_srlv_epi64');
  late final __mm_mask_srlv_epi64 = __mm_mask_srlv_epi64Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_srlv_epi64(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_srlv_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_srlv_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_maskz_srlv_epi64');
  late final __mm_maskz_srlv_epi64 = __mm_maskz_srlv_epi64Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_mask_srlv_epi64(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_srlv_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_srlv_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask8, __m256i, __m256i)>>('_mm256_mask_srlv_epi64');
  late final __mm256_mask_srlv_epi64 = __mm256_mask_srlv_epi64Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_srlv_epi64(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_srlv_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_srlv_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m256i, __m256i)>>(
          '_mm256_maskz_srlv_epi64');
  late final __mm256_maskz_srlv_epi64 = __mm256_maskz_srlv_epi64Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  void _mm_mask_store_epi32(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_store_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_store_epi32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8,
              __m128i)>>('_mm_mask_store_epi32');
  late final __mm_mask_store_epi32 = __mm_mask_store_epi32Ptr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m128i)>();

  void _mm256_mask_store_epi32(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_store_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_store_epi32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8,
              __m256i)>>('_mm256_mask_store_epi32');
  late final __mm256_mask_store_epi32 = __mm256_mask_store_epi32Ptr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m256i)>();

  void _mm_mask_store_epi64(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_store_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_store_epi64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8,
              __m128i)>>('_mm_mask_store_epi64');
  late final __mm_mask_store_epi64 = __mm_mask_store_epi64Ptr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m128i)>();

  void _mm256_mask_store_epi64(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_store_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_store_epi64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8,
              __m256i)>>('_mm256_mask_store_epi64');
  late final __mm256_mask_store_epi64 = __mm256_mask_store_epi64Ptr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m256i)>();

  void _mm_mask_store_pd(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    _m128d arg2,
  ) {
    return __mm_mask_store_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_store_pdPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<ffi.Void>, __mmask8, _m128d)>>('_mm_mask_store_pd');
  late final __mm_mask_store_pd = __mm_mask_store_pdPtr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, int, _m128d)>();

  void _mm256_mask_store_pd(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    _m256d arg2,
  ) {
    return __mm256_mask_store_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_store_pdPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8,
              _m256d)>>('_mm256_mask_store_pd');
  late final __mm256_mask_store_pd = __mm256_mask_store_pdPtr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, int, _m256d)>();

  void _mm_mask_store_ps(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m128 arg2,
  ) {
    return __mm_mask_store_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_store_psPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<ffi.Void>, __mmask8, __m128)>>('_mm_mask_store_ps');
  late final __mm_mask_store_ps = __mm_mask_store_psPtr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m128)>();

  void _mm256_mask_store_ps(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m256 arg2,
  ) {
    return __mm256_mask_store_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_store_psPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8,
              __m256)>>('_mm256_mask_store_ps');
  late final __mm256_mask_store_ps = __mm256_mask_store_psPtr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m256)>();

  void _mm_storeu_epi16(
    ffi.Pointer<ffi.Void> arg0,
    __m128i arg1,
  ) {
    return __mm_storeu_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm_storeu_epi16Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<ffi.Void>, __m128i)>>('_mm_storeu_epi16');
  late final __mm_storeu_epi16 = __mm_storeu_epi16Ptr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, __m128i)>();

  void _mm256_storeu_epi16(
    ffi.Pointer<ffi.Void> arg0,
    __m256i arg1,
  ) {
    return __mm256_storeu_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm256_storeu_epi16Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<ffi.Void>, __m256i)>>('_mm256_storeu_epi16');
  late final __mm256_storeu_epi16 = __mm256_storeu_epi16Ptr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, __m256i)>();

  void _mm_mask_storeu_epi16(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_storeu_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_storeu_epi16Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8,
              __m128i)>>('_mm_mask_storeu_epi16');
  late final __mm_mask_storeu_epi16 = __mm_mask_storeu_epi16Ptr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m128i)>();

  void _mm256_mask_storeu_epi16(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_storeu_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_storeu_epi16Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask16,
              __m256i)>>('_mm256_mask_storeu_epi16');
  late final __mm256_mask_storeu_epi16 = __mm256_mask_storeu_epi16Ptr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m256i)>();

  void _mm_storeu_epi32(
    ffi.Pointer<ffi.Void> arg0,
    __m128i arg1,
  ) {
    return __mm_storeu_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm_storeu_epi32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<ffi.Void>, __m128i)>>('_mm_storeu_epi32');
  late final __mm_storeu_epi32 = __mm_storeu_epi32Ptr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, __m128i)>();

  void _mm256_storeu_epi32(
    ffi.Pointer<ffi.Void> arg0,
    __m256i arg1,
  ) {
    return __mm256_storeu_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm256_storeu_epi32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<ffi.Void>, __m256i)>>('_mm256_storeu_epi32');
  late final __mm256_storeu_epi32 = __mm256_storeu_epi32Ptr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, __m256i)>();

  void _mm_mask_storeu_epi32(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_storeu_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_storeu_epi32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8,
              __m128i)>>('_mm_mask_storeu_epi32');
  late final __mm_mask_storeu_epi32 = __mm_mask_storeu_epi32Ptr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m128i)>();

  void _mm256_mask_storeu_epi32(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_storeu_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_storeu_epi32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8,
              __m256i)>>('_mm256_mask_storeu_epi32');
  late final __mm256_mask_storeu_epi32 = __mm256_mask_storeu_epi32Ptr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m256i)>();

  void _mm_storeu_epi64(
    ffi.Pointer<ffi.Void> arg0,
    __m128i arg1,
  ) {
    return __mm_storeu_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm_storeu_epi64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<ffi.Void>, __m128i)>>('_mm_storeu_epi64');
  late final __mm_storeu_epi64 = __mm_storeu_epi64Ptr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, __m128i)>();

  void _mm256_storeu_epi64(
    ffi.Pointer<ffi.Void> arg0,
    __m256i arg1,
  ) {
    return __mm256_storeu_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm256_storeu_epi64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<ffi.Void>, __m256i)>>('_mm256_storeu_epi64');
  late final __mm256_storeu_epi64 = __mm256_storeu_epi64Ptr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, __m256i)>();

  void _mm_mask_storeu_epi64(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_storeu_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_storeu_epi64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8,
              __m128i)>>('_mm_mask_storeu_epi64');
  late final __mm_mask_storeu_epi64 = __mm_mask_storeu_epi64Ptr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m128i)>();

  void _mm256_mask_storeu_epi64(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_storeu_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_storeu_epi64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8,
              __m256i)>>('_mm256_mask_storeu_epi64');
  late final __mm256_mask_storeu_epi64 = __mm256_mask_storeu_epi64Ptr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m256i)>();

  void _mm_storeu_epi8(
    ffi.Pointer<ffi.Void> arg0,
    __m128i arg1,
  ) {
    return __mm_storeu_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm_storeu_epi8Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<ffi.Void>, __m128i)>>('_mm_storeu_epi8');
  late final __mm_storeu_epi8 = __mm_storeu_epi8Ptr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, __m128i)>();

  void _mm256_storeu_epi8(
    ffi.Pointer<ffi.Void> arg0,
    __m256i arg1,
  ) {
    return __mm256_storeu_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm256_storeu_epi8Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<ffi.Void>, __m256i)>>('_mm256_storeu_epi8');
  late final __mm256_storeu_epi8 = __mm256_storeu_epi8Ptr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, __m256i)>();

  void _mm_mask_storeu_epi8(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_storeu_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_storeu_epi8Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask16,
              __m128i)>>('_mm_mask_storeu_epi8');
  late final __mm_mask_storeu_epi8 = __mm_mask_storeu_epi8Ptr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m128i)>();

  void _mm256_mask_storeu_epi8(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_storeu_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_storeu_epi8Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask32,
              __m256i)>>('_mm256_mask_storeu_epi8');
  late final __mm256_mask_storeu_epi8 = __mm256_mask_storeu_epi8Ptr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m256i)>();

  void _mm_mask_storeu_pd(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    _m128d arg2,
  ) {
    return __mm_mask_storeu_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_storeu_pdPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<ffi.Void>, __mmask8, _m128d)>>('_mm_mask_storeu_pd');
  late final __mm_mask_storeu_pd = __mm_mask_storeu_pdPtr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, int, _m128d)>();

  void _mm256_mask_storeu_pd(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    _m256d arg2,
  ) {
    return __mm256_mask_storeu_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_storeu_pdPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8,
              _m256d)>>('_mm256_mask_storeu_pd');
  late final __mm256_mask_storeu_pd = __mm256_mask_storeu_pdPtr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, int, _m256d)>();

  void _mm_mask_storeu_ps(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m128 arg2,
  ) {
    return __mm_mask_storeu_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_storeu_psPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<ffi.Void>, __mmask8, __m128)>>('_mm_mask_storeu_ps');
  late final __mm_mask_storeu_ps = __mm_mask_storeu_psPtr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m128)>();

  void _mm256_mask_storeu_ps(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m256 arg2,
  ) {
    return __mm256_mask_storeu_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_storeu_psPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8,
              __m256)>>('_mm256_mask_storeu_ps');
  late final __mm256_mask_storeu_ps = __mm256_mask_storeu_psPtr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m256)>();

  __m128i _mm_mask_sub_epi16(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_sub_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_sub_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_sub_epi16');
  late final __mm_mask_sub_epi16 = __mm_mask_sub_epi16Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_sub_epi16(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_sub_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_sub_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_maskz_sub_epi16');
  late final __mm_maskz_sub_epi16 = __mm_maskz_sub_epi16Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_mask_sub_epi16(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_sub_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_sub_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask16, __m256i, __m256i)>>('_mm256_mask_sub_epi16');
  late final __mm256_mask_sub_epi16 = __mm256_mask_sub_epi16Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_sub_epi16(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_sub_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_sub_epi16Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__mmask16, __m256i, __m256i)>>(
      '_mm256_maskz_sub_epi16');
  late final __mm256_maskz_sub_epi16 = __mm256_maskz_sub_epi16Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  __m128i _mm_mask_sub_epi32(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_sub_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_sub_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_sub_epi32');
  late final __mm_mask_sub_epi32 = __mm_mask_sub_epi32Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_sub_epi32(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_sub_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_sub_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_maskz_sub_epi32');
  late final __mm_maskz_sub_epi32 = __mm_maskz_sub_epi32Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_mask_sub_epi32(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_sub_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_sub_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask8, __m256i, __m256i)>>('_mm256_mask_sub_epi32');
  late final __mm256_mask_sub_epi32 = __mm256_mask_sub_epi32Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_sub_epi32(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_sub_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_sub_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m256i, __m256i)>>(
          '_mm256_maskz_sub_epi32');
  late final __mm256_maskz_sub_epi32 = __mm256_maskz_sub_epi32Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  __m128i _mm_mask_sub_epi64(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_sub_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_sub_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_sub_epi64');
  late final __mm_mask_sub_epi64 = __mm_mask_sub_epi64Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_sub_epi64(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_sub_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_sub_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_maskz_sub_epi64');
  late final __mm_maskz_sub_epi64 = __mm_maskz_sub_epi64Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_mask_sub_epi64(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_sub_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_sub_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask8, __m256i, __m256i)>>('_mm256_mask_sub_epi64');
  late final __mm256_mask_sub_epi64 = __mm256_mask_sub_epi64Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_sub_epi64(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_sub_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_sub_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m256i, __m256i)>>(
          '_mm256_maskz_sub_epi64');
  late final __mm256_maskz_sub_epi64 = __mm256_maskz_sub_epi64Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  __m128i _mm_mask_sub_epi8(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_sub_epi8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_sub_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask16, __m128i, __m128i)>>('_mm_mask_sub_epi8');
  late final __mm_mask_sub_epi8 = __mm_mask_sub_epi8Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_sub_epi8(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_sub_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_sub_epi8Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__mmask16, __m128i, __m128i)>>(
      '_mm_maskz_sub_epi8');
  late final __mm_maskz_sub_epi8 = __mm_maskz_sub_epi8Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_mask_sub_epi8(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_sub_epi8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_sub_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask32, __m256i, __m256i)>>('_mm256_mask_sub_epi8');
  late final __mm256_mask_sub_epi8 = __mm256_mask_sub_epi8Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_sub_epi8(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_sub_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_sub_epi8Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__mmask32, __m256i, __m256i)>>(
      '_mm256_maskz_sub_epi8');
  late final __mm256_maskz_sub_epi8 = __mm256_maskz_sub_epi8Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  _m128d _mm_mask_sub_pd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    _m128d arg3,
  ) {
    return __mm_mask_sub_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_sub_pdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              _m128d, __mmask8, _m128d, _m128d)>>('_mm_mask_sub_pd');
  late final __mm_mask_sub_pd = __mm_mask_sub_pdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d, _m128d)>();

  _m128d _mm_maskz_sub_pd(
    int arg0,
    _m128d arg1,
    _m128d arg2,
  ) {
    return __mm_maskz_sub_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_sub_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(__mmask8, _m128d, _m128d)>>(
          '_mm_maskz_sub_pd');
  late final __mm_maskz_sub_pd =
      __mm_maskz_sub_pdPtr.asFunction<_m128d Function(int, _m128d, _m128d)>();

  _m256d _mm256_mask_sub_pd(
    _m256d arg0,
    int arg1,
    _m256d arg2,
    _m256d arg3,
  ) {
    return __mm256_mask_sub_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_sub_pdPtr = _lookup<
      ffi.NativeFunction<
          _m256d Function(
              _m256d, __mmask8, _m256d, _m256d)>>('_mm256_mask_sub_pd');
  late final __mm256_mask_sub_pd = __mm256_mask_sub_pdPtr
      .asFunction<_m256d Function(_m256d, int, _m256d, _m256d)>();

  _m256d _mm256_maskz_sub_pd(
    int arg0,
    _m256d arg1,
    _m256d arg2,
  ) {
    return __mm256_maskz_sub_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_sub_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(__mmask8, _m256d, _m256d)>>(
          '_mm256_maskz_sub_pd');
  late final __mm256_maskz_sub_pd = __mm256_maskz_sub_pdPtr
      .asFunction<_m256d Function(int, _m256d, _m256d)>();

  __m128 _mm_mask_sub_ps(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    __m128 arg3,
  ) {
    return __mm_mask_sub_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_sub_psPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __m128, __mmask8, __m128, __m128)>>('_mm_mask_sub_ps');
  late final __mm_mask_sub_ps = __mm_mask_sub_psPtr
      .asFunction<__m128 Function(__m128, int, __m128, __m128)>();

  __m128 _mm_maskz_sub_ps(
    int arg0,
    __m128 arg1,
    __m128 arg2,
  ) {
    return __mm_maskz_sub_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_sub_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__mmask8, __m128, __m128)>>(
          '_mm_maskz_sub_ps');
  late final __mm_maskz_sub_ps =
      __mm_maskz_sub_psPtr.asFunction<__m128 Function(int, __m128, __m128)>();

  __m256 _mm256_mask_sub_ps(
    __m256 arg0,
    int arg1,
    __m256 arg2,
    __m256 arg3,
  ) {
    return __mm256_mask_sub_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_sub_psPtr = _lookup<
      ffi.NativeFunction<
          __m256 Function(
              __m256, __mmask8, __m256, __m256)>>('_mm256_mask_sub_ps');
  late final __mm256_mask_sub_ps = __mm256_mask_sub_psPtr
      .asFunction<__m256 Function(__m256, int, __m256, __m256)>();

  __m256 _mm256_maskz_sub_ps(
    int arg0,
    __m256 arg1,
    __m256 arg2,
  ) {
    return __mm256_maskz_sub_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_sub_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__mmask8, __m256, __m256)>>(
          '_mm256_maskz_sub_ps');
  late final __mm256_maskz_sub_ps = __mm256_maskz_sub_psPtr
      .asFunction<__m256 Function(int, __m256, __m256)>();

  __m128i _mm_mask_subs_epi16(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_subs_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_subs_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_subs_epi16');
  late final __mm_mask_subs_epi16 = __mm_mask_subs_epi16Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_subs_epi16(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_subs_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_subs_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_maskz_subs_epi16');
  late final __mm_maskz_subs_epi16 = __mm_maskz_subs_epi16Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_mask_subs_epi16(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_subs_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_subs_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask16, __m256i, __m256i)>>('_mm256_mask_subs_epi16');
  late final __mm256_mask_subs_epi16 = __mm256_mask_subs_epi16Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_subs_epi16(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_subs_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_subs_epi16Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__mmask16, __m256i, __m256i)>>(
      '_mm256_maskz_subs_epi16');
  late final __mm256_maskz_subs_epi16 = __mm256_maskz_subs_epi16Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  __m128i _mm_mask_subs_epi8(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_subs_epi8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_subs_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask16, __m128i, __m128i)>>('_mm_mask_subs_epi8');
  late final __mm_mask_subs_epi8 = __mm_mask_subs_epi8Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_subs_epi8(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_subs_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_subs_epi8Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__mmask16, __m128i, __m128i)>>(
      '_mm_maskz_subs_epi8');
  late final __mm_maskz_subs_epi8 = __mm_maskz_subs_epi8Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_mask_subs_epi8(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_subs_epi8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_subs_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask32, __m256i, __m256i)>>('_mm256_mask_subs_epi8');
  late final __mm256_mask_subs_epi8 = __mm256_mask_subs_epi8Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_subs_epi8(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_subs_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_subs_epi8Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__mmask32, __m256i, __m256i)>>(
      '_mm256_maskz_subs_epi8');
  late final __mm256_maskz_subs_epi8 = __mm256_maskz_subs_epi8Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  __m128i _mm_mask_subs_epu16(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_subs_epu16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_subs_epu16Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_subs_epu16');
  late final __mm_mask_subs_epu16 = __mm_mask_subs_epu16Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_subs_epu16(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_subs_epu16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_subs_epu16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_maskz_subs_epu16');
  late final __mm_maskz_subs_epu16 = __mm_maskz_subs_epu16Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_mask_subs_epu16(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_subs_epu16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_subs_epu16Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask16, __m256i, __m256i)>>('_mm256_mask_subs_epu16');
  late final __mm256_mask_subs_epu16 = __mm256_mask_subs_epu16Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_subs_epu16(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_subs_epu16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_subs_epu16Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__mmask16, __m256i, __m256i)>>(
      '_mm256_maskz_subs_epu16');
  late final __mm256_maskz_subs_epu16 = __mm256_maskz_subs_epu16Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  __m128i _mm_mask_subs_epu8(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_subs_epu8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_subs_epu8Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask16, __m128i, __m128i)>>('_mm_mask_subs_epu8');
  late final __mm_mask_subs_epu8 = __mm_mask_subs_epu8Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_subs_epu8(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_subs_epu8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_subs_epu8Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__mmask16, __m128i, __m128i)>>(
      '_mm_maskz_subs_epu8');
  late final __mm_maskz_subs_epu8 = __mm_maskz_subs_epu8Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_mask_subs_epu8(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_subs_epu8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_subs_epu8Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask32, __m256i, __m256i)>>('_mm256_mask_subs_epu8');
  late final __mm256_mask_subs_epu8 = __mm256_mask_subs_epu8Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_subs_epu8(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_subs_epu8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_subs_epu8Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__mmask32, __m256i, __m256i)>>(
      '_mm256_maskz_subs_epu8');
  late final __mm256_maskz_subs_epu8 = __mm256_maskz_subs_epu8Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  __m128i _mm_mask_ternarylogic_epi32(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
    int arg4,
  ) {
    return __mm_mask_ternarylogic_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_ternarylogic_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(__m128i, __mmask8, __m128i, __m128i,
              ffi.Int32)>>('_mm_mask_ternarylogic_epi32');
  late final __mm_mask_ternarylogic_epi32 = __mm_mask_ternarylogic_epi32Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i, int)>();

  __m128i _mm_maskz_ternarylogic_epi32(
    int arg0,
    __m128i arg1,
    __m128i arg2,
    __m128i arg3,
    int arg4,
  ) {
    return __mm_maskz_ternarylogic_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_maskz_ternarylogic_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(__mmask8, __m128i, __m128i, __m128i,
              ffi.Int32)>>('_mm_maskz_ternarylogic_epi32');
  late final __mm_maskz_ternarylogic_epi32 = __mm_maskz_ternarylogic_epi32Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i, __m128i, int)>();

  __m128i _mm_ternarylogic_epi32(
    __m128i arg0,
    __m128i arg1,
    __m128i arg2,
    int arg3,
  ) {
    return __mm_ternarylogic_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_ternarylogic_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __m128i, __m128i, ffi.Int32)>>('_mm_ternarylogic_epi32');
  late final __mm_ternarylogic_epi32 = __mm_ternarylogic_epi32Ptr
      .asFunction<__m128i Function(__m128i, __m128i, __m128i, int)>();

  __m256i _mm256_mask_ternarylogic_epi32(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
    int arg4,
  ) {
    return __mm256_mask_ternarylogic_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm256_mask_ternarylogic_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask8, __m256i, __m256i,
              ffi.Int32)>>('_mm256_mask_ternarylogic_epi32');
  late final __mm256_mask_ternarylogic_epi32 =
      __mm256_mask_ternarylogic_epi32Ptr
          .asFunction<__m256i Function(__m256i, int, __m256i, __m256i, int)>();

  __m256i _mm256_maskz_ternarylogic_epi32(
    int arg0,
    __m256i arg1,
    __m256i arg2,
    __m256i arg3,
    int arg4,
  ) {
    return __mm256_maskz_ternarylogic_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm256_maskz_ternarylogic_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__mmask8, __m256i, __m256i, __m256i,
              ffi.Int32)>>('_mm256_maskz_ternarylogic_epi32');
  late final __mm256_maskz_ternarylogic_epi32 =
      __mm256_maskz_ternarylogic_epi32Ptr
          .asFunction<__m256i Function(int, __m256i, __m256i, __m256i, int)>();

  __m256i _mm256_ternarylogic_epi32(
    __m256i arg0,
    __m256i arg1,
    __m256i arg2,
    int arg3,
  ) {
    return __mm256_ternarylogic_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_ternarylogic_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __m256i, __m256i,
              ffi.Int32)>>('_mm256_ternarylogic_epi32');
  late final __mm256_ternarylogic_epi32 = __mm256_ternarylogic_epi32Ptr
      .asFunction<__m256i Function(__m256i, __m256i, __m256i, int)>();

  __m128i _mm_mask_ternarylogic_epi64(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
    int arg4,
  ) {
    return __mm_mask_ternarylogic_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_ternarylogic_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(__m128i, __mmask8, __m128i, __m128i,
              ffi.Int32)>>('_mm_mask_ternarylogic_epi64');
  late final __mm_mask_ternarylogic_epi64 = __mm_mask_ternarylogic_epi64Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i, int)>();

  __m128i _mm_maskz_ternarylogic_epi64(
    int arg0,
    __m128i arg1,
    __m128i arg2,
    __m128i arg3,
    int arg4,
  ) {
    return __mm_maskz_ternarylogic_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_maskz_ternarylogic_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(__mmask8, __m128i, __m128i, __m128i,
              ffi.Int32)>>('_mm_maskz_ternarylogic_epi64');
  late final __mm_maskz_ternarylogic_epi64 = __mm_maskz_ternarylogic_epi64Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i, __m128i, int)>();

  __m128i _mm_ternarylogic_epi64(
    __m128i arg0,
    __m128i arg1,
    __m128i arg2,
    int arg3,
  ) {
    return __mm_ternarylogic_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_ternarylogic_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __m128i, __m128i, ffi.Int32)>>('_mm_ternarylogic_epi64');
  late final __mm_ternarylogic_epi64 = __mm_ternarylogic_epi64Ptr
      .asFunction<__m128i Function(__m128i, __m128i, __m128i, int)>();

  __m256i _mm256_mask_ternarylogic_epi64(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
    int arg4,
  ) {
    return __mm256_mask_ternarylogic_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm256_mask_ternarylogic_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask8, __m256i, __m256i,
              ffi.Int32)>>('_mm256_mask_ternarylogic_epi64');
  late final __mm256_mask_ternarylogic_epi64 =
      __mm256_mask_ternarylogic_epi64Ptr
          .asFunction<__m256i Function(__m256i, int, __m256i, __m256i, int)>();

  __m256i _mm256_maskz_ternarylogic_epi64(
    int arg0,
    __m256i arg1,
    __m256i arg2,
    __m256i arg3,
    int arg4,
  ) {
    return __mm256_maskz_ternarylogic_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm256_maskz_ternarylogic_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__mmask8, __m256i, __m256i, __m256i,
              ffi.Int32)>>('_mm256_maskz_ternarylogic_epi64');
  late final __mm256_maskz_ternarylogic_epi64 =
      __mm256_maskz_ternarylogic_epi64Ptr
          .asFunction<__m256i Function(int, __m256i, __m256i, __m256i, int)>();

  __m256i _mm256_ternarylogic_epi64(
    __m256i arg0,
    __m256i arg1,
    __m256i arg2,
    int arg3,
  ) {
    return __mm256_ternarylogic_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_ternarylogic_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __m256i, __m256i,
              ffi.Int32)>>('_mm256_ternarylogic_epi64');
  late final __mm256_ternarylogic_epi64 = __mm256_ternarylogic_epi64Ptr
      .asFunction<__m256i Function(__m256i, __m256i, __m256i, int)>();

  int _mm_mask_test_epi16_mask(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_mask_test_epi16_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_test_epi16_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m128i, __m128i)>>(
      '_mm_mask_test_epi16_mask');
  late final __mm_mask_test_epi16_mask = __mm_mask_test_epi16_maskPtr
      .asFunction<int Function(int, __m128i, __m128i)>();

  int _mm_test_epi16_mask(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_test_epi16_mask(
      arg0,
      arg1,
    );
  }

  late final __mm_test_epi16_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m128i, __m128i)>>(
          '_mm_test_epi16_mask');
  late final __mm_test_epi16_mask =
      __mm_test_epi16_maskPtr.asFunction<int Function(__m128i, __m128i)>();

  int _mm256_mask_test_epi16_mask(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_test_epi16_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_test_epi16_maskPtr = _lookup<
          ffi.NativeFunction<__mmask16 Function(__mmask16, __m256i, __m256i)>>(
      '_mm256_mask_test_epi16_mask');
  late final __mm256_mask_test_epi16_mask = __mm256_mask_test_epi16_maskPtr
      .asFunction<int Function(int, __m256i, __m256i)>();

  int _mm256_test_epi16_mask(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_test_epi16_mask(
      arg0,
      arg1,
    );
  }

  late final __mm256_test_epi16_maskPtr =
      _lookup<ffi.NativeFunction<__mmask16 Function(__m256i, __m256i)>>(
          '_mm256_test_epi16_mask');
  late final __mm256_test_epi16_mask =
      __mm256_test_epi16_maskPtr.asFunction<int Function(__m256i, __m256i)>();

  int _mm_mask_test_epi32_mask(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_mask_test_epi32_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_test_epi32_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m128i, __m128i)>>(
      '_mm_mask_test_epi32_mask');
  late final __mm_mask_test_epi32_mask = __mm_mask_test_epi32_maskPtr
      .asFunction<int Function(int, __m128i, __m128i)>();

  int _mm_test_epi32_mask(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_test_epi32_mask(
      arg0,
      arg1,
    );
  }

  late final __mm_test_epi32_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m128i, __m128i)>>(
          '_mm_test_epi32_mask');
  late final __mm_test_epi32_mask =
      __mm_test_epi32_maskPtr.asFunction<int Function(__m128i, __m128i)>();

  int _mm256_mask_test_epi32_mask(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_test_epi32_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_test_epi32_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m256i, __m256i)>>(
      '_mm256_mask_test_epi32_mask');
  late final __mm256_mask_test_epi32_mask = __mm256_mask_test_epi32_maskPtr
      .asFunction<int Function(int, __m256i, __m256i)>();

  int _mm256_test_epi32_mask(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_test_epi32_mask(
      arg0,
      arg1,
    );
  }

  late final __mm256_test_epi32_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m256i, __m256i)>>(
          '_mm256_test_epi32_mask');
  late final __mm256_test_epi32_mask =
      __mm256_test_epi32_maskPtr.asFunction<int Function(__m256i, __m256i)>();

  int _mm_mask_test_epi64_mask(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_mask_test_epi64_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_test_epi64_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m128i, __m128i)>>(
      '_mm_mask_test_epi64_mask');
  late final __mm_mask_test_epi64_mask = __mm_mask_test_epi64_maskPtr
      .asFunction<int Function(int, __m128i, __m128i)>();

  int _mm_test_epi64_mask(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_test_epi64_mask(
      arg0,
      arg1,
    );
  }

  late final __mm_test_epi64_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m128i, __m128i)>>(
          '_mm_test_epi64_mask');
  late final __mm_test_epi64_mask =
      __mm_test_epi64_maskPtr.asFunction<int Function(__m128i, __m128i)>();

  int _mm256_mask_test_epi64_mask(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_test_epi64_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_test_epi64_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m256i, __m256i)>>(
      '_mm256_mask_test_epi64_mask');
  late final __mm256_mask_test_epi64_mask = __mm256_mask_test_epi64_maskPtr
      .asFunction<int Function(int, __m256i, __m256i)>();

  int _mm256_test_epi64_mask(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_test_epi64_mask(
      arg0,
      arg1,
    );
  }

  late final __mm256_test_epi64_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m256i, __m256i)>>(
          '_mm256_test_epi64_mask');
  late final __mm256_test_epi64_mask =
      __mm256_test_epi64_maskPtr.asFunction<int Function(__m256i, __m256i)>();

  int _mm_mask_test_epi8_mask(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_mask_test_epi8_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_test_epi8_maskPtr = _lookup<
          ffi.NativeFunction<__mmask16 Function(__mmask16, __m128i, __m128i)>>(
      '_mm_mask_test_epi8_mask');
  late final __mm_mask_test_epi8_mask = __mm_mask_test_epi8_maskPtr
      .asFunction<int Function(int, __m128i, __m128i)>();

  int _mm_test_epi8_mask(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_test_epi8_mask(
      arg0,
      arg1,
    );
  }

  late final __mm_test_epi8_maskPtr =
      _lookup<ffi.NativeFunction<__mmask16 Function(__m128i, __m128i)>>(
          '_mm_test_epi8_mask');
  late final __mm_test_epi8_mask =
      __mm_test_epi8_maskPtr.asFunction<int Function(__m128i, __m128i)>();

  int _mm256_mask_test_epi8_mask(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_test_epi8_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_test_epi8_maskPtr = _lookup<
          ffi.NativeFunction<__mmask32 Function(__mmask32, __m256i, __m256i)>>(
      '_mm256_mask_test_epi8_mask');
  late final __mm256_mask_test_epi8_mask = __mm256_mask_test_epi8_maskPtr
      .asFunction<int Function(int, __m256i, __m256i)>();

  int _mm256_test_epi8_mask(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_test_epi8_mask(
      arg0,
      arg1,
    );
  }

  late final __mm256_test_epi8_maskPtr =
      _lookup<ffi.NativeFunction<__mmask32 Function(__m256i, __m256i)>>(
          '_mm256_test_epi8_mask');
  late final __mm256_test_epi8_mask =
      __mm256_test_epi8_maskPtr.asFunction<int Function(__m256i, __m256i)>();

  int _mm_mask_testn_epi16_mask(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_mask_testn_epi16_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_testn_epi16_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m128i, __m128i)>>(
      '_mm_mask_testn_epi16_mask');
  late final __mm_mask_testn_epi16_mask = __mm_mask_testn_epi16_maskPtr
      .asFunction<int Function(int, __m128i, __m128i)>();

  int _mm_testn_epi16_mask(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_testn_epi16_mask(
      arg0,
      arg1,
    );
  }

  late final __mm_testn_epi16_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m128i, __m128i)>>(
          '_mm_testn_epi16_mask');
  late final __mm_testn_epi16_mask =
      __mm_testn_epi16_maskPtr.asFunction<int Function(__m128i, __m128i)>();

  int _mm256_mask_testn_epi16_mask(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_testn_epi16_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_testn_epi16_maskPtr = _lookup<
          ffi.NativeFunction<__mmask16 Function(__mmask16, __m256i, __m256i)>>(
      '_mm256_mask_testn_epi16_mask');
  late final __mm256_mask_testn_epi16_mask = __mm256_mask_testn_epi16_maskPtr
      .asFunction<int Function(int, __m256i, __m256i)>();

  int _mm256_testn_epi16_mask(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_testn_epi16_mask(
      arg0,
      arg1,
    );
  }

  late final __mm256_testn_epi16_maskPtr =
      _lookup<ffi.NativeFunction<__mmask16 Function(__m256i, __m256i)>>(
          '_mm256_testn_epi16_mask');
  late final __mm256_testn_epi16_mask =
      __mm256_testn_epi16_maskPtr.asFunction<int Function(__m256i, __m256i)>();

  int _mm_mask_testn_epi32_mask(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_mask_testn_epi32_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_testn_epi32_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m128i, __m128i)>>(
      '_mm_mask_testn_epi32_mask');
  late final __mm_mask_testn_epi32_mask = __mm_mask_testn_epi32_maskPtr
      .asFunction<int Function(int, __m128i, __m128i)>();

  int _mm_testn_epi32_mask(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_testn_epi32_mask(
      arg0,
      arg1,
    );
  }

  late final __mm_testn_epi32_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m128i, __m128i)>>(
          '_mm_testn_epi32_mask');
  late final __mm_testn_epi32_mask =
      __mm_testn_epi32_maskPtr.asFunction<int Function(__m128i, __m128i)>();

  int _mm256_mask_testn_epi32_mask(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_testn_epi32_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_testn_epi32_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m256i, __m256i)>>(
      '_mm256_mask_testn_epi32_mask');
  late final __mm256_mask_testn_epi32_mask = __mm256_mask_testn_epi32_maskPtr
      .asFunction<int Function(int, __m256i, __m256i)>();

  int _mm256_testn_epi32_mask(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_testn_epi32_mask(
      arg0,
      arg1,
    );
  }

  late final __mm256_testn_epi32_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m256i, __m256i)>>(
          '_mm256_testn_epi32_mask');
  late final __mm256_testn_epi32_mask =
      __mm256_testn_epi32_maskPtr.asFunction<int Function(__m256i, __m256i)>();

  int _mm_mask_testn_epi64_mask(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_mask_testn_epi64_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_testn_epi64_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m128i, __m128i)>>(
      '_mm_mask_testn_epi64_mask');
  late final __mm_mask_testn_epi64_mask = __mm_mask_testn_epi64_maskPtr
      .asFunction<int Function(int, __m128i, __m128i)>();

  int _mm_testn_epi64_mask(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_testn_epi64_mask(
      arg0,
      arg1,
    );
  }

  late final __mm_testn_epi64_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m128i, __m128i)>>(
          '_mm_testn_epi64_mask');
  late final __mm_testn_epi64_mask =
      __mm_testn_epi64_maskPtr.asFunction<int Function(__m128i, __m128i)>();

  int _mm256_mask_testn_epi64_mask(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_testn_epi64_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_testn_epi64_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m256i, __m256i)>>(
      '_mm256_mask_testn_epi64_mask');
  late final __mm256_mask_testn_epi64_mask = __mm256_mask_testn_epi64_maskPtr
      .asFunction<int Function(int, __m256i, __m256i)>();

  int _mm256_testn_epi64_mask(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_testn_epi64_mask(
      arg0,
      arg1,
    );
  }

  late final __mm256_testn_epi64_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m256i, __m256i)>>(
          '_mm256_testn_epi64_mask');
  late final __mm256_testn_epi64_mask =
      __mm256_testn_epi64_maskPtr.asFunction<int Function(__m256i, __m256i)>();

  int _mm_mask_testn_epi8_mask(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_mask_testn_epi8_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_testn_epi8_maskPtr = _lookup<
          ffi.NativeFunction<__mmask16 Function(__mmask16, __m128i, __m128i)>>(
      '_mm_mask_testn_epi8_mask');
  late final __mm_mask_testn_epi8_mask = __mm_mask_testn_epi8_maskPtr
      .asFunction<int Function(int, __m128i, __m128i)>();

  int _mm_testn_epi8_mask(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_testn_epi8_mask(
      arg0,
      arg1,
    );
  }

  late final __mm_testn_epi8_maskPtr =
      _lookup<ffi.NativeFunction<__mmask16 Function(__m128i, __m128i)>>(
          '_mm_testn_epi8_mask');
  late final __mm_testn_epi8_mask =
      __mm_testn_epi8_maskPtr.asFunction<int Function(__m128i, __m128i)>();

  int _mm256_mask_testn_epi8_mask(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_testn_epi8_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_testn_epi8_maskPtr = _lookup<
          ffi.NativeFunction<__mmask32 Function(__mmask32, __m256i, __m256i)>>(
      '_mm256_mask_testn_epi8_mask');
  late final __mm256_mask_testn_epi8_mask = __mm256_mask_testn_epi8_maskPtr
      .asFunction<int Function(int, __m256i, __m256i)>();

  int _mm256_testn_epi8_mask(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_testn_epi8_mask(
      arg0,
      arg1,
    );
  }

  late final __mm256_testn_epi8_maskPtr =
      _lookup<ffi.NativeFunction<__mmask32 Function(__m256i, __m256i)>>(
          '_mm256_testn_epi8_mask');
  late final __mm256_testn_epi8_mask =
      __mm256_testn_epi8_maskPtr.asFunction<int Function(__m256i, __m256i)>();

  __m128i _mm_mask_unpackhi_epi16(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_unpackhi_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_unpackhi_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_unpackhi_epi16');
  late final __mm_mask_unpackhi_epi16 = __mm_mask_unpackhi_epi16Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_unpackhi_epi16(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_unpackhi_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_unpackhi_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_maskz_unpackhi_epi16');
  late final __mm_maskz_unpackhi_epi16 = __mm_maskz_unpackhi_epi16Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_mask_unpackhi_epi16(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_unpackhi_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_unpackhi_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask16, __m256i,
              __m256i)>>('_mm256_mask_unpackhi_epi16');
  late final __mm256_mask_unpackhi_epi16 = __mm256_mask_unpackhi_epi16Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_unpackhi_epi16(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_unpackhi_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_unpackhi_epi16Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__mmask16, __m256i, __m256i)>>(
      '_mm256_maskz_unpackhi_epi16');
  late final __mm256_maskz_unpackhi_epi16 = __mm256_maskz_unpackhi_epi16Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  __m128i _mm_mask_unpackhi_epi32(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_unpackhi_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_unpackhi_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_unpackhi_epi32');
  late final __mm_mask_unpackhi_epi32 = __mm_mask_unpackhi_epi32Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_unpackhi_epi32(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_unpackhi_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_unpackhi_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_maskz_unpackhi_epi32');
  late final __mm_maskz_unpackhi_epi32 = __mm_maskz_unpackhi_epi32Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_mask_unpackhi_epi32(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_unpackhi_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_unpackhi_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask8, __m256i,
              __m256i)>>('_mm256_mask_unpackhi_epi32');
  late final __mm256_mask_unpackhi_epi32 = __mm256_mask_unpackhi_epi32Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_unpackhi_epi32(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_unpackhi_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_unpackhi_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m256i, __m256i)>>(
          '_mm256_maskz_unpackhi_epi32');
  late final __mm256_maskz_unpackhi_epi32 = __mm256_maskz_unpackhi_epi32Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  __m128i _mm_mask_unpackhi_epi64(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_unpackhi_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_unpackhi_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_unpackhi_epi64');
  late final __mm_mask_unpackhi_epi64 = __mm_mask_unpackhi_epi64Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_unpackhi_epi64(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_unpackhi_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_unpackhi_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_maskz_unpackhi_epi64');
  late final __mm_maskz_unpackhi_epi64 = __mm_maskz_unpackhi_epi64Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_mask_unpackhi_epi64(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_unpackhi_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_unpackhi_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask8, __m256i,
              __m256i)>>('_mm256_mask_unpackhi_epi64');
  late final __mm256_mask_unpackhi_epi64 = __mm256_mask_unpackhi_epi64Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_unpackhi_epi64(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_unpackhi_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_unpackhi_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m256i, __m256i)>>(
          '_mm256_maskz_unpackhi_epi64');
  late final __mm256_maskz_unpackhi_epi64 = __mm256_maskz_unpackhi_epi64Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  __m128i _mm_mask_unpackhi_epi8(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_unpackhi_epi8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_unpackhi_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask16, __m128i, __m128i)>>('_mm_mask_unpackhi_epi8');
  late final __mm_mask_unpackhi_epi8 = __mm_mask_unpackhi_epi8Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_unpackhi_epi8(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_unpackhi_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_unpackhi_epi8Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__mmask16, __m128i, __m128i)>>(
      '_mm_maskz_unpackhi_epi8');
  late final __mm_maskz_unpackhi_epi8 = __mm_maskz_unpackhi_epi8Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_mask_unpackhi_epi8(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_unpackhi_epi8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_unpackhi_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask32, __m256i,
              __m256i)>>('_mm256_mask_unpackhi_epi8');
  late final __mm256_mask_unpackhi_epi8 = __mm256_mask_unpackhi_epi8Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_unpackhi_epi8(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_unpackhi_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_unpackhi_epi8Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__mmask32, __m256i, __m256i)>>(
      '_mm256_maskz_unpackhi_epi8');
  late final __mm256_maskz_unpackhi_epi8 = __mm256_maskz_unpackhi_epi8Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  _m128d _mm_mask_unpackhi_pd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    _m128d arg3,
  ) {
    return __mm_mask_unpackhi_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_unpackhi_pdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              _m128d, __mmask8, _m128d, _m128d)>>('_mm_mask_unpackhi_pd');
  late final __mm_mask_unpackhi_pd = __mm_mask_unpackhi_pdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d, _m128d)>();

  _m128d _mm_maskz_unpackhi_pd(
    int arg0,
    _m128d arg1,
    _m128d arg2,
  ) {
    return __mm_maskz_unpackhi_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_unpackhi_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(__mmask8, _m128d, _m128d)>>(
          '_mm_maskz_unpackhi_pd');
  late final __mm_maskz_unpackhi_pd = __mm_maskz_unpackhi_pdPtr
      .asFunction<_m128d Function(int, _m128d, _m128d)>();

  _m256d _mm256_mask_unpackhi_pd(
    _m256d arg0,
    int arg1,
    _m256d arg2,
    _m256d arg3,
  ) {
    return __mm256_mask_unpackhi_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_unpackhi_pdPtr = _lookup<
      ffi.NativeFunction<
          _m256d Function(
              _m256d, __mmask8, _m256d, _m256d)>>('_mm256_mask_unpackhi_pd');
  late final __mm256_mask_unpackhi_pd = __mm256_mask_unpackhi_pdPtr
      .asFunction<_m256d Function(_m256d, int, _m256d, _m256d)>();

  _m256d _mm256_maskz_unpackhi_pd(
    int arg0,
    _m256d arg1,
    _m256d arg2,
  ) {
    return __mm256_maskz_unpackhi_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_unpackhi_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(__mmask8, _m256d, _m256d)>>(
          '_mm256_maskz_unpackhi_pd');
  late final __mm256_maskz_unpackhi_pd = __mm256_maskz_unpackhi_pdPtr
      .asFunction<_m256d Function(int, _m256d, _m256d)>();

  __m128 _mm_mask_unpackhi_ps(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    __m128 arg3,
  ) {
    return __mm_mask_unpackhi_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_unpackhi_psPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __m128, __mmask8, __m128, __m128)>>('_mm_mask_unpackhi_ps');
  late final __mm_mask_unpackhi_ps = __mm_mask_unpackhi_psPtr
      .asFunction<__m128 Function(__m128, int, __m128, __m128)>();

  __m128 _mm_maskz_unpackhi_ps(
    int arg0,
    __m128 arg1,
    __m128 arg2,
  ) {
    return __mm_maskz_unpackhi_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_unpackhi_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__mmask8, __m128, __m128)>>(
          '_mm_maskz_unpackhi_ps');
  late final __mm_maskz_unpackhi_ps = __mm_maskz_unpackhi_psPtr
      .asFunction<__m128 Function(int, __m128, __m128)>();

  __m256 _mm256_mask_unpackhi_ps(
    __m256 arg0,
    int arg1,
    __m256 arg2,
    __m256 arg3,
  ) {
    return __mm256_mask_unpackhi_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_unpackhi_psPtr = _lookup<
      ffi.NativeFunction<
          __m256 Function(
              __m256, __mmask8, __m256, __m256)>>('_mm256_mask_unpackhi_ps');
  late final __mm256_mask_unpackhi_ps = __mm256_mask_unpackhi_psPtr
      .asFunction<__m256 Function(__m256, int, __m256, __m256)>();

  __m256 _mm256_maskz_unpackhi_ps(
    int arg0,
    __m256 arg1,
    __m256 arg2,
  ) {
    return __mm256_maskz_unpackhi_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_unpackhi_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__mmask8, __m256, __m256)>>(
          '_mm256_maskz_unpackhi_ps');
  late final __mm256_maskz_unpackhi_ps = __mm256_maskz_unpackhi_psPtr
      .asFunction<__m256 Function(int, __m256, __m256)>();

  __m128i _mm_mask_unpacklo_epi16(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_unpacklo_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_unpacklo_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_unpacklo_epi16');
  late final __mm_mask_unpacklo_epi16 = __mm_mask_unpacklo_epi16Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_unpacklo_epi16(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_unpacklo_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_unpacklo_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_maskz_unpacklo_epi16');
  late final __mm_maskz_unpacklo_epi16 = __mm_maskz_unpacklo_epi16Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_mask_unpacklo_epi16(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_unpacklo_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_unpacklo_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask16, __m256i,
              __m256i)>>('_mm256_mask_unpacklo_epi16');
  late final __mm256_mask_unpacklo_epi16 = __mm256_mask_unpacklo_epi16Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_unpacklo_epi16(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_unpacklo_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_unpacklo_epi16Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__mmask16, __m256i, __m256i)>>(
      '_mm256_maskz_unpacklo_epi16');
  late final __mm256_maskz_unpacklo_epi16 = __mm256_maskz_unpacklo_epi16Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  __m128i _mm_mask_unpacklo_epi32(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_unpacklo_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_unpacklo_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_unpacklo_epi32');
  late final __mm_mask_unpacklo_epi32 = __mm_mask_unpacklo_epi32Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_unpacklo_epi32(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_unpacklo_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_unpacklo_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_maskz_unpacklo_epi32');
  late final __mm_maskz_unpacklo_epi32 = __mm_maskz_unpacklo_epi32Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_mask_unpacklo_epi32(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_unpacklo_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_unpacklo_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask8, __m256i,
              __m256i)>>('_mm256_mask_unpacklo_epi32');
  late final __mm256_mask_unpacklo_epi32 = __mm256_mask_unpacklo_epi32Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_unpacklo_epi32(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_unpacklo_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_unpacklo_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m256i, __m256i)>>(
          '_mm256_maskz_unpacklo_epi32');
  late final __mm256_maskz_unpacklo_epi32 = __mm256_maskz_unpacklo_epi32Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  __m128i _mm_mask_unpacklo_epi64(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_unpacklo_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_unpacklo_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_unpacklo_epi64');
  late final __mm_mask_unpacklo_epi64 = __mm_mask_unpacklo_epi64Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_unpacklo_epi64(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_unpacklo_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_unpacklo_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_maskz_unpacklo_epi64');
  late final __mm_maskz_unpacklo_epi64 = __mm_maskz_unpacklo_epi64Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_mask_unpacklo_epi64(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_unpacklo_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_unpacklo_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask8, __m256i,
              __m256i)>>('_mm256_mask_unpacklo_epi64');
  late final __mm256_mask_unpacklo_epi64 = __mm256_mask_unpacklo_epi64Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_unpacklo_epi64(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_unpacklo_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_unpacklo_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m256i, __m256i)>>(
          '_mm256_maskz_unpacklo_epi64');
  late final __mm256_maskz_unpacklo_epi64 = __mm256_maskz_unpacklo_epi64Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  __m128i _mm_mask_unpacklo_epi8(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_unpacklo_epi8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_unpacklo_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask16, __m128i, __m128i)>>('_mm_mask_unpacklo_epi8');
  late final __mm_mask_unpacklo_epi8 = __mm_mask_unpacklo_epi8Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_unpacklo_epi8(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_unpacklo_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_unpacklo_epi8Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__mmask16, __m128i, __m128i)>>(
      '_mm_maskz_unpacklo_epi8');
  late final __mm_maskz_unpacklo_epi8 = __mm_maskz_unpacklo_epi8Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_mask_unpacklo_epi8(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_unpacklo_epi8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_unpacklo_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask32, __m256i,
              __m256i)>>('_mm256_mask_unpacklo_epi8');
  late final __mm256_mask_unpacklo_epi8 = __mm256_mask_unpacklo_epi8Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_unpacklo_epi8(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_unpacklo_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_unpacklo_epi8Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__mmask32, __m256i, __m256i)>>(
      '_mm256_maskz_unpacklo_epi8');
  late final __mm256_maskz_unpacklo_epi8 = __mm256_maskz_unpacklo_epi8Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  _m128d _mm_mask_unpacklo_pd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    _m128d arg3,
  ) {
    return __mm_mask_unpacklo_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_unpacklo_pdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              _m128d, __mmask8, _m128d, _m128d)>>('_mm_mask_unpacklo_pd');
  late final __mm_mask_unpacklo_pd = __mm_mask_unpacklo_pdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d, _m128d)>();

  _m128d _mm_maskz_unpacklo_pd(
    int arg0,
    _m128d arg1,
    _m128d arg2,
  ) {
    return __mm_maskz_unpacklo_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_unpacklo_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(__mmask8, _m128d, _m128d)>>(
          '_mm_maskz_unpacklo_pd');
  late final __mm_maskz_unpacklo_pd = __mm_maskz_unpacklo_pdPtr
      .asFunction<_m128d Function(int, _m128d, _m128d)>();

  _m256d _mm256_mask_unpacklo_pd(
    _m256d arg0,
    int arg1,
    _m256d arg2,
    _m256d arg3,
  ) {
    return __mm256_mask_unpacklo_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_unpacklo_pdPtr = _lookup<
      ffi.NativeFunction<
          _m256d Function(
              _m256d, __mmask8, _m256d, _m256d)>>('_mm256_mask_unpacklo_pd');
  late final __mm256_mask_unpacklo_pd = __mm256_mask_unpacklo_pdPtr
      .asFunction<_m256d Function(_m256d, int, _m256d, _m256d)>();

  _m256d _mm256_maskz_unpacklo_pd(
    int arg0,
    _m256d arg1,
    _m256d arg2,
  ) {
    return __mm256_maskz_unpacklo_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_unpacklo_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(__mmask8, _m256d, _m256d)>>(
          '_mm256_maskz_unpacklo_pd');
  late final __mm256_maskz_unpacklo_pd = __mm256_maskz_unpacklo_pdPtr
      .asFunction<_m256d Function(int, _m256d, _m256d)>();

  __m128 _mm_mask_unpacklo_ps(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    __m128 arg3,
  ) {
    return __mm_mask_unpacklo_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_unpacklo_psPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __m128, __mmask8, __m128, __m128)>>('_mm_mask_unpacklo_ps');
  late final __mm_mask_unpacklo_ps = __mm_mask_unpacklo_psPtr
      .asFunction<__m128 Function(__m128, int, __m128, __m128)>();

  __m128 _mm_maskz_unpacklo_ps(
    int arg0,
    __m128 arg1,
    __m128 arg2,
  ) {
    return __mm_maskz_unpacklo_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_unpacklo_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__mmask8, __m128, __m128)>>(
          '_mm_maskz_unpacklo_ps');
  late final __mm_maskz_unpacklo_ps = __mm_maskz_unpacklo_psPtr
      .asFunction<__m128 Function(int, __m128, __m128)>();

  __m256 _mm256_mask_unpacklo_ps(
    __m256 arg0,
    int arg1,
    __m256 arg2,
    __m256 arg3,
  ) {
    return __mm256_mask_unpacklo_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_unpacklo_psPtr = _lookup<
      ffi.NativeFunction<
          __m256 Function(
              __m256, __mmask8, __m256, __m256)>>('_mm256_mask_unpacklo_ps');
  late final __mm256_mask_unpacklo_ps = __mm256_mask_unpacklo_psPtr
      .asFunction<__m256 Function(__m256, int, __m256, __m256)>();

  __m256 _mm256_maskz_unpacklo_ps(
    int arg0,
    __m256 arg1,
    __m256 arg2,
  ) {
    return __mm256_maskz_unpacklo_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_unpacklo_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__mmask8, __m256, __m256)>>(
          '_mm256_maskz_unpacklo_ps');
  late final __mm256_maskz_unpacklo_ps = __mm256_maskz_unpacklo_psPtr
      .asFunction<__m256 Function(int, __m256, __m256)>();

  __m128i _mm_xor_epi32(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_xor_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm_xor_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_xor_epi32');
  late final __mm_xor_epi32 =
      __mm_xor_epi32Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_mask_xor_epi32(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_xor_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_xor_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_xor_epi32');
  late final __mm_mask_xor_epi32 = __mm_mask_xor_epi32Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_xor_epi32(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_xor_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_xor_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_maskz_xor_epi32');
  late final __mm_maskz_xor_epi32 = __mm_maskz_xor_epi32Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_xor_epi32(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_xor_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm256_xor_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_xor_epi32');
  late final __mm256_xor_epi32 =
      __mm256_xor_epi32Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_mask_xor_epi32(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_xor_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_xor_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask8, __m256i, __m256i)>>('_mm256_mask_xor_epi32');
  late final __mm256_mask_xor_epi32 = __mm256_mask_xor_epi32Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_xor_epi32(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_xor_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_xor_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m256i, __m256i)>>(
          '_mm256_maskz_xor_epi32');
  late final __mm256_maskz_xor_epi32 = __mm256_maskz_xor_epi32Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  __m128i _mm_xor_epi64(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_xor_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm_xor_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_xor_epi64');
  late final __mm_xor_epi64 =
      __mm_xor_epi64Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_mask_xor_epi64(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_xor_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_xor_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_xor_epi64');
  late final __mm_mask_xor_epi64 = __mm_mask_xor_epi64Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_xor_epi64(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_xor_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_xor_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i, __m128i)>>(
          '_mm_maskz_xor_epi64');
  late final __mm_maskz_xor_epi64 = __mm_maskz_xor_epi64Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_xor_epi64(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_xor_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm256_xor_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_xor_epi64');
  late final __mm256_xor_epi64 =
      __mm256_xor_epi64Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_mask_xor_epi64(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_xor_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_xor_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask8, __m256i, __m256i)>>('_mm256_mask_xor_epi64');
  late final __mm256_mask_xor_epi64 = __mm256_mask_xor_epi64Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_xor_epi64(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_xor_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_xor_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m256i, __m256i)>>(
          '_mm256_maskz_xor_epi64');
  late final __mm256_maskz_xor_epi64 = __mm256_maskz_xor_epi64Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  _m128d _mm_mask_xor_pd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    _m128d arg3,
  ) {
    return __mm_mask_xor_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_xor_pdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              _m128d, __mmask8, _m128d, _m128d)>>('_mm_mask_xor_pd');
  late final __mm_mask_xor_pd = __mm_mask_xor_pdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d, _m128d)>();

  _m128d _mm_maskz_xor_pd(
    int arg0,
    _m128d arg1,
    _m128d arg2,
  ) {
    return __mm_maskz_xor_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_xor_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(__mmask8, _m128d, _m128d)>>(
          '_mm_maskz_xor_pd');
  late final __mm_maskz_xor_pd =
      __mm_maskz_xor_pdPtr.asFunction<_m128d Function(int, _m128d, _m128d)>();

  _m256d _mm256_mask_xor_pd(
    _m256d arg0,
    int arg1,
    _m256d arg2,
    _m256d arg3,
  ) {
    return __mm256_mask_xor_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_xor_pdPtr = _lookup<
      ffi.NativeFunction<
          _m256d Function(
              _m256d, __mmask8, _m256d, _m256d)>>('_mm256_mask_xor_pd');
  late final __mm256_mask_xor_pd = __mm256_mask_xor_pdPtr
      .asFunction<_m256d Function(_m256d, int, _m256d, _m256d)>();

  _m256d _mm256_maskz_xor_pd(
    int arg0,
    _m256d arg1,
    _m256d arg2,
  ) {
    return __mm256_maskz_xor_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_xor_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(__mmask8, _m256d, _m256d)>>(
          '_mm256_maskz_xor_pd');
  late final __mm256_maskz_xor_pd = __mm256_maskz_xor_pdPtr
      .asFunction<_m256d Function(int, _m256d, _m256d)>();

  __m128 _mm_mask_xor_ps(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    __m128 arg3,
  ) {
    return __mm_mask_xor_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_xor_psPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __m128, __mmask8, __m128, __m128)>>('_mm_mask_xor_ps');
  late final __mm_mask_xor_ps = __mm_mask_xor_psPtr
      .asFunction<__m128 Function(__m128, int, __m128, __m128)>();

  __m128 _mm_maskz_xor_ps(
    int arg0,
    __m128 arg1,
    __m128 arg2,
  ) {
    return __mm_maskz_xor_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_xor_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__mmask8, __m128, __m128)>>(
          '_mm_maskz_xor_ps');
  late final __mm_maskz_xor_ps =
      __mm_maskz_xor_psPtr.asFunction<__m128 Function(int, __m128, __m128)>();

  __m256 _mm256_mask_xor_ps(
    __m256 arg0,
    int arg1,
    __m256 arg2,
    __m256 arg3,
  ) {
    return __mm256_mask_xor_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_xor_psPtr = _lookup<
      ffi.NativeFunction<
          __m256 Function(
              __m256, __mmask8, __m256, __m256)>>('_mm256_mask_xor_ps');
  late final __mm256_mask_xor_ps = __mm256_mask_xor_psPtr
      .asFunction<__m256 Function(__m256, int, __m256, __m256)>();

  __m256 _mm256_maskz_xor_ps(
    int arg0,
    __m256 arg1,
    __m256 arg2,
  ) {
    return __mm256_maskz_xor_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_xor_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__mmask8, __m256, __m256)>>(
          '_mm256_maskz_xor_ps');
  late final __mm256_maskz_xor_ps = __mm256_maskz_xor_psPtr
      .asFunction<__m256 Function(int, __m256, __m256)>();

  int _mm_cmpeq_epi8_mask(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_cmpeq_epi8_mask(
      arg0,
      arg1,
    );
  }

  late final __mm_cmpeq_epi8_maskPtr =
      _lookup<ffi.NativeFunction<__mmask16 Function(__m128i, __m128i)>>(
          '_mm_cmpeq_epi8_mask');
  late final __mm_cmpeq_epi8_mask =
      __mm_cmpeq_epi8_maskPtr.asFunction<int Function(__m128i, __m128i)>();

  int _mm_cmpge_epi8_mask(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_cmpge_epi8_mask(
      arg0,
      arg1,
    );
  }

  late final __mm_cmpge_epi8_maskPtr =
      _lookup<ffi.NativeFunction<__mmask16 Function(__m128i, __m128i)>>(
          '_mm_cmpge_epi8_mask');
  late final __mm_cmpge_epi8_mask =
      __mm_cmpge_epi8_maskPtr.asFunction<int Function(__m128i, __m128i)>();

  int _mm_cmpgt_epi8_mask(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_cmpgt_epi8_mask(
      arg0,
      arg1,
    );
  }

  late final __mm_cmpgt_epi8_maskPtr =
      _lookup<ffi.NativeFunction<__mmask16 Function(__m128i, __m128i)>>(
          '_mm_cmpgt_epi8_mask');
  late final __mm_cmpgt_epi8_mask =
      __mm_cmpgt_epi8_maskPtr.asFunction<int Function(__m128i, __m128i)>();

  int _mm_cmple_epi8_mask(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_cmple_epi8_mask(
      arg0,
      arg1,
    );
  }

  late final __mm_cmple_epi8_maskPtr =
      _lookup<ffi.NativeFunction<__mmask16 Function(__m128i, __m128i)>>(
          '_mm_cmple_epi8_mask');
  late final __mm_cmple_epi8_mask =
      __mm_cmple_epi8_maskPtr.asFunction<int Function(__m128i, __m128i)>();

  int _mm_cmplt_epi8_mask(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_cmplt_epi8_mask(
      arg0,
      arg1,
    );
  }

  late final __mm_cmplt_epi8_maskPtr =
      _lookup<ffi.NativeFunction<__mmask16 Function(__m128i, __m128i)>>(
          '_mm_cmplt_epi8_mask');
  late final __mm_cmplt_epi8_mask =
      __mm_cmplt_epi8_maskPtr.asFunction<int Function(__m128i, __m128i)>();

  int _mm_cmpneq_epi8_mask(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_cmpneq_epi8_mask(
      arg0,
      arg1,
    );
  }

  late final __mm_cmpneq_epi8_maskPtr =
      _lookup<ffi.NativeFunction<__mmask16 Function(__m128i, __m128i)>>(
          '_mm_cmpneq_epi8_mask');
  late final __mm_cmpneq_epi8_mask =
      __mm_cmpneq_epi8_maskPtr.asFunction<int Function(__m128i, __m128i)>();

  int _mm_cmpeq_epu8_mask(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_cmpeq_epu8_mask(
      arg0,
      arg1,
    );
  }

  late final __mm_cmpeq_epu8_maskPtr =
      _lookup<ffi.NativeFunction<__mmask16 Function(__m128i, __m128i)>>(
          '_mm_cmpeq_epu8_mask');
  late final __mm_cmpeq_epu8_mask =
      __mm_cmpeq_epu8_maskPtr.asFunction<int Function(__m128i, __m128i)>();

  int _mm_cmpge_epu8_mask(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_cmpge_epu8_mask(
      arg0,
      arg1,
    );
  }

  late final __mm_cmpge_epu8_maskPtr =
      _lookup<ffi.NativeFunction<__mmask16 Function(__m128i, __m128i)>>(
          '_mm_cmpge_epu8_mask');
  late final __mm_cmpge_epu8_mask =
      __mm_cmpge_epu8_maskPtr.asFunction<int Function(__m128i, __m128i)>();

  int _mm_cmpgt_epu8_mask(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_cmpgt_epu8_mask(
      arg0,
      arg1,
    );
  }

  late final __mm_cmpgt_epu8_maskPtr =
      _lookup<ffi.NativeFunction<__mmask16 Function(__m128i, __m128i)>>(
          '_mm_cmpgt_epu8_mask');
  late final __mm_cmpgt_epu8_mask =
      __mm_cmpgt_epu8_maskPtr.asFunction<int Function(__m128i, __m128i)>();

  int _mm_cmple_epu8_mask(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_cmple_epu8_mask(
      arg0,
      arg1,
    );
  }

  late final __mm_cmple_epu8_maskPtr =
      _lookup<ffi.NativeFunction<__mmask16 Function(__m128i, __m128i)>>(
          '_mm_cmple_epu8_mask');
  late final __mm_cmple_epu8_mask =
      __mm_cmple_epu8_maskPtr.asFunction<int Function(__m128i, __m128i)>();

  int _mm_cmplt_epu8_mask(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_cmplt_epu8_mask(
      arg0,
      arg1,
    );
  }

  late final __mm_cmplt_epu8_maskPtr =
      _lookup<ffi.NativeFunction<__mmask16 Function(__m128i, __m128i)>>(
          '_mm_cmplt_epu8_mask');
  late final __mm_cmplt_epu8_mask =
      __mm_cmplt_epu8_maskPtr.asFunction<int Function(__m128i, __m128i)>();

  int _mm_cmpneq_epu8_mask(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_cmpneq_epu8_mask(
      arg0,
      arg1,
    );
  }

  late final __mm_cmpneq_epu8_maskPtr =
      _lookup<ffi.NativeFunction<__mmask16 Function(__m128i, __m128i)>>(
          '_mm_cmpneq_epu8_mask');
  late final __mm_cmpneq_epu8_mask =
      __mm_cmpneq_epu8_maskPtr.asFunction<int Function(__m128i, __m128i)>();

  int _mm_mask_cmpeq_epi8_mask(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cmpeq_epi8_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cmpeq_epi8_maskPtr = _lookup<
          ffi.NativeFunction<__mmask16 Function(__mmask16, __m128i, __m128i)>>(
      '_mm_mask_cmpeq_epi8_mask');
  late final __mm_mask_cmpeq_epi8_mask = __mm_mask_cmpeq_epi8_maskPtr
      .asFunction<int Function(int, __m128i, __m128i)>();

  int _mm_mask_cmpge_epi8_mask(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cmpge_epi8_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cmpge_epi8_maskPtr = _lookup<
          ffi.NativeFunction<__mmask16 Function(__mmask16, __m128i, __m128i)>>(
      '_mm_mask_cmpge_epi8_mask');
  late final __mm_mask_cmpge_epi8_mask = __mm_mask_cmpge_epi8_maskPtr
      .asFunction<int Function(int, __m128i, __m128i)>();

  int _mm_mask_cmpgt_epi8_mask(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cmpgt_epi8_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cmpgt_epi8_maskPtr = _lookup<
          ffi.NativeFunction<__mmask16 Function(__mmask16, __m128i, __m128i)>>(
      '_mm_mask_cmpgt_epi8_mask');
  late final __mm_mask_cmpgt_epi8_mask = __mm_mask_cmpgt_epi8_maskPtr
      .asFunction<int Function(int, __m128i, __m128i)>();

  int _mm_mask_cmple_epi8_mask(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cmple_epi8_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cmple_epi8_maskPtr = _lookup<
          ffi.NativeFunction<__mmask16 Function(__mmask16, __m128i, __m128i)>>(
      '_mm_mask_cmple_epi8_mask');
  late final __mm_mask_cmple_epi8_mask = __mm_mask_cmple_epi8_maskPtr
      .asFunction<int Function(int, __m128i, __m128i)>();

  int _mm_mask_cmplt_epi8_mask(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cmplt_epi8_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cmplt_epi8_maskPtr = _lookup<
          ffi.NativeFunction<__mmask16 Function(__mmask16, __m128i, __m128i)>>(
      '_mm_mask_cmplt_epi8_mask');
  late final __mm_mask_cmplt_epi8_mask = __mm_mask_cmplt_epi8_maskPtr
      .asFunction<int Function(int, __m128i, __m128i)>();

  int _mm_mask_cmpneq_epi8_mask(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cmpneq_epi8_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cmpneq_epi8_maskPtr = _lookup<
          ffi.NativeFunction<__mmask16 Function(__mmask16, __m128i, __m128i)>>(
      '_mm_mask_cmpneq_epi8_mask');
  late final __mm_mask_cmpneq_epi8_mask = __mm_mask_cmpneq_epi8_maskPtr
      .asFunction<int Function(int, __m128i, __m128i)>();

  int _mm_mask_cmpeq_epu8_mask(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cmpeq_epu8_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cmpeq_epu8_maskPtr = _lookup<
          ffi.NativeFunction<__mmask16 Function(__mmask16, __m128i, __m128i)>>(
      '_mm_mask_cmpeq_epu8_mask');
  late final __mm_mask_cmpeq_epu8_mask = __mm_mask_cmpeq_epu8_maskPtr
      .asFunction<int Function(int, __m128i, __m128i)>();

  int _mm_mask_cmpge_epu8_mask(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cmpge_epu8_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cmpge_epu8_maskPtr = _lookup<
          ffi.NativeFunction<__mmask16 Function(__mmask16, __m128i, __m128i)>>(
      '_mm_mask_cmpge_epu8_mask');
  late final __mm_mask_cmpge_epu8_mask = __mm_mask_cmpge_epu8_maskPtr
      .asFunction<int Function(int, __m128i, __m128i)>();

  int _mm_mask_cmpgt_epu8_mask(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cmpgt_epu8_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cmpgt_epu8_maskPtr = _lookup<
          ffi.NativeFunction<__mmask16 Function(__mmask16, __m128i, __m128i)>>(
      '_mm_mask_cmpgt_epu8_mask');
  late final __mm_mask_cmpgt_epu8_mask = __mm_mask_cmpgt_epu8_maskPtr
      .asFunction<int Function(int, __m128i, __m128i)>();

  int _mm_mask_cmple_epu8_mask(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cmple_epu8_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cmple_epu8_maskPtr = _lookup<
          ffi.NativeFunction<__mmask16 Function(__mmask16, __m128i, __m128i)>>(
      '_mm_mask_cmple_epu8_mask');
  late final __mm_mask_cmple_epu8_mask = __mm_mask_cmple_epu8_maskPtr
      .asFunction<int Function(int, __m128i, __m128i)>();

  int _mm_mask_cmplt_epu8_mask(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cmplt_epu8_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cmplt_epu8_maskPtr = _lookup<
          ffi.NativeFunction<__mmask16 Function(__mmask16, __m128i, __m128i)>>(
      '_mm_mask_cmplt_epu8_mask');
  late final __mm_mask_cmplt_epu8_mask = __mm_mask_cmplt_epu8_maskPtr
      .asFunction<int Function(int, __m128i, __m128i)>();

  int _mm_mask_cmpneq_epu8_mask(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cmpneq_epu8_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cmpneq_epu8_maskPtr = _lookup<
          ffi.NativeFunction<__mmask16 Function(__mmask16, __m128i, __m128i)>>(
      '_mm_mask_cmpneq_epu8_mask');
  late final __mm_mask_cmpneq_epu8_mask = __mm_mask_cmpneq_epu8_maskPtr
      .asFunction<int Function(int, __m128i, __m128i)>();

  int _mm_cmpeq_epi16_mask(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_cmpeq_epi16_mask(
      arg0,
      arg1,
    );
  }

  late final __mm_cmpeq_epi16_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m128i, __m128i)>>(
          '_mm_cmpeq_epi16_mask');
  late final __mm_cmpeq_epi16_mask =
      __mm_cmpeq_epi16_maskPtr.asFunction<int Function(__m128i, __m128i)>();

  int _mm_cmpge_epi16_mask(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_cmpge_epi16_mask(
      arg0,
      arg1,
    );
  }

  late final __mm_cmpge_epi16_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m128i, __m128i)>>(
          '_mm_cmpge_epi16_mask');
  late final __mm_cmpge_epi16_mask =
      __mm_cmpge_epi16_maskPtr.asFunction<int Function(__m128i, __m128i)>();

  int _mm_cmpgt_epi16_mask(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_cmpgt_epi16_mask(
      arg0,
      arg1,
    );
  }

  late final __mm_cmpgt_epi16_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m128i, __m128i)>>(
          '_mm_cmpgt_epi16_mask');
  late final __mm_cmpgt_epi16_mask =
      __mm_cmpgt_epi16_maskPtr.asFunction<int Function(__m128i, __m128i)>();

  int _mm_cmple_epi16_mask(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_cmple_epi16_mask(
      arg0,
      arg1,
    );
  }

  late final __mm_cmple_epi16_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m128i, __m128i)>>(
          '_mm_cmple_epi16_mask');
  late final __mm_cmple_epi16_mask =
      __mm_cmple_epi16_maskPtr.asFunction<int Function(__m128i, __m128i)>();

  int _mm_cmplt_epi16_mask(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_cmplt_epi16_mask(
      arg0,
      arg1,
    );
  }

  late final __mm_cmplt_epi16_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m128i, __m128i)>>(
          '_mm_cmplt_epi16_mask');
  late final __mm_cmplt_epi16_mask =
      __mm_cmplt_epi16_maskPtr.asFunction<int Function(__m128i, __m128i)>();

  int _mm_cmpneq_epi16_mask(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_cmpneq_epi16_mask(
      arg0,
      arg1,
    );
  }

  late final __mm_cmpneq_epi16_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m128i, __m128i)>>(
          '_mm_cmpneq_epi16_mask');
  late final __mm_cmpneq_epi16_mask =
      __mm_cmpneq_epi16_maskPtr.asFunction<int Function(__m128i, __m128i)>();

  int _mm_cmpeq_epu16_mask(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_cmpeq_epu16_mask(
      arg0,
      arg1,
    );
  }

  late final __mm_cmpeq_epu16_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m128i, __m128i)>>(
          '_mm_cmpeq_epu16_mask');
  late final __mm_cmpeq_epu16_mask =
      __mm_cmpeq_epu16_maskPtr.asFunction<int Function(__m128i, __m128i)>();

  int _mm_cmpge_epu16_mask(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_cmpge_epu16_mask(
      arg0,
      arg1,
    );
  }

  late final __mm_cmpge_epu16_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m128i, __m128i)>>(
          '_mm_cmpge_epu16_mask');
  late final __mm_cmpge_epu16_mask =
      __mm_cmpge_epu16_maskPtr.asFunction<int Function(__m128i, __m128i)>();

  int _mm_cmpgt_epu16_mask(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_cmpgt_epu16_mask(
      arg0,
      arg1,
    );
  }

  late final __mm_cmpgt_epu16_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m128i, __m128i)>>(
          '_mm_cmpgt_epu16_mask');
  late final __mm_cmpgt_epu16_mask =
      __mm_cmpgt_epu16_maskPtr.asFunction<int Function(__m128i, __m128i)>();

  int _mm_cmple_epu16_mask(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_cmple_epu16_mask(
      arg0,
      arg1,
    );
  }

  late final __mm_cmple_epu16_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m128i, __m128i)>>(
          '_mm_cmple_epu16_mask');
  late final __mm_cmple_epu16_mask =
      __mm_cmple_epu16_maskPtr.asFunction<int Function(__m128i, __m128i)>();

  int _mm_cmplt_epu16_mask(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_cmplt_epu16_mask(
      arg0,
      arg1,
    );
  }

  late final __mm_cmplt_epu16_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m128i, __m128i)>>(
          '_mm_cmplt_epu16_mask');
  late final __mm_cmplt_epu16_mask =
      __mm_cmplt_epu16_maskPtr.asFunction<int Function(__m128i, __m128i)>();

  int _mm_cmpneq_epu16_mask(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_cmpneq_epu16_mask(
      arg0,
      arg1,
    );
  }

  late final __mm_cmpneq_epu16_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m128i, __m128i)>>(
          '_mm_cmpneq_epu16_mask');
  late final __mm_cmpneq_epu16_mask =
      __mm_cmpneq_epu16_maskPtr.asFunction<int Function(__m128i, __m128i)>();

  int _mm_mask_cmpeq_epi16_mask(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cmpeq_epi16_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cmpeq_epi16_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m128i, __m128i)>>(
      '_mm_mask_cmpeq_epi16_mask');
  late final __mm_mask_cmpeq_epi16_mask = __mm_mask_cmpeq_epi16_maskPtr
      .asFunction<int Function(int, __m128i, __m128i)>();

  int _mm_mask_cmpge_epi16_mask(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cmpge_epi16_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cmpge_epi16_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m128i, __m128i)>>(
      '_mm_mask_cmpge_epi16_mask');
  late final __mm_mask_cmpge_epi16_mask = __mm_mask_cmpge_epi16_maskPtr
      .asFunction<int Function(int, __m128i, __m128i)>();

  int _mm_mask_cmpgt_epi16_mask(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cmpgt_epi16_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cmpgt_epi16_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m128i, __m128i)>>(
      '_mm_mask_cmpgt_epi16_mask');
  late final __mm_mask_cmpgt_epi16_mask = __mm_mask_cmpgt_epi16_maskPtr
      .asFunction<int Function(int, __m128i, __m128i)>();

  int _mm_mask_cmple_epi16_mask(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cmple_epi16_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cmple_epi16_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m128i, __m128i)>>(
      '_mm_mask_cmple_epi16_mask');
  late final __mm_mask_cmple_epi16_mask = __mm_mask_cmple_epi16_maskPtr
      .asFunction<int Function(int, __m128i, __m128i)>();

  int _mm_mask_cmplt_epi16_mask(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cmplt_epi16_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cmplt_epi16_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m128i, __m128i)>>(
      '_mm_mask_cmplt_epi16_mask');
  late final __mm_mask_cmplt_epi16_mask = __mm_mask_cmplt_epi16_maskPtr
      .asFunction<int Function(int, __m128i, __m128i)>();

  int _mm_mask_cmpneq_epi16_mask(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cmpneq_epi16_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cmpneq_epi16_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m128i, __m128i)>>(
      '_mm_mask_cmpneq_epi16_mask');
  late final __mm_mask_cmpneq_epi16_mask = __mm_mask_cmpneq_epi16_maskPtr
      .asFunction<int Function(int, __m128i, __m128i)>();

  int _mm_mask_cmpeq_epu16_mask(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cmpeq_epu16_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cmpeq_epu16_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m128i, __m128i)>>(
      '_mm_mask_cmpeq_epu16_mask');
  late final __mm_mask_cmpeq_epu16_mask = __mm_mask_cmpeq_epu16_maskPtr
      .asFunction<int Function(int, __m128i, __m128i)>();

  int _mm_mask_cmpge_epu16_mask(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cmpge_epu16_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cmpge_epu16_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m128i, __m128i)>>(
      '_mm_mask_cmpge_epu16_mask');
  late final __mm_mask_cmpge_epu16_mask = __mm_mask_cmpge_epu16_maskPtr
      .asFunction<int Function(int, __m128i, __m128i)>();

  int _mm_mask_cmpgt_epu16_mask(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cmpgt_epu16_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cmpgt_epu16_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m128i, __m128i)>>(
      '_mm_mask_cmpgt_epu16_mask');
  late final __mm_mask_cmpgt_epu16_mask = __mm_mask_cmpgt_epu16_maskPtr
      .asFunction<int Function(int, __m128i, __m128i)>();

  int _mm_mask_cmple_epu16_mask(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cmple_epu16_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cmple_epu16_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m128i, __m128i)>>(
      '_mm_mask_cmple_epu16_mask');
  late final __mm_mask_cmple_epu16_mask = __mm_mask_cmple_epu16_maskPtr
      .asFunction<int Function(int, __m128i, __m128i)>();

  int _mm_mask_cmplt_epu16_mask(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cmplt_epu16_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cmplt_epu16_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m128i, __m128i)>>(
      '_mm_mask_cmplt_epu16_mask');
  late final __mm_mask_cmplt_epu16_mask = __mm_mask_cmplt_epu16_maskPtr
      .asFunction<int Function(int, __m128i, __m128i)>();

  int _mm_mask_cmpneq_epu16_mask(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cmpneq_epu16_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cmpneq_epu16_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m128i, __m128i)>>(
      '_mm_mask_cmpneq_epu16_mask');
  late final __mm_mask_cmpneq_epu16_mask = __mm_mask_cmpneq_epu16_maskPtr
      .asFunction<int Function(int, __m128i, __m128i)>();

  int _mm_cmpeq_epi32_mask(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_cmpeq_epi32_mask(
      arg0,
      arg1,
    );
  }

  late final __mm_cmpeq_epi32_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m128i, __m128i)>>(
          '_mm_cmpeq_epi32_mask');
  late final __mm_cmpeq_epi32_mask =
      __mm_cmpeq_epi32_maskPtr.asFunction<int Function(__m128i, __m128i)>();

  int _mm_cmpge_epi32_mask(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_cmpge_epi32_mask(
      arg0,
      arg1,
    );
  }

  late final __mm_cmpge_epi32_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m128i, __m128i)>>(
          '_mm_cmpge_epi32_mask');
  late final __mm_cmpge_epi32_mask =
      __mm_cmpge_epi32_maskPtr.asFunction<int Function(__m128i, __m128i)>();

  int _mm_cmpgt_epi32_mask(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_cmpgt_epi32_mask(
      arg0,
      arg1,
    );
  }

  late final __mm_cmpgt_epi32_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m128i, __m128i)>>(
          '_mm_cmpgt_epi32_mask');
  late final __mm_cmpgt_epi32_mask =
      __mm_cmpgt_epi32_maskPtr.asFunction<int Function(__m128i, __m128i)>();

  int _mm_cmple_epi32_mask(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_cmple_epi32_mask(
      arg0,
      arg1,
    );
  }

  late final __mm_cmple_epi32_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m128i, __m128i)>>(
          '_mm_cmple_epi32_mask');
  late final __mm_cmple_epi32_mask =
      __mm_cmple_epi32_maskPtr.asFunction<int Function(__m128i, __m128i)>();

  int _mm_cmplt_epi32_mask(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_cmplt_epi32_mask(
      arg0,
      arg1,
    );
  }

  late final __mm_cmplt_epi32_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m128i, __m128i)>>(
          '_mm_cmplt_epi32_mask');
  late final __mm_cmplt_epi32_mask =
      __mm_cmplt_epi32_maskPtr.asFunction<int Function(__m128i, __m128i)>();

  int _mm_cmpneq_epi32_mask(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_cmpneq_epi32_mask(
      arg0,
      arg1,
    );
  }

  late final __mm_cmpneq_epi32_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m128i, __m128i)>>(
          '_mm_cmpneq_epi32_mask');
  late final __mm_cmpneq_epi32_mask =
      __mm_cmpneq_epi32_maskPtr.asFunction<int Function(__m128i, __m128i)>();

  int _mm_cmpeq_epu32_mask(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_cmpeq_epu32_mask(
      arg0,
      arg1,
    );
  }

  late final __mm_cmpeq_epu32_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m128i, __m128i)>>(
          '_mm_cmpeq_epu32_mask');
  late final __mm_cmpeq_epu32_mask =
      __mm_cmpeq_epu32_maskPtr.asFunction<int Function(__m128i, __m128i)>();

  int _mm_cmpge_epu32_mask(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_cmpge_epu32_mask(
      arg0,
      arg1,
    );
  }

  late final __mm_cmpge_epu32_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m128i, __m128i)>>(
          '_mm_cmpge_epu32_mask');
  late final __mm_cmpge_epu32_mask =
      __mm_cmpge_epu32_maskPtr.asFunction<int Function(__m128i, __m128i)>();

  int _mm_cmpgt_epu32_mask(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_cmpgt_epu32_mask(
      arg0,
      arg1,
    );
  }

  late final __mm_cmpgt_epu32_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m128i, __m128i)>>(
          '_mm_cmpgt_epu32_mask');
  late final __mm_cmpgt_epu32_mask =
      __mm_cmpgt_epu32_maskPtr.asFunction<int Function(__m128i, __m128i)>();

  int _mm_cmple_epu32_mask(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_cmple_epu32_mask(
      arg0,
      arg1,
    );
  }

  late final __mm_cmple_epu32_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m128i, __m128i)>>(
          '_mm_cmple_epu32_mask');
  late final __mm_cmple_epu32_mask =
      __mm_cmple_epu32_maskPtr.asFunction<int Function(__m128i, __m128i)>();

  int _mm_cmplt_epu32_mask(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_cmplt_epu32_mask(
      arg0,
      arg1,
    );
  }

  late final __mm_cmplt_epu32_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m128i, __m128i)>>(
          '_mm_cmplt_epu32_mask');
  late final __mm_cmplt_epu32_mask =
      __mm_cmplt_epu32_maskPtr.asFunction<int Function(__m128i, __m128i)>();

  int _mm_cmpneq_epu32_mask(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_cmpneq_epu32_mask(
      arg0,
      arg1,
    );
  }

  late final __mm_cmpneq_epu32_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m128i, __m128i)>>(
          '_mm_cmpneq_epu32_mask');
  late final __mm_cmpneq_epu32_mask =
      __mm_cmpneq_epu32_maskPtr.asFunction<int Function(__m128i, __m128i)>();

  int _mm_mask_cmpeq_epi32_mask(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cmpeq_epi32_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cmpeq_epi32_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m128i, __m128i)>>(
      '_mm_mask_cmpeq_epi32_mask');
  late final __mm_mask_cmpeq_epi32_mask = __mm_mask_cmpeq_epi32_maskPtr
      .asFunction<int Function(int, __m128i, __m128i)>();

  int _mm_mask_cmpge_epi32_mask(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cmpge_epi32_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cmpge_epi32_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m128i, __m128i)>>(
      '_mm_mask_cmpge_epi32_mask');
  late final __mm_mask_cmpge_epi32_mask = __mm_mask_cmpge_epi32_maskPtr
      .asFunction<int Function(int, __m128i, __m128i)>();

  int _mm_mask_cmpgt_epi32_mask(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cmpgt_epi32_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cmpgt_epi32_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m128i, __m128i)>>(
      '_mm_mask_cmpgt_epi32_mask');
  late final __mm_mask_cmpgt_epi32_mask = __mm_mask_cmpgt_epi32_maskPtr
      .asFunction<int Function(int, __m128i, __m128i)>();

  int _mm_mask_cmple_epi32_mask(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cmple_epi32_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cmple_epi32_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m128i, __m128i)>>(
      '_mm_mask_cmple_epi32_mask');
  late final __mm_mask_cmple_epi32_mask = __mm_mask_cmple_epi32_maskPtr
      .asFunction<int Function(int, __m128i, __m128i)>();

  int _mm_mask_cmplt_epi32_mask(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cmplt_epi32_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cmplt_epi32_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m128i, __m128i)>>(
      '_mm_mask_cmplt_epi32_mask');
  late final __mm_mask_cmplt_epi32_mask = __mm_mask_cmplt_epi32_maskPtr
      .asFunction<int Function(int, __m128i, __m128i)>();

  int _mm_mask_cmpneq_epi32_mask(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cmpneq_epi32_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cmpneq_epi32_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m128i, __m128i)>>(
      '_mm_mask_cmpneq_epi32_mask');
  late final __mm_mask_cmpneq_epi32_mask = __mm_mask_cmpneq_epi32_maskPtr
      .asFunction<int Function(int, __m128i, __m128i)>();

  int _mm_mask_cmpeq_epu32_mask(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cmpeq_epu32_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cmpeq_epu32_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m128i, __m128i)>>(
      '_mm_mask_cmpeq_epu32_mask');
  late final __mm_mask_cmpeq_epu32_mask = __mm_mask_cmpeq_epu32_maskPtr
      .asFunction<int Function(int, __m128i, __m128i)>();

  int _mm_mask_cmpge_epu32_mask(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cmpge_epu32_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cmpge_epu32_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m128i, __m128i)>>(
      '_mm_mask_cmpge_epu32_mask');
  late final __mm_mask_cmpge_epu32_mask = __mm_mask_cmpge_epu32_maskPtr
      .asFunction<int Function(int, __m128i, __m128i)>();

  int _mm_mask_cmpgt_epu32_mask(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cmpgt_epu32_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cmpgt_epu32_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m128i, __m128i)>>(
      '_mm_mask_cmpgt_epu32_mask');
  late final __mm_mask_cmpgt_epu32_mask = __mm_mask_cmpgt_epu32_maskPtr
      .asFunction<int Function(int, __m128i, __m128i)>();

  int _mm_mask_cmple_epu32_mask(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cmple_epu32_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cmple_epu32_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m128i, __m128i)>>(
      '_mm_mask_cmple_epu32_mask');
  late final __mm_mask_cmple_epu32_mask = __mm_mask_cmple_epu32_maskPtr
      .asFunction<int Function(int, __m128i, __m128i)>();

  int _mm_mask_cmplt_epu32_mask(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cmplt_epu32_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cmplt_epu32_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m128i, __m128i)>>(
      '_mm_mask_cmplt_epu32_mask');
  late final __mm_mask_cmplt_epu32_mask = __mm_mask_cmplt_epu32_maskPtr
      .asFunction<int Function(int, __m128i, __m128i)>();

  int _mm_mask_cmpneq_epu32_mask(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cmpneq_epu32_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cmpneq_epu32_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m128i, __m128i)>>(
      '_mm_mask_cmpneq_epu32_mask');
  late final __mm_mask_cmpneq_epu32_mask = __mm_mask_cmpneq_epu32_maskPtr
      .asFunction<int Function(int, __m128i, __m128i)>();

  int _mm_cmpeq_epi64_mask(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_cmpeq_epi64_mask(
      arg0,
      arg1,
    );
  }

  late final __mm_cmpeq_epi64_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m128i, __m128i)>>(
          '_mm_cmpeq_epi64_mask');
  late final __mm_cmpeq_epi64_mask =
      __mm_cmpeq_epi64_maskPtr.asFunction<int Function(__m128i, __m128i)>();

  int _mm_cmpge_epi64_mask(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_cmpge_epi64_mask(
      arg0,
      arg1,
    );
  }

  late final __mm_cmpge_epi64_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m128i, __m128i)>>(
          '_mm_cmpge_epi64_mask');
  late final __mm_cmpge_epi64_mask =
      __mm_cmpge_epi64_maskPtr.asFunction<int Function(__m128i, __m128i)>();

  int _mm_cmpgt_epi64_mask(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_cmpgt_epi64_mask(
      arg0,
      arg1,
    );
  }

  late final __mm_cmpgt_epi64_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m128i, __m128i)>>(
          '_mm_cmpgt_epi64_mask');
  late final __mm_cmpgt_epi64_mask =
      __mm_cmpgt_epi64_maskPtr.asFunction<int Function(__m128i, __m128i)>();

  int _mm_cmple_epi64_mask(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_cmple_epi64_mask(
      arg0,
      arg1,
    );
  }

  late final __mm_cmple_epi64_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m128i, __m128i)>>(
          '_mm_cmple_epi64_mask');
  late final __mm_cmple_epi64_mask =
      __mm_cmple_epi64_maskPtr.asFunction<int Function(__m128i, __m128i)>();

  int _mm_cmplt_epi64_mask(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_cmplt_epi64_mask(
      arg0,
      arg1,
    );
  }

  late final __mm_cmplt_epi64_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m128i, __m128i)>>(
          '_mm_cmplt_epi64_mask');
  late final __mm_cmplt_epi64_mask =
      __mm_cmplt_epi64_maskPtr.asFunction<int Function(__m128i, __m128i)>();

  int _mm_cmpneq_epi64_mask(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_cmpneq_epi64_mask(
      arg0,
      arg1,
    );
  }

  late final __mm_cmpneq_epi64_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m128i, __m128i)>>(
          '_mm_cmpneq_epi64_mask');
  late final __mm_cmpneq_epi64_mask =
      __mm_cmpneq_epi64_maskPtr.asFunction<int Function(__m128i, __m128i)>();

  int _mm_cmpeq_epu64_mask(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_cmpeq_epu64_mask(
      arg0,
      arg1,
    );
  }

  late final __mm_cmpeq_epu64_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m128i, __m128i)>>(
          '_mm_cmpeq_epu64_mask');
  late final __mm_cmpeq_epu64_mask =
      __mm_cmpeq_epu64_maskPtr.asFunction<int Function(__m128i, __m128i)>();

  int _mm_cmpge_epu64_mask(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_cmpge_epu64_mask(
      arg0,
      arg1,
    );
  }

  late final __mm_cmpge_epu64_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m128i, __m128i)>>(
          '_mm_cmpge_epu64_mask');
  late final __mm_cmpge_epu64_mask =
      __mm_cmpge_epu64_maskPtr.asFunction<int Function(__m128i, __m128i)>();

  int _mm_cmpgt_epu64_mask(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_cmpgt_epu64_mask(
      arg0,
      arg1,
    );
  }

  late final __mm_cmpgt_epu64_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m128i, __m128i)>>(
          '_mm_cmpgt_epu64_mask');
  late final __mm_cmpgt_epu64_mask =
      __mm_cmpgt_epu64_maskPtr.asFunction<int Function(__m128i, __m128i)>();

  int _mm_cmple_epu64_mask(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_cmple_epu64_mask(
      arg0,
      arg1,
    );
  }

  late final __mm_cmple_epu64_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m128i, __m128i)>>(
          '_mm_cmple_epu64_mask');
  late final __mm_cmple_epu64_mask =
      __mm_cmple_epu64_maskPtr.asFunction<int Function(__m128i, __m128i)>();

  int _mm_cmplt_epu64_mask(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_cmplt_epu64_mask(
      arg0,
      arg1,
    );
  }

  late final __mm_cmplt_epu64_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m128i, __m128i)>>(
          '_mm_cmplt_epu64_mask');
  late final __mm_cmplt_epu64_mask =
      __mm_cmplt_epu64_maskPtr.asFunction<int Function(__m128i, __m128i)>();

  int _mm_cmpneq_epu64_mask(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_cmpneq_epu64_mask(
      arg0,
      arg1,
    );
  }

  late final __mm_cmpneq_epu64_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m128i, __m128i)>>(
          '_mm_cmpneq_epu64_mask');
  late final __mm_cmpneq_epu64_mask =
      __mm_cmpneq_epu64_maskPtr.asFunction<int Function(__m128i, __m128i)>();

  int _mm_mask_cmpeq_epi64_mask(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cmpeq_epi64_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cmpeq_epi64_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m128i, __m128i)>>(
      '_mm_mask_cmpeq_epi64_mask');
  late final __mm_mask_cmpeq_epi64_mask = __mm_mask_cmpeq_epi64_maskPtr
      .asFunction<int Function(int, __m128i, __m128i)>();

  int _mm_mask_cmpge_epi64_mask(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cmpge_epi64_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cmpge_epi64_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m128i, __m128i)>>(
      '_mm_mask_cmpge_epi64_mask');
  late final __mm_mask_cmpge_epi64_mask = __mm_mask_cmpge_epi64_maskPtr
      .asFunction<int Function(int, __m128i, __m128i)>();

  int _mm_mask_cmpgt_epi64_mask(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cmpgt_epi64_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cmpgt_epi64_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m128i, __m128i)>>(
      '_mm_mask_cmpgt_epi64_mask');
  late final __mm_mask_cmpgt_epi64_mask = __mm_mask_cmpgt_epi64_maskPtr
      .asFunction<int Function(int, __m128i, __m128i)>();

  int _mm_mask_cmple_epi64_mask(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cmple_epi64_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cmple_epi64_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m128i, __m128i)>>(
      '_mm_mask_cmple_epi64_mask');
  late final __mm_mask_cmple_epi64_mask = __mm_mask_cmple_epi64_maskPtr
      .asFunction<int Function(int, __m128i, __m128i)>();

  int _mm_mask_cmplt_epi64_mask(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cmplt_epi64_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cmplt_epi64_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m128i, __m128i)>>(
      '_mm_mask_cmplt_epi64_mask');
  late final __mm_mask_cmplt_epi64_mask = __mm_mask_cmplt_epi64_maskPtr
      .asFunction<int Function(int, __m128i, __m128i)>();

  int _mm_mask_cmpneq_epi64_mask(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cmpneq_epi64_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cmpneq_epi64_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m128i, __m128i)>>(
      '_mm_mask_cmpneq_epi64_mask');
  late final __mm_mask_cmpneq_epi64_mask = __mm_mask_cmpneq_epi64_maskPtr
      .asFunction<int Function(int, __m128i, __m128i)>();

  int _mm_mask_cmpeq_epu64_mask(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cmpeq_epu64_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cmpeq_epu64_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m128i, __m128i)>>(
      '_mm_mask_cmpeq_epu64_mask');
  late final __mm_mask_cmpeq_epu64_mask = __mm_mask_cmpeq_epu64_maskPtr
      .asFunction<int Function(int, __m128i, __m128i)>();

  int _mm_mask_cmpge_epu64_mask(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cmpge_epu64_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cmpge_epu64_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m128i, __m128i)>>(
      '_mm_mask_cmpge_epu64_mask');
  late final __mm_mask_cmpge_epu64_mask = __mm_mask_cmpge_epu64_maskPtr
      .asFunction<int Function(int, __m128i, __m128i)>();

  int _mm_mask_cmpgt_epu64_mask(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cmpgt_epu64_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cmpgt_epu64_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m128i, __m128i)>>(
      '_mm_mask_cmpgt_epu64_mask');
  late final __mm_mask_cmpgt_epu64_mask = __mm_mask_cmpgt_epu64_maskPtr
      .asFunction<int Function(int, __m128i, __m128i)>();

  int _mm_mask_cmple_epu64_mask(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cmple_epu64_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cmple_epu64_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m128i, __m128i)>>(
      '_mm_mask_cmple_epu64_mask');
  late final __mm_mask_cmple_epu64_mask = __mm_mask_cmple_epu64_maskPtr
      .asFunction<int Function(int, __m128i, __m128i)>();

  int _mm_mask_cmplt_epu64_mask(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cmplt_epu64_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cmplt_epu64_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m128i, __m128i)>>(
      '_mm_mask_cmplt_epu64_mask');
  late final __mm_mask_cmplt_epu64_mask = __mm_mask_cmplt_epu64_maskPtr
      .asFunction<int Function(int, __m128i, __m128i)>();

  int _mm_mask_cmpneq_epu64_mask(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cmpneq_epu64_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cmpneq_epu64_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m128i, __m128i)>>(
      '_mm_mask_cmpneq_epu64_mask');
  late final __mm_mask_cmpneq_epu64_mask = __mm_mask_cmpneq_epu64_maskPtr
      .asFunction<int Function(int, __m128i, __m128i)>();

  int _mm256_cmpeq_epi8_mask(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_cmpeq_epi8_mask(
      arg0,
      arg1,
    );
  }

  late final __mm256_cmpeq_epi8_maskPtr =
      _lookup<ffi.NativeFunction<__mmask32 Function(__m256i, __m256i)>>(
          '_mm256_cmpeq_epi8_mask');
  late final __mm256_cmpeq_epi8_mask =
      __mm256_cmpeq_epi8_maskPtr.asFunction<int Function(__m256i, __m256i)>();

  int _mm256_cmpge_epi8_mask(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_cmpge_epi8_mask(
      arg0,
      arg1,
    );
  }

  late final __mm256_cmpge_epi8_maskPtr =
      _lookup<ffi.NativeFunction<__mmask32 Function(__m256i, __m256i)>>(
          '_mm256_cmpge_epi8_mask');
  late final __mm256_cmpge_epi8_mask =
      __mm256_cmpge_epi8_maskPtr.asFunction<int Function(__m256i, __m256i)>();

  int _mm256_cmpgt_epi8_mask(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_cmpgt_epi8_mask(
      arg0,
      arg1,
    );
  }

  late final __mm256_cmpgt_epi8_maskPtr =
      _lookup<ffi.NativeFunction<__mmask32 Function(__m256i, __m256i)>>(
          '_mm256_cmpgt_epi8_mask');
  late final __mm256_cmpgt_epi8_mask =
      __mm256_cmpgt_epi8_maskPtr.asFunction<int Function(__m256i, __m256i)>();

  int _mm256_cmple_epi8_mask(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_cmple_epi8_mask(
      arg0,
      arg1,
    );
  }

  late final __mm256_cmple_epi8_maskPtr =
      _lookup<ffi.NativeFunction<__mmask32 Function(__m256i, __m256i)>>(
          '_mm256_cmple_epi8_mask');
  late final __mm256_cmple_epi8_mask =
      __mm256_cmple_epi8_maskPtr.asFunction<int Function(__m256i, __m256i)>();

  int _mm256_cmplt_epi8_mask(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_cmplt_epi8_mask(
      arg0,
      arg1,
    );
  }

  late final __mm256_cmplt_epi8_maskPtr =
      _lookup<ffi.NativeFunction<__mmask32 Function(__m256i, __m256i)>>(
          '_mm256_cmplt_epi8_mask');
  late final __mm256_cmplt_epi8_mask =
      __mm256_cmplt_epi8_maskPtr.asFunction<int Function(__m256i, __m256i)>();

  int _mm256_cmpneq_epi8_mask(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_cmpneq_epi8_mask(
      arg0,
      arg1,
    );
  }

  late final __mm256_cmpneq_epi8_maskPtr =
      _lookup<ffi.NativeFunction<__mmask32 Function(__m256i, __m256i)>>(
          '_mm256_cmpneq_epi8_mask');
  late final __mm256_cmpneq_epi8_mask =
      __mm256_cmpneq_epi8_maskPtr.asFunction<int Function(__m256i, __m256i)>();

  int _mm256_cmpeq_epu8_mask(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_cmpeq_epu8_mask(
      arg0,
      arg1,
    );
  }

  late final __mm256_cmpeq_epu8_maskPtr =
      _lookup<ffi.NativeFunction<__mmask32 Function(__m256i, __m256i)>>(
          '_mm256_cmpeq_epu8_mask');
  late final __mm256_cmpeq_epu8_mask =
      __mm256_cmpeq_epu8_maskPtr.asFunction<int Function(__m256i, __m256i)>();

  int _mm256_cmpge_epu8_mask(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_cmpge_epu8_mask(
      arg0,
      arg1,
    );
  }

  late final __mm256_cmpge_epu8_maskPtr =
      _lookup<ffi.NativeFunction<__mmask32 Function(__m256i, __m256i)>>(
          '_mm256_cmpge_epu8_mask');
  late final __mm256_cmpge_epu8_mask =
      __mm256_cmpge_epu8_maskPtr.asFunction<int Function(__m256i, __m256i)>();

  int _mm256_cmpgt_epu8_mask(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_cmpgt_epu8_mask(
      arg0,
      arg1,
    );
  }

  late final __mm256_cmpgt_epu8_maskPtr =
      _lookup<ffi.NativeFunction<__mmask32 Function(__m256i, __m256i)>>(
          '_mm256_cmpgt_epu8_mask');
  late final __mm256_cmpgt_epu8_mask =
      __mm256_cmpgt_epu8_maskPtr.asFunction<int Function(__m256i, __m256i)>();

  int _mm256_cmple_epu8_mask(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_cmple_epu8_mask(
      arg0,
      arg1,
    );
  }

  late final __mm256_cmple_epu8_maskPtr =
      _lookup<ffi.NativeFunction<__mmask32 Function(__m256i, __m256i)>>(
          '_mm256_cmple_epu8_mask');
  late final __mm256_cmple_epu8_mask =
      __mm256_cmple_epu8_maskPtr.asFunction<int Function(__m256i, __m256i)>();

  int _mm256_cmplt_epu8_mask(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_cmplt_epu8_mask(
      arg0,
      arg1,
    );
  }

  late final __mm256_cmplt_epu8_maskPtr =
      _lookup<ffi.NativeFunction<__mmask32 Function(__m256i, __m256i)>>(
          '_mm256_cmplt_epu8_mask');
  late final __mm256_cmplt_epu8_mask =
      __mm256_cmplt_epu8_maskPtr.asFunction<int Function(__m256i, __m256i)>();

  int _mm256_cmpneq_epu8_mask(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_cmpneq_epu8_mask(
      arg0,
      arg1,
    );
  }

  late final __mm256_cmpneq_epu8_maskPtr =
      _lookup<ffi.NativeFunction<__mmask32 Function(__m256i, __m256i)>>(
          '_mm256_cmpneq_epu8_mask');
  late final __mm256_cmpneq_epu8_mask =
      __mm256_cmpneq_epu8_maskPtr.asFunction<int Function(__m256i, __m256i)>();

  int _mm256_mask_cmpeq_epi8_mask(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cmpeq_epi8_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cmpeq_epi8_maskPtr = _lookup<
          ffi.NativeFunction<__mmask32 Function(__mmask32, __m256i, __m256i)>>(
      '_mm256_mask_cmpeq_epi8_mask');
  late final __mm256_mask_cmpeq_epi8_mask = __mm256_mask_cmpeq_epi8_maskPtr
      .asFunction<int Function(int, __m256i, __m256i)>();

  int _mm256_mask_cmpge_epi8_mask(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cmpge_epi8_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cmpge_epi8_maskPtr = _lookup<
          ffi.NativeFunction<__mmask32 Function(__mmask32, __m256i, __m256i)>>(
      '_mm256_mask_cmpge_epi8_mask');
  late final __mm256_mask_cmpge_epi8_mask = __mm256_mask_cmpge_epi8_maskPtr
      .asFunction<int Function(int, __m256i, __m256i)>();

  int _mm256_mask_cmpgt_epi8_mask(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cmpgt_epi8_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cmpgt_epi8_maskPtr = _lookup<
          ffi.NativeFunction<__mmask32 Function(__mmask32, __m256i, __m256i)>>(
      '_mm256_mask_cmpgt_epi8_mask');
  late final __mm256_mask_cmpgt_epi8_mask = __mm256_mask_cmpgt_epi8_maskPtr
      .asFunction<int Function(int, __m256i, __m256i)>();

  int _mm256_mask_cmple_epi8_mask(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cmple_epi8_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cmple_epi8_maskPtr = _lookup<
          ffi.NativeFunction<__mmask32 Function(__mmask32, __m256i, __m256i)>>(
      '_mm256_mask_cmple_epi8_mask');
  late final __mm256_mask_cmple_epi8_mask = __mm256_mask_cmple_epi8_maskPtr
      .asFunction<int Function(int, __m256i, __m256i)>();

  int _mm256_mask_cmplt_epi8_mask(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cmplt_epi8_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cmplt_epi8_maskPtr = _lookup<
          ffi.NativeFunction<__mmask32 Function(__mmask32, __m256i, __m256i)>>(
      '_mm256_mask_cmplt_epi8_mask');
  late final __mm256_mask_cmplt_epi8_mask = __mm256_mask_cmplt_epi8_maskPtr
      .asFunction<int Function(int, __m256i, __m256i)>();

  int _mm256_mask_cmpneq_epi8_mask(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cmpneq_epi8_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cmpneq_epi8_maskPtr = _lookup<
          ffi.NativeFunction<__mmask32 Function(__mmask32, __m256i, __m256i)>>(
      '_mm256_mask_cmpneq_epi8_mask');
  late final __mm256_mask_cmpneq_epi8_mask = __mm256_mask_cmpneq_epi8_maskPtr
      .asFunction<int Function(int, __m256i, __m256i)>();

  int _mm256_mask_cmpeq_epu8_mask(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cmpeq_epu8_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cmpeq_epu8_maskPtr = _lookup<
          ffi.NativeFunction<__mmask32 Function(__mmask32, __m256i, __m256i)>>(
      '_mm256_mask_cmpeq_epu8_mask');
  late final __mm256_mask_cmpeq_epu8_mask = __mm256_mask_cmpeq_epu8_maskPtr
      .asFunction<int Function(int, __m256i, __m256i)>();

  int _mm256_mask_cmpge_epu8_mask(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cmpge_epu8_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cmpge_epu8_maskPtr = _lookup<
          ffi.NativeFunction<__mmask32 Function(__mmask32, __m256i, __m256i)>>(
      '_mm256_mask_cmpge_epu8_mask');
  late final __mm256_mask_cmpge_epu8_mask = __mm256_mask_cmpge_epu8_maskPtr
      .asFunction<int Function(int, __m256i, __m256i)>();

  int _mm256_mask_cmpgt_epu8_mask(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cmpgt_epu8_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cmpgt_epu8_maskPtr = _lookup<
          ffi.NativeFunction<__mmask32 Function(__mmask32, __m256i, __m256i)>>(
      '_mm256_mask_cmpgt_epu8_mask');
  late final __mm256_mask_cmpgt_epu8_mask = __mm256_mask_cmpgt_epu8_maskPtr
      .asFunction<int Function(int, __m256i, __m256i)>();

  int _mm256_mask_cmple_epu8_mask(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cmple_epu8_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cmple_epu8_maskPtr = _lookup<
          ffi.NativeFunction<__mmask32 Function(__mmask32, __m256i, __m256i)>>(
      '_mm256_mask_cmple_epu8_mask');
  late final __mm256_mask_cmple_epu8_mask = __mm256_mask_cmple_epu8_maskPtr
      .asFunction<int Function(int, __m256i, __m256i)>();

  int _mm256_mask_cmplt_epu8_mask(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cmplt_epu8_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cmplt_epu8_maskPtr = _lookup<
          ffi.NativeFunction<__mmask32 Function(__mmask32, __m256i, __m256i)>>(
      '_mm256_mask_cmplt_epu8_mask');
  late final __mm256_mask_cmplt_epu8_mask = __mm256_mask_cmplt_epu8_maskPtr
      .asFunction<int Function(int, __m256i, __m256i)>();

  int _mm256_mask_cmpneq_epu8_mask(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cmpneq_epu8_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cmpneq_epu8_maskPtr = _lookup<
          ffi.NativeFunction<__mmask32 Function(__mmask32, __m256i, __m256i)>>(
      '_mm256_mask_cmpneq_epu8_mask');
  late final __mm256_mask_cmpneq_epu8_mask = __mm256_mask_cmpneq_epu8_maskPtr
      .asFunction<int Function(int, __m256i, __m256i)>();

  int _mm256_cmpeq_epi16_mask(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_cmpeq_epi16_mask(
      arg0,
      arg1,
    );
  }

  late final __mm256_cmpeq_epi16_maskPtr =
      _lookup<ffi.NativeFunction<__mmask16 Function(__m256i, __m256i)>>(
          '_mm256_cmpeq_epi16_mask');
  late final __mm256_cmpeq_epi16_mask =
      __mm256_cmpeq_epi16_maskPtr.asFunction<int Function(__m256i, __m256i)>();

  int _mm256_cmpge_epi16_mask(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_cmpge_epi16_mask(
      arg0,
      arg1,
    );
  }

  late final __mm256_cmpge_epi16_maskPtr =
      _lookup<ffi.NativeFunction<__mmask16 Function(__m256i, __m256i)>>(
          '_mm256_cmpge_epi16_mask');
  late final __mm256_cmpge_epi16_mask =
      __mm256_cmpge_epi16_maskPtr.asFunction<int Function(__m256i, __m256i)>();

  int _mm256_cmpgt_epi16_mask(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_cmpgt_epi16_mask(
      arg0,
      arg1,
    );
  }

  late final __mm256_cmpgt_epi16_maskPtr =
      _lookup<ffi.NativeFunction<__mmask16 Function(__m256i, __m256i)>>(
          '_mm256_cmpgt_epi16_mask');
  late final __mm256_cmpgt_epi16_mask =
      __mm256_cmpgt_epi16_maskPtr.asFunction<int Function(__m256i, __m256i)>();

  int _mm256_cmple_epi16_mask(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_cmple_epi16_mask(
      arg0,
      arg1,
    );
  }

  late final __mm256_cmple_epi16_maskPtr =
      _lookup<ffi.NativeFunction<__mmask16 Function(__m256i, __m256i)>>(
          '_mm256_cmple_epi16_mask');
  late final __mm256_cmple_epi16_mask =
      __mm256_cmple_epi16_maskPtr.asFunction<int Function(__m256i, __m256i)>();

  int _mm256_cmplt_epi16_mask(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_cmplt_epi16_mask(
      arg0,
      arg1,
    );
  }

  late final __mm256_cmplt_epi16_maskPtr =
      _lookup<ffi.NativeFunction<__mmask16 Function(__m256i, __m256i)>>(
          '_mm256_cmplt_epi16_mask');
  late final __mm256_cmplt_epi16_mask =
      __mm256_cmplt_epi16_maskPtr.asFunction<int Function(__m256i, __m256i)>();

  int _mm256_cmpneq_epi16_mask(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_cmpneq_epi16_mask(
      arg0,
      arg1,
    );
  }

  late final __mm256_cmpneq_epi16_maskPtr =
      _lookup<ffi.NativeFunction<__mmask16 Function(__m256i, __m256i)>>(
          '_mm256_cmpneq_epi16_mask');
  late final __mm256_cmpneq_epi16_mask =
      __mm256_cmpneq_epi16_maskPtr.asFunction<int Function(__m256i, __m256i)>();

  int _mm256_cmpeq_epu16_mask(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_cmpeq_epu16_mask(
      arg0,
      arg1,
    );
  }

  late final __mm256_cmpeq_epu16_maskPtr =
      _lookup<ffi.NativeFunction<__mmask16 Function(__m256i, __m256i)>>(
          '_mm256_cmpeq_epu16_mask');
  late final __mm256_cmpeq_epu16_mask =
      __mm256_cmpeq_epu16_maskPtr.asFunction<int Function(__m256i, __m256i)>();

  int _mm256_cmpge_epu16_mask(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_cmpge_epu16_mask(
      arg0,
      arg1,
    );
  }

  late final __mm256_cmpge_epu16_maskPtr =
      _lookup<ffi.NativeFunction<__mmask16 Function(__m256i, __m256i)>>(
          '_mm256_cmpge_epu16_mask');
  late final __mm256_cmpge_epu16_mask =
      __mm256_cmpge_epu16_maskPtr.asFunction<int Function(__m256i, __m256i)>();

  int _mm256_cmpgt_epu16_mask(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_cmpgt_epu16_mask(
      arg0,
      arg1,
    );
  }

  late final __mm256_cmpgt_epu16_maskPtr =
      _lookup<ffi.NativeFunction<__mmask16 Function(__m256i, __m256i)>>(
          '_mm256_cmpgt_epu16_mask');
  late final __mm256_cmpgt_epu16_mask =
      __mm256_cmpgt_epu16_maskPtr.asFunction<int Function(__m256i, __m256i)>();

  int _mm256_cmple_epu16_mask(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_cmple_epu16_mask(
      arg0,
      arg1,
    );
  }

  late final __mm256_cmple_epu16_maskPtr =
      _lookup<ffi.NativeFunction<__mmask16 Function(__m256i, __m256i)>>(
          '_mm256_cmple_epu16_mask');
  late final __mm256_cmple_epu16_mask =
      __mm256_cmple_epu16_maskPtr.asFunction<int Function(__m256i, __m256i)>();

  int _mm256_cmplt_epu16_mask(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_cmplt_epu16_mask(
      arg0,
      arg1,
    );
  }

  late final __mm256_cmplt_epu16_maskPtr =
      _lookup<ffi.NativeFunction<__mmask16 Function(__m256i, __m256i)>>(
          '_mm256_cmplt_epu16_mask');
  late final __mm256_cmplt_epu16_mask =
      __mm256_cmplt_epu16_maskPtr.asFunction<int Function(__m256i, __m256i)>();

  int _mm256_cmpneq_epu16_mask(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_cmpneq_epu16_mask(
      arg0,
      arg1,
    );
  }

  late final __mm256_cmpneq_epu16_maskPtr =
      _lookup<ffi.NativeFunction<__mmask16 Function(__m256i, __m256i)>>(
          '_mm256_cmpneq_epu16_mask');
  late final __mm256_cmpneq_epu16_mask =
      __mm256_cmpneq_epu16_maskPtr.asFunction<int Function(__m256i, __m256i)>();

  int _mm256_mask_cmpeq_epi16_mask(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cmpeq_epi16_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cmpeq_epi16_maskPtr = _lookup<
          ffi.NativeFunction<__mmask16 Function(__mmask16, __m256i, __m256i)>>(
      '_mm256_mask_cmpeq_epi16_mask');
  late final __mm256_mask_cmpeq_epi16_mask = __mm256_mask_cmpeq_epi16_maskPtr
      .asFunction<int Function(int, __m256i, __m256i)>();

  int _mm256_mask_cmpge_epi16_mask(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cmpge_epi16_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cmpge_epi16_maskPtr = _lookup<
          ffi.NativeFunction<__mmask16 Function(__mmask16, __m256i, __m256i)>>(
      '_mm256_mask_cmpge_epi16_mask');
  late final __mm256_mask_cmpge_epi16_mask = __mm256_mask_cmpge_epi16_maskPtr
      .asFunction<int Function(int, __m256i, __m256i)>();

  int _mm256_mask_cmpgt_epi16_mask(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cmpgt_epi16_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cmpgt_epi16_maskPtr = _lookup<
          ffi.NativeFunction<__mmask16 Function(__mmask16, __m256i, __m256i)>>(
      '_mm256_mask_cmpgt_epi16_mask');
  late final __mm256_mask_cmpgt_epi16_mask = __mm256_mask_cmpgt_epi16_maskPtr
      .asFunction<int Function(int, __m256i, __m256i)>();

  int _mm256_mask_cmple_epi16_mask(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cmple_epi16_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cmple_epi16_maskPtr = _lookup<
          ffi.NativeFunction<__mmask16 Function(__mmask16, __m256i, __m256i)>>(
      '_mm256_mask_cmple_epi16_mask');
  late final __mm256_mask_cmple_epi16_mask = __mm256_mask_cmple_epi16_maskPtr
      .asFunction<int Function(int, __m256i, __m256i)>();

  int _mm256_mask_cmplt_epi16_mask(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cmplt_epi16_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cmplt_epi16_maskPtr = _lookup<
          ffi.NativeFunction<__mmask16 Function(__mmask16, __m256i, __m256i)>>(
      '_mm256_mask_cmplt_epi16_mask');
  late final __mm256_mask_cmplt_epi16_mask = __mm256_mask_cmplt_epi16_maskPtr
      .asFunction<int Function(int, __m256i, __m256i)>();

  int _mm256_mask_cmpneq_epi16_mask(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cmpneq_epi16_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cmpneq_epi16_maskPtr = _lookup<
          ffi.NativeFunction<__mmask16 Function(__mmask16, __m256i, __m256i)>>(
      '_mm256_mask_cmpneq_epi16_mask');
  late final __mm256_mask_cmpneq_epi16_mask = __mm256_mask_cmpneq_epi16_maskPtr
      .asFunction<int Function(int, __m256i, __m256i)>();

  int _mm256_mask_cmpeq_epu16_mask(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cmpeq_epu16_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cmpeq_epu16_maskPtr = _lookup<
          ffi.NativeFunction<__mmask16 Function(__mmask16, __m256i, __m256i)>>(
      '_mm256_mask_cmpeq_epu16_mask');
  late final __mm256_mask_cmpeq_epu16_mask = __mm256_mask_cmpeq_epu16_maskPtr
      .asFunction<int Function(int, __m256i, __m256i)>();

  int _mm256_mask_cmpge_epu16_mask(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cmpge_epu16_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cmpge_epu16_maskPtr = _lookup<
          ffi.NativeFunction<__mmask16 Function(__mmask16, __m256i, __m256i)>>(
      '_mm256_mask_cmpge_epu16_mask');
  late final __mm256_mask_cmpge_epu16_mask = __mm256_mask_cmpge_epu16_maskPtr
      .asFunction<int Function(int, __m256i, __m256i)>();

  int _mm256_mask_cmpgt_epu16_mask(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cmpgt_epu16_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cmpgt_epu16_maskPtr = _lookup<
          ffi.NativeFunction<__mmask16 Function(__mmask16, __m256i, __m256i)>>(
      '_mm256_mask_cmpgt_epu16_mask');
  late final __mm256_mask_cmpgt_epu16_mask = __mm256_mask_cmpgt_epu16_maskPtr
      .asFunction<int Function(int, __m256i, __m256i)>();

  int _mm256_mask_cmple_epu16_mask(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cmple_epu16_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cmple_epu16_maskPtr = _lookup<
          ffi.NativeFunction<__mmask16 Function(__mmask16, __m256i, __m256i)>>(
      '_mm256_mask_cmple_epu16_mask');
  late final __mm256_mask_cmple_epu16_mask = __mm256_mask_cmple_epu16_maskPtr
      .asFunction<int Function(int, __m256i, __m256i)>();

  int _mm256_mask_cmplt_epu16_mask(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cmplt_epu16_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cmplt_epu16_maskPtr = _lookup<
          ffi.NativeFunction<__mmask16 Function(__mmask16, __m256i, __m256i)>>(
      '_mm256_mask_cmplt_epu16_mask');
  late final __mm256_mask_cmplt_epu16_mask = __mm256_mask_cmplt_epu16_maskPtr
      .asFunction<int Function(int, __m256i, __m256i)>();

  int _mm256_mask_cmpneq_epu16_mask(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cmpneq_epu16_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cmpneq_epu16_maskPtr = _lookup<
          ffi.NativeFunction<__mmask16 Function(__mmask16, __m256i, __m256i)>>(
      '_mm256_mask_cmpneq_epu16_mask');
  late final __mm256_mask_cmpneq_epu16_mask = __mm256_mask_cmpneq_epu16_maskPtr
      .asFunction<int Function(int, __m256i, __m256i)>();

  int _mm256_cmpeq_epi32_mask(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_cmpeq_epi32_mask(
      arg0,
      arg1,
    );
  }

  late final __mm256_cmpeq_epi32_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m256i, __m256i)>>(
          '_mm256_cmpeq_epi32_mask');
  late final __mm256_cmpeq_epi32_mask =
      __mm256_cmpeq_epi32_maskPtr.asFunction<int Function(__m256i, __m256i)>();

  int _mm256_cmpge_epi32_mask(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_cmpge_epi32_mask(
      arg0,
      arg1,
    );
  }

  late final __mm256_cmpge_epi32_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m256i, __m256i)>>(
          '_mm256_cmpge_epi32_mask');
  late final __mm256_cmpge_epi32_mask =
      __mm256_cmpge_epi32_maskPtr.asFunction<int Function(__m256i, __m256i)>();

  int _mm256_cmpgt_epi32_mask(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_cmpgt_epi32_mask(
      arg0,
      arg1,
    );
  }

  late final __mm256_cmpgt_epi32_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m256i, __m256i)>>(
          '_mm256_cmpgt_epi32_mask');
  late final __mm256_cmpgt_epi32_mask =
      __mm256_cmpgt_epi32_maskPtr.asFunction<int Function(__m256i, __m256i)>();

  int _mm256_cmple_epi32_mask(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_cmple_epi32_mask(
      arg0,
      arg1,
    );
  }

  late final __mm256_cmple_epi32_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m256i, __m256i)>>(
          '_mm256_cmple_epi32_mask');
  late final __mm256_cmple_epi32_mask =
      __mm256_cmple_epi32_maskPtr.asFunction<int Function(__m256i, __m256i)>();

  int _mm256_cmplt_epi32_mask(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_cmplt_epi32_mask(
      arg0,
      arg1,
    );
  }

  late final __mm256_cmplt_epi32_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m256i, __m256i)>>(
          '_mm256_cmplt_epi32_mask');
  late final __mm256_cmplt_epi32_mask =
      __mm256_cmplt_epi32_maskPtr.asFunction<int Function(__m256i, __m256i)>();

  int _mm256_cmpneq_epi32_mask(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_cmpneq_epi32_mask(
      arg0,
      arg1,
    );
  }

  late final __mm256_cmpneq_epi32_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m256i, __m256i)>>(
          '_mm256_cmpneq_epi32_mask');
  late final __mm256_cmpneq_epi32_mask =
      __mm256_cmpneq_epi32_maskPtr.asFunction<int Function(__m256i, __m256i)>();

  int _mm256_cmpeq_epu32_mask(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_cmpeq_epu32_mask(
      arg0,
      arg1,
    );
  }

  late final __mm256_cmpeq_epu32_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m256i, __m256i)>>(
          '_mm256_cmpeq_epu32_mask');
  late final __mm256_cmpeq_epu32_mask =
      __mm256_cmpeq_epu32_maskPtr.asFunction<int Function(__m256i, __m256i)>();

  int _mm256_cmpge_epu32_mask(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_cmpge_epu32_mask(
      arg0,
      arg1,
    );
  }

  late final __mm256_cmpge_epu32_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m256i, __m256i)>>(
          '_mm256_cmpge_epu32_mask');
  late final __mm256_cmpge_epu32_mask =
      __mm256_cmpge_epu32_maskPtr.asFunction<int Function(__m256i, __m256i)>();

  int _mm256_cmpgt_epu32_mask(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_cmpgt_epu32_mask(
      arg0,
      arg1,
    );
  }

  late final __mm256_cmpgt_epu32_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m256i, __m256i)>>(
          '_mm256_cmpgt_epu32_mask');
  late final __mm256_cmpgt_epu32_mask =
      __mm256_cmpgt_epu32_maskPtr.asFunction<int Function(__m256i, __m256i)>();

  int _mm256_cmple_epu32_mask(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_cmple_epu32_mask(
      arg0,
      arg1,
    );
  }

  late final __mm256_cmple_epu32_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m256i, __m256i)>>(
          '_mm256_cmple_epu32_mask');
  late final __mm256_cmple_epu32_mask =
      __mm256_cmple_epu32_maskPtr.asFunction<int Function(__m256i, __m256i)>();

  int _mm256_cmplt_epu32_mask(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_cmplt_epu32_mask(
      arg0,
      arg1,
    );
  }

  late final __mm256_cmplt_epu32_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m256i, __m256i)>>(
          '_mm256_cmplt_epu32_mask');
  late final __mm256_cmplt_epu32_mask =
      __mm256_cmplt_epu32_maskPtr.asFunction<int Function(__m256i, __m256i)>();

  int _mm256_cmpneq_epu32_mask(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_cmpneq_epu32_mask(
      arg0,
      arg1,
    );
  }

  late final __mm256_cmpneq_epu32_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m256i, __m256i)>>(
          '_mm256_cmpneq_epu32_mask');
  late final __mm256_cmpneq_epu32_mask =
      __mm256_cmpneq_epu32_maskPtr.asFunction<int Function(__m256i, __m256i)>();

  int _mm256_mask_cmpeq_epi32_mask(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cmpeq_epi32_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cmpeq_epi32_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m256i, __m256i)>>(
      '_mm256_mask_cmpeq_epi32_mask');
  late final __mm256_mask_cmpeq_epi32_mask = __mm256_mask_cmpeq_epi32_maskPtr
      .asFunction<int Function(int, __m256i, __m256i)>();

  int _mm256_mask_cmpge_epi32_mask(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cmpge_epi32_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cmpge_epi32_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m256i, __m256i)>>(
      '_mm256_mask_cmpge_epi32_mask');
  late final __mm256_mask_cmpge_epi32_mask = __mm256_mask_cmpge_epi32_maskPtr
      .asFunction<int Function(int, __m256i, __m256i)>();

  int _mm256_mask_cmpgt_epi32_mask(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cmpgt_epi32_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cmpgt_epi32_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m256i, __m256i)>>(
      '_mm256_mask_cmpgt_epi32_mask');
  late final __mm256_mask_cmpgt_epi32_mask = __mm256_mask_cmpgt_epi32_maskPtr
      .asFunction<int Function(int, __m256i, __m256i)>();

  int _mm256_mask_cmple_epi32_mask(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cmple_epi32_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cmple_epi32_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m256i, __m256i)>>(
      '_mm256_mask_cmple_epi32_mask');
  late final __mm256_mask_cmple_epi32_mask = __mm256_mask_cmple_epi32_maskPtr
      .asFunction<int Function(int, __m256i, __m256i)>();

  int _mm256_mask_cmplt_epi32_mask(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cmplt_epi32_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cmplt_epi32_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m256i, __m256i)>>(
      '_mm256_mask_cmplt_epi32_mask');
  late final __mm256_mask_cmplt_epi32_mask = __mm256_mask_cmplt_epi32_maskPtr
      .asFunction<int Function(int, __m256i, __m256i)>();

  int _mm256_mask_cmpneq_epi32_mask(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cmpneq_epi32_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cmpneq_epi32_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m256i, __m256i)>>(
      '_mm256_mask_cmpneq_epi32_mask');
  late final __mm256_mask_cmpneq_epi32_mask = __mm256_mask_cmpneq_epi32_maskPtr
      .asFunction<int Function(int, __m256i, __m256i)>();

  int _mm256_mask_cmpeq_epu32_mask(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cmpeq_epu32_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cmpeq_epu32_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m256i, __m256i)>>(
      '_mm256_mask_cmpeq_epu32_mask');
  late final __mm256_mask_cmpeq_epu32_mask = __mm256_mask_cmpeq_epu32_maskPtr
      .asFunction<int Function(int, __m256i, __m256i)>();

  int _mm256_mask_cmpge_epu32_mask(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cmpge_epu32_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cmpge_epu32_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m256i, __m256i)>>(
      '_mm256_mask_cmpge_epu32_mask');
  late final __mm256_mask_cmpge_epu32_mask = __mm256_mask_cmpge_epu32_maskPtr
      .asFunction<int Function(int, __m256i, __m256i)>();

  int _mm256_mask_cmpgt_epu32_mask(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cmpgt_epu32_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cmpgt_epu32_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m256i, __m256i)>>(
      '_mm256_mask_cmpgt_epu32_mask');
  late final __mm256_mask_cmpgt_epu32_mask = __mm256_mask_cmpgt_epu32_maskPtr
      .asFunction<int Function(int, __m256i, __m256i)>();

  int _mm256_mask_cmple_epu32_mask(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cmple_epu32_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cmple_epu32_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m256i, __m256i)>>(
      '_mm256_mask_cmple_epu32_mask');
  late final __mm256_mask_cmple_epu32_mask = __mm256_mask_cmple_epu32_maskPtr
      .asFunction<int Function(int, __m256i, __m256i)>();

  int _mm256_mask_cmplt_epu32_mask(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cmplt_epu32_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cmplt_epu32_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m256i, __m256i)>>(
      '_mm256_mask_cmplt_epu32_mask');
  late final __mm256_mask_cmplt_epu32_mask = __mm256_mask_cmplt_epu32_maskPtr
      .asFunction<int Function(int, __m256i, __m256i)>();

  int _mm256_mask_cmpneq_epu32_mask(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cmpneq_epu32_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cmpneq_epu32_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m256i, __m256i)>>(
      '_mm256_mask_cmpneq_epu32_mask');
  late final __mm256_mask_cmpneq_epu32_mask = __mm256_mask_cmpneq_epu32_maskPtr
      .asFunction<int Function(int, __m256i, __m256i)>();

  int _mm256_cmpeq_epi64_mask(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_cmpeq_epi64_mask(
      arg0,
      arg1,
    );
  }

  late final __mm256_cmpeq_epi64_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m256i, __m256i)>>(
          '_mm256_cmpeq_epi64_mask');
  late final __mm256_cmpeq_epi64_mask =
      __mm256_cmpeq_epi64_maskPtr.asFunction<int Function(__m256i, __m256i)>();

  int _mm256_cmpge_epi64_mask(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_cmpge_epi64_mask(
      arg0,
      arg1,
    );
  }

  late final __mm256_cmpge_epi64_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m256i, __m256i)>>(
          '_mm256_cmpge_epi64_mask');
  late final __mm256_cmpge_epi64_mask =
      __mm256_cmpge_epi64_maskPtr.asFunction<int Function(__m256i, __m256i)>();

  int _mm256_cmpgt_epi64_mask(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_cmpgt_epi64_mask(
      arg0,
      arg1,
    );
  }

  late final __mm256_cmpgt_epi64_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m256i, __m256i)>>(
          '_mm256_cmpgt_epi64_mask');
  late final __mm256_cmpgt_epi64_mask =
      __mm256_cmpgt_epi64_maskPtr.asFunction<int Function(__m256i, __m256i)>();

  int _mm256_cmple_epi64_mask(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_cmple_epi64_mask(
      arg0,
      arg1,
    );
  }

  late final __mm256_cmple_epi64_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m256i, __m256i)>>(
          '_mm256_cmple_epi64_mask');
  late final __mm256_cmple_epi64_mask =
      __mm256_cmple_epi64_maskPtr.asFunction<int Function(__m256i, __m256i)>();

  int _mm256_cmplt_epi64_mask(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_cmplt_epi64_mask(
      arg0,
      arg1,
    );
  }

  late final __mm256_cmplt_epi64_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m256i, __m256i)>>(
          '_mm256_cmplt_epi64_mask');
  late final __mm256_cmplt_epi64_mask =
      __mm256_cmplt_epi64_maskPtr.asFunction<int Function(__m256i, __m256i)>();

  int _mm256_cmpneq_epi64_mask(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_cmpneq_epi64_mask(
      arg0,
      arg1,
    );
  }

  late final __mm256_cmpneq_epi64_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m256i, __m256i)>>(
          '_mm256_cmpneq_epi64_mask');
  late final __mm256_cmpneq_epi64_mask =
      __mm256_cmpneq_epi64_maskPtr.asFunction<int Function(__m256i, __m256i)>();

  int _mm256_cmpeq_epu64_mask(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_cmpeq_epu64_mask(
      arg0,
      arg1,
    );
  }

  late final __mm256_cmpeq_epu64_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m256i, __m256i)>>(
          '_mm256_cmpeq_epu64_mask');
  late final __mm256_cmpeq_epu64_mask =
      __mm256_cmpeq_epu64_maskPtr.asFunction<int Function(__m256i, __m256i)>();

  int _mm256_cmpge_epu64_mask(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_cmpge_epu64_mask(
      arg0,
      arg1,
    );
  }

  late final __mm256_cmpge_epu64_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m256i, __m256i)>>(
          '_mm256_cmpge_epu64_mask');
  late final __mm256_cmpge_epu64_mask =
      __mm256_cmpge_epu64_maskPtr.asFunction<int Function(__m256i, __m256i)>();

  int _mm256_cmpgt_epu64_mask(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_cmpgt_epu64_mask(
      arg0,
      arg1,
    );
  }

  late final __mm256_cmpgt_epu64_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m256i, __m256i)>>(
          '_mm256_cmpgt_epu64_mask');
  late final __mm256_cmpgt_epu64_mask =
      __mm256_cmpgt_epu64_maskPtr.asFunction<int Function(__m256i, __m256i)>();

  int _mm256_cmple_epu64_mask(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_cmple_epu64_mask(
      arg0,
      arg1,
    );
  }

  late final __mm256_cmple_epu64_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m256i, __m256i)>>(
          '_mm256_cmple_epu64_mask');
  late final __mm256_cmple_epu64_mask =
      __mm256_cmple_epu64_maskPtr.asFunction<int Function(__m256i, __m256i)>();

  int _mm256_cmplt_epu64_mask(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_cmplt_epu64_mask(
      arg0,
      arg1,
    );
  }

  late final __mm256_cmplt_epu64_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m256i, __m256i)>>(
          '_mm256_cmplt_epu64_mask');
  late final __mm256_cmplt_epu64_mask =
      __mm256_cmplt_epu64_maskPtr.asFunction<int Function(__m256i, __m256i)>();

  int _mm256_cmpneq_epu64_mask(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_cmpneq_epu64_mask(
      arg0,
      arg1,
    );
  }

  late final __mm256_cmpneq_epu64_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m256i, __m256i)>>(
          '_mm256_cmpneq_epu64_mask');
  late final __mm256_cmpneq_epu64_mask =
      __mm256_cmpneq_epu64_maskPtr.asFunction<int Function(__m256i, __m256i)>();

  int _mm256_mask_cmpeq_epi64_mask(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cmpeq_epi64_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cmpeq_epi64_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m256i, __m256i)>>(
      '_mm256_mask_cmpeq_epi64_mask');
  late final __mm256_mask_cmpeq_epi64_mask = __mm256_mask_cmpeq_epi64_maskPtr
      .asFunction<int Function(int, __m256i, __m256i)>();

  int _mm256_mask_cmpge_epi64_mask(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cmpge_epi64_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cmpge_epi64_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m256i, __m256i)>>(
      '_mm256_mask_cmpge_epi64_mask');
  late final __mm256_mask_cmpge_epi64_mask = __mm256_mask_cmpge_epi64_maskPtr
      .asFunction<int Function(int, __m256i, __m256i)>();

  int _mm256_mask_cmpgt_epi64_mask(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cmpgt_epi64_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cmpgt_epi64_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m256i, __m256i)>>(
      '_mm256_mask_cmpgt_epi64_mask');
  late final __mm256_mask_cmpgt_epi64_mask = __mm256_mask_cmpgt_epi64_maskPtr
      .asFunction<int Function(int, __m256i, __m256i)>();

  int _mm256_mask_cmple_epi64_mask(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cmple_epi64_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cmple_epi64_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m256i, __m256i)>>(
      '_mm256_mask_cmple_epi64_mask');
  late final __mm256_mask_cmple_epi64_mask = __mm256_mask_cmple_epi64_maskPtr
      .asFunction<int Function(int, __m256i, __m256i)>();

  int _mm256_mask_cmplt_epi64_mask(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cmplt_epi64_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cmplt_epi64_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m256i, __m256i)>>(
      '_mm256_mask_cmplt_epi64_mask');
  late final __mm256_mask_cmplt_epi64_mask = __mm256_mask_cmplt_epi64_maskPtr
      .asFunction<int Function(int, __m256i, __m256i)>();

  int _mm256_mask_cmpneq_epi64_mask(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cmpneq_epi64_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cmpneq_epi64_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m256i, __m256i)>>(
      '_mm256_mask_cmpneq_epi64_mask');
  late final __mm256_mask_cmpneq_epi64_mask = __mm256_mask_cmpneq_epi64_maskPtr
      .asFunction<int Function(int, __m256i, __m256i)>();

  int _mm256_mask_cmpeq_epu64_mask(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cmpeq_epu64_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cmpeq_epu64_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m256i, __m256i)>>(
      '_mm256_mask_cmpeq_epu64_mask');
  late final __mm256_mask_cmpeq_epu64_mask = __mm256_mask_cmpeq_epu64_maskPtr
      .asFunction<int Function(int, __m256i, __m256i)>();

  int _mm256_mask_cmpge_epu64_mask(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cmpge_epu64_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cmpge_epu64_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m256i, __m256i)>>(
      '_mm256_mask_cmpge_epu64_mask');
  late final __mm256_mask_cmpge_epu64_mask = __mm256_mask_cmpge_epu64_maskPtr
      .asFunction<int Function(int, __m256i, __m256i)>();

  int _mm256_mask_cmpgt_epu64_mask(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cmpgt_epu64_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cmpgt_epu64_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m256i, __m256i)>>(
      '_mm256_mask_cmpgt_epu64_mask');
  late final __mm256_mask_cmpgt_epu64_mask = __mm256_mask_cmpgt_epu64_maskPtr
      .asFunction<int Function(int, __m256i, __m256i)>();

  int _mm256_mask_cmple_epu64_mask(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cmple_epu64_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cmple_epu64_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m256i, __m256i)>>(
      '_mm256_mask_cmple_epu64_mask');
  late final __mm256_mask_cmple_epu64_mask = __mm256_mask_cmple_epu64_maskPtr
      .asFunction<int Function(int, __m256i, __m256i)>();

  int _mm256_mask_cmplt_epu64_mask(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cmplt_epu64_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cmplt_epu64_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m256i, __m256i)>>(
      '_mm256_mask_cmplt_epu64_mask');
  late final __mm256_mask_cmplt_epu64_mask = __mm256_mask_cmplt_epu64_maskPtr
      .asFunction<int Function(int, __m256i, __m256i)>();

  int _mm256_mask_cmpneq_epu64_mask(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cmpneq_epu64_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cmpneq_epu64_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m256i, __m256i)>>(
      '_mm256_mask_cmpneq_epu64_mask');
  late final __mm256_mask_cmpneq_epu64_mask = __mm256_mask_cmpneq_epu64_maskPtr
      .asFunction<int Function(int, __m256i, __m256i)>();

  _m128d _mm_add_round_sd(
    _m128d arg0,
    _m128d arg1,
    int arg2,
  ) {
    return __mm_add_round_sd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_add_round_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d, ffi.Int32)>>(
          '_mm_add_round_sd');
  late final __mm_add_round_sd =
      __mm_add_round_sdPtr.asFunction<_m128d Function(_m128d, _m128d, int)>();

  _m128d _mm_mask_add_round_sd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    _m128d arg3,
    int arg4,
  ) {
    return __mm_mask_add_round_sd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_add_round_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(_m128d, __mmask8, _m128d, _m128d,
              ffi.Int32)>>('_mm_mask_add_round_sd');
  late final __mm_mask_add_round_sd = __mm_mask_add_round_sdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d, _m128d, int)>();

  _m128d _mm_maskz_add_round_sd(
    int arg0,
    _m128d arg1,
    _m128d arg2,
    int arg3,
  ) {
    return __mm_maskz_add_round_sd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_add_round_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              __mmask8, _m128d, _m128d, ffi.Int32)>>('_mm_maskz_add_round_sd');
  late final __mm_maskz_add_round_sd = __mm_maskz_add_round_sdPtr
      .asFunction<_m128d Function(int, _m128d, _m128d, int)>();

  __m128 _mm_add_round_ss(
    __m128 arg0,
    __m128 arg1,
    int arg2,
  ) {
    return __mm_add_round_ss(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_add_round_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128, ffi.Int32)>>(
          '_mm_add_round_ss');
  late final __mm_add_round_ss =
      __mm_add_round_ssPtr.asFunction<__m128 Function(__m128, __m128, int)>();

  __m128 _mm_mask_add_round_ss(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    __m128 arg3,
    int arg4,
  ) {
    return __mm_mask_add_round_ss(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_add_round_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(__m128, __mmask8, __m128, __m128,
              ffi.Int32)>>('_mm_mask_add_round_ss');
  late final __mm_mask_add_round_ss = __mm_mask_add_round_ssPtr
      .asFunction<__m128 Function(__m128, int, __m128, __m128, int)>();

  __m128 _mm_maskz_add_round_ss(
    int arg0,
    __m128 arg1,
    __m128 arg2,
    int arg3,
  ) {
    return __mm_maskz_add_round_ss(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_add_round_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __mmask8, __m128, __m128, ffi.Int32)>>('_mm_maskz_add_round_ss');
  late final __mm_maskz_add_round_ss = __mm_maskz_add_round_ssPtr
      .asFunction<__m128 Function(int, __m128, __m128, int)>();

  _m128d _mm_mask_add_sd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    _m128d arg3,
  ) {
    return __mm_mask_add_sd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_add_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              _m128d, __mmask8, _m128d, _m128d)>>('_mm_mask_add_sd');
  late final __mm_mask_add_sd = __mm_mask_add_sdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d, _m128d)>();

  _m128d _mm_maskz_add_sd(
    int arg0,
    _m128d arg1,
    _m128d arg2,
  ) {
    return __mm_maskz_add_sd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_add_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(__mmask8, _m128d, _m128d)>>(
          '_mm_maskz_add_sd');
  late final __mm_maskz_add_sd =
      __mm_maskz_add_sdPtr.asFunction<_m128d Function(int, _m128d, _m128d)>();

  __m128 _mm_mask_add_ss(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    __m128 arg3,
  ) {
    return __mm_mask_add_ss(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_add_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __m128, __mmask8, __m128, __m128)>>('_mm_mask_add_ss');
  late final __mm_mask_add_ss = __mm_mask_add_ssPtr
      .asFunction<__m128 Function(__m128, int, __m128, __m128)>();

  __m128 _mm_maskz_add_ss(
    int arg0,
    __m128 arg1,
    __m128 arg2,
  ) {
    return __mm_maskz_add_ss(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_add_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__mmask8, __m128, __m128)>>(
          '_mm_maskz_add_ss');
  late final __mm_maskz_add_ss =
      __mm_maskz_add_ssPtr.asFunction<__m128 Function(int, __m128, __m128)>();

  int _mm_cmp_round_sd_mask(
    _m128d arg0,
    _m128d arg1,
    int arg2,
    int arg3,
  ) {
    return __mm_cmp_round_sd_mask(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_cmp_round_sd_maskPtr = _lookup<
      ffi.NativeFunction<
          __mmask8 Function(
              _m128d, _m128d, ffi.Int32, ffi.Int32)>>('_mm_cmp_round_sd_mask');
  late final __mm_cmp_round_sd_mask = __mm_cmp_round_sd_maskPtr
      .asFunction<int Function(_m128d, _m128d, int, int)>();

  int _mm_mask_cmp_round_sd_mask(
    int arg0,
    _m128d arg1,
    _m128d arg2,
    int arg3,
    int arg4,
  ) {
    return __mm_mask_cmp_round_sd_mask(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_cmp_round_sd_maskPtr = _lookup<
      ffi.NativeFunction<
          __mmask8 Function(__mmask8, _m128d, _m128d, ffi.Int32,
              ffi.Int32)>>('_mm_mask_cmp_round_sd_mask');
  late final __mm_mask_cmp_round_sd_mask = __mm_mask_cmp_round_sd_maskPtr
      .asFunction<int Function(int, _m128d, _m128d, int, int)>();

  int _mm_cmp_round_ss_mask(
    __m128 arg0,
    __m128 arg1,
    int arg2,
    int arg3,
  ) {
    return __mm_cmp_round_ss_mask(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_cmp_round_ss_maskPtr = _lookup<
      ffi.NativeFunction<
          __mmask8 Function(
              __m128, __m128, ffi.Int32, ffi.Int32)>>('_mm_cmp_round_ss_mask');
  late final __mm_cmp_round_ss_mask = __mm_cmp_round_ss_maskPtr
      .asFunction<int Function(__m128, __m128, int, int)>();

  int _mm_mask_cmp_round_ss_mask(
    int arg0,
    __m128 arg1,
    __m128 arg2,
    int arg3,
    int arg4,
  ) {
    return __mm_mask_cmp_round_ss_mask(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_cmp_round_ss_maskPtr = _lookup<
      ffi.NativeFunction<
          __mmask8 Function(__mmask8, __m128, __m128, ffi.Int32,
              ffi.Int32)>>('_mm_mask_cmp_round_ss_mask');
  late final __mm_mask_cmp_round_ss_mask = __mm_mask_cmp_round_ss_maskPtr
      .asFunction<int Function(int, __m128, __m128, int, int)>();

  int _mm_cmp_sd_mask(
    _m128d arg0,
    _m128d arg1,
    int arg2,
  ) {
    return __mm_cmp_sd_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_cmp_sd_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(_m128d, _m128d, ffi.Int32)>>(
          '_mm_cmp_sd_mask');
  late final __mm_cmp_sd_mask =
      __mm_cmp_sd_maskPtr.asFunction<int Function(_m128d, _m128d, int)>();

  int _mm_mask_cmp_sd_mask(
    int arg0,
    _m128d arg1,
    _m128d arg2,
    int arg3,
  ) {
    return __mm_mask_cmp_sd_mask(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_cmp_sd_maskPtr = _lookup<
      ffi.NativeFunction<
          __mmask8 Function(
              __mmask8, _m128d, _m128d, ffi.Int32)>>('_mm_mask_cmp_sd_mask');
  late final __mm_mask_cmp_sd_mask = __mm_mask_cmp_sd_maskPtr
      .asFunction<int Function(int, _m128d, _m128d, int)>();

  int _mm_cmp_ss_mask(
    __m128 arg0,
    __m128 arg1,
    int arg2,
  ) {
    return __mm_cmp_ss_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_cmp_ss_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m128, __m128, ffi.Int32)>>(
          '_mm_cmp_ss_mask');
  late final __mm_cmp_ss_mask =
      __mm_cmp_ss_maskPtr.asFunction<int Function(__m128, __m128, int)>();

  int _mm_mask_cmp_ss_mask(
    int arg0,
    __m128 arg1,
    __m128 arg2,
    int arg3,
  ) {
    return __mm_mask_cmp_ss_mask(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_cmp_ss_maskPtr = _lookup<
      ffi.NativeFunction<
          __mmask8 Function(
              __mmask8, __m128, __m128, ffi.Int32)>>('_mm_mask_cmp_ss_mask');
  late final __mm_mask_cmp_ss_mask = __mm_mask_cmp_ss_maskPtr
      .asFunction<int Function(int, __m128, __m128, int)>();

  int _mm_comi_round_sd(
    _m128d arg0,
    _m128d arg1,
    int arg2,
    int arg3,
  ) {
    return __mm_comi_round_sd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_comi_round_sdPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              _m128d, _m128d, ffi.Int32, ffi.Int32)>>('_mm_comi_round_sd');
  late final __mm_comi_round_sd = __mm_comi_round_sdPtr
      .asFunction<int Function(_m128d, _m128d, int, int)>();

  int _mm_comi_round_ss(
    __m128 arg0,
    __m128 arg1,
    int arg2,
    int arg3,
  ) {
    return __mm_comi_round_ss(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_comi_round_ssPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              __m128, __m128, ffi.Int32, ffi.Int32)>>('_mm_comi_round_ss');
  late final __mm_comi_round_ss = __mm_comi_round_ssPtr
      .asFunction<int Function(__m128, __m128, int, int)>();

  __m128 _mm_cvt_roundi32_ss(
    __m128 arg0,
    int arg1,
    int arg2,
  ) {
    return __mm_cvt_roundi32_ss(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_cvt_roundi32_ssPtr = _lookup<
          ffi.NativeFunction<__m128 Function(__m128, ffi.Int32, ffi.Int32)>>(
      '_mm_cvt_roundi32_ss');
  late final __mm_cvt_roundi32_ss =
      __mm_cvt_roundi32_ssPtr.asFunction<__m128 Function(__m128, int, int)>();

  int _mm_cvt_roundsd_i32(
    _m128d arg0,
    int arg1,
  ) {
    return __mm_cvt_roundsd_i32(
      arg0,
      arg1,
    );
  }

  late final __mm_cvt_roundsd_i32Ptr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(_m128d, ffi.Int32)>>(
          '_mm_cvt_roundsd_i32');
  late final __mm_cvt_roundsd_i32 =
      __mm_cvt_roundsd_i32Ptr.asFunction<int Function(_m128d, int)>();

  int _mm_cvt_roundsd_si32(
    _m128d arg0,
    int arg1,
  ) {
    return __mm_cvt_roundsd_si32(
      arg0,
      arg1,
    );
  }

  late final __mm_cvt_roundsd_si32Ptr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(_m128d, ffi.Int32)>>(
          '_mm_cvt_roundsd_si32');
  late final __mm_cvt_roundsd_si32 =
      __mm_cvt_roundsd_si32Ptr.asFunction<int Function(_m128d, int)>();

  __m128 _mm_cvt_roundsd_ss(
    __m128 arg0,
    _m128d arg1,
    int arg2,
  ) {
    return __mm_cvt_roundsd_ss(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_cvt_roundsd_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, _m128d, ffi.Int32)>>(
          '_mm_cvt_roundsd_ss');
  late final __mm_cvt_roundsd_ss =
      __mm_cvt_roundsd_ssPtr.asFunction<__m128 Function(__m128, _m128d, int)>();

  __m128 _mm_mask_cvt_roundsd_ss(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    _m128d arg3,
    int arg4,
  ) {
    return __mm_mask_cvt_roundsd_ss(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_cvt_roundsd_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(__m128, __mmask8, __m128, _m128d,
              ffi.Int32)>>('_mm_mask_cvt_roundsd_ss');
  late final __mm_mask_cvt_roundsd_ss = __mm_mask_cvt_roundsd_ssPtr
      .asFunction<__m128 Function(__m128, int, __m128, _m128d, int)>();

  __m128 _mm_maskz_cvt_roundsd_ss(
    int arg0,
    __m128 arg1,
    _m128d arg2,
    int arg3,
  ) {
    return __mm_maskz_cvt_roundsd_ss(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_cvt_roundsd_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(__mmask8, __m128, _m128d,
              ffi.Int32)>>('_mm_maskz_cvt_roundsd_ss');
  late final __mm_maskz_cvt_roundsd_ss = __mm_maskz_cvt_roundsd_ssPtr
      .asFunction<__m128 Function(int, __m128, _m128d, int)>();

  int _mm_cvt_roundsd_u32(
    _m128d arg0,
    int arg1,
  ) {
    return __mm_cvt_roundsd_u32(
      arg0,
      arg1,
    );
  }

  late final __mm_cvt_roundsd_u32Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint32 Function(_m128d, ffi.Int32)>>(
          '_mm_cvt_roundsd_u32');
  late final __mm_cvt_roundsd_u32 =
      __mm_cvt_roundsd_u32Ptr.asFunction<int Function(_m128d, int)>();

  __m128 _mm_cvt_roundsi32_ss(
    __m128 arg0,
    int arg1,
    int arg2,
  ) {
    return __mm_cvt_roundsi32_ss(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_cvt_roundsi32_ssPtr = _lookup<
          ffi.NativeFunction<__m128 Function(__m128, ffi.Int32, ffi.Int32)>>(
      '_mm_cvt_roundsi32_ss');
  late final __mm_cvt_roundsi32_ss =
      __mm_cvt_roundsi32_ssPtr.asFunction<__m128 Function(__m128, int, int)>();

  int _mm_cvt_roundss_i32(
    __m128 arg0,
    int arg1,
  ) {
    return __mm_cvt_roundss_i32(
      arg0,
      arg1,
    );
  }

  late final __mm_cvt_roundss_i32Ptr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(__m128, ffi.Int32)>>(
          '_mm_cvt_roundss_i32');
  late final __mm_cvt_roundss_i32 =
      __mm_cvt_roundss_i32Ptr.asFunction<int Function(__m128, int)>();

  _m128d _mm_cvt_roundss_sd(
    _m128d arg0,
    __m128 arg1,
    int arg2,
  ) {
    return __mm_cvt_roundss_sd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_cvt_roundss_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, __m128, ffi.Int32)>>(
          '_mm_cvt_roundss_sd');
  late final __mm_cvt_roundss_sd =
      __mm_cvt_roundss_sdPtr.asFunction<_m128d Function(_m128d, __m128, int)>();

  _m128d _mm_mask_cvt_roundss_sd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    __m128 arg3,
    int arg4,
  ) {
    return __mm_mask_cvt_roundss_sd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_cvt_roundss_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(_m128d, __mmask8, _m128d, __m128,
              ffi.Int32)>>('_mm_mask_cvt_roundss_sd');
  late final __mm_mask_cvt_roundss_sd = __mm_mask_cvt_roundss_sdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d, __m128, int)>();

  _m128d _mm_maskz_cvt_roundss_sd(
    int arg0,
    _m128d arg1,
    __m128 arg2,
    int arg3,
  ) {
    return __mm_maskz_cvt_roundss_sd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_cvt_roundss_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(__mmask8, _m128d, __m128,
              ffi.Int32)>>('_mm_maskz_cvt_roundss_sd');
  late final __mm_maskz_cvt_roundss_sd = __mm_maskz_cvt_roundss_sdPtr
      .asFunction<_m128d Function(int, _m128d, __m128, int)>();

  int _mm_cvt_roundss_si32(
    __m128 arg0,
    int arg1,
  ) {
    return __mm_cvt_roundss_si32(
      arg0,
      arg1,
    );
  }

  late final __mm_cvt_roundss_si32Ptr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(__m128, ffi.Int32)>>(
          '_mm_cvt_roundss_si32');
  late final __mm_cvt_roundss_si32 =
      __mm_cvt_roundss_si32Ptr.asFunction<int Function(__m128, int)>();

  int _mm_cvt_roundss_u32(
    __m128 arg0,
    int arg1,
  ) {
    return __mm_cvt_roundss_u32(
      arg0,
      arg1,
    );
  }

  late final __mm_cvt_roundss_u32Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint32 Function(__m128, ffi.Int32)>>(
          '_mm_cvt_roundss_u32');
  late final __mm_cvt_roundss_u32 =
      __mm_cvt_roundss_u32Ptr.asFunction<int Function(__m128, int)>();

  __m128 _mm_cvt_roundu32_ss(
    __m128 arg0,
    int arg1,
    int arg2,
  ) {
    return __mm_cvt_roundu32_ss(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_cvt_roundu32_ssPtr = _lookup<
          ffi.NativeFunction<__m128 Function(__m128, ffi.Uint32, ffi.Int32)>>(
      '_mm_cvt_roundu32_ss');
  late final __mm_cvt_roundu32_ss =
      __mm_cvt_roundu32_ssPtr.asFunction<__m128 Function(__m128, int, int)>();

  _m128d _mm_cvti32_sd(
    _m128d arg0,
    int arg1,
  ) {
    return __mm_cvti32_sd(
      arg0,
      arg1,
    );
  }

  late final __mm_cvti32_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, ffi.Int32)>>(
          '_mm_cvti32_sd');
  late final __mm_cvti32_sd =
      __mm_cvti32_sdPtr.asFunction<_m128d Function(_m128d, int)>();

  __m128 _mm_cvti32_ss(
    __m128 arg0,
    int arg1,
  ) {
    return __mm_cvti32_ss(
      arg0,
      arg1,
    );
  }

  late final __mm_cvti32_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, ffi.Int32)>>(
          '_mm_cvti32_ss');
  late final __mm_cvti32_ss =
      __mm_cvti32_ssPtr.asFunction<__m128 Function(__m128, int)>();

  int _mm_cvtsd_i32(
    _m128d arg0,
  ) {
    return __mm_cvtsd_i32(
      arg0,
    );
  }

  late final __mm_cvtsd_i32Ptr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(_m128d)>>('_mm_cvtsd_i32');
  late final __mm_cvtsd_i32 =
      __mm_cvtsd_i32Ptr.asFunction<int Function(_m128d)>();

  __m128 _mm_mask_cvtsd_ss(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    _m128d arg3,
  ) {
    return __mm_mask_cvtsd_ss(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_cvtsd_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __m128, __mmask8, __m128, _m128d)>>('_mm_mask_cvtsd_ss');
  late final __mm_mask_cvtsd_ss = __mm_mask_cvtsd_ssPtr
      .asFunction<__m128 Function(__m128, int, __m128, _m128d)>();

  __m128 _mm_maskz_cvtsd_ss(
    int arg0,
    __m128 arg1,
    _m128d arg2,
  ) {
    return __mm_maskz_cvtsd_ss(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_cvtsd_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__mmask8, __m128, _m128d)>>(
          '_mm_maskz_cvtsd_ss');
  late final __mm_maskz_cvtsd_ss =
      __mm_maskz_cvtsd_ssPtr.asFunction<__m128 Function(int, __m128, _m128d)>();

  int _mm_cvtsd_u32(
    _m128d arg0,
  ) {
    return __mm_cvtsd_u32(
      arg0,
    );
  }

  late final __mm_cvtsd_u32Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint32 Function(_m128d)>>('_mm_cvtsd_u32');
  late final __mm_cvtsd_u32 =
      __mm_cvtsd_u32Ptr.asFunction<int Function(_m128d)>();

  int _mm_cvtss_i32(
    __m128 arg0,
  ) {
    return __mm_cvtss_i32(
      arg0,
    );
  }

  late final __mm_cvtss_i32Ptr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(__m128)>>('_mm_cvtss_i32');
  late final __mm_cvtss_i32 =
      __mm_cvtss_i32Ptr.asFunction<int Function(__m128)>();

  _m128d _mm_mask_cvtss_sd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    __m128 arg3,
  ) {
    return __mm_mask_cvtss_sd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_cvtss_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              _m128d, __mmask8, _m128d, __m128)>>('_mm_mask_cvtss_sd');
  late final __mm_mask_cvtss_sd = __mm_mask_cvtss_sdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d, __m128)>();

  _m128d _mm_maskz_cvtss_sd(
    int arg0,
    _m128d arg1,
    __m128 arg2,
  ) {
    return __mm_maskz_cvtss_sd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_cvtss_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(__mmask8, _m128d, __m128)>>(
          '_mm_maskz_cvtss_sd');
  late final __mm_maskz_cvtss_sd =
      __mm_maskz_cvtss_sdPtr.asFunction<_m128d Function(int, _m128d, __m128)>();

  int _mm_cvtss_u32(
    __m128 arg0,
  ) {
    return __mm_cvtss_u32(
      arg0,
    );
  }

  late final __mm_cvtss_u32Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint32 Function(__m128)>>('_mm_cvtss_u32');
  late final __mm_cvtss_u32 =
      __mm_cvtss_u32Ptr.asFunction<int Function(__m128)>();

  int _mm_cvtt_roundsd_i32(
    _m128d arg0,
    int arg1,
  ) {
    return __mm_cvtt_roundsd_i32(
      arg0,
      arg1,
    );
  }

  late final __mm_cvtt_roundsd_i32Ptr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(_m128d, ffi.Int32)>>(
          '_mm_cvtt_roundsd_i32');
  late final __mm_cvtt_roundsd_i32 =
      __mm_cvtt_roundsd_i32Ptr.asFunction<int Function(_m128d, int)>();

  int _mm_cvtt_roundsd_si32(
    _m128d arg0,
    int arg1,
  ) {
    return __mm_cvtt_roundsd_si32(
      arg0,
      arg1,
    );
  }

  late final __mm_cvtt_roundsd_si32Ptr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(_m128d, ffi.Int32)>>(
          '_mm_cvtt_roundsd_si32');
  late final __mm_cvtt_roundsd_si32 =
      __mm_cvtt_roundsd_si32Ptr.asFunction<int Function(_m128d, int)>();

  int _mm_cvtt_roundsd_u32(
    _m128d arg0,
    int arg1,
  ) {
    return __mm_cvtt_roundsd_u32(
      arg0,
      arg1,
    );
  }

  late final __mm_cvtt_roundsd_u32Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint32 Function(_m128d, ffi.Int32)>>(
          '_mm_cvtt_roundsd_u32');
  late final __mm_cvtt_roundsd_u32 =
      __mm_cvtt_roundsd_u32Ptr.asFunction<int Function(_m128d, int)>();

  int _mm_cvtt_roundss_i32(
    __m128 arg0,
    int arg1,
  ) {
    return __mm_cvtt_roundss_i32(
      arg0,
      arg1,
    );
  }

  late final __mm_cvtt_roundss_i32Ptr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(__m128, ffi.Int32)>>(
          '_mm_cvtt_roundss_i32');
  late final __mm_cvtt_roundss_i32 =
      __mm_cvtt_roundss_i32Ptr.asFunction<int Function(__m128, int)>();

  int _mm_cvtt_roundss_si32(
    __m128 arg0,
    int arg1,
  ) {
    return __mm_cvtt_roundss_si32(
      arg0,
      arg1,
    );
  }

  late final __mm_cvtt_roundss_si32Ptr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(__m128, ffi.Int32)>>(
          '_mm_cvtt_roundss_si32');
  late final __mm_cvtt_roundss_si32 =
      __mm_cvtt_roundss_si32Ptr.asFunction<int Function(__m128, int)>();

  int _mm_cvtt_roundss_u32(
    __m128 arg0,
    int arg1,
  ) {
    return __mm_cvtt_roundss_u32(
      arg0,
      arg1,
    );
  }

  late final __mm_cvtt_roundss_u32Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint32 Function(__m128, ffi.Int32)>>(
          '_mm_cvtt_roundss_u32');
  late final __mm_cvtt_roundss_u32 =
      __mm_cvtt_roundss_u32Ptr.asFunction<int Function(__m128, int)>();

  int _mm_cvttsd_i32(
    _m128d arg0,
  ) {
    return __mm_cvttsd_i32(
      arg0,
    );
  }

  late final __mm_cvttsd_i32Ptr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(_m128d)>>('_mm_cvttsd_i32');
  late final __mm_cvttsd_i32 =
      __mm_cvttsd_i32Ptr.asFunction<int Function(_m128d)>();

  int _mm_cvttsd_u32(
    _m128d arg0,
  ) {
    return __mm_cvttsd_u32(
      arg0,
    );
  }

  late final __mm_cvttsd_u32Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint32 Function(_m128d)>>(
          '_mm_cvttsd_u32');
  late final __mm_cvttsd_u32 =
      __mm_cvttsd_u32Ptr.asFunction<int Function(_m128d)>();

  int _mm_cvttss_i32(
    __m128 arg0,
  ) {
    return __mm_cvttss_i32(
      arg0,
    );
  }

  late final __mm_cvttss_i32Ptr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(__m128)>>('_mm_cvttss_i32');
  late final __mm_cvttss_i32 =
      __mm_cvttss_i32Ptr.asFunction<int Function(__m128)>();

  int _mm_cvttss_u32(
    __m128 arg0,
  ) {
    return __mm_cvttss_u32(
      arg0,
    );
  }

  late final __mm_cvttss_u32Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint32 Function(__m128)>>(
          '_mm_cvttss_u32');
  late final __mm_cvttss_u32 =
      __mm_cvttss_u32Ptr.asFunction<int Function(__m128)>();

  _m128d _mm_cvtu32_sd(
    _m128d arg0,
    int arg1,
  ) {
    return __mm_cvtu32_sd(
      arg0,
      arg1,
    );
  }

  late final __mm_cvtu32_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, ffi.Uint32)>>(
          '_mm_cvtu32_sd');
  late final __mm_cvtu32_sd =
      __mm_cvtu32_sdPtr.asFunction<_m128d Function(_m128d, int)>();

  __m128 _mm_cvtu32_ss(
    __m128 arg0,
    int arg1,
  ) {
    return __mm_cvtu32_ss(
      arg0,
      arg1,
    );
  }

  late final __mm_cvtu32_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, ffi.Uint32)>>(
          '_mm_cvtu32_ss');
  late final __mm_cvtu32_ss =
      __mm_cvtu32_ssPtr.asFunction<__m128 Function(__m128, int)>();

  _m128d _mm_div_round_sd(
    _m128d arg0,
    _m128d arg1,
    int arg2,
  ) {
    return __mm_div_round_sd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_div_round_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d, ffi.Int32)>>(
          '_mm_div_round_sd');
  late final __mm_div_round_sd =
      __mm_div_round_sdPtr.asFunction<_m128d Function(_m128d, _m128d, int)>();

  _m128d _mm_mask_div_round_sd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    _m128d arg3,
    int arg4,
  ) {
    return __mm_mask_div_round_sd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_div_round_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(_m128d, __mmask8, _m128d, _m128d,
              ffi.Int32)>>('_mm_mask_div_round_sd');
  late final __mm_mask_div_round_sd = __mm_mask_div_round_sdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d, _m128d, int)>();

  _m128d _mm_maskz_div_round_sd(
    int arg0,
    _m128d arg1,
    _m128d arg2,
    int arg3,
  ) {
    return __mm_maskz_div_round_sd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_div_round_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              __mmask8, _m128d, _m128d, ffi.Int32)>>('_mm_maskz_div_round_sd');
  late final __mm_maskz_div_round_sd = __mm_maskz_div_round_sdPtr
      .asFunction<_m128d Function(int, _m128d, _m128d, int)>();

  __m128 _mm_div_round_ss(
    __m128 arg0,
    __m128 arg1,
    int arg2,
  ) {
    return __mm_div_round_ss(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_div_round_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128, ffi.Int32)>>(
          '_mm_div_round_ss');
  late final __mm_div_round_ss =
      __mm_div_round_ssPtr.asFunction<__m128 Function(__m128, __m128, int)>();

  __m128 _mm_mask_div_round_ss(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    __m128 arg3,
    int arg4,
  ) {
    return __mm_mask_div_round_ss(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_div_round_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(__m128, __mmask8, __m128, __m128,
              ffi.Int32)>>('_mm_mask_div_round_ss');
  late final __mm_mask_div_round_ss = __mm_mask_div_round_ssPtr
      .asFunction<__m128 Function(__m128, int, __m128, __m128, int)>();

  __m128 _mm_maskz_div_round_ss(
    int arg0,
    __m128 arg1,
    __m128 arg2,
    int arg3,
  ) {
    return __mm_maskz_div_round_ss(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_div_round_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __mmask8, __m128, __m128, ffi.Int32)>>('_mm_maskz_div_round_ss');
  late final __mm_maskz_div_round_ss = __mm_maskz_div_round_ssPtr
      .asFunction<__m128 Function(int, __m128, __m128, int)>();

  _m128d _mm_mask_div_sd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    _m128d arg3,
  ) {
    return __mm_mask_div_sd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_div_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              _m128d, __mmask8, _m128d, _m128d)>>('_mm_mask_div_sd');
  late final __mm_mask_div_sd = __mm_mask_div_sdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d, _m128d)>();

  _m128d _mm_maskz_div_sd(
    int arg0,
    _m128d arg1,
    _m128d arg2,
  ) {
    return __mm_maskz_div_sd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_div_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(__mmask8, _m128d, _m128d)>>(
          '_mm_maskz_div_sd');
  late final __mm_maskz_div_sd =
      __mm_maskz_div_sdPtr.asFunction<_m128d Function(int, _m128d, _m128d)>();

  __m128 _mm_mask_div_ss(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    __m128 arg3,
  ) {
    return __mm_mask_div_ss(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_div_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __m128, __mmask8, __m128, __m128)>>('_mm_mask_div_ss');
  late final __mm_mask_div_ss = __mm_mask_div_ssPtr
      .asFunction<__m128 Function(__m128, int, __m128, __m128)>();

  __m128 _mm_maskz_div_ss(
    int arg0,
    __m128 arg1,
    __m128 arg2,
  ) {
    return __mm_maskz_div_ss(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_div_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__mmask8, __m128, __m128)>>(
          '_mm_maskz_div_ss');
  late final __mm_maskz_div_ss =
      __mm_maskz_div_ssPtr.asFunction<__m128 Function(int, __m128, __m128)>();

  _m128d _mm_fixupimm_round_sd(
    _m128d arg0,
    _m128d arg1,
    __m128i arg2,
    int arg3,
    int arg4,
  ) {
    return __mm_fixupimm_round_sd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_fixupimm_round_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(_m128d, _m128d, __m128i, ffi.Int32,
              ffi.Int32)>>('_mm_fixupimm_round_sd');
  late final __mm_fixupimm_round_sd = __mm_fixupimm_round_sdPtr
      .asFunction<_m128d Function(_m128d, _m128d, __m128i, int, int)>();

  _m128d _mm_mask_fixupimm_round_sd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    __m128i arg3,
    int arg4,
    int arg5,
  ) {
    return __mm_mask_fixupimm_round_sd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
      arg5,
    );
  }

  late final __mm_mask_fixupimm_round_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(_m128d, __mmask8, _m128d, __m128i, ffi.Int32,
              ffi.Int32)>>('_mm_mask_fixupimm_round_sd');
  late final __mm_mask_fixupimm_round_sd = __mm_mask_fixupimm_round_sdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d, __m128i, int, int)>();

  _m128d _mm_maskz_fixupimm_round_sd(
    int arg0,
    _m128d arg1,
    _m128d arg2,
    __m128i arg3,
    int arg4,
    int arg5,
  ) {
    return __mm_maskz_fixupimm_round_sd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
      arg5,
    );
  }

  late final __mm_maskz_fixupimm_round_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(__mmask8, _m128d, _m128d, __m128i, ffi.Int32,
              ffi.Int32)>>('_mm_maskz_fixupimm_round_sd');
  late final __mm_maskz_fixupimm_round_sd = __mm_maskz_fixupimm_round_sdPtr
      .asFunction<_m128d Function(int, _m128d, _m128d, __m128i, int, int)>();

  __m128 _mm_fixupimm_round_ss(
    __m128 arg0,
    __m128 arg1,
    __m128i arg2,
    int arg3,
    int arg4,
  ) {
    return __mm_fixupimm_round_ss(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_fixupimm_round_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(__m128, __m128, __m128i, ffi.Int32,
              ffi.Int32)>>('_mm_fixupimm_round_ss');
  late final __mm_fixupimm_round_ss = __mm_fixupimm_round_ssPtr
      .asFunction<__m128 Function(__m128, __m128, __m128i, int, int)>();

  __m128 _mm_mask_fixupimm_round_ss(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    __m128i arg3,
    int arg4,
    int arg5,
  ) {
    return __mm_mask_fixupimm_round_ss(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
      arg5,
    );
  }

  late final __mm_mask_fixupimm_round_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(__m128, __mmask8, __m128, __m128i, ffi.Int32,
              ffi.Int32)>>('_mm_mask_fixupimm_round_ss');
  late final __mm_mask_fixupimm_round_ss = __mm_mask_fixupimm_round_ssPtr
      .asFunction<__m128 Function(__m128, int, __m128, __m128i, int, int)>();

  __m128 _mm_maskz_fixupimm_round_ss(
    int arg0,
    __m128 arg1,
    __m128 arg2,
    __m128i arg3,
    int arg4,
    int arg5,
  ) {
    return __mm_maskz_fixupimm_round_ss(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
      arg5,
    );
  }

  late final __mm_maskz_fixupimm_round_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(__mmask8, __m128, __m128, __m128i, ffi.Int32,
              ffi.Int32)>>('_mm_maskz_fixupimm_round_ss');
  late final __mm_maskz_fixupimm_round_ss = __mm_maskz_fixupimm_round_ssPtr
      .asFunction<__m128 Function(int, __m128, __m128, __m128i, int, int)>();

  _m128d _mm_fixupimm_sd(
    _m128d arg0,
    _m128d arg1,
    __m128i arg2,
    int arg3,
  ) {
    return __mm_fixupimm_sd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_fixupimm_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              _m128d, _m128d, __m128i, ffi.Int32)>>('_mm_fixupimm_sd');
  late final __mm_fixupimm_sd = __mm_fixupimm_sdPtr
      .asFunction<_m128d Function(_m128d, _m128d, __m128i, int)>();

  _m128d _mm_mask_fixupimm_sd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    __m128i arg3,
    int arg4,
  ) {
    return __mm_mask_fixupimm_sd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_fixupimm_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(_m128d, __mmask8, _m128d, __m128i,
              ffi.Int32)>>('_mm_mask_fixupimm_sd');
  late final __mm_mask_fixupimm_sd = __mm_mask_fixupimm_sdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d, __m128i, int)>();

  _m128d _mm_maskz_fixupimm_sd(
    int arg0,
    _m128d arg1,
    _m128d arg2,
    __m128i arg3,
    int arg4,
  ) {
    return __mm_maskz_fixupimm_sd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_maskz_fixupimm_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(__mmask8, _m128d, _m128d, __m128i,
              ffi.Int32)>>('_mm_maskz_fixupimm_sd');
  late final __mm_maskz_fixupimm_sd = __mm_maskz_fixupimm_sdPtr
      .asFunction<_m128d Function(int, _m128d, _m128d, __m128i, int)>();

  __m128 _mm_fixupimm_ss(
    __m128 arg0,
    __m128 arg1,
    __m128i arg2,
    int arg3,
  ) {
    return __mm_fixupimm_ss(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_fixupimm_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __m128, __m128, __m128i, ffi.Int32)>>('_mm_fixupimm_ss');
  late final __mm_fixupimm_ss = __mm_fixupimm_ssPtr
      .asFunction<__m128 Function(__m128, __m128, __m128i, int)>();

  __m128 _mm_mask_fixupimm_ss(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    __m128i arg3,
    int arg4,
  ) {
    return __mm_mask_fixupimm_ss(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_fixupimm_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(__m128, __mmask8, __m128, __m128i,
              ffi.Int32)>>('_mm_mask_fixupimm_ss');
  late final __mm_mask_fixupimm_ss = __mm_mask_fixupimm_ssPtr
      .asFunction<__m128 Function(__m128, int, __m128, __m128i, int)>();

  __m128 _mm_maskz_fixupimm_ss(
    int arg0,
    __m128 arg1,
    __m128 arg2,
    __m128i arg3,
    int arg4,
  ) {
    return __mm_maskz_fixupimm_ss(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_maskz_fixupimm_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(__mmask8, __m128, __m128, __m128i,
              ffi.Int32)>>('_mm_maskz_fixupimm_ss');
  late final __mm_maskz_fixupimm_ss = __mm_maskz_fixupimm_ssPtr
      .asFunction<__m128 Function(int, __m128, __m128, __m128i, int)>();

  _m128d _mm_fmadd_round_sd(
    _m128d arg0,
    _m128d arg1,
    _m128d arg2,
    int arg3,
  ) {
    return __mm_fmadd_round_sd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_fmadd_round_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              _m128d, _m128d, _m128d, ffi.Int32)>>('_mm_fmadd_round_sd');
  late final __mm_fmadd_round_sd = __mm_fmadd_round_sdPtr
      .asFunction<_m128d Function(_m128d, _m128d, _m128d, int)>();

  _m128d _mm_mask_fmadd_round_sd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    _m128d arg3,
    int arg4,
  ) {
    return __mm_mask_fmadd_round_sd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_fmadd_round_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(_m128d, __mmask8, _m128d, _m128d,
              ffi.Int32)>>('_mm_mask_fmadd_round_sd');
  late final __mm_mask_fmadd_round_sd = __mm_mask_fmadd_round_sdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d, _m128d, int)>();

  _m128d _mm_mask3_fmadd_round_sd(
    _m128d arg0,
    _m128d arg1,
    _m128d arg2,
    int arg3,
    int arg4,
  ) {
    return __mm_mask3_fmadd_round_sd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask3_fmadd_round_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(_m128d, _m128d, _m128d, __mmask8,
              ffi.Int32)>>('_mm_mask3_fmadd_round_sd');
  late final __mm_mask3_fmadd_round_sd = __mm_mask3_fmadd_round_sdPtr
      .asFunction<_m128d Function(_m128d, _m128d, _m128d, int, int)>();

  _m128d _mm_maskz_fmadd_round_sd(
    int arg0,
    _m128d arg1,
    _m128d arg2,
    _m128d arg3,
    int arg4,
  ) {
    return __mm_maskz_fmadd_round_sd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_maskz_fmadd_round_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(__mmask8, _m128d, _m128d, _m128d,
              ffi.Int32)>>('_mm_maskz_fmadd_round_sd');
  late final __mm_maskz_fmadd_round_sd = __mm_maskz_fmadd_round_sdPtr
      .asFunction<_m128d Function(int, _m128d, _m128d, _m128d, int)>();

  __m128 _mm_fmadd_round_ss(
    __m128 arg0,
    __m128 arg1,
    __m128 arg2,
    int arg3,
  ) {
    return __mm_fmadd_round_ss(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_fmadd_round_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __m128, __m128, __m128, ffi.Int32)>>('_mm_fmadd_round_ss');
  late final __mm_fmadd_round_ss = __mm_fmadd_round_ssPtr
      .asFunction<__m128 Function(__m128, __m128, __m128, int)>();

  __m128 _mm_mask_fmadd_round_ss(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    __m128 arg3,
    int arg4,
  ) {
    return __mm_mask_fmadd_round_ss(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_fmadd_round_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(__m128, __mmask8, __m128, __m128,
              ffi.Int32)>>('_mm_mask_fmadd_round_ss');
  late final __mm_mask_fmadd_round_ss = __mm_mask_fmadd_round_ssPtr
      .asFunction<__m128 Function(__m128, int, __m128, __m128, int)>();

  __m128 _mm_mask3_fmadd_round_ss(
    __m128 arg0,
    __m128 arg1,
    __m128 arg2,
    int arg3,
    int arg4,
  ) {
    return __mm_mask3_fmadd_round_ss(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask3_fmadd_round_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(__m128, __m128, __m128, __mmask8,
              ffi.Int32)>>('_mm_mask3_fmadd_round_ss');
  late final __mm_mask3_fmadd_round_ss = __mm_mask3_fmadd_round_ssPtr
      .asFunction<__m128 Function(__m128, __m128, __m128, int, int)>();

  __m128 _mm_maskz_fmadd_round_ss(
    int arg0,
    __m128 arg1,
    __m128 arg2,
    __m128 arg3,
    int arg4,
  ) {
    return __mm_maskz_fmadd_round_ss(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_maskz_fmadd_round_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(__mmask8, __m128, __m128, __m128,
              ffi.Int32)>>('_mm_maskz_fmadd_round_ss');
  late final __mm_maskz_fmadd_round_ss = __mm_maskz_fmadd_round_ssPtr
      .asFunction<__m128 Function(int, __m128, __m128, __m128, int)>();

  _m128d _mm_mask_fmadd_sd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    _m128d arg3,
  ) {
    return __mm_mask_fmadd_sd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_fmadd_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              _m128d, __mmask8, _m128d, _m128d)>>('_mm_mask_fmadd_sd');
  late final __mm_mask_fmadd_sd = __mm_mask_fmadd_sdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d, _m128d)>();

  _m128d _mm_mask3_fmadd_sd(
    _m128d arg0,
    _m128d arg1,
    _m128d arg2,
    int arg3,
  ) {
    return __mm_mask3_fmadd_sd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask3_fmadd_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              _m128d, _m128d, _m128d, __mmask8)>>('_mm_mask3_fmadd_sd');
  late final __mm_mask3_fmadd_sd = __mm_mask3_fmadd_sdPtr
      .asFunction<_m128d Function(_m128d, _m128d, _m128d, int)>();

  _m128d _mm_maskz_fmadd_sd(
    int arg0,
    _m128d arg1,
    _m128d arg2,
    _m128d arg3,
  ) {
    return __mm_maskz_fmadd_sd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_fmadd_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              __mmask8, _m128d, _m128d, _m128d)>>('_mm_maskz_fmadd_sd');
  late final __mm_maskz_fmadd_sd = __mm_maskz_fmadd_sdPtr
      .asFunction<_m128d Function(int, _m128d, _m128d, _m128d)>();

  __m128 _mm_mask_fmadd_ss(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    __m128 arg3,
  ) {
    return __mm_mask_fmadd_ss(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_fmadd_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __m128, __mmask8, __m128, __m128)>>('_mm_mask_fmadd_ss');
  late final __mm_mask_fmadd_ss = __mm_mask_fmadd_ssPtr
      .asFunction<__m128 Function(__m128, int, __m128, __m128)>();

  __m128 _mm_mask3_fmadd_ss(
    __m128 arg0,
    __m128 arg1,
    __m128 arg2,
    int arg3,
  ) {
    return __mm_mask3_fmadd_ss(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask3_fmadd_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __m128, __m128, __m128, __mmask8)>>('_mm_mask3_fmadd_ss');
  late final __mm_mask3_fmadd_ss = __mm_mask3_fmadd_ssPtr
      .asFunction<__m128 Function(__m128, __m128, __m128, int)>();

  __m128 _mm_maskz_fmadd_ss(
    int arg0,
    __m128 arg1,
    __m128 arg2,
    __m128 arg3,
  ) {
    return __mm_maskz_fmadd_ss(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_fmadd_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __mmask8, __m128, __m128, __m128)>>('_mm_maskz_fmadd_ss');
  late final __mm_maskz_fmadd_ss = __mm_maskz_fmadd_ssPtr
      .asFunction<__m128 Function(int, __m128, __m128, __m128)>();

  _m128d _mm_fmsub_round_sd(
    _m128d arg0,
    _m128d arg1,
    _m128d arg2,
    int arg3,
  ) {
    return __mm_fmsub_round_sd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_fmsub_round_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              _m128d, _m128d, _m128d, ffi.Int32)>>('_mm_fmsub_round_sd');
  late final __mm_fmsub_round_sd = __mm_fmsub_round_sdPtr
      .asFunction<_m128d Function(_m128d, _m128d, _m128d, int)>();

  _m128d _mm_mask_fmsub_round_sd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    _m128d arg3,
    int arg4,
  ) {
    return __mm_mask_fmsub_round_sd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_fmsub_round_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(_m128d, __mmask8, _m128d, _m128d,
              ffi.Int32)>>('_mm_mask_fmsub_round_sd');
  late final __mm_mask_fmsub_round_sd = __mm_mask_fmsub_round_sdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d, _m128d, int)>();

  _m128d _mm_mask3_fmsub_round_sd(
    _m128d arg0,
    _m128d arg1,
    _m128d arg2,
    int arg3,
    int arg4,
  ) {
    return __mm_mask3_fmsub_round_sd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask3_fmsub_round_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(_m128d, _m128d, _m128d, __mmask8,
              ffi.Int32)>>('_mm_mask3_fmsub_round_sd');
  late final __mm_mask3_fmsub_round_sd = __mm_mask3_fmsub_round_sdPtr
      .asFunction<_m128d Function(_m128d, _m128d, _m128d, int, int)>();

  _m128d _mm_maskz_fmsub_round_sd(
    int arg0,
    _m128d arg1,
    _m128d arg2,
    _m128d arg3,
    int arg4,
  ) {
    return __mm_maskz_fmsub_round_sd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_maskz_fmsub_round_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(__mmask8, _m128d, _m128d, _m128d,
              ffi.Int32)>>('_mm_maskz_fmsub_round_sd');
  late final __mm_maskz_fmsub_round_sd = __mm_maskz_fmsub_round_sdPtr
      .asFunction<_m128d Function(int, _m128d, _m128d, _m128d, int)>();

  __m128 _mm_fmsub_round_ss(
    __m128 arg0,
    __m128 arg1,
    __m128 arg2,
    int arg3,
  ) {
    return __mm_fmsub_round_ss(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_fmsub_round_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __m128, __m128, __m128, ffi.Int32)>>('_mm_fmsub_round_ss');
  late final __mm_fmsub_round_ss = __mm_fmsub_round_ssPtr
      .asFunction<__m128 Function(__m128, __m128, __m128, int)>();

  __m128 _mm_mask_fmsub_round_ss(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    __m128 arg3,
    int arg4,
  ) {
    return __mm_mask_fmsub_round_ss(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_fmsub_round_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(__m128, __mmask8, __m128, __m128,
              ffi.Int32)>>('_mm_mask_fmsub_round_ss');
  late final __mm_mask_fmsub_round_ss = __mm_mask_fmsub_round_ssPtr
      .asFunction<__m128 Function(__m128, int, __m128, __m128, int)>();

  __m128 _mm_mask3_fmsub_round_ss(
    __m128 arg0,
    __m128 arg1,
    __m128 arg2,
    int arg3,
    int arg4,
  ) {
    return __mm_mask3_fmsub_round_ss(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask3_fmsub_round_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(__m128, __m128, __m128, __mmask8,
              ffi.Int32)>>('_mm_mask3_fmsub_round_ss');
  late final __mm_mask3_fmsub_round_ss = __mm_mask3_fmsub_round_ssPtr
      .asFunction<__m128 Function(__m128, __m128, __m128, int, int)>();

  __m128 _mm_maskz_fmsub_round_ss(
    int arg0,
    __m128 arg1,
    __m128 arg2,
    __m128 arg3,
    int arg4,
  ) {
    return __mm_maskz_fmsub_round_ss(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_maskz_fmsub_round_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(__mmask8, __m128, __m128, __m128,
              ffi.Int32)>>('_mm_maskz_fmsub_round_ss');
  late final __mm_maskz_fmsub_round_ss = __mm_maskz_fmsub_round_ssPtr
      .asFunction<__m128 Function(int, __m128, __m128, __m128, int)>();

  _m128d _mm_mask_fmsub_sd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    _m128d arg3,
  ) {
    return __mm_mask_fmsub_sd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_fmsub_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              _m128d, __mmask8, _m128d, _m128d)>>('_mm_mask_fmsub_sd');
  late final __mm_mask_fmsub_sd = __mm_mask_fmsub_sdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d, _m128d)>();

  _m128d _mm_mask3_fmsub_sd(
    _m128d arg0,
    _m128d arg1,
    _m128d arg2,
    int arg3,
  ) {
    return __mm_mask3_fmsub_sd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask3_fmsub_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              _m128d, _m128d, _m128d, __mmask8)>>('_mm_mask3_fmsub_sd');
  late final __mm_mask3_fmsub_sd = __mm_mask3_fmsub_sdPtr
      .asFunction<_m128d Function(_m128d, _m128d, _m128d, int)>();

  _m128d _mm_maskz_fmsub_sd(
    int arg0,
    _m128d arg1,
    _m128d arg2,
    _m128d arg3,
  ) {
    return __mm_maskz_fmsub_sd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_fmsub_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              __mmask8, _m128d, _m128d, _m128d)>>('_mm_maskz_fmsub_sd');
  late final __mm_maskz_fmsub_sd = __mm_maskz_fmsub_sdPtr
      .asFunction<_m128d Function(int, _m128d, _m128d, _m128d)>();

  __m128 _mm_mask_fmsub_ss(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    __m128 arg3,
  ) {
    return __mm_mask_fmsub_ss(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_fmsub_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __m128, __mmask8, __m128, __m128)>>('_mm_mask_fmsub_ss');
  late final __mm_mask_fmsub_ss = __mm_mask_fmsub_ssPtr
      .asFunction<__m128 Function(__m128, int, __m128, __m128)>();

  __m128 _mm_mask3_fmsub_ss(
    __m128 arg0,
    __m128 arg1,
    __m128 arg2,
    int arg3,
  ) {
    return __mm_mask3_fmsub_ss(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask3_fmsub_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __m128, __m128, __m128, __mmask8)>>('_mm_mask3_fmsub_ss');
  late final __mm_mask3_fmsub_ss = __mm_mask3_fmsub_ssPtr
      .asFunction<__m128 Function(__m128, __m128, __m128, int)>();

  __m128 _mm_maskz_fmsub_ss(
    int arg0,
    __m128 arg1,
    __m128 arg2,
    __m128 arg3,
  ) {
    return __mm_maskz_fmsub_ss(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_fmsub_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __mmask8, __m128, __m128, __m128)>>('_mm_maskz_fmsub_ss');
  late final __mm_maskz_fmsub_ss = __mm_maskz_fmsub_ssPtr
      .asFunction<__m128 Function(int, __m128, __m128, __m128)>();

  _m128d _mm_fnmadd_round_sd(
    _m128d arg0,
    _m128d arg1,
    _m128d arg2,
    int arg3,
  ) {
    return __mm_fnmadd_round_sd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_fnmadd_round_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              _m128d, _m128d, _m128d, ffi.Int32)>>('_mm_fnmadd_round_sd');
  late final __mm_fnmadd_round_sd = __mm_fnmadd_round_sdPtr
      .asFunction<_m128d Function(_m128d, _m128d, _m128d, int)>();

  _m128d _mm_mask_fnmadd_round_sd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    _m128d arg3,
    int arg4,
  ) {
    return __mm_mask_fnmadd_round_sd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_fnmadd_round_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(_m128d, __mmask8, _m128d, _m128d,
              ffi.Int32)>>('_mm_mask_fnmadd_round_sd');
  late final __mm_mask_fnmadd_round_sd = __mm_mask_fnmadd_round_sdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d, _m128d, int)>();

  _m128d _mm_mask3_fnmadd_round_sd(
    _m128d arg0,
    _m128d arg1,
    _m128d arg2,
    int arg3,
    int arg4,
  ) {
    return __mm_mask3_fnmadd_round_sd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask3_fnmadd_round_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(_m128d, _m128d, _m128d, __mmask8,
              ffi.Int32)>>('_mm_mask3_fnmadd_round_sd');
  late final __mm_mask3_fnmadd_round_sd = __mm_mask3_fnmadd_round_sdPtr
      .asFunction<_m128d Function(_m128d, _m128d, _m128d, int, int)>();

  _m128d _mm_maskz_fnmadd_round_sd(
    int arg0,
    _m128d arg1,
    _m128d arg2,
    _m128d arg3,
    int arg4,
  ) {
    return __mm_maskz_fnmadd_round_sd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_maskz_fnmadd_round_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(__mmask8, _m128d, _m128d, _m128d,
              ffi.Int32)>>('_mm_maskz_fnmadd_round_sd');
  late final __mm_maskz_fnmadd_round_sd = __mm_maskz_fnmadd_round_sdPtr
      .asFunction<_m128d Function(int, _m128d, _m128d, _m128d, int)>();

  __m128 _mm_fnmadd_round_ss(
    __m128 arg0,
    __m128 arg1,
    __m128 arg2,
    int arg3,
  ) {
    return __mm_fnmadd_round_ss(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_fnmadd_round_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __m128, __m128, __m128, ffi.Int32)>>('_mm_fnmadd_round_ss');
  late final __mm_fnmadd_round_ss = __mm_fnmadd_round_ssPtr
      .asFunction<__m128 Function(__m128, __m128, __m128, int)>();

  __m128 _mm_mask_fnmadd_round_ss(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    __m128 arg3,
    int arg4,
  ) {
    return __mm_mask_fnmadd_round_ss(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_fnmadd_round_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(__m128, __mmask8, __m128, __m128,
              ffi.Int32)>>('_mm_mask_fnmadd_round_ss');
  late final __mm_mask_fnmadd_round_ss = __mm_mask_fnmadd_round_ssPtr
      .asFunction<__m128 Function(__m128, int, __m128, __m128, int)>();

  __m128 _mm_mask3_fnmadd_round_ss(
    __m128 arg0,
    __m128 arg1,
    __m128 arg2,
    int arg3,
    int arg4,
  ) {
    return __mm_mask3_fnmadd_round_ss(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask3_fnmadd_round_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(__m128, __m128, __m128, __mmask8,
              ffi.Int32)>>('_mm_mask3_fnmadd_round_ss');
  late final __mm_mask3_fnmadd_round_ss = __mm_mask3_fnmadd_round_ssPtr
      .asFunction<__m128 Function(__m128, __m128, __m128, int, int)>();

  __m128 _mm_maskz_fnmadd_round_ss(
    int arg0,
    __m128 arg1,
    __m128 arg2,
    __m128 arg3,
    int arg4,
  ) {
    return __mm_maskz_fnmadd_round_ss(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_maskz_fnmadd_round_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(__mmask8, __m128, __m128, __m128,
              ffi.Int32)>>('_mm_maskz_fnmadd_round_ss');
  late final __mm_maskz_fnmadd_round_ss = __mm_maskz_fnmadd_round_ssPtr
      .asFunction<__m128 Function(int, __m128, __m128, __m128, int)>();

  _m128d _mm_mask_fnmadd_sd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    _m128d arg3,
  ) {
    return __mm_mask_fnmadd_sd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_fnmadd_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              _m128d, __mmask8, _m128d, _m128d)>>('_mm_mask_fnmadd_sd');
  late final __mm_mask_fnmadd_sd = __mm_mask_fnmadd_sdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d, _m128d)>();

  _m128d _mm_mask3_fnmadd_sd(
    _m128d arg0,
    _m128d arg1,
    _m128d arg2,
    int arg3,
  ) {
    return __mm_mask3_fnmadd_sd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask3_fnmadd_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              _m128d, _m128d, _m128d, __mmask8)>>('_mm_mask3_fnmadd_sd');
  late final __mm_mask3_fnmadd_sd = __mm_mask3_fnmadd_sdPtr
      .asFunction<_m128d Function(_m128d, _m128d, _m128d, int)>();

  _m128d _mm_maskz_fnmadd_sd(
    int arg0,
    _m128d arg1,
    _m128d arg2,
    _m128d arg3,
  ) {
    return __mm_maskz_fnmadd_sd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_fnmadd_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              __mmask8, _m128d, _m128d, _m128d)>>('_mm_maskz_fnmadd_sd');
  late final __mm_maskz_fnmadd_sd = __mm_maskz_fnmadd_sdPtr
      .asFunction<_m128d Function(int, _m128d, _m128d, _m128d)>();

  __m128 _mm_mask_fnmadd_ss(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    __m128 arg3,
  ) {
    return __mm_mask_fnmadd_ss(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_fnmadd_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __m128, __mmask8, __m128, __m128)>>('_mm_mask_fnmadd_ss');
  late final __mm_mask_fnmadd_ss = __mm_mask_fnmadd_ssPtr
      .asFunction<__m128 Function(__m128, int, __m128, __m128)>();

  __m128 _mm_mask3_fnmadd_ss(
    __m128 arg0,
    __m128 arg1,
    __m128 arg2,
    int arg3,
  ) {
    return __mm_mask3_fnmadd_ss(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask3_fnmadd_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __m128, __m128, __m128, __mmask8)>>('_mm_mask3_fnmadd_ss');
  late final __mm_mask3_fnmadd_ss = __mm_mask3_fnmadd_ssPtr
      .asFunction<__m128 Function(__m128, __m128, __m128, int)>();

  __m128 _mm_maskz_fnmadd_ss(
    int arg0,
    __m128 arg1,
    __m128 arg2,
    __m128 arg3,
  ) {
    return __mm_maskz_fnmadd_ss(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_fnmadd_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __mmask8, __m128, __m128, __m128)>>('_mm_maskz_fnmadd_ss');
  late final __mm_maskz_fnmadd_ss = __mm_maskz_fnmadd_ssPtr
      .asFunction<__m128 Function(int, __m128, __m128, __m128)>();

  _m128d _mm_fnmsub_round_sd(
    _m128d arg0,
    _m128d arg1,
    _m128d arg2,
    int arg3,
  ) {
    return __mm_fnmsub_round_sd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_fnmsub_round_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              _m128d, _m128d, _m128d, ffi.Int32)>>('_mm_fnmsub_round_sd');
  late final __mm_fnmsub_round_sd = __mm_fnmsub_round_sdPtr
      .asFunction<_m128d Function(_m128d, _m128d, _m128d, int)>();

  _m128d _mm_mask_fnmsub_round_sd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    _m128d arg3,
    int arg4,
  ) {
    return __mm_mask_fnmsub_round_sd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_fnmsub_round_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(_m128d, __mmask8, _m128d, _m128d,
              ffi.Int32)>>('_mm_mask_fnmsub_round_sd');
  late final __mm_mask_fnmsub_round_sd = __mm_mask_fnmsub_round_sdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d, _m128d, int)>();

  _m128d _mm_mask3_fnmsub_round_sd(
    _m128d arg0,
    _m128d arg1,
    _m128d arg2,
    int arg3,
    int arg4,
  ) {
    return __mm_mask3_fnmsub_round_sd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask3_fnmsub_round_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(_m128d, _m128d, _m128d, __mmask8,
              ffi.Int32)>>('_mm_mask3_fnmsub_round_sd');
  late final __mm_mask3_fnmsub_round_sd = __mm_mask3_fnmsub_round_sdPtr
      .asFunction<_m128d Function(_m128d, _m128d, _m128d, int, int)>();

  _m128d _mm_maskz_fnmsub_round_sd(
    int arg0,
    _m128d arg1,
    _m128d arg2,
    _m128d arg3,
    int arg4,
  ) {
    return __mm_maskz_fnmsub_round_sd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_maskz_fnmsub_round_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(__mmask8, _m128d, _m128d, _m128d,
              ffi.Int32)>>('_mm_maskz_fnmsub_round_sd');
  late final __mm_maskz_fnmsub_round_sd = __mm_maskz_fnmsub_round_sdPtr
      .asFunction<_m128d Function(int, _m128d, _m128d, _m128d, int)>();

  __m128 _mm_fnmsub_round_ss(
    __m128 arg0,
    __m128 arg1,
    __m128 arg2,
    int arg3,
  ) {
    return __mm_fnmsub_round_ss(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_fnmsub_round_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __m128, __m128, __m128, ffi.Int32)>>('_mm_fnmsub_round_ss');
  late final __mm_fnmsub_round_ss = __mm_fnmsub_round_ssPtr
      .asFunction<__m128 Function(__m128, __m128, __m128, int)>();

  __m128 _mm_mask_fnmsub_round_ss(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    __m128 arg3,
    int arg4,
  ) {
    return __mm_mask_fnmsub_round_ss(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_fnmsub_round_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(__m128, __mmask8, __m128, __m128,
              ffi.Int32)>>('_mm_mask_fnmsub_round_ss');
  late final __mm_mask_fnmsub_round_ss = __mm_mask_fnmsub_round_ssPtr
      .asFunction<__m128 Function(__m128, int, __m128, __m128, int)>();

  __m128 _mm_mask3_fnmsub_round_ss(
    __m128 arg0,
    __m128 arg1,
    __m128 arg2,
    int arg3,
    int arg4,
  ) {
    return __mm_mask3_fnmsub_round_ss(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask3_fnmsub_round_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(__m128, __m128, __m128, __mmask8,
              ffi.Int32)>>('_mm_mask3_fnmsub_round_ss');
  late final __mm_mask3_fnmsub_round_ss = __mm_mask3_fnmsub_round_ssPtr
      .asFunction<__m128 Function(__m128, __m128, __m128, int, int)>();

  __m128 _mm_maskz_fnmsub_round_ss(
    int arg0,
    __m128 arg1,
    __m128 arg2,
    __m128 arg3,
    int arg4,
  ) {
    return __mm_maskz_fnmsub_round_ss(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_maskz_fnmsub_round_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(__mmask8, __m128, __m128, __m128,
              ffi.Int32)>>('_mm_maskz_fnmsub_round_ss');
  late final __mm_maskz_fnmsub_round_ss = __mm_maskz_fnmsub_round_ssPtr
      .asFunction<__m128 Function(int, __m128, __m128, __m128, int)>();

  _m128d _mm_mask_fnmsub_sd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    _m128d arg3,
  ) {
    return __mm_mask_fnmsub_sd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_fnmsub_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              _m128d, __mmask8, _m128d, _m128d)>>('_mm_mask_fnmsub_sd');
  late final __mm_mask_fnmsub_sd = __mm_mask_fnmsub_sdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d, _m128d)>();

  _m128d _mm_mask3_fnmsub_sd(
    _m128d arg0,
    _m128d arg1,
    _m128d arg2,
    int arg3,
  ) {
    return __mm_mask3_fnmsub_sd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask3_fnmsub_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              _m128d, _m128d, _m128d, __mmask8)>>('_mm_mask3_fnmsub_sd');
  late final __mm_mask3_fnmsub_sd = __mm_mask3_fnmsub_sdPtr
      .asFunction<_m128d Function(_m128d, _m128d, _m128d, int)>();

  _m128d _mm_maskz_fnmsub_sd(
    int arg0,
    _m128d arg1,
    _m128d arg2,
    _m128d arg3,
  ) {
    return __mm_maskz_fnmsub_sd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_fnmsub_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              __mmask8, _m128d, _m128d, _m128d)>>('_mm_maskz_fnmsub_sd');
  late final __mm_maskz_fnmsub_sd = __mm_maskz_fnmsub_sdPtr
      .asFunction<_m128d Function(int, _m128d, _m128d, _m128d)>();

  __m128 _mm_mask_fnmsub_ss(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    __m128 arg3,
  ) {
    return __mm_mask_fnmsub_ss(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_fnmsub_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __m128, __mmask8, __m128, __m128)>>('_mm_mask_fnmsub_ss');
  late final __mm_mask_fnmsub_ss = __mm_mask_fnmsub_ssPtr
      .asFunction<__m128 Function(__m128, int, __m128, __m128)>();

  __m128 _mm_mask3_fnmsub_ss(
    __m128 arg0,
    __m128 arg1,
    __m128 arg2,
    int arg3,
  ) {
    return __mm_mask3_fnmsub_ss(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask3_fnmsub_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __m128, __m128, __m128, __mmask8)>>('_mm_mask3_fnmsub_ss');
  late final __mm_mask3_fnmsub_ss = __mm_mask3_fnmsub_ssPtr
      .asFunction<__m128 Function(__m128, __m128, __m128, int)>();

  __m128 _mm_maskz_fnmsub_ss(
    int arg0,
    __m128 arg1,
    __m128 arg2,
    __m128 arg3,
  ) {
    return __mm_maskz_fnmsub_ss(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_fnmsub_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __mmask8, __m128, __m128, __m128)>>('_mm_maskz_fnmsub_ss');
  late final __mm_maskz_fnmsub_ss = __mm_maskz_fnmsub_ssPtr
      .asFunction<__m128 Function(int, __m128, __m128, __m128)>();

  int _mm_fpclass_sd_mask(
    _m128d arg0,
    int arg1,
  ) {
    return __mm_fpclass_sd_mask(
      arg0,
      arg1,
    );
  }

  late final __mm_fpclass_sd_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(_m128d, ffi.Int32)>>(
          '_mm_fpclass_sd_mask');
  late final __mm_fpclass_sd_mask =
      __mm_fpclass_sd_maskPtr.asFunction<int Function(_m128d, int)>();

  int _mm_mask_fpclass_sd_mask(
    int arg0,
    _m128d arg1,
    int arg2,
  ) {
    return __mm_mask_fpclass_sd_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_fpclass_sd_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, _m128d, ffi.Int32)>>(
      '_mm_mask_fpclass_sd_mask');
  late final __mm_mask_fpclass_sd_mask =
      __mm_mask_fpclass_sd_maskPtr.asFunction<int Function(int, _m128d, int)>();

  int _mm_fpclass_ss_mask(
    __m128 arg0,
    int arg1,
  ) {
    return __mm_fpclass_ss_mask(
      arg0,
      arg1,
    );
  }

  late final __mm_fpclass_ss_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m128, ffi.Int32)>>(
          '_mm_fpclass_ss_mask');
  late final __mm_fpclass_ss_mask =
      __mm_fpclass_ss_maskPtr.asFunction<int Function(__m128, int)>();

  int _mm_mask_fpclass_ss_mask(
    int arg0,
    __m128 arg1,
    int arg2,
  ) {
    return __mm_mask_fpclass_ss_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_fpclass_ss_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m128, ffi.Int32)>>(
      '_mm_mask_fpclass_ss_mask');
  late final __mm_mask_fpclass_ss_mask =
      __mm_mask_fpclass_ss_maskPtr.asFunction<int Function(int, __m128, int)>();

  _m128d _mm_getexp_round_sd(
    _m128d arg0,
    _m128d arg1,
    int arg2,
  ) {
    return __mm_getexp_round_sd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_getexp_round_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d, ffi.Int32)>>(
          '_mm_getexp_round_sd');
  late final __mm_getexp_round_sd = __mm_getexp_round_sdPtr
      .asFunction<_m128d Function(_m128d, _m128d, int)>();

  _m128d _mm_mask_getexp_round_sd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    _m128d arg3,
    int arg4,
  ) {
    return __mm_mask_getexp_round_sd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_getexp_round_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(_m128d, __mmask8, _m128d, _m128d,
              ffi.Int32)>>('_mm_mask_getexp_round_sd');
  late final __mm_mask_getexp_round_sd = __mm_mask_getexp_round_sdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d, _m128d, int)>();

  _m128d _mm_maskz_getexp_round_sd(
    int arg0,
    _m128d arg1,
    _m128d arg2,
    int arg3,
  ) {
    return __mm_maskz_getexp_round_sd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_getexp_round_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(__mmask8, _m128d, _m128d,
              ffi.Int32)>>('_mm_maskz_getexp_round_sd');
  late final __mm_maskz_getexp_round_sd = __mm_maskz_getexp_round_sdPtr
      .asFunction<_m128d Function(int, _m128d, _m128d, int)>();

  __m128 _mm_getexp_round_ss(
    __m128 arg0,
    __m128 arg1,
    int arg2,
  ) {
    return __mm_getexp_round_ss(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_getexp_round_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128, ffi.Int32)>>(
          '_mm_getexp_round_ss');
  late final __mm_getexp_round_ss = __mm_getexp_round_ssPtr
      .asFunction<__m128 Function(__m128, __m128, int)>();

  __m128 _mm_mask_getexp_round_ss(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    __m128 arg3,
    int arg4,
  ) {
    return __mm_mask_getexp_round_ss(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_getexp_round_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(__m128, __mmask8, __m128, __m128,
              ffi.Int32)>>('_mm_mask_getexp_round_ss');
  late final __mm_mask_getexp_round_ss = __mm_mask_getexp_round_ssPtr
      .asFunction<__m128 Function(__m128, int, __m128, __m128, int)>();

  __m128 _mm_maskz_getexp_round_ss(
    int arg0,
    __m128 arg1,
    __m128 arg2,
    int arg3,
  ) {
    return __mm_maskz_getexp_round_ss(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_getexp_round_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(__mmask8, __m128, __m128,
              ffi.Int32)>>('_mm_maskz_getexp_round_ss');
  late final __mm_maskz_getexp_round_ss = __mm_maskz_getexp_round_ssPtr
      .asFunction<__m128 Function(int, __m128, __m128, int)>();

  _m128d _mm_getexp_sd(
    _m128d arg0,
    _m128d arg1,
  ) {
    return __mm_getexp_sd(
      arg0,
      arg1,
    );
  }

  late final __mm_getexp_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d)>>(
          '_mm_getexp_sd');
  late final __mm_getexp_sd =
      __mm_getexp_sdPtr.asFunction<_m128d Function(_m128d, _m128d)>();

  _m128d _mm_mask_getexp_sd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    _m128d arg3,
  ) {
    return __mm_mask_getexp_sd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_getexp_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              _m128d, __mmask8, _m128d, _m128d)>>('_mm_mask_getexp_sd');
  late final __mm_mask_getexp_sd = __mm_mask_getexp_sdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d, _m128d)>();

  _m128d _mm_maskz_getexp_sd(
    int arg0,
    _m128d arg1,
    _m128d arg2,
  ) {
    return __mm_maskz_getexp_sd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_getexp_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(__mmask8, _m128d, _m128d)>>(
          '_mm_maskz_getexp_sd');
  late final __mm_maskz_getexp_sd = __mm_maskz_getexp_sdPtr
      .asFunction<_m128d Function(int, _m128d, _m128d)>();

  __m128 _mm_getexp_ss(
    __m128 arg0,
    __m128 arg1,
  ) {
    return __mm_getexp_ss(
      arg0,
      arg1,
    );
  }

  late final __mm_getexp_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128)>>(
          '_mm_getexp_ss');
  late final __mm_getexp_ss =
      __mm_getexp_ssPtr.asFunction<__m128 Function(__m128, __m128)>();

  __m128 _mm_mask_getexp_ss(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    __m128 arg3,
  ) {
    return __mm_mask_getexp_ss(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_getexp_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __m128, __mmask8, __m128, __m128)>>('_mm_mask_getexp_ss');
  late final __mm_mask_getexp_ss = __mm_mask_getexp_ssPtr
      .asFunction<__m128 Function(__m128, int, __m128, __m128)>();

  __m128 _mm_maskz_getexp_ss(
    int arg0,
    __m128 arg1,
    __m128 arg2,
  ) {
    return __mm_maskz_getexp_ss(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_getexp_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__mmask8, __m128, __m128)>>(
          '_mm_maskz_getexp_ss');
  late final __mm_maskz_getexp_ss = __mm_maskz_getexp_ssPtr
      .asFunction<__m128 Function(int, __m128, __m128)>();

  _m128d _mm_getmant_round_sd(
    _m128d arg0,
    _m128d arg1,
    int arg2,
    int arg3,
    int arg4,
  ) {
    return __mm_getmant_round_sd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_getmant_round_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(_m128d, _m128d, ffi.Int32, ffi.Int32,
              ffi.Int32)>>('_mm_getmant_round_sd');
  late final __mm_getmant_round_sd = __mm_getmant_round_sdPtr
      .asFunction<_m128d Function(_m128d, _m128d, int, int, int)>();

  _m128d _mm_mask_getmant_round_sd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    _m128d arg3,
    int arg4,
    int arg5,
    int arg6,
  ) {
    return __mm_mask_getmant_round_sd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
      arg5,
      arg6,
    );
  }

  late final __mm_mask_getmant_round_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(_m128d, __mmask8, _m128d, _m128d, ffi.Int32,
              ffi.Int32, ffi.Int32)>>('_mm_mask_getmant_round_sd');
  late final __mm_mask_getmant_round_sd =
      __mm_mask_getmant_round_sdPtr.asFunction<
          _m128d Function(_m128d, int, _m128d, _m128d, int, int, int)>();

  _m128d _mm_maskz_getmant_round_sd(
    int arg0,
    _m128d arg1,
    _m128d arg2,
    int arg3,
    int arg4,
    int arg5,
  ) {
    return __mm_maskz_getmant_round_sd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
      arg5,
    );
  }

  late final __mm_maskz_getmant_round_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(__mmask8, _m128d, _m128d, ffi.Int32, ffi.Int32,
              ffi.Int32)>>('_mm_maskz_getmant_round_sd');
  late final __mm_maskz_getmant_round_sd = __mm_maskz_getmant_round_sdPtr
      .asFunction<_m128d Function(int, _m128d, _m128d, int, int, int)>();

  __m128 _mm_getmant_round_ss(
    __m128 arg0,
    __m128 arg1,
    int arg2,
    int arg3,
    int arg4,
  ) {
    return __mm_getmant_round_ss(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_getmant_round_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(__m128, __m128, ffi.Int32, ffi.Int32,
              ffi.Int32)>>('_mm_getmant_round_ss');
  late final __mm_getmant_round_ss = __mm_getmant_round_ssPtr
      .asFunction<__m128 Function(__m128, __m128, int, int, int)>();

  __m128 _mm_mask_getmant_round_ss(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    __m128 arg3,
    int arg4,
    int arg5,
    int arg6,
  ) {
    return __mm_mask_getmant_round_ss(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
      arg5,
      arg6,
    );
  }

  late final __mm_mask_getmant_round_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(__m128, __mmask8, __m128, __m128, ffi.Int32,
              ffi.Int32, ffi.Int32)>>('_mm_mask_getmant_round_ss');
  late final __mm_mask_getmant_round_ss =
      __mm_mask_getmant_round_ssPtr.asFunction<
          __m128 Function(__m128, int, __m128, __m128, int, int, int)>();

  __m128 _mm_maskz_getmant_round_ss(
    int arg0,
    __m128 arg1,
    __m128 arg2,
    int arg3,
    int arg4,
    int arg5,
  ) {
    return __mm_maskz_getmant_round_ss(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
      arg5,
    );
  }

  late final __mm_maskz_getmant_round_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(__mmask8, __m128, __m128, ffi.Int32, ffi.Int32,
              ffi.Int32)>>('_mm_maskz_getmant_round_ss');
  late final __mm_maskz_getmant_round_ss = __mm_maskz_getmant_round_ssPtr
      .asFunction<__m128 Function(int, __m128, __m128, int, int, int)>();

  _m128d _mm_getmant_sd(
    _m128d arg0,
    _m128d arg1,
    int arg2,
    int arg3,
  ) {
    return __mm_getmant_sd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_getmant_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              _m128d, _m128d, ffi.Int32, ffi.Int32)>>('_mm_getmant_sd');
  late final __mm_getmant_sd = __mm_getmant_sdPtr
      .asFunction<_m128d Function(_m128d, _m128d, int, int)>();

  _m128d _mm_mask_getmant_sd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    _m128d arg3,
    int arg4,
    int arg5,
  ) {
    return __mm_mask_getmant_sd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
      arg5,
    );
  }

  late final __mm_mask_getmant_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(_m128d, __mmask8, _m128d, _m128d, ffi.Int32,
              ffi.Int32)>>('_mm_mask_getmant_sd');
  late final __mm_mask_getmant_sd = __mm_mask_getmant_sdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d, _m128d, int, int)>();

  _m128d _mm_maskz_getmant_sd(
    int arg0,
    _m128d arg1,
    _m128d arg2,
    int arg3,
    int arg4,
  ) {
    return __mm_maskz_getmant_sd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_maskz_getmant_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(__mmask8, _m128d, _m128d, ffi.Int32,
              ffi.Int32)>>('_mm_maskz_getmant_sd');
  late final __mm_maskz_getmant_sd = __mm_maskz_getmant_sdPtr
      .asFunction<_m128d Function(int, _m128d, _m128d, int, int)>();

  __m128 _mm_getmant_ss(
    __m128 arg0,
    __m128 arg1,
    int arg2,
    int arg3,
  ) {
    return __mm_getmant_ss(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_getmant_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __m128, __m128, ffi.Int32, ffi.Int32)>>('_mm_getmant_ss');
  late final __mm_getmant_ss = __mm_getmant_ssPtr
      .asFunction<__m128 Function(__m128, __m128, int, int)>();

  __m128 _mm_mask_getmant_ss(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    __m128 arg3,
    int arg4,
    int arg5,
  ) {
    return __mm_mask_getmant_ss(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
      arg5,
    );
  }

  late final __mm_mask_getmant_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(__m128, __mmask8, __m128, __m128, ffi.Int32,
              ffi.Int32)>>('_mm_mask_getmant_ss');
  late final __mm_mask_getmant_ss = __mm_mask_getmant_ssPtr
      .asFunction<__m128 Function(__m128, int, __m128, __m128, int, int)>();

  __m128 _mm_maskz_getmant_ss(
    int arg0,
    __m128 arg1,
    __m128 arg2,
    int arg3,
    int arg4,
  ) {
    return __mm_maskz_getmant_ss(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_maskz_getmant_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(__mmask8, __m128, __m128, ffi.Int32,
              ffi.Int32)>>('_mm_maskz_getmant_ss');
  late final __mm_maskz_getmant_ss = __mm_maskz_getmant_ssPtr
      .asFunction<__m128 Function(int, __m128, __m128, int, int)>();

  _m128d _mm_mask_load_sd(
    _m128d arg0,
    int arg1,
    ffi.Pointer<ffi.Double> arg2,
  ) {
    return __mm_mask_load_sd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_load_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              _m128d, __mmask8, ffi.Pointer<ffi.Double>)>>('_mm_mask_load_sd');
  late final __mm_mask_load_sd = __mm_mask_load_sdPtr
      .asFunction<_m128d Function(_m128d, int, ffi.Pointer<ffi.Double>)>();

  _m128d _mm_maskz_load_sd(
    int arg0,
    ffi.Pointer<ffi.Double> arg1,
  ) {
    return __mm_maskz_load_sd(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_load_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              __mmask8, ffi.Pointer<ffi.Double>)>>('_mm_maskz_load_sd');
  late final __mm_maskz_load_sd = __mm_maskz_load_sdPtr
      .asFunction<_m128d Function(int, ffi.Pointer<ffi.Double>)>();

  __m128 _mm_mask_load_ss(
    __m128 arg0,
    int arg1,
    ffi.Pointer<ffi.Float> arg2,
  ) {
    return __mm_mask_load_ss(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_load_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __m128, __mmask8, ffi.Pointer<ffi.Float>)>>('_mm_mask_load_ss');
  late final __mm_mask_load_ss = __mm_mask_load_ssPtr
      .asFunction<__m128 Function(__m128, int, ffi.Pointer<ffi.Float>)>();

  __m128 _mm_maskz_load_ss(
    int arg0,
    ffi.Pointer<ffi.Float> arg1,
  ) {
    return __mm_maskz_load_ss(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_load_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __mmask8, ffi.Pointer<ffi.Float>)>>('_mm_maskz_load_ss');
  late final __mm_maskz_load_ss = __mm_maskz_load_ssPtr
      .asFunction<__m128 Function(int, ffi.Pointer<ffi.Float>)>();

  _m128d _mm_mask_max_round_sd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    _m128d arg3,
    int arg4,
  ) {
    return __mm_mask_max_round_sd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_max_round_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(_m128d, __mmask8, _m128d, _m128d,
              ffi.Int32)>>('_mm_mask_max_round_sd');
  late final __mm_mask_max_round_sd = __mm_mask_max_round_sdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d, _m128d, int)>();

  _m128d _mm_maskz_max_round_sd(
    int arg0,
    _m128d arg1,
    _m128d arg2,
    int arg3,
  ) {
    return __mm_maskz_max_round_sd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_max_round_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              __mmask8, _m128d, _m128d, ffi.Int32)>>('_mm_maskz_max_round_sd');
  late final __mm_maskz_max_round_sd = __mm_maskz_max_round_sdPtr
      .asFunction<_m128d Function(int, _m128d, _m128d, int)>();

  _m128d _mm_max_round_sd(
    _m128d arg0,
    _m128d arg1,
    int arg2,
  ) {
    return __mm_max_round_sd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_max_round_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d, ffi.Int32)>>(
          '_mm_max_round_sd');
  late final __mm_max_round_sd =
      __mm_max_round_sdPtr.asFunction<_m128d Function(_m128d, _m128d, int)>();

  __m128 _mm_mask_max_round_ss(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    __m128 arg3,
    int arg4,
  ) {
    return __mm_mask_max_round_ss(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_max_round_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(__m128, __mmask8, __m128, __m128,
              ffi.Int32)>>('_mm_mask_max_round_ss');
  late final __mm_mask_max_round_ss = __mm_mask_max_round_ssPtr
      .asFunction<__m128 Function(__m128, int, __m128, __m128, int)>();

  __m128 _mm_maskz_max_round_ss(
    int arg0,
    __m128 arg1,
    __m128 arg2,
    int arg3,
  ) {
    return __mm_maskz_max_round_ss(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_max_round_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __mmask8, __m128, __m128, ffi.Int32)>>('_mm_maskz_max_round_ss');
  late final __mm_maskz_max_round_ss = __mm_maskz_max_round_ssPtr
      .asFunction<__m128 Function(int, __m128, __m128, int)>();

  __m128 _mm_max_round_ss(
    __m128 arg0,
    __m128 arg1,
    int arg2,
  ) {
    return __mm_max_round_ss(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_max_round_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128, ffi.Int32)>>(
          '_mm_max_round_ss');
  late final __mm_max_round_ss =
      __mm_max_round_ssPtr.asFunction<__m128 Function(__m128, __m128, int)>();

  _m128d _mm_mask_max_sd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    _m128d arg3,
  ) {
    return __mm_mask_max_sd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_max_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              _m128d, __mmask8, _m128d, _m128d)>>('_mm_mask_max_sd');
  late final __mm_mask_max_sd = __mm_mask_max_sdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d, _m128d)>();

  _m128d _mm_maskz_max_sd(
    int arg0,
    _m128d arg1,
    _m128d arg2,
  ) {
    return __mm_maskz_max_sd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_max_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(__mmask8, _m128d, _m128d)>>(
          '_mm_maskz_max_sd');
  late final __mm_maskz_max_sd =
      __mm_maskz_max_sdPtr.asFunction<_m128d Function(int, _m128d, _m128d)>();

  __m128 _mm_mask_max_ss(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    __m128 arg3,
  ) {
    return __mm_mask_max_ss(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_max_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __m128, __mmask8, __m128, __m128)>>('_mm_mask_max_ss');
  late final __mm_mask_max_ss = __mm_mask_max_ssPtr
      .asFunction<__m128 Function(__m128, int, __m128, __m128)>();

  __m128 _mm_maskz_max_ss(
    int arg0,
    __m128 arg1,
    __m128 arg2,
  ) {
    return __mm_maskz_max_ss(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_max_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__mmask8, __m128, __m128)>>(
          '_mm_maskz_max_ss');
  late final __mm_maskz_max_ss =
      __mm_maskz_max_ssPtr.asFunction<__m128 Function(int, __m128, __m128)>();

  _m128d _mm_mask_min_round_sd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    _m128d arg3,
    int arg4,
  ) {
    return __mm_mask_min_round_sd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_min_round_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(_m128d, __mmask8, _m128d, _m128d,
              ffi.Int32)>>('_mm_mask_min_round_sd');
  late final __mm_mask_min_round_sd = __mm_mask_min_round_sdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d, _m128d, int)>();

  _m128d _mm_maskz_min_round_sd(
    int arg0,
    _m128d arg1,
    _m128d arg2,
    int arg3,
  ) {
    return __mm_maskz_min_round_sd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_min_round_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              __mmask8, _m128d, _m128d, ffi.Int32)>>('_mm_maskz_min_round_sd');
  late final __mm_maskz_min_round_sd = __mm_maskz_min_round_sdPtr
      .asFunction<_m128d Function(int, _m128d, _m128d, int)>();

  _m128d _mm_min_round_sd(
    _m128d arg0,
    _m128d arg1,
    int arg2,
  ) {
    return __mm_min_round_sd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_min_round_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d, ffi.Int32)>>(
          '_mm_min_round_sd');
  late final __mm_min_round_sd =
      __mm_min_round_sdPtr.asFunction<_m128d Function(_m128d, _m128d, int)>();

  __m128 _mm_mask_min_round_ss(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    __m128 arg3,
    int arg4,
  ) {
    return __mm_mask_min_round_ss(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_min_round_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(__m128, __mmask8, __m128, __m128,
              ffi.Int32)>>('_mm_mask_min_round_ss');
  late final __mm_mask_min_round_ss = __mm_mask_min_round_ssPtr
      .asFunction<__m128 Function(__m128, int, __m128, __m128, int)>();

  __m128 _mm_maskz_min_round_ss(
    int arg0,
    __m128 arg1,
    __m128 arg2,
    int arg3,
  ) {
    return __mm_maskz_min_round_ss(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_min_round_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __mmask8, __m128, __m128, ffi.Int32)>>('_mm_maskz_min_round_ss');
  late final __mm_maskz_min_round_ss = __mm_maskz_min_round_ssPtr
      .asFunction<__m128 Function(int, __m128, __m128, int)>();

  __m128 _mm_min_round_ss(
    __m128 arg0,
    __m128 arg1,
    int arg2,
  ) {
    return __mm_min_round_ss(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_min_round_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128, ffi.Int32)>>(
          '_mm_min_round_ss');
  late final __mm_min_round_ss =
      __mm_min_round_ssPtr.asFunction<__m128 Function(__m128, __m128, int)>();

  _m128d _mm_mask_min_sd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    _m128d arg3,
  ) {
    return __mm_mask_min_sd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_min_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              _m128d, __mmask8, _m128d, _m128d)>>('_mm_mask_min_sd');
  late final __mm_mask_min_sd = __mm_mask_min_sdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d, _m128d)>();

  _m128d _mm_maskz_min_sd(
    int arg0,
    _m128d arg1,
    _m128d arg2,
  ) {
    return __mm_maskz_min_sd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_min_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(__mmask8, _m128d, _m128d)>>(
          '_mm_maskz_min_sd');
  late final __mm_maskz_min_sd =
      __mm_maskz_min_sdPtr.asFunction<_m128d Function(int, _m128d, _m128d)>();

  __m128 _mm_mask_min_ss(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    __m128 arg3,
  ) {
    return __mm_mask_min_ss(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_min_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __m128, __mmask8, __m128, __m128)>>('_mm_mask_min_ss');
  late final __mm_mask_min_ss = __mm_mask_min_ssPtr
      .asFunction<__m128 Function(__m128, int, __m128, __m128)>();

  __m128 _mm_maskz_min_ss(
    int arg0,
    __m128 arg1,
    __m128 arg2,
  ) {
    return __mm_maskz_min_ss(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_min_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__mmask8, __m128, __m128)>>(
          '_mm_maskz_min_ss');
  late final __mm_maskz_min_ss =
      __mm_maskz_min_ssPtr.asFunction<__m128 Function(int, __m128, __m128)>();

  _m128d _mm_mask_move_sd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    _m128d arg3,
  ) {
    return __mm_mask_move_sd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_move_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              _m128d, __mmask8, _m128d, _m128d)>>('_mm_mask_move_sd');
  late final __mm_mask_move_sd = __mm_mask_move_sdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d, _m128d)>();

  _m128d _mm_maskz_move_sd(
    int arg0,
    _m128d arg1,
    _m128d arg2,
  ) {
    return __mm_maskz_move_sd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_move_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(__mmask8, _m128d, _m128d)>>(
          '_mm_maskz_move_sd');
  late final __mm_maskz_move_sd =
      __mm_maskz_move_sdPtr.asFunction<_m128d Function(int, _m128d, _m128d)>();

  __m128 _mm_mask_move_ss(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    __m128 arg3,
  ) {
    return __mm_mask_move_ss(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_move_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __m128, __mmask8, __m128, __m128)>>('_mm_mask_move_ss');
  late final __mm_mask_move_ss = __mm_mask_move_ssPtr
      .asFunction<__m128 Function(__m128, int, __m128, __m128)>();

  __m128 _mm_maskz_move_ss(
    int arg0,
    __m128 arg1,
    __m128 arg2,
  ) {
    return __mm_maskz_move_ss(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_move_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__mmask8, __m128, __m128)>>(
          '_mm_maskz_move_ss');
  late final __mm_maskz_move_ss =
      __mm_maskz_move_ssPtr.asFunction<__m128 Function(int, __m128, __m128)>();

  _m128d _mm_mask_mul_round_sd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    _m128d arg3,
    int arg4,
  ) {
    return __mm_mask_mul_round_sd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_mul_round_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(_m128d, __mmask8, _m128d, _m128d,
              ffi.Int32)>>('_mm_mask_mul_round_sd');
  late final __mm_mask_mul_round_sd = __mm_mask_mul_round_sdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d, _m128d, int)>();

  _m128d _mm_maskz_mul_round_sd(
    int arg0,
    _m128d arg1,
    _m128d arg2,
    int arg3,
  ) {
    return __mm_maskz_mul_round_sd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_mul_round_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              __mmask8, _m128d, _m128d, ffi.Int32)>>('_mm_maskz_mul_round_sd');
  late final __mm_maskz_mul_round_sd = __mm_maskz_mul_round_sdPtr
      .asFunction<_m128d Function(int, _m128d, _m128d, int)>();

  _m128d _mm_mul_round_sd(
    _m128d arg0,
    _m128d arg1,
    int arg2,
  ) {
    return __mm_mul_round_sd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mul_round_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d, ffi.Int32)>>(
          '_mm_mul_round_sd');
  late final __mm_mul_round_sd =
      __mm_mul_round_sdPtr.asFunction<_m128d Function(_m128d, _m128d, int)>();

  __m128 _mm_mask_mul_round_ss(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    __m128 arg3,
    int arg4,
  ) {
    return __mm_mask_mul_round_ss(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_mul_round_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(__m128, __mmask8, __m128, __m128,
              ffi.Int32)>>('_mm_mask_mul_round_ss');
  late final __mm_mask_mul_round_ss = __mm_mask_mul_round_ssPtr
      .asFunction<__m128 Function(__m128, int, __m128, __m128, int)>();

  __m128 _mm_maskz_mul_round_ss(
    int arg0,
    __m128 arg1,
    __m128 arg2,
    int arg3,
  ) {
    return __mm_maskz_mul_round_ss(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_mul_round_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __mmask8, __m128, __m128, ffi.Int32)>>('_mm_maskz_mul_round_ss');
  late final __mm_maskz_mul_round_ss = __mm_maskz_mul_round_ssPtr
      .asFunction<__m128 Function(int, __m128, __m128, int)>();

  __m128 _mm_mul_round_ss(
    __m128 arg0,
    __m128 arg1,
    int arg2,
  ) {
    return __mm_mul_round_ss(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mul_round_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128, ffi.Int32)>>(
          '_mm_mul_round_ss');
  late final __mm_mul_round_ss =
      __mm_mul_round_ssPtr.asFunction<__m128 Function(__m128, __m128, int)>();

  _m128d _mm_mask_mul_sd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    _m128d arg3,
  ) {
    return __mm_mask_mul_sd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_mul_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              _m128d, __mmask8, _m128d, _m128d)>>('_mm_mask_mul_sd');
  late final __mm_mask_mul_sd = __mm_mask_mul_sdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d, _m128d)>();

  _m128d _mm_maskz_mul_sd(
    int arg0,
    _m128d arg1,
    _m128d arg2,
  ) {
    return __mm_maskz_mul_sd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_mul_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(__mmask8, _m128d, _m128d)>>(
          '_mm_maskz_mul_sd');
  late final __mm_maskz_mul_sd =
      __mm_maskz_mul_sdPtr.asFunction<_m128d Function(int, _m128d, _m128d)>();

  __m128 _mm_mask_mul_ss(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    __m128 arg3,
  ) {
    return __mm_mask_mul_ss(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_mul_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __m128, __mmask8, __m128, __m128)>>('_mm_mask_mul_ss');
  late final __mm_mask_mul_ss = __mm_mask_mul_ssPtr
      .asFunction<__m128 Function(__m128, int, __m128, __m128)>();

  __m128 _mm_maskz_mul_ss(
    int arg0,
    __m128 arg1,
    __m128 arg2,
  ) {
    return __mm_maskz_mul_ss(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_mul_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__mmask8, __m128, __m128)>>(
          '_mm_maskz_mul_ss');
  late final __mm_maskz_mul_ss =
      __mm_maskz_mul_ssPtr.asFunction<__m128 Function(int, __m128, __m128)>();

  _m128d _mm_range_sd(
    _m128d arg0,
    _m128d arg1,
    int arg2,
  ) {
    return __mm_range_sd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_range_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d, ffi.Int32)>>(
          '_mm_range_sd');
  late final __mm_range_sd =
      __mm_range_sdPtr.asFunction<_m128d Function(_m128d, _m128d, int)>();

  _m128d _mm_mask_range_sd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    _m128d arg3,
    int arg4,
  ) {
    return __mm_mask_range_sd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_range_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(_m128d, __mmask8, _m128d, _m128d,
              ffi.Int32)>>('_mm_mask_range_sd');
  late final __mm_mask_range_sd = __mm_mask_range_sdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d, _m128d, int)>();

  _m128d _mm_maskz_range_sd(
    int arg0,
    _m128d arg1,
    _m128d arg2,
    int arg3,
  ) {
    return __mm_maskz_range_sd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_range_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              __mmask8, _m128d, _m128d, ffi.Int32)>>('_mm_maskz_range_sd');
  late final __mm_maskz_range_sd = __mm_maskz_range_sdPtr
      .asFunction<_m128d Function(int, _m128d, _m128d, int)>();

  _m128d _mm_range_round_sd(
    _m128d arg0,
    _m128d arg1,
    int arg2,
    int arg3,
  ) {
    return __mm_range_round_sd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_range_round_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              _m128d, _m128d, ffi.Int32, ffi.Int32)>>('_mm_range_round_sd');
  late final __mm_range_round_sd = __mm_range_round_sdPtr
      .asFunction<_m128d Function(_m128d, _m128d, int, int)>();

  _m128d _mm_mask_range_round_sd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    _m128d arg3,
    int arg4,
    int arg5,
  ) {
    return __mm_mask_range_round_sd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
      arg5,
    );
  }

  late final __mm_mask_range_round_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(_m128d, __mmask8, _m128d, _m128d, ffi.Int32,
              ffi.Int32)>>('_mm_mask_range_round_sd');
  late final __mm_mask_range_round_sd = __mm_mask_range_round_sdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d, _m128d, int, int)>();

  _m128d _mm_maskz_range_round_sd(
    int arg0,
    _m128d arg1,
    _m128d arg2,
    int arg3,
    int arg4,
  ) {
    return __mm_maskz_range_round_sd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_maskz_range_round_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(__mmask8, _m128d, _m128d, ffi.Int32,
              ffi.Int32)>>('_mm_maskz_range_round_sd');
  late final __mm_maskz_range_round_sd = __mm_maskz_range_round_sdPtr
      .asFunction<_m128d Function(int, _m128d, _m128d, int, int)>();

  __m128 _mm_range_ss(
    __m128 arg0,
    __m128 arg1,
    int arg2,
  ) {
    return __mm_range_ss(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_range_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128, ffi.Int32)>>(
          '_mm_range_ss');
  late final __mm_range_ss =
      __mm_range_ssPtr.asFunction<__m128 Function(__m128, __m128, int)>();

  __m128 _mm_mask_range_ss(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    __m128 arg3,
    int arg4,
  ) {
    return __mm_mask_range_ss(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_range_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(__m128, __mmask8, __m128, __m128,
              ffi.Int32)>>('_mm_mask_range_ss');
  late final __mm_mask_range_ss = __mm_mask_range_ssPtr
      .asFunction<__m128 Function(__m128, int, __m128, __m128, int)>();

  __m128 _mm_maskz_range_ss(
    int arg0,
    __m128 arg1,
    __m128 arg2,
    int arg3,
  ) {
    return __mm_maskz_range_ss(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_range_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __mmask8, __m128, __m128, ffi.Int32)>>('_mm_maskz_range_ss');
  late final __mm_maskz_range_ss = __mm_maskz_range_ssPtr
      .asFunction<__m128 Function(int, __m128, __m128, int)>();

  __m128 _mm_range_round_ss(
    __m128 arg0,
    __m128 arg1,
    int arg2,
    int arg3,
  ) {
    return __mm_range_round_ss(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_range_round_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __m128, __m128, ffi.Int32, ffi.Int32)>>('_mm_range_round_ss');
  late final __mm_range_round_ss = __mm_range_round_ssPtr
      .asFunction<__m128 Function(__m128, __m128, int, int)>();

  __m128 _mm_mask_range_round_ss(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    __m128 arg3,
    int arg4,
    int arg5,
  ) {
    return __mm_mask_range_round_ss(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
      arg5,
    );
  }

  late final __mm_mask_range_round_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(__m128, __mmask8, __m128, __m128, ffi.Int32,
              ffi.Int32)>>('_mm_mask_range_round_ss');
  late final __mm_mask_range_round_ss = __mm_mask_range_round_ssPtr
      .asFunction<__m128 Function(__m128, int, __m128, __m128, int, int)>();

  __m128 _mm_maskz_range_round_ss(
    int arg0,
    __m128 arg1,
    __m128 arg2,
    int arg3,
    int arg4,
  ) {
    return __mm_maskz_range_round_ss(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_maskz_range_round_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(__mmask8, __m128, __m128, ffi.Int32,
              ffi.Int32)>>('_mm_maskz_range_round_ss');
  late final __mm_maskz_range_round_ss = __mm_maskz_range_round_ssPtr
      .asFunction<__m128 Function(int, __m128, __m128, int, int)>();

  _m128d _mm_mask_rcp14_sd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    _m128d arg3,
  ) {
    return __mm_mask_rcp14_sd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_rcp14_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              _m128d, __mmask8, _m128d, _m128d)>>('_mm_mask_rcp14_sd');
  late final __mm_mask_rcp14_sd = __mm_mask_rcp14_sdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d, _m128d)>();

  _m128d _mm_maskz_rcp14_sd(
    int arg0,
    _m128d arg1,
    _m128d arg2,
  ) {
    return __mm_maskz_rcp14_sd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_rcp14_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(__mmask8, _m128d, _m128d)>>(
          '_mm_maskz_rcp14_sd');
  late final __mm_maskz_rcp14_sd =
      __mm_maskz_rcp14_sdPtr.asFunction<_m128d Function(int, _m128d, _m128d)>();

  _m128d _mm_rcp14_sd(
    _m128d arg0,
    _m128d arg1,
  ) {
    return __mm_rcp14_sd(
      arg0,
      arg1,
    );
  }

  late final __mm_rcp14_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d)>>(
          '_mm_rcp14_sd');
  late final __mm_rcp14_sd =
      __mm_rcp14_sdPtr.asFunction<_m128d Function(_m128d, _m128d)>();

  __m128 _mm_mask_rcp14_ss(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    __m128 arg3,
  ) {
    return __mm_mask_rcp14_ss(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_rcp14_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __m128, __mmask8, __m128, __m128)>>('_mm_mask_rcp14_ss');
  late final __mm_mask_rcp14_ss = __mm_mask_rcp14_ssPtr
      .asFunction<__m128 Function(__m128, int, __m128, __m128)>();

  __m128 _mm_maskz_rcp14_ss(
    int arg0,
    __m128 arg1,
    __m128 arg2,
  ) {
    return __mm_maskz_rcp14_ss(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_rcp14_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__mmask8, __m128, __m128)>>(
          '_mm_maskz_rcp14_ss');
  late final __mm_maskz_rcp14_ss =
      __mm_maskz_rcp14_ssPtr.asFunction<__m128 Function(int, __m128, __m128)>();

  __m128 _mm_rcp14_ss(
    __m128 arg0,
    __m128 arg1,
  ) {
    return __mm_rcp14_ss(
      arg0,
      arg1,
    );
  }

  late final __mm_rcp14_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128)>>(
          '_mm_rcp14_ss');
  late final __mm_rcp14_ss =
      __mm_rcp14_ssPtr.asFunction<__m128 Function(__m128, __m128)>();

  _m128d _mm_mask_rcp28_round_sd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    _m128d arg3,
    int arg4,
  ) {
    return __mm_mask_rcp28_round_sd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_rcp28_round_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(_m128d, __mmask8, _m128d, _m128d,
              ffi.Int32)>>('_mm_mask_rcp28_round_sd');
  late final __mm_mask_rcp28_round_sd = __mm_mask_rcp28_round_sdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d, _m128d, int)>();

  _m128d _mm_maskz_rcp28_round_sd(
    int arg0,
    _m128d arg1,
    _m128d arg2,
    int arg3,
  ) {
    return __mm_maskz_rcp28_round_sd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_rcp28_round_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(__mmask8, _m128d, _m128d,
              ffi.Int32)>>('_mm_maskz_rcp28_round_sd');
  late final __mm_maskz_rcp28_round_sd = __mm_maskz_rcp28_round_sdPtr
      .asFunction<_m128d Function(int, _m128d, _m128d, int)>();

  _m128d _mm_rcp28_round_sd(
    _m128d arg0,
    _m128d arg1,
    int arg2,
  ) {
    return __mm_rcp28_round_sd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_rcp28_round_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d, ffi.Int32)>>(
          '_mm_rcp28_round_sd');
  late final __mm_rcp28_round_sd =
      __mm_rcp28_round_sdPtr.asFunction<_m128d Function(_m128d, _m128d, int)>();

  __m128 _mm_mask_rcp28_round_ss(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    __m128 arg3,
    int arg4,
  ) {
    return __mm_mask_rcp28_round_ss(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_rcp28_round_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(__m128, __mmask8, __m128, __m128,
              ffi.Int32)>>('_mm_mask_rcp28_round_ss');
  late final __mm_mask_rcp28_round_ss = __mm_mask_rcp28_round_ssPtr
      .asFunction<__m128 Function(__m128, int, __m128, __m128, int)>();

  __m128 _mm_maskz_rcp28_round_ss(
    int arg0,
    __m128 arg1,
    __m128 arg2,
    int arg3,
  ) {
    return __mm_maskz_rcp28_round_ss(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_rcp28_round_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(__mmask8, __m128, __m128,
              ffi.Int32)>>('_mm_maskz_rcp28_round_ss');
  late final __mm_maskz_rcp28_round_ss = __mm_maskz_rcp28_round_ssPtr
      .asFunction<__m128 Function(int, __m128, __m128, int)>();

  __m128 _mm_rcp28_round_ss(
    __m128 arg0,
    __m128 arg1,
    int arg2,
  ) {
    return __mm_rcp28_round_ss(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_rcp28_round_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128, ffi.Int32)>>(
          '_mm_rcp28_round_ss');
  late final __mm_rcp28_round_ss =
      __mm_rcp28_round_ssPtr.asFunction<__m128 Function(__m128, __m128, int)>();

  _m128d _mm_mask_rcp28_sd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    _m128d arg3,
  ) {
    return __mm_mask_rcp28_sd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_rcp28_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              _m128d, __mmask8, _m128d, _m128d)>>('_mm_mask_rcp28_sd');
  late final __mm_mask_rcp28_sd = __mm_mask_rcp28_sdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d, _m128d)>();

  _m128d _mm_maskz_rcp28_sd(
    int arg0,
    _m128d arg1,
    _m128d arg2,
  ) {
    return __mm_maskz_rcp28_sd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_rcp28_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(__mmask8, _m128d, _m128d)>>(
          '_mm_maskz_rcp28_sd');
  late final __mm_maskz_rcp28_sd =
      __mm_maskz_rcp28_sdPtr.asFunction<_m128d Function(int, _m128d, _m128d)>();

  _m128d _mm_rcp28_sd(
    _m128d arg0,
    _m128d arg1,
  ) {
    return __mm_rcp28_sd(
      arg0,
      arg1,
    );
  }

  late final __mm_rcp28_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d)>>(
          '_mm_rcp28_sd');
  late final __mm_rcp28_sd =
      __mm_rcp28_sdPtr.asFunction<_m128d Function(_m128d, _m128d)>();

  __m128 _mm_mask_rcp28_ss(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    __m128 arg3,
  ) {
    return __mm_mask_rcp28_ss(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_rcp28_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __m128, __mmask8, __m128, __m128)>>('_mm_mask_rcp28_ss');
  late final __mm_mask_rcp28_ss = __mm_mask_rcp28_ssPtr
      .asFunction<__m128 Function(__m128, int, __m128, __m128)>();

  __m128 _mm_maskz_rcp28_ss(
    int arg0,
    __m128 arg1,
    __m128 arg2,
  ) {
    return __mm_maskz_rcp28_ss(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_rcp28_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__mmask8, __m128, __m128)>>(
          '_mm_maskz_rcp28_ss');
  late final __mm_maskz_rcp28_ss =
      __mm_maskz_rcp28_ssPtr.asFunction<__m128 Function(int, __m128, __m128)>();

  __m128 _mm_rcp28_ss(
    __m128 arg0,
    __m128 arg1,
  ) {
    return __mm_rcp28_ss(
      arg0,
      arg1,
    );
  }

  late final __mm_rcp28_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128)>>(
          '_mm_rcp28_ss');
  late final __mm_rcp28_ss =
      __mm_rcp28_ssPtr.asFunction<__m128 Function(__m128, __m128)>();

  _m128d _mm_mask_reduce_round_sd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    _m128d arg3,
    int arg4,
    int arg5,
  ) {
    return __mm_mask_reduce_round_sd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
      arg5,
    );
  }

  late final __mm_mask_reduce_round_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(_m128d, __mmask8, _m128d, _m128d, ffi.Int32,
              ffi.Int32)>>('_mm_mask_reduce_round_sd');
  late final __mm_mask_reduce_round_sd = __mm_mask_reduce_round_sdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d, _m128d, int, int)>();

  _m128d _mm_maskz_reduce_round_sd(
    int arg0,
    _m128d arg1,
    _m128d arg2,
    int arg3,
    int arg4,
  ) {
    return __mm_maskz_reduce_round_sd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_maskz_reduce_round_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(__mmask8, _m128d, _m128d, ffi.Int32,
              ffi.Int32)>>('_mm_maskz_reduce_round_sd');
  late final __mm_maskz_reduce_round_sd = __mm_maskz_reduce_round_sdPtr
      .asFunction<_m128d Function(int, _m128d, _m128d, int, int)>();

  _m128d _mm_reduce_round_sd(
    _m128d arg0,
    _m128d arg1,
    int arg2,
    int arg3,
  ) {
    return __mm_reduce_round_sd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_reduce_round_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              _m128d, _m128d, ffi.Int32, ffi.Int32)>>('_mm_reduce_round_sd');
  late final __mm_reduce_round_sd = __mm_reduce_round_sdPtr
      .asFunction<_m128d Function(_m128d, _m128d, int, int)>();

  __m128 _mm_mask_reduce_round_ss(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    __m128 arg3,
    int arg4,
    int arg5,
  ) {
    return __mm_mask_reduce_round_ss(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
      arg5,
    );
  }

  late final __mm_mask_reduce_round_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(__m128, __mmask8, __m128, __m128, ffi.Int32,
              ffi.Int32)>>('_mm_mask_reduce_round_ss');
  late final __mm_mask_reduce_round_ss = __mm_mask_reduce_round_ssPtr
      .asFunction<__m128 Function(__m128, int, __m128, __m128, int, int)>();

  __m128 _mm_maskz_reduce_round_ss(
    int arg0,
    __m128 arg1,
    __m128 arg2,
    int arg3,
    int arg4,
  ) {
    return __mm_maskz_reduce_round_ss(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_maskz_reduce_round_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(__mmask8, __m128, __m128, ffi.Int32,
              ffi.Int32)>>('_mm_maskz_reduce_round_ss');
  late final __mm_maskz_reduce_round_ss = __mm_maskz_reduce_round_ssPtr
      .asFunction<__m128 Function(int, __m128, __m128, int, int)>();

  __m128 _mm_reduce_round_ss(
    __m128 arg0,
    __m128 arg1,
    int arg2,
    int arg3,
  ) {
    return __mm_reduce_round_ss(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_reduce_round_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __m128, __m128, ffi.Int32, ffi.Int32)>>('_mm_reduce_round_ss');
  late final __mm_reduce_round_ss = __mm_reduce_round_ssPtr
      .asFunction<__m128 Function(__m128, __m128, int, int)>();

  _m128d _mm_mask_reduce_sd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    _m128d arg3,
    int arg4,
  ) {
    return __mm_mask_reduce_sd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_reduce_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(_m128d, __mmask8, _m128d, _m128d,
              ffi.Int32)>>('_mm_mask_reduce_sd');
  late final __mm_mask_reduce_sd = __mm_mask_reduce_sdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d, _m128d, int)>();

  _m128d _mm_maskz_reduce_sd(
    int arg0,
    _m128d arg1,
    _m128d arg2,
    int arg3,
  ) {
    return __mm_maskz_reduce_sd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_reduce_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              __mmask8, _m128d, _m128d, ffi.Int32)>>('_mm_maskz_reduce_sd');
  late final __mm_maskz_reduce_sd = __mm_maskz_reduce_sdPtr
      .asFunction<_m128d Function(int, _m128d, _m128d, int)>();

  _m128d _mm_reduce_sd(
    _m128d arg0,
    _m128d arg1,
    int arg2,
  ) {
    return __mm_reduce_sd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_reduce_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d, ffi.Int32)>>(
          '_mm_reduce_sd');
  late final __mm_reduce_sd =
      __mm_reduce_sdPtr.asFunction<_m128d Function(_m128d, _m128d, int)>();

  __m128 _mm_mask_reduce_ss(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    __m128 arg3,
    int arg4,
  ) {
    return __mm_mask_reduce_ss(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_reduce_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(__m128, __mmask8, __m128, __m128,
              ffi.Int32)>>('_mm_mask_reduce_ss');
  late final __mm_mask_reduce_ss = __mm_mask_reduce_ssPtr
      .asFunction<__m128 Function(__m128, int, __m128, __m128, int)>();

  __m128 _mm_maskz_reduce_ss(
    int arg0,
    __m128 arg1,
    __m128 arg2,
    int arg3,
  ) {
    return __mm_maskz_reduce_ss(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_reduce_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __mmask8, __m128, __m128, ffi.Int32)>>('_mm_maskz_reduce_ss');
  late final __mm_maskz_reduce_ss = __mm_maskz_reduce_ssPtr
      .asFunction<__m128 Function(int, __m128, __m128, int)>();

  __m128 _mm_reduce_ss(
    __m128 arg0,
    __m128 arg1,
    int arg2,
  ) {
    return __mm_reduce_ss(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_reduce_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128, ffi.Int32)>>(
          '_mm_reduce_ss');
  late final __mm_reduce_ss =
      __mm_reduce_ssPtr.asFunction<__m128 Function(__m128, __m128, int)>();

  _m128d _mm_mask_roundscale_round_sd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    _m128d arg3,
    int arg4,
    int arg5,
  ) {
    return __mm_mask_roundscale_round_sd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
      arg5,
    );
  }

  late final __mm_mask_roundscale_round_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(_m128d, __mmask8, _m128d, _m128d, ffi.Int32,
              ffi.Int32)>>('_mm_mask_roundscale_round_sd');
  late final __mm_mask_roundscale_round_sd = __mm_mask_roundscale_round_sdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d, _m128d, int, int)>();

  _m128d _mm_maskz_roundscale_round_sd(
    int arg0,
    _m128d arg1,
    _m128d arg2,
    int arg3,
    int arg4,
  ) {
    return __mm_maskz_roundscale_round_sd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_maskz_roundscale_round_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(__mmask8, _m128d, _m128d, ffi.Int32,
              ffi.Int32)>>('_mm_maskz_roundscale_round_sd');
  late final __mm_maskz_roundscale_round_sd = __mm_maskz_roundscale_round_sdPtr
      .asFunction<_m128d Function(int, _m128d, _m128d, int, int)>();

  _m128d _mm_roundscale_round_sd(
    _m128d arg0,
    _m128d arg1,
    int arg2,
    int arg3,
  ) {
    return __mm_roundscale_round_sd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_roundscale_round_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(_m128d, _m128d, ffi.Int32,
              ffi.Int32)>>('_mm_roundscale_round_sd');
  late final __mm_roundscale_round_sd = __mm_roundscale_round_sdPtr
      .asFunction<_m128d Function(_m128d, _m128d, int, int)>();

  __m128 _mm_mask_roundscale_round_ss(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    __m128 arg3,
    int arg4,
    int arg5,
  ) {
    return __mm_mask_roundscale_round_ss(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
      arg5,
    );
  }

  late final __mm_mask_roundscale_round_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(__m128, __mmask8, __m128, __m128, ffi.Int32,
              ffi.Int32)>>('_mm_mask_roundscale_round_ss');
  late final __mm_mask_roundscale_round_ss = __mm_mask_roundscale_round_ssPtr
      .asFunction<__m128 Function(__m128, int, __m128, __m128, int, int)>();

  __m128 _mm_maskz_roundscale_round_ss(
    int arg0,
    __m128 arg1,
    __m128 arg2,
    int arg3,
    int arg4,
  ) {
    return __mm_maskz_roundscale_round_ss(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_maskz_roundscale_round_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(__mmask8, __m128, __m128, ffi.Int32,
              ffi.Int32)>>('_mm_maskz_roundscale_round_ss');
  late final __mm_maskz_roundscale_round_ss = __mm_maskz_roundscale_round_ssPtr
      .asFunction<__m128 Function(int, __m128, __m128, int, int)>();

  __m128 _mm_roundscale_round_ss(
    __m128 arg0,
    __m128 arg1,
    int arg2,
    int arg3,
  ) {
    return __mm_roundscale_round_ss(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_roundscale_round_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(__m128, __m128, ffi.Int32,
              ffi.Int32)>>('_mm_roundscale_round_ss');
  late final __mm_roundscale_round_ss = __mm_roundscale_round_ssPtr
      .asFunction<__m128 Function(__m128, __m128, int, int)>();

  _m128d _mm_mask_roundscale_sd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    _m128d arg3,
    int arg4,
  ) {
    return __mm_mask_roundscale_sd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_roundscale_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(_m128d, __mmask8, _m128d, _m128d,
              ffi.Int32)>>('_mm_mask_roundscale_sd');
  late final __mm_mask_roundscale_sd = __mm_mask_roundscale_sdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d, _m128d, int)>();

  _m128d _mm_maskz_roundscale_sd(
    int arg0,
    _m128d arg1,
    _m128d arg2,
    int arg3,
  ) {
    return __mm_maskz_roundscale_sd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_roundscale_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              __mmask8, _m128d, _m128d, ffi.Int32)>>('_mm_maskz_roundscale_sd');
  late final __mm_maskz_roundscale_sd = __mm_maskz_roundscale_sdPtr
      .asFunction<_m128d Function(int, _m128d, _m128d, int)>();

  _m128d _mm_roundscale_sd(
    _m128d arg0,
    _m128d arg1,
    int arg2,
  ) {
    return __mm_roundscale_sd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_roundscale_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d, ffi.Int32)>>(
          '_mm_roundscale_sd');
  late final __mm_roundscale_sd =
      __mm_roundscale_sdPtr.asFunction<_m128d Function(_m128d, _m128d, int)>();

  __m128 _mm_mask_roundscale_ss(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    __m128 arg3,
    int arg4,
  ) {
    return __mm_mask_roundscale_ss(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_roundscale_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(__m128, __mmask8, __m128, __m128,
              ffi.Int32)>>('_mm_mask_roundscale_ss');
  late final __mm_mask_roundscale_ss = __mm_mask_roundscale_ssPtr
      .asFunction<__m128 Function(__m128, int, __m128, __m128, int)>();

  __m128 _mm_maskz_roundscale_ss(
    int arg0,
    __m128 arg1,
    __m128 arg2,
    int arg3,
  ) {
    return __mm_maskz_roundscale_ss(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_roundscale_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __mmask8, __m128, __m128, ffi.Int32)>>('_mm_maskz_roundscale_ss');
  late final __mm_maskz_roundscale_ss = __mm_maskz_roundscale_ssPtr
      .asFunction<__m128 Function(int, __m128, __m128, int)>();

  __m128 _mm_roundscale_ss(
    __m128 arg0,
    __m128 arg1,
    int arg2,
  ) {
    return __mm_roundscale_ss(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_roundscale_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128, ffi.Int32)>>(
          '_mm_roundscale_ss');
  late final __mm_roundscale_ss =
      __mm_roundscale_ssPtr.asFunction<__m128 Function(__m128, __m128, int)>();

  _m128d _mm_mask_rsqrt14_sd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    _m128d arg3,
  ) {
    return __mm_mask_rsqrt14_sd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_rsqrt14_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              _m128d, __mmask8, _m128d, _m128d)>>('_mm_mask_rsqrt14_sd');
  late final __mm_mask_rsqrt14_sd = __mm_mask_rsqrt14_sdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d, _m128d)>();

  _m128d _mm_maskz_rsqrt14_sd(
    int arg0,
    _m128d arg1,
    _m128d arg2,
  ) {
    return __mm_maskz_rsqrt14_sd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_rsqrt14_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(__mmask8, _m128d, _m128d)>>(
          '_mm_maskz_rsqrt14_sd');
  late final __mm_maskz_rsqrt14_sd = __mm_maskz_rsqrt14_sdPtr
      .asFunction<_m128d Function(int, _m128d, _m128d)>();

  _m128d _mm_rsqrt14_sd(
    _m128d arg0,
    _m128d arg1,
  ) {
    return __mm_rsqrt14_sd(
      arg0,
      arg1,
    );
  }

  late final __mm_rsqrt14_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d)>>(
          '_mm_rsqrt14_sd');
  late final __mm_rsqrt14_sd =
      __mm_rsqrt14_sdPtr.asFunction<_m128d Function(_m128d, _m128d)>();

  __m128 _mm_mask_rsqrt14_ss(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    __m128 arg3,
  ) {
    return __mm_mask_rsqrt14_ss(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_rsqrt14_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __m128, __mmask8, __m128, __m128)>>('_mm_mask_rsqrt14_ss');
  late final __mm_mask_rsqrt14_ss = __mm_mask_rsqrt14_ssPtr
      .asFunction<__m128 Function(__m128, int, __m128, __m128)>();

  __m128 _mm_maskz_rsqrt14_ss(
    int arg0,
    __m128 arg1,
    __m128 arg2,
  ) {
    return __mm_maskz_rsqrt14_ss(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_rsqrt14_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__mmask8, __m128, __m128)>>(
          '_mm_maskz_rsqrt14_ss');
  late final __mm_maskz_rsqrt14_ss = __mm_maskz_rsqrt14_ssPtr
      .asFunction<__m128 Function(int, __m128, __m128)>();

  __m128 _mm_rsqrt14_ss(
    __m128 arg0,
    __m128 arg1,
  ) {
    return __mm_rsqrt14_ss(
      arg0,
      arg1,
    );
  }

  late final __mm_rsqrt14_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128)>>(
          '_mm_rsqrt14_ss');
  late final __mm_rsqrt14_ss =
      __mm_rsqrt14_ssPtr.asFunction<__m128 Function(__m128, __m128)>();

  _m128d _mm_mask_rsqrt28_round_sd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    _m128d arg3,
    int arg4,
  ) {
    return __mm_mask_rsqrt28_round_sd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_rsqrt28_round_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(_m128d, __mmask8, _m128d, _m128d,
              ffi.Int32)>>('_mm_mask_rsqrt28_round_sd');
  late final __mm_mask_rsqrt28_round_sd = __mm_mask_rsqrt28_round_sdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d, _m128d, int)>();

  _m128d _mm_maskz_rsqrt28_round_sd(
    int arg0,
    _m128d arg1,
    _m128d arg2,
    int arg3,
  ) {
    return __mm_maskz_rsqrt28_round_sd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_rsqrt28_round_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(__mmask8, _m128d, _m128d,
              ffi.Int32)>>('_mm_maskz_rsqrt28_round_sd');
  late final __mm_maskz_rsqrt28_round_sd = __mm_maskz_rsqrt28_round_sdPtr
      .asFunction<_m128d Function(int, _m128d, _m128d, int)>();

  _m128d _mm_rsqrt28_round_sd(
    _m128d arg0,
    _m128d arg1,
    int arg2,
  ) {
    return __mm_rsqrt28_round_sd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_rsqrt28_round_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d, ffi.Int32)>>(
          '_mm_rsqrt28_round_sd');
  late final __mm_rsqrt28_round_sd = __mm_rsqrt28_round_sdPtr
      .asFunction<_m128d Function(_m128d, _m128d, int)>();

  __m128 _mm_mask_rsqrt28_round_ss(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    __m128 arg3,
    int arg4,
  ) {
    return __mm_mask_rsqrt28_round_ss(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_rsqrt28_round_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(__m128, __mmask8, __m128, __m128,
              ffi.Int32)>>('_mm_mask_rsqrt28_round_ss');
  late final __mm_mask_rsqrt28_round_ss = __mm_mask_rsqrt28_round_ssPtr
      .asFunction<__m128 Function(__m128, int, __m128, __m128, int)>();

  __m128 _mm_maskz_rsqrt28_round_ss(
    int arg0,
    __m128 arg1,
    __m128 arg2,
    int arg3,
  ) {
    return __mm_maskz_rsqrt28_round_ss(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_rsqrt28_round_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(__mmask8, __m128, __m128,
              ffi.Int32)>>('_mm_maskz_rsqrt28_round_ss');
  late final __mm_maskz_rsqrt28_round_ss = __mm_maskz_rsqrt28_round_ssPtr
      .asFunction<__m128 Function(int, __m128, __m128, int)>();

  __m128 _mm_rsqrt28_round_ss(
    __m128 arg0,
    __m128 arg1,
    int arg2,
  ) {
    return __mm_rsqrt28_round_ss(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_rsqrt28_round_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128, ffi.Int32)>>(
          '_mm_rsqrt28_round_ss');
  late final __mm_rsqrt28_round_ss = __mm_rsqrt28_round_ssPtr
      .asFunction<__m128 Function(__m128, __m128, int)>();

  _m128d _mm_mask_rsqrt28_sd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    _m128d arg3,
  ) {
    return __mm_mask_rsqrt28_sd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_rsqrt28_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              _m128d, __mmask8, _m128d, _m128d)>>('_mm_mask_rsqrt28_sd');
  late final __mm_mask_rsqrt28_sd = __mm_mask_rsqrt28_sdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d, _m128d)>();

  _m128d _mm_maskz_rsqrt28_sd(
    int arg0,
    _m128d arg1,
    _m128d arg2,
  ) {
    return __mm_maskz_rsqrt28_sd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_rsqrt28_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(__mmask8, _m128d, _m128d)>>(
          '_mm_maskz_rsqrt28_sd');
  late final __mm_maskz_rsqrt28_sd = __mm_maskz_rsqrt28_sdPtr
      .asFunction<_m128d Function(int, _m128d, _m128d)>();

  _m128d _mm_rsqrt28_sd(
    _m128d arg0,
    _m128d arg1,
  ) {
    return __mm_rsqrt28_sd(
      arg0,
      arg1,
    );
  }

  late final __mm_rsqrt28_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d)>>(
          '_mm_rsqrt28_sd');
  late final __mm_rsqrt28_sd =
      __mm_rsqrt28_sdPtr.asFunction<_m128d Function(_m128d, _m128d)>();

  __m128 _mm_mask_rsqrt28_ss(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    __m128 arg3,
  ) {
    return __mm_mask_rsqrt28_ss(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_rsqrt28_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __m128, __mmask8, __m128, __m128)>>('_mm_mask_rsqrt28_ss');
  late final __mm_mask_rsqrt28_ss = __mm_mask_rsqrt28_ssPtr
      .asFunction<__m128 Function(__m128, int, __m128, __m128)>();

  __m128 _mm_maskz_rsqrt28_ss(
    int arg0,
    __m128 arg1,
    __m128 arg2,
  ) {
    return __mm_maskz_rsqrt28_ss(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_rsqrt28_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__mmask8, __m128, __m128)>>(
          '_mm_maskz_rsqrt28_ss');
  late final __mm_maskz_rsqrt28_ss = __mm_maskz_rsqrt28_ssPtr
      .asFunction<__m128 Function(int, __m128, __m128)>();

  __m128 _mm_rsqrt28_ss(
    __m128 arg0,
    __m128 arg1,
  ) {
    return __mm_rsqrt28_ss(
      arg0,
      arg1,
    );
  }

  late final __mm_rsqrt28_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128)>>(
          '_mm_rsqrt28_ss');
  late final __mm_rsqrt28_ss =
      __mm_rsqrt28_ssPtr.asFunction<__m128 Function(__m128, __m128)>();

  _m128d _mm_mask_scalef_round_sd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    _m128d arg3,
    int arg4,
  ) {
    return __mm_mask_scalef_round_sd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_scalef_round_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(_m128d, __mmask8, _m128d, _m128d,
              ffi.Int32)>>('_mm_mask_scalef_round_sd');
  late final __mm_mask_scalef_round_sd = __mm_mask_scalef_round_sdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d, _m128d, int)>();

  _m128d _mm_maskz_scalef_round_sd(
    int arg0,
    _m128d arg1,
    _m128d arg2,
    int arg3,
  ) {
    return __mm_maskz_scalef_round_sd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_scalef_round_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(__mmask8, _m128d, _m128d,
              ffi.Int32)>>('_mm_maskz_scalef_round_sd');
  late final __mm_maskz_scalef_round_sd = __mm_maskz_scalef_round_sdPtr
      .asFunction<_m128d Function(int, _m128d, _m128d, int)>();

  _m128d _mm_scalef_round_sd(
    _m128d arg0,
    _m128d arg1,
    int arg2,
  ) {
    return __mm_scalef_round_sd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_scalef_round_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d, ffi.Int32)>>(
          '_mm_scalef_round_sd');
  late final __mm_scalef_round_sd = __mm_scalef_round_sdPtr
      .asFunction<_m128d Function(_m128d, _m128d, int)>();

  __m128 _mm_mask_scalef_round_ss(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    __m128 arg3,
    int arg4,
  ) {
    return __mm_mask_scalef_round_ss(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_scalef_round_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(__m128, __mmask8, __m128, __m128,
              ffi.Int32)>>('_mm_mask_scalef_round_ss');
  late final __mm_mask_scalef_round_ss = __mm_mask_scalef_round_ssPtr
      .asFunction<__m128 Function(__m128, int, __m128, __m128, int)>();

  __m128 _mm_maskz_scalef_round_ss(
    int arg0,
    __m128 arg1,
    __m128 arg2,
    int arg3,
  ) {
    return __mm_maskz_scalef_round_ss(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_scalef_round_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(__mmask8, __m128, __m128,
              ffi.Int32)>>('_mm_maskz_scalef_round_ss');
  late final __mm_maskz_scalef_round_ss = __mm_maskz_scalef_round_ssPtr
      .asFunction<__m128 Function(int, __m128, __m128, int)>();

  __m128 _mm_scalef_round_ss(
    __m128 arg0,
    __m128 arg1,
    int arg2,
  ) {
    return __mm_scalef_round_ss(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_scalef_round_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128, ffi.Int32)>>(
          '_mm_scalef_round_ss');
  late final __mm_scalef_round_ss = __mm_scalef_round_ssPtr
      .asFunction<__m128 Function(__m128, __m128, int)>();

  _m128d _mm_mask_scalef_sd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    _m128d arg3,
  ) {
    return __mm_mask_scalef_sd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_scalef_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              _m128d, __mmask8, _m128d, _m128d)>>('_mm_mask_scalef_sd');
  late final __mm_mask_scalef_sd = __mm_mask_scalef_sdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d, _m128d)>();

  _m128d _mm_maskz_scalef_sd(
    int arg0,
    _m128d arg1,
    _m128d arg2,
  ) {
    return __mm_maskz_scalef_sd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_scalef_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(__mmask8, _m128d, _m128d)>>(
          '_mm_maskz_scalef_sd');
  late final __mm_maskz_scalef_sd = __mm_maskz_scalef_sdPtr
      .asFunction<_m128d Function(int, _m128d, _m128d)>();

  _m128d _mm_scalef_sd(
    _m128d arg0,
    _m128d arg1,
  ) {
    return __mm_scalef_sd(
      arg0,
      arg1,
    );
  }

  late final __mm_scalef_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d)>>(
          '_mm_scalef_sd');
  late final __mm_scalef_sd =
      __mm_scalef_sdPtr.asFunction<_m128d Function(_m128d, _m128d)>();

  __m128 _mm_mask_scalef_ss(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    __m128 arg3,
  ) {
    return __mm_mask_scalef_ss(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_scalef_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __m128, __mmask8, __m128, __m128)>>('_mm_mask_scalef_ss');
  late final __mm_mask_scalef_ss = __mm_mask_scalef_ssPtr
      .asFunction<__m128 Function(__m128, int, __m128, __m128)>();

  __m128 _mm_maskz_scalef_ss(
    int arg0,
    __m128 arg1,
    __m128 arg2,
  ) {
    return __mm_maskz_scalef_ss(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_scalef_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__mmask8, __m128, __m128)>>(
          '_mm_maskz_scalef_ss');
  late final __mm_maskz_scalef_ss = __mm_maskz_scalef_ssPtr
      .asFunction<__m128 Function(int, __m128, __m128)>();

  __m128 _mm_scalef_ss(
    __m128 arg0,
    __m128 arg1,
  ) {
    return __mm_scalef_ss(
      arg0,
      arg1,
    );
  }

  late final __mm_scalef_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128)>>(
          '_mm_scalef_ss');
  late final __mm_scalef_ss =
      __mm_scalef_ssPtr.asFunction<__m128 Function(__m128, __m128)>();

  _m128d _mm_mask_sqrt_round_sd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    _m128d arg3,
    int arg4,
  ) {
    return __mm_mask_sqrt_round_sd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_sqrt_round_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(_m128d, __mmask8, _m128d, _m128d,
              ffi.Int32)>>('_mm_mask_sqrt_round_sd');
  late final __mm_mask_sqrt_round_sd = __mm_mask_sqrt_round_sdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d, _m128d, int)>();

  _m128d _mm_maskz_sqrt_round_sd(
    int arg0,
    _m128d arg1,
    _m128d arg2,
    int arg3,
  ) {
    return __mm_maskz_sqrt_round_sd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_sqrt_round_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              __mmask8, _m128d, _m128d, ffi.Int32)>>('_mm_maskz_sqrt_round_sd');
  late final __mm_maskz_sqrt_round_sd = __mm_maskz_sqrt_round_sdPtr
      .asFunction<_m128d Function(int, _m128d, _m128d, int)>();

  _m128d _mm_sqrt_round_sd(
    _m128d arg0,
    _m128d arg1,
    int arg2,
  ) {
    return __mm_sqrt_round_sd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_sqrt_round_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d, ffi.Int32)>>(
          '_mm_sqrt_round_sd');
  late final __mm_sqrt_round_sd =
      __mm_sqrt_round_sdPtr.asFunction<_m128d Function(_m128d, _m128d, int)>();

  __m128 _mm_mask_sqrt_round_ss(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    __m128 arg3,
    int arg4,
  ) {
    return __mm_mask_sqrt_round_ss(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_sqrt_round_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(__m128, __mmask8, __m128, __m128,
              ffi.Int32)>>('_mm_mask_sqrt_round_ss');
  late final __mm_mask_sqrt_round_ss = __mm_mask_sqrt_round_ssPtr
      .asFunction<__m128 Function(__m128, int, __m128, __m128, int)>();

  __m128 _mm_maskz_sqrt_round_ss(
    int arg0,
    __m128 arg1,
    __m128 arg2,
    int arg3,
  ) {
    return __mm_maskz_sqrt_round_ss(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_sqrt_round_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __mmask8, __m128, __m128, ffi.Int32)>>('_mm_maskz_sqrt_round_ss');
  late final __mm_maskz_sqrt_round_ss = __mm_maskz_sqrt_round_ssPtr
      .asFunction<__m128 Function(int, __m128, __m128, int)>();

  __m128 _mm_sqrt_round_ss(
    __m128 arg0,
    __m128 arg1,
    int arg2,
  ) {
    return __mm_sqrt_round_ss(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_sqrt_round_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128, ffi.Int32)>>(
          '_mm_sqrt_round_ss');
  late final __mm_sqrt_round_ss =
      __mm_sqrt_round_ssPtr.asFunction<__m128 Function(__m128, __m128, int)>();

  _m128d _mm_mask_sqrt_sd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    _m128d arg3,
  ) {
    return __mm_mask_sqrt_sd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_sqrt_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              _m128d, __mmask8, _m128d, _m128d)>>('_mm_mask_sqrt_sd');
  late final __mm_mask_sqrt_sd = __mm_mask_sqrt_sdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d, _m128d)>();

  _m128d _mm_maskz_sqrt_sd(
    int arg0,
    _m128d arg1,
    _m128d arg2,
  ) {
    return __mm_maskz_sqrt_sd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_sqrt_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(__mmask8, _m128d, _m128d)>>(
          '_mm_maskz_sqrt_sd');
  late final __mm_maskz_sqrt_sd =
      __mm_maskz_sqrt_sdPtr.asFunction<_m128d Function(int, _m128d, _m128d)>();

  __m128 _mm_mask_sqrt_ss(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    __m128 arg3,
  ) {
    return __mm_mask_sqrt_ss(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_sqrt_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __m128, __mmask8, __m128, __m128)>>('_mm_mask_sqrt_ss');
  late final __mm_mask_sqrt_ss = __mm_mask_sqrt_ssPtr
      .asFunction<__m128 Function(__m128, int, __m128, __m128)>();

  __m128 _mm_maskz_sqrt_ss(
    int arg0,
    __m128 arg1,
    __m128 arg2,
  ) {
    return __mm_maskz_sqrt_ss(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_sqrt_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__mmask8, __m128, __m128)>>(
          '_mm_maskz_sqrt_ss');
  late final __mm_maskz_sqrt_ss =
      __mm_maskz_sqrt_ssPtr.asFunction<__m128 Function(int, __m128, __m128)>();

  void _mm_mask_store_sd(
    ffi.Pointer<ffi.Double> arg0,
    int arg1,
    _m128d arg2,
  ) {
    return __mm_mask_store_sd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_store_sdPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<ffi.Double>, __mmask8, _m128d)>>('_mm_mask_store_sd');
  late final __mm_mask_store_sd = __mm_mask_store_sdPtr
      .asFunction<void Function(ffi.Pointer<ffi.Double>, int, _m128d)>();

  void _mm_mask_store_ss(
    ffi.Pointer<ffi.Float> arg0,
    int arg1,
    __m128 arg2,
  ) {
    return __mm_mask_store_ss(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_store_ssPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<ffi.Float>, __mmask8, __m128)>>('_mm_mask_store_ss');
  late final __mm_mask_store_ss = __mm_mask_store_ssPtr
      .asFunction<void Function(ffi.Pointer<ffi.Float>, int, __m128)>();

  _m128d _mm_mask_sub_round_sd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    _m128d arg3,
    int arg4,
  ) {
    return __mm_mask_sub_round_sd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_sub_round_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(_m128d, __mmask8, _m128d, _m128d,
              ffi.Int32)>>('_mm_mask_sub_round_sd');
  late final __mm_mask_sub_round_sd = __mm_mask_sub_round_sdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d, _m128d, int)>();

  _m128d _mm_maskz_sub_round_sd(
    int arg0,
    _m128d arg1,
    _m128d arg2,
    int arg3,
  ) {
    return __mm_maskz_sub_round_sd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_sub_round_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              __mmask8, _m128d, _m128d, ffi.Int32)>>('_mm_maskz_sub_round_sd');
  late final __mm_maskz_sub_round_sd = __mm_maskz_sub_round_sdPtr
      .asFunction<_m128d Function(int, _m128d, _m128d, int)>();

  _m128d _mm_sub_round_sd(
    _m128d arg0,
    _m128d arg1,
    int arg2,
  ) {
    return __mm_sub_round_sd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_sub_round_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d, ffi.Int32)>>(
          '_mm_sub_round_sd');
  late final __mm_sub_round_sd =
      __mm_sub_round_sdPtr.asFunction<_m128d Function(_m128d, _m128d, int)>();

  __m128 _mm_mask_sub_round_ss(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    __m128 arg3,
    int arg4,
  ) {
    return __mm_mask_sub_round_ss(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_sub_round_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(__m128, __mmask8, __m128, __m128,
              ffi.Int32)>>('_mm_mask_sub_round_ss');
  late final __mm_mask_sub_round_ss = __mm_mask_sub_round_ssPtr
      .asFunction<__m128 Function(__m128, int, __m128, __m128, int)>();

  __m128 _mm_maskz_sub_round_ss(
    int arg0,
    __m128 arg1,
    __m128 arg2,
    int arg3,
  ) {
    return __mm_maskz_sub_round_ss(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_sub_round_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __mmask8, __m128, __m128, ffi.Int32)>>('_mm_maskz_sub_round_ss');
  late final __mm_maskz_sub_round_ss = __mm_maskz_sub_round_ssPtr
      .asFunction<__m128 Function(int, __m128, __m128, int)>();

  __m128 _mm_sub_round_ss(
    __m128 arg0,
    __m128 arg1,
    int arg2,
  ) {
    return __mm_sub_round_ss(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_sub_round_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128, ffi.Int32)>>(
          '_mm_sub_round_ss');
  late final __mm_sub_round_ss =
      __mm_sub_round_ssPtr.asFunction<__m128 Function(__m128, __m128, int)>();

  _m128d _mm_mask_sub_sd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    _m128d arg3,
  ) {
    return __mm_mask_sub_sd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_sub_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              _m128d, __mmask8, _m128d, _m128d)>>('_mm_mask_sub_sd');
  late final __mm_mask_sub_sd = __mm_mask_sub_sdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d, _m128d)>();

  _m128d _mm_maskz_sub_sd(
    int arg0,
    _m128d arg1,
    _m128d arg2,
  ) {
    return __mm_maskz_sub_sd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_sub_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(__mmask8, _m128d, _m128d)>>(
          '_mm_maskz_sub_sd');
  late final __mm_maskz_sub_sd =
      __mm_maskz_sub_sdPtr.asFunction<_m128d Function(int, _m128d, _m128d)>();

  __m128 _mm_mask_sub_ss(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    __m128 arg3,
  ) {
    return __mm_mask_sub_ss(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_sub_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __m128, __mmask8, __m128, __m128)>>('_mm_mask_sub_ss');
  late final __mm_mask_sub_ss = __mm_mask_sub_ssPtr
      .asFunction<__m128 Function(__m128, int, __m128, __m128)>();

  __m128 _mm_maskz_sub_ss(
    int arg0,
    __m128 arg1,
    __m128 arg2,
  ) {
    return __mm_maskz_sub_ss(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_sub_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__mmask8, __m128, __m128)>>(
          '_mm_maskz_sub_ss');
  late final __mm_maskz_sub_ss =
      __mm_maskz_sub_ssPtr.asFunction<__m128 Function(int, __m128, __m128)>();

  int _mm_cvtsd_u64(
    _m128d arg0,
  ) {
    return __mm_cvtsd_u64(
      arg0,
    );
  }

  late final __mm_cvtsd_u64Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function(_m128d)>>('_mm_cvtsd_u64');
  late final __mm_cvtsd_u64 =
      __mm_cvtsd_u64Ptr.asFunction<int Function(_m128d)>();

  int _mm_cvtss_u64(
    __m128 arg0,
  ) {
    return __mm_cvtss_u64(
      arg0,
    );
  }

  late final __mm_cvtss_u64Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function(__m128)>>('_mm_cvtss_u64');
  late final __mm_cvtss_u64 =
      __mm_cvtss_u64Ptr.asFunction<int Function(__m128)>();

  int _mm_cvttsd_u64(
    _m128d arg0,
  ) {
    return __mm_cvttsd_u64(
      arg0,
    );
  }

  late final __mm_cvttsd_u64Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function(_m128d)>>(
          '_mm_cvttsd_u64');
  late final __mm_cvttsd_u64 =
      __mm_cvttsd_u64Ptr.asFunction<int Function(_m128d)>();

  int _mm_cvttss_u64(
    __m128 arg0,
  ) {
    return __mm_cvttss_u64(
      arg0,
    );
  }

  late final __mm_cvttss_u64Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function(__m128)>>(
          '_mm_cvttss_u64');
  late final __mm_cvttss_u64 =
      __mm_cvttss_u64Ptr.asFunction<int Function(__m128)>();

  int _mm_cvt_roundsd_u64(
    _m128d arg0,
    int arg1,
  ) {
    return __mm_cvt_roundsd_u64(
      arg0,
      arg1,
    );
  }

  late final __mm_cvt_roundsd_u64Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function(_m128d, ffi.Int32)>>(
          '_mm_cvt_roundsd_u64');
  late final __mm_cvt_roundsd_u64 =
      __mm_cvt_roundsd_u64Ptr.asFunction<int Function(_m128d, int)>();

  int _mm_cvt_roundss_u64(
    __m128 arg0,
    int arg1,
  ) {
    return __mm_cvt_roundss_u64(
      arg0,
      arg1,
    );
  }

  late final __mm_cvt_roundss_u64Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function(__m128, ffi.Int32)>>(
          '_mm_cvt_roundss_u64');
  late final __mm_cvt_roundss_u64 =
      __mm_cvt_roundss_u64Ptr.asFunction<int Function(__m128, int)>();

  int _mm_cvtt_roundsd_u64(
    _m128d arg0,
    int arg1,
  ) {
    return __mm_cvtt_roundsd_u64(
      arg0,
      arg1,
    );
  }

  late final __mm_cvtt_roundsd_u64Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function(_m128d, ffi.Int32)>>(
          '_mm_cvtt_roundsd_u64');
  late final __mm_cvtt_roundsd_u64 =
      __mm_cvtt_roundsd_u64Ptr.asFunction<int Function(_m128d, int)>();

  int _mm_cvtt_roundss_u64(
    __m128 arg0,
    int arg1,
  ) {
    return __mm_cvtt_roundss_u64(
      arg0,
      arg1,
    );
  }

  late final __mm_cvtt_roundss_u64Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function(__m128, ffi.Int32)>>(
          '_mm_cvtt_roundss_u64');
  late final __mm_cvtt_roundss_u64 =
      __mm_cvtt_roundss_u64Ptr.asFunction<int Function(__m128, int)>();

  _m128d _mm_cvti64_sd(
    _m128d arg0,
    int arg1,
  ) {
    return __mm_cvti64_sd(
      arg0,
      arg1,
    );
  }

  late final __mm_cvti64_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, ffi.Int64)>>(
          '_mm_cvti64_sd');
  late final __mm_cvti64_sd =
      __mm_cvti64_sdPtr.asFunction<_m128d Function(_m128d, int)>();

  __m128 _mm_cvti64_ss(
    __m128 arg0,
    int arg1,
  ) {
    return __mm_cvti64_ss(
      arg0,
      arg1,
    );
  }

  late final __mm_cvti64_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, ffi.Int64)>>(
          '_mm_cvti64_ss');
  late final __mm_cvti64_ss =
      __mm_cvti64_ssPtr.asFunction<__m128 Function(__m128, int)>();

  int _mm_cvtsd_i64(
    _m128d arg0,
  ) {
    return __mm_cvtsd_i64(
      arg0,
    );
  }

  late final __mm_cvtsd_i64Ptr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(_m128d)>>('_mm_cvtsd_i64');
  late final __mm_cvtsd_i64 =
      __mm_cvtsd_i64Ptr.asFunction<int Function(_m128d)>();

  int _mm_cvtss_i64(
    __m128 arg0,
  ) {
    return __mm_cvtss_i64(
      arg0,
    );
  }

  late final __mm_cvtss_i64Ptr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(__m128)>>('_mm_cvtss_i64');
  late final __mm_cvtss_i64 =
      __mm_cvtss_i64Ptr.asFunction<int Function(__m128)>();

  int _mm_cvttsd_i64(
    _m128d arg0,
  ) {
    return __mm_cvttsd_i64(
      arg0,
    );
  }

  late final __mm_cvttsd_i64Ptr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(_m128d)>>('_mm_cvttsd_i64');
  late final __mm_cvttsd_i64 =
      __mm_cvttsd_i64Ptr.asFunction<int Function(_m128d)>();

  int _mm_cvttss_i64(
    __m128 arg0,
  ) {
    return __mm_cvttss_i64(
      arg0,
    );
  }

  late final __mm_cvttss_i64Ptr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(__m128)>>('_mm_cvttss_i64');
  late final __mm_cvttss_i64 =
      __mm_cvttss_i64Ptr.asFunction<int Function(__m128)>();

  int _mm_cvtt_roundsd_i64(
    _m128d arg0,
    int arg1,
  ) {
    return __mm_cvtt_roundsd_i64(
      arg0,
      arg1,
    );
  }

  late final __mm_cvtt_roundsd_i64Ptr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(_m128d, ffi.Int32)>>(
          '_mm_cvtt_roundsd_i64');
  late final __mm_cvtt_roundsd_i64 =
      __mm_cvtt_roundsd_i64Ptr.asFunction<int Function(_m128d, int)>();

  int _mm_cvtt_roundsd_si64(
    _m128d arg0,
    int arg1,
  ) {
    return __mm_cvtt_roundsd_si64(
      arg0,
      arg1,
    );
  }

  late final __mm_cvtt_roundsd_si64Ptr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(_m128d, ffi.Int32)>>(
          '_mm_cvtt_roundsd_si64');
  late final __mm_cvtt_roundsd_si64 =
      __mm_cvtt_roundsd_si64Ptr.asFunction<int Function(_m128d, int)>();

  int _mm_cvtt_roundss_i64(
    __m128 arg0,
    int arg1,
  ) {
    return __mm_cvtt_roundss_i64(
      arg0,
      arg1,
    );
  }

  late final __mm_cvtt_roundss_i64Ptr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(__m128, ffi.Int32)>>(
          '_mm_cvtt_roundss_i64');
  late final __mm_cvtt_roundss_i64 =
      __mm_cvtt_roundss_i64Ptr.asFunction<int Function(__m128, int)>();

  int _mm_cvtt_roundss_si64(
    __m128 arg0,
    int arg1,
  ) {
    return __mm_cvtt_roundss_si64(
      arg0,
      arg1,
    );
  }

  late final __mm_cvtt_roundss_si64Ptr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(__m128, ffi.Int32)>>(
          '_mm_cvtt_roundss_si64');
  late final __mm_cvtt_roundss_si64 =
      __mm_cvtt_roundss_si64Ptr.asFunction<int Function(__m128, int)>();

  _m128d _mm_cvtu64_sd(
    _m128d arg0,
    int arg1,
  ) {
    return __mm_cvtu64_sd(
      arg0,
      arg1,
    );
  }

  late final __mm_cvtu64_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, ffi.Uint64)>>(
          '_mm_cvtu64_sd');
  late final __mm_cvtu64_sd =
      __mm_cvtu64_sdPtr.asFunction<_m128d Function(_m128d, int)>();

  __m128 _mm_cvtu64_ss(
    __m128 arg0,
    int arg1,
  ) {
    return __mm_cvtu64_ss(
      arg0,
      arg1,
    );
  }

  late final __mm_cvtu64_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, ffi.Uint64)>>(
          '_mm_cvtu64_ss');
  late final __mm_cvtu64_ss =
      __mm_cvtu64_ssPtr.asFunction<__m128 Function(__m128, int)>();

  _m128d _mm_cvt_roundi64_sd(
    _m128d arg0,
    int arg1,
    int arg2,
  ) {
    return __mm_cvt_roundi64_sd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_cvt_roundi64_sdPtr = _lookup<
          ffi.NativeFunction<_m128d Function(_m128d, ffi.Int64, ffi.Int32)>>(
      '_mm_cvt_roundi64_sd');
  late final __mm_cvt_roundi64_sd =
      __mm_cvt_roundi64_sdPtr.asFunction<_m128d Function(_m128d, int, int)>();

  __m128 _mm_cvt_roundi64_ss(
    __m128 arg0,
    int arg1,
    int arg2,
  ) {
    return __mm_cvt_roundi64_ss(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_cvt_roundi64_ssPtr = _lookup<
          ffi.NativeFunction<__m128 Function(__m128, ffi.Int64, ffi.Int32)>>(
      '_mm_cvt_roundi64_ss');
  late final __mm_cvt_roundi64_ss =
      __mm_cvt_roundi64_ssPtr.asFunction<__m128 Function(__m128, int, int)>();

  int _mm_cvt_roundsd_i64(
    _m128d arg0,
    int arg1,
  ) {
    return __mm_cvt_roundsd_i64(
      arg0,
      arg1,
    );
  }

  late final __mm_cvt_roundsd_i64Ptr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(_m128d, ffi.Int32)>>(
          '_mm_cvt_roundsd_i64');
  late final __mm_cvt_roundsd_i64 =
      __mm_cvt_roundsd_i64Ptr.asFunction<int Function(_m128d, int)>();

  int _mm_cvt_roundsd_si64(
    _m128d arg0,
    int arg1,
  ) {
    return __mm_cvt_roundsd_si64(
      arg0,
      arg1,
    );
  }

  late final __mm_cvt_roundsd_si64Ptr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(_m128d, ffi.Int32)>>(
          '_mm_cvt_roundsd_si64');
  late final __mm_cvt_roundsd_si64 =
      __mm_cvt_roundsd_si64Ptr.asFunction<int Function(_m128d, int)>();

  _m128d _mm_cvt_roundsi64_sd(
    _m128d arg0,
    int arg1,
    int arg2,
  ) {
    return __mm_cvt_roundsi64_sd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_cvt_roundsi64_sdPtr = _lookup<
          ffi.NativeFunction<_m128d Function(_m128d, ffi.Int64, ffi.Int32)>>(
      '_mm_cvt_roundsi64_sd');
  late final __mm_cvt_roundsi64_sd =
      __mm_cvt_roundsi64_sdPtr.asFunction<_m128d Function(_m128d, int, int)>();

  __m128 _mm_cvt_roundsi64_ss(
    __m128 arg0,
    int arg1,
    int arg2,
  ) {
    return __mm_cvt_roundsi64_ss(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_cvt_roundsi64_ssPtr = _lookup<
          ffi.NativeFunction<__m128 Function(__m128, ffi.Int64, ffi.Int32)>>(
      '_mm_cvt_roundsi64_ss');
  late final __mm_cvt_roundsi64_ss =
      __mm_cvt_roundsi64_ssPtr.asFunction<__m128 Function(__m128, int, int)>();

  int _mm_cvt_roundss_i64(
    __m128 arg0,
    int arg1,
  ) {
    return __mm_cvt_roundss_i64(
      arg0,
      arg1,
    );
  }

  late final __mm_cvt_roundss_i64Ptr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(__m128, ffi.Int32)>>(
          '_mm_cvt_roundss_i64');
  late final __mm_cvt_roundss_i64 =
      __mm_cvt_roundss_i64Ptr.asFunction<int Function(__m128, int)>();

  int _mm_cvt_roundss_si64(
    __m128 arg0,
    int arg1,
  ) {
    return __mm_cvt_roundss_si64(
      arg0,
      arg1,
    );
  }

  late final __mm_cvt_roundss_si64Ptr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(__m128, ffi.Int32)>>(
          '_mm_cvt_roundss_si64');
  late final __mm_cvt_roundss_si64 =
      __mm_cvt_roundss_si64Ptr.asFunction<int Function(__m128, int)>();

  _m128d _mm_cvt_roundu64_sd(
    _m128d arg0,
    int arg1,
    int arg2,
  ) {
    return __mm_cvt_roundu64_sd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_cvt_roundu64_sdPtr = _lookup<
          ffi.NativeFunction<_m128d Function(_m128d, ffi.Uint64, ffi.Int32)>>(
      '_mm_cvt_roundu64_sd');
  late final __mm_cvt_roundu64_sd =
      __mm_cvt_roundu64_sdPtr.asFunction<_m128d Function(_m128d, int, int)>();

  __m128 _mm_cvt_roundu64_ss(
    __m128 arg0,
    int arg1,
    int arg2,
  ) {
    return __mm_cvt_roundu64_ss(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_cvt_roundu64_ssPtr = _lookup<
          ffi.NativeFunction<__m128 Function(__m128, ffi.Uint64, ffi.Int32)>>(
      '_mm_cvt_roundu64_ss');
  late final __mm_cvt_roundu64_ss =
      __mm_cvt_roundu64_ssPtr.asFunction<__m128 Function(__m128, int, int)>();

  _m512d _mm512_zextpd128_pd512(
    _m128d arg0,
  ) {
    return __mm512_zextpd128_pd512(
      arg0,
    );
  }

  late final __mm512_zextpd128_pd512Ptr =
      _lookup<ffi.NativeFunction<_m512d Function(_m128d)>>(
          '_mm512_zextpd128_pd512');
  late final __mm512_zextpd128_pd512 =
      __mm512_zextpd128_pd512Ptr.asFunction<_m512d Function(_m128d)>();

  _m512d _mm512_zextpd256_pd512(
    _m256d arg0,
  ) {
    return __mm512_zextpd256_pd512(
      arg0,
    );
  }

  late final __mm512_zextpd256_pd512Ptr =
      _lookup<ffi.NativeFunction<_m512d Function(_m256d)>>(
          '_mm512_zextpd256_pd512');
  late final __mm512_zextpd256_pd512 =
      __mm512_zextpd256_pd512Ptr.asFunction<_m512d Function(_m256d)>();

  __m512 _mm512_zextps128_ps512(
    __m128 arg0,
  ) {
    return __mm512_zextps128_ps512(
      arg0,
    );
  }

  late final __mm512_zextps128_ps512Ptr =
      _lookup<ffi.NativeFunction<__m512 Function(__m128)>>(
          '_mm512_zextps128_ps512');
  late final __mm512_zextps128_ps512 =
      __mm512_zextps128_ps512Ptr.asFunction<__m512 Function(__m128)>();

  __m512 _mm512_zextps256_ps512(
    __m256 arg0,
  ) {
    return __mm512_zextps256_ps512(
      arg0,
    );
  }

  late final __mm512_zextps256_ps512Ptr =
      _lookup<ffi.NativeFunction<__m512 Function(__m256)>>(
          '_mm512_zextps256_ps512');
  late final __mm512_zextps256_ps512 =
      __mm512_zextps256_ps512Ptr.asFunction<__m512 Function(__m256)>();

  __m512i _mm512_zextsi128_si512(
    __m128i arg0,
  ) {
    return __mm512_zextsi128_si512(
      arg0,
    );
  }

  late final __mm512_zextsi128_si512Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m128i)>>(
          '_mm512_zextsi128_si512');
  late final __mm512_zextsi128_si512 =
      __mm512_zextsi128_si512Ptr.asFunction<__m512i Function(__m128i)>();

  __m512i _mm512_zextsi256_si512(
    __m256i arg0,
  ) {
    return __mm512_zextsi256_si512(
      arg0,
    );
  }

  late final __mm512_zextsi256_si512Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m256i)>>(
          '_mm512_zextsi256_si512');
  late final __mm512_zextsi256_si512 =
      __mm512_zextsi256_si512Ptr.asFunction<__m512i Function(__m256i)>();

  __m128i _mm_madd52hi_epu64(
    __m128i arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_madd52hi_epu64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_madd52hi_epu64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i, __m128i)>>(
          '_mm_madd52hi_epu64');
  late final __mm_madd52hi_epu64 = __mm_madd52hi_epu64Ptr
      .asFunction<__m128i Function(__m128i, __m128i, __m128i)>();

  __m128i _mm_mask_madd52hi_epu64(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_madd52hi_epu64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_madd52hi_epu64Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_madd52hi_epu64');
  late final __mm_mask_madd52hi_epu64 = __mm_mask_madd52hi_epu64Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_madd52hi_epu64(
    int arg0,
    __m128i arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_maskz_madd52hi_epu64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_madd52hi_epu64Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(__mmask8, __m128i, __m128i,
              __m128i)>>('_mm_maskz_madd52hi_epu64');
  late final __mm_maskz_madd52hi_epu64 = __mm_maskz_madd52hi_epu64Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i, __m128i)>();

  __m256i _mm256_madd52hi_epu64(
    __m256i arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_madd52hi_epu64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_madd52hi_epu64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i, __m256i)>>(
          '_mm256_madd52hi_epu64');
  late final __mm256_madd52hi_epu64 = __mm256_madd52hi_epu64Ptr
      .asFunction<__m256i Function(__m256i, __m256i, __m256i)>();

  __m256i _mm256_mask_madd52hi_epu64(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_madd52hi_epu64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_madd52hi_epu64Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask8, __m256i,
              __m256i)>>('_mm256_mask_madd52hi_epu64');
  late final __mm256_mask_madd52hi_epu64 = __mm256_mask_madd52hi_epu64Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_madd52hi_epu64(
    int arg0,
    __m256i arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_maskz_madd52hi_epu64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_maskz_madd52hi_epu64Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__mmask8, __m256i, __m256i,
              __m256i)>>('_mm256_maskz_madd52hi_epu64');
  late final __mm256_maskz_madd52hi_epu64 = __mm256_maskz_madd52hi_epu64Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i, __m256i)>();

  __m512i _mm512_madd52hi_epu64(
    __m512i arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_madd52hi_epu64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_madd52hi_epu64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i, __m512i)>>(
          '_mm512_madd52hi_epu64');
  late final __mm512_madd52hi_epu64 = __mm512_madd52hi_epu64Ptr
      .asFunction<__m512i Function(__m512i, __m512i, __m512i)>();

  __m512i _mm512_mask_madd52hi_epu64(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_madd52hi_epu64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_madd52hi_epu64Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask8, __m512i,
              __m512i)>>('_mm512_mask_madd52hi_epu64');
  late final __mm512_mask_madd52hi_epu64 = __mm512_mask_madd52hi_epu64Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_madd52hi_epu64(
    int arg0,
    __m512i arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_maskz_madd52hi_epu64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_madd52hi_epu64Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__mmask8, __m512i, __m512i,
              __m512i)>>('_mm512_maskz_madd52hi_epu64');
  late final __mm512_maskz_madd52hi_epu64 = __mm512_maskz_madd52hi_epu64Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i, __m512i)>();

  __m128i _mm_madd52lo_epu64(
    __m128i arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_madd52lo_epu64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_madd52lo_epu64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i, __m128i)>>(
          '_mm_madd52lo_epu64');
  late final __mm_madd52lo_epu64 = __mm_madd52lo_epu64Ptr
      .asFunction<__m128i Function(__m128i, __m128i, __m128i)>();

  __m128i _mm_mask_madd52lo_epu64(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_madd52lo_epu64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_madd52lo_epu64Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_madd52lo_epu64');
  late final __mm_mask_madd52lo_epu64 = __mm_mask_madd52lo_epu64Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_madd52lo_epu64(
    int arg0,
    __m128i arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_maskz_madd52lo_epu64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_madd52lo_epu64Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(__mmask8, __m128i, __m128i,
              __m128i)>>('_mm_maskz_madd52lo_epu64');
  late final __mm_maskz_madd52lo_epu64 = __mm_maskz_madd52lo_epu64Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i, __m128i)>();

  __m256i _mm256_madd52lo_epu64(
    __m256i arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_madd52lo_epu64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_madd52lo_epu64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i, __m256i)>>(
          '_mm256_madd52lo_epu64');
  late final __mm256_madd52lo_epu64 = __mm256_madd52lo_epu64Ptr
      .asFunction<__m256i Function(__m256i, __m256i, __m256i)>();

  __m256i _mm256_mask_madd52lo_epu64(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_madd52lo_epu64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_madd52lo_epu64Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask8, __m256i,
              __m256i)>>('_mm256_mask_madd52lo_epu64');
  late final __mm256_mask_madd52lo_epu64 = __mm256_mask_madd52lo_epu64Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_madd52lo_epu64(
    int arg0,
    __m256i arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_maskz_madd52lo_epu64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_maskz_madd52lo_epu64Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__mmask8, __m256i, __m256i,
              __m256i)>>('_mm256_maskz_madd52lo_epu64');
  late final __mm256_maskz_madd52lo_epu64 = __mm256_maskz_madd52lo_epu64Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i, __m256i)>();

  __m512i _mm512_madd52lo_epu64(
    __m512i arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_madd52lo_epu64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_madd52lo_epu64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i, __m512i)>>(
          '_mm512_madd52lo_epu64');
  late final __mm512_madd52lo_epu64 = __mm512_madd52lo_epu64Ptr
      .asFunction<__m512i Function(__m512i, __m512i, __m512i)>();

  __m512i _mm512_mask_madd52lo_epu64(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_madd52lo_epu64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_madd52lo_epu64Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask8, __m512i,
              __m512i)>>('_mm512_mask_madd52lo_epu64');
  late final __mm512_mask_madd52lo_epu64 = __mm512_mask_madd52lo_epu64Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_madd52lo_epu64(
    int arg0,
    __m512i arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_maskz_madd52lo_epu64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_madd52lo_epu64Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__mmask8, __m512i, __m512i,
              __m512i)>>('_mm512_maskz_madd52lo_epu64');
  late final __mm512_maskz_madd52lo_epu64 = __mm512_maskz_madd52lo_epu64Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i, __m512i)>();

  __m128i _mm_permutexvar_epi8(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_permutexvar_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm_permutexvar_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_permutexvar_epi8');
  late final __mm_permutexvar_epi8 =
      __mm_permutexvar_epi8Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_mask_permutexvar_epi8(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_permutexvar_epi8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_permutexvar_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(__m128i, __mmask16, __m128i,
              __m128i)>>('_mm_mask_permutexvar_epi8');
  late final __mm_mask_permutexvar_epi8 = __mm_mask_permutexvar_epi8Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_permutexvar_epi8(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_permutexvar_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_permutexvar_epi8Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__mmask16, __m128i, __m128i)>>(
      '_mm_maskz_permutexvar_epi8');
  late final __mm_maskz_permutexvar_epi8 = __mm_maskz_permutexvar_epi8Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_permutexvar_epi8(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_permutexvar_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm256_permutexvar_epi8Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_permutexvar_epi8');
  late final __mm256_permutexvar_epi8 = __mm256_permutexvar_epi8Ptr
      .asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_mask_permutexvar_epi8(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_permutexvar_epi8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_permutexvar_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask32, __m256i,
              __m256i)>>('_mm256_mask_permutexvar_epi8');
  late final __mm256_mask_permutexvar_epi8 = __mm256_mask_permutexvar_epi8Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_permutexvar_epi8(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_permutexvar_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_permutexvar_epi8Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__mmask32, __m256i, __m256i)>>(
      '_mm256_maskz_permutexvar_epi8');
  late final __mm256_maskz_permutexvar_epi8 = __mm256_maskz_permutexvar_epi8Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  __m512i _mm512_permutexvar_epi8(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_permutexvar_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm512_permutexvar_epi8Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_permutexvar_epi8');
  late final __mm512_permutexvar_epi8 = __mm512_permutexvar_epi8Ptr
      .asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_permutexvar_epi8(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_permutexvar_epi8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_permutexvar_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask64, __m512i,
              __m512i)>>('_mm512_mask_permutexvar_epi8');
  late final __mm512_mask_permutexvar_epi8 = __mm512_mask_permutexvar_epi8Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_permutexvar_epi8(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_permutexvar_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_permutexvar_epi8Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask64, __m512i, __m512i)>>(
      '_mm512_maskz_permutexvar_epi8');
  late final __mm512_maskz_permutexvar_epi8 = __mm512_maskz_permutexvar_epi8Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m128i _mm_permutex2var_epi8(
    __m128i arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_permutex2var_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_permutex2var_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i, __m128i)>>(
          '_mm_permutex2var_epi8');
  late final __mm_permutex2var_epi8 = __mm_permutex2var_epi8Ptr
      .asFunction<__m128i Function(__m128i, __m128i, __m128i)>();

  __m128i _mm_mask_permutex2var_epi8(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_permutex2var_epi8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_permutex2var_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(__m128i, __mmask16, __m128i,
              __m128i)>>('_mm_mask_permutex2var_epi8');
  late final __mm_mask_permutex2var_epi8 = __mm_mask_permutex2var_epi8Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_mask2_permutex2var_epi8(
    __m128i arg0,
    __m128i arg1,
    int arg2,
    __m128i arg3,
  ) {
    return __mm_mask2_permutex2var_epi8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask2_permutex2var_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(__m128i, __m128i, __mmask16,
              __m128i)>>('_mm_mask2_permutex2var_epi8');
  late final __mm_mask2_permutex2var_epi8 = __mm_mask2_permutex2var_epi8Ptr
      .asFunction<__m128i Function(__m128i, __m128i, int, __m128i)>();

  __m128i _mm_maskz_permutex2var_epi8(
    int arg0,
    __m128i arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_maskz_permutex2var_epi8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_permutex2var_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(__mmask16, __m128i, __m128i,
              __m128i)>>('_mm_maskz_permutex2var_epi8');
  late final __mm_maskz_permutex2var_epi8 = __mm_maskz_permutex2var_epi8Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i, __m128i)>();

  __m256i _mm256_permutex2var_epi8(
    __m256i arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_permutex2var_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_permutex2var_epi8Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i, __m256i)>>(
          '_mm256_permutex2var_epi8');
  late final __mm256_permutex2var_epi8 = __mm256_permutex2var_epi8Ptr
      .asFunction<__m256i Function(__m256i, __m256i, __m256i)>();

  __m256i _mm256_mask_permutex2var_epi8(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_permutex2var_epi8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_permutex2var_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask32, __m256i,
              __m256i)>>('_mm256_mask_permutex2var_epi8');
  late final __mm256_mask_permutex2var_epi8 = __mm256_mask_permutex2var_epi8Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_mask2_permutex2var_epi8(
    __m256i arg0,
    __m256i arg1,
    int arg2,
    __m256i arg3,
  ) {
    return __mm256_mask2_permutex2var_epi8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask2_permutex2var_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __m256i, __mmask32,
              __m256i)>>('_mm256_mask2_permutex2var_epi8');
  late final __mm256_mask2_permutex2var_epi8 =
      __mm256_mask2_permutex2var_epi8Ptr
          .asFunction<__m256i Function(__m256i, __m256i, int, __m256i)>();

  __m256i _mm256_maskz_permutex2var_epi8(
    int arg0,
    __m256i arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_maskz_permutex2var_epi8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_maskz_permutex2var_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__mmask32, __m256i, __m256i,
              __m256i)>>('_mm256_maskz_permutex2var_epi8');
  late final __mm256_maskz_permutex2var_epi8 =
      __mm256_maskz_permutex2var_epi8Ptr
          .asFunction<__m256i Function(int, __m256i, __m256i, __m256i)>();

  __m512i _mm512_permutex2var_epi8(
    __m512i arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_permutex2var_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_permutex2var_epi8Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i, __m512i)>>(
          '_mm512_permutex2var_epi8');
  late final __mm512_permutex2var_epi8 = __mm512_permutex2var_epi8Ptr
      .asFunction<__m512i Function(__m512i, __m512i, __m512i)>();

  __m512i _mm512_mask_permutex2var_epi8(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_permutex2var_epi8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_permutex2var_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask64, __m512i,
              __m512i)>>('_mm512_mask_permutex2var_epi8');
  late final __mm512_mask_permutex2var_epi8 = __mm512_mask_permutex2var_epi8Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_mask2_permutex2var_epi8(
    __m512i arg0,
    __m512i arg1,
    int arg2,
    __m512i arg3,
  ) {
    return __mm512_mask2_permutex2var_epi8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask2_permutex2var_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __m512i, __mmask64,
              __m512i)>>('_mm512_mask2_permutex2var_epi8');
  late final __mm512_mask2_permutex2var_epi8 =
      __mm512_mask2_permutex2var_epi8Ptr
          .asFunction<__m512i Function(__m512i, __m512i, int, __m512i)>();

  __m512i _mm512_maskz_permutex2var_epi8(
    int arg0,
    __m512i arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_maskz_permutex2var_epi8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_permutex2var_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__mmask64, __m512i, __m512i,
              __m512i)>>('_mm512_maskz_permutex2var_epi8');
  late final __mm512_maskz_permutex2var_epi8 =
      __mm512_maskz_permutex2var_epi8Ptr
          .asFunction<__m512i Function(int, __m512i, __m512i, __m512i)>();

  __m128i _mm_multishift_epi64_epi8(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_multishift_epi64_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm_multishift_epi64_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_multishift_epi64_epi8');
  late final __mm_multishift_epi64_epi8 = __mm_multishift_epi64_epi8Ptr
      .asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_mask_multishift_epi64_epi8(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_multishift_epi64_epi8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_multishift_epi64_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(__m128i, __mmask16, __m128i,
              __m128i)>>('_mm_mask_multishift_epi64_epi8');
  late final __mm_mask_multishift_epi64_epi8 =
      __mm_mask_multishift_epi64_epi8Ptr
          .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_multishift_epi64_epi8(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_multishift_epi64_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_multishift_epi64_epi8Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__mmask16, __m128i, __m128i)>>(
      '_mm_maskz_multishift_epi64_epi8');
  late final __mm_maskz_multishift_epi64_epi8 =
      __mm_maskz_multishift_epi64_epi8Ptr
          .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_multishift_epi64_epi8(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_multishift_epi64_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm256_multishift_epi64_epi8Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_multishift_epi64_epi8');
  late final __mm256_multishift_epi64_epi8 = __mm256_multishift_epi64_epi8Ptr
      .asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_mask_multishift_epi64_epi8(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_multishift_epi64_epi8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_multishift_epi64_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask32, __m256i,
              __m256i)>>('_mm256_mask_multishift_epi64_epi8');
  late final __mm256_mask_multishift_epi64_epi8 =
      __mm256_mask_multishift_epi64_epi8Ptr
          .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_multishift_epi64_epi8(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_multishift_epi64_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_multishift_epi64_epi8Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__mmask32, __m256i, __m256i)>>(
      '_mm256_maskz_multishift_epi64_epi8');
  late final __mm256_maskz_multishift_epi64_epi8 =
      __mm256_maskz_multishift_epi64_epi8Ptr
          .asFunction<__m256i Function(int, __m256i, __m256i)>();

  __m512i _mm512_multishift_epi64_epi8(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_multishift_epi64_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm512_multishift_epi64_epi8Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_multishift_epi64_epi8');
  late final __mm512_multishift_epi64_epi8 = __mm512_multishift_epi64_epi8Ptr
      .asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_multishift_epi64_epi8(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_multishift_epi64_epi8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_multishift_epi64_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask64, __m512i,
              __m512i)>>('_mm512_mask_multishift_epi64_epi8');
  late final __mm512_mask_multishift_epi64_epi8 =
      __mm512_mask_multishift_epi64_epi8Ptr
          .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_multishift_epi64_epi8(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_multishift_epi64_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_multishift_epi64_epi8Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask64, __m512i, __m512i)>>(
      '_mm512_maskz_multishift_epi64_epi8');
  late final __mm512_maskz_multishift_epi64_epi8 =
      __mm512_maskz_multishift_epi64_epi8Ptr
          .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m128i _mm_dpbusd_epi32(
    __m128i arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_dpbusd_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_dpbusd_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i, __m128i)>>(
          '_mm_dpbusd_epi32');
  late final __mm_dpbusd_epi32 = __mm_dpbusd_epi32Ptr
      .asFunction<__m128i Function(__m128i, __m128i, __m128i)>();

  __m128i _mm_mask_dpbusd_epi32(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_dpbusd_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_dpbusd_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_dpbusd_epi32');
  late final __mm_mask_dpbusd_epi32 = __mm_mask_dpbusd_epi32Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_dpbusd_epi32(
    int arg0,
    __m128i arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_maskz_dpbusd_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_dpbusd_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __mmask8, __m128i, __m128i, __m128i)>>('_mm_maskz_dpbusd_epi32');
  late final __mm_maskz_dpbusd_epi32 = __mm_maskz_dpbusd_epi32Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i, __m128i)>();

  __m256i _mm256_dpbusd_epi32(
    __m256i arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_dpbusd_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_dpbusd_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i, __m256i)>>(
          '_mm256_dpbusd_epi32');
  late final __mm256_dpbusd_epi32 = __mm256_dpbusd_epi32Ptr
      .asFunction<__m256i Function(__m256i, __m256i, __m256i)>();

  __m256i _mm256_mask_dpbusd_epi32(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_dpbusd_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_dpbusd_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask8, __m256i,
              __m256i)>>('_mm256_mask_dpbusd_epi32');
  late final __mm256_mask_dpbusd_epi32 = __mm256_mask_dpbusd_epi32Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_dpbusd_epi32(
    int arg0,
    __m256i arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_maskz_dpbusd_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_maskz_dpbusd_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__mmask8, __m256i, __m256i,
              __m256i)>>('_mm256_maskz_dpbusd_epi32');
  late final __mm256_maskz_dpbusd_epi32 = __mm256_maskz_dpbusd_epi32Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i, __m256i)>();

  __m512i _mm512_dpbusd_epi32(
    __m512i arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_dpbusd_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_dpbusd_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i, __m512i)>>(
          '_mm512_dpbusd_epi32');
  late final __mm512_dpbusd_epi32 = __mm512_dpbusd_epi32Ptr
      .asFunction<__m512i Function(__m512i, __m512i, __m512i)>();

  __m512i _mm512_mask_dpbusd_epi32(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_dpbusd_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_dpbusd_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask16, __m512i,
              __m512i)>>('_mm512_mask_dpbusd_epi32');
  late final __mm512_mask_dpbusd_epi32 = __mm512_mask_dpbusd_epi32Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_dpbusd_epi32(
    int arg0,
    __m512i arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_maskz_dpbusd_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_dpbusd_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__mmask16, __m512i, __m512i,
              __m512i)>>('_mm512_maskz_dpbusd_epi32');
  late final __mm512_maskz_dpbusd_epi32 = __mm512_maskz_dpbusd_epi32Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i, __m512i)>();

  __m128i _mm_dpbusds_epi32(
    __m128i arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_dpbusds_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_dpbusds_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i, __m128i)>>(
          '_mm_dpbusds_epi32');
  late final __mm_dpbusds_epi32 = __mm_dpbusds_epi32Ptr
      .asFunction<__m128i Function(__m128i, __m128i, __m128i)>();

  __m128i _mm_mask_dpbusds_epi32(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_dpbusds_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_dpbusds_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_dpbusds_epi32');
  late final __mm_mask_dpbusds_epi32 = __mm_mask_dpbusds_epi32Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_dpbusds_epi32(
    int arg0,
    __m128i arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_maskz_dpbusds_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_dpbusds_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __mmask8, __m128i, __m128i, __m128i)>>('_mm_maskz_dpbusds_epi32');
  late final __mm_maskz_dpbusds_epi32 = __mm_maskz_dpbusds_epi32Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i, __m128i)>();

  __m256i _mm256_dpbusds_epi32(
    __m256i arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_dpbusds_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_dpbusds_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i, __m256i)>>(
          '_mm256_dpbusds_epi32');
  late final __mm256_dpbusds_epi32 = __mm256_dpbusds_epi32Ptr
      .asFunction<__m256i Function(__m256i, __m256i, __m256i)>();

  __m256i _mm256_mask_dpbusds_epi32(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_dpbusds_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_dpbusds_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask8, __m256i,
              __m256i)>>('_mm256_mask_dpbusds_epi32');
  late final __mm256_mask_dpbusds_epi32 = __mm256_mask_dpbusds_epi32Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_dpbusds_epi32(
    int arg0,
    __m256i arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_maskz_dpbusds_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_maskz_dpbusds_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__mmask8, __m256i, __m256i,
              __m256i)>>('_mm256_maskz_dpbusds_epi32');
  late final __mm256_maskz_dpbusds_epi32 = __mm256_maskz_dpbusds_epi32Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i, __m256i)>();

  __m512i _mm512_dpbusds_epi32(
    __m512i arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_dpbusds_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_dpbusds_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i, __m512i)>>(
          '_mm512_dpbusds_epi32');
  late final __mm512_dpbusds_epi32 = __mm512_dpbusds_epi32Ptr
      .asFunction<__m512i Function(__m512i, __m512i, __m512i)>();

  __m512i _mm512_mask_dpbusds_epi32(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_dpbusds_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_dpbusds_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask16, __m512i,
              __m512i)>>('_mm512_mask_dpbusds_epi32');
  late final __mm512_mask_dpbusds_epi32 = __mm512_mask_dpbusds_epi32Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_dpbusds_epi32(
    int arg0,
    __m512i arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_maskz_dpbusds_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_dpbusds_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__mmask16, __m512i, __m512i,
              __m512i)>>('_mm512_maskz_dpbusds_epi32');
  late final __mm512_maskz_dpbusds_epi32 = __mm512_maskz_dpbusds_epi32Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i, __m512i)>();

  __m128i _mm_dpwssd_epi32(
    __m128i arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_dpwssd_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_dpwssd_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i, __m128i)>>(
          '_mm_dpwssd_epi32');
  late final __mm_dpwssd_epi32 = __mm_dpwssd_epi32Ptr
      .asFunction<__m128i Function(__m128i, __m128i, __m128i)>();

  __m128i _mm_mask_dpwssd_epi32(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_dpwssd_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_dpwssd_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_dpwssd_epi32');
  late final __mm_mask_dpwssd_epi32 = __mm_mask_dpwssd_epi32Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_dpwssd_epi32(
    int arg0,
    __m128i arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_maskz_dpwssd_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_dpwssd_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __mmask8, __m128i, __m128i, __m128i)>>('_mm_maskz_dpwssd_epi32');
  late final __mm_maskz_dpwssd_epi32 = __mm_maskz_dpwssd_epi32Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i, __m128i)>();

  __m256i _mm256_dpwssd_epi32(
    __m256i arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_dpwssd_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_dpwssd_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i, __m256i)>>(
          '_mm256_dpwssd_epi32');
  late final __mm256_dpwssd_epi32 = __mm256_dpwssd_epi32Ptr
      .asFunction<__m256i Function(__m256i, __m256i, __m256i)>();

  __m256i _mm256_mask_dpwssd_epi32(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_dpwssd_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_dpwssd_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask8, __m256i,
              __m256i)>>('_mm256_mask_dpwssd_epi32');
  late final __mm256_mask_dpwssd_epi32 = __mm256_mask_dpwssd_epi32Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_dpwssd_epi32(
    int arg0,
    __m256i arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_maskz_dpwssd_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_maskz_dpwssd_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__mmask8, __m256i, __m256i,
              __m256i)>>('_mm256_maskz_dpwssd_epi32');
  late final __mm256_maskz_dpwssd_epi32 = __mm256_maskz_dpwssd_epi32Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i, __m256i)>();

  __m512i _mm512_dpwssd_epi32(
    __m512i arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_dpwssd_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_dpwssd_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i, __m512i)>>(
          '_mm512_dpwssd_epi32');
  late final __mm512_dpwssd_epi32 = __mm512_dpwssd_epi32Ptr
      .asFunction<__m512i Function(__m512i, __m512i, __m512i)>();

  __m512i _mm512_mask_dpwssd_epi32(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_dpwssd_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_dpwssd_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask16, __m512i,
              __m512i)>>('_mm512_mask_dpwssd_epi32');
  late final __mm512_mask_dpwssd_epi32 = __mm512_mask_dpwssd_epi32Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_dpwssd_epi32(
    int arg0,
    __m512i arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_maskz_dpwssd_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_dpwssd_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__mmask16, __m512i, __m512i,
              __m512i)>>('_mm512_maskz_dpwssd_epi32');
  late final __mm512_maskz_dpwssd_epi32 = __mm512_maskz_dpwssd_epi32Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i, __m512i)>();

  __m128i _mm_dpwssds_epi32(
    __m128i arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_dpwssds_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_dpwssds_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i, __m128i)>>(
          '_mm_dpwssds_epi32');
  late final __mm_dpwssds_epi32 = __mm_dpwssds_epi32Ptr
      .asFunction<__m128i Function(__m128i, __m128i, __m128i)>();

  __m128i _mm_mask_dpwssds_epi32(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_dpwssds_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_dpwssds_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_dpwssds_epi32');
  late final __mm_mask_dpwssds_epi32 = __mm_mask_dpwssds_epi32Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_dpwssds_epi32(
    int arg0,
    __m128i arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_maskz_dpwssds_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_dpwssds_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __mmask8, __m128i, __m128i, __m128i)>>('_mm_maskz_dpwssds_epi32');
  late final __mm_maskz_dpwssds_epi32 = __mm_maskz_dpwssds_epi32Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i, __m128i)>();

  __m256i _mm256_dpwssds_epi32(
    __m256i arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_dpwssds_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_dpwssds_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i, __m256i)>>(
          '_mm256_dpwssds_epi32');
  late final __mm256_dpwssds_epi32 = __mm256_dpwssds_epi32Ptr
      .asFunction<__m256i Function(__m256i, __m256i, __m256i)>();

  __m256i _mm256_mask_dpwssds_epi32(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_dpwssds_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_dpwssds_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask8, __m256i,
              __m256i)>>('_mm256_mask_dpwssds_epi32');
  late final __mm256_mask_dpwssds_epi32 = __mm256_mask_dpwssds_epi32Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_dpwssds_epi32(
    int arg0,
    __m256i arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_maskz_dpwssds_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_maskz_dpwssds_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__mmask8, __m256i, __m256i,
              __m256i)>>('_mm256_maskz_dpwssds_epi32');
  late final __mm256_maskz_dpwssds_epi32 = __mm256_maskz_dpwssds_epi32Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i, __m256i)>();

  __m512i _mm512_dpwssds_epi32(
    __m512i arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_dpwssds_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_dpwssds_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i, __m512i)>>(
          '_mm512_dpwssds_epi32');
  late final __mm512_dpwssds_epi32 = __mm512_dpwssds_epi32Ptr
      .asFunction<__m512i Function(__m512i, __m512i, __m512i)>();

  __m512i _mm512_mask_dpwssds_epi32(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_dpwssds_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_dpwssds_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask16, __m512i,
              __m512i)>>('_mm512_mask_dpwssds_epi32');
  late final __mm512_mask_dpwssds_epi32 = __mm512_mask_dpwssds_epi32Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_dpwssds_epi32(
    int arg0,
    __m512i arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_maskz_dpwssds_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_dpwssds_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__mmask16, __m512i, __m512i,
              __m512i)>>('_mm512_maskz_dpwssds_epi32');
  late final __mm512_maskz_dpwssds_epi32 = __mm512_maskz_dpwssds_epi32Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i, __m512i)>();

  __m256i _mm256_aesenc_epi128(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_aesenc_epi128(
      arg0,
      arg1,
    );
  }

  late final __mm256_aesenc_epi128Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_aesenc_epi128');
  late final __mm256_aesenc_epi128 =
      __mm256_aesenc_epi128Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m512i _mm512_aesenc_epi128(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_aesenc_epi128(
      arg0,
      arg1,
    );
  }

  late final __mm512_aesenc_epi128Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_aesenc_epi128');
  late final __mm512_aesenc_epi128 =
      __mm512_aesenc_epi128Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m256i _mm256_aesenclast_epi128(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_aesenclast_epi128(
      arg0,
      arg1,
    );
  }

  late final __mm256_aesenclast_epi128Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_aesenclast_epi128');
  late final __mm256_aesenclast_epi128 = __mm256_aesenclast_epi128Ptr
      .asFunction<__m256i Function(__m256i, __m256i)>();

  __m512i _mm512_aesenclast_epi128(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_aesenclast_epi128(
      arg0,
      arg1,
    );
  }

  late final __mm512_aesenclast_epi128Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_aesenclast_epi128');
  late final __mm512_aesenclast_epi128 = __mm512_aesenclast_epi128Ptr
      .asFunction<__m512i Function(__m512i, __m512i)>();

  __m256i _mm256_aesdec_epi128(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_aesdec_epi128(
      arg0,
      arg1,
    );
  }

  late final __mm256_aesdec_epi128Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_aesdec_epi128');
  late final __mm256_aesdec_epi128 =
      __mm256_aesdec_epi128Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m512i _mm512_aesdec_epi128(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_aesdec_epi128(
      arg0,
      arg1,
    );
  }

  late final __mm512_aesdec_epi128Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_aesdec_epi128');
  late final __mm512_aesdec_epi128 =
      __mm512_aesdec_epi128Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m256i _mm256_aesdeclast_epi128(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_aesdeclast_epi128(
      arg0,
      arg1,
    );
  }

  late final __mm256_aesdeclast_epi128Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_aesdeclast_epi128');
  late final __mm256_aesdeclast_epi128 = __mm256_aesdeclast_epi128Ptr
      .asFunction<__m256i Function(__m256i, __m256i)>();

  __m512i _mm512_aesdeclast_epi128(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_aesdeclast_epi128(
      arg0,
      arg1,
    );
  }

  late final __mm512_aesdeclast_epi128Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_aesdeclast_epi128');
  late final __mm512_aesdeclast_epi128 = __mm512_aesdeclast_epi128Ptr
      .asFunction<__m512i Function(__m512i, __m512i)>();

  __m256i _mm256_clmulepi64_epi128(
    __m256i arg0,
    __m256i arg1,
    int arg2,
  ) {
    return __mm256_clmulepi64_epi128(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_clmulepi64_epi128Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__m256i, __m256i, ffi.Int32)>>(
      '_mm256_clmulepi64_epi128');
  late final __mm256_clmulepi64_epi128 = __mm256_clmulepi64_epi128Ptr
      .asFunction<__m256i Function(__m256i, __m256i, int)>();

  __m512i _mm512_clmulepi64_epi128(
    __m512i arg0,
    __m512i arg1,
    int arg2,
  ) {
    return __mm512_clmulepi64_epi128(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_clmulepi64_epi128Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__m512i, __m512i, ffi.Int32)>>(
      '_mm512_clmulepi64_epi128');
  late final __mm512_clmulepi64_epi128 = __mm512_clmulepi64_epi128Ptr
      .asFunction<__m512i Function(__m512i, __m512i, int)>();

  __m128i _mm_popcnt_epi32(
    __m128i arg0,
  ) {
    return __mm_popcnt_epi32(
      arg0,
    );
  }

  late final __mm_popcnt_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i)>>(
          '_mm_popcnt_epi32');
  late final __mm_popcnt_epi32 =
      __mm_popcnt_epi32Ptr.asFunction<__m128i Function(__m128i)>();

  __m128i _mm_mask_popcnt_epi32(
    __m128i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_popcnt_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_popcnt_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m128i)>>(
          '_mm_mask_popcnt_epi32');
  late final __mm_mask_popcnt_epi32 = __mm_mask_popcnt_epi32Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i)>();

  __m128i _mm_maskz_popcnt_epi32(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_popcnt_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_popcnt_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i)>>(
          '_mm_maskz_popcnt_epi32');
  late final __mm_maskz_popcnt_epi32 =
      __mm_maskz_popcnt_epi32Ptr.asFunction<__m128i Function(int, __m128i)>();

  __m256i _mm256_popcnt_epi32(
    __m256i arg0,
  ) {
    return __mm256_popcnt_epi32(
      arg0,
    );
  }

  late final __mm256_popcnt_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i)>>(
          '_mm256_popcnt_epi32');
  late final __mm256_popcnt_epi32 =
      __mm256_popcnt_epi32Ptr.asFunction<__m256i Function(__m256i)>();

  __m256i _mm256_mask_popcnt_epi32(
    __m256i arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_popcnt_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_popcnt_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __mmask8, __m256i)>>(
          '_mm256_mask_popcnt_epi32');
  late final __mm256_mask_popcnt_epi32 = __mm256_mask_popcnt_epi32Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i)>();

  __m256i _mm256_maskz_popcnt_epi32(
    int arg0,
    __m256i arg1,
  ) {
    return __mm256_maskz_popcnt_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_popcnt_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m256i)>>(
          '_mm256_maskz_popcnt_epi32');
  late final __mm256_maskz_popcnt_epi32 = __mm256_maskz_popcnt_epi32Ptr
      .asFunction<__m256i Function(int, __m256i)>();

  __m512i _mm512_popcnt_epi32(
    __m512i arg0,
  ) {
    return __mm512_popcnt_epi32(
      arg0,
    );
  }

  late final __mm512_popcnt_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i)>>(
          '_mm512_popcnt_epi32');
  late final __mm512_popcnt_epi32 =
      __mm512_popcnt_epi32Ptr.asFunction<__m512i Function(__m512i)>();

  __m512i _mm512_mask_popcnt_epi32(
    __m512i arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_popcnt_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_popcnt_epi32Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__m512i, __mmask16, __m512i)>>(
      '_mm512_mask_popcnt_epi32');
  late final __mm512_mask_popcnt_epi32 = __mm512_mask_popcnt_epi32Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i)>();

  __m512i _mm512_maskz_popcnt_epi32(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_maskz_popcnt_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_popcnt_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask16, __m512i)>>(
          '_mm512_maskz_popcnt_epi32');
  late final __mm512_maskz_popcnt_epi32 = __mm512_maskz_popcnt_epi32Ptr
      .asFunction<__m512i Function(int, __m512i)>();

  __m128i _mm_popcnt_epi64(
    __m128i arg0,
  ) {
    return __mm_popcnt_epi64(
      arg0,
    );
  }

  late final __mm_popcnt_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i)>>(
          '_mm_popcnt_epi64');
  late final __mm_popcnt_epi64 =
      __mm_popcnt_epi64Ptr.asFunction<__m128i Function(__m128i)>();

  __m128i _mm_mask_popcnt_epi64(
    __m128i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_popcnt_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_popcnt_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m128i)>>(
          '_mm_mask_popcnt_epi64');
  late final __mm_mask_popcnt_epi64 = __mm_mask_popcnt_epi64Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i)>();

  __m128i _mm_maskz_popcnt_epi64(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_popcnt_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_popcnt_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i)>>(
          '_mm_maskz_popcnt_epi64');
  late final __mm_maskz_popcnt_epi64 =
      __mm_maskz_popcnt_epi64Ptr.asFunction<__m128i Function(int, __m128i)>();

  __m256i _mm256_popcnt_epi64(
    __m256i arg0,
  ) {
    return __mm256_popcnt_epi64(
      arg0,
    );
  }

  late final __mm256_popcnt_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i)>>(
          '_mm256_popcnt_epi64');
  late final __mm256_popcnt_epi64 =
      __mm256_popcnt_epi64Ptr.asFunction<__m256i Function(__m256i)>();

  __m256i _mm256_mask_popcnt_epi64(
    __m256i arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_popcnt_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_popcnt_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __mmask8, __m256i)>>(
          '_mm256_mask_popcnt_epi64');
  late final __mm256_mask_popcnt_epi64 = __mm256_mask_popcnt_epi64Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i)>();

  __m256i _mm256_maskz_popcnt_epi64(
    int arg0,
    __m256i arg1,
  ) {
    return __mm256_maskz_popcnt_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_popcnt_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m256i)>>(
          '_mm256_maskz_popcnt_epi64');
  late final __mm256_maskz_popcnt_epi64 = __mm256_maskz_popcnt_epi64Ptr
      .asFunction<__m256i Function(int, __m256i)>();

  __m512i _mm512_popcnt_epi64(
    __m512i arg0,
  ) {
    return __mm512_popcnt_epi64(
      arg0,
    );
  }

  late final __mm512_popcnt_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i)>>(
          '_mm512_popcnt_epi64');
  late final __mm512_popcnt_epi64 =
      __mm512_popcnt_epi64Ptr.asFunction<__m512i Function(__m512i)>();

  __m512i _mm512_mask_popcnt_epi64(
    __m512i arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_popcnt_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_popcnt_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __mmask8, __m512i)>>(
          '_mm512_mask_popcnt_epi64');
  late final __mm512_mask_popcnt_epi64 = __mm512_mask_popcnt_epi64Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i)>();

  __m512i _mm512_maskz_popcnt_epi64(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_maskz_popcnt_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_popcnt_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask8, __m512i)>>(
          '_mm512_maskz_popcnt_epi64');
  late final __mm512_maskz_popcnt_epi64 = __mm512_maskz_popcnt_epi64Ptr
      .asFunction<__m512i Function(int, __m512i)>();

  __m128i _mm_popcnt_epi8(
    __m128i arg0,
  ) {
    return __mm_popcnt_epi8(
      arg0,
    );
  }

  late final __mm_popcnt_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i)>>('_mm_popcnt_epi8');
  late final __mm_popcnt_epi8 =
      __mm_popcnt_epi8Ptr.asFunction<__m128i Function(__m128i)>();

  __m128i _mm_mask_popcnt_epi8(
    __m128i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_popcnt_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_popcnt_epi8Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__m128i, __mmask16, __m128i)>>(
      '_mm_mask_popcnt_epi8');
  late final __mm_mask_popcnt_epi8 = __mm_mask_popcnt_epi8Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i)>();

  __m128i _mm_maskz_popcnt_epi8(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_popcnt_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_popcnt_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask16, __m128i)>>(
          '_mm_maskz_popcnt_epi8');
  late final __mm_maskz_popcnt_epi8 =
      __mm_maskz_popcnt_epi8Ptr.asFunction<__m128i Function(int, __m128i)>();

  __m256i _mm256_popcnt_epi8(
    __m256i arg0,
  ) {
    return __mm256_popcnt_epi8(
      arg0,
    );
  }

  late final __mm256_popcnt_epi8Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i)>>(
          '_mm256_popcnt_epi8');
  late final __mm256_popcnt_epi8 =
      __mm256_popcnt_epi8Ptr.asFunction<__m256i Function(__m256i)>();

  __m256i _mm256_mask_popcnt_epi8(
    __m256i arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_popcnt_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_popcnt_epi8Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__m256i, __mmask32, __m256i)>>(
      '_mm256_mask_popcnt_epi8');
  late final __mm256_mask_popcnt_epi8 = __mm256_mask_popcnt_epi8Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i)>();

  __m256i _mm256_maskz_popcnt_epi8(
    int arg0,
    __m256i arg1,
  ) {
    return __mm256_maskz_popcnt_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_popcnt_epi8Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask32, __m256i)>>(
          '_mm256_maskz_popcnt_epi8');
  late final __mm256_maskz_popcnt_epi8 =
      __mm256_maskz_popcnt_epi8Ptr.asFunction<__m256i Function(int, __m256i)>();

  __m512i _mm512_popcnt_epi8(
    __m512i arg0,
  ) {
    return __mm512_popcnt_epi8(
      arg0,
    );
  }

  late final __mm512_popcnt_epi8Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i)>>(
          '_mm512_popcnt_epi8');
  late final __mm512_popcnt_epi8 =
      __mm512_popcnt_epi8Ptr.asFunction<__m512i Function(__m512i)>();

  __m512i _mm512_mask_popcnt_epi8(
    __m512i arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_popcnt_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_popcnt_epi8Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__m512i, __mmask64, __m512i)>>(
      '_mm512_mask_popcnt_epi8');
  late final __mm512_mask_popcnt_epi8 = __mm512_mask_popcnt_epi8Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i)>();

  __m512i _mm512_maskz_popcnt_epi8(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_maskz_popcnt_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_popcnt_epi8Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask64, __m512i)>>(
          '_mm512_maskz_popcnt_epi8');
  late final __mm512_maskz_popcnt_epi8 =
      __mm512_maskz_popcnt_epi8Ptr.asFunction<__m512i Function(int, __m512i)>();

  __m128i _mm_popcnt_epi16(
    __m128i arg0,
  ) {
    return __mm_popcnt_epi16(
      arg0,
    );
  }

  late final __mm_popcnt_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i)>>(
          '_mm_popcnt_epi16');
  late final __mm_popcnt_epi16 =
      __mm_popcnt_epi16Ptr.asFunction<__m128i Function(__m128i)>();

  __m128i _mm_mask_popcnt_epi16(
    __m128i arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_popcnt_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_popcnt_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m128i)>>(
          '_mm_mask_popcnt_epi16');
  late final __mm_mask_popcnt_epi16 = __mm_mask_popcnt_epi16Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i)>();

  __m128i _mm_maskz_popcnt_epi16(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_popcnt_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_popcnt_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128i)>>(
          '_mm_maskz_popcnt_epi16');
  late final __mm_maskz_popcnt_epi16 =
      __mm_maskz_popcnt_epi16Ptr.asFunction<__m128i Function(int, __m128i)>();

  __m256i _mm256_popcnt_epi16(
    __m256i arg0,
  ) {
    return __mm256_popcnt_epi16(
      arg0,
    );
  }

  late final __mm256_popcnt_epi16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i)>>(
          '_mm256_popcnt_epi16');
  late final __mm256_popcnt_epi16 =
      __mm256_popcnt_epi16Ptr.asFunction<__m256i Function(__m256i)>();

  __m256i _mm256_mask_popcnt_epi16(
    __m256i arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_popcnt_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_popcnt_epi16Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__m256i, __mmask16, __m256i)>>(
      '_mm256_mask_popcnt_epi16');
  late final __mm256_mask_popcnt_epi16 = __mm256_mask_popcnt_epi16Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i)>();

  __m256i _mm256_maskz_popcnt_epi16(
    int arg0,
    __m256i arg1,
  ) {
    return __mm256_maskz_popcnt_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_popcnt_epi16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask16, __m256i)>>(
          '_mm256_maskz_popcnt_epi16');
  late final __mm256_maskz_popcnt_epi16 = __mm256_maskz_popcnt_epi16Ptr
      .asFunction<__m256i Function(int, __m256i)>();

  __m512i _mm512_popcnt_epi16(
    __m512i arg0,
  ) {
    return __mm512_popcnt_epi16(
      arg0,
    );
  }

  late final __mm512_popcnt_epi16Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i)>>(
          '_mm512_popcnt_epi16');
  late final __mm512_popcnt_epi16 =
      __mm512_popcnt_epi16Ptr.asFunction<__m512i Function(__m512i)>();

  __m512i _mm512_mask_popcnt_epi16(
    __m512i arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_popcnt_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_popcnt_epi16Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__m512i, __mmask32, __m512i)>>(
      '_mm512_mask_popcnt_epi16');
  late final __mm512_mask_popcnt_epi16 = __mm512_mask_popcnt_epi16Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i)>();

  __m512i _mm512_maskz_popcnt_epi16(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_maskz_popcnt_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_popcnt_epi16Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask32, __m512i)>>(
          '_mm512_maskz_popcnt_epi16');
  late final __mm512_maskz_popcnt_epi16 = __mm512_maskz_popcnt_epi16Ptr
      .asFunction<__m512i Function(int, __m512i)>();

  int _mm_bitshuffle_epi64_mask(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_bitshuffle_epi64_mask(
      arg0,
      arg1,
    );
  }

  late final __mm_bitshuffle_epi64_maskPtr =
      _lookup<ffi.NativeFunction<__mmask16 Function(__m128i, __m128i)>>(
          '_mm_bitshuffle_epi64_mask');
  late final __mm_bitshuffle_epi64_mask = __mm_bitshuffle_epi64_maskPtr
      .asFunction<int Function(__m128i, __m128i)>();

  int _mm_mask_bitshuffle_epi64_mask(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_mask_bitshuffle_epi64_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_bitshuffle_epi64_maskPtr = _lookup<
          ffi.NativeFunction<__mmask16 Function(__mmask16, __m128i, __m128i)>>(
      '_mm_mask_bitshuffle_epi64_mask');
  late final __mm_mask_bitshuffle_epi64_mask =
      __mm_mask_bitshuffle_epi64_maskPtr
          .asFunction<int Function(int, __m128i, __m128i)>();

  int _mm256_bitshuffle_epi64_mask(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_bitshuffle_epi64_mask(
      arg0,
      arg1,
    );
  }

  late final __mm256_bitshuffle_epi64_maskPtr =
      _lookup<ffi.NativeFunction<__mmask32 Function(__m256i, __m256i)>>(
          '_mm256_bitshuffle_epi64_mask');
  late final __mm256_bitshuffle_epi64_mask = __mm256_bitshuffle_epi64_maskPtr
      .asFunction<int Function(__m256i, __m256i)>();

  int _mm256_mask_bitshuffle_epi64_mask(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_bitshuffle_epi64_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_bitshuffle_epi64_maskPtr = _lookup<
          ffi.NativeFunction<__mmask32 Function(__mmask32, __m256i, __m256i)>>(
      '_mm256_mask_bitshuffle_epi64_mask');
  late final __mm256_mask_bitshuffle_epi64_mask =
      __mm256_mask_bitshuffle_epi64_maskPtr
          .asFunction<int Function(int, __m256i, __m256i)>();

  int _mm512_bitshuffle_epi64_mask(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_bitshuffle_epi64_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_bitshuffle_epi64_maskPtr =
      _lookup<ffi.NativeFunction<__mmask64 Function(__m512i, __m512i)>>(
          '_mm512_bitshuffle_epi64_mask');
  late final __mm512_bitshuffle_epi64_mask = __mm512_bitshuffle_epi64_maskPtr
      .asFunction<int Function(__m512i, __m512i)>();

  int _mm512_mask_bitshuffle_epi64_mask(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_bitshuffle_epi64_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_bitshuffle_epi64_maskPtr = _lookup<
          ffi.NativeFunction<__mmask64 Function(__mmask64, __m512i, __m512i)>>(
      '_mm512_mask_bitshuffle_epi64_mask');
  late final __mm512_mask_bitshuffle_epi64_mask =
      __mm512_mask_bitshuffle_epi64_maskPtr
          .asFunction<int Function(int, __m512i, __m512i)>();

  __m128i _mm_gf2p8affineinv_epi64_epi8(
    __m128i arg0,
    __m128i arg1,
    int arg2,
  ) {
    return __mm_gf2p8affineinv_epi64_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_gf2p8affineinv_epi64_epi8Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__m128i, __m128i, ffi.Int32)>>(
      '_mm_gf2p8affineinv_epi64_epi8');
  late final __mm_gf2p8affineinv_epi64_epi8 = __mm_gf2p8affineinv_epi64_epi8Ptr
      .asFunction<__m128i Function(__m128i, __m128i, int)>();

  __m128i _mm_mask_gf2p8affineinv_epi64_epi8(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
    int arg4,
  ) {
    return __mm_mask_gf2p8affineinv_epi64_epi8(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_gf2p8affineinv_epi64_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(__m128i, __mmask16, __m128i, __m128i,
              ffi.Int32)>>('_mm_mask_gf2p8affineinv_epi64_epi8');
  late final __mm_mask_gf2p8affineinv_epi64_epi8 =
      __mm_mask_gf2p8affineinv_epi64_epi8Ptr
          .asFunction<__m128i Function(__m128i, int, __m128i, __m128i, int)>();

  __m128i _mm_maskz_gf2p8affineinv_epi64_epi8(
    int arg0,
    __m128i arg1,
    __m128i arg2,
    int arg3,
  ) {
    return __mm_maskz_gf2p8affineinv_epi64_epi8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_gf2p8affineinv_epi64_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(__mmask16, __m128i, __m128i,
              ffi.Int32)>>('_mm_maskz_gf2p8affineinv_epi64_epi8');
  late final __mm_maskz_gf2p8affineinv_epi64_epi8 =
      __mm_maskz_gf2p8affineinv_epi64_epi8Ptr
          .asFunction<__m128i Function(int, __m128i, __m128i, int)>();

  __m256i _mm256_gf2p8affineinv_epi64_epi8(
    __m256i arg0,
    __m256i arg1,
    int arg2,
  ) {
    return __mm256_gf2p8affineinv_epi64_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_gf2p8affineinv_epi64_epi8Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__m256i, __m256i, ffi.Int32)>>(
      '_mm256_gf2p8affineinv_epi64_epi8');
  late final __mm256_gf2p8affineinv_epi64_epi8 =
      __mm256_gf2p8affineinv_epi64_epi8Ptr
          .asFunction<__m256i Function(__m256i, __m256i, int)>();

  __m256i _mm256_mask_gf2p8affineinv_epi64_epi8(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
    int arg4,
  ) {
    return __mm256_mask_gf2p8affineinv_epi64_epi8(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm256_mask_gf2p8affineinv_epi64_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask32, __m256i, __m256i,
              ffi.Int32)>>('_mm256_mask_gf2p8affineinv_epi64_epi8');
  late final __mm256_mask_gf2p8affineinv_epi64_epi8 =
      __mm256_mask_gf2p8affineinv_epi64_epi8Ptr
          .asFunction<__m256i Function(__m256i, int, __m256i, __m256i, int)>();

  __m256i _mm256_maskz_gf2p8affineinv_epi64_epi8(
    int arg0,
    __m256i arg1,
    __m256i arg2,
    int arg3,
  ) {
    return __mm256_maskz_gf2p8affineinv_epi64_epi8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_maskz_gf2p8affineinv_epi64_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__mmask32, __m256i, __m256i,
              ffi.Int32)>>('_mm256_maskz_gf2p8affineinv_epi64_epi8');
  late final __mm256_maskz_gf2p8affineinv_epi64_epi8 =
      __mm256_maskz_gf2p8affineinv_epi64_epi8Ptr
          .asFunction<__m256i Function(int, __m256i, __m256i, int)>();

  __m512i _mm512_gf2p8affineinv_epi64_epi8(
    __m512i arg0,
    __m512i arg1,
    int arg2,
  ) {
    return __mm512_gf2p8affineinv_epi64_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_gf2p8affineinv_epi64_epi8Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__m512i, __m512i, ffi.Int32)>>(
      '_mm512_gf2p8affineinv_epi64_epi8');
  late final __mm512_gf2p8affineinv_epi64_epi8 =
      __mm512_gf2p8affineinv_epi64_epi8Ptr
          .asFunction<__m512i Function(__m512i, __m512i, int)>();

  __m512i _mm512_mask_gf2p8affineinv_epi64_epi8(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
    int arg4,
  ) {
    return __mm512_mask_gf2p8affineinv_epi64_epi8(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_gf2p8affineinv_epi64_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask64, __m512i, __m512i,
              ffi.Int32)>>('_mm512_mask_gf2p8affineinv_epi64_epi8');
  late final __mm512_mask_gf2p8affineinv_epi64_epi8 =
      __mm512_mask_gf2p8affineinv_epi64_epi8Ptr
          .asFunction<__m512i Function(__m512i, int, __m512i, __m512i, int)>();

  __m512i _mm512_maskz_gf2p8affineinv_epi64_epi8(
    int arg0,
    __m512i arg1,
    __m512i arg2,
    int arg3,
  ) {
    return __mm512_maskz_gf2p8affineinv_epi64_epi8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_gf2p8affineinv_epi64_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__mmask64, __m512i, __m512i,
              ffi.Int32)>>('_mm512_maskz_gf2p8affineinv_epi64_epi8');
  late final __mm512_maskz_gf2p8affineinv_epi64_epi8 =
      __mm512_maskz_gf2p8affineinv_epi64_epi8Ptr
          .asFunction<__m512i Function(int, __m512i, __m512i, int)>();

  __m128i _mm_gf2p8affine_epi64_epi8(
    __m128i arg0,
    __m128i arg1,
    int arg2,
  ) {
    return __mm_gf2p8affine_epi64_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_gf2p8affine_epi64_epi8Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__m128i, __m128i, ffi.Int32)>>(
      '_mm_gf2p8affine_epi64_epi8');
  late final __mm_gf2p8affine_epi64_epi8 = __mm_gf2p8affine_epi64_epi8Ptr
      .asFunction<__m128i Function(__m128i, __m128i, int)>();

  __m128i _mm_mask_gf2p8affine_epi64_epi8(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
    int arg4,
  ) {
    return __mm_mask_gf2p8affine_epi64_epi8(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_gf2p8affine_epi64_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(__m128i, __mmask16, __m128i, __m128i,
              ffi.Int32)>>('_mm_mask_gf2p8affine_epi64_epi8');
  late final __mm_mask_gf2p8affine_epi64_epi8 =
      __mm_mask_gf2p8affine_epi64_epi8Ptr
          .asFunction<__m128i Function(__m128i, int, __m128i, __m128i, int)>();

  __m128i _mm_maskz_gf2p8affine_epi64_epi8(
    int arg0,
    __m128i arg1,
    __m128i arg2,
    int arg3,
  ) {
    return __mm_maskz_gf2p8affine_epi64_epi8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_gf2p8affine_epi64_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(__mmask16, __m128i, __m128i,
              ffi.Int32)>>('_mm_maskz_gf2p8affine_epi64_epi8');
  late final __mm_maskz_gf2p8affine_epi64_epi8 =
      __mm_maskz_gf2p8affine_epi64_epi8Ptr
          .asFunction<__m128i Function(int, __m128i, __m128i, int)>();

  __m256i _mm256_gf2p8affine_epi64_epi8(
    __m256i arg0,
    __m256i arg1,
    int arg2,
  ) {
    return __mm256_gf2p8affine_epi64_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_gf2p8affine_epi64_epi8Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__m256i, __m256i, ffi.Int32)>>(
      '_mm256_gf2p8affine_epi64_epi8');
  late final __mm256_gf2p8affine_epi64_epi8 = __mm256_gf2p8affine_epi64_epi8Ptr
      .asFunction<__m256i Function(__m256i, __m256i, int)>();

  __m256i _mm256_mask_gf2p8affine_epi64_epi8(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
    int arg4,
  ) {
    return __mm256_mask_gf2p8affine_epi64_epi8(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm256_mask_gf2p8affine_epi64_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask32, __m256i, __m256i,
              ffi.Int32)>>('_mm256_mask_gf2p8affine_epi64_epi8');
  late final __mm256_mask_gf2p8affine_epi64_epi8 =
      __mm256_mask_gf2p8affine_epi64_epi8Ptr
          .asFunction<__m256i Function(__m256i, int, __m256i, __m256i, int)>();

  __m256i _mm256_maskz_gf2p8affine_epi64_epi8(
    int arg0,
    __m256i arg1,
    __m256i arg2,
    int arg3,
  ) {
    return __mm256_maskz_gf2p8affine_epi64_epi8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_maskz_gf2p8affine_epi64_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__mmask32, __m256i, __m256i,
              ffi.Int32)>>('_mm256_maskz_gf2p8affine_epi64_epi8');
  late final __mm256_maskz_gf2p8affine_epi64_epi8 =
      __mm256_maskz_gf2p8affine_epi64_epi8Ptr
          .asFunction<__m256i Function(int, __m256i, __m256i, int)>();

  __m512i _mm512_gf2p8affine_epi64_epi8(
    __m512i arg0,
    __m512i arg1,
    int arg2,
  ) {
    return __mm512_gf2p8affine_epi64_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_gf2p8affine_epi64_epi8Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__m512i, __m512i, ffi.Int32)>>(
      '_mm512_gf2p8affine_epi64_epi8');
  late final __mm512_gf2p8affine_epi64_epi8 = __mm512_gf2p8affine_epi64_epi8Ptr
      .asFunction<__m512i Function(__m512i, __m512i, int)>();

  __m512i _mm512_mask_gf2p8affine_epi64_epi8(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
    int arg4,
  ) {
    return __mm512_mask_gf2p8affine_epi64_epi8(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_gf2p8affine_epi64_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask64, __m512i, __m512i,
              ffi.Int32)>>('_mm512_mask_gf2p8affine_epi64_epi8');
  late final __mm512_mask_gf2p8affine_epi64_epi8 =
      __mm512_mask_gf2p8affine_epi64_epi8Ptr
          .asFunction<__m512i Function(__m512i, int, __m512i, __m512i, int)>();

  __m512i _mm512_maskz_gf2p8affine_epi64_epi8(
    int arg0,
    __m512i arg1,
    __m512i arg2,
    int arg3,
  ) {
    return __mm512_maskz_gf2p8affine_epi64_epi8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_gf2p8affine_epi64_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__mmask64, __m512i, __m512i,
              ffi.Int32)>>('_mm512_maskz_gf2p8affine_epi64_epi8');
  late final __mm512_maskz_gf2p8affine_epi64_epi8 =
      __mm512_maskz_gf2p8affine_epi64_epi8Ptr
          .asFunction<__m512i Function(int, __m512i, __m512i, int)>();

  __m128i _mm_gf2p8mul_epi8(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_gf2p8mul_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm_gf2p8mul_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_gf2p8mul_epi8');
  late final __mm_gf2p8mul_epi8 =
      __mm_gf2p8mul_epi8Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_mask_gf2p8mul_epi8(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_gf2p8mul_epi8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_gf2p8mul_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask16, __m128i, __m128i)>>('_mm_mask_gf2p8mul_epi8');
  late final __mm_mask_gf2p8mul_epi8 = __mm_mask_gf2p8mul_epi8Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_gf2p8mul_epi8(
    int arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maskz_gf2p8mul_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_gf2p8mul_epi8Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__mmask16, __m128i, __m128i)>>(
      '_mm_maskz_gf2p8mul_epi8');
  late final __mm_maskz_gf2p8mul_epi8 = __mm_maskz_gf2p8mul_epi8Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i)>();

  __m256i _mm256_gf2p8mul_epi8(
    __m256i arg0,
    __m256i arg1,
  ) {
    return __mm256_gf2p8mul_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm256_gf2p8mul_epi8Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i)>>(
          '_mm256_gf2p8mul_epi8');
  late final __mm256_gf2p8mul_epi8 =
      __mm256_gf2p8mul_epi8Ptr.asFunction<__m256i Function(__m256i, __m256i)>();

  __m256i _mm256_mask_gf2p8mul_epi8(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_gf2p8mul_epi8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_gf2p8mul_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask32, __m256i,
              __m256i)>>('_mm256_mask_gf2p8mul_epi8');
  late final __mm256_mask_gf2p8mul_epi8 = __mm256_mask_gf2p8mul_epi8Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_gf2p8mul_epi8(
    int arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_maskz_gf2p8mul_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_gf2p8mul_epi8Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__mmask32, __m256i, __m256i)>>(
      '_mm256_maskz_gf2p8mul_epi8');
  late final __mm256_maskz_gf2p8mul_epi8 = __mm256_maskz_gf2p8mul_epi8Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i)>();

  __m512i _mm512_gf2p8mul_epi8(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_gf2p8mul_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm512_gf2p8mul_epi8Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_gf2p8mul_epi8');
  late final __mm512_gf2p8mul_epi8 =
      __mm512_gf2p8mul_epi8Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_gf2p8mul_epi8(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_gf2p8mul_epi8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_gf2p8mul_epi8Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask64, __m512i,
              __m512i)>>('_mm512_mask_gf2p8mul_epi8');
  late final __mm512_mask_gf2p8mul_epi8 = __mm512_mask_gf2p8mul_epi8Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_gf2p8mul_epi8(
    int arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_maskz_gf2p8mul_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_gf2p8mul_epi8Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask64, __m512i, __m512i)>>(
      '_mm512_maskz_gf2p8mul_epi8');
  late final __mm512_maskz_gf2p8mul_epi8 = __mm512_maskz_gf2p8mul_epi8Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i)>();

  __m128i _mm_shldi_epi16(
    __m128i arg0,
    __m128i arg1,
    int arg2,
  ) {
    return __mm_shldi_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_shldi_epi16Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__m128i, __m128i, ffi.Int32)>>(
      '_mm_shldi_epi16');
  late final __mm_shldi_epi16 =
      __mm_shldi_epi16Ptr.asFunction<__m128i Function(__m128i, __m128i, int)>();

  __m128i _mm_mask_shldi_epi16(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
    int arg4,
  ) {
    return __mm_mask_shldi_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_shldi_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(__m128i, __mmask8, __m128i, __m128i,
              ffi.Int32)>>('_mm_mask_shldi_epi16');
  late final __mm_mask_shldi_epi16 = __mm_mask_shldi_epi16Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i, int)>();

  __m128i _mm_maskz_shldi_epi16(
    int arg0,
    __m128i arg1,
    __m128i arg2,
    int arg3,
  ) {
    return __mm_maskz_shldi_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_shldi_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __mmask8, __m128i, __m128i, ffi.Int32)>>('_mm_maskz_shldi_epi16');
  late final __mm_maskz_shldi_epi16 = __mm_maskz_shldi_epi16Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i, int)>();

  __m256i _mm256_shldi_epi16(
    __m256i arg0,
    __m256i arg1,
    int arg2,
  ) {
    return __mm256_shldi_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_shldi_epi16Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__m256i, __m256i, ffi.Int32)>>(
      '_mm256_shldi_epi16');
  late final __mm256_shldi_epi16 = __mm256_shldi_epi16Ptr
      .asFunction<__m256i Function(__m256i, __m256i, int)>();

  __m256i _mm256_mask_shldi_epi16(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
    int arg4,
  ) {
    return __mm256_mask_shldi_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm256_mask_shldi_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask16, __m256i, __m256i,
              ffi.Int32)>>('_mm256_mask_shldi_epi16');
  late final __mm256_mask_shldi_epi16 = __mm256_mask_shldi_epi16Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i, int)>();

  __m256i _mm256_maskz_shldi_epi16(
    int arg0,
    __m256i arg1,
    __m256i arg2,
    int arg3,
  ) {
    return __mm256_maskz_shldi_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_maskz_shldi_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__mmask16, __m256i, __m256i,
              ffi.Int32)>>('_mm256_maskz_shldi_epi16');
  late final __mm256_maskz_shldi_epi16 = __mm256_maskz_shldi_epi16Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i, int)>();

  __m512i _mm512_shldi_epi16(
    __m512i arg0,
    __m512i arg1,
    int arg2,
  ) {
    return __mm512_shldi_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_shldi_epi16Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__m512i, __m512i, ffi.Int32)>>(
      '_mm512_shldi_epi16');
  late final __mm512_shldi_epi16 = __mm512_shldi_epi16Ptr
      .asFunction<__m512i Function(__m512i, __m512i, int)>();

  __m512i _mm512_mask_shldi_epi16(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
    int arg4,
  ) {
    return __mm512_mask_shldi_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_shldi_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask32, __m512i, __m512i,
              ffi.Int32)>>('_mm512_mask_shldi_epi16');
  late final __mm512_mask_shldi_epi16 = __mm512_mask_shldi_epi16Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i, int)>();

  __m512i _mm512_maskz_shldi_epi16(
    int arg0,
    __m512i arg1,
    __m512i arg2,
    int arg3,
  ) {
    return __mm512_maskz_shldi_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_shldi_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__mmask32, __m512i, __m512i,
              ffi.Int32)>>('_mm512_maskz_shldi_epi16');
  late final __mm512_maskz_shldi_epi16 = __mm512_maskz_shldi_epi16Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i, int)>();

  __m128i _mm_shldi_epi32(
    __m128i arg0,
    __m128i arg1,
    int arg2,
  ) {
    return __mm_shldi_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_shldi_epi32Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__m128i, __m128i, ffi.Int32)>>(
      '_mm_shldi_epi32');
  late final __mm_shldi_epi32 =
      __mm_shldi_epi32Ptr.asFunction<__m128i Function(__m128i, __m128i, int)>();

  __m128i _mm_mask_shldi_epi32(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
    int arg4,
  ) {
    return __mm_mask_shldi_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_shldi_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(__m128i, __mmask8, __m128i, __m128i,
              ffi.Int32)>>('_mm_mask_shldi_epi32');
  late final __mm_mask_shldi_epi32 = __mm_mask_shldi_epi32Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i, int)>();

  __m128i _mm_maskz_shldi_epi32(
    int arg0,
    __m128i arg1,
    __m128i arg2,
    int arg3,
  ) {
    return __mm_maskz_shldi_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_shldi_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __mmask8, __m128i, __m128i, ffi.Int32)>>('_mm_maskz_shldi_epi32');
  late final __mm_maskz_shldi_epi32 = __mm_maskz_shldi_epi32Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i, int)>();

  __m256i _mm256_shldi_epi32(
    __m256i arg0,
    __m256i arg1,
    int arg2,
  ) {
    return __mm256_shldi_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_shldi_epi32Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__m256i, __m256i, ffi.Int32)>>(
      '_mm256_shldi_epi32');
  late final __mm256_shldi_epi32 = __mm256_shldi_epi32Ptr
      .asFunction<__m256i Function(__m256i, __m256i, int)>();

  __m256i _mm256_mask_shldi_epi32(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
    int arg4,
  ) {
    return __mm256_mask_shldi_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm256_mask_shldi_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask8, __m256i, __m256i,
              ffi.Int32)>>('_mm256_mask_shldi_epi32');
  late final __mm256_mask_shldi_epi32 = __mm256_mask_shldi_epi32Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i, int)>();

  __m256i _mm256_maskz_shldi_epi32(
    int arg0,
    __m256i arg1,
    __m256i arg2,
    int arg3,
  ) {
    return __mm256_maskz_shldi_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_maskz_shldi_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__mmask8, __m256i, __m256i,
              ffi.Int32)>>('_mm256_maskz_shldi_epi32');
  late final __mm256_maskz_shldi_epi32 = __mm256_maskz_shldi_epi32Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i, int)>();

  __m512i _mm512_shldi_epi32(
    __m512i arg0,
    __m512i arg1,
    int arg2,
  ) {
    return __mm512_shldi_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_shldi_epi32Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__m512i, __m512i, ffi.Int32)>>(
      '_mm512_shldi_epi32');
  late final __mm512_shldi_epi32 = __mm512_shldi_epi32Ptr
      .asFunction<__m512i Function(__m512i, __m512i, int)>();

  __m512i _mm512_mask_shldi_epi32(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
    int arg4,
  ) {
    return __mm512_mask_shldi_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_shldi_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask16, __m512i, __m512i,
              ffi.Int32)>>('_mm512_mask_shldi_epi32');
  late final __mm512_mask_shldi_epi32 = __mm512_mask_shldi_epi32Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i, int)>();

  __m512i _mm512_maskz_shldi_epi32(
    int arg0,
    __m512i arg1,
    __m512i arg2,
    int arg3,
  ) {
    return __mm512_maskz_shldi_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_shldi_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__mmask16, __m512i, __m512i,
              ffi.Int32)>>('_mm512_maskz_shldi_epi32');
  late final __mm512_maskz_shldi_epi32 = __mm512_maskz_shldi_epi32Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i, int)>();

  __m128i _mm_shldi_epi64(
    __m128i arg0,
    __m128i arg1,
    int arg2,
  ) {
    return __mm_shldi_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_shldi_epi64Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__m128i, __m128i, ffi.Int32)>>(
      '_mm_shldi_epi64');
  late final __mm_shldi_epi64 =
      __mm_shldi_epi64Ptr.asFunction<__m128i Function(__m128i, __m128i, int)>();

  __m128i _mm_mask_shldi_epi64(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
    int arg4,
  ) {
    return __mm_mask_shldi_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_shldi_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(__m128i, __mmask8, __m128i, __m128i,
              ffi.Int32)>>('_mm_mask_shldi_epi64');
  late final __mm_mask_shldi_epi64 = __mm_mask_shldi_epi64Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i, int)>();

  __m128i _mm_maskz_shldi_epi64(
    int arg0,
    __m128i arg1,
    __m128i arg2,
    int arg3,
  ) {
    return __mm_maskz_shldi_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_shldi_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __mmask8, __m128i, __m128i, ffi.Int32)>>('_mm_maskz_shldi_epi64');
  late final __mm_maskz_shldi_epi64 = __mm_maskz_shldi_epi64Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i, int)>();

  __m256i _mm256_shldi_epi64(
    __m256i arg0,
    __m256i arg1,
    int arg2,
  ) {
    return __mm256_shldi_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_shldi_epi64Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__m256i, __m256i, ffi.Int32)>>(
      '_mm256_shldi_epi64');
  late final __mm256_shldi_epi64 = __mm256_shldi_epi64Ptr
      .asFunction<__m256i Function(__m256i, __m256i, int)>();

  __m256i _mm256_mask_shldi_epi64(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
    int arg4,
  ) {
    return __mm256_mask_shldi_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm256_mask_shldi_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask8, __m256i, __m256i,
              ffi.Int32)>>('_mm256_mask_shldi_epi64');
  late final __mm256_mask_shldi_epi64 = __mm256_mask_shldi_epi64Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i, int)>();

  __m256i _mm256_maskz_shldi_epi64(
    int arg0,
    __m256i arg1,
    __m256i arg2,
    int arg3,
  ) {
    return __mm256_maskz_shldi_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_maskz_shldi_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__mmask8, __m256i, __m256i,
              ffi.Int32)>>('_mm256_maskz_shldi_epi64');
  late final __mm256_maskz_shldi_epi64 = __mm256_maskz_shldi_epi64Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i, int)>();

  __m512i _mm512_shldi_epi64(
    __m512i arg0,
    __m512i arg1,
    int arg2,
  ) {
    return __mm512_shldi_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_shldi_epi64Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__m512i, __m512i, ffi.Int32)>>(
      '_mm512_shldi_epi64');
  late final __mm512_shldi_epi64 = __mm512_shldi_epi64Ptr
      .asFunction<__m512i Function(__m512i, __m512i, int)>();

  __m512i _mm512_mask_shldi_epi64(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
    int arg4,
  ) {
    return __mm512_mask_shldi_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_shldi_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask8, __m512i, __m512i,
              ffi.Int32)>>('_mm512_mask_shldi_epi64');
  late final __mm512_mask_shldi_epi64 = __mm512_mask_shldi_epi64Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i, int)>();

  __m512i _mm512_maskz_shldi_epi64(
    int arg0,
    __m512i arg1,
    __m512i arg2,
    int arg3,
  ) {
    return __mm512_maskz_shldi_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_shldi_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__mmask8, __m512i, __m512i,
              ffi.Int32)>>('_mm512_maskz_shldi_epi64');
  late final __mm512_maskz_shldi_epi64 = __mm512_maskz_shldi_epi64Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i, int)>();

  __m128i _mm_shldv_epi16(
    __m128i arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_shldv_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_shldv_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i, __m128i)>>(
          '_mm_shldv_epi16');
  late final __mm_shldv_epi16 = __mm_shldv_epi16Ptr
      .asFunction<__m128i Function(__m128i, __m128i, __m128i)>();

  __m128i _mm_mask_shldv_epi16(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_shldv_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_shldv_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_shldv_epi16');
  late final __mm_mask_shldv_epi16 = __mm_mask_shldv_epi16Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_shldv_epi16(
    int arg0,
    __m128i arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_maskz_shldv_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_shldv_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __mmask8, __m128i, __m128i, __m128i)>>('_mm_maskz_shldv_epi16');
  late final __mm_maskz_shldv_epi16 = __mm_maskz_shldv_epi16Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i, __m128i)>();

  __m256i _mm256_shldv_epi16(
    __m256i arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_shldv_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_shldv_epi16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i, __m256i)>>(
          '_mm256_shldv_epi16');
  late final __mm256_shldv_epi16 = __mm256_shldv_epi16Ptr
      .asFunction<__m256i Function(__m256i, __m256i, __m256i)>();

  __m256i _mm256_mask_shldv_epi16(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_shldv_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_shldv_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask16, __m256i,
              __m256i)>>('_mm256_mask_shldv_epi16');
  late final __mm256_mask_shldv_epi16 = __mm256_mask_shldv_epi16Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_shldv_epi16(
    int arg0,
    __m256i arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_maskz_shldv_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_maskz_shldv_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__mmask16, __m256i, __m256i,
              __m256i)>>('_mm256_maskz_shldv_epi16');
  late final __mm256_maskz_shldv_epi16 = __mm256_maskz_shldv_epi16Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i, __m256i)>();

  __m512i _mm512_shldv_epi16(
    __m512i arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_shldv_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_shldv_epi16Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i, __m512i)>>(
          '_mm512_shldv_epi16');
  late final __mm512_shldv_epi16 = __mm512_shldv_epi16Ptr
      .asFunction<__m512i Function(__m512i, __m512i, __m512i)>();

  __m512i _mm512_mask_shldv_epi16(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_shldv_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_shldv_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask32, __m512i,
              __m512i)>>('_mm512_mask_shldv_epi16');
  late final __mm512_mask_shldv_epi16 = __mm512_mask_shldv_epi16Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_shldv_epi16(
    int arg0,
    __m512i arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_maskz_shldv_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_shldv_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__mmask32, __m512i, __m512i,
              __m512i)>>('_mm512_maskz_shldv_epi16');
  late final __mm512_maskz_shldv_epi16 = __mm512_maskz_shldv_epi16Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i, __m512i)>();

  __m128i _mm_shldv_epi32(
    __m128i arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_shldv_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_shldv_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i, __m128i)>>(
          '_mm_shldv_epi32');
  late final __mm_shldv_epi32 = __mm_shldv_epi32Ptr
      .asFunction<__m128i Function(__m128i, __m128i, __m128i)>();

  __m128i _mm_mask_shldv_epi32(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_shldv_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_shldv_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_shldv_epi32');
  late final __mm_mask_shldv_epi32 = __mm_mask_shldv_epi32Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_shldv_epi32(
    int arg0,
    __m128i arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_maskz_shldv_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_shldv_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __mmask8, __m128i, __m128i, __m128i)>>('_mm_maskz_shldv_epi32');
  late final __mm_maskz_shldv_epi32 = __mm_maskz_shldv_epi32Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i, __m128i)>();

  __m256i _mm256_shldv_epi32(
    __m256i arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_shldv_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_shldv_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i, __m256i)>>(
          '_mm256_shldv_epi32');
  late final __mm256_shldv_epi32 = __mm256_shldv_epi32Ptr
      .asFunction<__m256i Function(__m256i, __m256i, __m256i)>();

  __m256i _mm256_mask_shldv_epi32(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_shldv_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_shldv_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask8, __m256i, __m256i)>>('_mm256_mask_shldv_epi32');
  late final __mm256_mask_shldv_epi32 = __mm256_mask_shldv_epi32Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_shldv_epi32(
    int arg0,
    __m256i arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_maskz_shldv_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_maskz_shldv_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__mmask8, __m256i, __m256i,
              __m256i)>>('_mm256_maskz_shldv_epi32');
  late final __mm256_maskz_shldv_epi32 = __mm256_maskz_shldv_epi32Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i, __m256i)>();

  __m512i _mm512_shldv_epi32(
    __m512i arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_shldv_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_shldv_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i, __m512i)>>(
          '_mm512_shldv_epi32');
  late final __mm512_shldv_epi32 = __mm512_shldv_epi32Ptr
      .asFunction<__m512i Function(__m512i, __m512i, __m512i)>();

  __m512i _mm512_mask_shldv_epi32(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_shldv_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_shldv_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask16, __m512i,
              __m512i)>>('_mm512_mask_shldv_epi32');
  late final __mm512_mask_shldv_epi32 = __mm512_mask_shldv_epi32Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_shldv_epi32(
    int arg0,
    __m512i arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_maskz_shldv_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_shldv_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__mmask16, __m512i, __m512i,
              __m512i)>>('_mm512_maskz_shldv_epi32');
  late final __mm512_maskz_shldv_epi32 = __mm512_maskz_shldv_epi32Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i, __m512i)>();

  __m128i _mm_shldv_epi64(
    __m128i arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_shldv_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_shldv_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i, __m128i)>>(
          '_mm_shldv_epi64');
  late final __mm_shldv_epi64 = __mm_shldv_epi64Ptr
      .asFunction<__m128i Function(__m128i, __m128i, __m128i)>();

  __m128i _mm_mask_shldv_epi64(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_shldv_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_shldv_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_shldv_epi64');
  late final __mm_mask_shldv_epi64 = __mm_mask_shldv_epi64Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_shldv_epi64(
    int arg0,
    __m128i arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_maskz_shldv_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_shldv_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __mmask8, __m128i, __m128i, __m128i)>>('_mm_maskz_shldv_epi64');
  late final __mm_maskz_shldv_epi64 = __mm_maskz_shldv_epi64Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i, __m128i)>();

  __m256i _mm256_shldv_epi64(
    __m256i arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_shldv_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_shldv_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i, __m256i)>>(
          '_mm256_shldv_epi64');
  late final __mm256_shldv_epi64 = __mm256_shldv_epi64Ptr
      .asFunction<__m256i Function(__m256i, __m256i, __m256i)>();

  __m256i _mm256_mask_shldv_epi64(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_shldv_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_shldv_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask8, __m256i, __m256i)>>('_mm256_mask_shldv_epi64');
  late final __mm256_mask_shldv_epi64 = __mm256_mask_shldv_epi64Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_shldv_epi64(
    int arg0,
    __m256i arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_maskz_shldv_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_maskz_shldv_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__mmask8, __m256i, __m256i,
              __m256i)>>('_mm256_maskz_shldv_epi64');
  late final __mm256_maskz_shldv_epi64 = __mm256_maskz_shldv_epi64Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i, __m256i)>();

  __m512i _mm512_shldv_epi64(
    __m512i arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_shldv_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_shldv_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i, __m512i)>>(
          '_mm512_shldv_epi64');
  late final __mm512_shldv_epi64 = __mm512_shldv_epi64Ptr
      .asFunction<__m512i Function(__m512i, __m512i, __m512i)>();

  __m512i _mm512_mask_shldv_epi64(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_shldv_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_shldv_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask8, __m512i, __m512i)>>('_mm512_mask_shldv_epi64');
  late final __mm512_mask_shldv_epi64 = __mm512_mask_shldv_epi64Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_shldv_epi64(
    int arg0,
    __m512i arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_maskz_shldv_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_shldv_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__mmask8, __m512i, __m512i,
              __m512i)>>('_mm512_maskz_shldv_epi64');
  late final __mm512_maskz_shldv_epi64 = __mm512_maskz_shldv_epi64Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i, __m512i)>();

  __m128i _mm_shrdi_epi16(
    __m128i arg0,
    __m128i arg1,
    int arg2,
  ) {
    return __mm_shrdi_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_shrdi_epi16Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__m128i, __m128i, ffi.Int32)>>(
      '_mm_shrdi_epi16');
  late final __mm_shrdi_epi16 =
      __mm_shrdi_epi16Ptr.asFunction<__m128i Function(__m128i, __m128i, int)>();

  __m128i _mm_mask_shrdi_epi16(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
    int arg4,
  ) {
    return __mm_mask_shrdi_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_shrdi_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(__m128i, __mmask8, __m128i, __m128i,
              ffi.Int32)>>('_mm_mask_shrdi_epi16');
  late final __mm_mask_shrdi_epi16 = __mm_mask_shrdi_epi16Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i, int)>();

  __m128i _mm_maskz_shrdi_epi16(
    int arg0,
    __m128i arg1,
    __m128i arg2,
    int arg3,
  ) {
    return __mm_maskz_shrdi_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_shrdi_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __mmask8, __m128i, __m128i, ffi.Int32)>>('_mm_maskz_shrdi_epi16');
  late final __mm_maskz_shrdi_epi16 = __mm_maskz_shrdi_epi16Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i, int)>();

  __m256i _mm256_shrdi_epi16(
    __m256i arg0,
    __m256i arg1,
    int arg2,
  ) {
    return __mm256_shrdi_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_shrdi_epi16Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__m256i, __m256i, ffi.Int32)>>(
      '_mm256_shrdi_epi16');
  late final __mm256_shrdi_epi16 = __mm256_shrdi_epi16Ptr
      .asFunction<__m256i Function(__m256i, __m256i, int)>();

  __m256i _mm256_mask_shrdi_epi16(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
    int arg4,
  ) {
    return __mm256_mask_shrdi_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm256_mask_shrdi_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask16, __m256i, __m256i,
              ffi.Int32)>>('_mm256_mask_shrdi_epi16');
  late final __mm256_mask_shrdi_epi16 = __mm256_mask_shrdi_epi16Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i, int)>();

  __m256i _mm256_maskz_shrdi_epi16(
    int arg0,
    __m256i arg1,
    __m256i arg2,
    int arg3,
  ) {
    return __mm256_maskz_shrdi_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_maskz_shrdi_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__mmask16, __m256i, __m256i,
              ffi.Int32)>>('_mm256_maskz_shrdi_epi16');
  late final __mm256_maskz_shrdi_epi16 = __mm256_maskz_shrdi_epi16Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i, int)>();

  __m512i _mm512_shrdi_epi16(
    __m512i arg0,
    __m512i arg1,
    int arg2,
  ) {
    return __mm512_shrdi_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_shrdi_epi16Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__m512i, __m512i, ffi.Int32)>>(
      '_mm512_shrdi_epi16');
  late final __mm512_shrdi_epi16 = __mm512_shrdi_epi16Ptr
      .asFunction<__m512i Function(__m512i, __m512i, int)>();

  __m512i _mm512_mask_shrdi_epi16(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
    int arg4,
  ) {
    return __mm512_mask_shrdi_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_shrdi_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask32, __m512i, __m512i,
              ffi.Int32)>>('_mm512_mask_shrdi_epi16');
  late final __mm512_mask_shrdi_epi16 = __mm512_mask_shrdi_epi16Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i, int)>();

  __m512i _mm512_maskz_shrdi_epi16(
    int arg0,
    __m512i arg1,
    __m512i arg2,
    int arg3,
  ) {
    return __mm512_maskz_shrdi_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_shrdi_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__mmask32, __m512i, __m512i,
              ffi.Int32)>>('_mm512_maskz_shrdi_epi16');
  late final __mm512_maskz_shrdi_epi16 = __mm512_maskz_shrdi_epi16Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i, int)>();

  __m128i _mm_shrdi_epi32(
    __m128i arg0,
    __m128i arg1,
    int arg2,
  ) {
    return __mm_shrdi_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_shrdi_epi32Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__m128i, __m128i, ffi.Int32)>>(
      '_mm_shrdi_epi32');
  late final __mm_shrdi_epi32 =
      __mm_shrdi_epi32Ptr.asFunction<__m128i Function(__m128i, __m128i, int)>();

  __m128i _mm_mask_shrdi_epi32(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
    int arg4,
  ) {
    return __mm_mask_shrdi_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_shrdi_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(__m128i, __mmask8, __m128i, __m128i,
              ffi.Int32)>>('_mm_mask_shrdi_epi32');
  late final __mm_mask_shrdi_epi32 = __mm_mask_shrdi_epi32Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i, int)>();

  __m128i _mm_maskz_shrdi_epi32(
    int arg0,
    __m128i arg1,
    __m128i arg2,
    int arg3,
  ) {
    return __mm_maskz_shrdi_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_shrdi_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __mmask8, __m128i, __m128i, ffi.Int32)>>('_mm_maskz_shrdi_epi32');
  late final __mm_maskz_shrdi_epi32 = __mm_maskz_shrdi_epi32Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i, int)>();

  __m256i _mm256_shrdi_epi32(
    __m256i arg0,
    __m256i arg1,
    int arg2,
  ) {
    return __mm256_shrdi_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_shrdi_epi32Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__m256i, __m256i, ffi.Int32)>>(
      '_mm256_shrdi_epi32');
  late final __mm256_shrdi_epi32 = __mm256_shrdi_epi32Ptr
      .asFunction<__m256i Function(__m256i, __m256i, int)>();

  __m256i _mm256_mask_shrdi_epi32(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
    int arg4,
  ) {
    return __mm256_mask_shrdi_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm256_mask_shrdi_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask8, __m256i, __m256i,
              ffi.Int32)>>('_mm256_mask_shrdi_epi32');
  late final __mm256_mask_shrdi_epi32 = __mm256_mask_shrdi_epi32Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i, int)>();

  __m256i _mm256_maskz_shrdi_epi32(
    int arg0,
    __m256i arg1,
    __m256i arg2,
    int arg3,
  ) {
    return __mm256_maskz_shrdi_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_maskz_shrdi_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__mmask8, __m256i, __m256i,
              ffi.Int32)>>('_mm256_maskz_shrdi_epi32');
  late final __mm256_maskz_shrdi_epi32 = __mm256_maskz_shrdi_epi32Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i, int)>();

  __m512i _mm512_shrdi_epi32(
    __m512i arg0,
    __m512i arg1,
    int arg2,
  ) {
    return __mm512_shrdi_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_shrdi_epi32Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__m512i, __m512i, ffi.Int32)>>(
      '_mm512_shrdi_epi32');
  late final __mm512_shrdi_epi32 = __mm512_shrdi_epi32Ptr
      .asFunction<__m512i Function(__m512i, __m512i, int)>();

  __m512i _mm512_mask_shrdi_epi32(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
    int arg4,
  ) {
    return __mm512_mask_shrdi_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_shrdi_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask16, __m512i, __m512i,
              ffi.Int32)>>('_mm512_mask_shrdi_epi32');
  late final __mm512_mask_shrdi_epi32 = __mm512_mask_shrdi_epi32Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i, int)>();

  __m512i _mm512_maskz_shrdi_epi32(
    int arg0,
    __m512i arg1,
    __m512i arg2,
    int arg3,
  ) {
    return __mm512_maskz_shrdi_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_shrdi_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__mmask16, __m512i, __m512i,
              ffi.Int32)>>('_mm512_maskz_shrdi_epi32');
  late final __mm512_maskz_shrdi_epi32 = __mm512_maskz_shrdi_epi32Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i, int)>();

  __m128i _mm_shrdi_epi64(
    __m128i arg0,
    __m128i arg1,
    int arg2,
  ) {
    return __mm_shrdi_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_shrdi_epi64Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__m128i, __m128i, ffi.Int32)>>(
      '_mm_shrdi_epi64');
  late final __mm_shrdi_epi64 =
      __mm_shrdi_epi64Ptr.asFunction<__m128i Function(__m128i, __m128i, int)>();

  __m128i _mm_mask_shrdi_epi64(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
    int arg4,
  ) {
    return __mm_mask_shrdi_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_shrdi_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(__m128i, __mmask8, __m128i, __m128i,
              ffi.Int32)>>('_mm_mask_shrdi_epi64');
  late final __mm_mask_shrdi_epi64 = __mm_mask_shrdi_epi64Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i, int)>();

  __m128i _mm_maskz_shrdi_epi64(
    int arg0,
    __m128i arg1,
    __m128i arg2,
    int arg3,
  ) {
    return __mm_maskz_shrdi_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_shrdi_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __mmask8, __m128i, __m128i, ffi.Int32)>>('_mm_maskz_shrdi_epi64');
  late final __mm_maskz_shrdi_epi64 = __mm_maskz_shrdi_epi64Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i, int)>();

  __m256i _mm256_shrdi_epi64(
    __m256i arg0,
    __m256i arg1,
    int arg2,
  ) {
    return __mm256_shrdi_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_shrdi_epi64Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__m256i, __m256i, ffi.Int32)>>(
      '_mm256_shrdi_epi64');
  late final __mm256_shrdi_epi64 = __mm256_shrdi_epi64Ptr
      .asFunction<__m256i Function(__m256i, __m256i, int)>();

  __m256i _mm256_mask_shrdi_epi64(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
    int arg4,
  ) {
    return __mm256_mask_shrdi_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm256_mask_shrdi_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask8, __m256i, __m256i,
              ffi.Int32)>>('_mm256_mask_shrdi_epi64');
  late final __mm256_mask_shrdi_epi64 = __mm256_mask_shrdi_epi64Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i, int)>();

  __m256i _mm256_maskz_shrdi_epi64(
    int arg0,
    __m256i arg1,
    __m256i arg2,
    int arg3,
  ) {
    return __mm256_maskz_shrdi_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_maskz_shrdi_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__mmask8, __m256i, __m256i,
              ffi.Int32)>>('_mm256_maskz_shrdi_epi64');
  late final __mm256_maskz_shrdi_epi64 = __mm256_maskz_shrdi_epi64Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i, int)>();

  __m512i _mm512_shrdi_epi64(
    __m512i arg0,
    __m512i arg1,
    int arg2,
  ) {
    return __mm512_shrdi_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_shrdi_epi64Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__m512i, __m512i, ffi.Int32)>>(
      '_mm512_shrdi_epi64');
  late final __mm512_shrdi_epi64 = __mm512_shrdi_epi64Ptr
      .asFunction<__m512i Function(__m512i, __m512i, int)>();

  __m512i _mm512_mask_shrdi_epi64(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
    int arg4,
  ) {
    return __mm512_mask_shrdi_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_shrdi_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask8, __m512i, __m512i,
              ffi.Int32)>>('_mm512_mask_shrdi_epi64');
  late final __mm512_mask_shrdi_epi64 = __mm512_mask_shrdi_epi64Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i, int)>();

  __m512i _mm512_maskz_shrdi_epi64(
    int arg0,
    __m512i arg1,
    __m512i arg2,
    int arg3,
  ) {
    return __mm512_maskz_shrdi_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_shrdi_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__mmask8, __m512i, __m512i,
              ffi.Int32)>>('_mm512_maskz_shrdi_epi64');
  late final __mm512_maskz_shrdi_epi64 = __mm512_maskz_shrdi_epi64Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i, int)>();

  __m128i _mm_shrdv_epi16(
    __m128i arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_shrdv_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_shrdv_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i, __m128i)>>(
          '_mm_shrdv_epi16');
  late final __mm_shrdv_epi16 = __mm_shrdv_epi16Ptr
      .asFunction<__m128i Function(__m128i, __m128i, __m128i)>();

  __m128i _mm_mask_shrdv_epi16(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_shrdv_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_shrdv_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_shrdv_epi16');
  late final __mm_mask_shrdv_epi16 = __mm_mask_shrdv_epi16Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_shrdv_epi16(
    int arg0,
    __m128i arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_maskz_shrdv_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_shrdv_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __mmask8, __m128i, __m128i, __m128i)>>('_mm_maskz_shrdv_epi16');
  late final __mm_maskz_shrdv_epi16 = __mm_maskz_shrdv_epi16Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i, __m128i)>();

  __m256i _mm256_shrdv_epi16(
    __m256i arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_shrdv_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_shrdv_epi16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i, __m256i)>>(
          '_mm256_shrdv_epi16');
  late final __mm256_shrdv_epi16 = __mm256_shrdv_epi16Ptr
      .asFunction<__m256i Function(__m256i, __m256i, __m256i)>();

  __m256i _mm256_mask_shrdv_epi16(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_shrdv_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_shrdv_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__m256i, __mmask16, __m256i,
              __m256i)>>('_mm256_mask_shrdv_epi16');
  late final __mm256_mask_shrdv_epi16 = __mm256_mask_shrdv_epi16Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_shrdv_epi16(
    int arg0,
    __m256i arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_maskz_shrdv_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_maskz_shrdv_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__mmask16, __m256i, __m256i,
              __m256i)>>('_mm256_maskz_shrdv_epi16');
  late final __mm256_maskz_shrdv_epi16 = __mm256_maskz_shrdv_epi16Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i, __m256i)>();

  __m512i _mm512_shrdv_epi16(
    __m512i arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_shrdv_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_shrdv_epi16Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i, __m512i)>>(
          '_mm512_shrdv_epi16');
  late final __mm512_shrdv_epi16 = __mm512_shrdv_epi16Ptr
      .asFunction<__m512i Function(__m512i, __m512i, __m512i)>();

  __m512i _mm512_mask_shrdv_epi16(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_shrdv_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_shrdv_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask32, __m512i,
              __m512i)>>('_mm512_mask_shrdv_epi16');
  late final __mm512_mask_shrdv_epi16 = __mm512_mask_shrdv_epi16Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_shrdv_epi16(
    int arg0,
    __m512i arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_maskz_shrdv_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_shrdv_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__mmask32, __m512i, __m512i,
              __m512i)>>('_mm512_maskz_shrdv_epi16');
  late final __mm512_maskz_shrdv_epi16 = __mm512_maskz_shrdv_epi16Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i, __m512i)>();

  __m128i _mm_shrdv_epi32(
    __m128i arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_shrdv_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_shrdv_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i, __m128i)>>(
          '_mm_shrdv_epi32');
  late final __mm_shrdv_epi32 = __mm_shrdv_epi32Ptr
      .asFunction<__m128i Function(__m128i, __m128i, __m128i)>();

  __m128i _mm_mask_shrdv_epi32(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_shrdv_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_shrdv_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_shrdv_epi32');
  late final __mm_mask_shrdv_epi32 = __mm_mask_shrdv_epi32Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_shrdv_epi32(
    int arg0,
    __m128i arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_maskz_shrdv_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_shrdv_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __mmask8, __m128i, __m128i, __m128i)>>('_mm_maskz_shrdv_epi32');
  late final __mm_maskz_shrdv_epi32 = __mm_maskz_shrdv_epi32Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i, __m128i)>();

  __m256i _mm256_shrdv_epi32(
    __m256i arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_shrdv_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_shrdv_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i, __m256i)>>(
          '_mm256_shrdv_epi32');
  late final __mm256_shrdv_epi32 = __mm256_shrdv_epi32Ptr
      .asFunction<__m256i Function(__m256i, __m256i, __m256i)>();

  __m256i _mm256_mask_shrdv_epi32(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_shrdv_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_shrdv_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask8, __m256i, __m256i)>>('_mm256_mask_shrdv_epi32');
  late final __mm256_mask_shrdv_epi32 = __mm256_mask_shrdv_epi32Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_shrdv_epi32(
    int arg0,
    __m256i arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_maskz_shrdv_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_maskz_shrdv_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__mmask8, __m256i, __m256i,
              __m256i)>>('_mm256_maskz_shrdv_epi32');
  late final __mm256_maskz_shrdv_epi32 = __mm256_maskz_shrdv_epi32Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i, __m256i)>();

  __m512i _mm512_shrdv_epi32(
    __m512i arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_shrdv_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_shrdv_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i, __m512i)>>(
          '_mm512_shrdv_epi32');
  late final __mm512_shrdv_epi32 = __mm512_shrdv_epi32Ptr
      .asFunction<__m512i Function(__m512i, __m512i, __m512i)>();

  __m512i _mm512_mask_shrdv_epi32(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_shrdv_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_shrdv_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask16, __m512i,
              __m512i)>>('_mm512_mask_shrdv_epi32');
  late final __mm512_mask_shrdv_epi32 = __mm512_mask_shrdv_epi32Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_shrdv_epi32(
    int arg0,
    __m512i arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_maskz_shrdv_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_shrdv_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__mmask16, __m512i, __m512i,
              __m512i)>>('_mm512_maskz_shrdv_epi32');
  late final __mm512_maskz_shrdv_epi32 = __mm512_maskz_shrdv_epi32Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i, __m512i)>();

  __m128i _mm_shrdv_epi64(
    __m128i arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_shrdv_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_shrdv_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i, __m128i)>>(
          '_mm_shrdv_epi64');
  late final __mm_shrdv_epi64 = __mm_shrdv_epi64Ptr
      .asFunction<__m128i Function(__m128i, __m128i, __m128i)>();

  __m128i _mm_mask_shrdv_epi64(
    __m128i arg0,
    int arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_mask_shrdv_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_shrdv_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __mmask8, __m128i, __m128i)>>('_mm_mask_shrdv_epi64');
  late final __mm_mask_shrdv_epi64 = __mm_mask_shrdv_epi64Ptr
      .asFunction<__m128i Function(__m128i, int, __m128i, __m128i)>();

  __m128i _mm_maskz_shrdv_epi64(
    int arg0,
    __m128i arg1,
    __m128i arg2,
    __m128i arg3,
  ) {
    return __mm_maskz_shrdv_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_shrdv_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __mmask8, __m128i, __m128i, __m128i)>>('_mm_maskz_shrdv_epi64');
  late final __mm_maskz_shrdv_epi64 = __mm_maskz_shrdv_epi64Ptr
      .asFunction<__m128i Function(int, __m128i, __m128i, __m128i)>();

  __m256i _mm256_shrdv_epi64(
    __m256i arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_shrdv_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_shrdv_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i, __m256i)>>(
          '_mm256_shrdv_epi64');
  late final __mm256_shrdv_epi64 = __mm256_shrdv_epi64Ptr
      .asFunction<__m256i Function(__m256i, __m256i, __m256i)>();

  __m256i _mm256_mask_shrdv_epi64(
    __m256i arg0,
    int arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_mask_shrdv_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_shrdv_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(
              __m256i, __mmask8, __m256i, __m256i)>>('_mm256_mask_shrdv_epi64');
  late final __mm256_mask_shrdv_epi64 = __mm256_mask_shrdv_epi64Ptr
      .asFunction<__m256i Function(__m256i, int, __m256i, __m256i)>();

  __m256i _mm256_maskz_shrdv_epi64(
    int arg0,
    __m256i arg1,
    __m256i arg2,
    __m256i arg3,
  ) {
    return __mm256_maskz_shrdv_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_maskz_shrdv_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m256i Function(__mmask8, __m256i, __m256i,
              __m256i)>>('_mm256_maskz_shrdv_epi64');
  late final __mm256_maskz_shrdv_epi64 = __mm256_maskz_shrdv_epi64Ptr
      .asFunction<__m256i Function(int, __m256i, __m256i, __m256i)>();

  __m512i _mm512_shrdv_epi64(
    __m512i arg0,
    __m512i arg1,
    __m512i arg2,
  ) {
    return __mm512_shrdv_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_shrdv_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i, __m512i)>>(
          '_mm512_shrdv_epi64');
  late final __mm512_shrdv_epi64 = __mm512_shrdv_epi64Ptr
      .asFunction<__m512i Function(__m512i, __m512i, __m512i)>();

  __m512i _mm512_mask_shrdv_epi64(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_shrdv_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_shrdv_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask8, __m512i, __m512i)>>('_mm512_mask_shrdv_epi64');
  late final __mm512_mask_shrdv_epi64 = __mm512_mask_shrdv_epi64Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_maskz_shrdv_epi64(
    int arg0,
    __m512i arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_maskz_shrdv_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_shrdv_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__mmask8, __m512i, __m512i,
              __m512i)>>('_mm512_maskz_shrdv_epi64');
  late final __mm512_maskz_shrdv_epi64 = __mm512_maskz_shrdv_epi64Ptr
      .asFunction<__m512i Function(int, __m512i, __m512i, __m512i)>();

  __m512i _mm512_div_epi8(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_div_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm512_div_epi8Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_div_epi8');
  late final __mm512_div_epi8 =
      __mm512_div_epi8Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_div_epi16(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_div_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm512_div_epi16Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_div_epi16');
  late final __mm512_div_epi16 =
      __mm512_div_epi16Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_div_epi32(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_div_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_div_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_div_epi32');
  late final __mm512_div_epi32 =
      __mm512_div_epi32Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_div_epi64(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_div_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm512_div_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_div_epi64');
  late final __mm512_div_epi64 =
      __mm512_div_epi64Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_div_epu8(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_div_epu8(
      arg0,
      arg1,
    );
  }

  late final __mm512_div_epu8Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_div_epu8');
  late final __mm512_div_epu8 =
      __mm512_div_epu8Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_div_epu16(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_div_epu16(
      arg0,
      arg1,
    );
  }

  late final __mm512_div_epu16Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_div_epu16');
  late final __mm512_div_epu16 =
      __mm512_div_epu16Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_div_epu32(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_div_epu32(
      arg0,
      arg1,
    );
  }

  late final __mm512_div_epu32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_div_epu32');
  late final __mm512_div_epu32 =
      __mm512_div_epu32Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_div_epu64(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_div_epu64(
      arg0,
      arg1,
    );
  }

  late final __mm512_div_epu64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_div_epu64');
  late final __mm512_div_epu64 =
      __mm512_div_epu64Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_div_epi32(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_div_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_div_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask16, __m512i, __m512i)>>('_mm512_mask_div_epi32');
  late final __mm512_mask_div_epi32 = __mm512_mask_div_epi32Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_mask_div_epu32(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_div_epu32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_div_epu32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask16, __m512i, __m512i)>>('_mm512_mask_div_epu32');
  late final __mm512_mask_div_epu32 = __mm512_mask_div_epu32Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_rem_epi8(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_rem_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm512_rem_epi8Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_rem_epi8');
  late final __mm512_rem_epi8 =
      __mm512_rem_epi8Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_rem_epi16(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_rem_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm512_rem_epi16Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_rem_epi16');
  late final __mm512_rem_epi16 =
      __mm512_rem_epi16Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_rem_epi32(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_rem_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_rem_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_rem_epi32');
  late final __mm512_rem_epi32 =
      __mm512_rem_epi32Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_rem_epi64(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_rem_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm512_rem_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_rem_epi64');
  late final __mm512_rem_epi64 =
      __mm512_rem_epi64Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_rem_epu8(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_rem_epu8(
      arg0,
      arg1,
    );
  }

  late final __mm512_rem_epu8Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_rem_epu8');
  late final __mm512_rem_epu8 =
      __mm512_rem_epu8Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_rem_epu16(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_rem_epu16(
      arg0,
      arg1,
    );
  }

  late final __mm512_rem_epu16Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_rem_epu16');
  late final __mm512_rem_epu16 =
      __mm512_rem_epu16Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_rem_epu32(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_rem_epu32(
      arg0,
      arg1,
    );
  }

  late final __mm512_rem_epu32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_rem_epu32');
  late final __mm512_rem_epu32 =
      __mm512_rem_epu32Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_rem_epu64(
    __m512i arg0,
    __m512i arg1,
  ) {
    return __mm512_rem_epu64(
      arg0,
      arg1,
    );
  }

  late final __mm512_rem_epu64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __m512i)>>(
          '_mm512_rem_epu64');
  late final __mm512_rem_epu64 =
      __mm512_rem_epu64Ptr.asFunction<__m512i Function(__m512i, __m512i)>();

  __m512i _mm512_mask_rem_epi32(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_rem_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_rem_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask16, __m512i, __m512i)>>('_mm512_mask_rem_epi32');
  late final __mm512_mask_rem_epi32 = __mm512_mask_rem_epi32Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512i _mm512_mask_rem_epu32(
    __m512i arg0,
    int arg1,
    __m512i arg2,
    __m512i arg3,
  ) {
    return __mm512_mask_rem_epu32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_rem_epu32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(
              __m512i, __mmask16, __m512i, __m512i)>>('_mm512_mask_rem_epu32');
  late final __mm512_mask_rem_epu32 = __mm512_mask_rem_epu32Ptr
      .asFunction<__m512i Function(__m512i, int, __m512i, __m512i)>();

  __m512 _mm512_sin_ps(
    __m512 arg0,
  ) {
    return __mm512_sin_ps(
      arg0,
    );
  }

  late final __mm512_sin_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512)>>('_mm512_sin_ps');
  late final __mm512_sin_ps =
      __mm512_sin_psPtr.asFunction<__m512 Function(__m512)>();

  __m512 _mm512_mask_sin_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
  ) {
    return __mm512_mask_sin_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_sin_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __mmask16, __m512)>>(
          '_mm512_mask_sin_ps');
  late final __mm512_mask_sin_ps =
      __mm512_mask_sin_psPtr.asFunction<__m512 Function(__m512, int, __m512)>();

  _m512d _mm512_sin_pd(
    _m512d arg0,
  ) {
    return __mm512_sin_pd(
      arg0,
    );
  }

  late final __mm512_sin_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d)>>('_mm512_sin_pd');
  late final __mm512_sin_pd =
      __mm512_sin_pdPtr.asFunction<_m512d Function(_m512d)>();

  _m512d _mm512_mask_sin_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
  ) {
    return __mm512_mask_sin_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_sin_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, __mmask8, _m512d)>>(
          '_mm512_mask_sin_pd');
  late final __mm512_mask_sin_pd =
      __mm512_mask_sin_pdPtr.asFunction<_m512d Function(_m512d, int, _m512d)>();

  __m512 _mm512_cos_ps(
    __m512 arg0,
  ) {
    return __mm512_cos_ps(
      arg0,
    );
  }

  late final __mm512_cos_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512)>>('_mm512_cos_ps');
  late final __mm512_cos_ps =
      __mm512_cos_psPtr.asFunction<__m512 Function(__m512)>();

  __m512 _mm512_mask_cos_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
  ) {
    return __mm512_mask_cos_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cos_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __mmask16, __m512)>>(
          '_mm512_mask_cos_ps');
  late final __mm512_mask_cos_ps =
      __mm512_mask_cos_psPtr.asFunction<__m512 Function(__m512, int, __m512)>();

  _m512d _mm512_cos_pd(
    _m512d arg0,
  ) {
    return __mm512_cos_pd(
      arg0,
    );
  }

  late final __mm512_cos_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d)>>('_mm512_cos_pd');
  late final __mm512_cos_pd =
      __mm512_cos_pdPtr.asFunction<_m512d Function(_m512d)>();

  _m512d _mm512_mask_cos_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
  ) {
    return __mm512_mask_cos_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cos_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, __mmask8, _m512d)>>(
          '_mm512_mask_cos_pd');
  late final __mm512_mask_cos_pd =
      __mm512_mask_cos_pdPtr.asFunction<_m512d Function(_m512d, int, _m512d)>();

  __m512 _mm512_sincos_ps(
    ffi.Pointer<__m512> arg0,
    __m512 arg1,
  ) {
    return __mm512_sincos_ps(
      arg0,
      arg1,
    );
  }

  late final __mm512_sincos_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(ffi.Pointer<__m512>, __m512)>>(
          '_mm512_sincos_ps');
  late final __mm512_sincos_ps = __mm512_sincos_psPtr
      .asFunction<__m512 Function(ffi.Pointer<__m512>, __m512)>();

  __m512 _mm512_mask_sincos_ps(
    ffi.Pointer<__m512> arg0,
    __m512 arg1,
    __m512 arg2,
    int arg3,
    __m512 arg4,
  ) {
    return __mm512_mask_sincos_ps(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_sincos_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(ffi.Pointer<__m512>, __m512, __m512, __mmask16,
              __m512)>>('_mm512_mask_sincos_ps');
  late final __mm512_mask_sincos_ps = __mm512_mask_sincos_psPtr.asFunction<
      __m512 Function(ffi.Pointer<__m512>, __m512, __m512, int, __m512)>();

  _m512d _mm512_sincos_pd(
    ffi.Pointer<_m512d> arg0,
    _m512d arg1,
  ) {
    return __mm512_sincos_pd(
      arg0,
      arg1,
    );
  }

  late final __mm512_sincos_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(ffi.Pointer<_m512d>, _m512d)>>(
          '_mm512_sincos_pd');
  late final __mm512_sincos_pd = __mm512_sincos_pdPtr
      .asFunction<_m512d Function(ffi.Pointer<_m512d>, _m512d)>();

  _m512d _mm512_mask_sincos_pd(
    ffi.Pointer<_m512d> arg0,
    _m512d arg1,
    _m512d arg2,
    int arg3,
    _m512d arg4,
  ) {
    return __mm512_mask_sincos_pd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_sincos_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(ffi.Pointer<_m512d>, _m512d, _m512d, __mmask8,
              _m512d)>>('_mm512_mask_sincos_pd');
  late final __mm512_mask_sincos_pd = __mm512_mask_sincos_pdPtr.asFunction<
      _m512d Function(ffi.Pointer<_m512d>, _m512d, _m512d, int, _m512d)>();

  __m512 _mm512_tan_ps(
    __m512 arg0,
  ) {
    return __mm512_tan_ps(
      arg0,
    );
  }

  late final __mm512_tan_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512)>>('_mm512_tan_ps');
  late final __mm512_tan_ps =
      __mm512_tan_psPtr.asFunction<__m512 Function(__m512)>();

  __m512 _mm512_mask_tan_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
  ) {
    return __mm512_mask_tan_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_tan_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __mmask16, __m512)>>(
          '_mm512_mask_tan_ps');
  late final __mm512_mask_tan_ps =
      __mm512_mask_tan_psPtr.asFunction<__m512 Function(__m512, int, __m512)>();

  _m512d _mm512_tan_pd(
    _m512d arg0,
  ) {
    return __mm512_tan_pd(
      arg0,
    );
  }

  late final __mm512_tan_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d)>>('_mm512_tan_pd');
  late final __mm512_tan_pd =
      __mm512_tan_pdPtr.asFunction<_m512d Function(_m512d)>();

  _m512d _mm512_mask_tan_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
  ) {
    return __mm512_mask_tan_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_tan_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, __mmask8, _m512d)>>(
          '_mm512_mask_tan_pd');
  late final __mm512_mask_tan_pd =
      __mm512_mask_tan_pdPtr.asFunction<_m512d Function(_m512d, int, _m512d)>();

  __m512 _mm512_asin_ps(
    __m512 arg0,
  ) {
    return __mm512_asin_ps(
      arg0,
    );
  }

  late final __mm512_asin_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512)>>('_mm512_asin_ps');
  late final __mm512_asin_ps =
      __mm512_asin_psPtr.asFunction<__m512 Function(__m512)>();

  __m512 _mm512_mask_asin_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
  ) {
    return __mm512_mask_asin_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_asin_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __mmask16, __m512)>>(
          '_mm512_mask_asin_ps');
  late final __mm512_mask_asin_ps = __mm512_mask_asin_psPtr
      .asFunction<__m512 Function(__m512, int, __m512)>();

  _m512d _mm512_asin_pd(
    _m512d arg0,
  ) {
    return __mm512_asin_pd(
      arg0,
    );
  }

  late final __mm512_asin_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d)>>('_mm512_asin_pd');
  late final __mm512_asin_pd =
      __mm512_asin_pdPtr.asFunction<_m512d Function(_m512d)>();

  _m512d _mm512_mask_asin_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
  ) {
    return __mm512_mask_asin_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_asin_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, __mmask8, _m512d)>>(
          '_mm512_mask_asin_pd');
  late final __mm512_mask_asin_pd = __mm512_mask_asin_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d)>();

  __m512 _mm512_acos_ps(
    __m512 arg0,
  ) {
    return __mm512_acos_ps(
      arg0,
    );
  }

  late final __mm512_acos_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512)>>('_mm512_acos_ps');
  late final __mm512_acos_ps =
      __mm512_acos_psPtr.asFunction<__m512 Function(__m512)>();

  __m512 _mm512_mask_acos_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
  ) {
    return __mm512_mask_acos_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_acos_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __mmask16, __m512)>>(
          '_mm512_mask_acos_ps');
  late final __mm512_mask_acos_ps = __mm512_mask_acos_psPtr
      .asFunction<__m512 Function(__m512, int, __m512)>();

  _m512d _mm512_acos_pd(
    _m512d arg0,
  ) {
    return __mm512_acos_pd(
      arg0,
    );
  }

  late final __mm512_acos_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d)>>('_mm512_acos_pd');
  late final __mm512_acos_pd =
      __mm512_acos_pdPtr.asFunction<_m512d Function(_m512d)>();

  _m512d _mm512_mask_acos_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
  ) {
    return __mm512_mask_acos_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_acos_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, __mmask8, _m512d)>>(
          '_mm512_mask_acos_pd');
  late final __mm512_mask_acos_pd = __mm512_mask_acos_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d)>();

  __m512 _mm512_atan_ps(
    __m512 arg0,
  ) {
    return __mm512_atan_ps(
      arg0,
    );
  }

  late final __mm512_atan_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512)>>('_mm512_atan_ps');
  late final __mm512_atan_ps =
      __mm512_atan_psPtr.asFunction<__m512 Function(__m512)>();

  __m512 _mm512_mask_atan_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
  ) {
    return __mm512_mask_atan_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_atan_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __mmask16, __m512)>>(
          '_mm512_mask_atan_ps');
  late final __mm512_mask_atan_ps = __mm512_mask_atan_psPtr
      .asFunction<__m512 Function(__m512, int, __m512)>();

  _m512d _mm512_atan_pd(
    _m512d arg0,
  ) {
    return __mm512_atan_pd(
      arg0,
    );
  }

  late final __mm512_atan_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d)>>('_mm512_atan_pd');
  late final __mm512_atan_pd =
      __mm512_atan_pdPtr.asFunction<_m512d Function(_m512d)>();

  _m512d _mm512_mask_atan_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
  ) {
    return __mm512_mask_atan_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_atan_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, __mmask8, _m512d)>>(
          '_mm512_mask_atan_pd');
  late final __mm512_mask_atan_pd = __mm512_mask_atan_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d)>();

  __m512 _mm512_atan2_ps(
    __m512 arg0,
    __m512 arg1,
  ) {
    return __mm512_atan2_ps(
      arg0,
      arg1,
    );
  }

  late final __mm512_atan2_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __m512)>>(
          '_mm512_atan2_ps');
  late final __mm512_atan2_ps =
      __mm512_atan2_psPtr.asFunction<__m512 Function(__m512, __m512)>();

  __m512 _mm512_mask_atan2_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
    __m512 arg3,
  ) {
    return __mm512_mask_atan2_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_atan2_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(
              __m512, __mmask16, __m512, __m512)>>('_mm512_mask_atan2_ps');
  late final __mm512_mask_atan2_ps = __mm512_mask_atan2_psPtr
      .asFunction<__m512 Function(__m512, int, __m512, __m512)>();

  _m512d _mm512_atan2_pd(
    _m512d arg0,
    _m512d arg1,
  ) {
    return __mm512_atan2_pd(
      arg0,
      arg1,
    );
  }

  late final __mm512_atan2_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, _m512d)>>(
          '_mm512_atan2_pd');
  late final __mm512_atan2_pd =
      __mm512_atan2_pdPtr.asFunction<_m512d Function(_m512d, _m512d)>();

  _m512d _mm512_mask_atan2_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
    _m512d arg3,
  ) {
    return __mm512_mask_atan2_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_atan2_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(
              _m512d, __mmask8, _m512d, _m512d)>>('_mm512_mask_atan2_pd');
  late final __mm512_mask_atan2_pd = __mm512_mask_atan2_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d, _m512d)>();

  __m512 _mm512_sind_ps(
    __m512 arg0,
  ) {
    return __mm512_sind_ps(
      arg0,
    );
  }

  late final __mm512_sind_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512)>>('_mm512_sind_ps');
  late final __mm512_sind_ps =
      __mm512_sind_psPtr.asFunction<__m512 Function(__m512)>();

  __m512 _mm512_mask_sind_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
  ) {
    return __mm512_mask_sind_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_sind_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __mmask16, __m512)>>(
          '_mm512_mask_sind_ps');
  late final __mm512_mask_sind_ps = __mm512_mask_sind_psPtr
      .asFunction<__m512 Function(__m512, int, __m512)>();

  _m512d _mm512_sind_pd(
    _m512d arg0,
  ) {
    return __mm512_sind_pd(
      arg0,
    );
  }

  late final __mm512_sind_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d)>>('_mm512_sind_pd');
  late final __mm512_sind_pd =
      __mm512_sind_pdPtr.asFunction<_m512d Function(_m512d)>();

  _m512d _mm512_mask_sind_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
  ) {
    return __mm512_mask_sind_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_sind_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, __mmask8, _m512d)>>(
          '_mm512_mask_sind_pd');
  late final __mm512_mask_sind_pd = __mm512_mask_sind_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d)>();

  __m512 _mm512_cosd_ps(
    __m512 arg0,
  ) {
    return __mm512_cosd_ps(
      arg0,
    );
  }

  late final __mm512_cosd_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512)>>('_mm512_cosd_ps');
  late final __mm512_cosd_ps =
      __mm512_cosd_psPtr.asFunction<__m512 Function(__m512)>();

  __m512 _mm512_mask_cosd_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
  ) {
    return __mm512_mask_cosd_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cosd_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __mmask16, __m512)>>(
          '_mm512_mask_cosd_ps');
  late final __mm512_mask_cosd_ps = __mm512_mask_cosd_psPtr
      .asFunction<__m512 Function(__m512, int, __m512)>();

  _m512d _mm512_cosd_pd(
    _m512d arg0,
  ) {
    return __mm512_cosd_pd(
      arg0,
    );
  }

  late final __mm512_cosd_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d)>>('_mm512_cosd_pd');
  late final __mm512_cosd_pd =
      __mm512_cosd_pdPtr.asFunction<_m512d Function(_m512d)>();

  _m512d _mm512_mask_cosd_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
  ) {
    return __mm512_mask_cosd_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cosd_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, __mmask8, _m512d)>>(
          '_mm512_mask_cosd_pd');
  late final __mm512_mask_cosd_pd = __mm512_mask_cosd_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d)>();

  __m512 _mm512_tand_ps(
    __m512 arg0,
  ) {
    return __mm512_tand_ps(
      arg0,
    );
  }

  late final __mm512_tand_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512)>>('_mm512_tand_ps');
  late final __mm512_tand_ps =
      __mm512_tand_psPtr.asFunction<__m512 Function(__m512)>();

  __m512 _mm512_mask_tand_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
  ) {
    return __mm512_mask_tand_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_tand_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __mmask16, __m512)>>(
          '_mm512_mask_tand_ps');
  late final __mm512_mask_tand_ps = __mm512_mask_tand_psPtr
      .asFunction<__m512 Function(__m512, int, __m512)>();

  _m512d _mm512_tand_pd(
    _m512d arg0,
  ) {
    return __mm512_tand_pd(
      arg0,
    );
  }

  late final __mm512_tand_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d)>>('_mm512_tand_pd');
  late final __mm512_tand_pd =
      __mm512_tand_pdPtr.asFunction<_m512d Function(_m512d)>();

  _m512d _mm512_mask_tand_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
  ) {
    return __mm512_mask_tand_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_tand_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, __mmask8, _m512d)>>(
          '_mm512_mask_tand_pd');
  late final __mm512_mask_tand_pd = __mm512_mask_tand_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d)>();

  __m512 _mm512_sinh_ps(
    __m512 arg0,
  ) {
    return __mm512_sinh_ps(
      arg0,
    );
  }

  late final __mm512_sinh_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512)>>('_mm512_sinh_ps');
  late final __mm512_sinh_ps =
      __mm512_sinh_psPtr.asFunction<__m512 Function(__m512)>();

  __m512 _mm512_mask_sinh_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
  ) {
    return __mm512_mask_sinh_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_sinh_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __mmask16, __m512)>>(
          '_mm512_mask_sinh_ps');
  late final __mm512_mask_sinh_ps = __mm512_mask_sinh_psPtr
      .asFunction<__m512 Function(__m512, int, __m512)>();

  _m512d _mm512_sinh_pd(
    _m512d arg0,
  ) {
    return __mm512_sinh_pd(
      arg0,
    );
  }

  late final __mm512_sinh_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d)>>('_mm512_sinh_pd');
  late final __mm512_sinh_pd =
      __mm512_sinh_pdPtr.asFunction<_m512d Function(_m512d)>();

  _m512d _mm512_mask_sinh_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
  ) {
    return __mm512_mask_sinh_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_sinh_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, __mmask8, _m512d)>>(
          '_mm512_mask_sinh_pd');
  late final __mm512_mask_sinh_pd = __mm512_mask_sinh_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d)>();

  __m512 _mm512_cosh_ps(
    __m512 arg0,
  ) {
    return __mm512_cosh_ps(
      arg0,
    );
  }

  late final __mm512_cosh_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512)>>('_mm512_cosh_ps');
  late final __mm512_cosh_ps =
      __mm512_cosh_psPtr.asFunction<__m512 Function(__m512)>();

  __m512 _mm512_mask_cosh_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
  ) {
    return __mm512_mask_cosh_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cosh_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __mmask16, __m512)>>(
          '_mm512_mask_cosh_ps');
  late final __mm512_mask_cosh_ps = __mm512_mask_cosh_psPtr
      .asFunction<__m512 Function(__m512, int, __m512)>();

  _m512d _mm512_cosh_pd(
    _m512d arg0,
  ) {
    return __mm512_cosh_pd(
      arg0,
    );
  }

  late final __mm512_cosh_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d)>>('_mm512_cosh_pd');
  late final __mm512_cosh_pd =
      __mm512_cosh_pdPtr.asFunction<_m512d Function(_m512d)>();

  _m512d _mm512_mask_cosh_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
  ) {
    return __mm512_mask_cosh_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cosh_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, __mmask8, _m512d)>>(
          '_mm512_mask_cosh_pd');
  late final __mm512_mask_cosh_pd = __mm512_mask_cosh_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d)>();

  __m512 _mm512_tanh_ps(
    __m512 arg0,
  ) {
    return __mm512_tanh_ps(
      arg0,
    );
  }

  late final __mm512_tanh_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512)>>('_mm512_tanh_ps');
  late final __mm512_tanh_ps =
      __mm512_tanh_psPtr.asFunction<__m512 Function(__m512)>();

  __m512 _mm512_mask_tanh_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
  ) {
    return __mm512_mask_tanh_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_tanh_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __mmask16, __m512)>>(
          '_mm512_mask_tanh_ps');
  late final __mm512_mask_tanh_ps = __mm512_mask_tanh_psPtr
      .asFunction<__m512 Function(__m512, int, __m512)>();

  _m512d _mm512_tanh_pd(
    _m512d arg0,
  ) {
    return __mm512_tanh_pd(
      arg0,
    );
  }

  late final __mm512_tanh_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d)>>('_mm512_tanh_pd');
  late final __mm512_tanh_pd =
      __mm512_tanh_pdPtr.asFunction<_m512d Function(_m512d)>();

  _m512d _mm512_mask_tanh_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
  ) {
    return __mm512_mask_tanh_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_tanh_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, __mmask8, _m512d)>>(
          '_mm512_mask_tanh_pd');
  late final __mm512_mask_tanh_pd = __mm512_mask_tanh_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d)>();

  __m512 _mm512_asinh_ps(
    __m512 arg0,
  ) {
    return __mm512_asinh_ps(
      arg0,
    );
  }

  late final __mm512_asinh_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512)>>('_mm512_asinh_ps');
  late final __mm512_asinh_ps =
      __mm512_asinh_psPtr.asFunction<__m512 Function(__m512)>();

  __m512 _mm512_mask_asinh_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
  ) {
    return __mm512_mask_asinh_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_asinh_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __mmask16, __m512)>>(
          '_mm512_mask_asinh_ps');
  late final __mm512_mask_asinh_ps = __mm512_mask_asinh_psPtr
      .asFunction<__m512 Function(__m512, int, __m512)>();

  _m512d _mm512_asinh_pd(
    _m512d arg0,
  ) {
    return __mm512_asinh_pd(
      arg0,
    );
  }

  late final __mm512_asinh_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d)>>('_mm512_asinh_pd');
  late final __mm512_asinh_pd =
      __mm512_asinh_pdPtr.asFunction<_m512d Function(_m512d)>();

  _m512d _mm512_mask_asinh_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
  ) {
    return __mm512_mask_asinh_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_asinh_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, __mmask8, _m512d)>>(
          '_mm512_mask_asinh_pd');
  late final __mm512_mask_asinh_pd = __mm512_mask_asinh_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d)>();

  __m512 _mm512_acosh_ps(
    __m512 arg0,
  ) {
    return __mm512_acosh_ps(
      arg0,
    );
  }

  late final __mm512_acosh_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512)>>('_mm512_acosh_ps');
  late final __mm512_acosh_ps =
      __mm512_acosh_psPtr.asFunction<__m512 Function(__m512)>();

  __m512 _mm512_mask_acosh_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
  ) {
    return __mm512_mask_acosh_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_acosh_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __mmask16, __m512)>>(
          '_mm512_mask_acosh_ps');
  late final __mm512_mask_acosh_ps = __mm512_mask_acosh_psPtr
      .asFunction<__m512 Function(__m512, int, __m512)>();

  _m512d _mm512_acosh_pd(
    _m512d arg0,
  ) {
    return __mm512_acosh_pd(
      arg0,
    );
  }

  late final __mm512_acosh_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d)>>('_mm512_acosh_pd');
  late final __mm512_acosh_pd =
      __mm512_acosh_pdPtr.asFunction<_m512d Function(_m512d)>();

  _m512d _mm512_mask_acosh_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
  ) {
    return __mm512_mask_acosh_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_acosh_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, __mmask8, _m512d)>>(
          '_mm512_mask_acosh_pd');
  late final __mm512_mask_acosh_pd = __mm512_mask_acosh_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d)>();

  __m512 _mm512_atanh_ps(
    __m512 arg0,
  ) {
    return __mm512_atanh_ps(
      arg0,
    );
  }

  late final __mm512_atanh_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512)>>('_mm512_atanh_ps');
  late final __mm512_atanh_ps =
      __mm512_atanh_psPtr.asFunction<__m512 Function(__m512)>();

  __m512 _mm512_mask_atanh_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
  ) {
    return __mm512_mask_atanh_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_atanh_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __mmask16, __m512)>>(
          '_mm512_mask_atanh_ps');
  late final __mm512_mask_atanh_ps = __mm512_mask_atanh_psPtr
      .asFunction<__m512 Function(__m512, int, __m512)>();

  _m512d _mm512_atanh_pd(
    _m512d arg0,
  ) {
    return __mm512_atanh_pd(
      arg0,
    );
  }

  late final __mm512_atanh_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d)>>('_mm512_atanh_pd');
  late final __mm512_atanh_pd =
      __mm512_atanh_pdPtr.asFunction<_m512d Function(_m512d)>();

  _m512d _mm512_mask_atanh_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
  ) {
    return __mm512_mask_atanh_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_atanh_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, __mmask8, _m512d)>>(
          '_mm512_mask_atanh_pd');
  late final __mm512_mask_atanh_pd = __mm512_mask_atanh_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d)>();

  __m512 _mm512_log_ps(
    __m512 arg0,
  ) {
    return __mm512_log_ps(
      arg0,
    );
  }

  late final __mm512_log_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512)>>('_mm512_log_ps');
  late final __mm512_log_ps =
      __mm512_log_psPtr.asFunction<__m512 Function(__m512)>();

  __m512 _mm512_mask_log_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
  ) {
    return __mm512_mask_log_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_log_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __mmask16, __m512)>>(
          '_mm512_mask_log_ps');
  late final __mm512_mask_log_ps =
      __mm512_mask_log_psPtr.asFunction<__m512 Function(__m512, int, __m512)>();

  _m512d _mm512_log_pd(
    _m512d arg0,
  ) {
    return __mm512_log_pd(
      arg0,
    );
  }

  late final __mm512_log_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d)>>('_mm512_log_pd');
  late final __mm512_log_pd =
      __mm512_log_pdPtr.asFunction<_m512d Function(_m512d)>();

  _m512d _mm512_mask_log_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
  ) {
    return __mm512_mask_log_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_log_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, __mmask8, _m512d)>>(
          '_mm512_mask_log_pd');
  late final __mm512_mask_log_pd =
      __mm512_mask_log_pdPtr.asFunction<_m512d Function(_m512d, int, _m512d)>();

  __m512 _mm512_log1p_ps(
    __m512 arg0,
  ) {
    return __mm512_log1p_ps(
      arg0,
    );
  }

  late final __mm512_log1p_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512)>>('_mm512_log1p_ps');
  late final __mm512_log1p_ps =
      __mm512_log1p_psPtr.asFunction<__m512 Function(__m512)>();

  __m512 _mm512_mask_log1p_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
  ) {
    return __mm512_mask_log1p_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_log1p_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __mmask16, __m512)>>(
          '_mm512_mask_log1p_ps');
  late final __mm512_mask_log1p_ps = __mm512_mask_log1p_psPtr
      .asFunction<__m512 Function(__m512, int, __m512)>();

  _m512d _mm512_log1p_pd(
    _m512d arg0,
  ) {
    return __mm512_log1p_pd(
      arg0,
    );
  }

  late final __mm512_log1p_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d)>>('_mm512_log1p_pd');
  late final __mm512_log1p_pd =
      __mm512_log1p_pdPtr.asFunction<_m512d Function(_m512d)>();

  _m512d _mm512_mask_log1p_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
  ) {
    return __mm512_mask_log1p_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_log1p_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, __mmask8, _m512d)>>(
          '_mm512_mask_log1p_pd');
  late final __mm512_mask_log1p_pd = __mm512_mask_log1p_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d)>();

  __m512 _mm512_log10_ps(
    __m512 arg0,
  ) {
    return __mm512_log10_ps(
      arg0,
    );
  }

  late final __mm512_log10_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512)>>('_mm512_log10_ps');
  late final __mm512_log10_ps =
      __mm512_log10_psPtr.asFunction<__m512 Function(__m512)>();

  __m512 _mm512_mask_log10_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
  ) {
    return __mm512_mask_log10_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_log10_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __mmask16, __m512)>>(
          '_mm512_mask_log10_ps');
  late final __mm512_mask_log10_ps = __mm512_mask_log10_psPtr
      .asFunction<__m512 Function(__m512, int, __m512)>();

  _m512d _mm512_log10_pd(
    _m512d arg0,
  ) {
    return __mm512_log10_pd(
      arg0,
    );
  }

  late final __mm512_log10_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d)>>('_mm512_log10_pd');
  late final __mm512_log10_pd =
      __mm512_log10_pdPtr.asFunction<_m512d Function(_m512d)>();

  _m512d _mm512_mask_log10_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
  ) {
    return __mm512_mask_log10_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_log10_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, __mmask8, _m512d)>>(
          '_mm512_mask_log10_pd');
  late final __mm512_mask_log10_pd = __mm512_mask_log10_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d)>();

  __m512 _mm512_log2_ps(
    __m512 arg0,
  ) {
    return __mm512_log2_ps(
      arg0,
    );
  }

  late final __mm512_log2_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512)>>('_mm512_log2_ps');
  late final __mm512_log2_ps =
      __mm512_log2_psPtr.asFunction<__m512 Function(__m512)>();

  __m512 _mm512_mask_log2_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
  ) {
    return __mm512_mask_log2_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_log2_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __mmask16, __m512)>>(
          '_mm512_mask_log2_ps');
  late final __mm512_mask_log2_ps = __mm512_mask_log2_psPtr
      .asFunction<__m512 Function(__m512, int, __m512)>();

  _m512d _mm512_log2_pd(
    _m512d arg0,
  ) {
    return __mm512_log2_pd(
      arg0,
    );
  }

  late final __mm512_log2_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d)>>('_mm512_log2_pd');
  late final __mm512_log2_pd =
      __mm512_log2_pdPtr.asFunction<_m512d Function(_m512d)>();

  _m512d _mm512_mask_log2_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
  ) {
    return __mm512_mask_log2_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_log2_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, __mmask8, _m512d)>>(
          '_mm512_mask_log2_pd');
  late final __mm512_mask_log2_pd = __mm512_mask_log2_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d)>();

  __m512 _mm512_logb_ps(
    __m512 arg0,
  ) {
    return __mm512_logb_ps(
      arg0,
    );
  }

  late final __mm512_logb_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512)>>('_mm512_logb_ps');
  late final __mm512_logb_ps =
      __mm512_logb_psPtr.asFunction<__m512 Function(__m512)>();

  __m512 _mm512_mask_logb_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
  ) {
    return __mm512_mask_logb_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_logb_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __mmask16, __m512)>>(
          '_mm512_mask_logb_ps');
  late final __mm512_mask_logb_ps = __mm512_mask_logb_psPtr
      .asFunction<__m512 Function(__m512, int, __m512)>();

  _m512d _mm512_logb_pd(
    _m512d arg0,
  ) {
    return __mm512_logb_pd(
      arg0,
    );
  }

  late final __mm512_logb_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d)>>('_mm512_logb_pd');
  late final __mm512_logb_pd =
      __mm512_logb_pdPtr.asFunction<_m512d Function(_m512d)>();

  _m512d _mm512_mask_logb_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
  ) {
    return __mm512_mask_logb_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_logb_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, __mmask8, _m512d)>>(
          '_mm512_mask_logb_pd');
  late final __mm512_mask_logb_pd = __mm512_mask_logb_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d)>();

  __m512 _mm512_exp_ps(
    __m512 arg0,
  ) {
    return __mm512_exp_ps(
      arg0,
    );
  }

  late final __mm512_exp_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512)>>('_mm512_exp_ps');
  late final __mm512_exp_ps =
      __mm512_exp_psPtr.asFunction<__m512 Function(__m512)>();

  __m512 _mm512_mask_exp_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
  ) {
    return __mm512_mask_exp_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_exp_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __mmask16, __m512)>>(
          '_mm512_mask_exp_ps');
  late final __mm512_mask_exp_ps =
      __mm512_mask_exp_psPtr.asFunction<__m512 Function(__m512, int, __m512)>();

  _m512d _mm512_exp_pd(
    _m512d arg0,
  ) {
    return __mm512_exp_pd(
      arg0,
    );
  }

  late final __mm512_exp_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d)>>('_mm512_exp_pd');
  late final __mm512_exp_pd =
      __mm512_exp_pdPtr.asFunction<_m512d Function(_m512d)>();

  _m512d _mm512_mask_exp_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
  ) {
    return __mm512_mask_exp_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_exp_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, __mmask8, _m512d)>>(
          '_mm512_mask_exp_pd');
  late final __mm512_mask_exp_pd =
      __mm512_mask_exp_pdPtr.asFunction<_m512d Function(_m512d, int, _m512d)>();

  __m512 _mm512_exp10_ps(
    __m512 arg0,
  ) {
    return __mm512_exp10_ps(
      arg0,
    );
  }

  late final __mm512_exp10_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512)>>('_mm512_exp10_ps');
  late final __mm512_exp10_ps =
      __mm512_exp10_psPtr.asFunction<__m512 Function(__m512)>();

  __m512 _mm512_mask_exp10_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
  ) {
    return __mm512_mask_exp10_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_exp10_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __mmask16, __m512)>>(
          '_mm512_mask_exp10_ps');
  late final __mm512_mask_exp10_ps = __mm512_mask_exp10_psPtr
      .asFunction<__m512 Function(__m512, int, __m512)>();

  _m512d _mm512_exp10_pd(
    _m512d arg0,
  ) {
    return __mm512_exp10_pd(
      arg0,
    );
  }

  late final __mm512_exp10_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d)>>('_mm512_exp10_pd');
  late final __mm512_exp10_pd =
      __mm512_exp10_pdPtr.asFunction<_m512d Function(_m512d)>();

  _m512d _mm512_mask_exp10_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
  ) {
    return __mm512_mask_exp10_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_exp10_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, __mmask8, _m512d)>>(
          '_mm512_mask_exp10_pd');
  late final __mm512_mask_exp10_pd = __mm512_mask_exp10_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d)>();

  __m512 _mm512_exp2_ps(
    __m512 arg0,
  ) {
    return __mm512_exp2_ps(
      arg0,
    );
  }

  late final __mm512_exp2_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512)>>('_mm512_exp2_ps');
  late final __mm512_exp2_ps =
      __mm512_exp2_psPtr.asFunction<__m512 Function(__m512)>();

  __m512 _mm512_mask_exp2_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
  ) {
    return __mm512_mask_exp2_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_exp2_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __mmask16, __m512)>>(
          '_mm512_mask_exp2_ps');
  late final __mm512_mask_exp2_ps = __mm512_mask_exp2_psPtr
      .asFunction<__m512 Function(__m512, int, __m512)>();

  _m512d _mm512_exp2_pd(
    _m512d arg0,
  ) {
    return __mm512_exp2_pd(
      arg0,
    );
  }

  late final __mm512_exp2_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d)>>('_mm512_exp2_pd');
  late final __mm512_exp2_pd =
      __mm512_exp2_pdPtr.asFunction<_m512d Function(_m512d)>();

  _m512d _mm512_mask_exp2_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
  ) {
    return __mm512_mask_exp2_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_exp2_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, __mmask8, _m512d)>>(
          '_mm512_mask_exp2_pd');
  late final __mm512_mask_exp2_pd = __mm512_mask_exp2_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d)>();

  __m512 _mm512_expm1_ps(
    __m512 arg0,
  ) {
    return __mm512_expm1_ps(
      arg0,
    );
  }

  late final __mm512_expm1_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512)>>('_mm512_expm1_ps');
  late final __mm512_expm1_ps =
      __mm512_expm1_psPtr.asFunction<__m512 Function(__m512)>();

  __m512 _mm512_mask_expm1_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
  ) {
    return __mm512_mask_expm1_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_expm1_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __mmask16, __m512)>>(
          '_mm512_mask_expm1_ps');
  late final __mm512_mask_expm1_ps = __mm512_mask_expm1_psPtr
      .asFunction<__m512 Function(__m512, int, __m512)>();

  _m512d _mm512_expm1_pd(
    _m512d arg0,
  ) {
    return __mm512_expm1_pd(
      arg0,
    );
  }

  late final __mm512_expm1_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d)>>('_mm512_expm1_pd');
  late final __mm512_expm1_pd =
      __mm512_expm1_pdPtr.asFunction<_m512d Function(_m512d)>();

  _m512d _mm512_mask_expm1_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
  ) {
    return __mm512_mask_expm1_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_expm1_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, __mmask8, _m512d)>>(
          '_mm512_mask_expm1_pd');
  late final __mm512_mask_expm1_pd = __mm512_mask_expm1_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d)>();

  __m512 _mm512_pow_ps(
    __m512 arg0,
    __m512 arg1,
  ) {
    return __mm512_pow_ps(
      arg0,
      arg1,
    );
  }

  late final __mm512_pow_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __m512)>>(
          '_mm512_pow_ps');
  late final __mm512_pow_ps =
      __mm512_pow_psPtr.asFunction<__m512 Function(__m512, __m512)>();

  __m512 _mm512_mask_pow_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
    __m512 arg3,
  ) {
    return __mm512_mask_pow_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_pow_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(
              __m512, __mmask16, __m512, __m512)>>('_mm512_mask_pow_ps');
  late final __mm512_mask_pow_ps = __mm512_mask_pow_psPtr
      .asFunction<__m512 Function(__m512, int, __m512, __m512)>();

  _m512d _mm512_pow_pd(
    _m512d arg0,
    _m512d arg1,
  ) {
    return __mm512_pow_pd(
      arg0,
      arg1,
    );
  }

  late final __mm512_pow_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, _m512d)>>(
          '_mm512_pow_pd');
  late final __mm512_pow_pd =
      __mm512_pow_pdPtr.asFunction<_m512d Function(_m512d, _m512d)>();

  _m512d _mm512_mask_pow_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
    _m512d arg3,
  ) {
    return __mm512_mask_pow_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_pow_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(
              _m512d, __mmask8, _m512d, _m512d)>>('_mm512_mask_pow_pd');
  late final __mm512_mask_pow_pd = __mm512_mask_pow_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d, _m512d)>();

  __m512 _mm512_trunc_ps(
    __m512 arg0,
  ) {
    return __mm512_trunc_ps(
      arg0,
    );
  }

  late final __mm512_trunc_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512)>>('_mm512_trunc_ps');
  late final __mm512_trunc_ps =
      __mm512_trunc_psPtr.asFunction<__m512 Function(__m512)>();

  __m512 _mm512_mask_trunc_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
  ) {
    return __mm512_mask_trunc_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_trunc_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __mmask16, __m512)>>(
          '_mm512_mask_trunc_ps');
  late final __mm512_mask_trunc_ps = __mm512_mask_trunc_psPtr
      .asFunction<__m512 Function(__m512, int, __m512)>();

  _m512d _mm512_trunc_pd(
    _m512d arg0,
  ) {
    return __mm512_trunc_pd(
      arg0,
    );
  }

  late final __mm512_trunc_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d)>>('_mm512_trunc_pd');
  late final __mm512_trunc_pd =
      __mm512_trunc_pdPtr.asFunction<_m512d Function(_m512d)>();

  _m512d _mm512_mask_trunc_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
  ) {
    return __mm512_mask_trunc_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_trunc_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, __mmask8, _m512d)>>(
          '_mm512_mask_trunc_pd');
  late final __mm512_mask_trunc_pd = __mm512_mask_trunc_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d)>();

  __m512 _mm512_floor_ps(
    __m512 arg0,
  ) {
    return __mm512_floor_ps(
      arg0,
    );
  }

  late final __mm512_floor_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512)>>('_mm512_floor_ps');
  late final __mm512_floor_ps =
      __mm512_floor_psPtr.asFunction<__m512 Function(__m512)>();

  __m512 _mm512_mask_floor_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
  ) {
    return __mm512_mask_floor_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_floor_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __mmask16, __m512)>>(
          '_mm512_mask_floor_ps');
  late final __mm512_mask_floor_ps = __mm512_mask_floor_psPtr
      .asFunction<__m512 Function(__m512, int, __m512)>();

  _m512d _mm512_floor_pd(
    _m512d arg0,
  ) {
    return __mm512_floor_pd(
      arg0,
    );
  }

  late final __mm512_floor_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d)>>('_mm512_floor_pd');
  late final __mm512_floor_pd =
      __mm512_floor_pdPtr.asFunction<_m512d Function(_m512d)>();

  _m512d _mm512_mask_floor_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
  ) {
    return __mm512_mask_floor_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_floor_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, __mmask8, _m512d)>>(
          '_mm512_mask_floor_pd');
  late final __mm512_mask_floor_pd = __mm512_mask_floor_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d)>();

  __m512 _mm512_ceil_ps(
    __m512 arg0,
  ) {
    return __mm512_ceil_ps(
      arg0,
    );
  }

  late final __mm512_ceil_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512)>>('_mm512_ceil_ps');
  late final __mm512_ceil_ps =
      __mm512_ceil_psPtr.asFunction<__m512 Function(__m512)>();

  __m512 _mm512_mask_ceil_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
  ) {
    return __mm512_mask_ceil_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_ceil_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __mmask16, __m512)>>(
          '_mm512_mask_ceil_ps');
  late final __mm512_mask_ceil_ps = __mm512_mask_ceil_psPtr
      .asFunction<__m512 Function(__m512, int, __m512)>();

  _m512d _mm512_ceil_pd(
    _m512d arg0,
  ) {
    return __mm512_ceil_pd(
      arg0,
    );
  }

  late final __mm512_ceil_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d)>>('_mm512_ceil_pd');
  late final __mm512_ceil_pd =
      __mm512_ceil_pdPtr.asFunction<_m512d Function(_m512d)>();

  _m512d _mm512_mask_ceil_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
  ) {
    return __mm512_mask_ceil_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_ceil_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, __mmask8, _m512d)>>(
          '_mm512_mask_ceil_pd');
  late final __mm512_mask_ceil_pd = __mm512_mask_ceil_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d)>();

  __m512 _mm512_svml_round_ps(
    __m512 arg0,
  ) {
    return __mm512_svml_round_ps(
      arg0,
    );
  }

  late final __mm512_svml_round_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512)>>(
          '_mm512_svml_round_ps');
  late final __mm512_svml_round_ps =
      __mm512_svml_round_psPtr.asFunction<__m512 Function(__m512)>();

  __m512 _mm512_mask_svml_round_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
  ) {
    return __mm512_mask_svml_round_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_svml_round_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __mmask16, __m512)>>(
          '_mm512_mask_svml_round_ps');
  late final __mm512_mask_svml_round_ps = __mm512_mask_svml_round_psPtr
      .asFunction<__m512 Function(__m512, int, __m512)>();

  _m512d _mm512_svml_round_pd(
    _m512d arg0,
  ) {
    return __mm512_svml_round_pd(
      arg0,
    );
  }

  late final __mm512_svml_round_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d)>>(
          '_mm512_svml_round_pd');
  late final __mm512_svml_round_pd =
      __mm512_svml_round_pdPtr.asFunction<_m512d Function(_m512d)>();

  _m512d _mm512_mask_svml_round_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
  ) {
    return __mm512_mask_svml_round_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_svml_round_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, __mmask8, _m512d)>>(
          '_mm512_mask_svml_round_pd');
  late final __mm512_mask_svml_round_pd = __mm512_mask_svml_round_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d)>();

  __m512 _mm512_fmod_ps(
    __m512 arg0,
    __m512 arg1,
  ) {
    return __mm512_fmod_ps(
      arg0,
      arg1,
    );
  }

  late final __mm512_fmod_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __m512)>>(
          '_mm512_fmod_ps');
  late final __mm512_fmod_ps =
      __mm512_fmod_psPtr.asFunction<__m512 Function(__m512, __m512)>();

  __m512 _mm512_mask_fmod_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
    __m512 arg3,
  ) {
    return __mm512_mask_fmod_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_fmod_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(
              __m512, __mmask16, __m512, __m512)>>('_mm512_mask_fmod_ps');
  late final __mm512_mask_fmod_ps = __mm512_mask_fmod_psPtr
      .asFunction<__m512 Function(__m512, int, __m512, __m512)>();

  _m512d _mm512_fmod_pd(
    _m512d arg0,
    _m512d arg1,
  ) {
    return __mm512_fmod_pd(
      arg0,
      arg1,
    );
  }

  late final __mm512_fmod_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, _m512d)>>(
          '_mm512_fmod_pd');
  late final __mm512_fmod_pd =
      __mm512_fmod_pdPtr.asFunction<_m512d Function(_m512d, _m512d)>();

  _m512d _mm512_mask_fmod_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
    _m512d arg3,
  ) {
    return __mm512_mask_fmod_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_fmod_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(
              _m512d, __mmask8, _m512d, _m512d)>>('_mm512_mask_fmod_pd');
  late final __mm512_mask_fmod_pd = __mm512_mask_fmod_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d, _m512d)>();

  __m512 _mm512_rint_ps(
    __m512 arg0,
  ) {
    return __mm512_rint_ps(
      arg0,
    );
  }

  late final __mm512_rint_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512)>>('_mm512_rint_ps');
  late final __mm512_rint_ps =
      __mm512_rint_psPtr.asFunction<__m512 Function(__m512)>();

  __m512 _mm512_mask_rint_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
  ) {
    return __mm512_mask_rint_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_rint_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __mmask16, __m512)>>(
          '_mm512_mask_rint_ps');
  late final __mm512_mask_rint_ps = __mm512_mask_rint_psPtr
      .asFunction<__m512 Function(__m512, int, __m512)>();

  _m512d _mm512_rint_pd(
    _m512d arg0,
  ) {
    return __mm512_rint_pd(
      arg0,
    );
  }

  late final __mm512_rint_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d)>>('_mm512_rint_pd');
  late final __mm512_rint_pd =
      __mm512_rint_pdPtr.asFunction<_m512d Function(_m512d)>();

  _m512d _mm512_mask_rint_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
  ) {
    return __mm512_mask_rint_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_rint_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, __mmask8, _m512d)>>(
          '_mm512_mask_rint_pd');
  late final __mm512_mask_rint_pd = __mm512_mask_rint_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d)>();

  __m512 _mm512_invsqrt_ps(
    __m512 arg0,
  ) {
    return __mm512_invsqrt_ps(
      arg0,
    );
  }

  late final __mm512_invsqrt_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512)>>('_mm512_invsqrt_ps');
  late final __mm512_invsqrt_ps =
      __mm512_invsqrt_psPtr.asFunction<__m512 Function(__m512)>();

  __m512 _mm512_mask_invsqrt_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
  ) {
    return __mm512_mask_invsqrt_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_invsqrt_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __mmask16, __m512)>>(
          '_mm512_mask_invsqrt_ps');
  late final __mm512_mask_invsqrt_ps = __mm512_mask_invsqrt_psPtr
      .asFunction<__m512 Function(__m512, int, __m512)>();

  _m512d _mm512_invsqrt_pd(
    _m512d arg0,
  ) {
    return __mm512_invsqrt_pd(
      arg0,
    );
  }

  late final __mm512_invsqrt_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d)>>('_mm512_invsqrt_pd');
  late final __mm512_invsqrt_pd =
      __mm512_invsqrt_pdPtr.asFunction<_m512d Function(_m512d)>();

  _m512d _mm512_mask_invsqrt_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
  ) {
    return __mm512_mask_invsqrt_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_invsqrt_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, __mmask8, _m512d)>>(
          '_mm512_mask_invsqrt_pd');
  late final __mm512_mask_invsqrt_pd = __mm512_mask_invsqrt_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d)>();

  __m512 _mm512_cbrt_ps(
    __m512 arg0,
  ) {
    return __mm512_cbrt_ps(
      arg0,
    );
  }

  late final __mm512_cbrt_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512)>>('_mm512_cbrt_ps');
  late final __mm512_cbrt_ps =
      __mm512_cbrt_psPtr.asFunction<__m512 Function(__m512)>();

  __m512 _mm512_mask_cbrt_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
  ) {
    return __mm512_mask_cbrt_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cbrt_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __mmask16, __m512)>>(
          '_mm512_mask_cbrt_ps');
  late final __mm512_mask_cbrt_ps = __mm512_mask_cbrt_psPtr
      .asFunction<__m512 Function(__m512, int, __m512)>();

  _m512d _mm512_cbrt_pd(
    _m512d arg0,
  ) {
    return __mm512_cbrt_pd(
      arg0,
    );
  }

  late final __mm512_cbrt_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d)>>('_mm512_cbrt_pd');
  late final __mm512_cbrt_pd =
      __mm512_cbrt_pdPtr.asFunction<_m512d Function(_m512d)>();

  _m512d _mm512_mask_cbrt_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
  ) {
    return __mm512_mask_cbrt_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cbrt_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, __mmask8, _m512d)>>(
          '_mm512_mask_cbrt_pd');
  late final __mm512_mask_cbrt_pd = __mm512_mask_cbrt_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d)>();

  __m512 _mm512_invcbrt_ps(
    __m512 arg0,
  ) {
    return __mm512_invcbrt_ps(
      arg0,
    );
  }

  late final __mm512_invcbrt_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512)>>('_mm512_invcbrt_ps');
  late final __mm512_invcbrt_ps =
      __mm512_invcbrt_psPtr.asFunction<__m512 Function(__m512)>();

  __m512 _mm512_mask_invcbrt_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
  ) {
    return __mm512_mask_invcbrt_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_invcbrt_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __mmask16, __m512)>>(
          '_mm512_mask_invcbrt_ps');
  late final __mm512_mask_invcbrt_ps = __mm512_mask_invcbrt_psPtr
      .asFunction<__m512 Function(__m512, int, __m512)>();

  _m512d _mm512_invcbrt_pd(
    _m512d arg0,
  ) {
    return __mm512_invcbrt_pd(
      arg0,
    );
  }

  late final __mm512_invcbrt_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d)>>('_mm512_invcbrt_pd');
  late final __mm512_invcbrt_pd =
      __mm512_invcbrt_pdPtr.asFunction<_m512d Function(_m512d)>();

  _m512d _mm512_mask_invcbrt_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
  ) {
    return __mm512_mask_invcbrt_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_invcbrt_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, __mmask8, _m512d)>>(
          '_mm512_mask_invcbrt_pd');
  late final __mm512_mask_invcbrt_pd = __mm512_mask_invcbrt_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d)>();

  __m512 _mm512_hypot_ps(
    __m512 arg0,
    __m512 arg1,
  ) {
    return __mm512_hypot_ps(
      arg0,
      arg1,
    );
  }

  late final __mm512_hypot_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __m512)>>(
          '_mm512_hypot_ps');
  late final __mm512_hypot_ps =
      __mm512_hypot_psPtr.asFunction<__m512 Function(__m512, __m512)>();

  __m512 _mm512_mask_hypot_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
    __m512 arg3,
  ) {
    return __mm512_mask_hypot_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_hypot_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(
              __m512, __mmask16, __m512, __m512)>>('_mm512_mask_hypot_ps');
  late final __mm512_mask_hypot_ps = __mm512_mask_hypot_psPtr
      .asFunction<__m512 Function(__m512, int, __m512, __m512)>();

  _m512d _mm512_hypot_pd(
    _m512d arg0,
    _m512d arg1,
  ) {
    return __mm512_hypot_pd(
      arg0,
      arg1,
    );
  }

  late final __mm512_hypot_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, _m512d)>>(
          '_mm512_hypot_pd');
  late final __mm512_hypot_pd =
      __mm512_hypot_pdPtr.asFunction<_m512d Function(_m512d, _m512d)>();

  _m512d _mm512_mask_hypot_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
    _m512d arg3,
  ) {
    return __mm512_mask_hypot_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_hypot_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(
              _m512d, __mmask8, _m512d, _m512d)>>('_mm512_mask_hypot_pd');
  late final __mm512_mask_hypot_pd = __mm512_mask_hypot_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d, _m512d)>();

  __m512 _mm512_cdfnorm_ps(
    __m512 arg0,
  ) {
    return __mm512_cdfnorm_ps(
      arg0,
    );
  }

  late final __mm512_cdfnorm_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512)>>('_mm512_cdfnorm_ps');
  late final __mm512_cdfnorm_ps =
      __mm512_cdfnorm_psPtr.asFunction<__m512 Function(__m512)>();

  __m512 _mm512_mask_cdfnorm_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
  ) {
    return __mm512_mask_cdfnorm_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cdfnorm_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __mmask16, __m512)>>(
          '_mm512_mask_cdfnorm_ps');
  late final __mm512_mask_cdfnorm_ps = __mm512_mask_cdfnorm_psPtr
      .asFunction<__m512 Function(__m512, int, __m512)>();

  _m512d _mm512_cdfnorm_pd(
    _m512d arg0,
  ) {
    return __mm512_cdfnorm_pd(
      arg0,
    );
  }

  late final __mm512_cdfnorm_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d)>>('_mm512_cdfnorm_pd');
  late final __mm512_cdfnorm_pd =
      __mm512_cdfnorm_pdPtr.asFunction<_m512d Function(_m512d)>();

  _m512d _mm512_mask_cdfnorm_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
  ) {
    return __mm512_mask_cdfnorm_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cdfnorm_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, __mmask8, _m512d)>>(
          '_mm512_mask_cdfnorm_pd');
  late final __mm512_mask_cdfnorm_pd = __mm512_mask_cdfnorm_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d)>();

  __m512 _mm512_cdfnorminv_ps(
    __m512 arg0,
  ) {
    return __mm512_cdfnorminv_ps(
      arg0,
    );
  }

  late final __mm512_cdfnorminv_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512)>>(
          '_mm512_cdfnorminv_ps');
  late final __mm512_cdfnorminv_ps =
      __mm512_cdfnorminv_psPtr.asFunction<__m512 Function(__m512)>();

  __m512 _mm512_mask_cdfnorminv_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
  ) {
    return __mm512_mask_cdfnorminv_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cdfnorminv_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __mmask16, __m512)>>(
          '_mm512_mask_cdfnorminv_ps');
  late final __mm512_mask_cdfnorminv_ps = __mm512_mask_cdfnorminv_psPtr
      .asFunction<__m512 Function(__m512, int, __m512)>();

  _m512d _mm512_cdfnorminv_pd(
    _m512d arg0,
  ) {
    return __mm512_cdfnorminv_pd(
      arg0,
    );
  }

  late final __mm512_cdfnorminv_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d)>>(
          '_mm512_cdfnorminv_pd');
  late final __mm512_cdfnorminv_pd =
      __mm512_cdfnorminv_pdPtr.asFunction<_m512d Function(_m512d)>();

  _m512d _mm512_mask_cdfnorminv_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
  ) {
    return __mm512_mask_cdfnorminv_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cdfnorminv_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, __mmask8, _m512d)>>(
          '_mm512_mask_cdfnorminv_pd');
  late final __mm512_mask_cdfnorminv_pd = __mm512_mask_cdfnorminv_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d)>();

  __m512 _mm512_erf_ps(
    __m512 arg0,
  ) {
    return __mm512_erf_ps(
      arg0,
    );
  }

  late final __mm512_erf_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512)>>('_mm512_erf_ps');
  late final __mm512_erf_ps =
      __mm512_erf_psPtr.asFunction<__m512 Function(__m512)>();

  __m512 _mm512_mask_erf_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
  ) {
    return __mm512_mask_erf_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_erf_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __mmask16, __m512)>>(
          '_mm512_mask_erf_ps');
  late final __mm512_mask_erf_ps =
      __mm512_mask_erf_psPtr.asFunction<__m512 Function(__m512, int, __m512)>();

  _m512d _mm512_erf_pd(
    _m512d arg0,
  ) {
    return __mm512_erf_pd(
      arg0,
    );
  }

  late final __mm512_erf_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d)>>('_mm512_erf_pd');
  late final __mm512_erf_pd =
      __mm512_erf_pdPtr.asFunction<_m512d Function(_m512d)>();

  _m512d _mm512_mask_erf_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
  ) {
    return __mm512_mask_erf_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_erf_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, __mmask8, _m512d)>>(
          '_mm512_mask_erf_pd');
  late final __mm512_mask_erf_pd =
      __mm512_mask_erf_pdPtr.asFunction<_m512d Function(_m512d, int, _m512d)>();

  __m512 _mm512_erfc_ps(
    __m512 arg0,
  ) {
    return __mm512_erfc_ps(
      arg0,
    );
  }

  late final __mm512_erfc_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512)>>('_mm512_erfc_ps');
  late final __mm512_erfc_ps =
      __mm512_erfc_psPtr.asFunction<__m512 Function(__m512)>();

  __m512 _mm512_mask_erfc_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
  ) {
    return __mm512_mask_erfc_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_erfc_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __mmask16, __m512)>>(
          '_mm512_mask_erfc_ps');
  late final __mm512_mask_erfc_ps = __mm512_mask_erfc_psPtr
      .asFunction<__m512 Function(__m512, int, __m512)>();

  _m512d _mm512_erfc_pd(
    _m512d arg0,
  ) {
    return __mm512_erfc_pd(
      arg0,
    );
  }

  late final __mm512_erfc_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d)>>('_mm512_erfc_pd');
  late final __mm512_erfc_pd =
      __mm512_erfc_pdPtr.asFunction<_m512d Function(_m512d)>();

  _m512d _mm512_mask_erfc_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
  ) {
    return __mm512_mask_erfc_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_erfc_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, __mmask8, _m512d)>>(
          '_mm512_mask_erfc_pd');
  late final __mm512_mask_erfc_pd = __mm512_mask_erfc_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d)>();

  __m512 _mm512_erfcinv_ps(
    __m512 arg0,
  ) {
    return __mm512_erfcinv_ps(
      arg0,
    );
  }

  late final __mm512_erfcinv_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512)>>('_mm512_erfcinv_ps');
  late final __mm512_erfcinv_ps =
      __mm512_erfcinv_psPtr.asFunction<__m512 Function(__m512)>();

  __m512 _mm512_mask_erfcinv_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
  ) {
    return __mm512_mask_erfcinv_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_erfcinv_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __mmask16, __m512)>>(
          '_mm512_mask_erfcinv_ps');
  late final __mm512_mask_erfcinv_ps = __mm512_mask_erfcinv_psPtr
      .asFunction<__m512 Function(__m512, int, __m512)>();

  _m512d _mm512_erfcinv_pd(
    _m512d arg0,
  ) {
    return __mm512_erfcinv_pd(
      arg0,
    );
  }

  late final __mm512_erfcinv_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d)>>('_mm512_erfcinv_pd');
  late final __mm512_erfcinv_pd =
      __mm512_erfcinv_pdPtr.asFunction<_m512d Function(_m512d)>();

  _m512d _mm512_mask_erfcinv_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
  ) {
    return __mm512_mask_erfcinv_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_erfcinv_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, __mmask8, _m512d)>>(
          '_mm512_mask_erfcinv_pd');
  late final __mm512_mask_erfcinv_pd = __mm512_mask_erfcinv_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d)>();

  __m512 _mm512_erfinv_ps(
    __m512 arg0,
  ) {
    return __mm512_erfinv_ps(
      arg0,
    );
  }

  late final __mm512_erfinv_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512)>>('_mm512_erfinv_ps');
  late final __mm512_erfinv_ps =
      __mm512_erfinv_psPtr.asFunction<__m512 Function(__m512)>();

  __m512 _mm512_mask_erfinv_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
  ) {
    return __mm512_mask_erfinv_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_erfinv_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __mmask16, __m512)>>(
          '_mm512_mask_erfinv_ps');
  late final __mm512_mask_erfinv_ps = __mm512_mask_erfinv_psPtr
      .asFunction<__m512 Function(__m512, int, __m512)>();

  _m512d _mm512_erfinv_pd(
    _m512d arg0,
  ) {
    return __mm512_erfinv_pd(
      arg0,
    );
  }

  late final __mm512_erfinv_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d)>>('_mm512_erfinv_pd');
  late final __mm512_erfinv_pd =
      __mm512_erfinv_pdPtr.asFunction<_m512d Function(_m512d)>();

  _m512d _mm512_mask_erfinv_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
  ) {
    return __mm512_mask_erfinv_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_erfinv_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, __mmask8, _m512d)>>(
          '_mm512_mask_erfinv_pd');
  late final __mm512_mask_erfinv_pd = __mm512_mask_erfinv_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d)>();

  __m512 _mm512_nearbyint_ps(
    __m512 arg0,
  ) {
    return __mm512_nearbyint_ps(
      arg0,
    );
  }

  late final __mm512_nearbyint_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512)>>(
          '_mm512_nearbyint_ps');
  late final __mm512_nearbyint_ps =
      __mm512_nearbyint_psPtr.asFunction<__m512 Function(__m512)>();

  __m512 _mm512_mask_nearbyint_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
  ) {
    return __mm512_mask_nearbyint_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_nearbyint_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __mmask16, __m512)>>(
          '_mm512_mask_nearbyint_ps');
  late final __mm512_mask_nearbyint_ps = __mm512_mask_nearbyint_psPtr
      .asFunction<__m512 Function(__m512, int, __m512)>();

  _m512d _mm512_nearbyint_pd(
    _m512d arg0,
  ) {
    return __mm512_nearbyint_pd(
      arg0,
    );
  }

  late final __mm512_nearbyint_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d)>>(
          '_mm512_nearbyint_pd');
  late final __mm512_nearbyint_pd =
      __mm512_nearbyint_pdPtr.asFunction<_m512d Function(_m512d)>();

  _m512d _mm512_mask_nearbyint_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
  ) {
    return __mm512_mask_nearbyint_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_nearbyint_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, __mmask8, _m512d)>>(
          '_mm512_mask_nearbyint_pd');
  late final __mm512_mask_nearbyint_pd = __mm512_mask_nearbyint_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d)>();

  __m128bh _mm_cvtneps_pbh(
    __m128 arg0,
  ) {
    return __mm_cvtneps_pbh(
      arg0,
    );
  }

  late final __mm_cvtneps_pbhPtr =
      _lookup<ffi.NativeFunction<__m128bh Function(__m128)>>('_mm_cvtneps_pbh');
  late final __mm_cvtneps_pbh =
      __mm_cvtneps_pbhPtr.asFunction<__m128bh Function(__m128)>();

  __m128bh _mm_mask_cvtneps_pbh(
    __m128bh arg0,
    int arg1,
    __m128 arg2,
  ) {
    return __mm_mask_cvtneps_pbh(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtneps_pbhPtr = _lookup<
          ffi.NativeFunction<__m128bh Function(__m128bh, __mmask8, __m128)>>(
      '_mm_mask_cvtneps_pbh');
  late final __mm_mask_cvtneps_pbh = __mm_mask_cvtneps_pbhPtr
      .asFunction<__m128bh Function(__m128bh, int, __m128)>();

  __m128bh _mm_maskz_cvtneps_pbh(
    int arg0,
    __m128 arg1,
  ) {
    return __mm_maskz_cvtneps_pbh(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvtneps_pbhPtr =
      _lookup<ffi.NativeFunction<__m128bh Function(__mmask8, __m128)>>(
          '_mm_maskz_cvtneps_pbh');
  late final __mm_maskz_cvtneps_pbh =
      __mm_maskz_cvtneps_pbhPtr.asFunction<__m128bh Function(int, __m128)>();

  __m128bh _mm_cvtne2ps_pbh(
    __m128 arg0,
    __m128 arg1,
  ) {
    return __mm_cvtne2ps_pbh(
      arg0,
      arg1,
    );
  }

  late final __mm_cvtne2ps_pbhPtr =
      _lookup<ffi.NativeFunction<__m128bh Function(__m128, __m128)>>(
          '_mm_cvtne2ps_pbh');
  late final __mm_cvtne2ps_pbh =
      __mm_cvtne2ps_pbhPtr.asFunction<__m128bh Function(__m128, __m128)>();

  __m128bh _mm_mask_cvtne2ps_pbh(
    __m128bh arg0,
    int arg1,
    __m128 arg2,
    __m128 arg3,
  ) {
    return __mm_mask_cvtne2ps_pbh(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_cvtne2ps_pbhPtr = _lookup<
      ffi.NativeFunction<
          __m128bh Function(
              __m128bh, __mmask8, __m128, __m128)>>('_mm_mask_cvtne2ps_pbh');
  late final __mm_mask_cvtne2ps_pbh = __mm_mask_cvtne2ps_pbhPtr
      .asFunction<__m128bh Function(__m128bh, int, __m128, __m128)>();

  __m128bh _mm_maskz_cvtne2ps_pbh(
    int arg0,
    __m128 arg1,
    __m128 arg2,
  ) {
    return __mm_maskz_cvtne2ps_pbh(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_cvtne2ps_pbhPtr =
      _lookup<ffi.NativeFunction<__m128bh Function(__mmask8, __m128, __m128)>>(
          '_mm_maskz_cvtne2ps_pbh');
  late final __mm_maskz_cvtne2ps_pbh = __mm_maskz_cvtne2ps_pbhPtr
      .asFunction<__m128bh Function(int, __m128, __m128)>();

  __m128 _mm_dpbf16_ps(
    __m128 arg0,
    __m128bh arg1,
    __m128bh arg2,
  ) {
    return __mm_dpbf16_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_dpbf16_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128bh, __m128bh)>>(
          '_mm_dpbf16_ps');
  late final __mm_dpbf16_ps = __mm_dpbf16_psPtr
      .asFunction<__m128 Function(__m128, __m128bh, __m128bh)>();

  __m128 _mm_mask_dpbf16_ps(
    __m128 arg0,
    int arg1,
    __m128bh arg2,
    __m128bh arg3,
  ) {
    return __mm_mask_dpbf16_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_dpbf16_psPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __m128, __mmask8, __m128bh, __m128bh)>>('_mm_mask_dpbf16_ps');
  late final __mm_mask_dpbf16_ps = __mm_mask_dpbf16_psPtr
      .asFunction<__m128 Function(__m128, int, __m128bh, __m128bh)>();

  __m128 _mm_maskz_dpbf16_ps(
    int arg0,
    __m128 arg1,
    __m128bh arg2,
    __m128bh arg3,
  ) {
    return __mm_maskz_dpbf16_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_dpbf16_psPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __mmask8, __m128, __m128bh, __m128bh)>>('_mm_maskz_dpbf16_ps');
  late final __mm_maskz_dpbf16_ps = __mm_maskz_dpbf16_psPtr
      .asFunction<__m128 Function(int, __m128, __m128bh, __m128bh)>();

  __m128bh _mm256_cvtneps_pbh(
    __m256 arg0,
  ) {
    return __mm256_cvtneps_pbh(
      arg0,
    );
  }

  late final __mm256_cvtneps_pbhPtr =
      _lookup<ffi.NativeFunction<__m128bh Function(__m256)>>(
          '_mm256_cvtneps_pbh');
  late final __mm256_cvtneps_pbh =
      __mm256_cvtneps_pbhPtr.asFunction<__m128bh Function(__m256)>();

  __m128bh _mm256_mask_cvtneps_pbh(
    __m128bh arg0,
    int arg1,
    __m256 arg2,
  ) {
    return __mm256_mask_cvtneps_pbh(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtneps_pbhPtr = _lookup<
          ffi.NativeFunction<__m128bh Function(__m128bh, __mmask8, __m256)>>(
      '_mm256_mask_cvtneps_pbh');
  late final __mm256_mask_cvtneps_pbh = __mm256_mask_cvtneps_pbhPtr
      .asFunction<__m128bh Function(__m128bh, int, __m256)>();

  __m128bh _mm256_maskz_cvtneps_pbh(
    int arg0,
    __m256 arg1,
  ) {
    return __mm256_maskz_cvtneps_pbh(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvtneps_pbhPtr =
      _lookup<ffi.NativeFunction<__m128bh Function(__mmask8, __m256)>>(
          '_mm256_maskz_cvtneps_pbh');
  late final __mm256_maskz_cvtneps_pbh =
      __mm256_maskz_cvtneps_pbhPtr.asFunction<__m128bh Function(int, __m256)>();

  __m256bh _mm256_cvtne2ps_pbh(
    __m256 arg0,
    __m256 arg1,
  ) {
    return __mm256_cvtne2ps_pbh(
      arg0,
      arg1,
    );
  }

  late final __mm256_cvtne2ps_pbhPtr =
      _lookup<ffi.NativeFunction<__m256bh Function(__m256, __m256)>>(
          '_mm256_cvtne2ps_pbh');
  late final __mm256_cvtne2ps_pbh =
      __mm256_cvtne2ps_pbhPtr.asFunction<__m256bh Function(__m256, __m256)>();

  __m256bh _mm256_mask_cvtne2ps_pbh(
    __m256bh arg0,
    int arg1,
    __m256 arg2,
    __m256 arg3,
  ) {
    return __mm256_mask_cvtne2ps_pbh(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_cvtne2ps_pbhPtr = _lookup<
      ffi.NativeFunction<
          __m256bh Function(__m256bh, __mmask16, __m256,
              __m256)>>('_mm256_mask_cvtne2ps_pbh');
  late final __mm256_mask_cvtne2ps_pbh = __mm256_mask_cvtne2ps_pbhPtr
      .asFunction<__m256bh Function(__m256bh, int, __m256, __m256)>();

  __m256bh _mm256_maskz_cvtne2ps_pbh(
    int arg0,
    __m256 arg1,
    __m256 arg2,
  ) {
    return __mm256_maskz_cvtne2ps_pbh(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_cvtne2ps_pbhPtr =
      _lookup<ffi.NativeFunction<__m256bh Function(__mmask16, __m256, __m256)>>(
          '_mm256_maskz_cvtne2ps_pbh');
  late final __mm256_maskz_cvtne2ps_pbh = __mm256_maskz_cvtne2ps_pbhPtr
      .asFunction<__m256bh Function(int, __m256, __m256)>();

  __m256 _mm256_dpbf16_ps(
    __m256 arg0,
    __m256bh arg1,
    __m256bh arg2,
  ) {
    return __mm256_dpbf16_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_dpbf16_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256, __m256bh, __m256bh)>>(
          '_mm256_dpbf16_ps');
  late final __mm256_dpbf16_ps = __mm256_dpbf16_psPtr
      .asFunction<__m256 Function(__m256, __m256bh, __m256bh)>();

  __m256 _mm256_mask_dpbf16_ps(
    __m256 arg0,
    int arg1,
    __m256bh arg2,
    __m256bh arg3,
  ) {
    return __mm256_mask_dpbf16_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_dpbf16_psPtr = _lookup<
      ffi.NativeFunction<
          __m256 Function(
              __m256, __mmask8, __m256bh, __m256bh)>>('_mm256_mask_dpbf16_ps');
  late final __mm256_mask_dpbf16_ps = __mm256_mask_dpbf16_psPtr
      .asFunction<__m256 Function(__m256, int, __m256bh, __m256bh)>();

  __m256 _mm256_maskz_dpbf16_ps(
    int arg0,
    __m256 arg1,
    __m256bh arg2,
    __m256bh arg3,
  ) {
    return __mm256_maskz_dpbf16_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_maskz_dpbf16_psPtr = _lookup<
      ffi.NativeFunction<
          __m256 Function(
              __mmask8, __m256, __m256bh, __m256bh)>>('_mm256_maskz_dpbf16_ps');
  late final __mm256_maskz_dpbf16_ps = __mm256_maskz_dpbf16_psPtr
      .asFunction<__m256 Function(int, __m256, __m256bh, __m256bh)>();

  __m256bh _mm512_cvtneps_pbh(
    __m512 arg0,
  ) {
    return __mm512_cvtneps_pbh(
      arg0,
    );
  }

  late final __mm512_cvtneps_pbhPtr =
      _lookup<ffi.NativeFunction<__m256bh Function(__m512)>>(
          '_mm512_cvtneps_pbh');
  late final __mm512_cvtneps_pbh =
      __mm512_cvtneps_pbhPtr.asFunction<__m256bh Function(__m512)>();

  __m256bh _mm512_mask_cvtneps_pbh(
    __m256bh arg0,
    int arg1,
    __m512 arg2,
  ) {
    return __mm512_mask_cvtneps_pbh(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtneps_pbhPtr = _lookup<
          ffi.NativeFunction<__m256bh Function(__m256bh, __mmask16, __m512)>>(
      '_mm512_mask_cvtneps_pbh');
  late final __mm512_mask_cvtneps_pbh = __mm512_mask_cvtneps_pbhPtr
      .asFunction<__m256bh Function(__m256bh, int, __m512)>();

  __m256bh _mm512_maskz_cvtneps_pbh(
    int arg0,
    __m512 arg1,
  ) {
    return __mm512_maskz_cvtneps_pbh(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvtneps_pbhPtr =
      _lookup<ffi.NativeFunction<__m256bh Function(__mmask16, __m512)>>(
          '_mm512_maskz_cvtneps_pbh');
  late final __mm512_maskz_cvtneps_pbh =
      __mm512_maskz_cvtneps_pbhPtr.asFunction<__m256bh Function(int, __m512)>();

  __m512bh _mm512_cvtne2ps_pbh(
    __m512 arg0,
    __m512 arg1,
  ) {
    return __mm512_cvtne2ps_pbh(
      arg0,
      arg1,
    );
  }

  late final __mm512_cvtne2ps_pbhPtr =
      _lookup<ffi.NativeFunction<__m512bh Function(__m512, __m512)>>(
          '_mm512_cvtne2ps_pbh');
  late final __mm512_cvtne2ps_pbh =
      __mm512_cvtne2ps_pbhPtr.asFunction<__m512bh Function(__m512, __m512)>();

  __m512bh _mm512_mask_cvtne2ps_pbh(
    __m512bh arg0,
    int arg1,
    __m512 arg2,
    __m512 arg3,
  ) {
    return __mm512_mask_cvtne2ps_pbh(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_cvtne2ps_pbhPtr = _lookup<
      ffi.NativeFunction<
          __m512bh Function(__m512bh, __mmask32, __m512,
              __m512)>>('_mm512_mask_cvtne2ps_pbh');
  late final __mm512_mask_cvtne2ps_pbh = __mm512_mask_cvtne2ps_pbhPtr
      .asFunction<__m512bh Function(__m512bh, int, __m512, __m512)>();

  __m512bh _mm512_maskz_cvtne2ps_pbh(
    int arg0,
    __m512 arg1,
    __m512 arg2,
  ) {
    return __mm512_maskz_cvtne2ps_pbh(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_cvtne2ps_pbhPtr =
      _lookup<ffi.NativeFunction<__m512bh Function(__mmask32, __m512, __m512)>>(
          '_mm512_maskz_cvtne2ps_pbh');
  late final __mm512_maskz_cvtne2ps_pbh = __mm512_maskz_cvtne2ps_pbhPtr
      .asFunction<__m512bh Function(int, __m512, __m512)>();

  __m512 _mm512_dpbf16_ps(
    __m512 arg0,
    __m512bh arg1,
    __m512bh arg2,
  ) {
    return __mm512_dpbf16_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_dpbf16_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __m512bh, __m512bh)>>(
          '_mm512_dpbf16_ps');
  late final __mm512_dpbf16_ps = __mm512_dpbf16_psPtr
      .asFunction<__m512 Function(__m512, __m512bh, __m512bh)>();

  __m512 _mm512_mask_dpbf16_ps(
    __m512 arg0,
    int arg1,
    __m512bh arg2,
    __m512bh arg3,
  ) {
    return __mm512_mask_dpbf16_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_dpbf16_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(
              __m512, __mmask16, __m512bh, __m512bh)>>('_mm512_mask_dpbf16_ps');
  late final __mm512_mask_dpbf16_ps = __mm512_mask_dpbf16_psPtr
      .asFunction<__m512 Function(__m512, int, __m512bh, __m512bh)>();

  __m512 _mm512_maskz_dpbf16_ps(
    int arg0,
    __m512 arg1,
    __m512bh arg2,
    __m512bh arg3,
  ) {
    return __mm512_maskz_dpbf16_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_dpbf16_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__mmask16, __m512, __m512bh,
              __m512bh)>>('_mm512_maskz_dpbf16_ps');
  late final __mm512_maskz_dpbf16_ps = __mm512_maskz_dpbf16_psPtr
      .asFunction<__m512 Function(int, __m512, __m512bh, __m512bh)>();

  int _kadd_mask8(
    int arg0,
    int arg1,
  ) {
    return __kadd_mask8(
      arg0,
      arg1,
    );
  }

  late final __kadd_mask8Ptr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__mmask8, __mmask8)>>(
          '_kadd_mask8');
  late final __kadd_mask8 =
      __kadd_mask8Ptr.asFunction<int Function(int, int)>();

  int _kadd_mask16(
    int arg0,
    int arg1,
  ) {
    return __kadd_mask16(
      arg0,
      arg1,
    );
  }

  late final __kadd_mask16Ptr =
      _lookup<ffi.NativeFunction<__mmask16 Function(__mmask16, __mmask16)>>(
          '_kadd_mask16');
  late final __kadd_mask16 =
      __kadd_mask16Ptr.asFunction<int Function(int, int)>();

  int _kadd_mask32(
    int arg0,
    int arg1,
  ) {
    return __kadd_mask32(
      arg0,
      arg1,
    );
  }

  late final __kadd_mask32Ptr =
      _lookup<ffi.NativeFunction<__mmask32 Function(__mmask32, __mmask32)>>(
          '_kadd_mask32');
  late final __kadd_mask32 =
      __kadd_mask32Ptr.asFunction<int Function(int, int)>();

  int _kadd_mask64(
    int arg0,
    int arg1,
  ) {
    return __kadd_mask64(
      arg0,
      arg1,
    );
  }

  late final __kadd_mask64Ptr =
      _lookup<ffi.NativeFunction<__mmask64 Function(__mmask64, __mmask64)>>(
          '_kadd_mask64');
  late final __kadd_mask64 =
      __kadd_mask64Ptr.asFunction<int Function(int, int)>();

  int _kand_mask8(
    int arg0,
    int arg1,
  ) {
    return __kand_mask8(
      arg0,
      arg1,
    );
  }

  late final __kand_mask8Ptr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__mmask8, __mmask8)>>(
          '_kand_mask8');
  late final __kand_mask8 =
      __kand_mask8Ptr.asFunction<int Function(int, int)>();

  int _kand_mask16(
    int arg0,
    int arg1,
  ) {
    return __kand_mask16(
      arg0,
      arg1,
    );
  }

  late final __kand_mask16Ptr =
      _lookup<ffi.NativeFunction<__mmask16 Function(__mmask16, __mmask16)>>(
          '_kand_mask16');
  late final __kand_mask16 =
      __kand_mask16Ptr.asFunction<int Function(int, int)>();

  int _kand_mask32(
    int arg0,
    int arg1,
  ) {
    return __kand_mask32(
      arg0,
      arg1,
    );
  }

  late final __kand_mask32Ptr =
      _lookup<ffi.NativeFunction<__mmask32 Function(__mmask32, __mmask32)>>(
          '_kand_mask32');
  late final __kand_mask32 =
      __kand_mask32Ptr.asFunction<int Function(int, int)>();

  int _kand_mask64(
    int arg0,
    int arg1,
  ) {
    return __kand_mask64(
      arg0,
      arg1,
    );
  }

  late final __kand_mask64Ptr =
      _lookup<ffi.NativeFunction<__mmask64 Function(__mmask64, __mmask64)>>(
          '_kand_mask64');
  late final __kand_mask64 =
      __kand_mask64Ptr.asFunction<int Function(int, int)>();

  int _kandn_mask8(
    int arg0,
    int arg1,
  ) {
    return __kandn_mask8(
      arg0,
      arg1,
    );
  }

  late final __kandn_mask8Ptr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__mmask8, __mmask8)>>(
          '_kandn_mask8');
  late final __kandn_mask8 =
      __kandn_mask8Ptr.asFunction<int Function(int, int)>();

  int _kandn_mask16(
    int arg0,
    int arg1,
  ) {
    return __kandn_mask16(
      arg0,
      arg1,
    );
  }

  late final __kandn_mask16Ptr =
      _lookup<ffi.NativeFunction<__mmask16 Function(__mmask16, __mmask16)>>(
          '_kandn_mask16');
  late final __kandn_mask16 =
      __kandn_mask16Ptr.asFunction<int Function(int, int)>();

  int _kandn_mask32(
    int arg0,
    int arg1,
  ) {
    return __kandn_mask32(
      arg0,
      arg1,
    );
  }

  late final __kandn_mask32Ptr =
      _lookup<ffi.NativeFunction<__mmask32 Function(__mmask32, __mmask32)>>(
          '_kandn_mask32');
  late final __kandn_mask32 =
      __kandn_mask32Ptr.asFunction<int Function(int, int)>();

  int _kandn_mask64(
    int arg0,
    int arg1,
  ) {
    return __kandn_mask64(
      arg0,
      arg1,
    );
  }

  late final __kandn_mask64Ptr =
      _lookup<ffi.NativeFunction<__mmask64 Function(__mmask64, __mmask64)>>(
          '_kandn_mask64');
  late final __kandn_mask64 =
      __kandn_mask64Ptr.asFunction<int Function(int, int)>();

  int _knot_mask8(
    int arg0,
  ) {
    return __knot_mask8(
      arg0,
    );
  }

  late final __knot_mask8Ptr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__mmask8)>>('_knot_mask8');
  late final __knot_mask8 = __knot_mask8Ptr.asFunction<int Function(int)>();

  int _knot_mask16(
    int arg0,
  ) {
    return __knot_mask16(
      arg0,
    );
  }

  late final __knot_mask16Ptr =
      _lookup<ffi.NativeFunction<__mmask16 Function(__mmask16)>>(
          '_knot_mask16');
  late final __knot_mask16 = __knot_mask16Ptr.asFunction<int Function(int)>();

  int _knot_mask32(
    int arg0,
  ) {
    return __knot_mask32(
      arg0,
    );
  }

  late final __knot_mask32Ptr =
      _lookup<ffi.NativeFunction<__mmask32 Function(__mmask32)>>(
          '_knot_mask32');
  late final __knot_mask32 = __knot_mask32Ptr.asFunction<int Function(int)>();

  int _knot_mask64(
    int arg0,
  ) {
    return __knot_mask64(
      arg0,
    );
  }

  late final __knot_mask64Ptr =
      _lookup<ffi.NativeFunction<__mmask64 Function(__mmask64)>>(
          '_knot_mask64');
  late final __knot_mask64 = __knot_mask64Ptr.asFunction<int Function(int)>();

  int _kor_mask8(
    int arg0,
    int arg1,
  ) {
    return __kor_mask8(
      arg0,
      arg1,
    );
  }

  late final __kor_mask8Ptr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__mmask8, __mmask8)>>(
          '_kor_mask8');
  late final __kor_mask8 = __kor_mask8Ptr.asFunction<int Function(int, int)>();

  int _kor_mask16(
    int arg0,
    int arg1,
  ) {
    return __kor_mask16(
      arg0,
      arg1,
    );
  }

  late final __kor_mask16Ptr =
      _lookup<ffi.NativeFunction<__mmask16 Function(__mmask16, __mmask16)>>(
          '_kor_mask16');
  late final __kor_mask16 =
      __kor_mask16Ptr.asFunction<int Function(int, int)>();

  int _kor_mask32(
    int arg0,
    int arg1,
  ) {
    return __kor_mask32(
      arg0,
      arg1,
    );
  }

  late final __kor_mask32Ptr =
      _lookup<ffi.NativeFunction<__mmask32 Function(__mmask32, __mmask32)>>(
          '_kor_mask32');
  late final __kor_mask32 =
      __kor_mask32Ptr.asFunction<int Function(int, int)>();

  int _kor_mask64(
    int arg0,
    int arg1,
  ) {
    return __kor_mask64(
      arg0,
      arg1,
    );
  }

  late final __kor_mask64Ptr =
      _lookup<ffi.NativeFunction<__mmask64 Function(__mmask64, __mmask64)>>(
          '_kor_mask64');
  late final __kor_mask64 =
      __kor_mask64Ptr.asFunction<int Function(int, int)>();

  int _kxnor_mask8(
    int arg0,
    int arg1,
  ) {
    return __kxnor_mask8(
      arg0,
      arg1,
    );
  }

  late final __kxnor_mask8Ptr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__mmask8, __mmask8)>>(
          '_kxnor_mask8');
  late final __kxnor_mask8 =
      __kxnor_mask8Ptr.asFunction<int Function(int, int)>();

  int _kxnor_mask16(
    int arg0,
    int arg1,
  ) {
    return __kxnor_mask16(
      arg0,
      arg1,
    );
  }

  late final __kxnor_mask16Ptr =
      _lookup<ffi.NativeFunction<__mmask16 Function(__mmask16, __mmask16)>>(
          '_kxnor_mask16');
  late final __kxnor_mask16 =
      __kxnor_mask16Ptr.asFunction<int Function(int, int)>();

  int _kxnor_mask32(
    int arg0,
    int arg1,
  ) {
    return __kxnor_mask32(
      arg0,
      arg1,
    );
  }

  late final __kxnor_mask32Ptr =
      _lookup<ffi.NativeFunction<__mmask32 Function(__mmask32, __mmask32)>>(
          '_kxnor_mask32');
  late final __kxnor_mask32 =
      __kxnor_mask32Ptr.asFunction<int Function(int, int)>();

  int _kxnor_mask64(
    int arg0,
    int arg1,
  ) {
    return __kxnor_mask64(
      arg0,
      arg1,
    );
  }

  late final __kxnor_mask64Ptr =
      _lookup<ffi.NativeFunction<__mmask64 Function(__mmask64, __mmask64)>>(
          '_kxnor_mask64');
  late final __kxnor_mask64 =
      __kxnor_mask64Ptr.asFunction<int Function(int, int)>();

  int _kxor_mask8(
    int arg0,
    int arg1,
  ) {
    return __kxor_mask8(
      arg0,
      arg1,
    );
  }

  late final __kxor_mask8Ptr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__mmask8, __mmask8)>>(
          '_kxor_mask8');
  late final __kxor_mask8 =
      __kxor_mask8Ptr.asFunction<int Function(int, int)>();

  int _kxor_mask16(
    int arg0,
    int arg1,
  ) {
    return __kxor_mask16(
      arg0,
      arg1,
    );
  }

  late final __kxor_mask16Ptr =
      _lookup<ffi.NativeFunction<__mmask16 Function(__mmask16, __mmask16)>>(
          '_kxor_mask16');
  late final __kxor_mask16 =
      __kxor_mask16Ptr.asFunction<int Function(int, int)>();

  int _kxor_mask32(
    int arg0,
    int arg1,
  ) {
    return __kxor_mask32(
      arg0,
      arg1,
    );
  }

  late final __kxor_mask32Ptr =
      _lookup<ffi.NativeFunction<__mmask32 Function(__mmask32, __mmask32)>>(
          '_kxor_mask32');
  late final __kxor_mask32 =
      __kxor_mask32Ptr.asFunction<int Function(int, int)>();

  int _kxor_mask64(
    int arg0,
    int arg1,
  ) {
    return __kxor_mask64(
      arg0,
      arg1,
    );
  }

  late final __kxor_mask64Ptr =
      _lookup<ffi.NativeFunction<__mmask64 Function(__mmask64, __mmask64)>>(
          '_kxor_mask64');
  late final __kxor_mask64 =
      __kxor_mask64Ptr.asFunction<int Function(int, int)>();

  int _kshiftli_mask8(
    int arg0,
    int arg1,
  ) {
    return __kshiftli_mask8(
      arg0,
      arg1,
    );
  }

  late final __kshiftli_mask8Ptr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__mmask8, ffi.Uint32)>>(
          '_kshiftli_mask8');
  late final __kshiftli_mask8 =
      __kshiftli_mask8Ptr.asFunction<int Function(int, int)>();

  int _kshiftli_mask16(
    int arg0,
    int arg1,
  ) {
    return __kshiftli_mask16(
      arg0,
      arg1,
    );
  }

  late final __kshiftli_mask16Ptr =
      _lookup<ffi.NativeFunction<__mmask16 Function(__mmask16, ffi.Uint32)>>(
          '_kshiftli_mask16');
  late final __kshiftli_mask16 =
      __kshiftli_mask16Ptr.asFunction<int Function(int, int)>();

  int _kshiftli_mask32(
    int arg0,
    int arg1,
  ) {
    return __kshiftli_mask32(
      arg0,
      arg1,
    );
  }

  late final __kshiftli_mask32Ptr =
      _lookup<ffi.NativeFunction<__mmask32 Function(__mmask32, ffi.Uint32)>>(
          '_kshiftli_mask32');
  late final __kshiftli_mask32 =
      __kshiftli_mask32Ptr.asFunction<int Function(int, int)>();

  int _kshiftli_mask64(
    int arg0,
    int arg1,
  ) {
    return __kshiftli_mask64(
      arg0,
      arg1,
    );
  }

  late final __kshiftli_mask64Ptr =
      _lookup<ffi.NativeFunction<__mmask64 Function(__mmask64, ffi.Uint32)>>(
          '_kshiftli_mask64');
  late final __kshiftli_mask64 =
      __kshiftli_mask64Ptr.asFunction<int Function(int, int)>();

  int _kshiftri_mask8(
    int arg0,
    int arg1,
  ) {
    return __kshiftri_mask8(
      arg0,
      arg1,
    );
  }

  late final __kshiftri_mask8Ptr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__mmask8, ffi.Uint32)>>(
          '_kshiftri_mask8');
  late final __kshiftri_mask8 =
      __kshiftri_mask8Ptr.asFunction<int Function(int, int)>();

  int _kshiftri_mask16(
    int arg0,
    int arg1,
  ) {
    return __kshiftri_mask16(
      arg0,
      arg1,
    );
  }

  late final __kshiftri_mask16Ptr =
      _lookup<ffi.NativeFunction<__mmask16 Function(__mmask16, ffi.Uint32)>>(
          '_kshiftri_mask16');
  late final __kshiftri_mask16 =
      __kshiftri_mask16Ptr.asFunction<int Function(int, int)>();

  int _kshiftri_mask32(
    int arg0,
    int arg1,
  ) {
    return __kshiftri_mask32(
      arg0,
      arg1,
    );
  }

  late final __kshiftri_mask32Ptr =
      _lookup<ffi.NativeFunction<__mmask32 Function(__mmask32, ffi.Uint32)>>(
          '_kshiftri_mask32');
  late final __kshiftri_mask32 =
      __kshiftri_mask32Ptr.asFunction<int Function(int, int)>();

  int _kshiftri_mask64(
    int arg0,
    int arg1,
  ) {
    return __kshiftri_mask64(
      arg0,
      arg1,
    );
  }

  late final __kshiftri_mask64Ptr =
      _lookup<ffi.NativeFunction<__mmask64 Function(__mmask64, ffi.Uint32)>>(
          '_kshiftri_mask64');
  late final __kshiftri_mask64 =
      __kshiftri_mask64Ptr.asFunction<int Function(int, int)>();

  int _load_mask8(
    ffi.Pointer<__mmask8> arg0,
  ) {
    return __load_mask8(
      arg0,
    );
  }

  late final __load_mask8Ptr =
      _lookup<ffi.NativeFunction<__mmask8 Function(ffi.Pointer<__mmask8>)>>(
          '_load_mask8');
  late final __load_mask8 =
      __load_mask8Ptr.asFunction<int Function(ffi.Pointer<__mmask8>)>();

  int _load_mask16(
    ffi.Pointer<__mmask16> arg0,
  ) {
    return __load_mask16(
      arg0,
    );
  }

  late final __load_mask16Ptr =
      _lookup<ffi.NativeFunction<__mmask16 Function(ffi.Pointer<__mmask16>)>>(
          '_load_mask16');
  late final __load_mask16 =
      __load_mask16Ptr.asFunction<int Function(ffi.Pointer<__mmask16>)>();

  int _load_mask32(
    ffi.Pointer<__mmask32> arg0,
  ) {
    return __load_mask32(
      arg0,
    );
  }

  late final __load_mask32Ptr =
      _lookup<ffi.NativeFunction<__mmask32 Function(ffi.Pointer<__mmask32>)>>(
          '_load_mask32');
  late final __load_mask32 =
      __load_mask32Ptr.asFunction<int Function(ffi.Pointer<__mmask32>)>();

  int _load_mask64(
    ffi.Pointer<__mmask64> arg0,
  ) {
    return __load_mask64(
      arg0,
    );
  }

  late final __load_mask64Ptr =
      _lookup<ffi.NativeFunction<__mmask64 Function(ffi.Pointer<__mmask64>)>>(
          '_load_mask64');
  late final __load_mask64 =
      __load_mask64Ptr.asFunction<int Function(ffi.Pointer<__mmask64>)>();

  void _store_mask8(
    ffi.Pointer<__mmask8> arg0,
    int arg1,
  ) {
    return __store_mask8(
      arg0,
      arg1,
    );
  }

  late final __store_mask8Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<__mmask8>, __mmask8)>>('_store_mask8');
  late final __store_mask8 =
      __store_mask8Ptr.asFunction<void Function(ffi.Pointer<__mmask8>, int)>();

  void _store_mask16(
    ffi.Pointer<__mmask16> arg0,
    int arg1,
  ) {
    return __store_mask16(
      arg0,
      arg1,
    );
  }

  late final __store_mask16Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<__mmask16>, __mmask16)>>('_store_mask16');
  late final __store_mask16 = __store_mask16Ptr
      .asFunction<void Function(ffi.Pointer<__mmask16>, int)>();

  void _store_mask32(
    ffi.Pointer<__mmask32> arg0,
    int arg1,
  ) {
    return __store_mask32(
      arg0,
      arg1,
    );
  }

  late final __store_mask32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<__mmask32>, __mmask32)>>('_store_mask32');
  late final __store_mask32 = __store_mask32Ptr
      .asFunction<void Function(ffi.Pointer<__mmask32>, int)>();

  void _store_mask64(
    ffi.Pointer<__mmask64> arg0,
    int arg1,
  ) {
    return __store_mask64(
      arg0,
      arg1,
    );
  }

  late final __store_mask64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<__mmask64>, __mmask64)>>('_store_mask64');
  late final __store_mask64 = __store_mask64Ptr
      .asFunction<void Function(ffi.Pointer<__mmask64>, int)>();

  int _cvtmask8_u32(
    int arg0,
  ) {
    return __cvtmask8_u32(
      arg0,
    );
  }

  late final __cvtmask8_u32Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint32 Function(__mmask8)>>(
          '_cvtmask8_u32');
  late final __cvtmask8_u32 = __cvtmask8_u32Ptr.asFunction<int Function(int)>();

  int _cvtmask16_u32(
    int arg0,
  ) {
    return __cvtmask16_u32(
      arg0,
    );
  }

  late final __cvtmask16_u32Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint32 Function(__mmask16)>>(
          '_cvtmask16_u32');
  late final __cvtmask16_u32 =
      __cvtmask16_u32Ptr.asFunction<int Function(int)>();

  int _cvtmask32_u32(
    int arg0,
  ) {
    return __cvtmask32_u32(
      arg0,
    );
  }

  late final __cvtmask32_u32Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint32 Function(__mmask32)>>(
          '_cvtmask32_u32');
  late final __cvtmask32_u32 =
      __cvtmask32_u32Ptr.asFunction<int Function(int)>();

  int _cvtmask64_u64(
    int arg0,
  ) {
    return __cvtmask64_u64(
      arg0,
    );
  }

  late final __cvtmask64_u64Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function(__mmask64)>>(
          '_cvtmask64_u64');
  late final __cvtmask64_u64 =
      __cvtmask64_u64Ptr.asFunction<int Function(int)>();

  int _cvtu32_mask8(
    int arg0,
  ) {
    return __cvtu32_mask8(
      arg0,
    );
  }

  late final __cvtu32_mask8Ptr =
      _lookup<ffi.NativeFunction<__mmask8 Function(ffi.Uint32)>>(
          '_cvtu32_mask8');
  late final __cvtu32_mask8 = __cvtu32_mask8Ptr.asFunction<int Function(int)>();

  int _cvtu32_mask16(
    int arg0,
  ) {
    return __cvtu32_mask16(
      arg0,
    );
  }

  late final __cvtu32_mask16Ptr =
      _lookup<ffi.NativeFunction<__mmask16 Function(ffi.Uint32)>>(
          '_cvtu32_mask16');
  late final __cvtu32_mask16 =
      __cvtu32_mask16Ptr.asFunction<int Function(int)>();

  int _cvtu32_mask32(
    int arg0,
  ) {
    return __cvtu32_mask32(
      arg0,
    );
  }

  late final __cvtu32_mask32Ptr =
      _lookup<ffi.NativeFunction<__mmask32 Function(ffi.Uint32)>>(
          '_cvtu32_mask32');
  late final __cvtu32_mask32 =
      __cvtu32_mask32Ptr.asFunction<int Function(int)>();

  int _cvtu64_mask64(
    int arg0,
  ) {
    return __cvtu64_mask64(
      arg0,
    );
  }

  late final __cvtu64_mask64Ptr =
      _lookup<ffi.NativeFunction<__mmask64 Function(ffi.Uint64)>>(
          '_cvtu64_mask64');
  late final __cvtu64_mask64 =
      __cvtu64_mask64Ptr.asFunction<int Function(int)>();

  int _mm512_kmov(
    int arg0,
  ) {
    return __mm512_kmov(
      arg0,
    );
  }

  late final __mm512_kmovPtr =
      _lookup<ffi.NativeFunction<__mmask16 Function(__mmask16)>>('_mm512_kmov');
  late final __mm512_kmov = __mm512_kmovPtr.asFunction<int Function(int)>();

  int _kortest_mask8_u8(
    int arg0,
    int arg1,
    ffi.Pointer<ffi.Uint8> arg2,
  ) {
    return __kortest_mask8_u8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __kortest_mask8_u8Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Uint8 Function(__mmask8, __mmask8,
              ffi.Pointer<ffi.Uint8>)>>('_kortest_mask8_u8');
  late final __kortest_mask8_u8 = __kortest_mask8_u8Ptr
      .asFunction<int Function(int, int, ffi.Pointer<ffi.Uint8>)>();

  int _kortest_mask16_u8(
    int arg0,
    int arg1,
    ffi.Pointer<ffi.Uint8> arg2,
  ) {
    return __kortest_mask16_u8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __kortest_mask16_u8Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Uint8 Function(__mmask16, __mmask16,
              ffi.Pointer<ffi.Uint8>)>>('_kortest_mask16_u8');
  late final __kortest_mask16_u8 = __kortest_mask16_u8Ptr
      .asFunction<int Function(int, int, ffi.Pointer<ffi.Uint8>)>();

  int _kortest_mask32_u8(
    int arg0,
    int arg1,
    ffi.Pointer<ffi.Uint8> arg2,
  ) {
    return __kortest_mask32_u8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __kortest_mask32_u8Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Uint8 Function(__mmask32, __mmask32,
              ffi.Pointer<ffi.Uint8>)>>('_kortest_mask32_u8');
  late final __kortest_mask32_u8 = __kortest_mask32_u8Ptr
      .asFunction<int Function(int, int, ffi.Pointer<ffi.Uint8>)>();

  int _kortest_mask64_u8(
    int arg0,
    int arg1,
    ffi.Pointer<ffi.Uint8> arg2,
  ) {
    return __kortest_mask64_u8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __kortest_mask64_u8Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Uint8 Function(__mmask64, __mmask64,
              ffi.Pointer<ffi.Uint8>)>>('_kortest_mask64_u8');
  late final __kortest_mask64_u8 = __kortest_mask64_u8Ptr
      .asFunction<int Function(int, int, ffi.Pointer<ffi.Uint8>)>();

  int _ktest_mask8_u8(
    int arg0,
    int arg1,
    ffi.Pointer<ffi.Uint8> arg2,
  ) {
    return __ktest_mask8_u8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __ktest_mask8_u8Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Uint8 Function(
              __mmask8, __mmask8, ffi.Pointer<ffi.Uint8>)>>('_ktest_mask8_u8');
  late final __ktest_mask8_u8 = __ktest_mask8_u8Ptr
      .asFunction<int Function(int, int, ffi.Pointer<ffi.Uint8>)>();

  int _ktest_mask16_u8(
    int arg0,
    int arg1,
    ffi.Pointer<ffi.Uint8> arg2,
  ) {
    return __ktest_mask16_u8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __ktest_mask16_u8Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Uint8 Function(__mmask16, __mmask16,
              ffi.Pointer<ffi.Uint8>)>>('_ktest_mask16_u8');
  late final __ktest_mask16_u8 = __ktest_mask16_u8Ptr
      .asFunction<int Function(int, int, ffi.Pointer<ffi.Uint8>)>();

  int _ktest_mask32_u8(
    int arg0,
    int arg1,
    ffi.Pointer<ffi.Uint8> arg2,
  ) {
    return __ktest_mask32_u8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __ktest_mask32_u8Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Uint8 Function(__mmask32, __mmask32,
              ffi.Pointer<ffi.Uint8>)>>('_ktest_mask32_u8');
  late final __ktest_mask32_u8 = __ktest_mask32_u8Ptr
      .asFunction<int Function(int, int, ffi.Pointer<ffi.Uint8>)>();

  int _ktest_mask64_u8(
    int arg0,
    int arg1,
    ffi.Pointer<ffi.Uint8> arg2,
  ) {
    return __ktest_mask64_u8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __ktest_mask64_u8Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Uint8 Function(__mmask64, __mmask64,
              ffi.Pointer<ffi.Uint8>)>>('_ktest_mask64_u8');
  late final __ktest_mask64_u8 = __ktest_mask64_u8Ptr
      .asFunction<int Function(int, int, ffi.Pointer<ffi.Uint8>)>();

  __m512 _mm512_mask_exp2a23_round_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
    int arg3,
  ) {
    return __mm512_mask_exp2a23_round_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_exp2a23_round_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__m512, __mmask16, __m512,
              ffi.Int32)>>('_mm512_mask_exp2a23_round_ps');
  late final __mm512_mask_exp2a23_round_ps = __mm512_mask_exp2a23_round_psPtr
      .asFunction<__m512 Function(__m512, int, __m512, int)>();

  __m512 _mm512_maskz_exp2a23_round_ps(
    int arg0,
    __m512 arg1,
    int arg2,
  ) {
    return __mm512_maskz_exp2a23_round_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_exp2a23_round_psPtr = _lookup<
          ffi.NativeFunction<__m512 Function(__mmask16, __m512, ffi.Int32)>>(
      '_mm512_maskz_exp2a23_round_ps');
  late final __mm512_maskz_exp2a23_round_ps = __mm512_maskz_exp2a23_round_psPtr
      .asFunction<__m512 Function(int, __m512, int)>();

  _m512d _mm512_mask_exp2a23_round_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
    int arg3,
  ) {
    return __mm512_mask_exp2a23_round_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_exp2a23_round_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(_m512d, __mmask8, _m512d,
              ffi.Int32)>>('_mm512_mask_exp2a23_round_pd');
  late final __mm512_mask_exp2a23_round_pd = __mm512_mask_exp2a23_round_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d, int)>();

  _m512d _mm512_maskz_exp2a23_round_pd(
    int arg0,
    _m512d arg1,
    int arg2,
  ) {
    return __mm512_maskz_exp2a23_round_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_exp2a23_round_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(__mmask8, _m512d, ffi.Int32)>>(
          '_mm512_maskz_exp2a23_round_pd');
  late final __mm512_maskz_exp2a23_round_pd = __mm512_maskz_exp2a23_round_pdPtr
      .asFunction<_m512d Function(int, _m512d, int)>();

  __m512 _mm512_mask_rcp28_round_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
    int arg3,
  ) {
    return __mm512_mask_rcp28_round_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_rcp28_round_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__m512, __mmask16, __m512,
              ffi.Int32)>>('_mm512_mask_rcp28_round_ps');
  late final __mm512_mask_rcp28_round_ps = __mm512_mask_rcp28_round_psPtr
      .asFunction<__m512 Function(__m512, int, __m512, int)>();

  __m512 _mm512_maskz_rcp28_round_ps(
    int arg0,
    __m512 arg1,
    int arg2,
  ) {
    return __mm512_maskz_rcp28_round_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_rcp28_round_psPtr = _lookup<
          ffi.NativeFunction<__m512 Function(__mmask16, __m512, ffi.Int32)>>(
      '_mm512_maskz_rcp28_round_ps');
  late final __mm512_maskz_rcp28_round_ps = __mm512_maskz_rcp28_round_psPtr
      .asFunction<__m512 Function(int, __m512, int)>();

  _m512d _mm512_mask_rcp28_round_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
    int arg3,
  ) {
    return __mm512_mask_rcp28_round_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_rcp28_round_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(_m512d, __mmask8, _m512d,
              ffi.Int32)>>('_mm512_mask_rcp28_round_pd');
  late final __mm512_mask_rcp28_round_pd = __mm512_mask_rcp28_round_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d, int)>();

  _m512d _mm512_maskz_rcp28_round_pd(
    int arg0,
    _m512d arg1,
    int arg2,
  ) {
    return __mm512_maskz_rcp28_round_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_rcp28_round_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(__mmask8, _m512d, ffi.Int32)>>(
          '_mm512_maskz_rcp28_round_pd');
  late final __mm512_maskz_rcp28_round_pd = __mm512_maskz_rcp28_round_pdPtr
      .asFunction<_m512d Function(int, _m512d, int)>();

  __m512 _mm512_mask_rsqrt28_round_ps(
    __m512 arg0,
    int arg1,
    __m512 arg2,
    int arg3,
  ) {
    return __mm512_mask_rsqrt28_round_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_rsqrt28_round_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__m512, __mmask16, __m512,
              ffi.Int32)>>('_mm512_mask_rsqrt28_round_ps');
  late final __mm512_mask_rsqrt28_round_ps = __mm512_mask_rsqrt28_round_psPtr
      .asFunction<__m512 Function(__m512, int, __m512, int)>();

  __m512 _mm512_maskz_rsqrt28_round_ps(
    int arg0,
    __m512 arg1,
    int arg2,
  ) {
    return __mm512_maskz_rsqrt28_round_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_rsqrt28_round_psPtr = _lookup<
          ffi.NativeFunction<__m512 Function(__mmask16, __m512, ffi.Int32)>>(
      '_mm512_maskz_rsqrt28_round_ps');
  late final __mm512_maskz_rsqrt28_round_ps = __mm512_maskz_rsqrt28_round_psPtr
      .asFunction<__m512 Function(int, __m512, int)>();

  _m512d _mm512_mask_rsqrt28_round_pd(
    _m512d arg0,
    int arg1,
    _m512d arg2,
    int arg3,
  ) {
    return __mm512_mask_rsqrt28_round_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_rsqrt28_round_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(_m512d, __mmask8, _m512d,
              ffi.Int32)>>('_mm512_mask_rsqrt28_round_pd');
  late final __mm512_mask_rsqrt28_round_pd = __mm512_mask_rsqrt28_round_pdPtr
      .asFunction<_m512d Function(_m512d, int, _m512d, int)>();

  _m512d _mm512_maskz_rsqrt28_round_pd(
    int arg0,
    _m512d arg1,
    int arg2,
  ) {
    return __mm512_maskz_rsqrt28_round_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_rsqrt28_round_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(__mmask8, _m512d, ffi.Int32)>>(
          '_mm512_maskz_rsqrt28_round_pd');
  late final __mm512_maskz_rsqrt28_round_pd = __mm512_maskz_rsqrt28_round_pdPtr
      .asFunction<_m512d Function(int, _m512d, int)>();

  void _mm512_prefetch_i32gather_pd(
    __m256i vindex,
    ffi.Pointer<ffi.Void> base_addr,
    int scale,
    int hint,
  ) {
    return __mm512_prefetch_i32gather_pd(
      vindex,
      base_addr,
      scale,
      hint,
    );
  }

  late final __mm512_prefetch_i32gather_pdPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(__m256i, ffi.Pointer<ffi.Void>, ffi.Int32,
              ffi.Int32)>>('_mm512_prefetch_i32gather_pd');
  late final __mm512_prefetch_i32gather_pd = __mm512_prefetch_i32gather_pdPtr
      .asFunction<void Function(__m256i, ffi.Pointer<ffi.Void>, int, int)>();

  void _mm512_prefetch_i32gather_ps(
    __m512i index,
    ffi.Pointer<ffi.Void> mv,
    int scale,
    int hint,
  ) {
    return __mm512_prefetch_i32gather_ps(
      index,
      mv,
      scale,
      hint,
    );
  }

  late final __mm512_prefetch_i32gather_psPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(__m512i, ffi.Pointer<ffi.Void>, ffi.Int32,
              ffi.Int32)>>('_mm512_prefetch_i32gather_ps');
  late final __mm512_prefetch_i32gather_ps = __mm512_prefetch_i32gather_psPtr
      .asFunction<void Function(__m512i, ffi.Pointer<ffi.Void>, int, int)>();

  void _mm512_prefetch_i32scatter_pd(
    ffi.Pointer<ffi.Void> base_addr,
    __m256i vindex,
    int scale,
    int hint,
  ) {
    return __mm512_prefetch_i32scatter_pd(
      base_addr,
      vindex,
      scale,
      hint,
    );
  }

  late final __mm512_prefetch_i32scatter_pdPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __m256i, ffi.Int32,
              ffi.Int32)>>('_mm512_prefetch_i32scatter_pd');
  late final __mm512_prefetch_i32scatter_pd = __mm512_prefetch_i32scatter_pdPtr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, __m256i, int, int)>();

  void _mm512_prefetch_i32scatter_ps(
    ffi.Pointer<ffi.Void> mv,
    __m512i index,
    int scale,
    int hint,
  ) {
    return __mm512_prefetch_i32scatter_ps(
      mv,
      index,
      scale,
      hint,
    );
  }

  late final __mm512_prefetch_i32scatter_psPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __m512i, ffi.Int32,
              ffi.Int32)>>('_mm512_prefetch_i32scatter_ps');
  late final __mm512_prefetch_i32scatter_ps = __mm512_prefetch_i32scatter_psPtr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, __m512i, int, int)>();

  void _mm512_prefetch_i64gather_pd(
    __m512i vindex,
    ffi.Pointer<ffi.Void> base_addr,
    int scale,
    int hint,
  ) {
    return __mm512_prefetch_i64gather_pd(
      vindex,
      base_addr,
      scale,
      hint,
    );
  }

  late final __mm512_prefetch_i64gather_pdPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(__m512i, ffi.Pointer<ffi.Void>, ffi.Int32,
              ffi.Int32)>>('_mm512_prefetch_i64gather_pd');
  late final __mm512_prefetch_i64gather_pd = __mm512_prefetch_i64gather_pdPtr
      .asFunction<void Function(__m512i, ffi.Pointer<ffi.Void>, int, int)>();

  void _mm512_prefetch_i64gather_ps(
    __m512i vindex,
    ffi.Pointer<ffi.Void> base_addr,
    int scale,
    int hint,
  ) {
    return __mm512_prefetch_i64gather_ps(
      vindex,
      base_addr,
      scale,
      hint,
    );
  }

  late final __mm512_prefetch_i64gather_psPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(__m512i, ffi.Pointer<ffi.Void>, ffi.Int32,
              ffi.Int32)>>('_mm512_prefetch_i64gather_ps');
  late final __mm512_prefetch_i64gather_ps = __mm512_prefetch_i64gather_psPtr
      .asFunction<void Function(__m512i, ffi.Pointer<ffi.Void>, int, int)>();

  void _mm512_prefetch_i64scatter_pd(
    ffi.Pointer<ffi.Void> base_addr,
    __m512i vindex,
    int scale,
    int hint,
  ) {
    return __mm512_prefetch_i64scatter_pd(
      base_addr,
      vindex,
      scale,
      hint,
    );
  }

  late final __mm512_prefetch_i64scatter_pdPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __m512i, ffi.Int32,
              ffi.Int32)>>('_mm512_prefetch_i64scatter_pd');
  late final __mm512_prefetch_i64scatter_pd = __mm512_prefetch_i64scatter_pdPtr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, __m512i, int, int)>();

  void _mm512_prefetch_i64scatter_ps(
    ffi.Pointer<ffi.Void> base_addr,
    __m512i vindex,
    int scale,
    int hint,
  ) {
    return __mm512_prefetch_i64scatter_ps(
      base_addr,
      vindex,
      scale,
      hint,
    );
  }

  late final __mm512_prefetch_i64scatter_psPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __m512i, ffi.Int32,
              ffi.Int32)>>('_mm512_prefetch_i64scatter_ps');
  late final __mm512_prefetch_i64scatter_ps = __mm512_prefetch_i64scatter_psPtr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, __m512i, int, int)>();

  void _mm512_mask_prefetch_i32gather_pd(
    __m256i vindex,
    int mask,
    ffi.Pointer<ffi.Void> base_addr,
    int scale,
    int hint,
  ) {
    return __mm512_mask_prefetch_i32gather_pd(
      vindex,
      mask,
      base_addr,
      scale,
      hint,
    );
  }

  late final __mm512_mask_prefetch_i32gather_pdPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(__m256i, __mmask8, ffi.Pointer<ffi.Void>, ffi.Int32,
              ffi.Int32)>>('_mm512_mask_prefetch_i32gather_pd');
  late final __mm512_mask_prefetch_i32gather_pd =
      __mm512_mask_prefetch_i32gather_pdPtr.asFunction<
          void Function(__m256i, int, ffi.Pointer<ffi.Void>, int, int)>();

  void _mm512_mask_prefetch_i32gather_ps(
    __m512i vindex,
    int mask,
    ffi.Pointer<ffi.Void> base_addr,
    int scale,
    int hint,
  ) {
    return __mm512_mask_prefetch_i32gather_ps(
      vindex,
      mask,
      base_addr,
      scale,
      hint,
    );
  }

  late final __mm512_mask_prefetch_i32gather_psPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(__m512i, __mmask16, ffi.Pointer<ffi.Void>,
              ffi.Int32, ffi.Int32)>>('_mm512_mask_prefetch_i32gather_ps');
  late final __mm512_mask_prefetch_i32gather_ps =
      __mm512_mask_prefetch_i32gather_psPtr.asFunction<
          void Function(__m512i, int, ffi.Pointer<ffi.Void>, int, int)>();

  void _mm512_mask_prefetch_i32scatter_pd(
    ffi.Pointer<ffi.Void> base_addr,
    int mask,
    __m256i vinde,
    int scale,
    int hint,
  ) {
    return __mm512_mask_prefetch_i32scatter_pd(
      base_addr,
      mask,
      vinde,
      scale,
      hint,
    );
  }

  late final __mm512_mask_prefetch_i32scatter_pdPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8, __m256i, ffi.Int32,
              ffi.Int32)>>('_mm512_mask_prefetch_i32scatter_pd');
  late final __mm512_mask_prefetch_i32scatter_pd =
      __mm512_mask_prefetch_i32scatter_pdPtr.asFunction<
          void Function(ffi.Pointer<ffi.Void>, int, __m256i, int, int)>();

  void _mm512_mask_prefetch_i32scatter_ps(
    ffi.Pointer<ffi.Void> mv,
    int k,
    __m512i index,
    int scale,
    int hint,
  ) {
    return __mm512_mask_prefetch_i32scatter_ps(
      mv,
      k,
      index,
      scale,
      hint,
    );
  }

  late final __mm512_mask_prefetch_i32scatter_psPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask16, __m512i,
              ffi.Int32, ffi.Int32)>>('_mm512_mask_prefetch_i32scatter_ps');
  late final __mm512_mask_prefetch_i32scatter_ps =
      __mm512_mask_prefetch_i32scatter_psPtr.asFunction<
          void Function(ffi.Pointer<ffi.Void>, int, __m512i, int, int)>();

  void _mm512_mask_prefetch_i64gather_pd(
    __m512i vindex,
    int mask,
    ffi.Pointer<ffi.Void> base_addr,
    int scale,
    int hint,
  ) {
    return __mm512_mask_prefetch_i64gather_pd(
      vindex,
      mask,
      base_addr,
      scale,
      hint,
    );
  }

  late final __mm512_mask_prefetch_i64gather_pdPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(__m512i, __mmask8, ffi.Pointer<ffi.Void>, ffi.Int32,
              ffi.Int32)>>('_mm512_mask_prefetch_i64gather_pd');
  late final __mm512_mask_prefetch_i64gather_pd =
      __mm512_mask_prefetch_i64gather_pdPtr.asFunction<
          void Function(__m512i, int, ffi.Pointer<ffi.Void>, int, int)>();

  void _mm512_mask_prefetch_i64gather_ps(
    __m512i vindex,
    int mask,
    ffi.Pointer<ffi.Void> base_addr,
    int scale,
    int hint,
  ) {
    return __mm512_mask_prefetch_i64gather_ps(
      vindex,
      mask,
      base_addr,
      scale,
      hint,
    );
  }

  late final __mm512_mask_prefetch_i64gather_psPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(__m512i, __mmask8, ffi.Pointer<ffi.Void>, ffi.Int32,
              ffi.Int32)>>('_mm512_mask_prefetch_i64gather_ps');
  late final __mm512_mask_prefetch_i64gather_ps =
      __mm512_mask_prefetch_i64gather_psPtr.asFunction<
          void Function(__m512i, int, ffi.Pointer<ffi.Void>, int, int)>();

  void _mm512_mask_prefetch_i64scatter_pd(
    ffi.Pointer<ffi.Void> base_addr,
    int mask,
    __m512i vindex,
    int scale,
    int hint,
  ) {
    return __mm512_mask_prefetch_i64scatter_pd(
      base_addr,
      mask,
      vindex,
      scale,
      hint,
    );
  }

  late final __mm512_mask_prefetch_i64scatter_pdPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8, __m512i, ffi.Int32,
              ffi.Int32)>>('_mm512_mask_prefetch_i64scatter_pd');
  late final __mm512_mask_prefetch_i64scatter_pd =
      __mm512_mask_prefetch_i64scatter_pdPtr.asFunction<
          void Function(ffi.Pointer<ffi.Void>, int, __m512i, int, int)>();

  void _mm512_mask_prefetch_i64scatter_ps(
    ffi.Pointer<ffi.Void> base_addr,
    int mask,
    __m512i vindex,
    int scale,
    int hint,
  ) {
    return __mm512_mask_prefetch_i64scatter_ps(
      base_addr,
      mask,
      vindex,
      scale,
      hint,
    );
  }

  late final __mm512_mask_prefetch_i64scatter_psPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __mmask8, __m512i, ffi.Int32,
              ffi.Int32)>>('_mm512_mask_prefetch_i64scatter_ps');
  late final __mm512_mask_prefetch_i64scatter_ps =
      __mm512_mask_prefetch_i64scatter_psPtr.asFunction<
          void Function(ffi.Pointer<ffi.Void>, int, __m512i, int, int)>();

  void _mm_2intersect_epi32(
    __m128i arg0,
    __m128i arg1,
    ffi.Pointer<__mmask8> arg2,
    ffi.Pointer<__mmask8> arg3,
  ) {
    return __mm_2intersect_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_2intersect_epi32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(__m128i, __m128i, ffi.Pointer<__mmask8>,
              ffi.Pointer<__mmask8>)>>('_mm_2intersect_epi32');
  late final __mm_2intersect_epi32 = __mm_2intersect_epi32Ptr.asFunction<
      void Function(
          __m128i, __m128i, ffi.Pointer<__mmask8>, ffi.Pointer<__mmask8>)>();

  void _mm256_2intersect_epi32(
    __m256i arg0,
    __m256i arg1,
    ffi.Pointer<__mmask8> arg2,
    ffi.Pointer<__mmask8> arg3,
  ) {
    return __mm256_2intersect_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_2intersect_epi32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(__m256i, __m256i, ffi.Pointer<__mmask8>,
              ffi.Pointer<__mmask8>)>>('_mm256_2intersect_epi32');
  late final __mm256_2intersect_epi32 = __mm256_2intersect_epi32Ptr.asFunction<
      void Function(
          __m256i, __m256i, ffi.Pointer<__mmask8>, ffi.Pointer<__mmask8>)>();

  void _mm512_2intersect_epi32(
    __m512i arg0,
    __m512i arg1,
    ffi.Pointer<__mmask16> arg2,
    ffi.Pointer<__mmask16> arg3,
  ) {
    return __mm512_2intersect_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_2intersect_epi32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(__m512i, __m512i, ffi.Pointer<__mmask16>,
              ffi.Pointer<__mmask16>)>>('_mm512_2intersect_epi32');
  late final __mm512_2intersect_epi32 = __mm512_2intersect_epi32Ptr.asFunction<
      void Function(
          __m512i, __m512i, ffi.Pointer<__mmask16>, ffi.Pointer<__mmask16>)>();

  void _mm_2intersect_epi64(
    __m128i arg0,
    __m128i arg1,
    ffi.Pointer<__mmask8> arg2,
    ffi.Pointer<__mmask8> arg3,
  ) {
    return __mm_2intersect_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_2intersect_epi64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(__m128i, __m128i, ffi.Pointer<__mmask8>,
              ffi.Pointer<__mmask8>)>>('_mm_2intersect_epi64');
  late final __mm_2intersect_epi64 = __mm_2intersect_epi64Ptr.asFunction<
      void Function(
          __m128i, __m128i, ffi.Pointer<__mmask8>, ffi.Pointer<__mmask8>)>();

  void _mm256_2intersect_epi64(
    __m256i arg0,
    __m256i arg1,
    ffi.Pointer<__mmask8> arg2,
    ffi.Pointer<__mmask8> arg3,
  ) {
    return __mm256_2intersect_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_2intersect_epi64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(__m256i, __m256i, ffi.Pointer<__mmask8>,
              ffi.Pointer<__mmask8>)>>('_mm256_2intersect_epi64');
  late final __mm256_2intersect_epi64 = __mm256_2intersect_epi64Ptr.asFunction<
      void Function(
          __m256i, __m256i, ffi.Pointer<__mmask8>, ffi.Pointer<__mmask8>)>();

  void _mm512_2intersect_epi64(
    __m512i arg0,
    __m512i arg1,
    ffi.Pointer<__mmask8> arg2,
    ffi.Pointer<__mmask8> arg3,
  ) {
    return __mm512_2intersect_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_2intersect_epi64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(__m512i, __m512i, ffi.Pointer<__mmask8>,
              ffi.Pointer<__mmask8>)>>('_mm512_2intersect_epi64');
  late final __mm512_2intersect_epi64 = __mm512_2intersect_epi64Ptr.asFunction<
      void Function(
          __m512i, __m512i, ffi.Pointer<__mmask8>, ffi.Pointer<__mmask8>)>();

  void _tile_loadconfig(
    ffi.Pointer<ffi.Void> arg0,
  ) {
    return __tile_loadconfig(
      arg0,
    );
  }

  late final __tile_loadconfigPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ffi.Void>)>>(
          '_tile_loadconfig');
  late final __tile_loadconfig =
      __tile_loadconfigPtr.asFunction<void Function(ffi.Pointer<ffi.Void>)>();

  void _tile_storeconfig(
    ffi.Pointer<ffi.Void> arg0,
  ) {
    return __tile_storeconfig(
      arg0,
    );
  }

  late final __tile_storeconfigPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ffi.Void>)>>(
          '_tile_storeconfig');
  late final __tile_storeconfig =
      __tile_storeconfigPtr.asFunction<void Function(ffi.Pointer<ffi.Void>)>();

  void _tile_release() {
    return __tile_release();
  }

  late final __tile_releasePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('_tile_release');
  late final __tile_release = __tile_releasePtr.asFunction<void Function()>();

  void _tile_loadd(
    int dst,
    ffi.Pointer<ffi.Void> base,
    int stride,
  ) {
    return __tile_loadd(
      dst,
      base,
      stride,
    );
  }

  late final __tile_loaddPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              __tile, ffi.Pointer<ffi.Void>, ffi.Int32)>>('_tile_loadd');
  late final __tile_loadd = __tile_loaddPtr
      .asFunction<void Function(int, ffi.Pointer<ffi.Void>, int)>();

  void _tile_stream_loadd(
    int dst,
    ffi.Pointer<ffi.Void> base,
    int stride,
  ) {
    return __tile_stream_loadd(
      dst,
      base,
      stride,
    );
  }

  late final __tile_stream_loaddPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              __tile, ffi.Pointer<ffi.Void>, ffi.Int32)>>('_tile_stream_loadd');
  late final __tile_stream_loadd = __tile_stream_loaddPtr
      .asFunction<void Function(int, ffi.Pointer<ffi.Void>, int)>();

  void _tile_stored(
    int src,
    ffi.Pointer<ffi.Void> base,
    int stride,
  ) {
    return __tile_stored(
      src,
      base,
      stride,
    );
  }

  late final __tile_storedPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              __tile, ffi.Pointer<ffi.Void>, ffi.Int32)>>('_tile_stored');
  late final __tile_stored = __tile_storedPtr
      .asFunction<void Function(int, ffi.Pointer<ffi.Void>, int)>();

  void _tile_zero(
    int dst,
  ) {
    return __tile_zero(
      dst,
    );
  }

  late final __tile_zeroPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(__tile)>>('_tile_zero');
  late final __tile_zero = __tile_zeroPtr.asFunction<void Function(int)>();

  void _tile_dpbf16ps(
    int dst,
    int src1,
    int src2,
  ) {
    return __tile_dpbf16ps(
      dst,
      src1,
      src2,
    );
  }

  late final __tile_dpbf16psPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(__tile, __tile, __tile)>>(
          '_tile_dpbf16ps');
  late final __tile_dpbf16ps =
      __tile_dpbf16psPtr.asFunction<void Function(int, int, int)>();

  void _tile_dpbssd(
    int dst,
    int src1,
    int src2,
  ) {
    return __tile_dpbssd(
      dst,
      src1,
      src2,
    );
  }

  late final __tile_dpbssdPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(__tile, __tile, __tile)>>(
          '_tile_dpbssd');
  late final __tile_dpbssd =
      __tile_dpbssdPtr.asFunction<void Function(int, int, int)>();

  void _tile_dpbsud(
    int dst,
    int src1,
    int src2,
  ) {
    return __tile_dpbsud(
      dst,
      src1,
      src2,
    );
  }

  late final __tile_dpbsudPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(__tile, __tile, __tile)>>(
          '_tile_dpbsud');
  late final __tile_dpbsud =
      __tile_dpbsudPtr.asFunction<void Function(int, int, int)>();

  void _tile_dpbusd(
    int dst,
    int src1,
    int src2,
  ) {
    return __tile_dpbusd(
      dst,
      src1,
      src2,
    );
  }

  late final __tile_dpbusdPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(__tile, __tile, __tile)>>(
          '_tile_dpbusd');
  late final __tile_dpbusd =
      __tile_dpbusdPtr.asFunction<void Function(int, int, int)>();

  void _tile_dpbuud(
    int dst,
    int src1,
    int src2,
  ) {
    return __tile_dpbuud(
      dst,
      src1,
      src2,
    );
  }

  late final __tile_dpbuudPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(__tile, __tile, __tile)>>(
          '_tile_dpbuud');
  late final __tile_dpbuud =
      __tile_dpbuudPtr.asFunction<void Function(int, int, int)>();

  __m128h _mm_add_ph(
    __m128h arg0,
    __m128h arg1,
  ) {
    return __mm_add_ph(
      arg0,
      arg1,
    );
  }

  late final __mm_add_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128h, __m128h)>>(
          '_mm_add_ph');
  late final __mm_add_ph =
      __mm_add_phPtr.asFunction<__m128h Function(__m128h, __m128h)>();

  __m128h _mm_mask_add_ph(
    __m128h arg0,
    int arg1,
    __m128h arg2,
    __m128h arg3,
  ) {
    return __mm_mask_add_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_add_phPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __m128h, __mmask8, __m128h, __m128h)>>('_mm_mask_add_ph');
  late final __mm_mask_add_ph = __mm_mask_add_phPtr
      .asFunction<__m128h Function(__m128h, int, __m128h, __m128h)>();

  __m128h _mm_maskz_add_ph(
    int arg0,
    __m128h arg1,
    __m128h arg2,
  ) {
    return __mm_maskz_add_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_add_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__mmask8, __m128h, __m128h)>>(
          '_mm_maskz_add_ph');
  late final __mm_maskz_add_ph = __mm_maskz_add_phPtr
      .asFunction<__m128h Function(int, __m128h, __m128h)>();

  __m256h _mm256_add_ph(
    __m256h arg0,
    __m256h arg1,
  ) {
    return __mm256_add_ph(
      arg0,
      arg1,
    );
  }

  late final __mm256_add_phPtr =
      _lookup<ffi.NativeFunction<__m256h Function(__m256h, __m256h)>>(
          '_mm256_add_ph');
  late final __mm256_add_ph =
      __mm256_add_phPtr.asFunction<__m256h Function(__m256h, __m256h)>();

  __m256h _mm256_mask_add_ph(
    __m256h arg0,
    int arg1,
    __m256h arg2,
    __m256h arg3,
  ) {
    return __mm256_mask_add_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_add_phPtr = _lookup<
      ffi.NativeFunction<
          __m256h Function(
              __m256h, __mmask16, __m256h, __m256h)>>('_mm256_mask_add_ph');
  late final __mm256_mask_add_ph = __mm256_mask_add_phPtr
      .asFunction<__m256h Function(__m256h, int, __m256h, __m256h)>();

  __m256h _mm256_maskz_add_ph(
    int arg0,
    __m256h arg1,
    __m256h arg2,
  ) {
    return __mm256_maskz_add_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_add_phPtr = _lookup<
          ffi.NativeFunction<__m256h Function(__mmask16, __m256h, __m256h)>>(
      '_mm256_maskz_add_ph');
  late final __mm256_maskz_add_ph = __mm256_maskz_add_phPtr
      .asFunction<__m256h Function(int, __m256h, __m256h)>();

  __m512h _mm512_add_ph(
    __m512h arg0,
    __m512h arg1,
  ) {
    return __mm512_add_ph(
      arg0,
      arg1,
    );
  }

  late final __mm512_add_phPtr =
      _lookup<ffi.NativeFunction<__m512h Function(__m512h, __m512h)>>(
          '_mm512_add_ph');
  late final __mm512_add_ph =
      __mm512_add_phPtr.asFunction<__m512h Function(__m512h, __m512h)>();

  __m512h _mm512_mask_add_ph(
    __m512h arg0,
    int arg1,
    __m512h arg2,
    __m512h arg3,
  ) {
    return __mm512_mask_add_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_add_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(
              __m512h, __mmask32, __m512h, __m512h)>>('_mm512_mask_add_ph');
  late final __mm512_mask_add_ph = __mm512_mask_add_phPtr
      .asFunction<__m512h Function(__m512h, int, __m512h, __m512h)>();

  __m512h _mm512_maskz_add_ph(
    int arg0,
    __m512h arg1,
    __m512h arg2,
  ) {
    return __mm512_maskz_add_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_add_phPtr = _lookup<
          ffi.NativeFunction<__m512h Function(__mmask32, __m512h, __m512h)>>(
      '_mm512_maskz_add_ph');
  late final __mm512_maskz_add_ph = __mm512_maskz_add_phPtr
      .asFunction<__m512h Function(int, __m512h, __m512h)>();

  __m512h _mm512_add_round_ph(
    __m512h arg0,
    __m512h arg1,
    int arg2,
  ) {
    return __mm512_add_round_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_add_round_phPtr = _lookup<
          ffi.NativeFunction<__m512h Function(__m512h, __m512h, ffi.Int32)>>(
      '_mm512_add_round_ph');
  late final __mm512_add_round_ph = __mm512_add_round_phPtr
      .asFunction<__m512h Function(__m512h, __m512h, int)>();

  __m512h _mm512_mask_add_round_ph(
    __m512h arg0,
    int arg1,
    __m512h arg2,
    __m512h arg3,
    int arg4,
  ) {
    return __mm512_mask_add_round_ph(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_add_round_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(__m512h, __mmask32, __m512h, __m512h,
              ffi.Int32)>>('_mm512_mask_add_round_ph');
  late final __mm512_mask_add_round_ph = __mm512_mask_add_round_phPtr
      .asFunction<__m512h Function(__m512h, int, __m512h, __m512h, int)>();

  __m512h _mm512_maskz_add_round_ph(
    int arg0,
    __m512h arg1,
    __m512h arg2,
    int arg3,
  ) {
    return __mm512_maskz_add_round_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_add_round_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(__mmask32, __m512h, __m512h,
              ffi.Int32)>>('_mm512_maskz_add_round_ph');
  late final __mm512_maskz_add_round_ph = __mm512_maskz_add_round_phPtr
      .asFunction<__m512h Function(int, __m512h, __m512h, int)>();

  __m128h _mm_add_sh(
    __m128h arg0,
    __m128h arg1,
  ) {
    return __mm_add_sh(
      arg0,
      arg1,
    );
  }

  late final __mm_add_shPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128h, __m128h)>>(
          '_mm_add_sh');
  late final __mm_add_sh =
      __mm_add_shPtr.asFunction<__m128h Function(__m128h, __m128h)>();

  __m128h _mm_mask_add_sh(
    __m128h arg0,
    int arg1,
    __m128h arg2,
    __m128h arg3,
  ) {
    return __mm_mask_add_sh(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_add_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __m128h, __mmask8, __m128h, __m128h)>>('_mm_mask_add_sh');
  late final __mm_mask_add_sh = __mm_mask_add_shPtr
      .asFunction<__m128h Function(__m128h, int, __m128h, __m128h)>();

  __m128h _mm_maskz_add_sh(
    int arg0,
    __m128h arg1,
    __m128h arg2,
  ) {
    return __mm_maskz_add_sh(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_add_shPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__mmask8, __m128h, __m128h)>>(
          '_mm_maskz_add_sh');
  late final __mm_maskz_add_sh = __mm_maskz_add_shPtr
      .asFunction<__m128h Function(int, __m128h, __m128h)>();

  __m128h _mm_add_round_sh(
    __m128h arg0,
    __m128h arg1,
    int arg2,
  ) {
    return __mm_add_round_sh(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_add_round_shPtr = _lookup<
          ffi.NativeFunction<__m128h Function(__m128h, __m128h, ffi.Int32)>>(
      '_mm_add_round_sh');
  late final __mm_add_round_sh = __mm_add_round_shPtr
      .asFunction<__m128h Function(__m128h, __m128h, int)>();

  __m128h _mm_mask_add_round_sh(
    __m128h arg0,
    int arg1,
    __m128h arg2,
    __m128h arg3,
    int arg4,
  ) {
    return __mm_mask_add_round_sh(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_add_round_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(__m128h, __mmask8, __m128h, __m128h,
              ffi.Int32)>>('_mm_mask_add_round_sh');
  late final __mm_mask_add_round_sh = __mm_mask_add_round_shPtr
      .asFunction<__m128h Function(__m128h, int, __m128h, __m128h, int)>();

  __m128h _mm_maskz_add_round_sh(
    int arg0,
    __m128h arg1,
    __m128h arg2,
    int arg3,
  ) {
    return __mm_maskz_add_round_sh(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_add_round_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(__mmask8, __m128h, __m128h,
              ffi.Int32)>>('_mm_maskz_add_round_sh');
  late final __mm_maskz_add_round_sh = __mm_maskz_add_round_shPtr
      .asFunction<__m128h Function(int, __m128h, __m128h, int)>();

  int _mm_cmp_ph_mask(
    __m128h arg0,
    __m128h arg1,
    int arg2,
  ) {
    return __mm_cmp_ph_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_cmp_ph_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__m128h, __m128h, ffi.Int32)>>(
      '_mm_cmp_ph_mask');
  late final __mm_cmp_ph_mask =
      __mm_cmp_ph_maskPtr.asFunction<int Function(__m128h, __m128h, int)>();

  int _mm_mask_cmp_ph_mask(
    int arg0,
    __m128h arg1,
    __m128h arg2,
    int arg3,
  ) {
    return __mm_mask_cmp_ph_mask(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_cmp_ph_maskPtr = _lookup<
      ffi.NativeFunction<
          __mmask8 Function(
              __mmask8, __m128h, __m128h, ffi.Int32)>>('_mm_mask_cmp_ph_mask');
  late final __mm_mask_cmp_ph_mask = __mm_mask_cmp_ph_maskPtr
      .asFunction<int Function(int, __m128h, __m128h, int)>();

  int _mm256_cmp_ph_mask(
    __m256h arg0,
    __m256h arg1,
    int arg2,
  ) {
    return __mm256_cmp_ph_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_cmp_ph_maskPtr = _lookup<
          ffi.NativeFunction<__mmask16 Function(__m256h, __m256h, ffi.Int32)>>(
      '_mm256_cmp_ph_mask');
  late final __mm256_cmp_ph_mask =
      __mm256_cmp_ph_maskPtr.asFunction<int Function(__m256h, __m256h, int)>();

  int _mm256_mask_cmp_ph_mask(
    int arg0,
    __m256h arg1,
    __m256h arg2,
    int arg3,
  ) {
    return __mm256_mask_cmp_ph_mask(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_cmp_ph_maskPtr = _lookup<
      ffi.NativeFunction<
          __mmask16 Function(__mmask16, __m256h, __m256h,
              ffi.Int32)>>('_mm256_mask_cmp_ph_mask');
  late final __mm256_mask_cmp_ph_mask = __mm256_mask_cmp_ph_maskPtr
      .asFunction<int Function(int, __m256h, __m256h, int)>();

  int _mm512_cmp_ph_mask(
    __m512h arg0,
    __m512h arg1,
    int arg2,
  ) {
    return __mm512_cmp_ph_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_cmp_ph_maskPtr = _lookup<
          ffi.NativeFunction<__mmask32 Function(__m512h, __m512h, ffi.Int32)>>(
      '_mm512_cmp_ph_mask');
  late final __mm512_cmp_ph_mask =
      __mm512_cmp_ph_maskPtr.asFunction<int Function(__m512h, __m512h, int)>();

  int _mm512_mask_cmp_ph_mask(
    int arg0,
    __m512h arg1,
    __m512h arg2,
    int arg3,
  ) {
    return __mm512_mask_cmp_ph_mask(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_cmp_ph_maskPtr = _lookup<
      ffi.NativeFunction<
          __mmask32 Function(__mmask32, __m512h, __m512h,
              ffi.Int32)>>('_mm512_mask_cmp_ph_mask');
  late final __mm512_mask_cmp_ph_mask = __mm512_mask_cmp_ph_maskPtr
      .asFunction<int Function(int, __m512h, __m512h, int)>();

  int _mm512_cmp_round_ph_mask(
    __m512h arg0,
    __m512h arg1,
    int arg2,
    int arg3,
  ) {
    return __mm512_cmp_round_ph_mask(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_cmp_round_ph_maskPtr = _lookup<
      ffi.NativeFunction<
          __mmask32 Function(__m512h, __m512h, ffi.Int32,
              ffi.Int32)>>('_mm512_cmp_round_ph_mask');
  late final __mm512_cmp_round_ph_mask = __mm512_cmp_round_ph_maskPtr
      .asFunction<int Function(__m512h, __m512h, int, int)>();

  int _mm512_mask_cmp_round_ph_mask(
    int arg0,
    __m512h arg1,
    __m512h arg2,
    int arg3,
    int arg4,
  ) {
    return __mm512_mask_cmp_round_ph_mask(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_cmp_round_ph_maskPtr = _lookup<
      ffi.NativeFunction<
          __mmask32 Function(__mmask32, __m512h, __m512h, ffi.Int32,
              ffi.Int32)>>('_mm512_mask_cmp_round_ph_mask');
  late final __mm512_mask_cmp_round_ph_mask = __mm512_mask_cmp_round_ph_maskPtr
      .asFunction<int Function(int, __m512h, __m512h, int, int)>();

  int _mm_cmp_sh_mask(
    __m128h arg0,
    __m128h arg1,
    int arg2,
  ) {
    return __mm_cmp_sh_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_cmp_sh_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__m128h, __m128h, ffi.Int32)>>(
      '_mm_cmp_sh_mask');
  late final __mm_cmp_sh_mask =
      __mm_cmp_sh_maskPtr.asFunction<int Function(__m128h, __m128h, int)>();

  int _mm_mask_cmp_sh_mask(
    int arg0,
    __m128h arg1,
    __m128h arg2,
    int arg3,
  ) {
    return __mm_mask_cmp_sh_mask(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_cmp_sh_maskPtr = _lookup<
      ffi.NativeFunction<
          __mmask8 Function(
              __mmask8, __m128h, __m128h, ffi.Int32)>>('_mm_mask_cmp_sh_mask');
  late final __mm_mask_cmp_sh_mask = __mm_mask_cmp_sh_maskPtr
      .asFunction<int Function(int, __m128h, __m128h, int)>();

  int _mm_cmp_round_sh_mask(
    __m128h arg0,
    __m128h arg1,
    int arg2,
    int arg3,
  ) {
    return __mm_cmp_round_sh_mask(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_cmp_round_sh_maskPtr = _lookup<
      ffi.NativeFunction<
          __mmask8 Function(__m128h, __m128h, ffi.Int32,
              ffi.Int32)>>('_mm_cmp_round_sh_mask');
  late final __mm_cmp_round_sh_mask = __mm_cmp_round_sh_maskPtr
      .asFunction<int Function(__m128h, __m128h, int, int)>();

  int _mm_mask_cmp_round_sh_mask(
    int arg0,
    __m128h arg1,
    __m128h arg2,
    int arg3,
    int arg4,
  ) {
    return __mm_mask_cmp_round_sh_mask(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_cmp_round_sh_maskPtr = _lookup<
      ffi.NativeFunction<
          __mmask8 Function(__mmask8, __m128h, __m128h, ffi.Int32,
              ffi.Int32)>>('_mm_mask_cmp_round_sh_mask');
  late final __mm_mask_cmp_round_sh_mask = __mm_mask_cmp_round_sh_maskPtr
      .asFunction<int Function(int, __m128h, __m128h, int, int)>();

  int _mm_comi_sh(
    __m128h arg0,
    __m128h arg1,
    int arg2,
  ) {
    return __mm_comi_sh(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_comi_shPtr = _lookup<
          ffi.NativeFunction<ffi.Int32 Function(__m128h, __m128h, ffi.Int32)>>(
      '_mm_comi_sh');
  late final __mm_comi_sh =
      __mm_comi_shPtr.asFunction<int Function(__m128h, __m128h, int)>();

  int _mm_comi_round_sh(
    __m128h arg0,
    __m128h arg1,
    int arg2,
    int arg3,
  ) {
    return __mm_comi_round_sh(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_comi_round_shPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              __m128h, __m128h, ffi.Int32, ffi.Int32)>>('_mm_comi_round_sh');
  late final __mm_comi_round_sh = __mm_comi_round_shPtr
      .asFunction<int Function(__m128h, __m128h, int, int)>();

  __m128h _mm_cvtepi32_ph(
    __m128i arg0,
  ) {
    return __mm_cvtepi32_ph(
      arg0,
    );
  }

  late final __mm_cvtepi32_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128i)>>('_mm_cvtepi32_ph');
  late final __mm_cvtepi32_ph =
      __mm_cvtepi32_phPtr.asFunction<__m128h Function(__m128i)>();

  __m128h _mm_mask_cvtepi32_ph(
    __m128h arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cvtepi32_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtepi32_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128h, __mmask8, __m128i)>>(
          '_mm_mask_cvtepi32_ph');
  late final __mm_mask_cvtepi32_ph = __mm_mask_cvtepi32_phPtr
      .asFunction<__m128h Function(__m128h, int, __m128i)>();

  __m128h _mm_maskz_cvtepi32_ph(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_cvtepi32_ph(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvtepi32_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__mmask8, __m128i)>>(
          '_mm_maskz_cvtepi32_ph');
  late final __mm_maskz_cvtepi32_ph =
      __mm_maskz_cvtepi32_phPtr.asFunction<__m128h Function(int, __m128i)>();

  __m128h _mm256_cvtepi32_ph(
    __m256i arg0,
  ) {
    return __mm256_cvtepi32_ph(
      arg0,
    );
  }

  late final __mm256_cvtepi32_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m256i)>>(
          '_mm256_cvtepi32_ph');
  late final __mm256_cvtepi32_ph =
      __mm256_cvtepi32_phPtr.asFunction<__m128h Function(__m256i)>();

  __m128h _mm256_mask_cvtepi32_ph(
    __m128h arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cvtepi32_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtepi32_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128h, __mmask8, __m256i)>>(
          '_mm256_mask_cvtepi32_ph');
  late final __mm256_mask_cvtepi32_ph = __mm256_mask_cvtepi32_phPtr
      .asFunction<__m128h Function(__m128h, int, __m256i)>();

  __m128h _mm256_maskz_cvtepi32_ph(
    int arg0,
    __m256i arg1,
  ) {
    return __mm256_maskz_cvtepi32_ph(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvtepi32_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__mmask8, __m256i)>>(
          '_mm256_maskz_cvtepi32_ph');
  late final __mm256_maskz_cvtepi32_ph =
      __mm256_maskz_cvtepi32_phPtr.asFunction<__m128h Function(int, __m256i)>();

  __m256h _mm512_cvtepi32_ph(
    __m512i arg0,
  ) {
    return __mm512_cvtepi32_ph(
      arg0,
    );
  }

  late final __mm512_cvtepi32_phPtr =
      _lookup<ffi.NativeFunction<__m256h Function(__m512i)>>(
          '_mm512_cvtepi32_ph');
  late final __mm512_cvtepi32_ph =
      __mm512_cvtepi32_phPtr.asFunction<__m256h Function(__m512i)>();

  __m256h _mm512_mask_cvtepi32_ph(
    __m256h arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cvtepi32_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtepi32_phPtr = _lookup<
          ffi.NativeFunction<__m256h Function(__m256h, __mmask16, __m512i)>>(
      '_mm512_mask_cvtepi32_ph');
  late final __mm512_mask_cvtepi32_ph = __mm512_mask_cvtepi32_phPtr
      .asFunction<__m256h Function(__m256h, int, __m512i)>();

  __m256h _mm512_maskz_cvtepi32_ph(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_maskz_cvtepi32_ph(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvtepi32_phPtr =
      _lookup<ffi.NativeFunction<__m256h Function(__mmask16, __m512i)>>(
          '_mm512_maskz_cvtepi32_ph');
  late final __mm512_maskz_cvtepi32_ph =
      __mm512_maskz_cvtepi32_phPtr.asFunction<__m256h Function(int, __m512i)>();

  __m256h _mm512_cvt_roundepi32_ph(
    __m512i arg0,
    int arg1,
  ) {
    return __mm512_cvt_roundepi32_ph(
      arg0,
      arg1,
    );
  }

  late final __mm512_cvt_roundepi32_phPtr =
      _lookup<ffi.NativeFunction<__m256h Function(__m512i, ffi.Int32)>>(
          '_mm512_cvt_roundepi32_ph');
  late final __mm512_cvt_roundepi32_ph =
      __mm512_cvt_roundepi32_phPtr.asFunction<__m256h Function(__m512i, int)>();

  __m256h _mm512_mask_cvt_roundepi32_ph(
    __m256h arg0,
    int arg1,
    __m512i arg2,
    int arg3,
  ) {
    return __mm512_mask_cvt_roundepi32_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_cvt_roundepi32_phPtr = _lookup<
      ffi.NativeFunction<
          __m256h Function(__m256h, __mmask16, __m512i,
              ffi.Int32)>>('_mm512_mask_cvt_roundepi32_ph');
  late final __mm512_mask_cvt_roundepi32_ph = __mm512_mask_cvt_roundepi32_phPtr
      .asFunction<__m256h Function(__m256h, int, __m512i, int)>();

  __m256h _mm512_maskz_cvt_roundepi32_ph(
    int arg0,
    __m512i arg1,
    int arg2,
  ) {
    return __mm512_maskz_cvt_roundepi32_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_cvt_roundepi32_phPtr = _lookup<
          ffi.NativeFunction<__m256h Function(__mmask16, __m512i, ffi.Int32)>>(
      '_mm512_maskz_cvt_roundepi32_ph');
  late final __mm512_maskz_cvt_roundepi32_ph =
      __mm512_maskz_cvt_roundepi32_phPtr
          .asFunction<__m256h Function(int, __m512i, int)>();

  __m128h _mm_cvtpd_ph(
    _m128d arg0,
  ) {
    return __mm_cvtpd_ph(
      arg0,
    );
  }

  late final __mm_cvtpd_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(_m128d)>>('_mm_cvtpd_ph');
  late final __mm_cvtpd_ph =
      __mm_cvtpd_phPtr.asFunction<__m128h Function(_m128d)>();

  __m128h _mm_mask_cvtpd_ph(
    __m128h arg0,
    int arg1,
    _m128d arg2,
  ) {
    return __mm_mask_cvtpd_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtpd_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128h, __mmask8, _m128d)>>(
          '_mm_mask_cvtpd_ph');
  late final __mm_mask_cvtpd_ph = __mm_mask_cvtpd_phPtr
      .asFunction<__m128h Function(__m128h, int, _m128d)>();

  __m128h _mm_maskz_cvtpd_ph(
    int arg0,
    _m128d arg1,
  ) {
    return __mm_maskz_cvtpd_ph(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvtpd_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__mmask8, _m128d)>>(
          '_mm_maskz_cvtpd_ph');
  late final __mm_maskz_cvtpd_ph =
      __mm_maskz_cvtpd_phPtr.asFunction<__m128h Function(int, _m128d)>();

  __m128h _mm256_cvtpd_ph(
    _m256d arg0,
  ) {
    return __mm256_cvtpd_ph(
      arg0,
    );
  }

  late final __mm256_cvtpd_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(_m256d)>>('_mm256_cvtpd_ph');
  late final __mm256_cvtpd_ph =
      __mm256_cvtpd_phPtr.asFunction<__m128h Function(_m256d)>();

  __m128h _mm256_mask_cvtpd_ph(
    __m128h arg0,
    int arg1,
    _m256d arg2,
  ) {
    return __mm256_mask_cvtpd_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtpd_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128h, __mmask8, _m256d)>>(
          '_mm256_mask_cvtpd_ph');
  late final __mm256_mask_cvtpd_ph = __mm256_mask_cvtpd_phPtr
      .asFunction<__m128h Function(__m128h, int, _m256d)>();

  __m128h _mm256_maskz_cvtpd_ph(
    int arg0,
    _m256d arg1,
  ) {
    return __mm256_maskz_cvtpd_ph(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvtpd_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__mmask8, _m256d)>>(
          '_mm256_maskz_cvtpd_ph');
  late final __mm256_maskz_cvtpd_ph =
      __mm256_maskz_cvtpd_phPtr.asFunction<__m128h Function(int, _m256d)>();

  __m128h _mm512_cvtpd_ph(
    _m512d arg0,
  ) {
    return __mm512_cvtpd_ph(
      arg0,
    );
  }

  late final __mm512_cvtpd_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(_m512d)>>('_mm512_cvtpd_ph');
  late final __mm512_cvtpd_ph =
      __mm512_cvtpd_phPtr.asFunction<__m128h Function(_m512d)>();

  __m128h _mm512_mask_cvtpd_ph(
    __m128h arg0,
    int arg1,
    _m512d arg2,
  ) {
    return __mm512_mask_cvtpd_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtpd_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128h, __mmask8, _m512d)>>(
          '_mm512_mask_cvtpd_ph');
  late final __mm512_mask_cvtpd_ph = __mm512_mask_cvtpd_phPtr
      .asFunction<__m128h Function(__m128h, int, _m512d)>();

  __m128h _mm512_maskz_cvtpd_ph(
    int arg0,
    _m512d arg1,
  ) {
    return __mm512_maskz_cvtpd_ph(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvtpd_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__mmask8, _m512d)>>(
          '_mm512_maskz_cvtpd_ph');
  late final __mm512_maskz_cvtpd_ph =
      __mm512_maskz_cvtpd_phPtr.asFunction<__m128h Function(int, _m512d)>();

  __m128h _mm512_cvt_roundpd_ph(
    _m512d arg0,
    int arg1,
  ) {
    return __mm512_cvt_roundpd_ph(
      arg0,
      arg1,
    );
  }

  late final __mm512_cvt_roundpd_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(_m512d, ffi.Int32)>>(
          '_mm512_cvt_roundpd_ph');
  late final __mm512_cvt_roundpd_ph =
      __mm512_cvt_roundpd_phPtr.asFunction<__m128h Function(_m512d, int)>();

  __m128h _mm512_mask_cvt_roundpd_ph(
    __m128h arg0,
    int arg1,
    _m512d arg2,
    int arg3,
  ) {
    return __mm512_mask_cvt_roundpd_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_cvt_roundpd_phPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(__m128h, __mmask8, _m512d,
              ffi.Int32)>>('_mm512_mask_cvt_roundpd_ph');
  late final __mm512_mask_cvt_roundpd_ph = __mm512_mask_cvt_roundpd_phPtr
      .asFunction<__m128h Function(__m128h, int, _m512d, int)>();

  __m128h _mm512_maskz_cvt_roundpd_ph(
    int arg0,
    _m512d arg1,
    int arg2,
  ) {
    return __mm512_maskz_cvt_roundpd_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_cvt_roundpd_phPtr = _lookup<
          ffi.NativeFunction<__m128h Function(__mmask8, _m512d, ffi.Int32)>>(
      '_mm512_maskz_cvt_roundpd_ph');
  late final __mm512_maskz_cvt_roundpd_ph = __mm512_maskz_cvt_roundpd_phPtr
      .asFunction<__m128h Function(int, _m512d, int)>();

  __m128i _mm_cvtph_epi32(
    __m128h arg0,
  ) {
    return __mm_cvtph_epi32(
      arg0,
    );
  }

  late final __mm_cvtph_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128h)>>('_mm_cvtph_epi32');
  late final __mm_cvtph_epi32 =
      __mm_cvtph_epi32Ptr.asFunction<__m128i Function(__m128h)>();

  __m128i _mm_mask_cvtph_epi32(
    __m128i arg0,
    int arg1,
    __m128h arg2,
  ) {
    return __mm_mask_cvtph_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtph_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m128h)>>(
          '_mm_mask_cvtph_epi32');
  late final __mm_mask_cvtph_epi32 = __mm_mask_cvtph_epi32Ptr
      .asFunction<__m128i Function(__m128i, int, __m128h)>();

  __m128i _mm_maskz_cvtph_epi32(
    int arg0,
    __m128h arg1,
  ) {
    return __mm_maskz_cvtph_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvtph_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128h)>>(
          '_mm_maskz_cvtph_epi32');
  late final __mm_maskz_cvtph_epi32 =
      __mm_maskz_cvtph_epi32Ptr.asFunction<__m128i Function(int, __m128h)>();

  __m256i _mm256_cvtph_epi32(
    __m128h arg0,
  ) {
    return __mm256_cvtph_epi32(
      arg0,
    );
  }

  late final __mm256_cvtph_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m128h)>>(
          '_mm256_cvtph_epi32');
  late final __mm256_cvtph_epi32 =
      __mm256_cvtph_epi32Ptr.asFunction<__m256i Function(__m128h)>();

  __m256i _mm256_mask_cvtph_epi32(
    __m256i arg0,
    int arg1,
    __m128h arg2,
  ) {
    return __mm256_mask_cvtph_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtph_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __mmask8, __m128h)>>(
          '_mm256_mask_cvtph_epi32');
  late final __mm256_mask_cvtph_epi32 = __mm256_mask_cvtph_epi32Ptr
      .asFunction<__m256i Function(__m256i, int, __m128h)>();

  __m256i _mm256_maskz_cvtph_epi32(
    int arg0,
    __m128h arg1,
  ) {
    return __mm256_maskz_cvtph_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvtph_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m128h)>>(
          '_mm256_maskz_cvtph_epi32');
  late final __mm256_maskz_cvtph_epi32 =
      __mm256_maskz_cvtph_epi32Ptr.asFunction<__m256i Function(int, __m128h)>();

  __m512i _mm512_cvtph_epi32(
    __m256h arg0,
  ) {
    return __mm512_cvtph_epi32(
      arg0,
    );
  }

  late final __mm512_cvtph_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m256h)>>(
          '_mm512_cvtph_epi32');
  late final __mm512_cvtph_epi32 =
      __mm512_cvtph_epi32Ptr.asFunction<__m512i Function(__m256h)>();

  __m512i _mm512_mask_cvtph_epi32(
    __m512i arg0,
    int arg1,
    __m256h arg2,
  ) {
    return __mm512_mask_cvtph_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtph_epi32Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__m512i, __mmask16, __m256h)>>(
      '_mm512_mask_cvtph_epi32');
  late final __mm512_mask_cvtph_epi32 = __mm512_mask_cvtph_epi32Ptr
      .asFunction<__m512i Function(__m512i, int, __m256h)>();

  __m512i _mm512_maskz_cvtph_epi32(
    int arg0,
    __m256h arg1,
  ) {
    return __mm512_maskz_cvtph_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvtph_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask16, __m256h)>>(
          '_mm512_maskz_cvtph_epi32');
  late final __mm512_maskz_cvtph_epi32 =
      __mm512_maskz_cvtph_epi32Ptr.asFunction<__m512i Function(int, __m256h)>();

  __m512i _mm512_cvt_roundph_epi32(
    __m256h arg0,
    int arg1,
  ) {
    return __mm512_cvt_roundph_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_cvt_roundph_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m256h, ffi.Int32)>>(
          '_mm512_cvt_roundph_epi32');
  late final __mm512_cvt_roundph_epi32 =
      __mm512_cvt_roundph_epi32Ptr.asFunction<__m512i Function(__m256h, int)>();

  __m512i _mm512_mask_cvt_roundph_epi32(
    __m512i arg0,
    int arg1,
    __m256h arg2,
    int arg3,
  ) {
    return __mm512_mask_cvt_roundph_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_cvt_roundph_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask16, __m256h,
              ffi.Int32)>>('_mm512_mask_cvt_roundph_epi32');
  late final __mm512_mask_cvt_roundph_epi32 = __mm512_mask_cvt_roundph_epi32Ptr
      .asFunction<__m512i Function(__m512i, int, __m256h, int)>();

  __m512i _mm512_maskz_cvt_roundph_epi32(
    int arg0,
    __m256h arg1,
    int arg2,
  ) {
    return __mm512_maskz_cvt_roundph_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_cvt_roundph_epi32Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask16, __m256h, ffi.Int32)>>(
      '_mm512_maskz_cvt_roundph_epi32');
  late final __mm512_maskz_cvt_roundph_epi32 =
      __mm512_maskz_cvt_roundph_epi32Ptr
          .asFunction<__m512i Function(int, __m256h, int)>();

  _m128d _mm_cvtph_pd(
    __m128h arg0,
  ) {
    return __mm_cvtph_pd(
      arg0,
    );
  }

  late final __mm_cvtph_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(__m128h)>>('_mm_cvtph_pd');
  late final __mm_cvtph_pd =
      __mm_cvtph_pdPtr.asFunction<_m128d Function(__m128h)>();

  _m128d _mm_mask_cvtph_pd(
    _m128d arg0,
    int arg1,
    __m128h arg2,
  ) {
    return __mm_mask_cvtph_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtph_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, __mmask8, __m128h)>>(
          '_mm_mask_cvtph_pd');
  late final __mm_mask_cvtph_pd =
      __mm_mask_cvtph_pdPtr.asFunction<_m128d Function(_m128d, int, __m128h)>();

  _m128d _mm_maskz_cvtph_pd(
    int arg0,
    __m128h arg1,
  ) {
    return __mm_maskz_cvtph_pd(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvtph_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(__mmask8, __m128h)>>(
          '_mm_maskz_cvtph_pd');
  late final __mm_maskz_cvtph_pd =
      __mm_maskz_cvtph_pdPtr.asFunction<_m128d Function(int, __m128h)>();

  _m256d _mm256_cvtph_pd(
    __m128h arg0,
  ) {
    return __mm256_cvtph_pd(
      arg0,
    );
  }

  late final __mm256_cvtph_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(__m128h)>>('_mm256_cvtph_pd');
  late final __mm256_cvtph_pd =
      __mm256_cvtph_pdPtr.asFunction<_m256d Function(__m128h)>();

  _m256d _mm256_mask_cvtph_pd(
    _m256d arg0,
    int arg1,
    __m128h arg2,
  ) {
    return __mm256_mask_cvtph_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtph_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d, __mmask8, __m128h)>>(
          '_mm256_mask_cvtph_pd');
  late final __mm256_mask_cvtph_pd = __mm256_mask_cvtph_pdPtr
      .asFunction<_m256d Function(_m256d, int, __m128h)>();

  _m256d _mm256_maskz_cvtph_pd(
    int arg0,
    __m128h arg1,
  ) {
    return __mm256_maskz_cvtph_pd(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvtph_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(__mmask8, __m128h)>>(
          '_mm256_maskz_cvtph_pd');
  late final __mm256_maskz_cvtph_pd =
      __mm256_maskz_cvtph_pdPtr.asFunction<_m256d Function(int, __m128h)>();

  _m512d _mm512_cvtph_pd(
    __m128h arg0,
  ) {
    return __mm512_cvtph_pd(
      arg0,
    );
  }

  late final __mm512_cvtph_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(__m128h)>>('_mm512_cvtph_pd');
  late final __mm512_cvtph_pd =
      __mm512_cvtph_pdPtr.asFunction<_m512d Function(__m128h)>();

  _m512d _mm512_mask_cvtph_pd(
    _m512d arg0,
    int arg1,
    __m128h arg2,
  ) {
    return __mm512_mask_cvtph_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtph_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(_m512d, __mmask8, __m128h)>>(
          '_mm512_mask_cvtph_pd');
  late final __mm512_mask_cvtph_pd = __mm512_mask_cvtph_pdPtr
      .asFunction<_m512d Function(_m512d, int, __m128h)>();

  _m512d _mm512_maskz_cvtph_pd(
    int arg0,
    __m128h arg1,
  ) {
    return __mm512_maskz_cvtph_pd(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvtph_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(__mmask8, __m128h)>>(
          '_mm512_maskz_cvtph_pd');
  late final __mm512_maskz_cvtph_pd =
      __mm512_maskz_cvtph_pdPtr.asFunction<_m512d Function(int, __m128h)>();

  _m512d _mm512_cvt_roundph_pd(
    __m128h arg0,
    int arg1,
  ) {
    return __mm512_cvt_roundph_pd(
      arg0,
      arg1,
    );
  }

  late final __mm512_cvt_roundph_pdPtr =
      _lookup<ffi.NativeFunction<_m512d Function(__m128h, ffi.Int32)>>(
          '_mm512_cvt_roundph_pd');
  late final __mm512_cvt_roundph_pd =
      __mm512_cvt_roundph_pdPtr.asFunction<_m512d Function(__m128h, int)>();

  _m512d _mm512_mask_cvt_roundph_pd(
    _m512d arg0,
    int arg1,
    __m128h arg2,
    int arg3,
  ) {
    return __mm512_mask_cvt_roundph_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_cvt_roundph_pdPtr = _lookup<
      ffi.NativeFunction<
          _m512d Function(_m512d, __mmask8, __m128h,
              ffi.Int32)>>('_mm512_mask_cvt_roundph_pd');
  late final __mm512_mask_cvt_roundph_pd = __mm512_mask_cvt_roundph_pdPtr
      .asFunction<_m512d Function(_m512d, int, __m128h, int)>();

  _m512d _mm512_maskz_cvt_roundph_pd(
    int arg0,
    __m128h arg1,
    int arg2,
  ) {
    return __mm512_maskz_cvt_roundph_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_cvt_roundph_pdPtr = _lookup<
          ffi.NativeFunction<_m512d Function(__mmask8, __m128h, ffi.Int32)>>(
      '_mm512_maskz_cvt_roundph_pd');
  late final __mm512_maskz_cvt_roundph_pd = __mm512_maskz_cvt_roundph_pdPtr
      .asFunction<_m512d Function(int, __m128h, int)>();

  __m128 _mm_cvtxph_ps(
    __m128h arg0,
  ) {
    return __mm_cvtxph_ps(
      arg0,
    );
  }

  late final __mm_cvtxph_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128h)>>('_mm_cvtxph_ps');
  late final __mm_cvtxph_ps =
      __mm_cvtxph_psPtr.asFunction<__m128 Function(__m128h)>();

  __m128 _mm_mask_cvtxph_ps(
    __m128 arg0,
    int arg1,
    __m128h arg2,
  ) {
    return __mm_mask_cvtxph_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtxph_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __mmask8, __m128h)>>(
          '_mm_mask_cvtxph_ps');
  late final __mm_mask_cvtxph_ps = __mm_mask_cvtxph_psPtr
      .asFunction<__m128 Function(__m128, int, __m128h)>();

  __m128 _mm_maskz_cvtxph_ps(
    int arg0,
    __m128h arg1,
  ) {
    return __mm_maskz_cvtxph_ps(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvtxph_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__mmask8, __m128h)>>(
          '_mm_maskz_cvtxph_ps');
  late final __mm_maskz_cvtxph_ps =
      __mm_maskz_cvtxph_psPtr.asFunction<__m128 Function(int, __m128h)>();

  __m256 _mm256_cvtxph_ps(
    __m128h arg0,
  ) {
    return __mm256_cvtxph_ps(
      arg0,
    );
  }

  late final __mm256_cvtxph_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m128h)>>('_mm256_cvtxph_ps');
  late final __mm256_cvtxph_ps =
      __mm256_cvtxph_psPtr.asFunction<__m256 Function(__m128h)>();

  __m256 _mm256_mask_cvtxph_ps(
    __m256 arg0,
    int arg1,
    __m128h arg2,
  ) {
    return __mm256_mask_cvtxph_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtxph_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256, __mmask8, __m128h)>>(
          '_mm256_mask_cvtxph_ps');
  late final __mm256_mask_cvtxph_ps = __mm256_mask_cvtxph_psPtr
      .asFunction<__m256 Function(__m256, int, __m128h)>();

  __m256 _mm256_maskz_cvtxph_ps(
    int arg0,
    __m128h arg1,
  ) {
    return __mm256_maskz_cvtxph_ps(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvtxph_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__mmask8, __m128h)>>(
          '_mm256_maskz_cvtxph_ps');
  late final __mm256_maskz_cvtxph_ps =
      __mm256_maskz_cvtxph_psPtr.asFunction<__m256 Function(int, __m128h)>();

  __m512 _mm512_cvtxph_ps(
    __m256h arg0,
  ) {
    return __mm512_cvtxph_ps(
      arg0,
    );
  }

  late final __mm512_cvtxph_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m256h)>>('_mm512_cvtxph_ps');
  late final __mm512_cvtxph_ps =
      __mm512_cvtxph_psPtr.asFunction<__m512 Function(__m256h)>();

  __m512 _mm512_mask_cvtxph_ps(
    __m512 arg0,
    int arg1,
    __m256h arg2,
  ) {
    return __mm512_mask_cvtxph_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtxph_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m512, __mmask16, __m256h)>>(
          '_mm512_mask_cvtxph_ps');
  late final __mm512_mask_cvtxph_ps = __mm512_mask_cvtxph_psPtr
      .asFunction<__m512 Function(__m512, int, __m256h)>();

  __m512 _mm512_maskz_cvtxph_ps(
    int arg0,
    __m256h arg1,
  ) {
    return __mm512_maskz_cvtxph_ps(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvtxph_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__mmask16, __m256h)>>(
          '_mm512_maskz_cvtxph_ps');
  late final __mm512_maskz_cvtxph_ps =
      __mm512_maskz_cvtxph_psPtr.asFunction<__m512 Function(int, __m256h)>();

  __m512 _mm512_cvtx_roundph_ps(
    __m256h arg0,
    int arg1,
  ) {
    return __mm512_cvtx_roundph_ps(
      arg0,
      arg1,
    );
  }

  late final __mm512_cvtx_roundph_psPtr =
      _lookup<ffi.NativeFunction<__m512 Function(__m256h, ffi.Int32)>>(
          '_mm512_cvtx_roundph_ps');
  late final __mm512_cvtx_roundph_ps =
      __mm512_cvtx_roundph_psPtr.asFunction<__m512 Function(__m256h, int)>();

  __m512 _mm512_mask_cvtx_roundph_ps(
    __m512 arg0,
    int arg1,
    __m256h arg2,
    int arg3,
  ) {
    return __mm512_mask_cvtx_roundph_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_cvtx_roundph_psPtr = _lookup<
      ffi.NativeFunction<
          __m512 Function(__m512, __mmask16, __m256h,
              ffi.Int32)>>('_mm512_mask_cvtx_roundph_ps');
  late final __mm512_mask_cvtx_roundph_ps = __mm512_mask_cvtx_roundph_psPtr
      .asFunction<__m512 Function(__m512, int, __m256h, int)>();

  __m512 _mm512_maskz_cvtx_roundph_ps(
    int arg0,
    __m256h arg1,
    int arg2,
  ) {
    return __mm512_maskz_cvtx_roundph_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_cvtx_roundph_psPtr = _lookup<
          ffi.NativeFunction<__m512 Function(__mmask16, __m256h, ffi.Int32)>>(
      '_mm512_maskz_cvtx_roundph_ps');
  late final __mm512_maskz_cvtx_roundph_ps = __mm512_maskz_cvtx_roundph_psPtr
      .asFunction<__m512 Function(int, __m256h, int)>();

  __m128i _mm_cvtph_epi64(
    __m128h arg0,
  ) {
    return __mm_cvtph_epi64(
      arg0,
    );
  }

  late final __mm_cvtph_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128h)>>('_mm_cvtph_epi64');
  late final __mm_cvtph_epi64 =
      __mm_cvtph_epi64Ptr.asFunction<__m128i Function(__m128h)>();

  __m128i _mm_mask_cvtph_epi64(
    __m128i arg0,
    int arg1,
    __m128h arg2,
  ) {
    return __mm_mask_cvtph_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtph_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m128h)>>(
          '_mm_mask_cvtph_epi64');
  late final __mm_mask_cvtph_epi64 = __mm_mask_cvtph_epi64Ptr
      .asFunction<__m128i Function(__m128i, int, __m128h)>();

  __m128i _mm_maskz_cvtph_epi64(
    int arg0,
    __m128h arg1,
  ) {
    return __mm_maskz_cvtph_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvtph_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128h)>>(
          '_mm_maskz_cvtph_epi64');
  late final __mm_maskz_cvtph_epi64 =
      __mm_maskz_cvtph_epi64Ptr.asFunction<__m128i Function(int, __m128h)>();

  __m256i _mm256_cvtph_epi64(
    __m128h arg0,
  ) {
    return __mm256_cvtph_epi64(
      arg0,
    );
  }

  late final __mm256_cvtph_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m128h)>>(
          '_mm256_cvtph_epi64');
  late final __mm256_cvtph_epi64 =
      __mm256_cvtph_epi64Ptr.asFunction<__m256i Function(__m128h)>();

  __m256i _mm256_mask_cvtph_epi64(
    __m256i arg0,
    int arg1,
    __m128h arg2,
  ) {
    return __mm256_mask_cvtph_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtph_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __mmask8, __m128h)>>(
          '_mm256_mask_cvtph_epi64');
  late final __mm256_mask_cvtph_epi64 = __mm256_mask_cvtph_epi64Ptr
      .asFunction<__m256i Function(__m256i, int, __m128h)>();

  __m256i _mm256_maskz_cvtph_epi64(
    int arg0,
    __m128h arg1,
  ) {
    return __mm256_maskz_cvtph_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvtph_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m128h)>>(
          '_mm256_maskz_cvtph_epi64');
  late final __mm256_maskz_cvtph_epi64 =
      __mm256_maskz_cvtph_epi64Ptr.asFunction<__m256i Function(int, __m128h)>();

  __m512i _mm512_cvtph_epi64(
    __m128h arg0,
  ) {
    return __mm512_cvtph_epi64(
      arg0,
    );
  }

  late final __mm512_cvtph_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m128h)>>(
          '_mm512_cvtph_epi64');
  late final __mm512_cvtph_epi64 =
      __mm512_cvtph_epi64Ptr.asFunction<__m512i Function(__m128h)>();

  __m512i _mm512_mask_cvtph_epi64(
    __m512i arg0,
    int arg1,
    __m128h arg2,
  ) {
    return __mm512_mask_cvtph_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtph_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __mmask8, __m128h)>>(
          '_mm512_mask_cvtph_epi64');
  late final __mm512_mask_cvtph_epi64 = __mm512_mask_cvtph_epi64Ptr
      .asFunction<__m512i Function(__m512i, int, __m128h)>();

  __m512i _mm512_maskz_cvtph_epi64(
    int arg0,
    __m128h arg1,
  ) {
    return __mm512_maskz_cvtph_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvtph_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask8, __m128h)>>(
          '_mm512_maskz_cvtph_epi64');
  late final __mm512_maskz_cvtph_epi64 =
      __mm512_maskz_cvtph_epi64Ptr.asFunction<__m512i Function(int, __m128h)>();

  __m512i _mm512_cvt_roundph_epi64(
    __m128h arg0,
    int arg1,
  ) {
    return __mm512_cvt_roundph_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm512_cvt_roundph_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m128h, ffi.Int32)>>(
          '_mm512_cvt_roundph_epi64');
  late final __mm512_cvt_roundph_epi64 =
      __mm512_cvt_roundph_epi64Ptr.asFunction<__m512i Function(__m128h, int)>();

  __m512i _mm512_mask_cvt_roundph_epi64(
    __m512i arg0,
    int arg1,
    __m128h arg2,
    int arg3,
  ) {
    return __mm512_mask_cvt_roundph_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_cvt_roundph_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask8, __m128h,
              ffi.Int32)>>('_mm512_mask_cvt_roundph_epi64');
  late final __mm512_mask_cvt_roundph_epi64 = __mm512_mask_cvt_roundph_epi64Ptr
      .asFunction<__m512i Function(__m512i, int, __m128h, int)>();

  __m512i _mm512_maskz_cvt_roundph_epi64(
    int arg0,
    __m128h arg1,
    int arg2,
  ) {
    return __mm512_maskz_cvt_roundph_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_cvt_roundph_epi64Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask8, __m128h, ffi.Int32)>>(
      '_mm512_maskz_cvt_roundph_epi64');
  late final __mm512_maskz_cvt_roundph_epi64 =
      __mm512_maskz_cvt_roundph_epi64Ptr
          .asFunction<__m512i Function(int, __m128h, int)>();

  __m128i _mm_cvtph_epu32(
    __m128h arg0,
  ) {
    return __mm_cvtph_epu32(
      arg0,
    );
  }

  late final __mm_cvtph_epu32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128h)>>('_mm_cvtph_epu32');
  late final __mm_cvtph_epu32 =
      __mm_cvtph_epu32Ptr.asFunction<__m128i Function(__m128h)>();

  __m128i _mm_mask_cvtph_epu32(
    __m128i arg0,
    int arg1,
    __m128h arg2,
  ) {
    return __mm_mask_cvtph_epu32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtph_epu32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m128h)>>(
          '_mm_mask_cvtph_epu32');
  late final __mm_mask_cvtph_epu32 = __mm_mask_cvtph_epu32Ptr
      .asFunction<__m128i Function(__m128i, int, __m128h)>();

  __m128i _mm_maskz_cvtph_epu32(
    int arg0,
    __m128h arg1,
  ) {
    return __mm_maskz_cvtph_epu32(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvtph_epu32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128h)>>(
          '_mm_maskz_cvtph_epu32');
  late final __mm_maskz_cvtph_epu32 =
      __mm_maskz_cvtph_epu32Ptr.asFunction<__m128i Function(int, __m128h)>();

  __m256i _mm256_cvtph_epu32(
    __m128h arg0,
  ) {
    return __mm256_cvtph_epu32(
      arg0,
    );
  }

  late final __mm256_cvtph_epu32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m128h)>>(
          '_mm256_cvtph_epu32');
  late final __mm256_cvtph_epu32 =
      __mm256_cvtph_epu32Ptr.asFunction<__m256i Function(__m128h)>();

  __m256i _mm256_mask_cvtph_epu32(
    __m256i arg0,
    int arg1,
    __m128h arg2,
  ) {
    return __mm256_mask_cvtph_epu32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtph_epu32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __mmask8, __m128h)>>(
          '_mm256_mask_cvtph_epu32');
  late final __mm256_mask_cvtph_epu32 = __mm256_mask_cvtph_epu32Ptr
      .asFunction<__m256i Function(__m256i, int, __m128h)>();

  __m256i _mm256_maskz_cvtph_epu32(
    int arg0,
    __m128h arg1,
  ) {
    return __mm256_maskz_cvtph_epu32(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvtph_epu32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m128h)>>(
          '_mm256_maskz_cvtph_epu32');
  late final __mm256_maskz_cvtph_epu32 =
      __mm256_maskz_cvtph_epu32Ptr.asFunction<__m256i Function(int, __m128h)>();

  __m512i _mm512_cvtph_epu32(
    __m256h arg0,
  ) {
    return __mm512_cvtph_epu32(
      arg0,
    );
  }

  late final __mm512_cvtph_epu32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m256h)>>(
          '_mm512_cvtph_epu32');
  late final __mm512_cvtph_epu32 =
      __mm512_cvtph_epu32Ptr.asFunction<__m512i Function(__m256h)>();

  __m512i _mm512_mask_cvtph_epu32(
    __m512i arg0,
    int arg1,
    __m256h arg2,
  ) {
    return __mm512_mask_cvtph_epu32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtph_epu32Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__m512i, __mmask16, __m256h)>>(
      '_mm512_mask_cvtph_epu32');
  late final __mm512_mask_cvtph_epu32 = __mm512_mask_cvtph_epu32Ptr
      .asFunction<__m512i Function(__m512i, int, __m256h)>();

  __m512i _mm512_maskz_cvtph_epu32(
    int arg0,
    __m256h arg1,
  ) {
    return __mm512_maskz_cvtph_epu32(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvtph_epu32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask16, __m256h)>>(
          '_mm512_maskz_cvtph_epu32');
  late final __mm512_maskz_cvtph_epu32 =
      __mm512_maskz_cvtph_epu32Ptr.asFunction<__m512i Function(int, __m256h)>();

  __m512i _mm512_cvt_roundph_epu32(
    __m256h arg0,
    int arg1,
  ) {
    return __mm512_cvt_roundph_epu32(
      arg0,
      arg1,
    );
  }

  late final __mm512_cvt_roundph_epu32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m256h, ffi.Int32)>>(
          '_mm512_cvt_roundph_epu32');
  late final __mm512_cvt_roundph_epu32 =
      __mm512_cvt_roundph_epu32Ptr.asFunction<__m512i Function(__m256h, int)>();

  __m512i _mm512_mask_cvt_roundph_epu32(
    __m512i arg0,
    int arg1,
    __m256h arg2,
    int arg3,
  ) {
    return __mm512_mask_cvt_roundph_epu32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_cvt_roundph_epu32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask16, __m256h,
              ffi.Int32)>>('_mm512_mask_cvt_roundph_epu32');
  late final __mm512_mask_cvt_roundph_epu32 = __mm512_mask_cvt_roundph_epu32Ptr
      .asFunction<__m512i Function(__m512i, int, __m256h, int)>();

  __m512i _mm512_maskz_cvt_roundph_epu32(
    int arg0,
    __m256h arg1,
    int arg2,
  ) {
    return __mm512_maskz_cvt_roundph_epu32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_cvt_roundph_epu32Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask16, __m256h, ffi.Int32)>>(
      '_mm512_maskz_cvt_roundph_epu32');
  late final __mm512_maskz_cvt_roundph_epu32 =
      __mm512_maskz_cvt_roundph_epu32Ptr
          .asFunction<__m512i Function(int, __m256h, int)>();

  __m128i _mm_cvtph_epu64(
    __m128h arg0,
  ) {
    return __mm_cvtph_epu64(
      arg0,
    );
  }

  late final __mm_cvtph_epu64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128h)>>('_mm_cvtph_epu64');
  late final __mm_cvtph_epu64 =
      __mm_cvtph_epu64Ptr.asFunction<__m128i Function(__m128h)>();

  __m128i _mm_mask_cvtph_epu64(
    __m128i arg0,
    int arg1,
    __m128h arg2,
  ) {
    return __mm_mask_cvtph_epu64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtph_epu64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m128h)>>(
          '_mm_mask_cvtph_epu64');
  late final __mm_mask_cvtph_epu64 = __mm_mask_cvtph_epu64Ptr
      .asFunction<__m128i Function(__m128i, int, __m128h)>();

  __m128i _mm_maskz_cvtph_epu64(
    int arg0,
    __m128h arg1,
  ) {
    return __mm_maskz_cvtph_epu64(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvtph_epu64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128h)>>(
          '_mm_maskz_cvtph_epu64');
  late final __mm_maskz_cvtph_epu64 =
      __mm_maskz_cvtph_epu64Ptr.asFunction<__m128i Function(int, __m128h)>();

  __m256i _mm256_cvtph_epu64(
    __m128h arg0,
  ) {
    return __mm256_cvtph_epu64(
      arg0,
    );
  }

  late final __mm256_cvtph_epu64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m128h)>>(
          '_mm256_cvtph_epu64');
  late final __mm256_cvtph_epu64 =
      __mm256_cvtph_epu64Ptr.asFunction<__m256i Function(__m128h)>();

  __m256i _mm256_mask_cvtph_epu64(
    __m256i arg0,
    int arg1,
    __m128h arg2,
  ) {
    return __mm256_mask_cvtph_epu64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtph_epu64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __mmask8, __m128h)>>(
          '_mm256_mask_cvtph_epu64');
  late final __mm256_mask_cvtph_epu64 = __mm256_mask_cvtph_epu64Ptr
      .asFunction<__m256i Function(__m256i, int, __m128h)>();

  __m256i _mm256_maskz_cvtph_epu64(
    int arg0,
    __m128h arg1,
  ) {
    return __mm256_maskz_cvtph_epu64(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvtph_epu64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m128h)>>(
          '_mm256_maskz_cvtph_epu64');
  late final __mm256_maskz_cvtph_epu64 =
      __mm256_maskz_cvtph_epu64Ptr.asFunction<__m256i Function(int, __m128h)>();

  __m512i _mm512_cvtph_epu64(
    __m128h arg0,
  ) {
    return __mm512_cvtph_epu64(
      arg0,
    );
  }

  late final __mm512_cvtph_epu64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m128h)>>(
          '_mm512_cvtph_epu64');
  late final __mm512_cvtph_epu64 =
      __mm512_cvtph_epu64Ptr.asFunction<__m512i Function(__m128h)>();

  __m512i _mm512_mask_cvtph_epu64(
    __m512i arg0,
    int arg1,
    __m128h arg2,
  ) {
    return __mm512_mask_cvtph_epu64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtph_epu64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __mmask8, __m128h)>>(
          '_mm512_mask_cvtph_epu64');
  late final __mm512_mask_cvtph_epu64 = __mm512_mask_cvtph_epu64Ptr
      .asFunction<__m512i Function(__m512i, int, __m128h)>();

  __m512i _mm512_maskz_cvtph_epu64(
    int arg0,
    __m128h arg1,
  ) {
    return __mm512_maskz_cvtph_epu64(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvtph_epu64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask8, __m128h)>>(
          '_mm512_maskz_cvtph_epu64');
  late final __mm512_maskz_cvtph_epu64 =
      __mm512_maskz_cvtph_epu64Ptr.asFunction<__m512i Function(int, __m128h)>();

  __m512i _mm512_cvt_roundph_epu64(
    __m128h arg0,
    int arg1,
  ) {
    return __mm512_cvt_roundph_epu64(
      arg0,
      arg1,
    );
  }

  late final __mm512_cvt_roundph_epu64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m128h, ffi.Int32)>>(
          '_mm512_cvt_roundph_epu64');
  late final __mm512_cvt_roundph_epu64 =
      __mm512_cvt_roundph_epu64Ptr.asFunction<__m512i Function(__m128h, int)>();

  __m512i _mm512_mask_cvt_roundph_epu64(
    __m512i arg0,
    int arg1,
    __m128h arg2,
    int arg3,
  ) {
    return __mm512_mask_cvt_roundph_epu64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_cvt_roundph_epu64Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask8, __m128h,
              ffi.Int32)>>('_mm512_mask_cvt_roundph_epu64');
  late final __mm512_mask_cvt_roundph_epu64 = __mm512_mask_cvt_roundph_epu64Ptr
      .asFunction<__m512i Function(__m512i, int, __m128h, int)>();

  __m512i _mm512_maskz_cvt_roundph_epu64(
    int arg0,
    __m128h arg1,
    int arg2,
  ) {
    return __mm512_maskz_cvt_roundph_epu64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_cvt_roundph_epu64Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask8, __m128h, ffi.Int32)>>(
      '_mm512_maskz_cvt_roundph_epu64');
  late final __mm512_maskz_cvt_roundph_epu64 =
      __mm512_maskz_cvt_roundph_epu64Ptr
          .asFunction<__m512i Function(int, __m128h, int)>();

  __m128i _mm_cvtph_epu16(
    __m128h arg0,
  ) {
    return __mm_cvtph_epu16(
      arg0,
    );
  }

  late final __mm_cvtph_epu16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128h)>>('_mm_cvtph_epu16');
  late final __mm_cvtph_epu16 =
      __mm_cvtph_epu16Ptr.asFunction<__m128i Function(__m128h)>();

  __m128i _mm_mask_cvtph_epu16(
    __m128i arg0,
    int arg1,
    __m128h arg2,
  ) {
    return __mm_mask_cvtph_epu16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtph_epu16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m128h)>>(
          '_mm_mask_cvtph_epu16');
  late final __mm_mask_cvtph_epu16 = __mm_mask_cvtph_epu16Ptr
      .asFunction<__m128i Function(__m128i, int, __m128h)>();

  __m128i _mm_maskz_cvtph_epu16(
    int arg0,
    __m128h arg1,
  ) {
    return __mm_maskz_cvtph_epu16(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvtph_epu16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128h)>>(
          '_mm_maskz_cvtph_epu16');
  late final __mm_maskz_cvtph_epu16 =
      __mm_maskz_cvtph_epu16Ptr.asFunction<__m128i Function(int, __m128h)>();

  __m256i _mm256_cvtph_epu16(
    __m256h arg0,
  ) {
    return __mm256_cvtph_epu16(
      arg0,
    );
  }

  late final __mm256_cvtph_epu16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256h)>>(
          '_mm256_cvtph_epu16');
  late final __mm256_cvtph_epu16 =
      __mm256_cvtph_epu16Ptr.asFunction<__m256i Function(__m256h)>();

  __m256i _mm256_mask_cvtph_epu16(
    __m256i arg0,
    int arg1,
    __m256h arg2,
  ) {
    return __mm256_mask_cvtph_epu16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtph_epu16Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__m256i, __mmask16, __m256h)>>(
      '_mm256_mask_cvtph_epu16');
  late final __mm256_mask_cvtph_epu16 = __mm256_mask_cvtph_epu16Ptr
      .asFunction<__m256i Function(__m256i, int, __m256h)>();

  __m256i _mm256_maskz_cvtph_epu16(
    int arg0,
    __m256h arg1,
  ) {
    return __mm256_maskz_cvtph_epu16(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvtph_epu16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask16, __m256h)>>(
          '_mm256_maskz_cvtph_epu16');
  late final __mm256_maskz_cvtph_epu16 =
      __mm256_maskz_cvtph_epu16Ptr.asFunction<__m256i Function(int, __m256h)>();

  __m512i _mm512_cvtph_epu16(
    __m512h arg0,
  ) {
    return __mm512_cvtph_epu16(
      arg0,
    );
  }

  late final __mm512_cvtph_epu16Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512h)>>(
          '_mm512_cvtph_epu16');
  late final __mm512_cvtph_epu16 =
      __mm512_cvtph_epu16Ptr.asFunction<__m512i Function(__m512h)>();

  __m512i _mm512_mask_cvtph_epu16(
    __m512i arg0,
    int arg1,
    __m512h arg2,
  ) {
    return __mm512_mask_cvtph_epu16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtph_epu16Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__m512i, __mmask32, __m512h)>>(
      '_mm512_mask_cvtph_epu16');
  late final __mm512_mask_cvtph_epu16 = __mm512_mask_cvtph_epu16Ptr
      .asFunction<__m512i Function(__m512i, int, __m512h)>();

  __m512i _mm512_maskz_cvtph_epu16(
    int arg0,
    __m512h arg1,
  ) {
    return __mm512_maskz_cvtph_epu16(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvtph_epu16Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask32, __m512h)>>(
          '_mm512_maskz_cvtph_epu16');
  late final __mm512_maskz_cvtph_epu16 =
      __mm512_maskz_cvtph_epu16Ptr.asFunction<__m512i Function(int, __m512h)>();

  __m512i _mm512_cvt_roundph_epu16(
    __m512h arg0,
    int arg1,
  ) {
    return __mm512_cvt_roundph_epu16(
      arg0,
      arg1,
    );
  }

  late final __mm512_cvt_roundph_epu16Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512h, ffi.Int32)>>(
          '_mm512_cvt_roundph_epu16');
  late final __mm512_cvt_roundph_epu16 =
      __mm512_cvt_roundph_epu16Ptr.asFunction<__m512i Function(__m512h, int)>();

  __m512i _mm512_mask_cvt_roundph_epu16(
    __m512i arg0,
    int arg1,
    __m512h arg2,
    int arg3,
  ) {
    return __mm512_mask_cvt_roundph_epu16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_cvt_roundph_epu16Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask32, __m512h,
              ffi.Int32)>>('_mm512_mask_cvt_roundph_epu16');
  late final __mm512_mask_cvt_roundph_epu16 = __mm512_mask_cvt_roundph_epu16Ptr
      .asFunction<__m512i Function(__m512i, int, __m512h, int)>();

  __m512i _mm512_maskz_cvt_roundph_epu16(
    int arg0,
    __m512h arg1,
    int arg2,
  ) {
    return __mm512_maskz_cvt_roundph_epu16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_cvt_roundph_epu16Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask32, __m512h, ffi.Int32)>>(
      '_mm512_maskz_cvt_roundph_epu16');
  late final __mm512_maskz_cvt_roundph_epu16 =
      __mm512_maskz_cvt_roundph_epu16Ptr
          .asFunction<__m512i Function(int, __m512h, int)>();

  __m128i _mm_cvtph_epi16(
    __m128h arg0,
  ) {
    return __mm_cvtph_epi16(
      arg0,
    );
  }

  late final __mm_cvtph_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128h)>>('_mm_cvtph_epi16');
  late final __mm_cvtph_epi16 =
      __mm_cvtph_epi16Ptr.asFunction<__m128i Function(__m128h)>();

  __m128i _mm_mask_cvtph_epi16(
    __m128i arg0,
    int arg1,
    __m128h arg2,
  ) {
    return __mm_mask_cvtph_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtph_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m128h)>>(
          '_mm_mask_cvtph_epi16');
  late final __mm_mask_cvtph_epi16 = __mm_mask_cvtph_epi16Ptr
      .asFunction<__m128i Function(__m128i, int, __m128h)>();

  __m128i _mm_maskz_cvtph_epi16(
    int arg0,
    __m128h arg1,
  ) {
    return __mm_maskz_cvtph_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvtph_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128h)>>(
          '_mm_maskz_cvtph_epi16');
  late final __mm_maskz_cvtph_epi16 =
      __mm_maskz_cvtph_epi16Ptr.asFunction<__m128i Function(int, __m128h)>();

  __m256i _mm256_cvtph_epi16(
    __m256h arg0,
  ) {
    return __mm256_cvtph_epi16(
      arg0,
    );
  }

  late final __mm256_cvtph_epi16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256h)>>(
          '_mm256_cvtph_epi16');
  late final __mm256_cvtph_epi16 =
      __mm256_cvtph_epi16Ptr.asFunction<__m256i Function(__m256h)>();

  __m256i _mm256_mask_cvtph_epi16(
    __m256i arg0,
    int arg1,
    __m256h arg2,
  ) {
    return __mm256_mask_cvtph_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtph_epi16Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__m256i, __mmask16, __m256h)>>(
      '_mm256_mask_cvtph_epi16');
  late final __mm256_mask_cvtph_epi16 = __mm256_mask_cvtph_epi16Ptr
      .asFunction<__m256i Function(__m256i, int, __m256h)>();

  __m256i _mm256_maskz_cvtph_epi16(
    int arg0,
    __m256h arg1,
  ) {
    return __mm256_maskz_cvtph_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvtph_epi16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask16, __m256h)>>(
          '_mm256_maskz_cvtph_epi16');
  late final __mm256_maskz_cvtph_epi16 =
      __mm256_maskz_cvtph_epi16Ptr.asFunction<__m256i Function(int, __m256h)>();

  __m512i _mm512_cvtph_epi16(
    __m512h arg0,
  ) {
    return __mm512_cvtph_epi16(
      arg0,
    );
  }

  late final __mm512_cvtph_epi16Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512h)>>(
          '_mm512_cvtph_epi16');
  late final __mm512_cvtph_epi16 =
      __mm512_cvtph_epi16Ptr.asFunction<__m512i Function(__m512h)>();

  __m512i _mm512_mask_cvtph_epi16(
    __m512i arg0,
    int arg1,
    __m512h arg2,
  ) {
    return __mm512_mask_cvtph_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtph_epi16Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__m512i, __mmask32, __m512h)>>(
      '_mm512_mask_cvtph_epi16');
  late final __mm512_mask_cvtph_epi16 = __mm512_mask_cvtph_epi16Ptr
      .asFunction<__m512i Function(__m512i, int, __m512h)>();

  __m512i _mm512_maskz_cvtph_epi16(
    int arg0,
    __m512h arg1,
  ) {
    return __mm512_maskz_cvtph_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvtph_epi16Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask32, __m512h)>>(
          '_mm512_maskz_cvtph_epi16');
  late final __mm512_maskz_cvtph_epi16 =
      __mm512_maskz_cvtph_epi16Ptr.asFunction<__m512i Function(int, __m512h)>();

  __m512i _mm512_cvt_roundph_epi16(
    __m512h arg0,
    int arg1,
  ) {
    return __mm512_cvt_roundph_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm512_cvt_roundph_epi16Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512h, ffi.Int32)>>(
          '_mm512_cvt_roundph_epi16');
  late final __mm512_cvt_roundph_epi16 =
      __mm512_cvt_roundph_epi16Ptr.asFunction<__m512i Function(__m512h, int)>();

  __m512i _mm512_mask_cvt_roundph_epi16(
    __m512i arg0,
    int arg1,
    __m512h arg2,
    int arg3,
  ) {
    return __mm512_mask_cvt_roundph_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_cvt_roundph_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask32, __m512h,
              ffi.Int32)>>('_mm512_mask_cvt_roundph_epi16');
  late final __mm512_mask_cvt_roundph_epi16 = __mm512_mask_cvt_roundph_epi16Ptr
      .asFunction<__m512i Function(__m512i, int, __m512h, int)>();

  __m512i _mm512_maskz_cvt_roundph_epi16(
    int arg0,
    __m512h arg1,
    int arg2,
  ) {
    return __mm512_maskz_cvt_roundph_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_cvt_roundph_epi16Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask32, __m512h, ffi.Int32)>>(
      '_mm512_maskz_cvt_roundph_epi16');
  late final __mm512_maskz_cvt_roundph_epi16 =
      __mm512_maskz_cvt_roundph_epi16Ptr
          .asFunction<__m512i Function(int, __m512h, int)>();

  __m128h _mm_cvtxps_ph(
    __m128 arg0,
  ) {
    return __mm_cvtxps_ph(
      arg0,
    );
  }

  late final __mm_cvtxps_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128)>>('_mm_cvtxps_ph');
  late final __mm_cvtxps_ph =
      __mm_cvtxps_phPtr.asFunction<__m128h Function(__m128)>();

  __m128h _mm_mask_cvtxps_ph(
    __m128h arg0,
    int arg1,
    __m128 arg2,
  ) {
    return __mm_mask_cvtxps_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtxps_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128h, __mmask8, __m128)>>(
          '_mm_mask_cvtxps_ph');
  late final __mm_mask_cvtxps_ph = __mm_mask_cvtxps_phPtr
      .asFunction<__m128h Function(__m128h, int, __m128)>();

  __m128h _mm_maskz_cvtxps_ph(
    int arg0,
    __m128 arg1,
  ) {
    return __mm_maskz_cvtxps_ph(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvtxps_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__mmask8, __m128)>>(
          '_mm_maskz_cvtxps_ph');
  late final __mm_maskz_cvtxps_ph =
      __mm_maskz_cvtxps_phPtr.asFunction<__m128h Function(int, __m128)>();

  __m128h _mm256_cvtxps_ph(
    __m256 arg0,
  ) {
    return __mm256_cvtxps_ph(
      arg0,
    );
  }

  late final __mm256_cvtxps_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m256)>>('_mm256_cvtxps_ph');
  late final __mm256_cvtxps_ph =
      __mm256_cvtxps_phPtr.asFunction<__m128h Function(__m256)>();

  __m128h _mm256_mask_cvtxps_ph(
    __m128h arg0,
    int arg1,
    __m256 arg2,
  ) {
    return __mm256_mask_cvtxps_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtxps_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128h, __mmask8, __m256)>>(
          '_mm256_mask_cvtxps_ph');
  late final __mm256_mask_cvtxps_ph = __mm256_mask_cvtxps_phPtr
      .asFunction<__m128h Function(__m128h, int, __m256)>();

  __m128h _mm256_maskz_cvtxps_ph(
    int arg0,
    __m256 arg1,
  ) {
    return __mm256_maskz_cvtxps_ph(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvtxps_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__mmask8, __m256)>>(
          '_mm256_maskz_cvtxps_ph');
  late final __mm256_maskz_cvtxps_ph =
      __mm256_maskz_cvtxps_phPtr.asFunction<__m128h Function(int, __m256)>();

  __m256h _mm512_cvtxps_ph(
    __m512 arg0,
  ) {
    return __mm512_cvtxps_ph(
      arg0,
    );
  }

  late final __mm512_cvtxps_phPtr =
      _lookup<ffi.NativeFunction<__m256h Function(__m512)>>('_mm512_cvtxps_ph');
  late final __mm512_cvtxps_ph =
      __mm512_cvtxps_phPtr.asFunction<__m256h Function(__m512)>();

  __m256h _mm512_mask_cvtxps_ph(
    __m256h arg0,
    int arg1,
    __m512 arg2,
  ) {
    return __mm512_mask_cvtxps_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtxps_phPtr =
      _lookup<ffi.NativeFunction<__m256h Function(__m256h, __mmask16, __m512)>>(
          '_mm512_mask_cvtxps_ph');
  late final __mm512_mask_cvtxps_ph = __mm512_mask_cvtxps_phPtr
      .asFunction<__m256h Function(__m256h, int, __m512)>();

  __m256h _mm512_maskz_cvtxps_ph(
    int arg0,
    __m512 arg1,
  ) {
    return __mm512_maskz_cvtxps_ph(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvtxps_phPtr =
      _lookup<ffi.NativeFunction<__m256h Function(__mmask16, __m512)>>(
          '_mm512_maskz_cvtxps_ph');
  late final __mm512_maskz_cvtxps_ph =
      __mm512_maskz_cvtxps_phPtr.asFunction<__m256h Function(int, __m512)>();

  __m256h _mm512_cvtx_roundps_ph(
    __m512 arg0,
    int arg1,
  ) {
    return __mm512_cvtx_roundps_ph(
      arg0,
      arg1,
    );
  }

  late final __mm512_cvtx_roundps_phPtr =
      _lookup<ffi.NativeFunction<__m256h Function(__m512, ffi.Int32)>>(
          '_mm512_cvtx_roundps_ph');
  late final __mm512_cvtx_roundps_ph =
      __mm512_cvtx_roundps_phPtr.asFunction<__m256h Function(__m512, int)>();

  __m256h _mm512_mask_cvtx_roundps_ph(
    __m256h arg0,
    int arg1,
    __m512 arg2,
    int arg3,
  ) {
    return __mm512_mask_cvtx_roundps_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_cvtx_roundps_phPtr = _lookup<
      ffi.NativeFunction<
          __m256h Function(__m256h, __mmask16, __m512,
              ffi.Int32)>>('_mm512_mask_cvtx_roundps_ph');
  late final __mm512_mask_cvtx_roundps_ph = __mm512_mask_cvtx_roundps_phPtr
      .asFunction<__m256h Function(__m256h, int, __m512, int)>();

  __m256h _mm512_maskz_cvtx_roundps_ph(
    int arg0,
    __m512 arg1,
    int arg2,
  ) {
    return __mm512_maskz_cvtx_roundps_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_cvtx_roundps_phPtr = _lookup<
          ffi.NativeFunction<__m256h Function(__mmask16, __m512, ffi.Int32)>>(
      '_mm512_maskz_cvtx_roundps_ph');
  late final __mm512_maskz_cvtx_roundps_ph = __mm512_maskz_cvtx_roundps_phPtr
      .asFunction<__m256h Function(int, __m512, int)>();

  __m128h _mm_cvtepi64_ph(
    __m128i arg0,
  ) {
    return __mm_cvtepi64_ph(
      arg0,
    );
  }

  late final __mm_cvtepi64_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128i)>>('_mm_cvtepi64_ph');
  late final __mm_cvtepi64_ph =
      __mm_cvtepi64_phPtr.asFunction<__m128h Function(__m128i)>();

  __m128h _mm_mask_cvtepi64_ph(
    __m128h arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cvtepi64_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtepi64_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128h, __mmask8, __m128i)>>(
          '_mm_mask_cvtepi64_ph');
  late final __mm_mask_cvtepi64_ph = __mm_mask_cvtepi64_phPtr
      .asFunction<__m128h Function(__m128h, int, __m128i)>();

  __m128h _mm_maskz_cvtepi64_ph(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_cvtepi64_ph(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvtepi64_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__mmask8, __m128i)>>(
          '_mm_maskz_cvtepi64_ph');
  late final __mm_maskz_cvtepi64_ph =
      __mm_maskz_cvtepi64_phPtr.asFunction<__m128h Function(int, __m128i)>();

  __m128h _mm256_cvtepi64_ph(
    __m256i arg0,
  ) {
    return __mm256_cvtepi64_ph(
      arg0,
    );
  }

  late final __mm256_cvtepi64_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m256i)>>(
          '_mm256_cvtepi64_ph');
  late final __mm256_cvtepi64_ph =
      __mm256_cvtepi64_phPtr.asFunction<__m128h Function(__m256i)>();

  __m128h _mm256_mask_cvtepi64_ph(
    __m128h arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cvtepi64_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtepi64_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128h, __mmask8, __m256i)>>(
          '_mm256_mask_cvtepi64_ph');
  late final __mm256_mask_cvtepi64_ph = __mm256_mask_cvtepi64_phPtr
      .asFunction<__m128h Function(__m128h, int, __m256i)>();

  __m128h _mm256_maskz_cvtepi64_ph(
    int arg0,
    __m256i arg1,
  ) {
    return __mm256_maskz_cvtepi64_ph(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvtepi64_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__mmask8, __m256i)>>(
          '_mm256_maskz_cvtepi64_ph');
  late final __mm256_maskz_cvtepi64_ph =
      __mm256_maskz_cvtepi64_phPtr.asFunction<__m128h Function(int, __m256i)>();

  __m128h _mm512_cvtepi64_ph(
    __m512i arg0,
  ) {
    return __mm512_cvtepi64_ph(
      arg0,
    );
  }

  late final __mm512_cvtepi64_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m512i)>>(
          '_mm512_cvtepi64_ph');
  late final __mm512_cvtepi64_ph =
      __mm512_cvtepi64_phPtr.asFunction<__m128h Function(__m512i)>();

  __m128h _mm512_mask_cvtepi64_ph(
    __m128h arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cvtepi64_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtepi64_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128h, __mmask8, __m512i)>>(
          '_mm512_mask_cvtepi64_ph');
  late final __mm512_mask_cvtepi64_ph = __mm512_mask_cvtepi64_phPtr
      .asFunction<__m128h Function(__m128h, int, __m512i)>();

  __m128h _mm512_maskz_cvtepi64_ph(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_maskz_cvtepi64_ph(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvtepi64_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__mmask8, __m512i)>>(
          '_mm512_maskz_cvtepi64_ph');
  late final __mm512_maskz_cvtepi64_ph =
      __mm512_maskz_cvtepi64_phPtr.asFunction<__m128h Function(int, __m512i)>();

  __m128h _mm512_cvt_roundepi64_ph(
    __m512i arg0,
    int arg1,
  ) {
    return __mm512_cvt_roundepi64_ph(
      arg0,
      arg1,
    );
  }

  late final __mm512_cvt_roundepi64_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m512i, ffi.Int32)>>(
          '_mm512_cvt_roundepi64_ph');
  late final __mm512_cvt_roundepi64_ph =
      __mm512_cvt_roundepi64_phPtr.asFunction<__m128h Function(__m512i, int)>();

  __m128h _mm512_mask_cvt_roundepi64_ph(
    __m128h arg0,
    int arg1,
    __m512i arg2,
    int arg3,
  ) {
    return __mm512_mask_cvt_roundepi64_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_cvt_roundepi64_phPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(__m128h, __mmask8, __m512i,
              ffi.Int32)>>('_mm512_mask_cvt_roundepi64_ph');
  late final __mm512_mask_cvt_roundepi64_ph = __mm512_mask_cvt_roundepi64_phPtr
      .asFunction<__m128h Function(__m128h, int, __m512i, int)>();

  __m128h _mm512_maskz_cvt_roundepi64_ph(
    int arg0,
    __m512i arg1,
    int arg2,
  ) {
    return __mm512_maskz_cvt_roundepi64_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_cvt_roundepi64_phPtr = _lookup<
          ffi.NativeFunction<__m128h Function(__mmask8, __m512i, ffi.Int32)>>(
      '_mm512_maskz_cvt_roundepi64_ph');
  late final __mm512_maskz_cvt_roundepi64_ph =
      __mm512_maskz_cvt_roundepi64_phPtr
          .asFunction<__m128h Function(int, __m512i, int)>();

  __m128h _mm_cvtsd_sh(
    __m128h arg0,
    _m128d arg1,
  ) {
    return __mm_cvtsd_sh(
      arg0,
      arg1,
    );
  }

  late final __mm_cvtsd_shPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128h, _m128d)>>(
          '_mm_cvtsd_sh');
  late final __mm_cvtsd_sh =
      __mm_cvtsd_shPtr.asFunction<__m128h Function(__m128h, _m128d)>();

  __m128h _mm_mask_cvtsd_sh(
    __m128h arg0,
    int arg1,
    __m128h arg2,
    _m128d arg3,
  ) {
    return __mm_mask_cvtsd_sh(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_cvtsd_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __m128h, __mmask8, __m128h, _m128d)>>('_mm_mask_cvtsd_sh');
  late final __mm_mask_cvtsd_sh = __mm_mask_cvtsd_shPtr
      .asFunction<__m128h Function(__m128h, int, __m128h, _m128d)>();

  __m128h _mm_maskz_cvtsd_sh(
    int arg0,
    __m128h arg1,
    _m128d arg2,
  ) {
    return __mm_maskz_cvtsd_sh(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_cvtsd_shPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__mmask8, __m128h, _m128d)>>(
          '_mm_maskz_cvtsd_sh');
  late final __mm_maskz_cvtsd_sh = __mm_maskz_cvtsd_shPtr
      .asFunction<__m128h Function(int, __m128h, _m128d)>();

  __m128h _mm_cvt_roundsd_sh(
    __m128h arg0,
    _m128d arg1,
    int arg2,
  ) {
    return __mm_cvt_roundsd_sh(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_cvt_roundsd_shPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128h, _m128d, ffi.Int32)>>(
          '_mm_cvt_roundsd_sh');
  late final __mm_cvt_roundsd_sh = __mm_cvt_roundsd_shPtr
      .asFunction<__m128h Function(__m128h, _m128d, int)>();

  __m128h _mm_mask_cvt_roundsd_sh(
    __m128h arg0,
    int arg1,
    __m128h arg2,
    _m128d arg3,
    int arg4,
  ) {
    return __mm_mask_cvt_roundsd_sh(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_cvt_roundsd_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(__m128h, __mmask8, __m128h, _m128d,
              ffi.Int32)>>('_mm_mask_cvt_roundsd_sh');
  late final __mm_mask_cvt_roundsd_sh = __mm_mask_cvt_roundsd_shPtr
      .asFunction<__m128h Function(__m128h, int, __m128h, _m128d, int)>();

  __m128h _mm_maskz_cvt_roundsd_sh(
    int arg0,
    __m128h arg1,
    _m128d arg2,
    int arg3,
  ) {
    return __mm_maskz_cvt_roundsd_sh(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_cvt_roundsd_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(__mmask8, __m128h, _m128d,
              ffi.Int32)>>('_mm_maskz_cvt_roundsd_sh');
  late final __mm_maskz_cvt_roundsd_sh = __mm_maskz_cvt_roundsd_shPtr
      .asFunction<__m128h Function(int, __m128h, _m128d, int)>();

  _m128d _mm_cvtsh_sd(
    _m128d arg0,
    __m128h arg1,
  ) {
    return __mm_cvtsh_sd(
      arg0,
      arg1,
    );
  }

  late final __mm_cvtsh_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, __m128h)>>(
          '_mm_cvtsh_sd');
  late final __mm_cvtsh_sd =
      __mm_cvtsh_sdPtr.asFunction<_m128d Function(_m128d, __m128h)>();

  _m128d _mm_mask_cvtsh_sd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    __m128h arg3,
  ) {
    return __mm_mask_cvtsh_sd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_cvtsh_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              _m128d, __mmask8, _m128d, __m128h)>>('_mm_mask_cvtsh_sd');
  late final __mm_mask_cvtsh_sd = __mm_mask_cvtsh_sdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d, __m128h)>();

  _m128d _mm_maskz_cvtsh_sd(
    int arg0,
    _m128d arg1,
    __m128h arg2,
  ) {
    return __mm_maskz_cvtsh_sd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_cvtsh_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(__mmask8, _m128d, __m128h)>>(
          '_mm_maskz_cvtsh_sd');
  late final __mm_maskz_cvtsh_sd = __mm_maskz_cvtsh_sdPtr
      .asFunction<_m128d Function(int, _m128d, __m128h)>();

  _m128d _mm_cvt_roundsh_sd(
    _m128d arg0,
    __m128h arg1,
    int arg2,
  ) {
    return __mm_cvt_roundsh_sd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_cvt_roundsh_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, __m128h, ffi.Int32)>>(
          '_mm_cvt_roundsh_sd');
  late final __mm_cvt_roundsh_sd = __mm_cvt_roundsh_sdPtr
      .asFunction<_m128d Function(_m128d, __m128h, int)>();

  _m128d _mm_mask_cvt_roundsh_sd(
    _m128d arg0,
    int arg1,
    _m128d arg2,
    __m128h arg3,
    int arg4,
  ) {
    return __mm_mask_cvt_roundsh_sd(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_cvt_roundsh_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(_m128d, __mmask8, _m128d, __m128h,
              ffi.Int32)>>('_mm_mask_cvt_roundsh_sd');
  late final __mm_mask_cvt_roundsh_sd = __mm_mask_cvt_roundsh_sdPtr
      .asFunction<_m128d Function(_m128d, int, _m128d, __m128h, int)>();

  _m128d _mm_maskz_cvt_roundsh_sd(
    int arg0,
    _m128d arg1,
    __m128h arg2,
    int arg3,
  ) {
    return __mm_maskz_cvt_roundsh_sd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_cvt_roundsh_sdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(__mmask8, _m128d, __m128h,
              ffi.Int32)>>('_mm_maskz_cvt_roundsh_sd');
  late final __mm_maskz_cvt_roundsh_sd = __mm_maskz_cvt_roundsh_sdPtr
      .asFunction<_m128d Function(int, _m128d, __m128h, int)>();

  int _mm_cvtsh_i32(
    __m128h arg0,
  ) {
    return __mm_cvtsh_i32(
      arg0,
    );
  }

  late final __mm_cvtsh_i32Ptr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(__m128h)>>('_mm_cvtsh_i32');
  late final __mm_cvtsh_i32 =
      __mm_cvtsh_i32Ptr.asFunction<int Function(__m128h)>();

  int _mm_cvtsh_i64(
    __m128h arg0,
  ) {
    return __mm_cvtsh_i64(
      arg0,
    );
  }

  late final __mm_cvtsh_i64Ptr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(__m128h)>>('_mm_cvtsh_i64');
  late final __mm_cvtsh_i64 =
      __mm_cvtsh_i64Ptr.asFunction<int Function(__m128h)>();

  int _mm_cvt_roundsh_i32(
    __m128h arg0,
    int arg1,
  ) {
    return __mm_cvt_roundsh_i32(
      arg0,
      arg1,
    );
  }

  late final __mm_cvt_roundsh_i32Ptr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(__m128h, ffi.Int32)>>(
          '_mm_cvt_roundsh_i32');
  late final __mm_cvt_roundsh_i32 =
      __mm_cvt_roundsh_i32Ptr.asFunction<int Function(__m128h, int)>();

  int _mm_cvt_roundsh_i64(
    __m128h arg0,
    int arg1,
  ) {
    return __mm_cvt_roundsh_i64(
      arg0,
      arg1,
    );
  }

  late final __mm_cvt_roundsh_i64Ptr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(__m128h, ffi.Int32)>>(
          '_mm_cvt_roundsh_i64');
  late final __mm_cvt_roundsh_i64 =
      __mm_cvt_roundsh_i64Ptr.asFunction<int Function(__m128h, int)>();

  __m128 _mm_cvtsh_ss(
    __m128 arg0,
    __m128h arg1,
  ) {
    return __mm_cvtsh_ss(
      arg0,
      arg1,
    );
  }

  late final __mm_cvtsh_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128h)>>(
          '_mm_cvtsh_ss');
  late final __mm_cvtsh_ss =
      __mm_cvtsh_ssPtr.asFunction<__m128 Function(__m128, __m128h)>();

  __m128 _mm_mask_cvtsh_ss(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    __m128h arg3,
  ) {
    return __mm_mask_cvtsh_ss(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_cvtsh_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __m128, __mmask8, __m128, __m128h)>>('_mm_mask_cvtsh_ss');
  late final __mm_mask_cvtsh_ss = __mm_mask_cvtsh_ssPtr
      .asFunction<__m128 Function(__m128, int, __m128, __m128h)>();

  __m128 _mm_maskz_cvtsh_ss(
    int arg0,
    __m128 arg1,
    __m128h arg2,
  ) {
    return __mm_maskz_cvtsh_ss(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_cvtsh_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__mmask8, __m128, __m128h)>>(
          '_mm_maskz_cvtsh_ss');
  late final __mm_maskz_cvtsh_ss = __mm_maskz_cvtsh_ssPtr
      .asFunction<__m128 Function(int, __m128, __m128h)>();

  __m128 _mm_cvt_roundsh_ss(
    __m128 arg0,
    __m128h arg1,
    int arg2,
  ) {
    return __mm_cvt_roundsh_ss(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_cvt_roundsh_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128h, ffi.Int32)>>(
          '_mm_cvt_roundsh_ss');
  late final __mm_cvt_roundsh_ss = __mm_cvt_roundsh_ssPtr
      .asFunction<__m128 Function(__m128, __m128h, int)>();

  __m128 _mm_mask_cvt_roundsh_ss(
    __m128 arg0,
    int arg1,
    __m128 arg2,
    __m128h arg3,
    int arg4,
  ) {
    return __mm_mask_cvt_roundsh_ss(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_cvt_roundsh_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(__m128, __mmask8, __m128, __m128h,
              ffi.Int32)>>('_mm_mask_cvt_roundsh_ss');
  late final __mm_mask_cvt_roundsh_ss = __mm_mask_cvt_roundsh_ssPtr
      .asFunction<__m128 Function(__m128, int, __m128, __m128h, int)>();

  __m128 _mm_maskz_cvt_roundsh_ss(
    int arg0,
    __m128 arg1,
    __m128h arg2,
    int arg3,
  ) {
    return __mm_maskz_cvt_roundsh_ss(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_cvt_roundsh_ssPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(__mmask8, __m128, __m128h,
              ffi.Int32)>>('_mm_maskz_cvt_roundsh_ss');
  late final __mm_maskz_cvt_roundsh_ss = __mm_maskz_cvt_roundsh_ssPtr
      .asFunction<__m128 Function(int, __m128, __m128h, int)>();

  int _mm_cvtsh_u32(
    __m128h arg0,
  ) {
    return __mm_cvtsh_u32(
      arg0,
    );
  }

  late final __mm_cvtsh_u32Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint32 Function(__m128h)>>(
          '_mm_cvtsh_u32');
  late final __mm_cvtsh_u32 =
      __mm_cvtsh_u32Ptr.asFunction<int Function(__m128h)>();

  int _mm_cvtsh_u64(
    __m128h arg0,
  ) {
    return __mm_cvtsh_u64(
      arg0,
    );
  }

  late final __mm_cvtsh_u64Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function(__m128h)>>(
          '_mm_cvtsh_u64');
  late final __mm_cvtsh_u64 =
      __mm_cvtsh_u64Ptr.asFunction<int Function(__m128h)>();

  int _mm_cvt_roundsh_u32(
    __m128h arg0,
    int arg1,
  ) {
    return __mm_cvt_roundsh_u32(
      arg0,
      arg1,
    );
  }

  late final __mm_cvt_roundsh_u32Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint32 Function(__m128h, ffi.Int32)>>(
          '_mm_cvt_roundsh_u32');
  late final __mm_cvt_roundsh_u32 =
      __mm_cvt_roundsh_u32Ptr.asFunction<int Function(__m128h, int)>();

  int _mm_cvt_roundsh_u64(
    __m128h arg0,
    int arg1,
  ) {
    return __mm_cvt_roundsh_u64(
      arg0,
      arg1,
    );
  }

  late final __mm_cvt_roundsh_u64Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function(__m128h, ffi.Int32)>>(
          '_mm_cvt_roundsh_u64');
  late final __mm_cvt_roundsh_u64 =
      __mm_cvt_roundsh_u64Ptr.asFunction<int Function(__m128h, int)>();

  __m128h _mm_cvti32_sh(
    __m128h arg0,
    int arg1,
  ) {
    return __mm_cvti32_sh(
      arg0,
      arg1,
    );
  }

  late final __mm_cvti32_shPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128h, ffi.Int32)>>(
          '_mm_cvti32_sh');
  late final __mm_cvti32_sh =
      __mm_cvti32_shPtr.asFunction<__m128h Function(__m128h, int)>();

  __m128h _mm_cvti64_sh(
    __m128h arg0,
    int arg1,
  ) {
    return __mm_cvti64_sh(
      arg0,
      arg1,
    );
  }

  late final __mm_cvti64_shPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128h, ffi.Int64)>>(
          '_mm_cvti64_sh');
  late final __mm_cvti64_sh =
      __mm_cvti64_shPtr.asFunction<__m128h Function(__m128h, int)>();

  __m128h _mm_cvt_roundi32_sh(
    __m128h arg0,
    int arg1,
    int arg2,
  ) {
    return __mm_cvt_roundi32_sh(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_cvt_roundi32_shPtr = _lookup<
          ffi.NativeFunction<__m128h Function(__m128h, ffi.Int32, ffi.Int32)>>(
      '_mm_cvt_roundi32_sh');
  late final __mm_cvt_roundi32_sh =
      __mm_cvt_roundi32_shPtr.asFunction<__m128h Function(__m128h, int, int)>();

  __m128h _mm_cvt_roundi64_sh(
    __m128h arg0,
    int arg1,
    int arg2,
  ) {
    return __mm_cvt_roundi64_sh(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_cvt_roundi64_shPtr = _lookup<
          ffi.NativeFunction<__m128h Function(__m128h, ffi.Int64, ffi.Int32)>>(
      '_mm_cvt_roundi64_sh');
  late final __mm_cvt_roundi64_sh =
      __mm_cvt_roundi64_shPtr.asFunction<__m128h Function(__m128h, int, int)>();

  __m128h _mm_cvtss_sh(
    __m128h arg0,
    __m128 arg1,
    int arg2,
  ) {
    return __mm_cvtss_sh(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_cvtss_shPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128h, __m128, ffi.Int32)>>(
          '_mm_cvtss_sh');
  late final __mm_cvtss_sh =
      __mm_cvtss_shPtr.asFunction<__m128h Function(__m128h, __m128, int)>();

  __m128h _mm_mask_cvtss_sh(
    __m128h arg0,
    int arg1,
    __m128h arg2,
    __m128 arg3,
    int arg4,
  ) {
    return __mm_mask_cvtss_sh(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_cvtss_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(__m128h, __mmask8, __m128h, __m128,
              ffi.Int32)>>('_mm_mask_cvtss_sh');
  late final __mm_mask_cvtss_sh = __mm_mask_cvtss_shPtr
      .asFunction<__m128h Function(__m128h, int, __m128h, __m128, int)>();

  __m128h _mm_maskz_cvtss_sh(
    int arg0,
    __m128h arg1,
    __m128 arg2,
    int arg3,
  ) {
    return __mm_maskz_cvtss_sh(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_cvtss_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __mmask8, __m128h, __m128, ffi.Int32)>>('_mm_maskz_cvtss_sh');
  late final __mm_maskz_cvtss_sh = __mm_maskz_cvtss_shPtr
      .asFunction<__m128h Function(int, __m128h, __m128, int)>();

  __m128h _mm_cvt_roundss_sh(
    __m128h arg0,
    __m128 arg1,
    int arg2,
  ) {
    return __mm_cvt_roundss_sh(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_cvt_roundss_shPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128h, __m128, ffi.Int32)>>(
          '_mm_cvt_roundss_sh');
  late final __mm_cvt_roundss_sh = __mm_cvt_roundss_shPtr
      .asFunction<__m128h Function(__m128h, __m128, int)>();

  __m128h _mm_mask_cvt_roundss_sh(
    __m128h arg0,
    int arg1,
    __m128h arg2,
    __m128 arg3,
    int arg4,
  ) {
    return __mm_mask_cvt_roundss_sh(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_cvt_roundss_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(__m128h, __mmask8, __m128h, __m128,
              ffi.Int32)>>('_mm_mask_cvt_roundss_sh');
  late final __mm_mask_cvt_roundss_sh = __mm_mask_cvt_roundss_shPtr
      .asFunction<__m128h Function(__m128h, int, __m128h, __m128, int)>();

  __m128h _mm_maskz_cvt_roundss_sh(
    int arg0,
    __m128h arg1,
    __m128 arg2,
    int arg3,
  ) {
    return __mm_maskz_cvt_roundss_sh(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_cvt_roundss_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(__mmask8, __m128h, __m128,
              ffi.Int32)>>('_mm_maskz_cvt_roundss_sh');
  late final __mm_maskz_cvt_roundss_sh = __mm_maskz_cvt_roundss_shPtr
      .asFunction<__m128h Function(int, __m128h, __m128, int)>();

  __m128i _mm_cvttph_epi32(
    __m128h arg0,
  ) {
    return __mm_cvttph_epi32(
      arg0,
    );
  }

  late final __mm_cvttph_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128h)>>(
          '_mm_cvttph_epi32');
  late final __mm_cvttph_epi32 =
      __mm_cvttph_epi32Ptr.asFunction<__m128i Function(__m128h)>();

  __m128i _mm_mask_cvttph_epi32(
    __m128i arg0,
    int arg1,
    __m128h arg2,
  ) {
    return __mm_mask_cvttph_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvttph_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m128h)>>(
          '_mm_mask_cvttph_epi32');
  late final __mm_mask_cvttph_epi32 = __mm_mask_cvttph_epi32Ptr
      .asFunction<__m128i Function(__m128i, int, __m128h)>();

  __m128i _mm_maskz_cvttph_epi32(
    int arg0,
    __m128h arg1,
  ) {
    return __mm_maskz_cvttph_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvttph_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128h)>>(
          '_mm_maskz_cvttph_epi32');
  late final __mm_maskz_cvttph_epi32 =
      __mm_maskz_cvttph_epi32Ptr.asFunction<__m128i Function(int, __m128h)>();

  __m256i _mm256_cvttph_epi32(
    __m128h arg0,
  ) {
    return __mm256_cvttph_epi32(
      arg0,
    );
  }

  late final __mm256_cvttph_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m128h)>>(
          '_mm256_cvttph_epi32');
  late final __mm256_cvttph_epi32 =
      __mm256_cvttph_epi32Ptr.asFunction<__m256i Function(__m128h)>();

  __m256i _mm256_mask_cvttph_epi32(
    __m256i arg0,
    int arg1,
    __m128h arg2,
  ) {
    return __mm256_mask_cvttph_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvttph_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __mmask8, __m128h)>>(
          '_mm256_mask_cvttph_epi32');
  late final __mm256_mask_cvttph_epi32 = __mm256_mask_cvttph_epi32Ptr
      .asFunction<__m256i Function(__m256i, int, __m128h)>();

  __m256i _mm256_maskz_cvttph_epi32(
    int arg0,
    __m128h arg1,
  ) {
    return __mm256_maskz_cvttph_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvttph_epi32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m128h)>>(
          '_mm256_maskz_cvttph_epi32');
  late final __mm256_maskz_cvttph_epi32 = __mm256_maskz_cvttph_epi32Ptr
      .asFunction<__m256i Function(int, __m128h)>();

  __m512i _mm512_cvttph_epi32(
    __m256h arg0,
  ) {
    return __mm512_cvttph_epi32(
      arg0,
    );
  }

  late final __mm512_cvttph_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m256h)>>(
          '_mm512_cvttph_epi32');
  late final __mm512_cvttph_epi32 =
      __mm512_cvttph_epi32Ptr.asFunction<__m512i Function(__m256h)>();

  __m512i _mm512_mask_cvttph_epi32(
    __m512i arg0,
    int arg1,
    __m256h arg2,
  ) {
    return __mm512_mask_cvttph_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvttph_epi32Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__m512i, __mmask16, __m256h)>>(
      '_mm512_mask_cvttph_epi32');
  late final __mm512_mask_cvttph_epi32 = __mm512_mask_cvttph_epi32Ptr
      .asFunction<__m512i Function(__m512i, int, __m256h)>();

  __m512i _mm512_maskz_cvttph_epi32(
    int arg0,
    __m256h arg1,
  ) {
    return __mm512_maskz_cvttph_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvttph_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask16, __m256h)>>(
          '_mm512_maskz_cvttph_epi32');
  late final __mm512_maskz_cvttph_epi32 = __mm512_maskz_cvttph_epi32Ptr
      .asFunction<__m512i Function(int, __m256h)>();

  __m512i _mm512_cvtt_roundph_epi32(
    __m256h arg0,
    int arg1,
  ) {
    return __mm512_cvtt_roundph_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm512_cvtt_roundph_epi32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m256h, ffi.Int32)>>(
          '_mm512_cvtt_roundph_epi32');
  late final __mm512_cvtt_roundph_epi32 = __mm512_cvtt_roundph_epi32Ptr
      .asFunction<__m512i Function(__m256h, int)>();

  __m512i _mm512_mask_cvtt_roundph_epi32(
    __m512i arg0,
    int arg1,
    __m256h arg2,
    int arg3,
  ) {
    return __mm512_mask_cvtt_roundph_epi32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_cvtt_roundph_epi32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask16, __m256h,
              ffi.Int32)>>('_mm512_mask_cvtt_roundph_epi32');
  late final __mm512_mask_cvtt_roundph_epi32 =
      __mm512_mask_cvtt_roundph_epi32Ptr
          .asFunction<__m512i Function(__m512i, int, __m256h, int)>();

  __m512i _mm512_maskz_cvtt_roundph_epi32(
    int arg0,
    __m256h arg1,
    int arg2,
  ) {
    return __mm512_maskz_cvtt_roundph_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_cvtt_roundph_epi32Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask16, __m256h, ffi.Int32)>>(
      '_mm512_maskz_cvtt_roundph_epi32');
  late final __mm512_maskz_cvtt_roundph_epi32 =
      __mm512_maskz_cvtt_roundph_epi32Ptr
          .asFunction<__m512i Function(int, __m256h, int)>();

  __m128i _mm_cvttph_epi64(
    __m128h arg0,
  ) {
    return __mm_cvttph_epi64(
      arg0,
    );
  }

  late final __mm_cvttph_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128h)>>(
          '_mm_cvttph_epi64');
  late final __mm_cvttph_epi64 =
      __mm_cvttph_epi64Ptr.asFunction<__m128i Function(__m128h)>();

  __m128i _mm_mask_cvttph_epi64(
    __m128i arg0,
    int arg1,
    __m128h arg2,
  ) {
    return __mm_mask_cvttph_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvttph_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m128h)>>(
          '_mm_mask_cvttph_epi64');
  late final __mm_mask_cvttph_epi64 = __mm_mask_cvttph_epi64Ptr
      .asFunction<__m128i Function(__m128i, int, __m128h)>();

  __m128i _mm_maskz_cvttph_epi64(
    int arg0,
    __m128h arg1,
  ) {
    return __mm_maskz_cvttph_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvttph_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128h)>>(
          '_mm_maskz_cvttph_epi64');
  late final __mm_maskz_cvttph_epi64 =
      __mm_maskz_cvttph_epi64Ptr.asFunction<__m128i Function(int, __m128h)>();

  __m256i _mm256_cvttph_epi64(
    __m128h arg0,
  ) {
    return __mm256_cvttph_epi64(
      arg0,
    );
  }

  late final __mm256_cvttph_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m128h)>>(
          '_mm256_cvttph_epi64');
  late final __mm256_cvttph_epi64 =
      __mm256_cvttph_epi64Ptr.asFunction<__m256i Function(__m128h)>();

  __m256i _mm256_mask_cvttph_epi64(
    __m256i arg0,
    int arg1,
    __m128h arg2,
  ) {
    return __mm256_mask_cvttph_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvttph_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __mmask8, __m128h)>>(
          '_mm256_mask_cvttph_epi64');
  late final __mm256_mask_cvttph_epi64 = __mm256_mask_cvttph_epi64Ptr
      .asFunction<__m256i Function(__m256i, int, __m128h)>();

  __m256i _mm256_maskz_cvttph_epi64(
    int arg0,
    __m128h arg1,
  ) {
    return __mm256_maskz_cvttph_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvttph_epi64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m128h)>>(
          '_mm256_maskz_cvttph_epi64');
  late final __mm256_maskz_cvttph_epi64 = __mm256_maskz_cvttph_epi64Ptr
      .asFunction<__m256i Function(int, __m128h)>();

  __m512i _mm512_cvttph_epi64(
    __m128h arg0,
  ) {
    return __mm512_cvttph_epi64(
      arg0,
    );
  }

  late final __mm512_cvttph_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m128h)>>(
          '_mm512_cvttph_epi64');
  late final __mm512_cvttph_epi64 =
      __mm512_cvttph_epi64Ptr.asFunction<__m512i Function(__m128h)>();

  __m512i _mm512_mask_cvttph_epi64(
    __m512i arg0,
    int arg1,
    __m128h arg2,
  ) {
    return __mm512_mask_cvttph_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvttph_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __mmask8, __m128h)>>(
          '_mm512_mask_cvttph_epi64');
  late final __mm512_mask_cvttph_epi64 = __mm512_mask_cvttph_epi64Ptr
      .asFunction<__m512i Function(__m512i, int, __m128h)>();

  __m512i _mm512_maskz_cvttph_epi64(
    int arg0,
    __m128h arg1,
  ) {
    return __mm512_maskz_cvttph_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvttph_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask8, __m128h)>>(
          '_mm512_maskz_cvttph_epi64');
  late final __mm512_maskz_cvttph_epi64 = __mm512_maskz_cvttph_epi64Ptr
      .asFunction<__m512i Function(int, __m128h)>();

  __m512i _mm512_cvtt_roundph_epi64(
    __m128h arg0,
    int arg1,
  ) {
    return __mm512_cvtt_roundph_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm512_cvtt_roundph_epi64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m128h, ffi.Int32)>>(
          '_mm512_cvtt_roundph_epi64');
  late final __mm512_cvtt_roundph_epi64 = __mm512_cvtt_roundph_epi64Ptr
      .asFunction<__m512i Function(__m128h, int)>();

  __m512i _mm512_mask_cvtt_roundph_epi64(
    __m512i arg0,
    int arg1,
    __m128h arg2,
    int arg3,
  ) {
    return __mm512_mask_cvtt_roundph_epi64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_cvtt_roundph_epi64Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask8, __m128h,
              ffi.Int32)>>('_mm512_mask_cvtt_roundph_epi64');
  late final __mm512_mask_cvtt_roundph_epi64 =
      __mm512_mask_cvtt_roundph_epi64Ptr
          .asFunction<__m512i Function(__m512i, int, __m128h, int)>();

  __m512i _mm512_maskz_cvtt_roundph_epi64(
    int arg0,
    __m128h arg1,
    int arg2,
  ) {
    return __mm512_maskz_cvtt_roundph_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_cvtt_roundph_epi64Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask8, __m128h, ffi.Int32)>>(
      '_mm512_maskz_cvtt_roundph_epi64');
  late final __mm512_maskz_cvtt_roundph_epi64 =
      __mm512_maskz_cvtt_roundph_epi64Ptr
          .asFunction<__m512i Function(int, __m128h, int)>();

  __m128i _mm_cvttph_epu32(
    __m128h arg0,
  ) {
    return __mm_cvttph_epu32(
      arg0,
    );
  }

  late final __mm_cvttph_epu32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128h)>>(
          '_mm_cvttph_epu32');
  late final __mm_cvttph_epu32 =
      __mm_cvttph_epu32Ptr.asFunction<__m128i Function(__m128h)>();

  __m128i _mm_mask_cvttph_epu32(
    __m128i arg0,
    int arg1,
    __m128h arg2,
  ) {
    return __mm_mask_cvttph_epu32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvttph_epu32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m128h)>>(
          '_mm_mask_cvttph_epu32');
  late final __mm_mask_cvttph_epu32 = __mm_mask_cvttph_epu32Ptr
      .asFunction<__m128i Function(__m128i, int, __m128h)>();

  __m128i _mm_maskz_cvttph_epu32(
    int arg0,
    __m128h arg1,
  ) {
    return __mm_maskz_cvttph_epu32(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvttph_epu32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128h)>>(
          '_mm_maskz_cvttph_epu32');
  late final __mm_maskz_cvttph_epu32 =
      __mm_maskz_cvttph_epu32Ptr.asFunction<__m128i Function(int, __m128h)>();

  __m256i _mm256_cvttph_epu32(
    __m128h arg0,
  ) {
    return __mm256_cvttph_epu32(
      arg0,
    );
  }

  late final __mm256_cvttph_epu32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m128h)>>(
          '_mm256_cvttph_epu32');
  late final __mm256_cvttph_epu32 =
      __mm256_cvttph_epu32Ptr.asFunction<__m256i Function(__m128h)>();

  __m256i _mm256_mask_cvttph_epu32(
    __m256i arg0,
    int arg1,
    __m128h arg2,
  ) {
    return __mm256_mask_cvttph_epu32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvttph_epu32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __mmask8, __m128h)>>(
          '_mm256_mask_cvttph_epu32');
  late final __mm256_mask_cvttph_epu32 = __mm256_mask_cvttph_epu32Ptr
      .asFunction<__m256i Function(__m256i, int, __m128h)>();

  __m256i _mm256_maskz_cvttph_epu32(
    int arg0,
    __m128h arg1,
  ) {
    return __mm256_maskz_cvttph_epu32(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvttph_epu32Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m128h)>>(
          '_mm256_maskz_cvttph_epu32');
  late final __mm256_maskz_cvttph_epu32 = __mm256_maskz_cvttph_epu32Ptr
      .asFunction<__m256i Function(int, __m128h)>();

  __m512i _mm512_cvttph_epu32(
    __m256h arg0,
  ) {
    return __mm512_cvttph_epu32(
      arg0,
    );
  }

  late final __mm512_cvttph_epu32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m256h)>>(
          '_mm512_cvttph_epu32');
  late final __mm512_cvttph_epu32 =
      __mm512_cvttph_epu32Ptr.asFunction<__m512i Function(__m256h)>();

  __m512i _mm512_mask_cvttph_epu32(
    __m512i arg0,
    int arg1,
    __m256h arg2,
  ) {
    return __mm512_mask_cvttph_epu32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvttph_epu32Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__m512i, __mmask16, __m256h)>>(
      '_mm512_mask_cvttph_epu32');
  late final __mm512_mask_cvttph_epu32 = __mm512_mask_cvttph_epu32Ptr
      .asFunction<__m512i Function(__m512i, int, __m256h)>();

  __m512i _mm512_maskz_cvttph_epu32(
    int arg0,
    __m256h arg1,
  ) {
    return __mm512_maskz_cvttph_epu32(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvttph_epu32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask16, __m256h)>>(
          '_mm512_maskz_cvttph_epu32');
  late final __mm512_maskz_cvttph_epu32 = __mm512_maskz_cvttph_epu32Ptr
      .asFunction<__m512i Function(int, __m256h)>();

  __m512i _mm512_cvtt_roundph_epu32(
    __m256h arg0,
    int arg1,
  ) {
    return __mm512_cvtt_roundph_epu32(
      arg0,
      arg1,
    );
  }

  late final __mm512_cvtt_roundph_epu32Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m256h, ffi.Int32)>>(
          '_mm512_cvtt_roundph_epu32');
  late final __mm512_cvtt_roundph_epu32 = __mm512_cvtt_roundph_epu32Ptr
      .asFunction<__m512i Function(__m256h, int)>();

  __m512i _mm512_mask_cvtt_roundph_epu32(
    __m512i arg0,
    int arg1,
    __m256h arg2,
    int arg3,
  ) {
    return __mm512_mask_cvtt_roundph_epu32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_cvtt_roundph_epu32Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask16, __m256h,
              ffi.Int32)>>('_mm512_mask_cvtt_roundph_epu32');
  late final __mm512_mask_cvtt_roundph_epu32 =
      __mm512_mask_cvtt_roundph_epu32Ptr
          .asFunction<__m512i Function(__m512i, int, __m256h, int)>();

  __m512i _mm512_maskz_cvtt_roundph_epu32(
    int arg0,
    __m256h arg1,
    int arg2,
  ) {
    return __mm512_maskz_cvtt_roundph_epu32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_cvtt_roundph_epu32Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask16, __m256h, ffi.Int32)>>(
      '_mm512_maskz_cvtt_roundph_epu32');
  late final __mm512_maskz_cvtt_roundph_epu32 =
      __mm512_maskz_cvtt_roundph_epu32Ptr
          .asFunction<__m512i Function(int, __m256h, int)>();

  __m128i _mm_cvttph_epu64(
    __m128h arg0,
  ) {
    return __mm_cvttph_epu64(
      arg0,
    );
  }

  late final __mm_cvttph_epu64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128h)>>(
          '_mm_cvttph_epu64');
  late final __mm_cvttph_epu64 =
      __mm_cvttph_epu64Ptr.asFunction<__m128i Function(__m128h)>();

  __m128i _mm_mask_cvttph_epu64(
    __m128i arg0,
    int arg1,
    __m128h arg2,
  ) {
    return __mm_mask_cvttph_epu64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvttph_epu64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m128h)>>(
          '_mm_mask_cvttph_epu64');
  late final __mm_mask_cvttph_epu64 = __mm_mask_cvttph_epu64Ptr
      .asFunction<__m128i Function(__m128i, int, __m128h)>();

  __m128i _mm_maskz_cvttph_epu64(
    int arg0,
    __m128h arg1,
  ) {
    return __mm_maskz_cvttph_epu64(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvttph_epu64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128h)>>(
          '_mm_maskz_cvttph_epu64');
  late final __mm_maskz_cvttph_epu64 =
      __mm_maskz_cvttph_epu64Ptr.asFunction<__m128i Function(int, __m128h)>();

  __m256i _mm256_cvttph_epu64(
    __m128h arg0,
  ) {
    return __mm256_cvttph_epu64(
      arg0,
    );
  }

  late final __mm256_cvttph_epu64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m128h)>>(
          '_mm256_cvttph_epu64');
  late final __mm256_cvttph_epu64 =
      __mm256_cvttph_epu64Ptr.asFunction<__m256i Function(__m128h)>();

  __m256i _mm256_mask_cvttph_epu64(
    __m256i arg0,
    int arg1,
    __m128h arg2,
  ) {
    return __mm256_mask_cvttph_epu64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvttph_epu64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __mmask8, __m128h)>>(
          '_mm256_mask_cvttph_epu64');
  late final __mm256_mask_cvttph_epu64 = __mm256_mask_cvttph_epu64Ptr
      .asFunction<__m256i Function(__m256i, int, __m128h)>();

  __m256i _mm256_maskz_cvttph_epu64(
    int arg0,
    __m128h arg1,
  ) {
    return __mm256_maskz_cvttph_epu64(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvttph_epu64Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask8, __m128h)>>(
          '_mm256_maskz_cvttph_epu64');
  late final __mm256_maskz_cvttph_epu64 = __mm256_maskz_cvttph_epu64Ptr
      .asFunction<__m256i Function(int, __m128h)>();

  __m512i _mm512_cvttph_epu64(
    __m128h arg0,
  ) {
    return __mm512_cvttph_epu64(
      arg0,
    );
  }

  late final __mm512_cvttph_epu64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m128h)>>(
          '_mm512_cvttph_epu64');
  late final __mm512_cvttph_epu64 =
      __mm512_cvttph_epu64Ptr.asFunction<__m512i Function(__m128h)>();

  __m512i _mm512_mask_cvttph_epu64(
    __m512i arg0,
    int arg1,
    __m128h arg2,
  ) {
    return __mm512_mask_cvttph_epu64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvttph_epu64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512i, __mmask8, __m128h)>>(
          '_mm512_mask_cvttph_epu64');
  late final __mm512_mask_cvttph_epu64 = __mm512_mask_cvttph_epu64Ptr
      .asFunction<__m512i Function(__m512i, int, __m128h)>();

  __m512i _mm512_maskz_cvttph_epu64(
    int arg0,
    __m128h arg1,
  ) {
    return __mm512_maskz_cvttph_epu64(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvttph_epu64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask8, __m128h)>>(
          '_mm512_maskz_cvttph_epu64');
  late final __mm512_maskz_cvttph_epu64 = __mm512_maskz_cvttph_epu64Ptr
      .asFunction<__m512i Function(int, __m128h)>();

  __m512i _mm512_cvtt_roundph_epu64(
    __m128h arg0,
    int arg1,
  ) {
    return __mm512_cvtt_roundph_epu64(
      arg0,
      arg1,
    );
  }

  late final __mm512_cvtt_roundph_epu64Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m128h, ffi.Int32)>>(
          '_mm512_cvtt_roundph_epu64');
  late final __mm512_cvtt_roundph_epu64 = __mm512_cvtt_roundph_epu64Ptr
      .asFunction<__m512i Function(__m128h, int)>();

  __m512i _mm512_mask_cvtt_roundph_epu64(
    __m512i arg0,
    int arg1,
    __m128h arg2,
    int arg3,
  ) {
    return __mm512_mask_cvtt_roundph_epu64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_cvtt_roundph_epu64Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask8, __m128h,
              ffi.Int32)>>('_mm512_mask_cvtt_roundph_epu64');
  late final __mm512_mask_cvtt_roundph_epu64 =
      __mm512_mask_cvtt_roundph_epu64Ptr
          .asFunction<__m512i Function(__m512i, int, __m128h, int)>();

  __m512i _mm512_maskz_cvtt_roundph_epu64(
    int arg0,
    __m128h arg1,
    int arg2,
  ) {
    return __mm512_maskz_cvtt_roundph_epu64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_cvtt_roundph_epu64Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask8, __m128h, ffi.Int32)>>(
      '_mm512_maskz_cvtt_roundph_epu64');
  late final __mm512_maskz_cvtt_roundph_epu64 =
      __mm512_maskz_cvtt_roundph_epu64Ptr
          .asFunction<__m512i Function(int, __m128h, int)>();

  __m128i _mm_cvttph_epu16(
    __m128h arg0,
  ) {
    return __mm_cvttph_epu16(
      arg0,
    );
  }

  late final __mm_cvttph_epu16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128h)>>(
          '_mm_cvttph_epu16');
  late final __mm_cvttph_epu16 =
      __mm_cvttph_epu16Ptr.asFunction<__m128i Function(__m128h)>();

  __m128i _mm_mask_cvttph_epu16(
    __m128i arg0,
    int arg1,
    __m128h arg2,
  ) {
    return __mm_mask_cvttph_epu16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvttph_epu16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m128h)>>(
          '_mm_mask_cvttph_epu16');
  late final __mm_mask_cvttph_epu16 = __mm_mask_cvttph_epu16Ptr
      .asFunction<__m128i Function(__m128i, int, __m128h)>();

  __m128i _mm_maskz_cvttph_epu16(
    int arg0,
    __m128h arg1,
  ) {
    return __mm_maskz_cvttph_epu16(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvttph_epu16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128h)>>(
          '_mm_maskz_cvttph_epu16');
  late final __mm_maskz_cvttph_epu16 =
      __mm_maskz_cvttph_epu16Ptr.asFunction<__m128i Function(int, __m128h)>();

  __m256i _mm256_cvttph_epu16(
    __m256h arg0,
  ) {
    return __mm256_cvttph_epu16(
      arg0,
    );
  }

  late final __mm256_cvttph_epu16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256h)>>(
          '_mm256_cvttph_epu16');
  late final __mm256_cvttph_epu16 =
      __mm256_cvttph_epu16Ptr.asFunction<__m256i Function(__m256h)>();

  __m256i _mm256_mask_cvttph_epu16(
    __m256i arg0,
    int arg1,
    __m256h arg2,
  ) {
    return __mm256_mask_cvttph_epu16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvttph_epu16Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__m256i, __mmask16, __m256h)>>(
      '_mm256_mask_cvttph_epu16');
  late final __mm256_mask_cvttph_epu16 = __mm256_mask_cvttph_epu16Ptr
      .asFunction<__m256i Function(__m256i, int, __m256h)>();

  __m256i _mm256_maskz_cvttph_epu16(
    int arg0,
    __m256h arg1,
  ) {
    return __mm256_maskz_cvttph_epu16(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvttph_epu16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask16, __m256h)>>(
          '_mm256_maskz_cvttph_epu16');
  late final __mm256_maskz_cvttph_epu16 = __mm256_maskz_cvttph_epu16Ptr
      .asFunction<__m256i Function(int, __m256h)>();

  __m512i _mm512_cvttph_epu16(
    __m512h arg0,
  ) {
    return __mm512_cvttph_epu16(
      arg0,
    );
  }

  late final __mm512_cvttph_epu16Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512h)>>(
          '_mm512_cvttph_epu16');
  late final __mm512_cvttph_epu16 =
      __mm512_cvttph_epu16Ptr.asFunction<__m512i Function(__m512h)>();

  __m512i _mm512_mask_cvttph_epu16(
    __m512i arg0,
    int arg1,
    __m512h arg2,
  ) {
    return __mm512_mask_cvttph_epu16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvttph_epu16Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__m512i, __mmask32, __m512h)>>(
      '_mm512_mask_cvttph_epu16');
  late final __mm512_mask_cvttph_epu16 = __mm512_mask_cvttph_epu16Ptr
      .asFunction<__m512i Function(__m512i, int, __m512h)>();

  __m512i _mm512_maskz_cvttph_epu16(
    int arg0,
    __m512h arg1,
  ) {
    return __mm512_maskz_cvttph_epu16(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvttph_epu16Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask32, __m512h)>>(
          '_mm512_maskz_cvttph_epu16');
  late final __mm512_maskz_cvttph_epu16 = __mm512_maskz_cvttph_epu16Ptr
      .asFunction<__m512i Function(int, __m512h)>();

  __m512i _mm512_cvtt_roundph_epu16(
    __m512h arg0,
    int arg1,
  ) {
    return __mm512_cvtt_roundph_epu16(
      arg0,
      arg1,
    );
  }

  late final __mm512_cvtt_roundph_epu16Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512h, ffi.Int32)>>(
          '_mm512_cvtt_roundph_epu16');
  late final __mm512_cvtt_roundph_epu16 = __mm512_cvtt_roundph_epu16Ptr
      .asFunction<__m512i Function(__m512h, int)>();

  __m512i _mm512_mask_cvtt_roundph_epu16(
    __m512i arg0,
    int arg1,
    __m512h arg2,
    int arg3,
  ) {
    return __mm512_mask_cvtt_roundph_epu16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_cvtt_roundph_epu16Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask32, __m512h,
              ffi.Int32)>>('_mm512_mask_cvtt_roundph_epu16');
  late final __mm512_mask_cvtt_roundph_epu16 =
      __mm512_mask_cvtt_roundph_epu16Ptr
          .asFunction<__m512i Function(__m512i, int, __m512h, int)>();

  __m512i _mm512_maskz_cvtt_roundph_epu16(
    int arg0,
    __m512h arg1,
    int arg2,
  ) {
    return __mm512_maskz_cvtt_roundph_epu16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_cvtt_roundph_epu16Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask32, __m512h, ffi.Int32)>>(
      '_mm512_maskz_cvtt_roundph_epu16');
  late final __mm512_maskz_cvtt_roundph_epu16 =
      __mm512_maskz_cvtt_roundph_epu16Ptr
          .asFunction<__m512i Function(int, __m512h, int)>();

  __m128i _mm_cvttph_epi16(
    __m128h arg0,
  ) {
    return __mm_cvttph_epi16(
      arg0,
    );
  }

  late final __mm_cvttph_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128h)>>(
          '_mm_cvttph_epi16');
  late final __mm_cvttph_epi16 =
      __mm_cvttph_epi16Ptr.asFunction<__m128i Function(__m128h)>();

  __m128i _mm_mask_cvttph_epi16(
    __m128i arg0,
    int arg1,
    __m128h arg2,
  ) {
    return __mm_mask_cvttph_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvttph_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __mmask8, __m128h)>>(
          '_mm_mask_cvttph_epi16');
  late final __mm_mask_cvttph_epi16 = __mm_mask_cvttph_epi16Ptr
      .asFunction<__m128i Function(__m128i, int, __m128h)>();

  __m128i _mm_maskz_cvttph_epi16(
    int arg0,
    __m128h arg1,
  ) {
    return __mm_maskz_cvttph_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvttph_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__mmask8, __m128h)>>(
          '_mm_maskz_cvttph_epi16');
  late final __mm_maskz_cvttph_epi16 =
      __mm_maskz_cvttph_epi16Ptr.asFunction<__m128i Function(int, __m128h)>();

  __m256i _mm256_cvttph_epi16(
    __m256h arg0,
  ) {
    return __mm256_cvttph_epi16(
      arg0,
    );
  }

  late final __mm256_cvttph_epi16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256h)>>(
          '_mm256_cvttph_epi16');
  late final __mm256_cvttph_epi16 =
      __mm256_cvttph_epi16Ptr.asFunction<__m256i Function(__m256h)>();

  __m256i _mm256_mask_cvttph_epi16(
    __m256i arg0,
    int arg1,
    __m256h arg2,
  ) {
    return __mm256_mask_cvttph_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvttph_epi16Ptr = _lookup<
          ffi.NativeFunction<__m256i Function(__m256i, __mmask16, __m256h)>>(
      '_mm256_mask_cvttph_epi16');
  late final __mm256_mask_cvttph_epi16 = __mm256_mask_cvttph_epi16Ptr
      .asFunction<__m256i Function(__m256i, int, __m256h)>();

  __m256i _mm256_maskz_cvttph_epi16(
    int arg0,
    __m256h arg1,
  ) {
    return __mm256_maskz_cvttph_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvttph_epi16Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__mmask16, __m256h)>>(
          '_mm256_maskz_cvttph_epi16');
  late final __mm256_maskz_cvttph_epi16 = __mm256_maskz_cvttph_epi16Ptr
      .asFunction<__m256i Function(int, __m256h)>();

  __m512i _mm512_cvttph_epi16(
    __m512h arg0,
  ) {
    return __mm512_cvttph_epi16(
      arg0,
    );
  }

  late final __mm512_cvttph_epi16Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512h)>>(
          '_mm512_cvttph_epi16');
  late final __mm512_cvttph_epi16 =
      __mm512_cvttph_epi16Ptr.asFunction<__m512i Function(__m512h)>();

  __m512i _mm512_mask_cvttph_epi16(
    __m512i arg0,
    int arg1,
    __m512h arg2,
  ) {
    return __mm512_mask_cvttph_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvttph_epi16Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__m512i, __mmask32, __m512h)>>(
      '_mm512_mask_cvttph_epi16');
  late final __mm512_mask_cvttph_epi16 = __mm512_mask_cvttph_epi16Ptr
      .asFunction<__m512i Function(__m512i, int, __m512h)>();

  __m512i _mm512_maskz_cvttph_epi16(
    int arg0,
    __m512h arg1,
  ) {
    return __mm512_maskz_cvttph_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvttph_epi16Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__mmask32, __m512h)>>(
          '_mm512_maskz_cvttph_epi16');
  late final __mm512_maskz_cvttph_epi16 = __mm512_maskz_cvttph_epi16Ptr
      .asFunction<__m512i Function(int, __m512h)>();

  __m512i _mm512_cvtt_roundph_epi16(
    __m512h arg0,
    int arg1,
  ) {
    return __mm512_cvtt_roundph_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm512_cvtt_roundph_epi16Ptr =
      _lookup<ffi.NativeFunction<__m512i Function(__m512h, ffi.Int32)>>(
          '_mm512_cvtt_roundph_epi16');
  late final __mm512_cvtt_roundph_epi16 = __mm512_cvtt_roundph_epi16Ptr
      .asFunction<__m512i Function(__m512h, int)>();

  __m512i _mm512_mask_cvtt_roundph_epi16(
    __m512i arg0,
    int arg1,
    __m512h arg2,
    int arg3,
  ) {
    return __mm512_mask_cvtt_roundph_epi16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_cvtt_roundph_epi16Ptr = _lookup<
      ffi.NativeFunction<
          __m512i Function(__m512i, __mmask32, __m512h,
              ffi.Int32)>>('_mm512_mask_cvtt_roundph_epi16');
  late final __mm512_mask_cvtt_roundph_epi16 =
      __mm512_mask_cvtt_roundph_epi16Ptr
          .asFunction<__m512i Function(__m512i, int, __m512h, int)>();

  __m512i _mm512_maskz_cvtt_roundph_epi16(
    int arg0,
    __m512h arg1,
    int arg2,
  ) {
    return __mm512_maskz_cvtt_roundph_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_cvtt_roundph_epi16Ptr = _lookup<
          ffi.NativeFunction<__m512i Function(__mmask32, __m512h, ffi.Int32)>>(
      '_mm512_maskz_cvtt_roundph_epi16');
  late final __mm512_maskz_cvtt_roundph_epi16 =
      __mm512_maskz_cvtt_roundph_epi16Ptr
          .asFunction<__m512i Function(int, __m512h, int)>();

  int _mm_cvttsh_i32(
    __m128h arg0,
  ) {
    return __mm_cvttsh_i32(
      arg0,
    );
  }

  late final __mm_cvttsh_i32Ptr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(__m128h)>>(
          '_mm_cvttsh_i32');
  late final __mm_cvttsh_i32 =
      __mm_cvttsh_i32Ptr.asFunction<int Function(__m128h)>();

  int _mm_cvttsh_i64(
    __m128h arg0,
  ) {
    return __mm_cvttsh_i64(
      arg0,
    );
  }

  late final __mm_cvttsh_i64Ptr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(__m128h)>>(
          '_mm_cvttsh_i64');
  late final __mm_cvttsh_i64 =
      __mm_cvttsh_i64Ptr.asFunction<int Function(__m128h)>();

  int _mm_cvtt_roundsh_i32(
    __m128h arg0,
    int arg1,
  ) {
    return __mm_cvtt_roundsh_i32(
      arg0,
      arg1,
    );
  }

  late final __mm_cvtt_roundsh_i32Ptr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(__m128h, ffi.Int32)>>(
          '_mm_cvtt_roundsh_i32');
  late final __mm_cvtt_roundsh_i32 =
      __mm_cvtt_roundsh_i32Ptr.asFunction<int Function(__m128h, int)>();

  int _mm_cvtt_roundsh_i64(
    __m128h arg0,
    int arg1,
  ) {
    return __mm_cvtt_roundsh_i64(
      arg0,
      arg1,
    );
  }

  late final __mm_cvtt_roundsh_i64Ptr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(__m128h, ffi.Int32)>>(
          '_mm_cvtt_roundsh_i64');
  late final __mm_cvtt_roundsh_i64 =
      __mm_cvtt_roundsh_i64Ptr.asFunction<int Function(__m128h, int)>();

  int _mm_cvttsh_u32(
    __m128h arg0,
  ) {
    return __mm_cvttsh_u32(
      arg0,
    );
  }

  late final __mm_cvttsh_u32Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint32 Function(__m128h)>>(
          '_mm_cvttsh_u32');
  late final __mm_cvttsh_u32 =
      __mm_cvttsh_u32Ptr.asFunction<int Function(__m128h)>();

  int _mm_cvttsh_u64(
    __m128h arg0,
  ) {
    return __mm_cvttsh_u64(
      arg0,
    );
  }

  late final __mm_cvttsh_u64Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function(__m128h)>>(
          '_mm_cvttsh_u64');
  late final __mm_cvttsh_u64 =
      __mm_cvttsh_u64Ptr.asFunction<int Function(__m128h)>();

  int _mm_cvtt_roundsh_u32(
    __m128h arg0,
    int arg1,
  ) {
    return __mm_cvtt_roundsh_u32(
      arg0,
      arg1,
    );
  }

  late final __mm_cvtt_roundsh_u32Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint32 Function(__m128h, ffi.Int32)>>(
          '_mm_cvtt_roundsh_u32');
  late final __mm_cvtt_roundsh_u32 =
      __mm_cvtt_roundsh_u32Ptr.asFunction<int Function(__m128h, int)>();

  int _mm_cvtt_roundsh_u64(
    __m128h arg0,
    int arg1,
  ) {
    return __mm_cvtt_roundsh_u64(
      arg0,
      arg1,
    );
  }

  late final __mm_cvtt_roundsh_u64Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function(__m128h, ffi.Int32)>>(
          '_mm_cvtt_roundsh_u64');
  late final __mm_cvtt_roundsh_u64 =
      __mm_cvtt_roundsh_u64Ptr.asFunction<int Function(__m128h, int)>();

  __m128h _mm_cvtepu32_ph(
    __m128i arg0,
  ) {
    return __mm_cvtepu32_ph(
      arg0,
    );
  }

  late final __mm_cvtepu32_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128i)>>('_mm_cvtepu32_ph');
  late final __mm_cvtepu32_ph =
      __mm_cvtepu32_phPtr.asFunction<__m128h Function(__m128i)>();

  __m128h _mm_mask_cvtepu32_ph(
    __m128h arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cvtepu32_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtepu32_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128h, __mmask8, __m128i)>>(
          '_mm_mask_cvtepu32_ph');
  late final __mm_mask_cvtepu32_ph = __mm_mask_cvtepu32_phPtr
      .asFunction<__m128h Function(__m128h, int, __m128i)>();

  __m128h _mm_maskz_cvtepu32_ph(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_cvtepu32_ph(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvtepu32_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__mmask8, __m128i)>>(
          '_mm_maskz_cvtepu32_ph');
  late final __mm_maskz_cvtepu32_ph =
      __mm_maskz_cvtepu32_phPtr.asFunction<__m128h Function(int, __m128i)>();

  __m128h _mm256_cvtepu32_ph(
    __m256i arg0,
  ) {
    return __mm256_cvtepu32_ph(
      arg0,
    );
  }

  late final __mm256_cvtepu32_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m256i)>>(
          '_mm256_cvtepu32_ph');
  late final __mm256_cvtepu32_ph =
      __mm256_cvtepu32_phPtr.asFunction<__m128h Function(__m256i)>();

  __m128h _mm256_mask_cvtepu32_ph(
    __m128h arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cvtepu32_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtepu32_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128h, __mmask8, __m256i)>>(
          '_mm256_mask_cvtepu32_ph');
  late final __mm256_mask_cvtepu32_ph = __mm256_mask_cvtepu32_phPtr
      .asFunction<__m128h Function(__m128h, int, __m256i)>();

  __m128h _mm256_maskz_cvtepu32_ph(
    int arg0,
    __m256i arg1,
  ) {
    return __mm256_maskz_cvtepu32_ph(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvtepu32_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__mmask8, __m256i)>>(
          '_mm256_maskz_cvtepu32_ph');
  late final __mm256_maskz_cvtepu32_ph =
      __mm256_maskz_cvtepu32_phPtr.asFunction<__m128h Function(int, __m256i)>();

  __m256h _mm512_cvtepu32_ph(
    __m512i arg0,
  ) {
    return __mm512_cvtepu32_ph(
      arg0,
    );
  }

  late final __mm512_cvtepu32_phPtr =
      _lookup<ffi.NativeFunction<__m256h Function(__m512i)>>(
          '_mm512_cvtepu32_ph');
  late final __mm512_cvtepu32_ph =
      __mm512_cvtepu32_phPtr.asFunction<__m256h Function(__m512i)>();

  __m256h _mm512_mask_cvtepu32_ph(
    __m256h arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cvtepu32_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtepu32_phPtr = _lookup<
          ffi.NativeFunction<__m256h Function(__m256h, __mmask16, __m512i)>>(
      '_mm512_mask_cvtepu32_ph');
  late final __mm512_mask_cvtepu32_ph = __mm512_mask_cvtepu32_phPtr
      .asFunction<__m256h Function(__m256h, int, __m512i)>();

  __m256h _mm512_maskz_cvtepu32_ph(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_maskz_cvtepu32_ph(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvtepu32_phPtr =
      _lookup<ffi.NativeFunction<__m256h Function(__mmask16, __m512i)>>(
          '_mm512_maskz_cvtepu32_ph');
  late final __mm512_maskz_cvtepu32_ph =
      __mm512_maskz_cvtepu32_phPtr.asFunction<__m256h Function(int, __m512i)>();

  __m256h _mm512_cvt_roundepu32_ph(
    __m512i arg0,
    int arg1,
  ) {
    return __mm512_cvt_roundepu32_ph(
      arg0,
      arg1,
    );
  }

  late final __mm512_cvt_roundepu32_phPtr =
      _lookup<ffi.NativeFunction<__m256h Function(__m512i, ffi.Int32)>>(
          '_mm512_cvt_roundepu32_ph');
  late final __mm512_cvt_roundepu32_ph =
      __mm512_cvt_roundepu32_phPtr.asFunction<__m256h Function(__m512i, int)>();

  __m256h _mm512_mask_cvt_roundepu32_ph(
    __m256h arg0,
    int arg1,
    __m512i arg2,
    int arg3,
  ) {
    return __mm512_mask_cvt_roundepu32_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_cvt_roundepu32_phPtr = _lookup<
      ffi.NativeFunction<
          __m256h Function(__m256h, __mmask16, __m512i,
              ffi.Int32)>>('_mm512_mask_cvt_roundepu32_ph');
  late final __mm512_mask_cvt_roundepu32_ph = __mm512_mask_cvt_roundepu32_phPtr
      .asFunction<__m256h Function(__m256h, int, __m512i, int)>();

  __m256h _mm512_maskz_cvt_roundepu32_ph(
    int arg0,
    __m512i arg1,
    int arg2,
  ) {
    return __mm512_maskz_cvt_roundepu32_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_cvt_roundepu32_phPtr = _lookup<
          ffi.NativeFunction<__m256h Function(__mmask16, __m512i, ffi.Int32)>>(
      '_mm512_maskz_cvt_roundepu32_ph');
  late final __mm512_maskz_cvt_roundepu32_ph =
      __mm512_maskz_cvt_roundepu32_phPtr
          .asFunction<__m256h Function(int, __m512i, int)>();

  __m128h _mm_cvtepu64_ph(
    __m128i arg0,
  ) {
    return __mm_cvtepu64_ph(
      arg0,
    );
  }

  late final __mm_cvtepu64_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128i)>>('_mm_cvtepu64_ph');
  late final __mm_cvtepu64_ph =
      __mm_cvtepu64_phPtr.asFunction<__m128h Function(__m128i)>();

  __m128h _mm_mask_cvtepu64_ph(
    __m128h arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cvtepu64_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtepu64_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128h, __mmask8, __m128i)>>(
          '_mm_mask_cvtepu64_ph');
  late final __mm_mask_cvtepu64_ph = __mm_mask_cvtepu64_phPtr
      .asFunction<__m128h Function(__m128h, int, __m128i)>();

  __m128h _mm_maskz_cvtepu64_ph(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_cvtepu64_ph(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvtepu64_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__mmask8, __m128i)>>(
          '_mm_maskz_cvtepu64_ph');
  late final __mm_maskz_cvtepu64_ph =
      __mm_maskz_cvtepu64_phPtr.asFunction<__m128h Function(int, __m128i)>();

  __m128h _mm256_cvtepu64_ph(
    __m256i arg0,
  ) {
    return __mm256_cvtepu64_ph(
      arg0,
    );
  }

  late final __mm256_cvtepu64_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m256i)>>(
          '_mm256_cvtepu64_ph');
  late final __mm256_cvtepu64_ph =
      __mm256_cvtepu64_phPtr.asFunction<__m128h Function(__m256i)>();

  __m128h _mm256_mask_cvtepu64_ph(
    __m128h arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cvtepu64_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtepu64_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128h, __mmask8, __m256i)>>(
          '_mm256_mask_cvtepu64_ph');
  late final __mm256_mask_cvtepu64_ph = __mm256_mask_cvtepu64_phPtr
      .asFunction<__m128h Function(__m128h, int, __m256i)>();

  __m128h _mm256_maskz_cvtepu64_ph(
    int arg0,
    __m256i arg1,
  ) {
    return __mm256_maskz_cvtepu64_ph(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvtepu64_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__mmask8, __m256i)>>(
          '_mm256_maskz_cvtepu64_ph');
  late final __mm256_maskz_cvtepu64_ph =
      __mm256_maskz_cvtepu64_phPtr.asFunction<__m128h Function(int, __m256i)>();

  __m128h _mm512_cvtepu64_ph(
    __m512i arg0,
  ) {
    return __mm512_cvtepu64_ph(
      arg0,
    );
  }

  late final __mm512_cvtepu64_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m512i)>>(
          '_mm512_cvtepu64_ph');
  late final __mm512_cvtepu64_ph =
      __mm512_cvtepu64_phPtr.asFunction<__m128h Function(__m512i)>();

  __m128h _mm512_mask_cvtepu64_ph(
    __m128h arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cvtepu64_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtepu64_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128h, __mmask8, __m512i)>>(
          '_mm512_mask_cvtepu64_ph');
  late final __mm512_mask_cvtepu64_ph = __mm512_mask_cvtepu64_phPtr
      .asFunction<__m128h Function(__m128h, int, __m512i)>();

  __m128h _mm512_maskz_cvtepu64_ph(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_maskz_cvtepu64_ph(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvtepu64_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__mmask8, __m512i)>>(
          '_mm512_maskz_cvtepu64_ph');
  late final __mm512_maskz_cvtepu64_ph =
      __mm512_maskz_cvtepu64_phPtr.asFunction<__m128h Function(int, __m512i)>();

  __m128h _mm512_cvt_roundepu64_ph(
    __m512i arg0,
    int arg1,
  ) {
    return __mm512_cvt_roundepu64_ph(
      arg0,
      arg1,
    );
  }

  late final __mm512_cvt_roundepu64_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m512i, ffi.Int32)>>(
          '_mm512_cvt_roundepu64_ph');
  late final __mm512_cvt_roundepu64_ph =
      __mm512_cvt_roundepu64_phPtr.asFunction<__m128h Function(__m512i, int)>();

  __m128h _mm512_mask_cvt_roundepu64_ph(
    __m128h arg0,
    int arg1,
    __m512i arg2,
    int arg3,
  ) {
    return __mm512_mask_cvt_roundepu64_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_cvt_roundepu64_phPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(__m128h, __mmask8, __m512i,
              ffi.Int32)>>('_mm512_mask_cvt_roundepu64_ph');
  late final __mm512_mask_cvt_roundepu64_ph = __mm512_mask_cvt_roundepu64_phPtr
      .asFunction<__m128h Function(__m128h, int, __m512i, int)>();

  __m128h _mm512_maskz_cvt_roundepu64_ph(
    int arg0,
    __m512i arg1,
    int arg2,
  ) {
    return __mm512_maskz_cvt_roundepu64_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_cvt_roundepu64_phPtr = _lookup<
          ffi.NativeFunction<__m128h Function(__mmask8, __m512i, ffi.Int32)>>(
      '_mm512_maskz_cvt_roundepu64_ph');
  late final __mm512_maskz_cvt_roundepu64_ph =
      __mm512_maskz_cvt_roundepu64_phPtr
          .asFunction<__m128h Function(int, __m512i, int)>();

  __m128h _mm_cvtu32_sh(
    __m128h arg0,
    int arg1,
  ) {
    return __mm_cvtu32_sh(
      arg0,
      arg1,
    );
  }

  late final __mm_cvtu32_shPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128h, ffi.Uint32)>>(
          '_mm_cvtu32_sh');
  late final __mm_cvtu32_sh =
      __mm_cvtu32_shPtr.asFunction<__m128h Function(__m128h, int)>();

  __m128h _mm_cvtu64_sh(
    __m128h arg0,
    int arg1,
  ) {
    return __mm_cvtu64_sh(
      arg0,
      arg1,
    );
  }

  late final __mm_cvtu64_shPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128h, ffi.Uint64)>>(
          '_mm_cvtu64_sh');
  late final __mm_cvtu64_sh =
      __mm_cvtu64_shPtr.asFunction<__m128h Function(__m128h, int)>();

  __m128h _mm_cvt_roundu32_sh(
    __m128h arg0,
    int arg1,
    int arg2,
  ) {
    return __mm_cvt_roundu32_sh(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_cvt_roundu32_shPtr = _lookup<
          ffi.NativeFunction<__m128h Function(__m128h, ffi.Uint32, ffi.Int32)>>(
      '_mm_cvt_roundu32_sh');
  late final __mm_cvt_roundu32_sh =
      __mm_cvt_roundu32_shPtr.asFunction<__m128h Function(__m128h, int, int)>();

  __m128h _mm_cvt_roundu64_sh(
    __m128h arg0,
    int arg1,
    int arg2,
  ) {
    return __mm_cvt_roundu64_sh(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_cvt_roundu64_shPtr = _lookup<
          ffi.NativeFunction<__m128h Function(__m128h, ffi.Uint64, ffi.Int32)>>(
      '_mm_cvt_roundu64_sh');
  late final __mm_cvt_roundu64_sh =
      __mm_cvt_roundu64_shPtr.asFunction<__m128h Function(__m128h, int, int)>();

  __m128h _mm_cvtepu16_ph(
    __m128i arg0,
  ) {
    return __mm_cvtepu16_ph(
      arg0,
    );
  }

  late final __mm_cvtepu16_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128i)>>('_mm_cvtepu16_ph');
  late final __mm_cvtepu16_ph =
      __mm_cvtepu16_phPtr.asFunction<__m128h Function(__m128i)>();

  __m128h _mm_mask_cvtepu16_ph(
    __m128h arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cvtepu16_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtepu16_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128h, __mmask8, __m128i)>>(
          '_mm_mask_cvtepu16_ph');
  late final __mm_mask_cvtepu16_ph = __mm_mask_cvtepu16_phPtr
      .asFunction<__m128h Function(__m128h, int, __m128i)>();

  __m128h _mm_maskz_cvtepu16_ph(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_cvtepu16_ph(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvtepu16_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__mmask8, __m128i)>>(
          '_mm_maskz_cvtepu16_ph');
  late final __mm_maskz_cvtepu16_ph =
      __mm_maskz_cvtepu16_phPtr.asFunction<__m128h Function(int, __m128i)>();

  __m256h _mm256_cvtepu16_ph(
    __m256i arg0,
  ) {
    return __mm256_cvtepu16_ph(
      arg0,
    );
  }

  late final __mm256_cvtepu16_phPtr =
      _lookup<ffi.NativeFunction<__m256h Function(__m256i)>>(
          '_mm256_cvtepu16_ph');
  late final __mm256_cvtepu16_ph =
      __mm256_cvtepu16_phPtr.asFunction<__m256h Function(__m256i)>();

  __m256h _mm256_mask_cvtepu16_ph(
    __m256h arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cvtepu16_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtepu16_phPtr = _lookup<
          ffi.NativeFunction<__m256h Function(__m256h, __mmask16, __m256i)>>(
      '_mm256_mask_cvtepu16_ph');
  late final __mm256_mask_cvtepu16_ph = __mm256_mask_cvtepu16_phPtr
      .asFunction<__m256h Function(__m256h, int, __m256i)>();

  __m256h _mm256_maskz_cvtepu16_ph(
    int arg0,
    __m256i arg1,
  ) {
    return __mm256_maskz_cvtepu16_ph(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvtepu16_phPtr =
      _lookup<ffi.NativeFunction<__m256h Function(__mmask16, __m256i)>>(
          '_mm256_maskz_cvtepu16_ph');
  late final __mm256_maskz_cvtepu16_ph =
      __mm256_maskz_cvtepu16_phPtr.asFunction<__m256h Function(int, __m256i)>();

  __m512h _mm512_cvtepu16_ph(
    __m512i arg0,
  ) {
    return __mm512_cvtepu16_ph(
      arg0,
    );
  }

  late final __mm512_cvtepu16_phPtr =
      _lookup<ffi.NativeFunction<__m512h Function(__m512i)>>(
          '_mm512_cvtepu16_ph');
  late final __mm512_cvtepu16_ph =
      __mm512_cvtepu16_phPtr.asFunction<__m512h Function(__m512i)>();

  __m512h _mm512_mask_cvtepu16_ph(
    __m512h arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cvtepu16_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtepu16_phPtr = _lookup<
          ffi.NativeFunction<__m512h Function(__m512h, __mmask32, __m512i)>>(
      '_mm512_mask_cvtepu16_ph');
  late final __mm512_mask_cvtepu16_ph = __mm512_mask_cvtepu16_phPtr
      .asFunction<__m512h Function(__m512h, int, __m512i)>();

  __m512h _mm512_maskz_cvtepu16_ph(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_maskz_cvtepu16_ph(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvtepu16_phPtr =
      _lookup<ffi.NativeFunction<__m512h Function(__mmask32, __m512i)>>(
          '_mm512_maskz_cvtepu16_ph');
  late final __mm512_maskz_cvtepu16_ph =
      __mm512_maskz_cvtepu16_phPtr.asFunction<__m512h Function(int, __m512i)>();

  __m512h _mm512_cvt_roundepu16_ph(
    __m512i arg0,
    int arg1,
  ) {
    return __mm512_cvt_roundepu16_ph(
      arg0,
      arg1,
    );
  }

  late final __mm512_cvt_roundepu16_phPtr =
      _lookup<ffi.NativeFunction<__m512h Function(__m512i, ffi.Int32)>>(
          '_mm512_cvt_roundepu16_ph');
  late final __mm512_cvt_roundepu16_ph =
      __mm512_cvt_roundepu16_phPtr.asFunction<__m512h Function(__m512i, int)>();

  __m512h _mm512_mask_cvt_roundepu16_ph(
    __m512h arg0,
    int arg1,
    __m512i arg2,
    int arg3,
  ) {
    return __mm512_mask_cvt_roundepu16_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_cvt_roundepu16_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(__m512h, __mmask32, __m512i,
              ffi.Int32)>>('_mm512_mask_cvt_roundepu16_ph');
  late final __mm512_mask_cvt_roundepu16_ph = __mm512_mask_cvt_roundepu16_phPtr
      .asFunction<__m512h Function(__m512h, int, __m512i, int)>();

  __m512h _mm512_maskz_cvt_roundepu16_ph(
    int arg0,
    __m512i arg1,
    int arg2,
  ) {
    return __mm512_maskz_cvt_roundepu16_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_cvt_roundepu16_phPtr = _lookup<
          ffi.NativeFunction<__m512h Function(__mmask32, __m512i, ffi.Int32)>>(
      '_mm512_maskz_cvt_roundepu16_ph');
  late final __mm512_maskz_cvt_roundepu16_ph =
      __mm512_maskz_cvt_roundepu16_phPtr
          .asFunction<__m512h Function(int, __m512i, int)>();

  __m128h _mm_cvtepi16_ph(
    __m128i arg0,
  ) {
    return __mm_cvtepi16_ph(
      arg0,
    );
  }

  late final __mm_cvtepi16_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128i)>>('_mm_cvtepi16_ph');
  late final __mm_cvtepi16_ph =
      __mm_cvtepi16_phPtr.asFunction<__m128h Function(__m128i)>();

  __m128h _mm_mask_cvtepi16_ph(
    __m128h arg0,
    int arg1,
    __m128i arg2,
  ) {
    return __mm_mask_cvtepi16_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_cvtepi16_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128h, __mmask8, __m128i)>>(
          '_mm_mask_cvtepi16_ph');
  late final __mm_mask_cvtepi16_ph = __mm_mask_cvtepi16_phPtr
      .asFunction<__m128h Function(__m128h, int, __m128i)>();

  __m128h _mm_maskz_cvtepi16_ph(
    int arg0,
    __m128i arg1,
  ) {
    return __mm_maskz_cvtepi16_ph(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_cvtepi16_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__mmask8, __m128i)>>(
          '_mm_maskz_cvtepi16_ph');
  late final __mm_maskz_cvtepi16_ph =
      __mm_maskz_cvtepi16_phPtr.asFunction<__m128h Function(int, __m128i)>();

  __m256h _mm256_cvtepi16_ph(
    __m256i arg0,
  ) {
    return __mm256_cvtepi16_ph(
      arg0,
    );
  }

  late final __mm256_cvtepi16_phPtr =
      _lookup<ffi.NativeFunction<__m256h Function(__m256i)>>(
          '_mm256_cvtepi16_ph');
  late final __mm256_cvtepi16_ph =
      __mm256_cvtepi16_phPtr.asFunction<__m256h Function(__m256i)>();

  __m256h _mm256_mask_cvtepi16_ph(
    __m256h arg0,
    int arg1,
    __m256i arg2,
  ) {
    return __mm256_mask_cvtepi16_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_cvtepi16_phPtr = _lookup<
          ffi.NativeFunction<__m256h Function(__m256h, __mmask16, __m256i)>>(
      '_mm256_mask_cvtepi16_ph');
  late final __mm256_mask_cvtepi16_ph = __mm256_mask_cvtepi16_phPtr
      .asFunction<__m256h Function(__m256h, int, __m256i)>();

  __m256h _mm256_maskz_cvtepi16_ph(
    int arg0,
    __m256i arg1,
  ) {
    return __mm256_maskz_cvtepi16_ph(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_cvtepi16_phPtr =
      _lookup<ffi.NativeFunction<__m256h Function(__mmask16, __m256i)>>(
          '_mm256_maskz_cvtepi16_ph');
  late final __mm256_maskz_cvtepi16_ph =
      __mm256_maskz_cvtepi16_phPtr.asFunction<__m256h Function(int, __m256i)>();

  __m512h _mm512_cvtepi16_ph(
    __m512i arg0,
  ) {
    return __mm512_cvtepi16_ph(
      arg0,
    );
  }

  late final __mm512_cvtepi16_phPtr =
      _lookup<ffi.NativeFunction<__m512h Function(__m512i)>>(
          '_mm512_cvtepi16_ph');
  late final __mm512_cvtepi16_ph =
      __mm512_cvtepi16_phPtr.asFunction<__m512h Function(__m512i)>();

  __m512h _mm512_mask_cvtepi16_ph(
    __m512h arg0,
    int arg1,
    __m512i arg2,
  ) {
    return __mm512_mask_cvtepi16_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_cvtepi16_phPtr = _lookup<
          ffi.NativeFunction<__m512h Function(__m512h, __mmask32, __m512i)>>(
      '_mm512_mask_cvtepi16_ph');
  late final __mm512_mask_cvtepi16_ph = __mm512_mask_cvtepi16_phPtr
      .asFunction<__m512h Function(__m512h, int, __m512i)>();

  __m512h _mm512_maskz_cvtepi16_ph(
    int arg0,
    __m512i arg1,
  ) {
    return __mm512_maskz_cvtepi16_ph(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_cvtepi16_phPtr =
      _lookup<ffi.NativeFunction<__m512h Function(__mmask32, __m512i)>>(
          '_mm512_maskz_cvtepi16_ph');
  late final __mm512_maskz_cvtepi16_ph =
      __mm512_maskz_cvtepi16_phPtr.asFunction<__m512h Function(int, __m512i)>();

  __m512h _mm512_cvt_roundepi16_ph(
    __m512i arg0,
    int arg1,
  ) {
    return __mm512_cvt_roundepi16_ph(
      arg0,
      arg1,
    );
  }

  late final __mm512_cvt_roundepi16_phPtr =
      _lookup<ffi.NativeFunction<__m512h Function(__m512i, ffi.Int32)>>(
          '_mm512_cvt_roundepi16_ph');
  late final __mm512_cvt_roundepi16_ph =
      __mm512_cvt_roundepi16_phPtr.asFunction<__m512h Function(__m512i, int)>();

  __m512h _mm512_mask_cvt_roundepi16_ph(
    __m512h arg0,
    int arg1,
    __m512i arg2,
    int arg3,
  ) {
    return __mm512_mask_cvt_roundepi16_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_cvt_roundepi16_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(__m512h, __mmask32, __m512i,
              ffi.Int32)>>('_mm512_mask_cvt_roundepi16_ph');
  late final __mm512_mask_cvt_roundepi16_ph = __mm512_mask_cvt_roundepi16_phPtr
      .asFunction<__m512h Function(__m512h, int, __m512i, int)>();

  __m512h _mm512_maskz_cvt_roundepi16_ph(
    int arg0,
    __m512i arg1,
    int arg2,
  ) {
    return __mm512_maskz_cvt_roundepi16_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_cvt_roundepi16_phPtr = _lookup<
          ffi.NativeFunction<__m512h Function(__mmask32, __m512i, ffi.Int32)>>(
      '_mm512_maskz_cvt_roundepi16_ph');
  late final __mm512_maskz_cvt_roundepi16_ph =
      __mm512_maskz_cvt_roundepi16_phPtr
          .asFunction<__m512h Function(int, __m512i, int)>();

  __m128h _mm_div_ph(
    __m128h arg0,
    __m128h arg1,
  ) {
    return __mm_div_ph(
      arg0,
      arg1,
    );
  }

  late final __mm_div_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128h, __m128h)>>(
          '_mm_div_ph');
  late final __mm_div_ph =
      __mm_div_phPtr.asFunction<__m128h Function(__m128h, __m128h)>();

  __m128h _mm_mask_div_ph(
    __m128h arg0,
    int arg1,
    __m128h arg2,
    __m128h arg3,
  ) {
    return __mm_mask_div_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_div_phPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __m128h, __mmask8, __m128h, __m128h)>>('_mm_mask_div_ph');
  late final __mm_mask_div_ph = __mm_mask_div_phPtr
      .asFunction<__m128h Function(__m128h, int, __m128h, __m128h)>();

  __m128h _mm_maskz_div_ph(
    int arg0,
    __m128h arg1,
    __m128h arg2,
  ) {
    return __mm_maskz_div_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_div_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__mmask8, __m128h, __m128h)>>(
          '_mm_maskz_div_ph');
  late final __mm_maskz_div_ph = __mm_maskz_div_phPtr
      .asFunction<__m128h Function(int, __m128h, __m128h)>();

  __m256h _mm256_div_ph(
    __m256h arg0,
    __m256h arg1,
  ) {
    return __mm256_div_ph(
      arg0,
      arg1,
    );
  }

  late final __mm256_div_phPtr =
      _lookup<ffi.NativeFunction<__m256h Function(__m256h, __m256h)>>(
          '_mm256_div_ph');
  late final __mm256_div_ph =
      __mm256_div_phPtr.asFunction<__m256h Function(__m256h, __m256h)>();

  __m256h _mm256_mask_div_ph(
    __m256h arg0,
    int arg1,
    __m256h arg2,
    __m256h arg3,
  ) {
    return __mm256_mask_div_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_div_phPtr = _lookup<
      ffi.NativeFunction<
          __m256h Function(
              __m256h, __mmask16, __m256h, __m256h)>>('_mm256_mask_div_ph');
  late final __mm256_mask_div_ph = __mm256_mask_div_phPtr
      .asFunction<__m256h Function(__m256h, int, __m256h, __m256h)>();

  __m256h _mm256_maskz_div_ph(
    int arg0,
    __m256h arg1,
    __m256h arg2,
  ) {
    return __mm256_maskz_div_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_div_phPtr = _lookup<
          ffi.NativeFunction<__m256h Function(__mmask16, __m256h, __m256h)>>(
      '_mm256_maskz_div_ph');
  late final __mm256_maskz_div_ph = __mm256_maskz_div_phPtr
      .asFunction<__m256h Function(int, __m256h, __m256h)>();

  __m512h _mm512_div_ph(
    __m512h arg0,
    __m512h arg1,
  ) {
    return __mm512_div_ph(
      arg0,
      arg1,
    );
  }

  late final __mm512_div_phPtr =
      _lookup<ffi.NativeFunction<__m512h Function(__m512h, __m512h)>>(
          '_mm512_div_ph');
  late final __mm512_div_ph =
      __mm512_div_phPtr.asFunction<__m512h Function(__m512h, __m512h)>();

  __m512h _mm512_mask_div_ph(
    __m512h arg0,
    int arg1,
    __m512h arg2,
    __m512h arg3,
  ) {
    return __mm512_mask_div_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_div_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(
              __m512h, __mmask32, __m512h, __m512h)>>('_mm512_mask_div_ph');
  late final __mm512_mask_div_ph = __mm512_mask_div_phPtr
      .asFunction<__m512h Function(__m512h, int, __m512h, __m512h)>();

  __m512h _mm512_maskz_div_ph(
    int arg0,
    __m512h arg1,
    __m512h arg2,
  ) {
    return __mm512_maskz_div_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_div_phPtr = _lookup<
          ffi.NativeFunction<__m512h Function(__mmask32, __m512h, __m512h)>>(
      '_mm512_maskz_div_ph');
  late final __mm512_maskz_div_ph = __mm512_maskz_div_phPtr
      .asFunction<__m512h Function(int, __m512h, __m512h)>();

  __m512h _mm512_div_round_ph(
    __m512h arg0,
    __m512h arg1,
    int arg2,
  ) {
    return __mm512_div_round_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_div_round_phPtr = _lookup<
          ffi.NativeFunction<__m512h Function(__m512h, __m512h, ffi.Int32)>>(
      '_mm512_div_round_ph');
  late final __mm512_div_round_ph = __mm512_div_round_phPtr
      .asFunction<__m512h Function(__m512h, __m512h, int)>();

  __m512h _mm512_mask_div_round_ph(
    __m512h arg0,
    int arg1,
    __m512h arg2,
    __m512h arg3,
    int arg4,
  ) {
    return __mm512_mask_div_round_ph(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_div_round_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(__m512h, __mmask32, __m512h, __m512h,
              ffi.Int32)>>('_mm512_mask_div_round_ph');
  late final __mm512_mask_div_round_ph = __mm512_mask_div_round_phPtr
      .asFunction<__m512h Function(__m512h, int, __m512h, __m512h, int)>();

  __m512h _mm512_maskz_div_round_ph(
    int arg0,
    __m512h arg1,
    __m512h arg2,
    int arg3,
  ) {
    return __mm512_maskz_div_round_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_div_round_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(__mmask32, __m512h, __m512h,
              ffi.Int32)>>('_mm512_maskz_div_round_ph');
  late final __mm512_maskz_div_round_ph = __mm512_maskz_div_round_phPtr
      .asFunction<__m512h Function(int, __m512h, __m512h, int)>();

  __m128h _mm_div_sh(
    __m128h arg0,
    __m128h arg1,
  ) {
    return __mm_div_sh(
      arg0,
      arg1,
    );
  }

  late final __mm_div_shPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128h, __m128h)>>(
          '_mm_div_sh');
  late final __mm_div_sh =
      __mm_div_shPtr.asFunction<__m128h Function(__m128h, __m128h)>();

  __m128h _mm_mask_div_sh(
    __m128h arg0,
    int arg1,
    __m128h arg2,
    __m128h arg3,
  ) {
    return __mm_mask_div_sh(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_div_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __m128h, __mmask8, __m128h, __m128h)>>('_mm_mask_div_sh');
  late final __mm_mask_div_sh = __mm_mask_div_shPtr
      .asFunction<__m128h Function(__m128h, int, __m128h, __m128h)>();

  __m128h _mm_maskz_div_sh(
    int arg0,
    __m128h arg1,
    __m128h arg2,
  ) {
    return __mm_maskz_div_sh(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_div_shPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__mmask8, __m128h, __m128h)>>(
          '_mm_maskz_div_sh');
  late final __mm_maskz_div_sh = __mm_maskz_div_shPtr
      .asFunction<__m128h Function(int, __m128h, __m128h)>();

  __m128h _mm_div_round_sh(
    __m128h arg0,
    __m128h arg1,
    int arg2,
  ) {
    return __mm_div_round_sh(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_div_round_shPtr = _lookup<
          ffi.NativeFunction<__m128h Function(__m128h, __m128h, ffi.Int32)>>(
      '_mm_div_round_sh');
  late final __mm_div_round_sh = __mm_div_round_shPtr
      .asFunction<__m128h Function(__m128h, __m128h, int)>();

  __m128h _mm_mask_div_round_sh(
    __m128h arg0,
    int arg1,
    __m128h arg2,
    __m128h arg3,
    int arg4,
  ) {
    return __mm_mask_div_round_sh(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_div_round_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(__m128h, __mmask8, __m128h, __m128h,
              ffi.Int32)>>('_mm_mask_div_round_sh');
  late final __mm_mask_div_round_sh = __mm_mask_div_round_shPtr
      .asFunction<__m128h Function(__m128h, int, __m128h, __m128h, int)>();

  __m128h _mm_maskz_div_round_sh(
    int arg0,
    __m128h arg1,
    __m128h arg2,
    int arg3,
  ) {
    return __mm_maskz_div_round_sh(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_div_round_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(__mmask8, __m128h, __m128h,
              ffi.Int32)>>('_mm_maskz_div_round_sh');
  late final __mm_maskz_div_round_sh = __mm_maskz_div_round_shPtr
      .asFunction<__m128h Function(int, __m128h, __m128h, int)>();

  __m128h _mm_fmaddsub_ph(
    __m128h arg0,
    __m128h arg1,
    __m128h arg2,
  ) {
    return __mm_fmaddsub_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_fmaddsub_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128h, __m128h, __m128h)>>(
          '_mm_fmaddsub_ph');
  late final __mm_fmaddsub_ph = __mm_fmaddsub_phPtr
      .asFunction<__m128h Function(__m128h, __m128h, __m128h)>();

  __m128h _mm_mask_fmaddsub_ph(
    __m128h arg0,
    int arg1,
    __m128h arg2,
    __m128h arg3,
  ) {
    return __mm_mask_fmaddsub_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_fmaddsub_phPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __m128h, __mmask8, __m128h, __m128h)>>('_mm_mask_fmaddsub_ph');
  late final __mm_mask_fmaddsub_ph = __mm_mask_fmaddsub_phPtr
      .asFunction<__m128h Function(__m128h, int, __m128h, __m128h)>();

  __m128h _mm_mask3_fmaddsub_ph(
    __m128h arg0,
    __m128h arg1,
    __m128h arg2,
    int arg3,
  ) {
    return __mm_mask3_fmaddsub_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask3_fmaddsub_phPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __m128h, __m128h, __m128h, __mmask8)>>('_mm_mask3_fmaddsub_ph');
  late final __mm_mask3_fmaddsub_ph = __mm_mask3_fmaddsub_phPtr
      .asFunction<__m128h Function(__m128h, __m128h, __m128h, int)>();

  __m128h _mm_maskz_fmaddsub_ph(
    int arg0,
    __m128h arg1,
    __m128h arg2,
    __m128h arg3,
  ) {
    return __mm_maskz_fmaddsub_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_fmaddsub_phPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __mmask8, __m128h, __m128h, __m128h)>>('_mm_maskz_fmaddsub_ph');
  late final __mm_maskz_fmaddsub_ph = __mm_maskz_fmaddsub_phPtr
      .asFunction<__m128h Function(int, __m128h, __m128h, __m128h)>();

  __m256h _mm256_fmaddsub_ph(
    __m256h arg0,
    __m256h arg1,
    __m256h arg2,
  ) {
    return __mm256_fmaddsub_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_fmaddsub_phPtr =
      _lookup<ffi.NativeFunction<__m256h Function(__m256h, __m256h, __m256h)>>(
          '_mm256_fmaddsub_ph');
  late final __mm256_fmaddsub_ph = __mm256_fmaddsub_phPtr
      .asFunction<__m256h Function(__m256h, __m256h, __m256h)>();

  __m256h _mm256_mask_fmaddsub_ph(
    __m256h arg0,
    int arg1,
    __m256h arg2,
    __m256h arg3,
  ) {
    return __mm256_mask_fmaddsub_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_fmaddsub_phPtr = _lookup<
      ffi.NativeFunction<
          __m256h Function(__m256h, __mmask16, __m256h,
              __m256h)>>('_mm256_mask_fmaddsub_ph');
  late final __mm256_mask_fmaddsub_ph = __mm256_mask_fmaddsub_phPtr
      .asFunction<__m256h Function(__m256h, int, __m256h, __m256h)>();

  __m256h _mm256_mask3_fmaddsub_ph(
    __m256h arg0,
    __m256h arg1,
    __m256h arg2,
    int arg3,
  ) {
    return __mm256_mask3_fmaddsub_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask3_fmaddsub_phPtr = _lookup<
      ffi.NativeFunction<
          __m256h Function(__m256h, __m256h, __m256h,
              __mmask16)>>('_mm256_mask3_fmaddsub_ph');
  late final __mm256_mask3_fmaddsub_ph = __mm256_mask3_fmaddsub_phPtr
      .asFunction<__m256h Function(__m256h, __m256h, __m256h, int)>();

  __m256h _mm256_maskz_fmaddsub_ph(
    int arg0,
    __m256h arg1,
    __m256h arg2,
    __m256h arg3,
  ) {
    return __mm256_maskz_fmaddsub_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_maskz_fmaddsub_phPtr = _lookup<
      ffi.NativeFunction<
          __m256h Function(__mmask16, __m256h, __m256h,
              __m256h)>>('_mm256_maskz_fmaddsub_ph');
  late final __mm256_maskz_fmaddsub_ph = __mm256_maskz_fmaddsub_phPtr
      .asFunction<__m256h Function(int, __m256h, __m256h, __m256h)>();

  __m512h _mm512_fmaddsub_ph(
    __m512h arg0,
    __m512h arg1,
    __m512h arg2,
  ) {
    return __mm512_fmaddsub_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_fmaddsub_phPtr =
      _lookup<ffi.NativeFunction<__m512h Function(__m512h, __m512h, __m512h)>>(
          '_mm512_fmaddsub_ph');
  late final __mm512_fmaddsub_ph = __mm512_fmaddsub_phPtr
      .asFunction<__m512h Function(__m512h, __m512h, __m512h)>();

  __m512h _mm512_mask_fmaddsub_ph(
    __m512h arg0,
    int arg1,
    __m512h arg2,
    __m512h arg3,
  ) {
    return __mm512_mask_fmaddsub_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_fmaddsub_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(__m512h, __mmask32, __m512h,
              __m512h)>>('_mm512_mask_fmaddsub_ph');
  late final __mm512_mask_fmaddsub_ph = __mm512_mask_fmaddsub_phPtr
      .asFunction<__m512h Function(__m512h, int, __m512h, __m512h)>();

  __m512h _mm512_mask3_fmaddsub_ph(
    __m512h arg0,
    __m512h arg1,
    __m512h arg2,
    int arg3,
  ) {
    return __mm512_mask3_fmaddsub_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask3_fmaddsub_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(__m512h, __m512h, __m512h,
              __mmask32)>>('_mm512_mask3_fmaddsub_ph');
  late final __mm512_mask3_fmaddsub_ph = __mm512_mask3_fmaddsub_phPtr
      .asFunction<__m512h Function(__m512h, __m512h, __m512h, int)>();

  __m512h _mm512_maskz_fmaddsub_ph(
    int arg0,
    __m512h arg1,
    __m512h arg2,
    __m512h arg3,
  ) {
    return __mm512_maskz_fmaddsub_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_fmaddsub_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(__mmask32, __m512h, __m512h,
              __m512h)>>('_mm512_maskz_fmaddsub_ph');
  late final __mm512_maskz_fmaddsub_ph = __mm512_maskz_fmaddsub_phPtr
      .asFunction<__m512h Function(int, __m512h, __m512h, __m512h)>();

  __m512h _mm512_fmaddsub_round_ph(
    __m512h arg0,
    __m512h arg1,
    __m512h arg2,
    int arg3,
  ) {
    return __mm512_fmaddsub_round_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_fmaddsub_round_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(__m512h, __m512h, __m512h,
              ffi.Int32)>>('_mm512_fmaddsub_round_ph');
  late final __mm512_fmaddsub_round_ph = __mm512_fmaddsub_round_phPtr
      .asFunction<__m512h Function(__m512h, __m512h, __m512h, int)>();

  __m512h _mm512_mask_fmaddsub_round_ph(
    __m512h arg0,
    int arg1,
    __m512h arg2,
    __m512h arg3,
    int arg4,
  ) {
    return __mm512_mask_fmaddsub_round_ph(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_fmaddsub_round_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(__m512h, __mmask32, __m512h, __m512h,
              ffi.Int32)>>('_mm512_mask_fmaddsub_round_ph');
  late final __mm512_mask_fmaddsub_round_ph = __mm512_mask_fmaddsub_round_phPtr
      .asFunction<__m512h Function(__m512h, int, __m512h, __m512h, int)>();

  __m512h _mm512_mask3_fmaddsub_round_ph(
    __m512h arg0,
    __m512h arg1,
    __m512h arg2,
    int arg3,
    int arg4,
  ) {
    return __mm512_mask3_fmaddsub_round_ph(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask3_fmaddsub_round_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(__m512h, __m512h, __m512h, __mmask32,
              ffi.Int32)>>('_mm512_mask3_fmaddsub_round_ph');
  late final __mm512_mask3_fmaddsub_round_ph =
      __mm512_mask3_fmaddsub_round_phPtr
          .asFunction<__m512h Function(__m512h, __m512h, __m512h, int, int)>();

  __m512h _mm512_maskz_fmaddsub_round_ph(
    int arg0,
    __m512h arg1,
    __m512h arg2,
    __m512h arg3,
    int arg4,
  ) {
    return __mm512_maskz_fmaddsub_round_ph(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_maskz_fmaddsub_round_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(__mmask32, __m512h, __m512h, __m512h,
              ffi.Int32)>>('_mm512_maskz_fmaddsub_round_ph');
  late final __mm512_maskz_fmaddsub_round_ph =
      __mm512_maskz_fmaddsub_round_phPtr
          .asFunction<__m512h Function(int, __m512h, __m512h, __m512h, int)>();

  __m128h _mm_fmsubadd_ph(
    __m128h arg0,
    __m128h arg1,
    __m128h arg2,
  ) {
    return __mm_fmsubadd_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_fmsubadd_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128h, __m128h, __m128h)>>(
          '_mm_fmsubadd_ph');
  late final __mm_fmsubadd_ph = __mm_fmsubadd_phPtr
      .asFunction<__m128h Function(__m128h, __m128h, __m128h)>();

  __m128h _mm_mask_fmsubadd_ph(
    __m128h arg0,
    int arg1,
    __m128h arg2,
    __m128h arg3,
  ) {
    return __mm_mask_fmsubadd_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_fmsubadd_phPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __m128h, __mmask8, __m128h, __m128h)>>('_mm_mask_fmsubadd_ph');
  late final __mm_mask_fmsubadd_ph = __mm_mask_fmsubadd_phPtr
      .asFunction<__m128h Function(__m128h, int, __m128h, __m128h)>();

  __m128h _mm_mask3_fmsubadd_ph(
    __m128h arg0,
    __m128h arg1,
    __m128h arg2,
    int arg3,
  ) {
    return __mm_mask3_fmsubadd_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask3_fmsubadd_phPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __m128h, __m128h, __m128h, __mmask8)>>('_mm_mask3_fmsubadd_ph');
  late final __mm_mask3_fmsubadd_ph = __mm_mask3_fmsubadd_phPtr
      .asFunction<__m128h Function(__m128h, __m128h, __m128h, int)>();

  __m128h _mm_maskz_fmsubadd_ph(
    int arg0,
    __m128h arg1,
    __m128h arg2,
    __m128h arg3,
  ) {
    return __mm_maskz_fmsubadd_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_fmsubadd_phPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __mmask8, __m128h, __m128h, __m128h)>>('_mm_maskz_fmsubadd_ph');
  late final __mm_maskz_fmsubadd_ph = __mm_maskz_fmsubadd_phPtr
      .asFunction<__m128h Function(int, __m128h, __m128h, __m128h)>();

  __m256h _mm256_fmsubadd_ph(
    __m256h arg0,
    __m256h arg1,
    __m256h arg2,
  ) {
    return __mm256_fmsubadd_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_fmsubadd_phPtr =
      _lookup<ffi.NativeFunction<__m256h Function(__m256h, __m256h, __m256h)>>(
          '_mm256_fmsubadd_ph');
  late final __mm256_fmsubadd_ph = __mm256_fmsubadd_phPtr
      .asFunction<__m256h Function(__m256h, __m256h, __m256h)>();

  __m256h _mm256_mask_fmsubadd_ph(
    __m256h arg0,
    int arg1,
    __m256h arg2,
    __m256h arg3,
  ) {
    return __mm256_mask_fmsubadd_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_fmsubadd_phPtr = _lookup<
      ffi.NativeFunction<
          __m256h Function(__m256h, __mmask16, __m256h,
              __m256h)>>('_mm256_mask_fmsubadd_ph');
  late final __mm256_mask_fmsubadd_ph = __mm256_mask_fmsubadd_phPtr
      .asFunction<__m256h Function(__m256h, int, __m256h, __m256h)>();

  __m256h _mm256_mask3_fmsubadd_ph(
    __m256h arg0,
    __m256h arg1,
    __m256h arg2,
    int arg3,
  ) {
    return __mm256_mask3_fmsubadd_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask3_fmsubadd_phPtr = _lookup<
      ffi.NativeFunction<
          __m256h Function(__m256h, __m256h, __m256h,
              __mmask16)>>('_mm256_mask3_fmsubadd_ph');
  late final __mm256_mask3_fmsubadd_ph = __mm256_mask3_fmsubadd_phPtr
      .asFunction<__m256h Function(__m256h, __m256h, __m256h, int)>();

  __m256h _mm256_maskz_fmsubadd_ph(
    int arg0,
    __m256h arg1,
    __m256h arg2,
    __m256h arg3,
  ) {
    return __mm256_maskz_fmsubadd_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_maskz_fmsubadd_phPtr = _lookup<
      ffi.NativeFunction<
          __m256h Function(__mmask16, __m256h, __m256h,
              __m256h)>>('_mm256_maskz_fmsubadd_ph');
  late final __mm256_maskz_fmsubadd_ph = __mm256_maskz_fmsubadd_phPtr
      .asFunction<__m256h Function(int, __m256h, __m256h, __m256h)>();

  __m512h _mm512_fmsubadd_ph(
    __m512h arg0,
    __m512h arg1,
    __m512h arg2,
  ) {
    return __mm512_fmsubadd_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_fmsubadd_phPtr =
      _lookup<ffi.NativeFunction<__m512h Function(__m512h, __m512h, __m512h)>>(
          '_mm512_fmsubadd_ph');
  late final __mm512_fmsubadd_ph = __mm512_fmsubadd_phPtr
      .asFunction<__m512h Function(__m512h, __m512h, __m512h)>();

  __m512h _mm512_mask_fmsubadd_ph(
    __m512h arg0,
    int arg1,
    __m512h arg2,
    __m512h arg3,
  ) {
    return __mm512_mask_fmsubadd_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_fmsubadd_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(__m512h, __mmask32, __m512h,
              __m512h)>>('_mm512_mask_fmsubadd_ph');
  late final __mm512_mask_fmsubadd_ph = __mm512_mask_fmsubadd_phPtr
      .asFunction<__m512h Function(__m512h, int, __m512h, __m512h)>();

  __m512h _mm512_mask3_fmsubadd_ph(
    __m512h arg0,
    __m512h arg1,
    __m512h arg2,
    int arg3,
  ) {
    return __mm512_mask3_fmsubadd_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask3_fmsubadd_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(__m512h, __m512h, __m512h,
              __mmask32)>>('_mm512_mask3_fmsubadd_ph');
  late final __mm512_mask3_fmsubadd_ph = __mm512_mask3_fmsubadd_phPtr
      .asFunction<__m512h Function(__m512h, __m512h, __m512h, int)>();

  __m512h _mm512_maskz_fmsubadd_ph(
    int arg0,
    __m512h arg1,
    __m512h arg2,
    __m512h arg3,
  ) {
    return __mm512_maskz_fmsubadd_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_fmsubadd_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(__mmask32, __m512h, __m512h,
              __m512h)>>('_mm512_maskz_fmsubadd_ph');
  late final __mm512_maskz_fmsubadd_ph = __mm512_maskz_fmsubadd_phPtr
      .asFunction<__m512h Function(int, __m512h, __m512h, __m512h)>();

  __m512h _mm512_fmsubadd_round_ph(
    __m512h arg0,
    __m512h arg1,
    __m512h arg2,
    int arg3,
  ) {
    return __mm512_fmsubadd_round_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_fmsubadd_round_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(__m512h, __m512h, __m512h,
              ffi.Int32)>>('_mm512_fmsubadd_round_ph');
  late final __mm512_fmsubadd_round_ph = __mm512_fmsubadd_round_phPtr
      .asFunction<__m512h Function(__m512h, __m512h, __m512h, int)>();

  __m512h _mm512_mask_fmsubadd_round_ph(
    __m512h arg0,
    int arg1,
    __m512h arg2,
    __m512h arg3,
    int arg4,
  ) {
    return __mm512_mask_fmsubadd_round_ph(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_fmsubadd_round_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(__m512h, __mmask32, __m512h, __m512h,
              ffi.Int32)>>('_mm512_mask_fmsubadd_round_ph');
  late final __mm512_mask_fmsubadd_round_ph = __mm512_mask_fmsubadd_round_phPtr
      .asFunction<__m512h Function(__m512h, int, __m512h, __m512h, int)>();

  __m512h _mm512_mask3_fmsubadd_round_ph(
    __m512h arg0,
    __m512h arg1,
    __m512h arg2,
    int arg3,
    int arg4,
  ) {
    return __mm512_mask3_fmsubadd_round_ph(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask3_fmsubadd_round_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(__m512h, __m512h, __m512h, __mmask32,
              ffi.Int32)>>('_mm512_mask3_fmsubadd_round_ph');
  late final __mm512_mask3_fmsubadd_round_ph =
      __mm512_mask3_fmsubadd_round_phPtr
          .asFunction<__m512h Function(__m512h, __m512h, __m512h, int, int)>();

  __m512h _mm512_maskz_fmsubadd_round_ph(
    int arg0,
    __m512h arg1,
    __m512h arg2,
    __m512h arg3,
    int arg4,
  ) {
    return __mm512_maskz_fmsubadd_round_ph(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_maskz_fmsubadd_round_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(__mmask32, __m512h, __m512h, __m512h,
              ffi.Int32)>>('_mm512_maskz_fmsubadd_round_ph');
  late final __mm512_maskz_fmsubadd_round_ph =
      __mm512_maskz_fmsubadd_round_phPtr
          .asFunction<__m512h Function(int, __m512h, __m512h, __m512h, int)>();

  int _mm_fpclass_ph_mask(
    __m128h arg0,
    int arg1,
  ) {
    return __mm_fpclass_ph_mask(
      arg0,
      arg1,
    );
  }

  late final __mm_fpclass_ph_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m128h, ffi.Int32)>>(
          '_mm_fpclass_ph_mask');
  late final __mm_fpclass_ph_mask =
      __mm_fpclass_ph_maskPtr.asFunction<int Function(__m128h, int)>();

  int _mm_mask_fpclass_ph_mask(
    int arg0,
    __m128h arg1,
    int arg2,
  ) {
    return __mm_mask_fpclass_ph_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_fpclass_ph_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m128h, ffi.Int32)>>(
      '_mm_mask_fpclass_ph_mask');
  late final __mm_mask_fpclass_ph_mask = __mm_mask_fpclass_ph_maskPtr
      .asFunction<int Function(int, __m128h, int)>();

  int _mm256_fpclass_ph_mask(
    __m256h arg0,
    int arg1,
  ) {
    return __mm256_fpclass_ph_mask(
      arg0,
      arg1,
    );
  }

  late final __mm256_fpclass_ph_maskPtr =
      _lookup<ffi.NativeFunction<__mmask16 Function(__m256h, ffi.Int32)>>(
          '_mm256_fpclass_ph_mask');
  late final __mm256_fpclass_ph_mask =
      __mm256_fpclass_ph_maskPtr.asFunction<int Function(__m256h, int)>();

  int _mm256_mask_fpclass_ph_mask(
    int arg0,
    __m256h arg1,
    int arg2,
  ) {
    return __mm256_mask_fpclass_ph_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_fpclass_ph_maskPtr = _lookup<
      ffi.NativeFunction<
          __mmask16 Function(
              __mmask16, __m256h, ffi.Int32)>>('_mm256_mask_fpclass_ph_mask');
  late final __mm256_mask_fpclass_ph_mask = __mm256_mask_fpclass_ph_maskPtr
      .asFunction<int Function(int, __m256h, int)>();

  int _mm512_fpclass_ph_mask(
    __m512h arg0,
    int arg1,
  ) {
    return __mm512_fpclass_ph_mask(
      arg0,
      arg1,
    );
  }

  late final __mm512_fpclass_ph_maskPtr =
      _lookup<ffi.NativeFunction<__mmask32 Function(__m512h, ffi.Int32)>>(
          '_mm512_fpclass_ph_mask');
  late final __mm512_fpclass_ph_mask =
      __mm512_fpclass_ph_maskPtr.asFunction<int Function(__m512h, int)>();

  int _mm512_mask_fpclass_ph_mask(
    int arg0,
    __m512h arg1,
    int arg2,
  ) {
    return __mm512_mask_fpclass_ph_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_fpclass_ph_maskPtr = _lookup<
      ffi.NativeFunction<
          __mmask32 Function(
              __mmask32, __m512h, ffi.Int32)>>('_mm512_mask_fpclass_ph_mask');
  late final __mm512_mask_fpclass_ph_mask = __mm512_mask_fpclass_ph_maskPtr
      .asFunction<int Function(int, __m512h, int)>();

  int _mm_fpclass_sh_mask(
    __m128h arg0,
    int arg1,
  ) {
    return __mm_fpclass_sh_mask(
      arg0,
      arg1,
    );
  }

  late final __mm_fpclass_sh_maskPtr =
      _lookup<ffi.NativeFunction<__mmask8 Function(__m128h, ffi.Int32)>>(
          '_mm_fpclass_sh_mask');
  late final __mm_fpclass_sh_mask =
      __mm_fpclass_sh_maskPtr.asFunction<int Function(__m128h, int)>();

  int _mm_mask_fpclass_sh_mask(
    int arg0,
    __m128h arg1,
    int arg2,
  ) {
    return __mm_mask_fpclass_sh_mask(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_fpclass_sh_maskPtr = _lookup<
          ffi.NativeFunction<__mmask8 Function(__mmask8, __m128h, ffi.Int32)>>(
      '_mm_mask_fpclass_sh_mask');
  late final __mm_mask_fpclass_sh_mask = __mm_mask_fpclass_sh_maskPtr
      .asFunction<int Function(int, __m128h, int)>();

  __m128h _mm_fmadd_pch(
    __m128h arg0,
    __m128h arg1,
    __m128h arg2,
  ) {
    return __mm_fmadd_pch(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_fmadd_pchPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128h, __m128h, __m128h)>>(
          '_mm_fmadd_pch');
  late final __mm_fmadd_pch = __mm_fmadd_pchPtr
      .asFunction<__m128h Function(__m128h, __m128h, __m128h)>();

  __m128h _mm_mask_fmadd_pch(
    __m128h arg0,
    int arg1,
    __m128h arg2,
    __m128h arg3,
  ) {
    return __mm_mask_fmadd_pch(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_fmadd_pchPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __m128h, __mmask8, __m128h, __m128h)>>('_mm_mask_fmadd_pch');
  late final __mm_mask_fmadd_pch = __mm_mask_fmadd_pchPtr
      .asFunction<__m128h Function(__m128h, int, __m128h, __m128h)>();

  __m128h _mm_mask3_fmadd_pch(
    __m128h arg0,
    __m128h arg1,
    __m128h arg2,
    int arg3,
  ) {
    return __mm_mask3_fmadd_pch(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask3_fmadd_pchPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __m128h, __m128h, __m128h, __mmask8)>>('_mm_mask3_fmadd_pch');
  late final __mm_mask3_fmadd_pch = __mm_mask3_fmadd_pchPtr
      .asFunction<__m128h Function(__m128h, __m128h, __m128h, int)>();

  __m128h _mm_maskz_fmadd_pch(
    int arg0,
    __m128h arg1,
    __m128h arg2,
    __m128h arg3,
  ) {
    return __mm_maskz_fmadd_pch(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_fmadd_pchPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __mmask8, __m128h, __m128h, __m128h)>>('_mm_maskz_fmadd_pch');
  late final __mm_maskz_fmadd_pch = __mm_maskz_fmadd_pchPtr
      .asFunction<__m128h Function(int, __m128h, __m128h, __m128h)>();

  __m256h _mm256_fmadd_pch(
    __m256h arg0,
    __m256h arg1,
    __m256h arg2,
  ) {
    return __mm256_fmadd_pch(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_fmadd_pchPtr =
      _lookup<ffi.NativeFunction<__m256h Function(__m256h, __m256h, __m256h)>>(
          '_mm256_fmadd_pch');
  late final __mm256_fmadd_pch = __mm256_fmadd_pchPtr
      .asFunction<__m256h Function(__m256h, __m256h, __m256h)>();

  __m256h _mm256_mask_fmadd_pch(
    __m256h arg0,
    int arg1,
    __m256h arg2,
    __m256h arg3,
  ) {
    return __mm256_mask_fmadd_pch(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_fmadd_pchPtr = _lookup<
      ffi.NativeFunction<
          __m256h Function(
              __m256h, __mmask8, __m256h, __m256h)>>('_mm256_mask_fmadd_pch');
  late final __mm256_mask_fmadd_pch = __mm256_mask_fmadd_pchPtr
      .asFunction<__m256h Function(__m256h, int, __m256h, __m256h)>();

  __m256h _mm256_mask3_fmadd_pch(
    __m256h arg0,
    __m256h arg1,
    __m256h arg2,
    int arg3,
  ) {
    return __mm256_mask3_fmadd_pch(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask3_fmadd_pchPtr = _lookup<
      ffi.NativeFunction<
          __m256h Function(
              __m256h, __m256h, __m256h, __mmask8)>>('_mm256_mask3_fmadd_pch');
  late final __mm256_mask3_fmadd_pch = __mm256_mask3_fmadd_pchPtr
      .asFunction<__m256h Function(__m256h, __m256h, __m256h, int)>();

  __m256h _mm256_maskz_fmadd_pch(
    int arg0,
    __m256h arg1,
    __m256h arg2,
    __m256h arg3,
  ) {
    return __mm256_maskz_fmadd_pch(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_maskz_fmadd_pchPtr = _lookup<
      ffi.NativeFunction<
          __m256h Function(
              __mmask8, __m256h, __m256h, __m256h)>>('_mm256_maskz_fmadd_pch');
  late final __mm256_maskz_fmadd_pch = __mm256_maskz_fmadd_pchPtr
      .asFunction<__m256h Function(int, __m256h, __m256h, __m256h)>();

  __m512h _mm512_fmadd_pch(
    __m512h arg0,
    __m512h arg1,
    __m512h arg2,
  ) {
    return __mm512_fmadd_pch(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_fmadd_pchPtr =
      _lookup<ffi.NativeFunction<__m512h Function(__m512h, __m512h, __m512h)>>(
          '_mm512_fmadd_pch');
  late final __mm512_fmadd_pch = __mm512_fmadd_pchPtr
      .asFunction<__m512h Function(__m512h, __m512h, __m512h)>();

  __m512h _mm512_mask_fmadd_pch(
    __m512h arg0,
    int arg1,
    __m512h arg2,
    __m512h arg3,
  ) {
    return __mm512_mask_fmadd_pch(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_fmadd_pchPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(
              __m512h, __mmask16, __m512h, __m512h)>>('_mm512_mask_fmadd_pch');
  late final __mm512_mask_fmadd_pch = __mm512_mask_fmadd_pchPtr
      .asFunction<__m512h Function(__m512h, int, __m512h, __m512h)>();

  __m512h _mm512_mask3_fmadd_pch(
    __m512h arg0,
    __m512h arg1,
    __m512h arg2,
    int arg3,
  ) {
    return __mm512_mask3_fmadd_pch(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask3_fmadd_pchPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(
              __m512h, __m512h, __m512h, __mmask16)>>('_mm512_mask3_fmadd_pch');
  late final __mm512_mask3_fmadd_pch = __mm512_mask3_fmadd_pchPtr
      .asFunction<__m512h Function(__m512h, __m512h, __m512h, int)>();

  __m512h _mm512_maskz_fmadd_pch(
    int arg0,
    __m512h arg1,
    __m512h arg2,
    __m512h arg3,
  ) {
    return __mm512_maskz_fmadd_pch(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_fmadd_pchPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(
              __mmask16, __m512h, __m512h, __m512h)>>('_mm512_maskz_fmadd_pch');
  late final __mm512_maskz_fmadd_pch = __mm512_maskz_fmadd_pchPtr
      .asFunction<__m512h Function(int, __m512h, __m512h, __m512h)>();

  __m512h _mm512_fmadd_round_pch(
    __m512h arg0,
    __m512h arg1,
    __m512h arg2,
    int arg3,
  ) {
    return __mm512_fmadd_round_pch(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_fmadd_round_pchPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(
              __m512h, __m512h, __m512h, ffi.Int32)>>('_mm512_fmadd_round_pch');
  late final __mm512_fmadd_round_pch = __mm512_fmadd_round_pchPtr
      .asFunction<__m512h Function(__m512h, __m512h, __m512h, int)>();

  __m512h _mm512_mask_fmadd_round_pch(
    __m512h arg0,
    int arg1,
    __m512h arg2,
    __m512h arg3,
    int arg4,
  ) {
    return __mm512_mask_fmadd_round_pch(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_fmadd_round_pchPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(__m512h, __mmask16, __m512h, __m512h,
              ffi.Int32)>>('_mm512_mask_fmadd_round_pch');
  late final __mm512_mask_fmadd_round_pch = __mm512_mask_fmadd_round_pchPtr
      .asFunction<__m512h Function(__m512h, int, __m512h, __m512h, int)>();

  __m512h _mm512_mask3_fmadd_round_pch(
    __m512h arg0,
    __m512h arg1,
    __m512h arg2,
    int arg3,
    int arg4,
  ) {
    return __mm512_mask3_fmadd_round_pch(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask3_fmadd_round_pchPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(__m512h, __m512h, __m512h, __mmask16,
              ffi.Int32)>>('_mm512_mask3_fmadd_round_pch');
  late final __mm512_mask3_fmadd_round_pch = __mm512_mask3_fmadd_round_pchPtr
      .asFunction<__m512h Function(__m512h, __m512h, __m512h, int, int)>();

  __m512h _mm512_maskz_fmadd_round_pch(
    int arg0,
    __m512h arg1,
    __m512h arg2,
    __m512h arg3,
    int arg4,
  ) {
    return __mm512_maskz_fmadd_round_pch(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_maskz_fmadd_round_pchPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(__mmask16, __m512h, __m512h, __m512h,
              ffi.Int32)>>('_mm512_maskz_fmadd_round_pch');
  late final __mm512_maskz_fmadd_round_pch = __mm512_maskz_fmadd_round_pchPtr
      .asFunction<__m512h Function(int, __m512h, __m512h, __m512h, int)>();

  __m128h _mm_fcmadd_pch(
    __m128h arg0,
    __m128h arg1,
    __m128h arg2,
  ) {
    return __mm_fcmadd_pch(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_fcmadd_pchPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128h, __m128h, __m128h)>>(
          '_mm_fcmadd_pch');
  late final __mm_fcmadd_pch = __mm_fcmadd_pchPtr
      .asFunction<__m128h Function(__m128h, __m128h, __m128h)>();

  __m128h _mm_mask_fcmadd_pch(
    __m128h arg0,
    int arg1,
    __m128h arg2,
    __m128h arg3,
  ) {
    return __mm_mask_fcmadd_pch(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_fcmadd_pchPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __m128h, __mmask8, __m128h, __m128h)>>('_mm_mask_fcmadd_pch');
  late final __mm_mask_fcmadd_pch = __mm_mask_fcmadd_pchPtr
      .asFunction<__m128h Function(__m128h, int, __m128h, __m128h)>();

  __m128h _mm_mask3_fcmadd_pch(
    __m128h arg0,
    __m128h arg1,
    __m128h arg2,
    int arg3,
  ) {
    return __mm_mask3_fcmadd_pch(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask3_fcmadd_pchPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __m128h, __m128h, __m128h, __mmask8)>>('_mm_mask3_fcmadd_pch');
  late final __mm_mask3_fcmadd_pch = __mm_mask3_fcmadd_pchPtr
      .asFunction<__m128h Function(__m128h, __m128h, __m128h, int)>();

  __m128h _mm_maskz_fcmadd_pch(
    int arg0,
    __m128h arg1,
    __m128h arg2,
    __m128h arg3,
  ) {
    return __mm_maskz_fcmadd_pch(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_fcmadd_pchPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __mmask8, __m128h, __m128h, __m128h)>>('_mm_maskz_fcmadd_pch');
  late final __mm_maskz_fcmadd_pch = __mm_maskz_fcmadd_pchPtr
      .asFunction<__m128h Function(int, __m128h, __m128h, __m128h)>();

  __m256h _mm256_fcmadd_pch(
    __m256h arg0,
    __m256h arg1,
    __m256h arg2,
  ) {
    return __mm256_fcmadd_pch(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_fcmadd_pchPtr =
      _lookup<ffi.NativeFunction<__m256h Function(__m256h, __m256h, __m256h)>>(
          '_mm256_fcmadd_pch');
  late final __mm256_fcmadd_pch = __mm256_fcmadd_pchPtr
      .asFunction<__m256h Function(__m256h, __m256h, __m256h)>();

  __m256h _mm256_mask_fcmadd_pch(
    __m256h arg0,
    int arg1,
    __m256h arg2,
    __m256h arg3,
  ) {
    return __mm256_mask_fcmadd_pch(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_fcmadd_pchPtr = _lookup<
      ffi.NativeFunction<
          __m256h Function(
              __m256h, __mmask8, __m256h, __m256h)>>('_mm256_mask_fcmadd_pch');
  late final __mm256_mask_fcmadd_pch = __mm256_mask_fcmadd_pchPtr
      .asFunction<__m256h Function(__m256h, int, __m256h, __m256h)>();

  __m256h _mm256_mask3_fcmadd_pch(
    __m256h arg0,
    __m256h arg1,
    __m256h arg2,
    int arg3,
  ) {
    return __mm256_mask3_fcmadd_pch(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask3_fcmadd_pchPtr = _lookup<
      ffi.NativeFunction<
          __m256h Function(
              __m256h, __m256h, __m256h, __mmask8)>>('_mm256_mask3_fcmadd_pch');
  late final __mm256_mask3_fcmadd_pch = __mm256_mask3_fcmadd_pchPtr
      .asFunction<__m256h Function(__m256h, __m256h, __m256h, int)>();

  __m256h _mm256_maskz_fcmadd_pch(
    int arg0,
    __m256h arg1,
    __m256h arg2,
    __m256h arg3,
  ) {
    return __mm256_maskz_fcmadd_pch(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_maskz_fcmadd_pchPtr = _lookup<
      ffi.NativeFunction<
          __m256h Function(
              __mmask8, __m256h, __m256h, __m256h)>>('_mm256_maskz_fcmadd_pch');
  late final __mm256_maskz_fcmadd_pch = __mm256_maskz_fcmadd_pchPtr
      .asFunction<__m256h Function(int, __m256h, __m256h, __m256h)>();

  __m512h _mm512_fcmadd_pch(
    __m512h arg0,
    __m512h arg1,
    __m512h arg2,
  ) {
    return __mm512_fcmadd_pch(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_fcmadd_pchPtr =
      _lookup<ffi.NativeFunction<__m512h Function(__m512h, __m512h, __m512h)>>(
          '_mm512_fcmadd_pch');
  late final __mm512_fcmadd_pch = __mm512_fcmadd_pchPtr
      .asFunction<__m512h Function(__m512h, __m512h, __m512h)>();

  __m512h _mm512_mask_fcmadd_pch(
    __m512h arg0,
    int arg1,
    __m512h arg2,
    __m512h arg3,
  ) {
    return __mm512_mask_fcmadd_pch(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_fcmadd_pchPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(
              __m512h, __mmask16, __m512h, __m512h)>>('_mm512_mask_fcmadd_pch');
  late final __mm512_mask_fcmadd_pch = __mm512_mask_fcmadd_pchPtr
      .asFunction<__m512h Function(__m512h, int, __m512h, __m512h)>();

  __m512h _mm512_mask3_fcmadd_pch(
    __m512h arg0,
    __m512h arg1,
    __m512h arg2,
    int arg3,
  ) {
    return __mm512_mask3_fcmadd_pch(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask3_fcmadd_pchPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(__m512h, __m512h, __m512h,
              __mmask16)>>('_mm512_mask3_fcmadd_pch');
  late final __mm512_mask3_fcmadd_pch = __mm512_mask3_fcmadd_pchPtr
      .asFunction<__m512h Function(__m512h, __m512h, __m512h, int)>();

  __m512h _mm512_maskz_fcmadd_pch(
    int arg0,
    __m512h arg1,
    __m512h arg2,
    __m512h arg3,
  ) {
    return __mm512_maskz_fcmadd_pch(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_fcmadd_pchPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(__mmask16, __m512h, __m512h,
              __m512h)>>('_mm512_maskz_fcmadd_pch');
  late final __mm512_maskz_fcmadd_pch = __mm512_maskz_fcmadd_pchPtr
      .asFunction<__m512h Function(int, __m512h, __m512h, __m512h)>();

  __m512h _mm512_fcmadd_round_pch(
    __m512h arg0,
    __m512h arg1,
    __m512h arg2,
    int arg3,
  ) {
    return __mm512_fcmadd_round_pch(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_fcmadd_round_pchPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(__m512h, __m512h, __m512h,
              ffi.Int32)>>('_mm512_fcmadd_round_pch');
  late final __mm512_fcmadd_round_pch = __mm512_fcmadd_round_pchPtr
      .asFunction<__m512h Function(__m512h, __m512h, __m512h, int)>();

  __m512h _mm512_mask_fcmadd_round_pch(
    __m512h arg0,
    int arg1,
    __m512h arg2,
    __m512h arg3,
    int arg4,
  ) {
    return __mm512_mask_fcmadd_round_pch(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_fcmadd_round_pchPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(__m512h, __mmask16, __m512h, __m512h,
              ffi.Int32)>>('_mm512_mask_fcmadd_round_pch');
  late final __mm512_mask_fcmadd_round_pch = __mm512_mask_fcmadd_round_pchPtr
      .asFunction<__m512h Function(__m512h, int, __m512h, __m512h, int)>();

  __m512h _mm512_mask3_fcmadd_round_pch(
    __m512h arg0,
    __m512h arg1,
    __m512h arg2,
    int arg3,
    int arg4,
  ) {
    return __mm512_mask3_fcmadd_round_pch(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask3_fcmadd_round_pchPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(__m512h, __m512h, __m512h, __mmask16,
              ffi.Int32)>>('_mm512_mask3_fcmadd_round_pch');
  late final __mm512_mask3_fcmadd_round_pch = __mm512_mask3_fcmadd_round_pchPtr
      .asFunction<__m512h Function(__m512h, __m512h, __m512h, int, int)>();

  __m512h _mm512_maskz_fcmadd_round_pch(
    int arg0,
    __m512h arg1,
    __m512h arg2,
    __m512h arg3,
    int arg4,
  ) {
    return __mm512_maskz_fcmadd_round_pch(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_maskz_fcmadd_round_pchPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(__mmask16, __m512h, __m512h, __m512h,
              ffi.Int32)>>('_mm512_maskz_fcmadd_round_pch');
  late final __mm512_maskz_fcmadd_round_pch = __mm512_maskz_fcmadd_round_pchPtr
      .asFunction<__m512h Function(int, __m512h, __m512h, __m512h, int)>();

  __m128h _mm_fcmadd_sch(
    __m128h arg0,
    __m128h arg1,
    __m128h arg2,
  ) {
    return __mm_fcmadd_sch(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_fcmadd_schPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128h, __m128h, __m128h)>>(
          '_mm_fcmadd_sch');
  late final __mm_fcmadd_sch = __mm_fcmadd_schPtr
      .asFunction<__m128h Function(__m128h, __m128h, __m128h)>();

  __m128h _mm_mask_fcmadd_sch(
    __m128h arg0,
    int arg1,
    __m128h arg2,
    __m128h arg3,
  ) {
    return __mm_mask_fcmadd_sch(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_fcmadd_schPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __m128h, __mmask8, __m128h, __m128h)>>('_mm_mask_fcmadd_sch');
  late final __mm_mask_fcmadd_sch = __mm_mask_fcmadd_schPtr
      .asFunction<__m128h Function(__m128h, int, __m128h, __m128h)>();

  __m128h _mm_mask3_fcmadd_sch(
    __m128h arg0,
    __m128h arg1,
    __m128h arg2,
    int arg3,
  ) {
    return __mm_mask3_fcmadd_sch(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask3_fcmadd_schPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __m128h, __m128h, __m128h, __mmask8)>>('_mm_mask3_fcmadd_sch');
  late final __mm_mask3_fcmadd_sch = __mm_mask3_fcmadd_schPtr
      .asFunction<__m128h Function(__m128h, __m128h, __m128h, int)>();

  __m128h _mm_maskz_fcmadd_sch(
    int arg0,
    __m128h arg1,
    __m128h arg2,
    __m128h arg3,
  ) {
    return __mm_maskz_fcmadd_sch(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_fcmadd_schPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __mmask8, __m128h, __m128h, __m128h)>>('_mm_maskz_fcmadd_sch');
  late final __mm_maskz_fcmadd_sch = __mm_maskz_fcmadd_schPtr
      .asFunction<__m128h Function(int, __m128h, __m128h, __m128h)>();

  __m128h _mm_fcmadd_round_sch(
    __m128h arg0,
    __m128h arg1,
    __m128h arg2,
    int arg3,
  ) {
    return __mm_fcmadd_round_sch(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_fcmadd_round_schPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __m128h, __m128h, __m128h, ffi.Int32)>>('_mm_fcmadd_round_sch');
  late final __mm_fcmadd_round_sch = __mm_fcmadd_round_schPtr
      .asFunction<__m128h Function(__m128h, __m128h, __m128h, int)>();

  __m128h _mm_mask_fcmadd_round_sch(
    __m128h arg0,
    int arg1,
    __m128h arg2,
    __m128h arg3,
    int arg4,
  ) {
    return __mm_mask_fcmadd_round_sch(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_fcmadd_round_schPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(__m128h, __mmask8, __m128h, __m128h,
              ffi.Int32)>>('_mm_mask_fcmadd_round_sch');
  late final __mm_mask_fcmadd_round_sch = __mm_mask_fcmadd_round_schPtr
      .asFunction<__m128h Function(__m128h, int, __m128h, __m128h, int)>();

  __m128h _mm_mask3_fcmadd_round_sch(
    __m128h arg0,
    __m128h arg1,
    __m128h arg2,
    int arg3,
    int arg4,
  ) {
    return __mm_mask3_fcmadd_round_sch(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask3_fcmadd_round_schPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(__m128h, __m128h, __m128h, __mmask8,
              ffi.Int32)>>('_mm_mask3_fcmadd_round_sch');
  late final __mm_mask3_fcmadd_round_sch = __mm_mask3_fcmadd_round_schPtr
      .asFunction<__m128h Function(__m128h, __m128h, __m128h, int, int)>();

  __m128h _mm_maskz_fcmadd_round_sch(
    int arg0,
    __m128h arg1,
    __m128h arg2,
    __m128h arg3,
    int arg4,
  ) {
    return __mm_maskz_fcmadd_round_sch(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_maskz_fcmadd_round_schPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(__mmask8, __m128h, __m128h, __m128h,
              ffi.Int32)>>('_mm_maskz_fcmadd_round_sch');
  late final __mm_maskz_fcmadd_round_sch = __mm_maskz_fcmadd_round_schPtr
      .asFunction<__m128h Function(int, __m128h, __m128h, __m128h, int)>();

  __m128h _mm_fmadd_sch(
    __m128h arg0,
    __m128h arg1,
    __m128h arg2,
  ) {
    return __mm_fmadd_sch(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_fmadd_schPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128h, __m128h, __m128h)>>(
          '_mm_fmadd_sch');
  late final __mm_fmadd_sch = __mm_fmadd_schPtr
      .asFunction<__m128h Function(__m128h, __m128h, __m128h)>();

  __m128h _mm_mask_fmadd_sch(
    __m128h arg0,
    int arg1,
    __m128h arg2,
    __m128h arg3,
  ) {
    return __mm_mask_fmadd_sch(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_fmadd_schPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __m128h, __mmask8, __m128h, __m128h)>>('_mm_mask_fmadd_sch');
  late final __mm_mask_fmadd_sch = __mm_mask_fmadd_schPtr
      .asFunction<__m128h Function(__m128h, int, __m128h, __m128h)>();

  __m128h _mm_maskz_fmadd_sch(
    int arg0,
    __m128h arg1,
    __m128h arg2,
    __m128h arg3,
  ) {
    return __mm_maskz_fmadd_sch(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_fmadd_schPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __mmask8, __m128h, __m128h, __m128h)>>('_mm_maskz_fmadd_sch');
  late final __mm_maskz_fmadd_sch = __mm_maskz_fmadd_schPtr
      .asFunction<__m128h Function(int, __m128h, __m128h, __m128h)>();

  __m128h _mm_fmadd_round_sch(
    __m128h arg0,
    __m128h arg1,
    __m128h arg2,
    int arg3,
  ) {
    return __mm_fmadd_round_sch(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_fmadd_round_schPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __m128h, __m128h, __m128h, ffi.Int32)>>('_mm_fmadd_round_sch');
  late final __mm_fmadd_round_sch = __mm_fmadd_round_schPtr
      .asFunction<__m128h Function(__m128h, __m128h, __m128h, int)>();

  __m128h _mm_mask_fmadd_round_sch(
    __m128h arg0,
    int arg1,
    __m128h arg2,
    __m128h arg3,
    int arg4,
  ) {
    return __mm_mask_fmadd_round_sch(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_fmadd_round_schPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(__m128h, __mmask8, __m128h, __m128h,
              ffi.Int32)>>('_mm_mask_fmadd_round_sch');
  late final __mm_mask_fmadd_round_sch = __mm_mask_fmadd_round_schPtr
      .asFunction<__m128h Function(__m128h, int, __m128h, __m128h, int)>();

  __m128h _mm_maskz_fmadd_round_sch(
    int arg0,
    __m128h arg1,
    __m128h arg2,
    __m128h arg3,
    int arg4,
  ) {
    return __mm_maskz_fmadd_round_sch(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_maskz_fmadd_round_schPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(__mmask8, __m128h, __m128h, __m128h,
              ffi.Int32)>>('_mm_maskz_fmadd_round_sch');
  late final __mm_maskz_fmadd_round_sch = __mm_maskz_fmadd_round_schPtr
      .asFunction<__m128h Function(int, __m128h, __m128h, __m128h, int)>();

  __m128h _mm_fcmul_pch(
    __m128h arg0,
    __m128h arg1,
  ) {
    return __mm_fcmul_pch(
      arg0,
      arg1,
    );
  }

  late final __mm_fcmul_pchPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128h, __m128h)>>(
          '_mm_fcmul_pch');
  late final __mm_fcmul_pch =
      __mm_fcmul_pchPtr.asFunction<__m128h Function(__m128h, __m128h)>();

  __m128h _mm_mask_fcmul_pch(
    __m128h arg0,
    int arg1,
    __m128h arg2,
    __m128h arg3,
  ) {
    return __mm_mask_fcmul_pch(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_fcmul_pchPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __m128h, __mmask8, __m128h, __m128h)>>('_mm_mask_fcmul_pch');
  late final __mm_mask_fcmul_pch = __mm_mask_fcmul_pchPtr
      .asFunction<__m128h Function(__m128h, int, __m128h, __m128h)>();

  __m128h _mm_maskz_fcmul_pch(
    int arg0,
    __m128h arg1,
    __m128h arg2,
  ) {
    return __mm_maskz_fcmul_pch(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_fcmul_pchPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__mmask8, __m128h, __m128h)>>(
          '_mm_maskz_fcmul_pch');
  late final __mm_maskz_fcmul_pch = __mm_maskz_fcmul_pchPtr
      .asFunction<__m128h Function(int, __m128h, __m128h)>();

  __m256h _mm256_fcmul_pch(
    __m256h arg0,
    __m256h arg1,
  ) {
    return __mm256_fcmul_pch(
      arg0,
      arg1,
    );
  }

  late final __mm256_fcmul_pchPtr =
      _lookup<ffi.NativeFunction<__m256h Function(__m256h, __m256h)>>(
          '_mm256_fcmul_pch');
  late final __mm256_fcmul_pch =
      __mm256_fcmul_pchPtr.asFunction<__m256h Function(__m256h, __m256h)>();

  __m256h _mm256_mask_fcmul_pch(
    __m256h arg0,
    int arg1,
    __m256h arg2,
    __m256h arg3,
  ) {
    return __mm256_mask_fcmul_pch(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_fcmul_pchPtr = _lookup<
      ffi.NativeFunction<
          __m256h Function(
              __m256h, __mmask8, __m256h, __m256h)>>('_mm256_mask_fcmul_pch');
  late final __mm256_mask_fcmul_pch = __mm256_mask_fcmul_pchPtr
      .asFunction<__m256h Function(__m256h, int, __m256h, __m256h)>();

  __m256h _mm256_maskz_fcmul_pch(
    int arg0,
    __m256h arg1,
    __m256h arg2,
  ) {
    return __mm256_maskz_fcmul_pch(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_fcmul_pchPtr =
      _lookup<ffi.NativeFunction<__m256h Function(__mmask8, __m256h, __m256h)>>(
          '_mm256_maskz_fcmul_pch');
  late final __mm256_maskz_fcmul_pch = __mm256_maskz_fcmul_pchPtr
      .asFunction<__m256h Function(int, __m256h, __m256h)>();

  __m512h _mm512_fcmul_pch(
    __m512h arg0,
    __m512h arg1,
  ) {
    return __mm512_fcmul_pch(
      arg0,
      arg1,
    );
  }

  late final __mm512_fcmul_pchPtr =
      _lookup<ffi.NativeFunction<__m512h Function(__m512h, __m512h)>>(
          '_mm512_fcmul_pch');
  late final __mm512_fcmul_pch =
      __mm512_fcmul_pchPtr.asFunction<__m512h Function(__m512h, __m512h)>();

  __m512h _mm512_mask_fcmul_pch(
    __m512h arg0,
    int arg1,
    __m512h arg2,
    __m512h arg3,
  ) {
    return __mm512_mask_fcmul_pch(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_fcmul_pchPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(
              __m512h, __mmask16, __m512h, __m512h)>>('_mm512_mask_fcmul_pch');
  late final __mm512_mask_fcmul_pch = __mm512_mask_fcmul_pchPtr
      .asFunction<__m512h Function(__m512h, int, __m512h, __m512h)>();

  __m512h _mm512_maskz_fcmul_pch(
    int arg0,
    __m512h arg1,
    __m512h arg2,
  ) {
    return __mm512_maskz_fcmul_pch(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_fcmul_pchPtr = _lookup<
          ffi.NativeFunction<__m512h Function(__mmask16, __m512h, __m512h)>>(
      '_mm512_maskz_fcmul_pch');
  late final __mm512_maskz_fcmul_pch = __mm512_maskz_fcmul_pchPtr
      .asFunction<__m512h Function(int, __m512h, __m512h)>();

  __m512h _mm512_fcmul_round_pch(
    __m512h arg0,
    __m512h arg1,
    int arg2,
  ) {
    return __mm512_fcmul_round_pch(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_fcmul_round_pchPtr = _lookup<
          ffi.NativeFunction<__m512h Function(__m512h, __m512h, ffi.Int32)>>(
      '_mm512_fcmul_round_pch');
  late final __mm512_fcmul_round_pch = __mm512_fcmul_round_pchPtr
      .asFunction<__m512h Function(__m512h, __m512h, int)>();

  __m512h _mm512_mask_fcmul_round_pch(
    __m512h arg0,
    int arg1,
    __m512h arg2,
    __m512h arg3,
    int arg4,
  ) {
    return __mm512_mask_fcmul_round_pch(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_fcmul_round_pchPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(__m512h, __mmask16, __m512h, __m512h,
              ffi.Int32)>>('_mm512_mask_fcmul_round_pch');
  late final __mm512_mask_fcmul_round_pch = __mm512_mask_fcmul_round_pchPtr
      .asFunction<__m512h Function(__m512h, int, __m512h, __m512h, int)>();

  __m512h _mm512_maskz_fcmul_round_pch(
    int arg0,
    __m512h arg1,
    __m512h arg2,
    int arg3,
  ) {
    return __mm512_maskz_fcmul_round_pch(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_fcmul_round_pchPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(__mmask16, __m512h, __m512h,
              ffi.Int32)>>('_mm512_maskz_fcmul_round_pch');
  late final __mm512_maskz_fcmul_round_pch = __mm512_maskz_fcmul_round_pchPtr
      .asFunction<__m512h Function(int, __m512h, __m512h, int)>();

  __m128h _mm_fmul_pch(
    __m128h arg0,
    __m128h arg1,
  ) {
    return __mm_fmul_pch(
      arg0,
      arg1,
    );
  }

  late final __mm_fmul_pchPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128h, __m128h)>>(
          '_mm_fmul_pch');
  late final __mm_fmul_pch =
      __mm_fmul_pchPtr.asFunction<__m128h Function(__m128h, __m128h)>();

  __m128h _mm_mask_fmul_pch(
    __m128h arg0,
    int arg1,
    __m128h arg2,
    __m128h arg3,
  ) {
    return __mm_mask_fmul_pch(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_fmul_pchPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __m128h, __mmask8, __m128h, __m128h)>>('_mm_mask_fmul_pch');
  late final __mm_mask_fmul_pch = __mm_mask_fmul_pchPtr
      .asFunction<__m128h Function(__m128h, int, __m128h, __m128h)>();

  __m128h _mm_maskz_fmul_pch(
    int arg0,
    __m128h arg1,
    __m128h arg2,
  ) {
    return __mm_maskz_fmul_pch(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_fmul_pchPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__mmask8, __m128h, __m128h)>>(
          '_mm_maskz_fmul_pch');
  late final __mm_maskz_fmul_pch = __mm_maskz_fmul_pchPtr
      .asFunction<__m128h Function(int, __m128h, __m128h)>();

  __m256h _mm256_fmul_pch(
    __m256h arg0,
    __m256h arg1,
  ) {
    return __mm256_fmul_pch(
      arg0,
      arg1,
    );
  }

  late final __mm256_fmul_pchPtr =
      _lookup<ffi.NativeFunction<__m256h Function(__m256h, __m256h)>>(
          '_mm256_fmul_pch');
  late final __mm256_fmul_pch =
      __mm256_fmul_pchPtr.asFunction<__m256h Function(__m256h, __m256h)>();

  __m256h _mm256_mask_fmul_pch(
    __m256h arg0,
    int arg1,
    __m256h arg2,
    __m256h arg3,
  ) {
    return __mm256_mask_fmul_pch(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_fmul_pchPtr = _lookup<
      ffi.NativeFunction<
          __m256h Function(
              __m256h, __mmask8, __m256h, __m256h)>>('_mm256_mask_fmul_pch');
  late final __mm256_mask_fmul_pch = __mm256_mask_fmul_pchPtr
      .asFunction<__m256h Function(__m256h, int, __m256h, __m256h)>();

  __m256h _mm256_maskz_fmul_pch(
    int arg0,
    __m256h arg1,
    __m256h arg2,
  ) {
    return __mm256_maskz_fmul_pch(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_fmul_pchPtr =
      _lookup<ffi.NativeFunction<__m256h Function(__mmask8, __m256h, __m256h)>>(
          '_mm256_maskz_fmul_pch');
  late final __mm256_maskz_fmul_pch = __mm256_maskz_fmul_pchPtr
      .asFunction<__m256h Function(int, __m256h, __m256h)>();

  __m512h _mm512_fmul_pch(
    __m512h arg0,
    __m512h arg1,
  ) {
    return __mm512_fmul_pch(
      arg0,
      arg1,
    );
  }

  late final __mm512_fmul_pchPtr =
      _lookup<ffi.NativeFunction<__m512h Function(__m512h, __m512h)>>(
          '_mm512_fmul_pch');
  late final __mm512_fmul_pch =
      __mm512_fmul_pchPtr.asFunction<__m512h Function(__m512h, __m512h)>();

  __m512h _mm512_mask_fmul_pch(
    __m512h arg0,
    int arg1,
    __m512h arg2,
    __m512h arg3,
  ) {
    return __mm512_mask_fmul_pch(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_fmul_pchPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(
              __m512h, __mmask16, __m512h, __m512h)>>('_mm512_mask_fmul_pch');
  late final __mm512_mask_fmul_pch = __mm512_mask_fmul_pchPtr
      .asFunction<__m512h Function(__m512h, int, __m512h, __m512h)>();

  __m512h _mm512_maskz_fmul_pch(
    int arg0,
    __m512h arg1,
    __m512h arg2,
  ) {
    return __mm512_maskz_fmul_pch(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_fmul_pchPtr = _lookup<
          ffi.NativeFunction<__m512h Function(__mmask16, __m512h, __m512h)>>(
      '_mm512_maskz_fmul_pch');
  late final __mm512_maskz_fmul_pch = __mm512_maskz_fmul_pchPtr
      .asFunction<__m512h Function(int, __m512h, __m512h)>();

  __m512h _mm512_fmul_round_pch(
    __m512h arg0,
    __m512h arg1,
    int arg2,
  ) {
    return __mm512_fmul_round_pch(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_fmul_round_pchPtr = _lookup<
          ffi.NativeFunction<__m512h Function(__m512h, __m512h, ffi.Int32)>>(
      '_mm512_fmul_round_pch');
  late final __mm512_fmul_round_pch = __mm512_fmul_round_pchPtr
      .asFunction<__m512h Function(__m512h, __m512h, int)>();

  __m512h _mm512_mask_fmul_round_pch(
    __m512h arg0,
    int arg1,
    __m512h arg2,
    __m512h arg3,
    int arg4,
  ) {
    return __mm512_mask_fmul_round_pch(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_fmul_round_pchPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(__m512h, __mmask16, __m512h, __m512h,
              ffi.Int32)>>('_mm512_mask_fmul_round_pch');
  late final __mm512_mask_fmul_round_pch = __mm512_mask_fmul_round_pchPtr
      .asFunction<__m512h Function(__m512h, int, __m512h, __m512h, int)>();

  __m512h _mm512_maskz_fmul_round_pch(
    int arg0,
    __m512h arg1,
    __m512h arg2,
    int arg3,
  ) {
    return __mm512_maskz_fmul_round_pch(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_fmul_round_pchPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(__mmask16, __m512h, __m512h,
              ffi.Int32)>>('_mm512_maskz_fmul_round_pch');
  late final __mm512_maskz_fmul_round_pch = __mm512_maskz_fmul_round_pchPtr
      .asFunction<__m512h Function(int, __m512h, __m512h, int)>();

  __m128h _mm_fcmul_sch(
    __m128h arg0,
    __m128h arg1,
  ) {
    return __mm_fcmul_sch(
      arg0,
      arg1,
    );
  }

  late final __mm_fcmul_schPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128h, __m128h)>>(
          '_mm_fcmul_sch');
  late final __mm_fcmul_sch =
      __mm_fcmul_schPtr.asFunction<__m128h Function(__m128h, __m128h)>();

  __m128h _mm_mask_fcmul_sch(
    __m128h arg0,
    int arg1,
    __m128h arg2,
    __m128h arg3,
  ) {
    return __mm_mask_fcmul_sch(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_fcmul_schPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __m128h, __mmask8, __m128h, __m128h)>>('_mm_mask_fcmul_sch');
  late final __mm_mask_fcmul_sch = __mm_mask_fcmul_schPtr
      .asFunction<__m128h Function(__m128h, int, __m128h, __m128h)>();

  __m128h _mm_maskz_fcmul_sch(
    int arg0,
    __m128h arg1,
    __m128h arg2,
  ) {
    return __mm_maskz_fcmul_sch(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_fcmul_schPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__mmask8, __m128h, __m128h)>>(
          '_mm_maskz_fcmul_sch');
  late final __mm_maskz_fcmul_sch = __mm_maskz_fcmul_schPtr
      .asFunction<__m128h Function(int, __m128h, __m128h)>();

  __m128h _mm_fcmul_round_sch(
    __m128h arg0,
    __m128h arg1,
    int arg2,
  ) {
    return __mm_fcmul_round_sch(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_fcmul_round_schPtr = _lookup<
          ffi.NativeFunction<__m128h Function(__m128h, __m128h, ffi.Int32)>>(
      '_mm_fcmul_round_sch');
  late final __mm_fcmul_round_sch = __mm_fcmul_round_schPtr
      .asFunction<__m128h Function(__m128h, __m128h, int)>();

  __m128h _mm_mask_fcmul_round_sch(
    __m128h arg0,
    int arg1,
    __m128h arg2,
    __m128h arg3,
    int arg4,
  ) {
    return __mm_mask_fcmul_round_sch(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_fcmul_round_schPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(__m128h, __mmask8, __m128h, __m128h,
              ffi.Int32)>>('_mm_mask_fcmul_round_sch');
  late final __mm_mask_fcmul_round_sch = __mm_mask_fcmul_round_schPtr
      .asFunction<__m128h Function(__m128h, int, __m128h, __m128h, int)>();

  __m128h _mm_maskz_fcmul_round_sch(
    int arg0,
    __m128h arg1,
    __m128h arg2,
    int arg3,
  ) {
    return __mm_maskz_fcmul_round_sch(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_fcmul_round_schPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(__mmask8, __m128h, __m128h,
              ffi.Int32)>>('_mm_maskz_fcmul_round_sch');
  late final __mm_maskz_fcmul_round_sch = __mm_maskz_fcmul_round_schPtr
      .asFunction<__m128h Function(int, __m128h, __m128h, int)>();

  __m128h _mm_fmul_sch(
    __m128h arg0,
    __m128h arg1,
  ) {
    return __mm_fmul_sch(
      arg0,
      arg1,
    );
  }

  late final __mm_fmul_schPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128h, __m128h)>>(
          '_mm_fmul_sch');
  late final __mm_fmul_sch =
      __mm_fmul_schPtr.asFunction<__m128h Function(__m128h, __m128h)>();

  __m128h _mm_mask_fmul_sch(
    __m128h arg0,
    int arg1,
    __m128h arg2,
    __m128h arg3,
  ) {
    return __mm_mask_fmul_sch(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_fmul_schPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __m128h, __mmask8, __m128h, __m128h)>>('_mm_mask_fmul_sch');
  late final __mm_mask_fmul_sch = __mm_mask_fmul_schPtr
      .asFunction<__m128h Function(__m128h, int, __m128h, __m128h)>();

  __m128h _mm_maskz_fmul_sch(
    int arg0,
    __m128h arg1,
    __m128h arg2,
  ) {
    return __mm_maskz_fmul_sch(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_fmul_schPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__mmask8, __m128h, __m128h)>>(
          '_mm_maskz_fmul_sch');
  late final __mm_maskz_fmul_sch = __mm_maskz_fmul_schPtr
      .asFunction<__m128h Function(int, __m128h, __m128h)>();

  __m128h _mm_fmul_round_sch(
    __m128h arg0,
    __m128h arg1,
    int arg2,
  ) {
    return __mm_fmul_round_sch(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_fmul_round_schPtr = _lookup<
          ffi.NativeFunction<__m128h Function(__m128h, __m128h, ffi.Int32)>>(
      '_mm_fmul_round_sch');
  late final __mm_fmul_round_sch = __mm_fmul_round_schPtr
      .asFunction<__m128h Function(__m128h, __m128h, int)>();

  __m128h _mm_mask_fmul_round_sch(
    __m128h arg0,
    int arg1,
    __m128h arg2,
    __m128h arg3,
    int arg4,
  ) {
    return __mm_mask_fmul_round_sch(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_fmul_round_schPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(__m128h, __mmask8, __m128h, __m128h,
              ffi.Int32)>>('_mm_mask_fmul_round_sch');
  late final __mm_mask_fmul_round_sch = __mm_mask_fmul_round_schPtr
      .asFunction<__m128h Function(__m128h, int, __m128h, __m128h, int)>();

  __m128h _mm_maskz_fmul_round_sch(
    int arg0,
    __m128h arg1,
    __m128h arg2,
    int arg3,
  ) {
    return __mm_maskz_fmul_round_sch(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_fmul_round_schPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(__mmask8, __m128h, __m128h,
              ffi.Int32)>>('_mm_maskz_fmul_round_sch');
  late final __mm_maskz_fmul_round_sch = __mm_maskz_fmul_round_schPtr
      .asFunction<__m128h Function(int, __m128h, __m128h, int)>();

  __m128h _mm_fnmadd_ph(
    __m128h arg0,
    __m128h arg1,
    __m128h arg2,
  ) {
    return __mm_fnmadd_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_fnmadd_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128h, __m128h, __m128h)>>(
          '_mm_fnmadd_ph');
  late final __mm_fnmadd_ph = __mm_fnmadd_phPtr
      .asFunction<__m128h Function(__m128h, __m128h, __m128h)>();

  __m128h _mm_mask_fnmadd_ph(
    __m128h arg0,
    int arg1,
    __m128h arg2,
    __m128h arg3,
  ) {
    return __mm_mask_fnmadd_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_fnmadd_phPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __m128h, __mmask8, __m128h, __m128h)>>('_mm_mask_fnmadd_ph');
  late final __mm_mask_fnmadd_ph = __mm_mask_fnmadd_phPtr
      .asFunction<__m128h Function(__m128h, int, __m128h, __m128h)>();

  __m128h _mm_mask3_fnmadd_ph(
    __m128h arg0,
    __m128h arg1,
    __m128h arg2,
    int arg3,
  ) {
    return __mm_mask3_fnmadd_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask3_fnmadd_phPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __m128h, __m128h, __m128h, __mmask8)>>('_mm_mask3_fnmadd_ph');
  late final __mm_mask3_fnmadd_ph = __mm_mask3_fnmadd_phPtr
      .asFunction<__m128h Function(__m128h, __m128h, __m128h, int)>();

  __m128h _mm_maskz_fnmadd_ph(
    int arg0,
    __m128h arg1,
    __m128h arg2,
    __m128h arg3,
  ) {
    return __mm_maskz_fnmadd_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_fnmadd_phPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __mmask8, __m128h, __m128h, __m128h)>>('_mm_maskz_fnmadd_ph');
  late final __mm_maskz_fnmadd_ph = __mm_maskz_fnmadd_phPtr
      .asFunction<__m128h Function(int, __m128h, __m128h, __m128h)>();

  __m256h _mm256_fnmadd_ph(
    __m256h arg0,
    __m256h arg1,
    __m256h arg2,
  ) {
    return __mm256_fnmadd_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_fnmadd_phPtr =
      _lookup<ffi.NativeFunction<__m256h Function(__m256h, __m256h, __m256h)>>(
          '_mm256_fnmadd_ph');
  late final __mm256_fnmadd_ph = __mm256_fnmadd_phPtr
      .asFunction<__m256h Function(__m256h, __m256h, __m256h)>();

  __m256h _mm256_mask_fnmadd_ph(
    __m256h arg0,
    int arg1,
    __m256h arg2,
    __m256h arg3,
  ) {
    return __mm256_mask_fnmadd_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_fnmadd_phPtr = _lookup<
      ffi.NativeFunction<
          __m256h Function(
              __m256h, __mmask16, __m256h, __m256h)>>('_mm256_mask_fnmadd_ph');
  late final __mm256_mask_fnmadd_ph = __mm256_mask_fnmadd_phPtr
      .asFunction<__m256h Function(__m256h, int, __m256h, __m256h)>();

  __m256h _mm256_mask3_fnmadd_ph(
    __m256h arg0,
    __m256h arg1,
    __m256h arg2,
    int arg3,
  ) {
    return __mm256_mask3_fnmadd_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask3_fnmadd_phPtr = _lookup<
      ffi.NativeFunction<
          __m256h Function(
              __m256h, __m256h, __m256h, __mmask16)>>('_mm256_mask3_fnmadd_ph');
  late final __mm256_mask3_fnmadd_ph = __mm256_mask3_fnmadd_phPtr
      .asFunction<__m256h Function(__m256h, __m256h, __m256h, int)>();

  __m256h _mm256_maskz_fnmadd_ph(
    int arg0,
    __m256h arg1,
    __m256h arg2,
    __m256h arg3,
  ) {
    return __mm256_maskz_fnmadd_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_maskz_fnmadd_phPtr = _lookup<
      ffi.NativeFunction<
          __m256h Function(
              __mmask16, __m256h, __m256h, __m256h)>>('_mm256_maskz_fnmadd_ph');
  late final __mm256_maskz_fnmadd_ph = __mm256_maskz_fnmadd_phPtr
      .asFunction<__m256h Function(int, __m256h, __m256h, __m256h)>();

  __m512h _mm512_fnmadd_ph(
    __m512h arg0,
    __m512h arg1,
    __m512h arg2,
  ) {
    return __mm512_fnmadd_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_fnmadd_phPtr =
      _lookup<ffi.NativeFunction<__m512h Function(__m512h, __m512h, __m512h)>>(
          '_mm512_fnmadd_ph');
  late final __mm512_fnmadd_ph = __mm512_fnmadd_phPtr
      .asFunction<__m512h Function(__m512h, __m512h, __m512h)>();

  __m512h _mm512_mask_fnmadd_ph(
    __m512h arg0,
    int arg1,
    __m512h arg2,
    __m512h arg3,
  ) {
    return __mm512_mask_fnmadd_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_fnmadd_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(
              __m512h, __mmask32, __m512h, __m512h)>>('_mm512_mask_fnmadd_ph');
  late final __mm512_mask_fnmadd_ph = __mm512_mask_fnmadd_phPtr
      .asFunction<__m512h Function(__m512h, int, __m512h, __m512h)>();

  __m512h _mm512_mask3_fnmadd_ph(
    __m512h arg0,
    __m512h arg1,
    __m512h arg2,
    int arg3,
  ) {
    return __mm512_mask3_fnmadd_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask3_fnmadd_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(
              __m512h, __m512h, __m512h, __mmask32)>>('_mm512_mask3_fnmadd_ph');
  late final __mm512_mask3_fnmadd_ph = __mm512_mask3_fnmadd_phPtr
      .asFunction<__m512h Function(__m512h, __m512h, __m512h, int)>();

  __m512h _mm512_maskz_fnmadd_ph(
    int arg0,
    __m512h arg1,
    __m512h arg2,
    __m512h arg3,
  ) {
    return __mm512_maskz_fnmadd_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_fnmadd_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(
              __mmask32, __m512h, __m512h, __m512h)>>('_mm512_maskz_fnmadd_ph');
  late final __mm512_maskz_fnmadd_ph = __mm512_maskz_fnmadd_phPtr
      .asFunction<__m512h Function(int, __m512h, __m512h, __m512h)>();

  __m512h _mm512_fnmadd_round_ph(
    __m512h arg0,
    __m512h arg1,
    __m512h arg2,
    int arg3,
  ) {
    return __mm512_fnmadd_round_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_fnmadd_round_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(
              __m512h, __m512h, __m512h, ffi.Int32)>>('_mm512_fnmadd_round_ph');
  late final __mm512_fnmadd_round_ph = __mm512_fnmadd_round_phPtr
      .asFunction<__m512h Function(__m512h, __m512h, __m512h, int)>();

  __m512h _mm512_mask_fnmadd_round_ph(
    __m512h arg0,
    int arg1,
    __m512h arg2,
    __m512h arg3,
    int arg4,
  ) {
    return __mm512_mask_fnmadd_round_ph(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_fnmadd_round_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(__m512h, __mmask32, __m512h, __m512h,
              ffi.Int32)>>('_mm512_mask_fnmadd_round_ph');
  late final __mm512_mask_fnmadd_round_ph = __mm512_mask_fnmadd_round_phPtr
      .asFunction<__m512h Function(__m512h, int, __m512h, __m512h, int)>();

  __m512h _mm512_mask3_fnmadd_round_ph(
    __m512h arg0,
    __m512h arg1,
    __m512h arg2,
    int arg3,
    int arg4,
  ) {
    return __mm512_mask3_fnmadd_round_ph(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask3_fnmadd_round_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(__m512h, __m512h, __m512h, __mmask32,
              ffi.Int32)>>('_mm512_mask3_fnmadd_round_ph');
  late final __mm512_mask3_fnmadd_round_ph = __mm512_mask3_fnmadd_round_phPtr
      .asFunction<__m512h Function(__m512h, __m512h, __m512h, int, int)>();

  __m512h _mm512_maskz_fnmadd_round_ph(
    int arg0,
    __m512h arg1,
    __m512h arg2,
    __m512h arg3,
    int arg4,
  ) {
    return __mm512_maskz_fnmadd_round_ph(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_maskz_fnmadd_round_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(__mmask32, __m512h, __m512h, __m512h,
              ffi.Int32)>>('_mm512_maskz_fnmadd_round_ph');
  late final __mm512_maskz_fnmadd_round_ph = __mm512_maskz_fnmadd_round_phPtr
      .asFunction<__m512h Function(int, __m512h, __m512h, __m512h, int)>();

  __m128h _mm_fmadd_ph(
    __m128h arg0,
    __m128h arg1,
    __m128h arg2,
  ) {
    return __mm_fmadd_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_fmadd_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128h, __m128h, __m128h)>>(
          '_mm_fmadd_ph');
  late final __mm_fmadd_ph = __mm_fmadd_phPtr
      .asFunction<__m128h Function(__m128h, __m128h, __m128h)>();

  __m128h _mm_mask_fmadd_ph(
    __m128h arg0,
    int arg1,
    __m128h arg2,
    __m128h arg3,
  ) {
    return __mm_mask_fmadd_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_fmadd_phPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __m128h, __mmask8, __m128h, __m128h)>>('_mm_mask_fmadd_ph');
  late final __mm_mask_fmadd_ph = __mm_mask_fmadd_phPtr
      .asFunction<__m128h Function(__m128h, int, __m128h, __m128h)>();

  __m128h _mm_mask3_fmadd_ph(
    __m128h arg0,
    __m128h arg1,
    __m128h arg2,
    int arg3,
  ) {
    return __mm_mask3_fmadd_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask3_fmadd_phPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __m128h, __m128h, __m128h, __mmask8)>>('_mm_mask3_fmadd_ph');
  late final __mm_mask3_fmadd_ph = __mm_mask3_fmadd_phPtr
      .asFunction<__m128h Function(__m128h, __m128h, __m128h, int)>();

  __m128h _mm_maskz_fmadd_ph(
    int arg0,
    __m128h arg1,
    __m128h arg2,
    __m128h arg3,
  ) {
    return __mm_maskz_fmadd_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_fmadd_phPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __mmask8, __m128h, __m128h, __m128h)>>('_mm_maskz_fmadd_ph');
  late final __mm_maskz_fmadd_ph = __mm_maskz_fmadd_phPtr
      .asFunction<__m128h Function(int, __m128h, __m128h, __m128h)>();

  __m256h _mm256_fmadd_ph(
    __m256h arg0,
    __m256h arg1,
    __m256h arg2,
  ) {
    return __mm256_fmadd_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_fmadd_phPtr =
      _lookup<ffi.NativeFunction<__m256h Function(__m256h, __m256h, __m256h)>>(
          '_mm256_fmadd_ph');
  late final __mm256_fmadd_ph = __mm256_fmadd_phPtr
      .asFunction<__m256h Function(__m256h, __m256h, __m256h)>();

  __m256h _mm256_mask_fmadd_ph(
    __m256h arg0,
    int arg1,
    __m256h arg2,
    __m256h arg3,
  ) {
    return __mm256_mask_fmadd_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_fmadd_phPtr = _lookup<
      ffi.NativeFunction<
          __m256h Function(
              __m256h, __mmask16, __m256h, __m256h)>>('_mm256_mask_fmadd_ph');
  late final __mm256_mask_fmadd_ph = __mm256_mask_fmadd_phPtr
      .asFunction<__m256h Function(__m256h, int, __m256h, __m256h)>();

  __m256h _mm256_mask3_fmadd_ph(
    __m256h arg0,
    __m256h arg1,
    __m256h arg2,
    int arg3,
  ) {
    return __mm256_mask3_fmadd_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask3_fmadd_phPtr = _lookup<
      ffi.NativeFunction<
          __m256h Function(
              __m256h, __m256h, __m256h, __mmask16)>>('_mm256_mask3_fmadd_ph');
  late final __mm256_mask3_fmadd_ph = __mm256_mask3_fmadd_phPtr
      .asFunction<__m256h Function(__m256h, __m256h, __m256h, int)>();

  __m256h _mm256_maskz_fmadd_ph(
    int arg0,
    __m256h arg1,
    __m256h arg2,
    __m256h arg3,
  ) {
    return __mm256_maskz_fmadd_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_maskz_fmadd_phPtr = _lookup<
      ffi.NativeFunction<
          __m256h Function(
              __mmask16, __m256h, __m256h, __m256h)>>('_mm256_maskz_fmadd_ph');
  late final __mm256_maskz_fmadd_ph = __mm256_maskz_fmadd_phPtr
      .asFunction<__m256h Function(int, __m256h, __m256h, __m256h)>();

  __m512h _mm512_fmadd_ph(
    __m512h arg0,
    __m512h arg1,
    __m512h arg2,
  ) {
    return __mm512_fmadd_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_fmadd_phPtr =
      _lookup<ffi.NativeFunction<__m512h Function(__m512h, __m512h, __m512h)>>(
          '_mm512_fmadd_ph');
  late final __mm512_fmadd_ph = __mm512_fmadd_phPtr
      .asFunction<__m512h Function(__m512h, __m512h, __m512h)>();

  __m512h _mm512_mask_fmadd_ph(
    __m512h arg0,
    int arg1,
    __m512h arg2,
    __m512h arg3,
  ) {
    return __mm512_mask_fmadd_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_fmadd_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(
              __m512h, __mmask32, __m512h, __m512h)>>('_mm512_mask_fmadd_ph');
  late final __mm512_mask_fmadd_ph = __mm512_mask_fmadd_phPtr
      .asFunction<__m512h Function(__m512h, int, __m512h, __m512h)>();

  __m512h _mm512_mask3_fmadd_ph(
    __m512h arg0,
    __m512h arg1,
    __m512h arg2,
    int arg3,
  ) {
    return __mm512_mask3_fmadd_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask3_fmadd_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(
              __m512h, __m512h, __m512h, __mmask32)>>('_mm512_mask3_fmadd_ph');
  late final __mm512_mask3_fmadd_ph = __mm512_mask3_fmadd_phPtr
      .asFunction<__m512h Function(__m512h, __m512h, __m512h, int)>();

  __m512h _mm512_maskz_fmadd_ph(
    int arg0,
    __m512h arg1,
    __m512h arg2,
    __m512h arg3,
  ) {
    return __mm512_maskz_fmadd_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_fmadd_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(
              __mmask32, __m512h, __m512h, __m512h)>>('_mm512_maskz_fmadd_ph');
  late final __mm512_maskz_fmadd_ph = __mm512_maskz_fmadd_phPtr
      .asFunction<__m512h Function(int, __m512h, __m512h, __m512h)>();

  __m512h _mm512_fmadd_round_ph(
    __m512h arg0,
    __m512h arg1,
    __m512h arg2,
    int arg3,
  ) {
    return __mm512_fmadd_round_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_fmadd_round_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(
              __m512h, __m512h, __m512h, ffi.Int32)>>('_mm512_fmadd_round_ph');
  late final __mm512_fmadd_round_ph = __mm512_fmadd_round_phPtr
      .asFunction<__m512h Function(__m512h, __m512h, __m512h, int)>();

  __m512h _mm512_mask_fmadd_round_ph(
    __m512h arg0,
    int arg1,
    __m512h arg2,
    __m512h arg3,
    int arg4,
  ) {
    return __mm512_mask_fmadd_round_ph(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_fmadd_round_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(__m512h, __mmask32, __m512h, __m512h,
              ffi.Int32)>>('_mm512_mask_fmadd_round_ph');
  late final __mm512_mask_fmadd_round_ph = __mm512_mask_fmadd_round_phPtr
      .asFunction<__m512h Function(__m512h, int, __m512h, __m512h, int)>();

  __m512h _mm512_mask3_fmadd_round_ph(
    __m512h arg0,
    __m512h arg1,
    __m512h arg2,
    int arg3,
    int arg4,
  ) {
    return __mm512_mask3_fmadd_round_ph(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask3_fmadd_round_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(__m512h, __m512h, __m512h, __mmask32,
              ffi.Int32)>>('_mm512_mask3_fmadd_round_ph');
  late final __mm512_mask3_fmadd_round_ph = __mm512_mask3_fmadd_round_phPtr
      .asFunction<__m512h Function(__m512h, __m512h, __m512h, int, int)>();

  __m512h _mm512_maskz_fmadd_round_ph(
    int arg0,
    __m512h arg1,
    __m512h arg2,
    __m512h arg3,
    int arg4,
  ) {
    return __mm512_maskz_fmadd_round_ph(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_maskz_fmadd_round_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(__mmask32, __m512h, __m512h, __m512h,
              ffi.Int32)>>('_mm512_maskz_fmadd_round_ph');
  late final __mm512_maskz_fmadd_round_ph = __mm512_maskz_fmadd_round_phPtr
      .asFunction<__m512h Function(int, __m512h, __m512h, __m512h, int)>();

  __m128h _mm_fnmadd_sh(
    __m128h arg0,
    __m128h arg1,
    __m128h arg2,
  ) {
    return __mm_fnmadd_sh(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_fnmadd_shPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128h, __m128h, __m128h)>>(
          '_mm_fnmadd_sh');
  late final __mm_fnmadd_sh = __mm_fnmadd_shPtr
      .asFunction<__m128h Function(__m128h, __m128h, __m128h)>();

  __m128h _mm_mask_fnmadd_sh(
    __m128h arg0,
    int arg1,
    __m128h arg2,
    __m128h arg3,
  ) {
    return __mm_mask_fnmadd_sh(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_fnmadd_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __m128h, __mmask8, __m128h, __m128h)>>('_mm_mask_fnmadd_sh');
  late final __mm_mask_fnmadd_sh = __mm_mask_fnmadd_shPtr
      .asFunction<__m128h Function(__m128h, int, __m128h, __m128h)>();

  __m128h _mm_mask3_fnmadd_sh(
    __m128h arg0,
    __m128h arg1,
    __m128h arg2,
    int arg3,
  ) {
    return __mm_mask3_fnmadd_sh(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask3_fnmadd_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __m128h, __m128h, __m128h, __mmask8)>>('_mm_mask3_fnmadd_sh');
  late final __mm_mask3_fnmadd_sh = __mm_mask3_fnmadd_shPtr
      .asFunction<__m128h Function(__m128h, __m128h, __m128h, int)>();

  __m128h _mm_maskz_fnmadd_sh(
    int arg0,
    __m128h arg1,
    __m128h arg2,
    __m128h arg3,
  ) {
    return __mm_maskz_fnmadd_sh(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_fnmadd_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __mmask8, __m128h, __m128h, __m128h)>>('_mm_maskz_fnmadd_sh');
  late final __mm_maskz_fnmadd_sh = __mm_maskz_fnmadd_shPtr
      .asFunction<__m128h Function(int, __m128h, __m128h, __m128h)>();

  __m128h _mm_fnmadd_round_sh(
    __m128h arg0,
    __m128h arg1,
    __m128h arg2,
    int arg3,
  ) {
    return __mm_fnmadd_round_sh(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_fnmadd_round_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __m128h, __m128h, __m128h, ffi.Int32)>>('_mm_fnmadd_round_sh');
  late final __mm_fnmadd_round_sh = __mm_fnmadd_round_shPtr
      .asFunction<__m128h Function(__m128h, __m128h, __m128h, int)>();

  __m128h _mm_mask_fnmadd_round_sh(
    __m128h arg0,
    int arg1,
    __m128h arg2,
    __m128h arg3,
    int arg4,
  ) {
    return __mm_mask_fnmadd_round_sh(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_fnmadd_round_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(__m128h, __mmask8, __m128h, __m128h,
              ffi.Int32)>>('_mm_mask_fnmadd_round_sh');
  late final __mm_mask_fnmadd_round_sh = __mm_mask_fnmadd_round_shPtr
      .asFunction<__m128h Function(__m128h, int, __m128h, __m128h, int)>();

  __m128h _mm_mask3_fnmadd_round_sh(
    __m128h arg0,
    __m128h arg1,
    __m128h arg2,
    int arg3,
    int arg4,
  ) {
    return __mm_mask3_fnmadd_round_sh(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask3_fnmadd_round_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(__m128h, __m128h, __m128h, __mmask8,
              ffi.Int32)>>('_mm_mask3_fnmadd_round_sh');
  late final __mm_mask3_fnmadd_round_sh = __mm_mask3_fnmadd_round_shPtr
      .asFunction<__m128h Function(__m128h, __m128h, __m128h, int, int)>();

  __m128h _mm_maskz_fnmadd_round_sh(
    int arg0,
    __m128h arg1,
    __m128h arg2,
    __m128h arg3,
    int arg4,
  ) {
    return __mm_maskz_fnmadd_round_sh(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_maskz_fnmadd_round_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(__mmask8, __m128h, __m128h, __m128h,
              ffi.Int32)>>('_mm_maskz_fnmadd_round_sh');
  late final __mm_maskz_fnmadd_round_sh = __mm_maskz_fnmadd_round_shPtr
      .asFunction<__m128h Function(int, __m128h, __m128h, __m128h, int)>();

  __m128h _mm_fmadd_sh(
    __m128h arg0,
    __m128h arg1,
    __m128h arg2,
  ) {
    return __mm_fmadd_sh(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_fmadd_shPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128h, __m128h, __m128h)>>(
          '_mm_fmadd_sh');
  late final __mm_fmadd_sh = __mm_fmadd_shPtr
      .asFunction<__m128h Function(__m128h, __m128h, __m128h)>();

  __m128h _mm_mask_fmadd_sh(
    __m128h arg0,
    int arg1,
    __m128h arg2,
    __m128h arg3,
  ) {
    return __mm_mask_fmadd_sh(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_fmadd_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __m128h, __mmask8, __m128h, __m128h)>>('_mm_mask_fmadd_sh');
  late final __mm_mask_fmadd_sh = __mm_mask_fmadd_shPtr
      .asFunction<__m128h Function(__m128h, int, __m128h, __m128h)>();

  __m128h _mm_mask3_fmadd_sh(
    __m128h arg0,
    __m128h arg1,
    __m128h arg2,
    int arg3,
  ) {
    return __mm_mask3_fmadd_sh(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask3_fmadd_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __m128h, __m128h, __m128h, __mmask8)>>('_mm_mask3_fmadd_sh');
  late final __mm_mask3_fmadd_sh = __mm_mask3_fmadd_shPtr
      .asFunction<__m128h Function(__m128h, __m128h, __m128h, int)>();

  __m128h _mm_maskz_fmadd_sh(
    int arg0,
    __m128h arg1,
    __m128h arg2,
    __m128h arg3,
  ) {
    return __mm_maskz_fmadd_sh(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_fmadd_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __mmask8, __m128h, __m128h, __m128h)>>('_mm_maskz_fmadd_sh');
  late final __mm_maskz_fmadd_sh = __mm_maskz_fmadd_shPtr
      .asFunction<__m128h Function(int, __m128h, __m128h, __m128h)>();

  __m128h _mm_fmadd_round_sh(
    __m128h arg0,
    __m128h arg1,
    __m128h arg2,
    int arg3,
  ) {
    return __mm_fmadd_round_sh(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_fmadd_round_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __m128h, __m128h, __m128h, ffi.Int32)>>('_mm_fmadd_round_sh');
  late final __mm_fmadd_round_sh = __mm_fmadd_round_shPtr
      .asFunction<__m128h Function(__m128h, __m128h, __m128h, int)>();

  __m128h _mm_mask_fmadd_round_sh(
    __m128h arg0,
    int arg1,
    __m128h arg2,
    __m128h arg3,
    int arg4,
  ) {
    return __mm_mask_fmadd_round_sh(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_fmadd_round_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(__m128h, __mmask8, __m128h, __m128h,
              ffi.Int32)>>('_mm_mask_fmadd_round_sh');
  late final __mm_mask_fmadd_round_sh = __mm_mask_fmadd_round_shPtr
      .asFunction<__m128h Function(__m128h, int, __m128h, __m128h, int)>();

  __m128h _mm_mask3_fmadd_round_sh(
    __m128h arg0,
    __m128h arg1,
    __m128h arg2,
    int arg3,
    int arg4,
  ) {
    return __mm_mask3_fmadd_round_sh(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask3_fmadd_round_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(__m128h, __m128h, __m128h, __mmask8,
              ffi.Int32)>>('_mm_mask3_fmadd_round_sh');
  late final __mm_mask3_fmadd_round_sh = __mm_mask3_fmadd_round_shPtr
      .asFunction<__m128h Function(__m128h, __m128h, __m128h, int, int)>();

  __m128h _mm_maskz_fmadd_round_sh(
    int arg0,
    __m128h arg1,
    __m128h arg2,
    __m128h arg3,
    int arg4,
  ) {
    return __mm_maskz_fmadd_round_sh(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_maskz_fmadd_round_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(__mmask8, __m128h, __m128h, __m128h,
              ffi.Int32)>>('_mm_maskz_fmadd_round_sh');
  late final __mm_maskz_fmadd_round_sh = __mm_maskz_fmadd_round_shPtr
      .asFunction<__m128h Function(int, __m128h, __m128h, __m128h, int)>();

  __m128h _mm_fnmsub_ph(
    __m128h arg0,
    __m128h arg1,
    __m128h arg2,
  ) {
    return __mm_fnmsub_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_fnmsub_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128h, __m128h, __m128h)>>(
          '_mm_fnmsub_ph');
  late final __mm_fnmsub_ph = __mm_fnmsub_phPtr
      .asFunction<__m128h Function(__m128h, __m128h, __m128h)>();

  __m128h _mm_mask_fnmsub_ph(
    __m128h arg0,
    int arg1,
    __m128h arg2,
    __m128h arg3,
  ) {
    return __mm_mask_fnmsub_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_fnmsub_phPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __m128h, __mmask8, __m128h, __m128h)>>('_mm_mask_fnmsub_ph');
  late final __mm_mask_fnmsub_ph = __mm_mask_fnmsub_phPtr
      .asFunction<__m128h Function(__m128h, int, __m128h, __m128h)>();

  __m128h _mm_mask3_fnmsub_ph(
    __m128h arg0,
    __m128h arg1,
    __m128h arg2,
    int arg3,
  ) {
    return __mm_mask3_fnmsub_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask3_fnmsub_phPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __m128h, __m128h, __m128h, __mmask8)>>('_mm_mask3_fnmsub_ph');
  late final __mm_mask3_fnmsub_ph = __mm_mask3_fnmsub_phPtr
      .asFunction<__m128h Function(__m128h, __m128h, __m128h, int)>();

  __m128h _mm_maskz_fnmsub_ph(
    int arg0,
    __m128h arg1,
    __m128h arg2,
    __m128h arg3,
  ) {
    return __mm_maskz_fnmsub_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_fnmsub_phPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __mmask8, __m128h, __m128h, __m128h)>>('_mm_maskz_fnmsub_ph');
  late final __mm_maskz_fnmsub_ph = __mm_maskz_fnmsub_phPtr
      .asFunction<__m128h Function(int, __m128h, __m128h, __m128h)>();

  __m256h _mm256_fnmsub_ph(
    __m256h arg0,
    __m256h arg1,
    __m256h arg2,
  ) {
    return __mm256_fnmsub_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_fnmsub_phPtr =
      _lookup<ffi.NativeFunction<__m256h Function(__m256h, __m256h, __m256h)>>(
          '_mm256_fnmsub_ph');
  late final __mm256_fnmsub_ph = __mm256_fnmsub_phPtr
      .asFunction<__m256h Function(__m256h, __m256h, __m256h)>();

  __m256h _mm256_mask_fnmsub_ph(
    __m256h arg0,
    int arg1,
    __m256h arg2,
    __m256h arg3,
  ) {
    return __mm256_mask_fnmsub_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_fnmsub_phPtr = _lookup<
      ffi.NativeFunction<
          __m256h Function(
              __m256h, __mmask16, __m256h, __m256h)>>('_mm256_mask_fnmsub_ph');
  late final __mm256_mask_fnmsub_ph = __mm256_mask_fnmsub_phPtr
      .asFunction<__m256h Function(__m256h, int, __m256h, __m256h)>();

  __m256h _mm256_mask3_fnmsub_ph(
    __m256h arg0,
    __m256h arg1,
    __m256h arg2,
    int arg3,
  ) {
    return __mm256_mask3_fnmsub_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask3_fnmsub_phPtr = _lookup<
      ffi.NativeFunction<
          __m256h Function(
              __m256h, __m256h, __m256h, __mmask16)>>('_mm256_mask3_fnmsub_ph');
  late final __mm256_mask3_fnmsub_ph = __mm256_mask3_fnmsub_phPtr
      .asFunction<__m256h Function(__m256h, __m256h, __m256h, int)>();

  __m256h _mm256_maskz_fnmsub_ph(
    int arg0,
    __m256h arg1,
    __m256h arg2,
    __m256h arg3,
  ) {
    return __mm256_maskz_fnmsub_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_maskz_fnmsub_phPtr = _lookup<
      ffi.NativeFunction<
          __m256h Function(
              __mmask16, __m256h, __m256h, __m256h)>>('_mm256_maskz_fnmsub_ph');
  late final __mm256_maskz_fnmsub_ph = __mm256_maskz_fnmsub_phPtr
      .asFunction<__m256h Function(int, __m256h, __m256h, __m256h)>();

  __m512h _mm512_fnmsub_ph(
    __m512h arg0,
    __m512h arg1,
    __m512h arg2,
  ) {
    return __mm512_fnmsub_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_fnmsub_phPtr =
      _lookup<ffi.NativeFunction<__m512h Function(__m512h, __m512h, __m512h)>>(
          '_mm512_fnmsub_ph');
  late final __mm512_fnmsub_ph = __mm512_fnmsub_phPtr
      .asFunction<__m512h Function(__m512h, __m512h, __m512h)>();

  __m512h _mm512_mask_fnmsub_ph(
    __m512h arg0,
    int arg1,
    __m512h arg2,
    __m512h arg3,
  ) {
    return __mm512_mask_fnmsub_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_fnmsub_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(
              __m512h, __mmask32, __m512h, __m512h)>>('_mm512_mask_fnmsub_ph');
  late final __mm512_mask_fnmsub_ph = __mm512_mask_fnmsub_phPtr
      .asFunction<__m512h Function(__m512h, int, __m512h, __m512h)>();

  __m512h _mm512_mask3_fnmsub_ph(
    __m512h arg0,
    __m512h arg1,
    __m512h arg2,
    int arg3,
  ) {
    return __mm512_mask3_fnmsub_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask3_fnmsub_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(
              __m512h, __m512h, __m512h, __mmask32)>>('_mm512_mask3_fnmsub_ph');
  late final __mm512_mask3_fnmsub_ph = __mm512_mask3_fnmsub_phPtr
      .asFunction<__m512h Function(__m512h, __m512h, __m512h, int)>();

  __m512h _mm512_maskz_fnmsub_ph(
    int arg0,
    __m512h arg1,
    __m512h arg2,
    __m512h arg3,
  ) {
    return __mm512_maskz_fnmsub_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_fnmsub_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(
              __mmask32, __m512h, __m512h, __m512h)>>('_mm512_maskz_fnmsub_ph');
  late final __mm512_maskz_fnmsub_ph = __mm512_maskz_fnmsub_phPtr
      .asFunction<__m512h Function(int, __m512h, __m512h, __m512h)>();

  __m512h _mm512_fnmsub_round_ph(
    __m512h arg0,
    __m512h arg1,
    __m512h arg2,
    int arg3,
  ) {
    return __mm512_fnmsub_round_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_fnmsub_round_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(
              __m512h, __m512h, __m512h, ffi.Int32)>>('_mm512_fnmsub_round_ph');
  late final __mm512_fnmsub_round_ph = __mm512_fnmsub_round_phPtr
      .asFunction<__m512h Function(__m512h, __m512h, __m512h, int)>();

  __m512h _mm512_mask_fnmsub_round_ph(
    __m512h arg0,
    int arg1,
    __m512h arg2,
    __m512h arg3,
    int arg4,
  ) {
    return __mm512_mask_fnmsub_round_ph(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_fnmsub_round_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(__m512h, __mmask32, __m512h, __m512h,
              ffi.Int32)>>('_mm512_mask_fnmsub_round_ph');
  late final __mm512_mask_fnmsub_round_ph = __mm512_mask_fnmsub_round_phPtr
      .asFunction<__m512h Function(__m512h, int, __m512h, __m512h, int)>();

  __m512h _mm512_mask3_fnmsub_round_ph(
    __m512h arg0,
    __m512h arg1,
    __m512h arg2,
    int arg3,
    int arg4,
  ) {
    return __mm512_mask3_fnmsub_round_ph(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask3_fnmsub_round_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(__m512h, __m512h, __m512h, __mmask32,
              ffi.Int32)>>('_mm512_mask3_fnmsub_round_ph');
  late final __mm512_mask3_fnmsub_round_ph = __mm512_mask3_fnmsub_round_phPtr
      .asFunction<__m512h Function(__m512h, __m512h, __m512h, int, int)>();

  __m512h _mm512_maskz_fnmsub_round_ph(
    int arg0,
    __m512h arg1,
    __m512h arg2,
    __m512h arg3,
    int arg4,
  ) {
    return __mm512_maskz_fnmsub_round_ph(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_maskz_fnmsub_round_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(__mmask32, __m512h, __m512h, __m512h,
              ffi.Int32)>>('_mm512_maskz_fnmsub_round_ph');
  late final __mm512_maskz_fnmsub_round_ph = __mm512_maskz_fnmsub_round_phPtr
      .asFunction<__m512h Function(int, __m512h, __m512h, __m512h, int)>();

  __m128h _mm_fmsub_ph(
    __m128h arg0,
    __m128h arg1,
    __m128h arg2,
  ) {
    return __mm_fmsub_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_fmsub_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128h, __m128h, __m128h)>>(
          '_mm_fmsub_ph');
  late final __mm_fmsub_ph = __mm_fmsub_phPtr
      .asFunction<__m128h Function(__m128h, __m128h, __m128h)>();

  __m128h _mm_mask_fmsub_ph(
    __m128h arg0,
    int arg1,
    __m128h arg2,
    __m128h arg3,
  ) {
    return __mm_mask_fmsub_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_fmsub_phPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __m128h, __mmask8, __m128h, __m128h)>>('_mm_mask_fmsub_ph');
  late final __mm_mask_fmsub_ph = __mm_mask_fmsub_phPtr
      .asFunction<__m128h Function(__m128h, int, __m128h, __m128h)>();

  __m128h _mm_mask3_fmsub_ph(
    __m128h arg0,
    __m128h arg1,
    __m128h arg2,
    int arg3,
  ) {
    return __mm_mask3_fmsub_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask3_fmsub_phPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __m128h, __m128h, __m128h, __mmask8)>>('_mm_mask3_fmsub_ph');
  late final __mm_mask3_fmsub_ph = __mm_mask3_fmsub_phPtr
      .asFunction<__m128h Function(__m128h, __m128h, __m128h, int)>();

  __m128h _mm_maskz_fmsub_ph(
    int arg0,
    __m128h arg1,
    __m128h arg2,
    __m128h arg3,
  ) {
    return __mm_maskz_fmsub_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_fmsub_phPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __mmask8, __m128h, __m128h, __m128h)>>('_mm_maskz_fmsub_ph');
  late final __mm_maskz_fmsub_ph = __mm_maskz_fmsub_phPtr
      .asFunction<__m128h Function(int, __m128h, __m128h, __m128h)>();

  __m256h _mm256_fmsub_ph(
    __m256h arg0,
    __m256h arg1,
    __m256h arg2,
  ) {
    return __mm256_fmsub_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_fmsub_phPtr =
      _lookup<ffi.NativeFunction<__m256h Function(__m256h, __m256h, __m256h)>>(
          '_mm256_fmsub_ph');
  late final __mm256_fmsub_ph = __mm256_fmsub_phPtr
      .asFunction<__m256h Function(__m256h, __m256h, __m256h)>();

  __m256h _mm256_mask_fmsub_ph(
    __m256h arg0,
    int arg1,
    __m256h arg2,
    __m256h arg3,
  ) {
    return __mm256_mask_fmsub_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_fmsub_phPtr = _lookup<
      ffi.NativeFunction<
          __m256h Function(
              __m256h, __mmask16, __m256h, __m256h)>>('_mm256_mask_fmsub_ph');
  late final __mm256_mask_fmsub_ph = __mm256_mask_fmsub_phPtr
      .asFunction<__m256h Function(__m256h, int, __m256h, __m256h)>();

  __m256h _mm256_mask3_fmsub_ph(
    __m256h arg0,
    __m256h arg1,
    __m256h arg2,
    int arg3,
  ) {
    return __mm256_mask3_fmsub_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask3_fmsub_phPtr = _lookup<
      ffi.NativeFunction<
          __m256h Function(
              __m256h, __m256h, __m256h, __mmask16)>>('_mm256_mask3_fmsub_ph');
  late final __mm256_mask3_fmsub_ph = __mm256_mask3_fmsub_phPtr
      .asFunction<__m256h Function(__m256h, __m256h, __m256h, int)>();

  __m256h _mm256_maskz_fmsub_ph(
    int arg0,
    __m256h arg1,
    __m256h arg2,
    __m256h arg3,
  ) {
    return __mm256_maskz_fmsub_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_maskz_fmsub_phPtr = _lookup<
      ffi.NativeFunction<
          __m256h Function(
              __mmask16, __m256h, __m256h, __m256h)>>('_mm256_maskz_fmsub_ph');
  late final __mm256_maskz_fmsub_ph = __mm256_maskz_fmsub_phPtr
      .asFunction<__m256h Function(int, __m256h, __m256h, __m256h)>();

  __m512h _mm512_fmsub_ph(
    __m512h arg0,
    __m512h arg1,
    __m512h arg2,
  ) {
    return __mm512_fmsub_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_fmsub_phPtr =
      _lookup<ffi.NativeFunction<__m512h Function(__m512h, __m512h, __m512h)>>(
          '_mm512_fmsub_ph');
  late final __mm512_fmsub_ph = __mm512_fmsub_phPtr
      .asFunction<__m512h Function(__m512h, __m512h, __m512h)>();

  __m512h _mm512_mask_fmsub_ph(
    __m512h arg0,
    int arg1,
    __m512h arg2,
    __m512h arg3,
  ) {
    return __mm512_mask_fmsub_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_fmsub_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(
              __m512h, __mmask32, __m512h, __m512h)>>('_mm512_mask_fmsub_ph');
  late final __mm512_mask_fmsub_ph = __mm512_mask_fmsub_phPtr
      .asFunction<__m512h Function(__m512h, int, __m512h, __m512h)>();

  __m512h _mm512_mask3_fmsub_ph(
    __m512h arg0,
    __m512h arg1,
    __m512h arg2,
    int arg3,
  ) {
    return __mm512_mask3_fmsub_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask3_fmsub_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(
              __m512h, __m512h, __m512h, __mmask32)>>('_mm512_mask3_fmsub_ph');
  late final __mm512_mask3_fmsub_ph = __mm512_mask3_fmsub_phPtr
      .asFunction<__m512h Function(__m512h, __m512h, __m512h, int)>();

  __m512h _mm512_maskz_fmsub_ph(
    int arg0,
    __m512h arg1,
    __m512h arg2,
    __m512h arg3,
  ) {
    return __mm512_maskz_fmsub_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_fmsub_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(
              __mmask32, __m512h, __m512h, __m512h)>>('_mm512_maskz_fmsub_ph');
  late final __mm512_maskz_fmsub_ph = __mm512_maskz_fmsub_phPtr
      .asFunction<__m512h Function(int, __m512h, __m512h, __m512h)>();

  __m512h _mm512_fmsub_round_ph(
    __m512h arg0,
    __m512h arg1,
    __m512h arg2,
    int arg3,
  ) {
    return __mm512_fmsub_round_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_fmsub_round_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(
              __m512h, __m512h, __m512h, ffi.Int32)>>('_mm512_fmsub_round_ph');
  late final __mm512_fmsub_round_ph = __mm512_fmsub_round_phPtr
      .asFunction<__m512h Function(__m512h, __m512h, __m512h, int)>();

  __m512h _mm512_mask_fmsub_round_ph(
    __m512h arg0,
    int arg1,
    __m512h arg2,
    __m512h arg3,
    int arg4,
  ) {
    return __mm512_mask_fmsub_round_ph(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_fmsub_round_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(__m512h, __mmask32, __m512h, __m512h,
              ffi.Int32)>>('_mm512_mask_fmsub_round_ph');
  late final __mm512_mask_fmsub_round_ph = __mm512_mask_fmsub_round_phPtr
      .asFunction<__m512h Function(__m512h, int, __m512h, __m512h, int)>();

  __m512h _mm512_mask3_fmsub_round_ph(
    __m512h arg0,
    __m512h arg1,
    __m512h arg2,
    int arg3,
    int arg4,
  ) {
    return __mm512_mask3_fmsub_round_ph(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask3_fmsub_round_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(__m512h, __m512h, __m512h, __mmask32,
              ffi.Int32)>>('_mm512_mask3_fmsub_round_ph');
  late final __mm512_mask3_fmsub_round_ph = __mm512_mask3_fmsub_round_phPtr
      .asFunction<__m512h Function(__m512h, __m512h, __m512h, int, int)>();

  __m512h _mm512_maskz_fmsub_round_ph(
    int arg0,
    __m512h arg1,
    __m512h arg2,
    __m512h arg3,
    int arg4,
  ) {
    return __mm512_maskz_fmsub_round_ph(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_maskz_fmsub_round_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(__mmask32, __m512h, __m512h, __m512h,
              ffi.Int32)>>('_mm512_maskz_fmsub_round_ph');
  late final __mm512_maskz_fmsub_round_ph = __mm512_maskz_fmsub_round_phPtr
      .asFunction<__m512h Function(int, __m512h, __m512h, __m512h, int)>();

  __m128h _mm_fnmsub_sh(
    __m128h arg0,
    __m128h arg1,
    __m128h arg2,
  ) {
    return __mm_fnmsub_sh(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_fnmsub_shPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128h, __m128h, __m128h)>>(
          '_mm_fnmsub_sh');
  late final __mm_fnmsub_sh = __mm_fnmsub_shPtr
      .asFunction<__m128h Function(__m128h, __m128h, __m128h)>();

  __m128h _mm_mask_fnmsub_sh(
    __m128h arg0,
    int arg1,
    __m128h arg2,
    __m128h arg3,
  ) {
    return __mm_mask_fnmsub_sh(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_fnmsub_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __m128h, __mmask8, __m128h, __m128h)>>('_mm_mask_fnmsub_sh');
  late final __mm_mask_fnmsub_sh = __mm_mask_fnmsub_shPtr
      .asFunction<__m128h Function(__m128h, int, __m128h, __m128h)>();

  __m128h _mm_mask3_fnmsub_sh(
    __m128h arg0,
    __m128h arg1,
    __m128h arg2,
    int arg3,
  ) {
    return __mm_mask3_fnmsub_sh(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask3_fnmsub_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __m128h, __m128h, __m128h, __mmask8)>>('_mm_mask3_fnmsub_sh');
  late final __mm_mask3_fnmsub_sh = __mm_mask3_fnmsub_shPtr
      .asFunction<__m128h Function(__m128h, __m128h, __m128h, int)>();

  __m128h _mm_maskz_fnmsub_sh(
    int arg0,
    __m128h arg1,
    __m128h arg2,
    __m128h arg3,
  ) {
    return __mm_maskz_fnmsub_sh(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_fnmsub_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __mmask8, __m128h, __m128h, __m128h)>>('_mm_maskz_fnmsub_sh');
  late final __mm_maskz_fnmsub_sh = __mm_maskz_fnmsub_shPtr
      .asFunction<__m128h Function(int, __m128h, __m128h, __m128h)>();

  __m128h _mm_fnmsub_round_sh(
    __m128h arg0,
    __m128h arg1,
    __m128h arg2,
    int arg3,
  ) {
    return __mm_fnmsub_round_sh(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_fnmsub_round_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __m128h, __m128h, __m128h, ffi.Int32)>>('_mm_fnmsub_round_sh');
  late final __mm_fnmsub_round_sh = __mm_fnmsub_round_shPtr
      .asFunction<__m128h Function(__m128h, __m128h, __m128h, int)>();

  __m128h _mm_mask_fnmsub_round_sh(
    __m128h arg0,
    int arg1,
    __m128h arg2,
    __m128h arg3,
    int arg4,
  ) {
    return __mm_mask_fnmsub_round_sh(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_fnmsub_round_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(__m128h, __mmask8, __m128h, __m128h,
              ffi.Int32)>>('_mm_mask_fnmsub_round_sh');
  late final __mm_mask_fnmsub_round_sh = __mm_mask_fnmsub_round_shPtr
      .asFunction<__m128h Function(__m128h, int, __m128h, __m128h, int)>();

  __m128h _mm_mask3_fnmsub_round_sh(
    __m128h arg0,
    __m128h arg1,
    __m128h arg2,
    int arg3,
    int arg4,
  ) {
    return __mm_mask3_fnmsub_round_sh(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask3_fnmsub_round_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(__m128h, __m128h, __m128h, __mmask8,
              ffi.Int32)>>('_mm_mask3_fnmsub_round_sh');
  late final __mm_mask3_fnmsub_round_sh = __mm_mask3_fnmsub_round_shPtr
      .asFunction<__m128h Function(__m128h, __m128h, __m128h, int, int)>();

  __m128h _mm_maskz_fnmsub_round_sh(
    int arg0,
    __m128h arg1,
    __m128h arg2,
    __m128h arg3,
    int arg4,
  ) {
    return __mm_maskz_fnmsub_round_sh(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_maskz_fnmsub_round_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(__mmask8, __m128h, __m128h, __m128h,
              ffi.Int32)>>('_mm_maskz_fnmsub_round_sh');
  late final __mm_maskz_fnmsub_round_sh = __mm_maskz_fnmsub_round_shPtr
      .asFunction<__m128h Function(int, __m128h, __m128h, __m128h, int)>();

  __m128h _mm_fmsub_sh(
    __m128h arg0,
    __m128h arg1,
    __m128h arg2,
  ) {
    return __mm_fmsub_sh(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_fmsub_shPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128h, __m128h, __m128h)>>(
          '_mm_fmsub_sh');
  late final __mm_fmsub_sh = __mm_fmsub_shPtr
      .asFunction<__m128h Function(__m128h, __m128h, __m128h)>();

  __m128h _mm_mask_fmsub_sh(
    __m128h arg0,
    int arg1,
    __m128h arg2,
    __m128h arg3,
  ) {
    return __mm_mask_fmsub_sh(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_fmsub_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __m128h, __mmask8, __m128h, __m128h)>>('_mm_mask_fmsub_sh');
  late final __mm_mask_fmsub_sh = __mm_mask_fmsub_shPtr
      .asFunction<__m128h Function(__m128h, int, __m128h, __m128h)>();

  __m128h _mm_mask3_fmsub_sh(
    __m128h arg0,
    __m128h arg1,
    __m128h arg2,
    int arg3,
  ) {
    return __mm_mask3_fmsub_sh(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask3_fmsub_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __m128h, __m128h, __m128h, __mmask8)>>('_mm_mask3_fmsub_sh');
  late final __mm_mask3_fmsub_sh = __mm_mask3_fmsub_shPtr
      .asFunction<__m128h Function(__m128h, __m128h, __m128h, int)>();

  __m128h _mm_maskz_fmsub_sh(
    int arg0,
    __m128h arg1,
    __m128h arg2,
    __m128h arg3,
  ) {
    return __mm_maskz_fmsub_sh(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_fmsub_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __mmask8, __m128h, __m128h, __m128h)>>('_mm_maskz_fmsub_sh');
  late final __mm_maskz_fmsub_sh = __mm_maskz_fmsub_shPtr
      .asFunction<__m128h Function(int, __m128h, __m128h, __m128h)>();

  __m128h _mm_fmsub_round_sh(
    __m128h arg0,
    __m128h arg1,
    __m128h arg2,
    int arg3,
  ) {
    return __mm_fmsub_round_sh(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_fmsub_round_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __m128h, __m128h, __m128h, ffi.Int32)>>('_mm_fmsub_round_sh');
  late final __mm_fmsub_round_sh = __mm_fmsub_round_shPtr
      .asFunction<__m128h Function(__m128h, __m128h, __m128h, int)>();

  __m128h _mm_mask_fmsub_round_sh(
    __m128h arg0,
    int arg1,
    __m128h arg2,
    __m128h arg3,
    int arg4,
  ) {
    return __mm_mask_fmsub_round_sh(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_fmsub_round_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(__m128h, __mmask8, __m128h, __m128h,
              ffi.Int32)>>('_mm_mask_fmsub_round_sh');
  late final __mm_mask_fmsub_round_sh = __mm_mask_fmsub_round_shPtr
      .asFunction<__m128h Function(__m128h, int, __m128h, __m128h, int)>();

  __m128h _mm_mask3_fmsub_round_sh(
    __m128h arg0,
    __m128h arg1,
    __m128h arg2,
    int arg3,
    int arg4,
  ) {
    return __mm_mask3_fmsub_round_sh(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask3_fmsub_round_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(__m128h, __m128h, __m128h, __mmask8,
              ffi.Int32)>>('_mm_mask3_fmsub_round_sh');
  late final __mm_mask3_fmsub_round_sh = __mm_mask3_fmsub_round_shPtr
      .asFunction<__m128h Function(__m128h, __m128h, __m128h, int, int)>();

  __m128h _mm_maskz_fmsub_round_sh(
    int arg0,
    __m128h arg1,
    __m128h arg2,
    __m128h arg3,
    int arg4,
  ) {
    return __mm_maskz_fmsub_round_sh(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_maskz_fmsub_round_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(__mmask8, __m128h, __m128h, __m128h,
              ffi.Int32)>>('_mm_maskz_fmsub_round_sh');
  late final __mm_maskz_fmsub_round_sh = __mm_maskz_fmsub_round_shPtr
      .asFunction<__m128h Function(int, __m128h, __m128h, __m128h, int)>();

  __m128h _mm_getexp_ph(
    __m128h arg0,
  ) {
    return __mm_getexp_ph(
      arg0,
    );
  }

  late final __mm_getexp_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128h)>>('_mm_getexp_ph');
  late final __mm_getexp_ph =
      __mm_getexp_phPtr.asFunction<__m128h Function(__m128h)>();

  __m128h _mm_mask_getexp_ph(
    __m128h arg0,
    int arg1,
    __m128h arg2,
  ) {
    return __mm_mask_getexp_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_getexp_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128h, __mmask8, __m128h)>>(
          '_mm_mask_getexp_ph');
  late final __mm_mask_getexp_ph = __mm_mask_getexp_phPtr
      .asFunction<__m128h Function(__m128h, int, __m128h)>();

  __m128h _mm_maskz_getexp_ph(
    int arg0,
    __m128h arg1,
  ) {
    return __mm_maskz_getexp_ph(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_getexp_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__mmask8, __m128h)>>(
          '_mm_maskz_getexp_ph');
  late final __mm_maskz_getexp_ph =
      __mm_maskz_getexp_phPtr.asFunction<__m128h Function(int, __m128h)>();

  __m256h _mm256_getexp_ph(
    __m256h arg0,
  ) {
    return __mm256_getexp_ph(
      arg0,
    );
  }

  late final __mm256_getexp_phPtr =
      _lookup<ffi.NativeFunction<__m256h Function(__m256h)>>(
          '_mm256_getexp_ph');
  late final __mm256_getexp_ph =
      __mm256_getexp_phPtr.asFunction<__m256h Function(__m256h)>();

  __m256h _mm256_mask_getexp_ph(
    __m256h arg0,
    int arg1,
    __m256h arg2,
  ) {
    return __mm256_mask_getexp_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_getexp_phPtr = _lookup<
          ffi.NativeFunction<__m256h Function(__m256h, __mmask16, __m256h)>>(
      '_mm256_mask_getexp_ph');
  late final __mm256_mask_getexp_ph = __mm256_mask_getexp_phPtr
      .asFunction<__m256h Function(__m256h, int, __m256h)>();

  __m256h _mm256_maskz_getexp_ph(
    int arg0,
    __m256h arg1,
  ) {
    return __mm256_maskz_getexp_ph(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_getexp_phPtr =
      _lookup<ffi.NativeFunction<__m256h Function(__mmask16, __m256h)>>(
          '_mm256_maskz_getexp_ph');
  late final __mm256_maskz_getexp_ph =
      __mm256_maskz_getexp_phPtr.asFunction<__m256h Function(int, __m256h)>();

  __m512h _mm512_getexp_ph(
    __m512h arg0,
  ) {
    return __mm512_getexp_ph(
      arg0,
    );
  }

  late final __mm512_getexp_phPtr =
      _lookup<ffi.NativeFunction<__m512h Function(__m512h)>>(
          '_mm512_getexp_ph');
  late final __mm512_getexp_ph =
      __mm512_getexp_phPtr.asFunction<__m512h Function(__m512h)>();

  __m512h _mm512_mask_getexp_ph(
    __m512h arg0,
    int arg1,
    __m512h arg2,
  ) {
    return __mm512_mask_getexp_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_getexp_phPtr = _lookup<
          ffi.NativeFunction<__m512h Function(__m512h, __mmask32, __m512h)>>(
      '_mm512_mask_getexp_ph');
  late final __mm512_mask_getexp_ph = __mm512_mask_getexp_phPtr
      .asFunction<__m512h Function(__m512h, int, __m512h)>();

  __m512h _mm512_maskz_getexp_ph(
    int arg0,
    __m512h arg1,
  ) {
    return __mm512_maskz_getexp_ph(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_getexp_phPtr =
      _lookup<ffi.NativeFunction<__m512h Function(__mmask32, __m512h)>>(
          '_mm512_maskz_getexp_ph');
  late final __mm512_maskz_getexp_ph =
      __mm512_maskz_getexp_phPtr.asFunction<__m512h Function(int, __m512h)>();

  __m512h _mm512_getexp_round_ph(
    __m512h arg0,
    int arg1,
  ) {
    return __mm512_getexp_round_ph(
      arg0,
      arg1,
    );
  }

  late final __mm512_getexp_round_phPtr =
      _lookup<ffi.NativeFunction<__m512h Function(__m512h, ffi.Int32)>>(
          '_mm512_getexp_round_ph');
  late final __mm512_getexp_round_ph =
      __mm512_getexp_round_phPtr.asFunction<__m512h Function(__m512h, int)>();

  __m512h _mm512_mask_getexp_round_ph(
    __m512h arg0,
    int arg1,
    __m512h arg2,
    int arg3,
  ) {
    return __mm512_mask_getexp_round_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_getexp_round_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(__m512h, __mmask32, __m512h,
              ffi.Int32)>>('_mm512_mask_getexp_round_ph');
  late final __mm512_mask_getexp_round_ph = __mm512_mask_getexp_round_phPtr
      .asFunction<__m512h Function(__m512h, int, __m512h, int)>();

  __m512h _mm512_maskz_getexp_round_ph(
    int arg0,
    __m512h arg1,
    int arg2,
  ) {
    return __mm512_maskz_getexp_round_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_getexp_round_phPtr = _lookup<
          ffi.NativeFunction<__m512h Function(__mmask32, __m512h, ffi.Int32)>>(
      '_mm512_maskz_getexp_round_ph');
  late final __mm512_maskz_getexp_round_ph = __mm512_maskz_getexp_round_phPtr
      .asFunction<__m512h Function(int, __m512h, int)>();

  __m128h _mm_getexp_sh(
    __m128h arg0,
    __m128h arg1,
  ) {
    return __mm_getexp_sh(
      arg0,
      arg1,
    );
  }

  late final __mm_getexp_shPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128h, __m128h)>>(
          '_mm_getexp_sh');
  late final __mm_getexp_sh =
      __mm_getexp_shPtr.asFunction<__m128h Function(__m128h, __m128h)>();

  __m128h _mm_mask_getexp_sh(
    __m128h arg0,
    int arg1,
    __m128h arg2,
    __m128h arg3,
  ) {
    return __mm_mask_getexp_sh(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_getexp_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __m128h, __mmask8, __m128h, __m128h)>>('_mm_mask_getexp_sh');
  late final __mm_mask_getexp_sh = __mm_mask_getexp_shPtr
      .asFunction<__m128h Function(__m128h, int, __m128h, __m128h)>();

  __m128h _mm_maskz_getexp_sh(
    int arg0,
    __m128h arg1,
    __m128h arg2,
  ) {
    return __mm_maskz_getexp_sh(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_getexp_shPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__mmask8, __m128h, __m128h)>>(
          '_mm_maskz_getexp_sh');
  late final __mm_maskz_getexp_sh = __mm_maskz_getexp_shPtr
      .asFunction<__m128h Function(int, __m128h, __m128h)>();

  __m128h _mm_getexp_round_sh(
    __m128h arg0,
    __m128h arg1,
    int arg2,
  ) {
    return __mm_getexp_round_sh(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_getexp_round_shPtr = _lookup<
          ffi.NativeFunction<__m128h Function(__m128h, __m128h, ffi.Int32)>>(
      '_mm_getexp_round_sh');
  late final __mm_getexp_round_sh = __mm_getexp_round_shPtr
      .asFunction<__m128h Function(__m128h, __m128h, int)>();

  __m128h _mm_mask_getexp_round_sh(
    __m128h arg0,
    int arg1,
    __m128h arg2,
    __m128h arg3,
    int arg4,
  ) {
    return __mm_mask_getexp_round_sh(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_getexp_round_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(__m128h, __mmask8, __m128h, __m128h,
              ffi.Int32)>>('_mm_mask_getexp_round_sh');
  late final __mm_mask_getexp_round_sh = __mm_mask_getexp_round_shPtr
      .asFunction<__m128h Function(__m128h, int, __m128h, __m128h, int)>();

  __m128h _mm_maskz_getexp_round_sh(
    int arg0,
    __m128h arg1,
    __m128h arg2,
    int arg3,
  ) {
    return __mm_maskz_getexp_round_sh(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_getexp_round_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(__mmask8, __m128h, __m128h,
              ffi.Int32)>>('_mm_maskz_getexp_round_sh');
  late final __mm_maskz_getexp_round_sh = __mm_maskz_getexp_round_shPtr
      .asFunction<__m128h Function(int, __m128h, __m128h, int)>();

  __m128h _mm_getmant_ph(
    __m128h arg0,
    int arg1,
    int arg2,
  ) {
    return __mm_getmant_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_getmant_phPtr = _lookup<
          ffi.NativeFunction<__m128h Function(__m128h, ffi.Int32, ffi.Int32)>>(
      '_mm_getmant_ph');
  late final __mm_getmant_ph =
      __mm_getmant_phPtr.asFunction<__m128h Function(__m128h, int, int)>();

  __m128h _mm_mask_getmant_ph(
    __m128h arg0,
    int arg1,
    __m128h arg2,
    int arg3,
    int arg4,
  ) {
    return __mm_mask_getmant_ph(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_getmant_phPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(__m128h, __mmask8, __m128h, ffi.Int32,
              ffi.Int32)>>('_mm_mask_getmant_ph');
  late final __mm_mask_getmant_ph = __mm_mask_getmant_phPtr
      .asFunction<__m128h Function(__m128h, int, __m128h, int, int)>();

  __m128h _mm_maskz_getmant_ph(
    int arg0,
    __m128h arg1,
    int arg2,
    int arg3,
  ) {
    return __mm_maskz_getmant_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_getmant_phPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(__mmask8, __m128h, ffi.Int32,
              ffi.Int32)>>('_mm_maskz_getmant_ph');
  late final __mm_maskz_getmant_ph = __mm_maskz_getmant_phPtr
      .asFunction<__m128h Function(int, __m128h, int, int)>();

  __m256h _mm256_getmant_ph(
    __m256h arg0,
    int arg1,
    int arg2,
  ) {
    return __mm256_getmant_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_getmant_phPtr = _lookup<
          ffi.NativeFunction<__m256h Function(__m256h, ffi.Int32, ffi.Int32)>>(
      '_mm256_getmant_ph');
  late final __mm256_getmant_ph =
      __mm256_getmant_phPtr.asFunction<__m256h Function(__m256h, int, int)>();

  __m256h _mm256_mask_getmant_ph(
    __m256h arg0,
    int arg1,
    __m256h arg2,
    int arg3,
    int arg4,
  ) {
    return __mm256_mask_getmant_ph(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm256_mask_getmant_phPtr = _lookup<
      ffi.NativeFunction<
          __m256h Function(__m256h, __mmask16, __m256h, ffi.Int32,
              ffi.Int32)>>('_mm256_mask_getmant_ph');
  late final __mm256_mask_getmant_ph = __mm256_mask_getmant_phPtr
      .asFunction<__m256h Function(__m256h, int, __m256h, int, int)>();

  __m256h _mm256_maskz_getmant_ph(
    int arg0,
    __m256h arg1,
    int arg2,
    int arg3,
  ) {
    return __mm256_maskz_getmant_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_maskz_getmant_phPtr = _lookup<
      ffi.NativeFunction<
          __m256h Function(__mmask16, __m256h, ffi.Int32,
              ffi.Int32)>>('_mm256_maskz_getmant_ph');
  late final __mm256_maskz_getmant_ph = __mm256_maskz_getmant_phPtr
      .asFunction<__m256h Function(int, __m256h, int, int)>();

  __m512h _mm512_getmant_ph(
    __m512h arg0,
    int arg1,
    int arg2,
  ) {
    return __mm512_getmant_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_getmant_phPtr = _lookup<
          ffi.NativeFunction<__m512h Function(__m512h, ffi.Int32, ffi.Int32)>>(
      '_mm512_getmant_ph');
  late final __mm512_getmant_ph =
      __mm512_getmant_phPtr.asFunction<__m512h Function(__m512h, int, int)>();

  __m512h _mm512_mask_getmant_ph(
    __m512h arg0,
    int arg1,
    __m512h arg2,
    int arg3,
    int arg4,
  ) {
    return __mm512_mask_getmant_ph(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_getmant_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(__m512h, __mmask32, __m512h, ffi.Int32,
              ffi.Int32)>>('_mm512_mask_getmant_ph');
  late final __mm512_mask_getmant_ph = __mm512_mask_getmant_phPtr
      .asFunction<__m512h Function(__m512h, int, __m512h, int, int)>();

  __m512h _mm512_maskz_getmant_ph(
    int arg0,
    __m512h arg1,
    int arg2,
    int arg3,
  ) {
    return __mm512_maskz_getmant_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_getmant_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(__mmask32, __m512h, ffi.Int32,
              ffi.Int32)>>('_mm512_maskz_getmant_ph');
  late final __mm512_maskz_getmant_ph = __mm512_maskz_getmant_phPtr
      .asFunction<__m512h Function(int, __m512h, int, int)>();

  __m512h _mm512_getmant_round_ph(
    __m512h arg0,
    int arg1,
    int arg2,
    int arg3,
  ) {
    return __mm512_getmant_round_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_getmant_round_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(__m512h, ffi.Int32, ffi.Int32,
              ffi.Int32)>>('_mm512_getmant_round_ph');
  late final __mm512_getmant_round_ph = __mm512_getmant_round_phPtr
      .asFunction<__m512h Function(__m512h, int, int, int)>();

  __m512h _mm512_mask_getmant_round_ph(
    __m512h arg0,
    int arg1,
    __m512h arg2,
    int arg3,
    int arg4,
    int arg5,
  ) {
    return __mm512_mask_getmant_round_ph(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
      arg5,
    );
  }

  late final __mm512_mask_getmant_round_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(__m512h, __mmask32, __m512h, ffi.Int32, ffi.Int32,
              ffi.Int32)>>('_mm512_mask_getmant_round_ph');
  late final __mm512_mask_getmant_round_ph = __mm512_mask_getmant_round_phPtr
      .asFunction<__m512h Function(__m512h, int, __m512h, int, int, int)>();

  __m512h _mm512_maskz_getmant_round_ph(
    int arg0,
    __m512h arg1,
    int arg2,
    int arg3,
    int arg4,
  ) {
    return __mm512_maskz_getmant_round_ph(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_maskz_getmant_round_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(__mmask32, __m512h, ffi.Int32, ffi.Int32,
              ffi.Int32)>>('_mm512_maskz_getmant_round_ph');
  late final __mm512_maskz_getmant_round_ph = __mm512_maskz_getmant_round_phPtr
      .asFunction<__m512h Function(int, __m512h, int, int, int)>();

  __m128h _mm_getmant_sh(
    __m128h arg0,
    __m128h arg1,
    int arg2,
    int arg3,
  ) {
    return __mm_getmant_sh(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_getmant_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __m128h, __m128h, ffi.Int32, ffi.Int32)>>('_mm_getmant_sh');
  late final __mm_getmant_sh = __mm_getmant_shPtr
      .asFunction<__m128h Function(__m128h, __m128h, int, int)>();

  __m128h _mm_mask_getmant_sh(
    __m128h arg0,
    int arg1,
    __m128h arg2,
    __m128h arg3,
    int arg4,
    int arg5,
  ) {
    return __mm_mask_getmant_sh(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
      arg5,
    );
  }

  late final __mm_mask_getmant_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(__m128h, __mmask8, __m128h, __m128h, ffi.Int32,
              ffi.Int32)>>('_mm_mask_getmant_sh');
  late final __mm_mask_getmant_sh = __mm_mask_getmant_shPtr
      .asFunction<__m128h Function(__m128h, int, __m128h, __m128h, int, int)>();

  __m128h _mm_maskz_getmant_sh(
    int arg0,
    __m128h arg1,
    __m128h arg2,
    int arg3,
    int arg4,
  ) {
    return __mm_maskz_getmant_sh(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_maskz_getmant_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(__mmask8, __m128h, __m128h, ffi.Int32,
              ffi.Int32)>>('_mm_maskz_getmant_sh');
  late final __mm_maskz_getmant_sh = __mm_maskz_getmant_shPtr
      .asFunction<__m128h Function(int, __m128h, __m128h, int, int)>();

  __m128h _mm_getmant_round_sh(
    __m128h arg0,
    __m128h arg1,
    int arg2,
    int arg3,
    int arg4,
  ) {
    return __mm_getmant_round_sh(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_getmant_round_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(__m128h, __m128h, ffi.Int32, ffi.Int32,
              ffi.Int32)>>('_mm_getmant_round_sh');
  late final __mm_getmant_round_sh = __mm_getmant_round_shPtr
      .asFunction<__m128h Function(__m128h, __m128h, int, int, int)>();

  __m128h _mm_mask_getmant_round_sh(
    __m128h arg0,
    int arg1,
    __m128h arg2,
    __m128h arg3,
    int arg4,
    int arg5,
    int arg6,
  ) {
    return __mm_mask_getmant_round_sh(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
      arg5,
      arg6,
    );
  }

  late final __mm_mask_getmant_round_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(__m128h, __mmask8, __m128h, __m128h, ffi.Int32,
              ffi.Int32, ffi.Int32)>>('_mm_mask_getmant_round_sh');
  late final __mm_mask_getmant_round_sh =
      __mm_mask_getmant_round_shPtr.asFunction<
          __m128h Function(__m128h, int, __m128h, __m128h, int, int, int)>();

  __m128h _mm_maskz_getmant_round_sh(
    int arg0,
    __m128h arg1,
    __m128h arg2,
    int arg3,
    int arg4,
    int arg5,
  ) {
    return __mm_maskz_getmant_round_sh(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
      arg5,
    );
  }

  late final __mm_maskz_getmant_round_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(__mmask8, __m128h, __m128h, ffi.Int32, ffi.Int32,
              ffi.Int32)>>('_mm_maskz_getmant_round_sh');
  late final __mm_maskz_getmant_round_sh = __mm_maskz_getmant_round_shPtr
      .asFunction<__m128h Function(int, __m128h, __m128h, int, int, int)>();

  __m128h _mm_max_ph(
    __m128h arg0,
    __m128h arg1,
  ) {
    return __mm_max_ph(
      arg0,
      arg1,
    );
  }

  late final __mm_max_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128h, __m128h)>>(
          '_mm_max_ph');
  late final __mm_max_ph =
      __mm_max_phPtr.asFunction<__m128h Function(__m128h, __m128h)>();

  __m128h _mm_mask_max_ph(
    __m128h arg0,
    int arg1,
    __m128h arg2,
    __m128h arg3,
  ) {
    return __mm_mask_max_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_max_phPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __m128h, __mmask8, __m128h, __m128h)>>('_mm_mask_max_ph');
  late final __mm_mask_max_ph = __mm_mask_max_phPtr
      .asFunction<__m128h Function(__m128h, int, __m128h, __m128h)>();

  __m128h _mm_maskz_max_ph(
    int arg0,
    __m128h arg1,
    __m128h arg2,
  ) {
    return __mm_maskz_max_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_max_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__mmask8, __m128h, __m128h)>>(
          '_mm_maskz_max_ph');
  late final __mm_maskz_max_ph = __mm_maskz_max_phPtr
      .asFunction<__m128h Function(int, __m128h, __m128h)>();

  __m256h _mm256_max_ph(
    __m256h arg0,
    __m256h arg1,
  ) {
    return __mm256_max_ph(
      arg0,
      arg1,
    );
  }

  late final __mm256_max_phPtr =
      _lookup<ffi.NativeFunction<__m256h Function(__m256h, __m256h)>>(
          '_mm256_max_ph');
  late final __mm256_max_ph =
      __mm256_max_phPtr.asFunction<__m256h Function(__m256h, __m256h)>();

  __m256h _mm256_mask_max_ph(
    __m256h arg0,
    int arg1,
    __m256h arg2,
    __m256h arg3,
  ) {
    return __mm256_mask_max_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_max_phPtr = _lookup<
      ffi.NativeFunction<
          __m256h Function(
              __m256h, __mmask16, __m256h, __m256h)>>('_mm256_mask_max_ph');
  late final __mm256_mask_max_ph = __mm256_mask_max_phPtr
      .asFunction<__m256h Function(__m256h, int, __m256h, __m256h)>();

  __m256h _mm256_maskz_max_ph(
    int arg0,
    __m256h arg1,
    __m256h arg2,
  ) {
    return __mm256_maskz_max_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_max_phPtr = _lookup<
          ffi.NativeFunction<__m256h Function(__mmask16, __m256h, __m256h)>>(
      '_mm256_maskz_max_ph');
  late final __mm256_maskz_max_ph = __mm256_maskz_max_phPtr
      .asFunction<__m256h Function(int, __m256h, __m256h)>();

  __m512h _mm512_max_ph(
    __m512h arg0,
    __m512h arg1,
  ) {
    return __mm512_max_ph(
      arg0,
      arg1,
    );
  }

  late final __mm512_max_phPtr =
      _lookup<ffi.NativeFunction<__m512h Function(__m512h, __m512h)>>(
          '_mm512_max_ph');
  late final __mm512_max_ph =
      __mm512_max_phPtr.asFunction<__m512h Function(__m512h, __m512h)>();

  __m512h _mm512_mask_max_ph(
    __m512h arg0,
    int arg1,
    __m512h arg2,
    __m512h arg3,
  ) {
    return __mm512_mask_max_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_max_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(
              __m512h, __mmask32, __m512h, __m512h)>>('_mm512_mask_max_ph');
  late final __mm512_mask_max_ph = __mm512_mask_max_phPtr
      .asFunction<__m512h Function(__m512h, int, __m512h, __m512h)>();

  __m512h _mm512_maskz_max_ph(
    int arg0,
    __m512h arg1,
    __m512h arg2,
  ) {
    return __mm512_maskz_max_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_max_phPtr = _lookup<
          ffi.NativeFunction<__m512h Function(__mmask32, __m512h, __m512h)>>(
      '_mm512_maskz_max_ph');
  late final __mm512_maskz_max_ph = __mm512_maskz_max_phPtr
      .asFunction<__m512h Function(int, __m512h, __m512h)>();

  __m512h _mm512_max_round_ph(
    __m512h arg0,
    __m512h arg1,
    int arg2,
  ) {
    return __mm512_max_round_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_max_round_phPtr = _lookup<
          ffi.NativeFunction<__m512h Function(__m512h, __m512h, ffi.Int32)>>(
      '_mm512_max_round_ph');
  late final __mm512_max_round_ph = __mm512_max_round_phPtr
      .asFunction<__m512h Function(__m512h, __m512h, int)>();

  __m512h _mm512_mask_max_round_ph(
    __m512h arg0,
    int arg1,
    __m512h arg2,
    __m512h arg3,
    int arg4,
  ) {
    return __mm512_mask_max_round_ph(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_max_round_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(__m512h, __mmask32, __m512h, __m512h,
              ffi.Int32)>>('_mm512_mask_max_round_ph');
  late final __mm512_mask_max_round_ph = __mm512_mask_max_round_phPtr
      .asFunction<__m512h Function(__m512h, int, __m512h, __m512h, int)>();

  __m512h _mm512_maskz_max_round_ph(
    int arg0,
    __m512h arg1,
    __m512h arg2,
    int arg3,
  ) {
    return __mm512_maskz_max_round_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_max_round_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(__mmask32, __m512h, __m512h,
              ffi.Int32)>>('_mm512_maskz_max_round_ph');
  late final __mm512_maskz_max_round_ph = __mm512_maskz_max_round_phPtr
      .asFunction<__m512h Function(int, __m512h, __m512h, int)>();

  __m128h _mm_max_sh(
    __m128h arg0,
    __m128h arg1,
  ) {
    return __mm_max_sh(
      arg0,
      arg1,
    );
  }

  late final __mm_max_shPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128h, __m128h)>>(
          '_mm_max_sh');
  late final __mm_max_sh =
      __mm_max_shPtr.asFunction<__m128h Function(__m128h, __m128h)>();

  __m128h _mm_mask_max_sh(
    __m128h arg0,
    int arg1,
    __m128h arg2,
    __m128h arg3,
  ) {
    return __mm_mask_max_sh(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_max_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __m128h, __mmask8, __m128h, __m128h)>>('_mm_mask_max_sh');
  late final __mm_mask_max_sh = __mm_mask_max_shPtr
      .asFunction<__m128h Function(__m128h, int, __m128h, __m128h)>();

  __m128h _mm_maskz_max_sh(
    int arg0,
    __m128h arg1,
    __m128h arg2,
  ) {
    return __mm_maskz_max_sh(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_max_shPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__mmask8, __m128h, __m128h)>>(
          '_mm_maskz_max_sh');
  late final __mm_maskz_max_sh = __mm_maskz_max_shPtr
      .asFunction<__m128h Function(int, __m128h, __m128h)>();

  __m128h _mm_max_round_sh(
    __m128h arg0,
    __m128h arg1,
    int arg2,
  ) {
    return __mm_max_round_sh(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_max_round_shPtr = _lookup<
          ffi.NativeFunction<__m128h Function(__m128h, __m128h, ffi.Int32)>>(
      '_mm_max_round_sh');
  late final __mm_max_round_sh = __mm_max_round_shPtr
      .asFunction<__m128h Function(__m128h, __m128h, int)>();

  __m128h _mm_mask_max_round_sh(
    __m128h arg0,
    int arg1,
    __m128h arg2,
    __m128h arg3,
    int arg4,
  ) {
    return __mm_mask_max_round_sh(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_max_round_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(__m128h, __mmask8, __m128h, __m128h,
              ffi.Int32)>>('_mm_mask_max_round_sh');
  late final __mm_mask_max_round_sh = __mm_mask_max_round_shPtr
      .asFunction<__m128h Function(__m128h, int, __m128h, __m128h, int)>();

  __m128h _mm_maskz_max_round_sh(
    int arg0,
    __m128h arg1,
    __m128h arg2,
    int arg3,
  ) {
    return __mm_maskz_max_round_sh(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_max_round_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(__mmask8, __m128h, __m128h,
              ffi.Int32)>>('_mm_maskz_max_round_sh');
  late final __mm_maskz_max_round_sh = __mm_maskz_max_round_shPtr
      .asFunction<__m128h Function(int, __m128h, __m128h, int)>();

  __m128h _mm_min_ph(
    __m128h arg0,
    __m128h arg1,
  ) {
    return __mm_min_ph(
      arg0,
      arg1,
    );
  }

  late final __mm_min_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128h, __m128h)>>(
          '_mm_min_ph');
  late final __mm_min_ph =
      __mm_min_phPtr.asFunction<__m128h Function(__m128h, __m128h)>();

  __m128h _mm_mask_min_ph(
    __m128h arg0,
    int arg1,
    __m128h arg2,
    __m128h arg3,
  ) {
    return __mm_mask_min_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_min_phPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __m128h, __mmask8, __m128h, __m128h)>>('_mm_mask_min_ph');
  late final __mm_mask_min_ph = __mm_mask_min_phPtr
      .asFunction<__m128h Function(__m128h, int, __m128h, __m128h)>();

  __m128h _mm_maskz_min_ph(
    int arg0,
    __m128h arg1,
    __m128h arg2,
  ) {
    return __mm_maskz_min_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_min_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__mmask8, __m128h, __m128h)>>(
          '_mm_maskz_min_ph');
  late final __mm_maskz_min_ph = __mm_maskz_min_phPtr
      .asFunction<__m128h Function(int, __m128h, __m128h)>();

  __m256h _mm256_min_ph(
    __m256h arg0,
    __m256h arg1,
  ) {
    return __mm256_min_ph(
      arg0,
      arg1,
    );
  }

  late final __mm256_min_phPtr =
      _lookup<ffi.NativeFunction<__m256h Function(__m256h, __m256h)>>(
          '_mm256_min_ph');
  late final __mm256_min_ph =
      __mm256_min_phPtr.asFunction<__m256h Function(__m256h, __m256h)>();

  __m256h _mm256_mask_min_ph(
    __m256h arg0,
    int arg1,
    __m256h arg2,
    __m256h arg3,
  ) {
    return __mm256_mask_min_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_min_phPtr = _lookup<
      ffi.NativeFunction<
          __m256h Function(
              __m256h, __mmask16, __m256h, __m256h)>>('_mm256_mask_min_ph');
  late final __mm256_mask_min_ph = __mm256_mask_min_phPtr
      .asFunction<__m256h Function(__m256h, int, __m256h, __m256h)>();

  __m256h _mm256_maskz_min_ph(
    int arg0,
    __m256h arg1,
    __m256h arg2,
  ) {
    return __mm256_maskz_min_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_min_phPtr = _lookup<
          ffi.NativeFunction<__m256h Function(__mmask16, __m256h, __m256h)>>(
      '_mm256_maskz_min_ph');
  late final __mm256_maskz_min_ph = __mm256_maskz_min_phPtr
      .asFunction<__m256h Function(int, __m256h, __m256h)>();

  __m512h _mm512_min_ph(
    __m512h arg0,
    __m512h arg1,
  ) {
    return __mm512_min_ph(
      arg0,
      arg1,
    );
  }

  late final __mm512_min_phPtr =
      _lookup<ffi.NativeFunction<__m512h Function(__m512h, __m512h)>>(
          '_mm512_min_ph');
  late final __mm512_min_ph =
      __mm512_min_phPtr.asFunction<__m512h Function(__m512h, __m512h)>();

  __m512h _mm512_mask_min_ph(
    __m512h arg0,
    int arg1,
    __m512h arg2,
    __m512h arg3,
  ) {
    return __mm512_mask_min_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_min_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(
              __m512h, __mmask32, __m512h, __m512h)>>('_mm512_mask_min_ph');
  late final __mm512_mask_min_ph = __mm512_mask_min_phPtr
      .asFunction<__m512h Function(__m512h, int, __m512h, __m512h)>();

  __m512h _mm512_maskz_min_ph(
    int arg0,
    __m512h arg1,
    __m512h arg2,
  ) {
    return __mm512_maskz_min_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_min_phPtr = _lookup<
          ffi.NativeFunction<__m512h Function(__mmask32, __m512h, __m512h)>>(
      '_mm512_maskz_min_ph');
  late final __mm512_maskz_min_ph = __mm512_maskz_min_phPtr
      .asFunction<__m512h Function(int, __m512h, __m512h)>();

  __m512h _mm512_min_round_ph(
    __m512h arg0,
    __m512h arg1,
    int arg2,
  ) {
    return __mm512_min_round_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_min_round_phPtr = _lookup<
          ffi.NativeFunction<__m512h Function(__m512h, __m512h, ffi.Int32)>>(
      '_mm512_min_round_ph');
  late final __mm512_min_round_ph = __mm512_min_round_phPtr
      .asFunction<__m512h Function(__m512h, __m512h, int)>();

  __m512h _mm512_mask_min_round_ph(
    __m512h arg0,
    int arg1,
    __m512h arg2,
    __m512h arg3,
    int arg4,
  ) {
    return __mm512_mask_min_round_ph(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_min_round_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(__m512h, __mmask32, __m512h, __m512h,
              ffi.Int32)>>('_mm512_mask_min_round_ph');
  late final __mm512_mask_min_round_ph = __mm512_mask_min_round_phPtr
      .asFunction<__m512h Function(__m512h, int, __m512h, __m512h, int)>();

  __m512h _mm512_maskz_min_round_ph(
    int arg0,
    __m512h arg1,
    __m512h arg2,
    int arg3,
  ) {
    return __mm512_maskz_min_round_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_min_round_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(__mmask32, __m512h, __m512h,
              ffi.Int32)>>('_mm512_maskz_min_round_ph');
  late final __mm512_maskz_min_round_ph = __mm512_maskz_min_round_phPtr
      .asFunction<__m512h Function(int, __m512h, __m512h, int)>();

  __m128h _mm_min_sh(
    __m128h arg0,
    __m128h arg1,
  ) {
    return __mm_min_sh(
      arg0,
      arg1,
    );
  }

  late final __mm_min_shPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128h, __m128h)>>(
          '_mm_min_sh');
  late final __mm_min_sh =
      __mm_min_shPtr.asFunction<__m128h Function(__m128h, __m128h)>();

  __m128h _mm_mask_min_sh(
    __m128h arg0,
    int arg1,
    __m128h arg2,
    __m128h arg3,
  ) {
    return __mm_mask_min_sh(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_min_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __m128h, __mmask8, __m128h, __m128h)>>('_mm_mask_min_sh');
  late final __mm_mask_min_sh = __mm_mask_min_shPtr
      .asFunction<__m128h Function(__m128h, int, __m128h, __m128h)>();

  __m128h _mm_maskz_min_sh(
    int arg0,
    __m128h arg1,
    __m128h arg2,
  ) {
    return __mm_maskz_min_sh(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_min_shPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__mmask8, __m128h, __m128h)>>(
          '_mm_maskz_min_sh');
  late final __mm_maskz_min_sh = __mm_maskz_min_shPtr
      .asFunction<__m128h Function(int, __m128h, __m128h)>();

  __m128h _mm_min_round_sh(
    __m128h arg0,
    __m128h arg1,
    int arg2,
  ) {
    return __mm_min_round_sh(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_min_round_shPtr = _lookup<
          ffi.NativeFunction<__m128h Function(__m128h, __m128h, ffi.Int32)>>(
      '_mm_min_round_sh');
  late final __mm_min_round_sh = __mm_min_round_shPtr
      .asFunction<__m128h Function(__m128h, __m128h, int)>();

  __m128h _mm_mask_min_round_sh(
    __m128h arg0,
    int arg1,
    __m128h arg2,
    __m128h arg3,
    int arg4,
  ) {
    return __mm_mask_min_round_sh(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_min_round_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(__m128h, __mmask8, __m128h, __m128h,
              ffi.Int32)>>('_mm_mask_min_round_sh');
  late final __mm_mask_min_round_sh = __mm_mask_min_round_shPtr
      .asFunction<__m128h Function(__m128h, int, __m128h, __m128h, int)>();

  __m128h _mm_maskz_min_round_sh(
    int arg0,
    __m128h arg1,
    __m128h arg2,
    int arg3,
  ) {
    return __mm_maskz_min_round_sh(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_min_round_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(__mmask8, __m128h, __m128h,
              ffi.Int32)>>('_mm_maskz_min_round_sh');
  late final __mm_maskz_min_round_sh = __mm_maskz_min_round_shPtr
      .asFunction<__m128h Function(int, __m128h, __m128h, int)>();

  __m128h _mm_load_sh(
    ffi.Pointer<ffi.Void> arg0,
  ) {
    return __mm_load_sh(
      arg0,
    );
  }

  late final __mm_load_shPtr =
      _lookup<ffi.NativeFunction<__m128h Function(ffi.Pointer<ffi.Void>)>>(
          '_mm_load_sh');
  late final __mm_load_sh =
      __mm_load_shPtr.asFunction<__m128h Function(ffi.Pointer<ffi.Void>)>();

  __m128h _mm_mask_load_sh(
    __m128h arg0,
    int arg1,
    ffi.Pointer<ffi.Void> arg2,
  ) {
    return __mm_mask_load_sh(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_load_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __m128h, __mmask8, ffi.Pointer<ffi.Void>)>>('_mm_mask_load_sh');
  late final __mm_mask_load_sh = __mm_mask_load_shPtr
      .asFunction<__m128h Function(__m128h, int, ffi.Pointer<ffi.Void>)>();

  __m128h _mm_maskz_load_sh(
    int arg0,
    ffi.Pointer<ffi.Void> arg1,
  ) {
    return __mm_maskz_load_sh(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_load_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __mmask8, ffi.Pointer<ffi.Void>)>>('_mm_maskz_load_sh');
  late final __mm_maskz_load_sh = __mm_maskz_load_shPtr
      .asFunction<__m128h Function(int, ffi.Pointer<ffi.Void>)>();

  void _mm_store_sh(
    ffi.Pointer<ffi.Void> arg0,
    __m128h arg1,
  ) {
    return __mm_store_sh(
      arg0,
      arg1,
    );
  }

  late final __mm_store_shPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Void>, __m128h)>>('_mm_store_sh');
  late final __mm_store_sh = __mm_store_shPtr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, __m128h)>();

  void _mm_mask_store_sh(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    __m128h arg2,
  ) {
    return __mm_mask_store_sh(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_store_shPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<ffi.Void>, __mmask8, __m128h)>>('_mm_mask_store_sh');
  late final __mm_mask_store_sh = __mm_mask_store_shPtr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, int, __m128h)>();

  __m128h _mm_move_sh(
    __m128h arg0,
    __m128h arg1,
  ) {
    return __mm_move_sh(
      arg0,
      arg1,
    );
  }

  late final __mm_move_shPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128h, __m128h)>>(
          '_mm_move_sh');
  late final __mm_move_sh =
      __mm_move_shPtr.asFunction<__m128h Function(__m128h, __m128h)>();

  __m128h _mm_mask_move_sh(
    __m128h arg0,
    int arg1,
    __m128h arg2,
    __m128h arg3,
  ) {
    return __mm_mask_move_sh(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_move_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __m128h, __mmask8, __m128h, __m128h)>>('_mm_mask_move_sh');
  late final __mm_mask_move_sh = __mm_mask_move_shPtr
      .asFunction<__m128h Function(__m128h, int, __m128h, __m128h)>();

  __m128h _mm_maskz_move_sh(
    int arg0,
    __m128h arg1,
    __m128h arg2,
  ) {
    return __mm_maskz_move_sh(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_move_shPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__mmask8, __m128h, __m128h)>>(
          '_mm_maskz_move_sh');
  late final __mm_maskz_move_sh = __mm_maskz_move_shPtr
      .asFunction<__m128h Function(int, __m128h, __m128h)>();

  __m128i _mm_cvtsi16_si128(
    int arg0,
  ) {
    return __mm_cvtsi16_si128(
      arg0,
    );
  }

  late final __mm_cvtsi16_si128Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(ffi.Int16)>>(
          '_mm_cvtsi16_si128');
  late final __mm_cvtsi16_si128 =
      __mm_cvtsi16_si128Ptr.asFunction<__m128i Function(int)>();

  int _mm_cvtsi128_si16(
    __m128i arg0,
  ) {
    return __mm_cvtsi128_si16(
      arg0,
    );
  }

  late final __mm_cvtsi128_si16Ptr =
      _lookup<ffi.NativeFunction<ffi.Int16 Function(__m128i)>>(
          '_mm_cvtsi128_si16');
  late final __mm_cvtsi128_si16 =
      __mm_cvtsi128_si16Ptr.asFunction<int Function(__m128i)>();

  __m128h _mm_mul_ph(
    __m128h arg0,
    __m128h arg1,
  ) {
    return __mm_mul_ph(
      arg0,
      arg1,
    );
  }

  late final __mm_mul_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128h, __m128h)>>(
          '_mm_mul_ph');
  late final __mm_mul_ph =
      __mm_mul_phPtr.asFunction<__m128h Function(__m128h, __m128h)>();

  __m128h _mm_mask_mul_ph(
    __m128h arg0,
    int arg1,
    __m128h arg2,
    __m128h arg3,
  ) {
    return __mm_mask_mul_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_mul_phPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __m128h, __mmask8, __m128h, __m128h)>>('_mm_mask_mul_ph');
  late final __mm_mask_mul_ph = __mm_mask_mul_phPtr
      .asFunction<__m128h Function(__m128h, int, __m128h, __m128h)>();

  __m128h _mm_maskz_mul_ph(
    int arg0,
    __m128h arg1,
    __m128h arg2,
  ) {
    return __mm_maskz_mul_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_mul_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__mmask8, __m128h, __m128h)>>(
          '_mm_maskz_mul_ph');
  late final __mm_maskz_mul_ph = __mm_maskz_mul_phPtr
      .asFunction<__m128h Function(int, __m128h, __m128h)>();

  __m256h _mm256_mul_ph(
    __m256h arg0,
    __m256h arg1,
  ) {
    return __mm256_mul_ph(
      arg0,
      arg1,
    );
  }

  late final __mm256_mul_phPtr =
      _lookup<ffi.NativeFunction<__m256h Function(__m256h, __m256h)>>(
          '_mm256_mul_ph');
  late final __mm256_mul_ph =
      __mm256_mul_phPtr.asFunction<__m256h Function(__m256h, __m256h)>();

  __m256h _mm256_mask_mul_ph(
    __m256h arg0,
    int arg1,
    __m256h arg2,
    __m256h arg3,
  ) {
    return __mm256_mask_mul_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_mul_phPtr = _lookup<
      ffi.NativeFunction<
          __m256h Function(
              __m256h, __mmask16, __m256h, __m256h)>>('_mm256_mask_mul_ph');
  late final __mm256_mask_mul_ph = __mm256_mask_mul_phPtr
      .asFunction<__m256h Function(__m256h, int, __m256h, __m256h)>();

  __m256h _mm256_maskz_mul_ph(
    int arg0,
    __m256h arg1,
    __m256h arg2,
  ) {
    return __mm256_maskz_mul_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_mul_phPtr = _lookup<
          ffi.NativeFunction<__m256h Function(__mmask16, __m256h, __m256h)>>(
      '_mm256_maskz_mul_ph');
  late final __mm256_maskz_mul_ph = __mm256_maskz_mul_phPtr
      .asFunction<__m256h Function(int, __m256h, __m256h)>();

  __m512h _mm512_mul_ph(
    __m512h arg0,
    __m512h arg1,
  ) {
    return __mm512_mul_ph(
      arg0,
      arg1,
    );
  }

  late final __mm512_mul_phPtr =
      _lookup<ffi.NativeFunction<__m512h Function(__m512h, __m512h)>>(
          '_mm512_mul_ph');
  late final __mm512_mul_ph =
      __mm512_mul_phPtr.asFunction<__m512h Function(__m512h, __m512h)>();

  __m512h _mm512_mask_mul_ph(
    __m512h arg0,
    int arg1,
    __m512h arg2,
    __m512h arg3,
  ) {
    return __mm512_mask_mul_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_mul_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(
              __m512h, __mmask32, __m512h, __m512h)>>('_mm512_mask_mul_ph');
  late final __mm512_mask_mul_ph = __mm512_mask_mul_phPtr
      .asFunction<__m512h Function(__m512h, int, __m512h, __m512h)>();

  __m512h _mm512_maskz_mul_ph(
    int arg0,
    __m512h arg1,
    __m512h arg2,
  ) {
    return __mm512_maskz_mul_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_mul_phPtr = _lookup<
          ffi.NativeFunction<__m512h Function(__mmask32, __m512h, __m512h)>>(
      '_mm512_maskz_mul_ph');
  late final __mm512_maskz_mul_ph = __mm512_maskz_mul_phPtr
      .asFunction<__m512h Function(int, __m512h, __m512h)>();

  __m512h _mm512_mul_round_ph(
    __m512h arg0,
    __m512h arg1,
    int arg2,
  ) {
    return __mm512_mul_round_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mul_round_phPtr = _lookup<
          ffi.NativeFunction<__m512h Function(__m512h, __m512h, ffi.Int32)>>(
      '_mm512_mul_round_ph');
  late final __mm512_mul_round_ph = __mm512_mul_round_phPtr
      .asFunction<__m512h Function(__m512h, __m512h, int)>();

  __m512h _mm512_mask_mul_round_ph(
    __m512h arg0,
    int arg1,
    __m512h arg2,
    __m512h arg3,
    int arg4,
  ) {
    return __mm512_mask_mul_round_ph(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_mul_round_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(__m512h, __mmask32, __m512h, __m512h,
              ffi.Int32)>>('_mm512_mask_mul_round_ph');
  late final __mm512_mask_mul_round_ph = __mm512_mask_mul_round_phPtr
      .asFunction<__m512h Function(__m512h, int, __m512h, __m512h, int)>();

  __m512h _mm512_maskz_mul_round_ph(
    int arg0,
    __m512h arg1,
    __m512h arg2,
    int arg3,
  ) {
    return __mm512_maskz_mul_round_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_mul_round_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(__mmask32, __m512h, __m512h,
              ffi.Int32)>>('_mm512_maskz_mul_round_ph');
  late final __mm512_maskz_mul_round_ph = __mm512_maskz_mul_round_phPtr
      .asFunction<__m512h Function(int, __m512h, __m512h, int)>();

  __m128h _mm_mul_sh(
    __m128h arg0,
    __m128h arg1,
  ) {
    return __mm_mul_sh(
      arg0,
      arg1,
    );
  }

  late final __mm_mul_shPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128h, __m128h)>>(
          '_mm_mul_sh');
  late final __mm_mul_sh =
      __mm_mul_shPtr.asFunction<__m128h Function(__m128h, __m128h)>();

  __m128h _mm_mask_mul_sh(
    __m128h arg0,
    int arg1,
    __m128h arg2,
    __m128h arg3,
  ) {
    return __mm_mask_mul_sh(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_mul_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __m128h, __mmask8, __m128h, __m128h)>>('_mm_mask_mul_sh');
  late final __mm_mask_mul_sh = __mm_mask_mul_shPtr
      .asFunction<__m128h Function(__m128h, int, __m128h, __m128h)>();

  __m128h _mm_maskz_mul_sh(
    int arg0,
    __m128h arg1,
    __m128h arg2,
  ) {
    return __mm_maskz_mul_sh(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_mul_shPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__mmask8, __m128h, __m128h)>>(
          '_mm_maskz_mul_sh');
  late final __mm_maskz_mul_sh = __mm_maskz_mul_shPtr
      .asFunction<__m128h Function(int, __m128h, __m128h)>();

  __m128h _mm_mul_round_sh(
    __m128h arg0,
    __m128h arg1,
    int arg2,
  ) {
    return __mm_mul_round_sh(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mul_round_shPtr = _lookup<
          ffi.NativeFunction<__m128h Function(__m128h, __m128h, ffi.Int32)>>(
      '_mm_mul_round_sh');
  late final __mm_mul_round_sh = __mm_mul_round_shPtr
      .asFunction<__m128h Function(__m128h, __m128h, int)>();

  __m128h _mm_mask_mul_round_sh(
    __m128h arg0,
    int arg1,
    __m128h arg2,
    __m128h arg3,
    int arg4,
  ) {
    return __mm_mask_mul_round_sh(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_mul_round_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(__m128h, __mmask8, __m128h, __m128h,
              ffi.Int32)>>('_mm_mask_mul_round_sh');
  late final __mm_mask_mul_round_sh = __mm_mask_mul_round_shPtr
      .asFunction<__m128h Function(__m128h, int, __m128h, __m128h, int)>();

  __m128h _mm_maskz_mul_round_sh(
    int arg0,
    __m128h arg1,
    __m128h arg2,
    int arg3,
  ) {
    return __mm_maskz_mul_round_sh(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_mul_round_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(__mmask8, __m128h, __m128h,
              ffi.Int32)>>('_mm_maskz_mul_round_sh');
  late final __mm_maskz_mul_round_sh = __mm_maskz_mul_round_shPtr
      .asFunction<__m128h Function(int, __m128h, __m128h, int)>();

  __m128h _mm_rcp_ph(
    __m128h arg0,
  ) {
    return __mm_rcp_ph(
      arg0,
    );
  }

  late final __mm_rcp_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128h)>>('_mm_rcp_ph');
  late final __mm_rcp_ph =
      __mm_rcp_phPtr.asFunction<__m128h Function(__m128h)>();

  __m128h _mm_mask_rcp_ph(
    __m128h arg0,
    int arg1,
    __m128h arg2,
  ) {
    return __mm_mask_rcp_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_rcp_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128h, __mmask8, __m128h)>>(
          '_mm_mask_rcp_ph');
  late final __mm_mask_rcp_ph =
      __mm_mask_rcp_phPtr.asFunction<__m128h Function(__m128h, int, __m128h)>();

  __m128h _mm_maskz_rcp_ph(
    int arg0,
    __m128h arg1,
  ) {
    return __mm_maskz_rcp_ph(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_rcp_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__mmask8, __m128h)>>(
          '_mm_maskz_rcp_ph');
  late final __mm_maskz_rcp_ph =
      __mm_maskz_rcp_phPtr.asFunction<__m128h Function(int, __m128h)>();

  __m256h _mm256_rcp_ph(
    __m256h arg0,
  ) {
    return __mm256_rcp_ph(
      arg0,
    );
  }

  late final __mm256_rcp_phPtr =
      _lookup<ffi.NativeFunction<__m256h Function(__m256h)>>('_mm256_rcp_ph');
  late final __mm256_rcp_ph =
      __mm256_rcp_phPtr.asFunction<__m256h Function(__m256h)>();

  __m256h _mm256_mask_rcp_ph(
    __m256h arg0,
    int arg1,
    __m256h arg2,
  ) {
    return __mm256_mask_rcp_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_rcp_phPtr = _lookup<
          ffi.NativeFunction<__m256h Function(__m256h, __mmask16, __m256h)>>(
      '_mm256_mask_rcp_ph');
  late final __mm256_mask_rcp_ph = __mm256_mask_rcp_phPtr
      .asFunction<__m256h Function(__m256h, int, __m256h)>();

  __m256h _mm256_maskz_rcp_ph(
    int arg0,
    __m256h arg1,
  ) {
    return __mm256_maskz_rcp_ph(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_rcp_phPtr =
      _lookup<ffi.NativeFunction<__m256h Function(__mmask16, __m256h)>>(
          '_mm256_maskz_rcp_ph');
  late final __mm256_maskz_rcp_ph =
      __mm256_maskz_rcp_phPtr.asFunction<__m256h Function(int, __m256h)>();

  __m512h _mm512_rcp_ph(
    __m512h arg0,
  ) {
    return __mm512_rcp_ph(
      arg0,
    );
  }

  late final __mm512_rcp_phPtr =
      _lookup<ffi.NativeFunction<__m512h Function(__m512h)>>('_mm512_rcp_ph');
  late final __mm512_rcp_ph =
      __mm512_rcp_phPtr.asFunction<__m512h Function(__m512h)>();

  __m512h _mm512_mask_rcp_ph(
    __m512h arg0,
    int arg1,
    __m512h arg2,
  ) {
    return __mm512_mask_rcp_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_rcp_phPtr = _lookup<
          ffi.NativeFunction<__m512h Function(__m512h, __mmask32, __m512h)>>(
      '_mm512_mask_rcp_ph');
  late final __mm512_mask_rcp_ph = __mm512_mask_rcp_phPtr
      .asFunction<__m512h Function(__m512h, int, __m512h)>();

  __m512h _mm512_maskz_rcp_ph(
    int arg0,
    __m512h arg1,
  ) {
    return __mm512_maskz_rcp_ph(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_rcp_phPtr =
      _lookup<ffi.NativeFunction<__m512h Function(__mmask32, __m512h)>>(
          '_mm512_maskz_rcp_ph');
  late final __mm512_maskz_rcp_ph =
      __mm512_maskz_rcp_phPtr.asFunction<__m512h Function(int, __m512h)>();

  __m128h _mm_rcp_sh(
    __m128h arg0,
    __m128h arg1,
  ) {
    return __mm_rcp_sh(
      arg0,
      arg1,
    );
  }

  late final __mm_rcp_shPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128h, __m128h)>>(
          '_mm_rcp_sh');
  late final __mm_rcp_sh =
      __mm_rcp_shPtr.asFunction<__m128h Function(__m128h, __m128h)>();

  __m128h _mm_mask_rcp_sh(
    __m128h arg0,
    int arg1,
    __m128h arg2,
    __m128h arg3,
  ) {
    return __mm_mask_rcp_sh(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_rcp_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __m128h, __mmask8, __m128h, __m128h)>>('_mm_mask_rcp_sh');
  late final __mm_mask_rcp_sh = __mm_mask_rcp_shPtr
      .asFunction<__m128h Function(__m128h, int, __m128h, __m128h)>();

  __m128h _mm_maskz_rcp_sh(
    int arg0,
    __m128h arg1,
    __m128h arg2,
  ) {
    return __mm_maskz_rcp_sh(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_rcp_shPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__mmask8, __m128h, __m128h)>>(
          '_mm_maskz_rcp_sh');
  late final __mm_maskz_rcp_sh = __mm_maskz_rcp_shPtr
      .asFunction<__m128h Function(int, __m128h, __m128h)>();

  __m128h _mm_reduce_ph(
    __m128h arg0,
    int arg1,
  ) {
    return __mm_reduce_ph(
      arg0,
      arg1,
    );
  }

  late final __mm_reduce_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128h, ffi.Int32)>>(
          '_mm_reduce_ph');
  late final __mm_reduce_ph =
      __mm_reduce_phPtr.asFunction<__m128h Function(__m128h, int)>();

  __m128h _mm_mask_reduce_ph(
    __m128h arg0,
    int arg1,
    __m128h arg2,
    int arg3,
  ) {
    return __mm_mask_reduce_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_reduce_phPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __m128h, __mmask8, __m128h, ffi.Int32)>>('_mm_mask_reduce_ph');
  late final __mm_mask_reduce_ph = __mm_mask_reduce_phPtr
      .asFunction<__m128h Function(__m128h, int, __m128h, int)>();

  __m128h _mm_maskz_reduce_ph(
    int arg0,
    __m128h arg1,
    int arg2,
  ) {
    return __mm_maskz_reduce_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_reduce_phPtr = _lookup<
          ffi.NativeFunction<__m128h Function(__mmask8, __m128h, ffi.Int32)>>(
      '_mm_maskz_reduce_ph');
  late final __mm_maskz_reduce_ph =
      __mm_maskz_reduce_phPtr.asFunction<__m128h Function(int, __m128h, int)>();

  __m256h _mm256_reduce_ph(
    __m256h arg0,
    int arg1,
  ) {
    return __mm256_reduce_ph(
      arg0,
      arg1,
    );
  }

  late final __mm256_reduce_phPtr =
      _lookup<ffi.NativeFunction<__m256h Function(__m256h, ffi.Int32)>>(
          '_mm256_reduce_ph');
  late final __mm256_reduce_ph =
      __mm256_reduce_phPtr.asFunction<__m256h Function(__m256h, int)>();

  __m256h _mm256_mask_reduce_ph(
    __m256h arg0,
    int arg1,
    __m256h arg2,
    int arg3,
  ) {
    return __mm256_mask_reduce_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_reduce_phPtr = _lookup<
      ffi.NativeFunction<
          __m256h Function(__m256h, __mmask16, __m256h,
              ffi.Int32)>>('_mm256_mask_reduce_ph');
  late final __mm256_mask_reduce_ph = __mm256_mask_reduce_phPtr
      .asFunction<__m256h Function(__m256h, int, __m256h, int)>();

  __m256h _mm256_maskz_reduce_ph(
    int arg0,
    __m256h arg1,
    int arg2,
  ) {
    return __mm256_maskz_reduce_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_reduce_phPtr = _lookup<
          ffi.NativeFunction<__m256h Function(__mmask16, __m256h, ffi.Int32)>>(
      '_mm256_maskz_reduce_ph');
  late final __mm256_maskz_reduce_ph = __mm256_maskz_reduce_phPtr
      .asFunction<__m256h Function(int, __m256h, int)>();

  __m512h _mm512_reduce_ph(
    __m512h arg0,
    int arg1,
  ) {
    return __mm512_reduce_ph(
      arg0,
      arg1,
    );
  }

  late final __mm512_reduce_phPtr =
      _lookup<ffi.NativeFunction<__m512h Function(__m512h, ffi.Int32)>>(
          '_mm512_reduce_ph');
  late final __mm512_reduce_ph =
      __mm512_reduce_phPtr.asFunction<__m512h Function(__m512h, int)>();

  __m512h _mm512_mask_reduce_ph(
    __m512h arg0,
    int arg1,
    __m512h arg2,
    int arg3,
  ) {
    return __mm512_mask_reduce_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_reduce_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(__m512h, __mmask32, __m512h,
              ffi.Int32)>>('_mm512_mask_reduce_ph');
  late final __mm512_mask_reduce_ph = __mm512_mask_reduce_phPtr
      .asFunction<__m512h Function(__m512h, int, __m512h, int)>();

  __m512h _mm512_maskz_reduce_ph(
    int arg0,
    __m512h arg1,
    int arg2,
  ) {
    return __mm512_maskz_reduce_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_reduce_phPtr = _lookup<
          ffi.NativeFunction<__m512h Function(__mmask32, __m512h, ffi.Int32)>>(
      '_mm512_maskz_reduce_ph');
  late final __mm512_maskz_reduce_ph = __mm512_maskz_reduce_phPtr
      .asFunction<__m512h Function(int, __m512h, int)>();

  __m512h _mm512_reduce_round_ph(
    __m512h arg0,
    int arg1,
    int arg2,
  ) {
    return __mm512_reduce_round_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_reduce_round_phPtr = _lookup<
          ffi.NativeFunction<__m512h Function(__m512h, ffi.Int32, ffi.Int32)>>(
      '_mm512_reduce_round_ph');
  late final __mm512_reduce_round_ph = __mm512_reduce_round_phPtr
      .asFunction<__m512h Function(__m512h, int, int)>();

  __m512h _mm512_mask_reduce_round_ph(
    __m512h arg0,
    int arg1,
    __m512h arg2,
    int arg3,
    int arg4,
  ) {
    return __mm512_mask_reduce_round_ph(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_reduce_round_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(__m512h, __mmask32, __m512h, ffi.Int32,
              ffi.Int32)>>('_mm512_mask_reduce_round_ph');
  late final __mm512_mask_reduce_round_ph = __mm512_mask_reduce_round_phPtr
      .asFunction<__m512h Function(__m512h, int, __m512h, int, int)>();

  __m512h _mm512_maskz_reduce_round_ph(
    int arg0,
    __m512h arg1,
    int arg2,
    int arg3,
  ) {
    return __mm512_maskz_reduce_round_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_reduce_round_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(__mmask32, __m512h, ffi.Int32,
              ffi.Int32)>>('_mm512_maskz_reduce_round_ph');
  late final __mm512_maskz_reduce_round_ph = __mm512_maskz_reduce_round_phPtr
      .asFunction<__m512h Function(int, __m512h, int, int)>();

  __m128h _mm_reduce_sh(
    __m128h arg0,
    __m128h arg1,
    int arg2,
  ) {
    return __mm_reduce_sh(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_reduce_shPtr = _lookup<
          ffi.NativeFunction<__m128h Function(__m128h, __m128h, ffi.Int32)>>(
      '_mm_reduce_sh');
  late final __mm_reduce_sh =
      __mm_reduce_shPtr.asFunction<__m128h Function(__m128h, __m128h, int)>();

  __m128h _mm_mask_reduce_sh(
    __m128h arg0,
    int arg1,
    __m128h arg2,
    __m128h arg3,
    int arg4,
  ) {
    return __mm_mask_reduce_sh(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_reduce_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(__m128h, __mmask8, __m128h, __m128h,
              ffi.Int32)>>('_mm_mask_reduce_sh');
  late final __mm_mask_reduce_sh = __mm_mask_reduce_shPtr
      .asFunction<__m128h Function(__m128h, int, __m128h, __m128h, int)>();

  __m128h _mm_maskz_reduce_sh(
    int arg0,
    __m128h arg1,
    __m128h arg2,
    int arg3,
  ) {
    return __mm_maskz_reduce_sh(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_reduce_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __mmask8, __m128h, __m128h, ffi.Int32)>>('_mm_maskz_reduce_sh');
  late final __mm_maskz_reduce_sh = __mm_maskz_reduce_shPtr
      .asFunction<__m128h Function(int, __m128h, __m128h, int)>();

  __m128h _mm_reduce_round_sh(
    __m128h arg0,
    __m128h arg1,
    int arg2,
    int arg3,
  ) {
    return __mm_reduce_round_sh(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_reduce_round_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __m128h, __m128h, ffi.Int32, ffi.Int32)>>('_mm_reduce_round_sh');
  late final __mm_reduce_round_sh = __mm_reduce_round_shPtr
      .asFunction<__m128h Function(__m128h, __m128h, int, int)>();

  __m128h _mm_mask_reduce_round_sh(
    __m128h arg0,
    int arg1,
    __m128h arg2,
    __m128h arg3,
    int arg4,
    int arg5,
  ) {
    return __mm_mask_reduce_round_sh(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
      arg5,
    );
  }

  late final __mm_mask_reduce_round_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(__m128h, __mmask8, __m128h, __m128h, ffi.Int32,
              ffi.Int32)>>('_mm_mask_reduce_round_sh');
  late final __mm_mask_reduce_round_sh = __mm_mask_reduce_round_shPtr
      .asFunction<__m128h Function(__m128h, int, __m128h, __m128h, int, int)>();

  __m128h _mm_maskz_reduce_round_sh(
    int arg0,
    __m128h arg1,
    __m128h arg2,
    int arg3,
    int arg4,
  ) {
    return __mm_maskz_reduce_round_sh(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_maskz_reduce_round_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(__mmask8, __m128h, __m128h, ffi.Int32,
              ffi.Int32)>>('_mm_maskz_reduce_round_sh');
  late final __mm_maskz_reduce_round_sh = __mm_maskz_reduce_round_shPtr
      .asFunction<__m128h Function(int, __m128h, __m128h, int, int)>();

  __m128h _mm_roundscale_ph(
    __m128h arg0,
    int arg1,
  ) {
    return __mm_roundscale_ph(
      arg0,
      arg1,
    );
  }

  late final __mm_roundscale_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128h, ffi.Int32)>>(
          '_mm_roundscale_ph');
  late final __mm_roundscale_ph =
      __mm_roundscale_phPtr.asFunction<__m128h Function(__m128h, int)>();

  __m128h _mm_mask_roundscale_ph(
    __m128h arg0,
    int arg1,
    __m128h arg2,
    int arg3,
  ) {
    return __mm_mask_roundscale_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_roundscale_phPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(__m128h, __mmask8, __m128h,
              ffi.Int32)>>('_mm_mask_roundscale_ph');
  late final __mm_mask_roundscale_ph = __mm_mask_roundscale_phPtr
      .asFunction<__m128h Function(__m128h, int, __m128h, int)>();

  __m128h _mm_maskz_roundscale_ph(
    int arg0,
    __m128h arg1,
    int arg2,
  ) {
    return __mm_maskz_roundscale_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_roundscale_phPtr = _lookup<
          ffi.NativeFunction<__m128h Function(__mmask8, __m128h, ffi.Int32)>>(
      '_mm_maskz_roundscale_ph');
  late final __mm_maskz_roundscale_ph = __mm_maskz_roundscale_phPtr
      .asFunction<__m128h Function(int, __m128h, int)>();

  __m256h _mm256_roundscale_ph(
    __m256h arg0,
    int arg1,
  ) {
    return __mm256_roundscale_ph(
      arg0,
      arg1,
    );
  }

  late final __mm256_roundscale_phPtr =
      _lookup<ffi.NativeFunction<__m256h Function(__m256h, ffi.Int32)>>(
          '_mm256_roundscale_ph');
  late final __mm256_roundscale_ph =
      __mm256_roundscale_phPtr.asFunction<__m256h Function(__m256h, int)>();

  __m256h _mm256_mask_roundscale_ph(
    __m256h arg0,
    int arg1,
    __m256h arg2,
    int arg3,
  ) {
    return __mm256_mask_roundscale_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_roundscale_phPtr = _lookup<
      ffi.NativeFunction<
          __m256h Function(__m256h, __mmask16, __m256h,
              ffi.Int32)>>('_mm256_mask_roundscale_ph');
  late final __mm256_mask_roundscale_ph = __mm256_mask_roundscale_phPtr
      .asFunction<__m256h Function(__m256h, int, __m256h, int)>();

  __m256h _mm256_maskz_roundscale_ph(
    int arg0,
    __m256h arg1,
    int arg2,
  ) {
    return __mm256_maskz_roundscale_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_roundscale_phPtr = _lookup<
          ffi.NativeFunction<__m256h Function(__mmask16, __m256h, ffi.Int32)>>(
      '_mm256_maskz_roundscale_ph');
  late final __mm256_maskz_roundscale_ph = __mm256_maskz_roundscale_phPtr
      .asFunction<__m256h Function(int, __m256h, int)>();

  __m512h _mm512_roundscale_ph(
    __m512h arg0,
    int arg1,
  ) {
    return __mm512_roundscale_ph(
      arg0,
      arg1,
    );
  }

  late final __mm512_roundscale_phPtr =
      _lookup<ffi.NativeFunction<__m512h Function(__m512h, ffi.Int32)>>(
          '_mm512_roundscale_ph');
  late final __mm512_roundscale_ph =
      __mm512_roundscale_phPtr.asFunction<__m512h Function(__m512h, int)>();

  __m512h _mm512_mask_roundscale_ph(
    __m512h arg0,
    int arg1,
    __m512h arg2,
    int arg3,
  ) {
    return __mm512_mask_roundscale_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_roundscale_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(__m512h, __mmask32, __m512h,
              ffi.Int32)>>('_mm512_mask_roundscale_ph');
  late final __mm512_mask_roundscale_ph = __mm512_mask_roundscale_phPtr
      .asFunction<__m512h Function(__m512h, int, __m512h, int)>();

  __m512h _mm512_maskz_roundscale_ph(
    int arg0,
    __m512h arg1,
    int arg2,
  ) {
    return __mm512_maskz_roundscale_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_roundscale_phPtr = _lookup<
          ffi.NativeFunction<__m512h Function(__mmask32, __m512h, ffi.Int32)>>(
      '_mm512_maskz_roundscale_ph');
  late final __mm512_maskz_roundscale_ph = __mm512_maskz_roundscale_phPtr
      .asFunction<__m512h Function(int, __m512h, int)>();

  __m512h _mm512_roundscale_round_ph(
    __m512h arg0,
    int arg1,
    int arg2,
  ) {
    return __mm512_roundscale_round_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_roundscale_round_phPtr = _lookup<
          ffi.NativeFunction<__m512h Function(__m512h, ffi.Int32, ffi.Int32)>>(
      '_mm512_roundscale_round_ph');
  late final __mm512_roundscale_round_ph = __mm512_roundscale_round_phPtr
      .asFunction<__m512h Function(__m512h, int, int)>();

  __m512h _mm512_mask_roundscale_round_ph(
    __m512h arg0,
    int arg1,
    __m512h arg2,
    int arg3,
    int arg4,
  ) {
    return __mm512_mask_roundscale_round_ph(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_roundscale_round_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(__m512h, __mmask32, __m512h, ffi.Int32,
              ffi.Int32)>>('_mm512_mask_roundscale_round_ph');
  late final __mm512_mask_roundscale_round_ph =
      __mm512_mask_roundscale_round_phPtr
          .asFunction<__m512h Function(__m512h, int, __m512h, int, int)>();

  __m512h _mm512_maskz_roundscale_round_ph(
    int arg0,
    __m512h arg1,
    int arg2,
    int arg3,
  ) {
    return __mm512_maskz_roundscale_round_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_roundscale_round_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(__mmask32, __m512h, ffi.Int32,
              ffi.Int32)>>('_mm512_maskz_roundscale_round_ph');
  late final __mm512_maskz_roundscale_round_ph =
      __mm512_maskz_roundscale_round_phPtr
          .asFunction<__m512h Function(int, __m512h, int, int)>();

  __m128h _mm_roundscale_sh(
    __m128h arg0,
    __m128h arg1,
    int arg2,
  ) {
    return __mm_roundscale_sh(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_roundscale_shPtr = _lookup<
          ffi.NativeFunction<__m128h Function(__m128h, __m128h, ffi.Int32)>>(
      '_mm_roundscale_sh');
  late final __mm_roundscale_sh = __mm_roundscale_shPtr
      .asFunction<__m128h Function(__m128h, __m128h, int)>();

  __m128h _mm_mask_roundscale_sh(
    __m128h arg0,
    int arg1,
    __m128h arg2,
    __m128h arg3,
    int arg4,
  ) {
    return __mm_mask_roundscale_sh(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_roundscale_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(__m128h, __mmask8, __m128h, __m128h,
              ffi.Int32)>>('_mm_mask_roundscale_sh');
  late final __mm_mask_roundscale_sh = __mm_mask_roundscale_shPtr
      .asFunction<__m128h Function(__m128h, int, __m128h, __m128h, int)>();

  __m128h _mm_maskz_roundscale_sh(
    int arg0,
    __m128h arg1,
    __m128h arg2,
    int arg3,
  ) {
    return __mm_maskz_roundscale_sh(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_roundscale_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(__mmask8, __m128h, __m128h,
              ffi.Int32)>>('_mm_maskz_roundscale_sh');
  late final __mm_maskz_roundscale_sh = __mm_maskz_roundscale_shPtr
      .asFunction<__m128h Function(int, __m128h, __m128h, int)>();

  __m128h _mm_roundscale_round_sh(
    __m128h arg0,
    __m128h arg1,
    int arg2,
    int arg3,
  ) {
    return __mm_roundscale_round_sh(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_roundscale_round_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(__m128h, __m128h, ffi.Int32,
              ffi.Int32)>>('_mm_roundscale_round_sh');
  late final __mm_roundscale_round_sh = __mm_roundscale_round_shPtr
      .asFunction<__m128h Function(__m128h, __m128h, int, int)>();

  __m128h _mm_mask_roundscale_round_sh(
    __m128h arg0,
    int arg1,
    __m128h arg2,
    __m128h arg3,
    int arg4,
    int arg5,
  ) {
    return __mm_mask_roundscale_round_sh(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
      arg5,
    );
  }

  late final __mm_mask_roundscale_round_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(__m128h, __mmask8, __m128h, __m128h, ffi.Int32,
              ffi.Int32)>>('_mm_mask_roundscale_round_sh');
  late final __mm_mask_roundscale_round_sh = __mm_mask_roundscale_round_shPtr
      .asFunction<__m128h Function(__m128h, int, __m128h, __m128h, int, int)>();

  __m128h _mm_maskz_roundscale_round_sh(
    int arg0,
    __m128h arg1,
    __m128h arg2,
    int arg3,
    int arg4,
  ) {
    return __mm_maskz_roundscale_round_sh(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_maskz_roundscale_round_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(__mmask8, __m128h, __m128h, ffi.Int32,
              ffi.Int32)>>('_mm_maskz_roundscale_round_sh');
  late final __mm_maskz_roundscale_round_sh = __mm_maskz_roundscale_round_shPtr
      .asFunction<__m128h Function(int, __m128h, __m128h, int, int)>();

  __m128h _mm_rsqrt_ph(
    __m128h arg0,
  ) {
    return __mm_rsqrt_ph(
      arg0,
    );
  }

  late final __mm_rsqrt_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128h)>>('_mm_rsqrt_ph');
  late final __mm_rsqrt_ph =
      __mm_rsqrt_phPtr.asFunction<__m128h Function(__m128h)>();

  __m128h _mm_mask_rsqrt_ph(
    __m128h arg0,
    int arg1,
    __m128h arg2,
  ) {
    return __mm_mask_rsqrt_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_rsqrt_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128h, __mmask8, __m128h)>>(
          '_mm_mask_rsqrt_ph');
  late final __mm_mask_rsqrt_ph = __mm_mask_rsqrt_phPtr
      .asFunction<__m128h Function(__m128h, int, __m128h)>();

  __m128h _mm_maskz_rsqrt_ph(
    int arg0,
    __m128h arg1,
  ) {
    return __mm_maskz_rsqrt_ph(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_rsqrt_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__mmask8, __m128h)>>(
          '_mm_maskz_rsqrt_ph');
  late final __mm_maskz_rsqrt_ph =
      __mm_maskz_rsqrt_phPtr.asFunction<__m128h Function(int, __m128h)>();

  __m256h _mm256_rsqrt_ph(
    __m256h arg0,
  ) {
    return __mm256_rsqrt_ph(
      arg0,
    );
  }

  late final __mm256_rsqrt_phPtr =
      _lookup<ffi.NativeFunction<__m256h Function(__m256h)>>('_mm256_rsqrt_ph');
  late final __mm256_rsqrt_ph =
      __mm256_rsqrt_phPtr.asFunction<__m256h Function(__m256h)>();

  __m256h _mm256_mask_rsqrt_ph(
    __m256h arg0,
    int arg1,
    __m256h arg2,
  ) {
    return __mm256_mask_rsqrt_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_rsqrt_phPtr = _lookup<
          ffi.NativeFunction<__m256h Function(__m256h, __mmask16, __m256h)>>(
      '_mm256_mask_rsqrt_ph');
  late final __mm256_mask_rsqrt_ph = __mm256_mask_rsqrt_phPtr
      .asFunction<__m256h Function(__m256h, int, __m256h)>();

  __m256h _mm256_maskz_rsqrt_ph(
    int arg0,
    __m256h arg1,
  ) {
    return __mm256_maskz_rsqrt_ph(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_rsqrt_phPtr =
      _lookup<ffi.NativeFunction<__m256h Function(__mmask16, __m256h)>>(
          '_mm256_maskz_rsqrt_ph');
  late final __mm256_maskz_rsqrt_ph =
      __mm256_maskz_rsqrt_phPtr.asFunction<__m256h Function(int, __m256h)>();

  __m512h _mm512_rsqrt_ph(
    __m512h arg0,
  ) {
    return __mm512_rsqrt_ph(
      arg0,
    );
  }

  late final __mm512_rsqrt_phPtr =
      _lookup<ffi.NativeFunction<__m512h Function(__m512h)>>('_mm512_rsqrt_ph');
  late final __mm512_rsqrt_ph =
      __mm512_rsqrt_phPtr.asFunction<__m512h Function(__m512h)>();

  __m512h _mm512_mask_rsqrt_ph(
    __m512h arg0,
    int arg1,
    __m512h arg2,
  ) {
    return __mm512_mask_rsqrt_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_rsqrt_phPtr = _lookup<
          ffi.NativeFunction<__m512h Function(__m512h, __mmask32, __m512h)>>(
      '_mm512_mask_rsqrt_ph');
  late final __mm512_mask_rsqrt_ph = __mm512_mask_rsqrt_phPtr
      .asFunction<__m512h Function(__m512h, int, __m512h)>();

  __m512h _mm512_maskz_rsqrt_ph(
    int arg0,
    __m512h arg1,
  ) {
    return __mm512_maskz_rsqrt_ph(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_rsqrt_phPtr =
      _lookup<ffi.NativeFunction<__m512h Function(__mmask32, __m512h)>>(
          '_mm512_maskz_rsqrt_ph');
  late final __mm512_maskz_rsqrt_ph =
      __mm512_maskz_rsqrt_phPtr.asFunction<__m512h Function(int, __m512h)>();

  __m128h _mm_rsqrt_sh(
    __m128h arg0,
    __m128h arg1,
  ) {
    return __mm_rsqrt_sh(
      arg0,
      arg1,
    );
  }

  late final __mm_rsqrt_shPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128h, __m128h)>>(
          '_mm_rsqrt_sh');
  late final __mm_rsqrt_sh =
      __mm_rsqrt_shPtr.asFunction<__m128h Function(__m128h, __m128h)>();

  __m128h _mm_mask_rsqrt_sh(
    __m128h arg0,
    int arg1,
    __m128h arg2,
    __m128h arg3,
  ) {
    return __mm_mask_rsqrt_sh(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_rsqrt_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __m128h, __mmask8, __m128h, __m128h)>>('_mm_mask_rsqrt_sh');
  late final __mm_mask_rsqrt_sh = __mm_mask_rsqrt_shPtr
      .asFunction<__m128h Function(__m128h, int, __m128h, __m128h)>();

  __m128h _mm_maskz_rsqrt_sh(
    int arg0,
    __m128h arg1,
    __m128h arg2,
  ) {
    return __mm_maskz_rsqrt_sh(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_rsqrt_shPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__mmask8, __m128h, __m128h)>>(
          '_mm_maskz_rsqrt_sh');
  late final __mm_maskz_rsqrt_sh = __mm_maskz_rsqrt_shPtr
      .asFunction<__m128h Function(int, __m128h, __m128h)>();

  __m128h _mm_scalef_ph(
    __m128h arg0,
    __m128h arg1,
  ) {
    return __mm_scalef_ph(
      arg0,
      arg1,
    );
  }

  late final __mm_scalef_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128h, __m128h)>>(
          '_mm_scalef_ph');
  late final __mm_scalef_ph =
      __mm_scalef_phPtr.asFunction<__m128h Function(__m128h, __m128h)>();

  __m128h _mm_mask_scalef_ph(
    __m128h arg0,
    int arg1,
    __m128h arg2,
    __m128h arg3,
  ) {
    return __mm_mask_scalef_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_scalef_phPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __m128h, __mmask8, __m128h, __m128h)>>('_mm_mask_scalef_ph');
  late final __mm_mask_scalef_ph = __mm_mask_scalef_phPtr
      .asFunction<__m128h Function(__m128h, int, __m128h, __m128h)>();

  __m128h _mm_maskz_scalef_ph(
    int arg0,
    __m128h arg1,
    __m128h arg2,
  ) {
    return __mm_maskz_scalef_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_scalef_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__mmask8, __m128h, __m128h)>>(
          '_mm_maskz_scalef_ph');
  late final __mm_maskz_scalef_ph = __mm_maskz_scalef_phPtr
      .asFunction<__m128h Function(int, __m128h, __m128h)>();

  __m256h _mm256_scalef_ph(
    __m256h arg0,
    __m256h arg1,
  ) {
    return __mm256_scalef_ph(
      arg0,
      arg1,
    );
  }

  late final __mm256_scalef_phPtr =
      _lookup<ffi.NativeFunction<__m256h Function(__m256h, __m256h)>>(
          '_mm256_scalef_ph');
  late final __mm256_scalef_ph =
      __mm256_scalef_phPtr.asFunction<__m256h Function(__m256h, __m256h)>();

  __m256h _mm256_mask_scalef_ph(
    __m256h arg0,
    int arg1,
    __m256h arg2,
    __m256h arg3,
  ) {
    return __mm256_mask_scalef_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_scalef_phPtr = _lookup<
      ffi.NativeFunction<
          __m256h Function(
              __m256h, __mmask16, __m256h, __m256h)>>('_mm256_mask_scalef_ph');
  late final __mm256_mask_scalef_ph = __mm256_mask_scalef_phPtr
      .asFunction<__m256h Function(__m256h, int, __m256h, __m256h)>();

  __m256h _mm256_maskz_scalef_ph(
    int arg0,
    __m256h arg1,
    __m256h arg2,
  ) {
    return __mm256_maskz_scalef_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_scalef_phPtr = _lookup<
          ffi.NativeFunction<__m256h Function(__mmask16, __m256h, __m256h)>>(
      '_mm256_maskz_scalef_ph');
  late final __mm256_maskz_scalef_ph = __mm256_maskz_scalef_phPtr
      .asFunction<__m256h Function(int, __m256h, __m256h)>();

  __m512h _mm512_scalef_ph(
    __m512h arg0,
    __m512h arg1,
  ) {
    return __mm512_scalef_ph(
      arg0,
      arg1,
    );
  }

  late final __mm512_scalef_phPtr =
      _lookup<ffi.NativeFunction<__m512h Function(__m512h, __m512h)>>(
          '_mm512_scalef_ph');
  late final __mm512_scalef_ph =
      __mm512_scalef_phPtr.asFunction<__m512h Function(__m512h, __m512h)>();

  __m512h _mm512_mask_scalef_ph(
    __m512h arg0,
    int arg1,
    __m512h arg2,
    __m512h arg3,
  ) {
    return __mm512_mask_scalef_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_scalef_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(
              __m512h, __mmask32, __m512h, __m512h)>>('_mm512_mask_scalef_ph');
  late final __mm512_mask_scalef_ph = __mm512_mask_scalef_phPtr
      .asFunction<__m512h Function(__m512h, int, __m512h, __m512h)>();

  __m512h _mm512_maskz_scalef_ph(
    int arg0,
    __m512h arg1,
    __m512h arg2,
  ) {
    return __mm512_maskz_scalef_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_scalef_phPtr = _lookup<
          ffi.NativeFunction<__m512h Function(__mmask32, __m512h, __m512h)>>(
      '_mm512_maskz_scalef_ph');
  late final __mm512_maskz_scalef_ph = __mm512_maskz_scalef_phPtr
      .asFunction<__m512h Function(int, __m512h, __m512h)>();

  __m512h _mm512_scalef_round_ph(
    __m512h arg0,
    __m512h arg1,
    int arg2,
  ) {
    return __mm512_scalef_round_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_scalef_round_phPtr = _lookup<
          ffi.NativeFunction<__m512h Function(__m512h, __m512h, ffi.Int32)>>(
      '_mm512_scalef_round_ph');
  late final __mm512_scalef_round_ph = __mm512_scalef_round_phPtr
      .asFunction<__m512h Function(__m512h, __m512h, int)>();

  __m512h _mm512_mask_scalef_round_ph(
    __m512h arg0,
    int arg1,
    __m512h arg2,
    __m512h arg3,
    int arg4,
  ) {
    return __mm512_mask_scalef_round_ph(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_scalef_round_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(__m512h, __mmask32, __m512h, __m512h,
              ffi.Int32)>>('_mm512_mask_scalef_round_ph');
  late final __mm512_mask_scalef_round_ph = __mm512_mask_scalef_round_phPtr
      .asFunction<__m512h Function(__m512h, int, __m512h, __m512h, int)>();

  __m512h _mm512_maskz_scalef_round_ph(
    int arg0,
    __m512h arg1,
    __m512h arg2,
    int arg3,
  ) {
    return __mm512_maskz_scalef_round_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_scalef_round_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(__mmask32, __m512h, __m512h,
              ffi.Int32)>>('_mm512_maskz_scalef_round_ph');
  late final __mm512_maskz_scalef_round_ph = __mm512_maskz_scalef_round_phPtr
      .asFunction<__m512h Function(int, __m512h, __m512h, int)>();

  __m128h _mm_scalef_sh(
    __m128h arg0,
    __m128h arg1,
  ) {
    return __mm_scalef_sh(
      arg0,
      arg1,
    );
  }

  late final __mm_scalef_shPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128h, __m128h)>>(
          '_mm_scalef_sh');
  late final __mm_scalef_sh =
      __mm_scalef_shPtr.asFunction<__m128h Function(__m128h, __m128h)>();

  __m128h _mm_mask_scalef_sh(
    __m128h arg0,
    int arg1,
    __m128h arg2,
    __m128h arg3,
  ) {
    return __mm_mask_scalef_sh(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_scalef_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __m128h, __mmask8, __m128h, __m128h)>>('_mm_mask_scalef_sh');
  late final __mm_mask_scalef_sh = __mm_mask_scalef_shPtr
      .asFunction<__m128h Function(__m128h, int, __m128h, __m128h)>();

  __m128h _mm_maskz_scalef_sh(
    int arg0,
    __m128h arg1,
    __m128h arg2,
  ) {
    return __mm_maskz_scalef_sh(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_scalef_shPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__mmask8, __m128h, __m128h)>>(
          '_mm_maskz_scalef_sh');
  late final __mm_maskz_scalef_sh = __mm_maskz_scalef_shPtr
      .asFunction<__m128h Function(int, __m128h, __m128h)>();

  __m128h _mm_scalef_round_sh(
    __m128h arg0,
    __m128h arg1,
    int arg2,
  ) {
    return __mm_scalef_round_sh(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_scalef_round_shPtr = _lookup<
          ffi.NativeFunction<__m128h Function(__m128h, __m128h, ffi.Int32)>>(
      '_mm_scalef_round_sh');
  late final __mm_scalef_round_sh = __mm_scalef_round_shPtr
      .asFunction<__m128h Function(__m128h, __m128h, int)>();

  __m128h _mm_mask_scalef_round_sh(
    __m128h arg0,
    int arg1,
    __m128h arg2,
    __m128h arg3,
    int arg4,
  ) {
    return __mm_mask_scalef_round_sh(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_scalef_round_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(__m128h, __mmask8, __m128h, __m128h,
              ffi.Int32)>>('_mm_mask_scalef_round_sh');
  late final __mm_mask_scalef_round_sh = __mm_mask_scalef_round_shPtr
      .asFunction<__m128h Function(__m128h, int, __m128h, __m128h, int)>();

  __m128h _mm_maskz_scalef_round_sh(
    int arg0,
    __m128h arg1,
    __m128h arg2,
    int arg3,
  ) {
    return __mm_maskz_scalef_round_sh(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_scalef_round_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(__mmask8, __m128h, __m128h,
              ffi.Int32)>>('_mm_maskz_scalef_round_sh');
  late final __mm_maskz_scalef_round_sh = __mm_maskz_scalef_round_shPtr
      .asFunction<__m128h Function(int, __m128h, __m128h, int)>();

  __m128h _mm_sqrt_ph(
    __m128h arg0,
  ) {
    return __mm_sqrt_ph(
      arg0,
    );
  }

  late final __mm_sqrt_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128h)>>('_mm_sqrt_ph');
  late final __mm_sqrt_ph =
      __mm_sqrt_phPtr.asFunction<__m128h Function(__m128h)>();

  __m128h _mm_mask_sqrt_ph(
    __m128h arg0,
    int arg1,
    __m128h arg2,
  ) {
    return __mm_mask_sqrt_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_sqrt_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128h, __mmask8, __m128h)>>(
          '_mm_mask_sqrt_ph');
  late final __mm_mask_sqrt_ph = __mm_mask_sqrt_phPtr
      .asFunction<__m128h Function(__m128h, int, __m128h)>();

  __m128h _mm_maskz_sqrt_ph(
    int arg0,
    __m128h arg1,
  ) {
    return __mm_maskz_sqrt_ph(
      arg0,
      arg1,
    );
  }

  late final __mm_maskz_sqrt_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__mmask8, __m128h)>>(
          '_mm_maskz_sqrt_ph');
  late final __mm_maskz_sqrt_ph =
      __mm_maskz_sqrt_phPtr.asFunction<__m128h Function(int, __m128h)>();

  __m256h _mm256_sqrt_ph(
    __m256h arg0,
  ) {
    return __mm256_sqrt_ph(
      arg0,
    );
  }

  late final __mm256_sqrt_phPtr =
      _lookup<ffi.NativeFunction<__m256h Function(__m256h)>>('_mm256_sqrt_ph');
  late final __mm256_sqrt_ph =
      __mm256_sqrt_phPtr.asFunction<__m256h Function(__m256h)>();

  __m256h _mm256_mask_sqrt_ph(
    __m256h arg0,
    int arg1,
    __m256h arg2,
  ) {
    return __mm256_mask_sqrt_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_sqrt_phPtr = _lookup<
          ffi.NativeFunction<__m256h Function(__m256h, __mmask16, __m256h)>>(
      '_mm256_mask_sqrt_ph');
  late final __mm256_mask_sqrt_ph = __mm256_mask_sqrt_phPtr
      .asFunction<__m256h Function(__m256h, int, __m256h)>();

  __m256h _mm256_maskz_sqrt_ph(
    int arg0,
    __m256h arg1,
  ) {
    return __mm256_maskz_sqrt_ph(
      arg0,
      arg1,
    );
  }

  late final __mm256_maskz_sqrt_phPtr =
      _lookup<ffi.NativeFunction<__m256h Function(__mmask16, __m256h)>>(
          '_mm256_maskz_sqrt_ph');
  late final __mm256_maskz_sqrt_ph =
      __mm256_maskz_sqrt_phPtr.asFunction<__m256h Function(int, __m256h)>();

  __m512h _mm512_sqrt_ph(
    __m512h arg0,
  ) {
    return __mm512_sqrt_ph(
      arg0,
    );
  }

  late final __mm512_sqrt_phPtr =
      _lookup<ffi.NativeFunction<__m512h Function(__m512h)>>('_mm512_sqrt_ph');
  late final __mm512_sqrt_ph =
      __mm512_sqrt_phPtr.asFunction<__m512h Function(__m512h)>();

  __m512h _mm512_mask_sqrt_ph(
    __m512h arg0,
    int arg1,
    __m512h arg2,
  ) {
    return __mm512_mask_sqrt_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_sqrt_phPtr = _lookup<
          ffi.NativeFunction<__m512h Function(__m512h, __mmask32, __m512h)>>(
      '_mm512_mask_sqrt_ph');
  late final __mm512_mask_sqrt_ph = __mm512_mask_sqrt_phPtr
      .asFunction<__m512h Function(__m512h, int, __m512h)>();

  __m512h _mm512_maskz_sqrt_ph(
    int arg0,
    __m512h arg1,
  ) {
    return __mm512_maskz_sqrt_ph(
      arg0,
      arg1,
    );
  }

  late final __mm512_maskz_sqrt_phPtr =
      _lookup<ffi.NativeFunction<__m512h Function(__mmask32, __m512h)>>(
          '_mm512_maskz_sqrt_ph');
  late final __mm512_maskz_sqrt_ph =
      __mm512_maskz_sqrt_phPtr.asFunction<__m512h Function(int, __m512h)>();

  __m512h _mm512_sqrt_round_ph(
    __m512h arg0,
    int arg1,
  ) {
    return __mm512_sqrt_round_ph(
      arg0,
      arg1,
    );
  }

  late final __mm512_sqrt_round_phPtr =
      _lookup<ffi.NativeFunction<__m512h Function(__m512h, ffi.Int32)>>(
          '_mm512_sqrt_round_ph');
  late final __mm512_sqrt_round_ph =
      __mm512_sqrt_round_phPtr.asFunction<__m512h Function(__m512h, int)>();

  __m512h _mm512_mask_sqrt_round_ph(
    __m512h arg0,
    int arg1,
    __m512h arg2,
    int arg3,
  ) {
    return __mm512_mask_sqrt_round_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_sqrt_round_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(__m512h, __mmask32, __m512h,
              ffi.Int32)>>('_mm512_mask_sqrt_round_ph');
  late final __mm512_mask_sqrt_round_ph = __mm512_mask_sqrt_round_phPtr
      .asFunction<__m512h Function(__m512h, int, __m512h, int)>();

  __m512h _mm512_maskz_sqrt_round_ph(
    int arg0,
    __m512h arg1,
    int arg2,
  ) {
    return __mm512_maskz_sqrt_round_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_sqrt_round_phPtr = _lookup<
          ffi.NativeFunction<__m512h Function(__mmask32, __m512h, ffi.Int32)>>(
      '_mm512_maskz_sqrt_round_ph');
  late final __mm512_maskz_sqrt_round_ph = __mm512_maskz_sqrt_round_phPtr
      .asFunction<__m512h Function(int, __m512h, int)>();

  __m128h _mm_sqrt_sh(
    __m128h arg0,
    __m128h arg1,
  ) {
    return __mm_sqrt_sh(
      arg0,
      arg1,
    );
  }

  late final __mm_sqrt_shPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128h, __m128h)>>(
          '_mm_sqrt_sh');
  late final __mm_sqrt_sh =
      __mm_sqrt_shPtr.asFunction<__m128h Function(__m128h, __m128h)>();

  __m128h _mm_mask_sqrt_sh(
    __m128h arg0,
    int arg1,
    __m128h arg2,
    __m128h arg3,
  ) {
    return __mm_mask_sqrt_sh(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_sqrt_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __m128h, __mmask8, __m128h, __m128h)>>('_mm_mask_sqrt_sh');
  late final __mm_mask_sqrt_sh = __mm_mask_sqrt_shPtr
      .asFunction<__m128h Function(__m128h, int, __m128h, __m128h)>();

  __m128h _mm_maskz_sqrt_sh(
    int arg0,
    __m128h arg1,
    __m128h arg2,
  ) {
    return __mm_maskz_sqrt_sh(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_sqrt_shPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__mmask8, __m128h, __m128h)>>(
          '_mm_maskz_sqrt_sh');
  late final __mm_maskz_sqrt_sh = __mm_maskz_sqrt_shPtr
      .asFunction<__m128h Function(int, __m128h, __m128h)>();

  __m128h _mm_sqrt_round_sh(
    __m128h arg0,
    __m128h arg1,
    int arg2,
  ) {
    return __mm_sqrt_round_sh(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_sqrt_round_shPtr = _lookup<
          ffi.NativeFunction<__m128h Function(__m128h, __m128h, ffi.Int32)>>(
      '_mm_sqrt_round_sh');
  late final __mm_sqrt_round_sh = __mm_sqrt_round_shPtr
      .asFunction<__m128h Function(__m128h, __m128h, int)>();

  __m128h _mm_mask_sqrt_round_sh(
    __m128h arg0,
    int arg1,
    __m128h arg2,
    __m128h arg3,
    int arg4,
  ) {
    return __mm_mask_sqrt_round_sh(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_sqrt_round_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(__m128h, __mmask8, __m128h, __m128h,
              ffi.Int32)>>('_mm_mask_sqrt_round_sh');
  late final __mm_mask_sqrt_round_sh = __mm_mask_sqrt_round_shPtr
      .asFunction<__m128h Function(__m128h, int, __m128h, __m128h, int)>();

  __m128h _mm_maskz_sqrt_round_sh(
    int arg0,
    __m128h arg1,
    __m128h arg2,
    int arg3,
  ) {
    return __mm_maskz_sqrt_round_sh(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_sqrt_round_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(__mmask8, __m128h, __m128h,
              ffi.Int32)>>('_mm_maskz_sqrt_round_sh');
  late final __mm_maskz_sqrt_round_sh = __mm_maskz_sqrt_round_shPtr
      .asFunction<__m128h Function(int, __m128h, __m128h, int)>();

  __m128h _mm_sub_ph(
    __m128h arg0,
    __m128h arg1,
  ) {
    return __mm_sub_ph(
      arg0,
      arg1,
    );
  }

  late final __mm_sub_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128h, __m128h)>>(
          '_mm_sub_ph');
  late final __mm_sub_ph =
      __mm_sub_phPtr.asFunction<__m128h Function(__m128h, __m128h)>();

  __m128h _mm_mask_sub_ph(
    __m128h arg0,
    int arg1,
    __m128h arg2,
    __m128h arg3,
  ) {
    return __mm_mask_sub_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_sub_phPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __m128h, __mmask8, __m128h, __m128h)>>('_mm_mask_sub_ph');
  late final __mm_mask_sub_ph = __mm_mask_sub_phPtr
      .asFunction<__m128h Function(__m128h, int, __m128h, __m128h)>();

  __m128h _mm_maskz_sub_ph(
    int arg0,
    __m128h arg1,
    __m128h arg2,
  ) {
    return __mm_maskz_sub_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_sub_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__mmask8, __m128h, __m128h)>>(
          '_mm_maskz_sub_ph');
  late final __mm_maskz_sub_ph = __mm_maskz_sub_phPtr
      .asFunction<__m128h Function(int, __m128h, __m128h)>();

  __m256h _mm256_sub_ph(
    __m256h arg0,
    __m256h arg1,
  ) {
    return __mm256_sub_ph(
      arg0,
      arg1,
    );
  }

  late final __mm256_sub_phPtr =
      _lookup<ffi.NativeFunction<__m256h Function(__m256h, __m256h)>>(
          '_mm256_sub_ph');
  late final __mm256_sub_ph =
      __mm256_sub_phPtr.asFunction<__m256h Function(__m256h, __m256h)>();

  __m256h _mm256_mask_sub_ph(
    __m256h arg0,
    int arg1,
    __m256h arg2,
    __m256h arg3,
  ) {
    return __mm256_mask_sub_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_mask_sub_phPtr = _lookup<
      ffi.NativeFunction<
          __m256h Function(
              __m256h, __mmask16, __m256h, __m256h)>>('_mm256_mask_sub_ph');
  late final __mm256_mask_sub_ph = __mm256_mask_sub_phPtr
      .asFunction<__m256h Function(__m256h, int, __m256h, __m256h)>();

  __m256h _mm256_maskz_sub_ph(
    int arg0,
    __m256h arg1,
    __m256h arg2,
  ) {
    return __mm256_maskz_sub_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maskz_sub_phPtr = _lookup<
          ffi.NativeFunction<__m256h Function(__mmask16, __m256h, __m256h)>>(
      '_mm256_maskz_sub_ph');
  late final __mm256_maskz_sub_ph = __mm256_maskz_sub_phPtr
      .asFunction<__m256h Function(int, __m256h, __m256h)>();

  __m512h _mm512_sub_ph(
    __m512h arg0,
    __m512h arg1,
  ) {
    return __mm512_sub_ph(
      arg0,
      arg1,
    );
  }

  late final __mm512_sub_phPtr =
      _lookup<ffi.NativeFunction<__m512h Function(__m512h, __m512h)>>(
          '_mm512_sub_ph');
  late final __mm512_sub_ph =
      __mm512_sub_phPtr.asFunction<__m512h Function(__m512h, __m512h)>();

  __m512h _mm512_mask_sub_ph(
    __m512h arg0,
    int arg1,
    __m512h arg2,
    __m512h arg3,
  ) {
    return __mm512_mask_sub_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_mask_sub_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(
              __m512h, __mmask32, __m512h, __m512h)>>('_mm512_mask_sub_ph');
  late final __mm512_mask_sub_ph = __mm512_mask_sub_phPtr
      .asFunction<__m512h Function(__m512h, int, __m512h, __m512h)>();

  __m512h _mm512_maskz_sub_ph(
    int arg0,
    __m512h arg1,
    __m512h arg2,
  ) {
    return __mm512_maskz_sub_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_maskz_sub_phPtr = _lookup<
          ffi.NativeFunction<__m512h Function(__mmask32, __m512h, __m512h)>>(
      '_mm512_maskz_sub_ph');
  late final __mm512_maskz_sub_ph = __mm512_maskz_sub_phPtr
      .asFunction<__m512h Function(int, __m512h, __m512h)>();

  __m512h _mm512_sub_round_ph(
    __m512h arg0,
    __m512h arg1,
    int arg2,
  ) {
    return __mm512_sub_round_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_sub_round_phPtr = _lookup<
          ffi.NativeFunction<__m512h Function(__m512h, __m512h, ffi.Int32)>>(
      '_mm512_sub_round_ph');
  late final __mm512_sub_round_ph = __mm512_sub_round_phPtr
      .asFunction<__m512h Function(__m512h, __m512h, int)>();

  __m512h _mm512_mask_sub_round_ph(
    __m512h arg0,
    int arg1,
    __m512h arg2,
    __m512h arg3,
    int arg4,
  ) {
    return __mm512_mask_sub_round_ph(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm512_mask_sub_round_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(__m512h, __mmask32, __m512h, __m512h,
              ffi.Int32)>>('_mm512_mask_sub_round_ph');
  late final __mm512_mask_sub_round_ph = __mm512_mask_sub_round_phPtr
      .asFunction<__m512h Function(__m512h, int, __m512h, __m512h, int)>();

  __m512h _mm512_maskz_sub_round_ph(
    int arg0,
    __m512h arg1,
    __m512h arg2,
    int arg3,
  ) {
    return __mm512_maskz_sub_round_ph(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm512_maskz_sub_round_phPtr = _lookup<
      ffi.NativeFunction<
          __m512h Function(__mmask32, __m512h, __m512h,
              ffi.Int32)>>('_mm512_maskz_sub_round_ph');
  late final __mm512_maskz_sub_round_ph = __mm512_maskz_sub_round_phPtr
      .asFunction<__m512h Function(int, __m512h, __m512h, int)>();

  __m128h _mm_sub_sh(
    __m128h arg0,
    __m128h arg1,
  ) {
    return __mm_sub_sh(
      arg0,
      arg1,
    );
  }

  late final __mm_sub_shPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__m128h, __m128h)>>(
          '_mm_sub_sh');
  late final __mm_sub_sh =
      __mm_sub_shPtr.asFunction<__m128h Function(__m128h, __m128h)>();

  __m128h _mm_mask_sub_sh(
    __m128h arg0,
    int arg1,
    __m128h arg2,
    __m128h arg3,
  ) {
    return __mm_mask_sub_sh(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_mask_sub_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(
              __m128h, __mmask8, __m128h, __m128h)>>('_mm_mask_sub_sh');
  late final __mm_mask_sub_sh = __mm_mask_sub_shPtr
      .asFunction<__m128h Function(__m128h, int, __m128h, __m128h)>();

  __m128h _mm_maskz_sub_sh(
    int arg0,
    __m128h arg1,
    __m128h arg2,
  ) {
    return __mm_maskz_sub_sh(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maskz_sub_shPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__mmask8, __m128h, __m128h)>>(
          '_mm_maskz_sub_sh');
  late final __mm_maskz_sub_sh = __mm_maskz_sub_shPtr
      .asFunction<__m128h Function(int, __m128h, __m128h)>();

  __m128h _mm_sub_round_sh(
    __m128h arg0,
    __m128h arg1,
    int arg2,
  ) {
    return __mm_sub_round_sh(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_sub_round_shPtr = _lookup<
          ffi.NativeFunction<__m128h Function(__m128h, __m128h, ffi.Int32)>>(
      '_mm_sub_round_sh');
  late final __mm_sub_round_sh = __mm_sub_round_shPtr
      .asFunction<__m128h Function(__m128h, __m128h, int)>();

  __m128h _mm_mask_sub_round_sh(
    __m128h arg0,
    int arg1,
    __m128h arg2,
    __m128h arg3,
    int arg4,
  ) {
    return __mm_mask_sub_round_sh(
      arg0,
      arg1,
      arg2,
      arg3,
      arg4,
    );
  }

  late final __mm_mask_sub_round_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(__m128h, __mmask8, __m128h, __m128h,
              ffi.Int32)>>('_mm_mask_sub_round_sh');
  late final __mm_mask_sub_round_sh = __mm_mask_sub_round_shPtr
      .asFunction<__m128h Function(__m128h, int, __m128h, __m128h, int)>();

  __m128h _mm_maskz_sub_round_sh(
    int arg0,
    __m128h arg1,
    __m128h arg2,
    int arg3,
  ) {
    return __mm_maskz_sub_round_sh(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_maskz_sub_round_shPtr = _lookup<
      ffi.NativeFunction<
          __m128h Function(__mmask8, __m128h, __m128h,
              ffi.Int32)>>('_mm_maskz_sub_round_sh');
  late final __mm_maskz_sub_round_sh = __mm_maskz_sub_round_shPtr
      .asFunction<__m128h Function(int, __m128h, __m128h, int)>();

  __m128h _mm_mask_blend_ph(
    int arg0,
    __m128h arg1,
    __m128h arg2,
  ) {
    return __mm_mask_blend_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mask_blend_phPtr =
      _lookup<ffi.NativeFunction<__m128h Function(__mmask8, __m128h, __m128h)>>(
          '_mm_mask_blend_ph');
  late final __mm_mask_blend_ph = __mm_mask_blend_phPtr
      .asFunction<__m128h Function(int, __m128h, __m128h)>();

  __m256h _mm256_mask_blend_ph(
    int arg0,
    __m256h arg1,
    __m256h arg2,
  ) {
    return __mm256_mask_blend_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_mask_blend_phPtr = _lookup<
          ffi.NativeFunction<__m256h Function(__mmask16, __m256h, __m256h)>>(
      '_mm256_mask_blend_ph');
  late final __mm256_mask_blend_ph = __mm256_mask_blend_phPtr
      .asFunction<__m256h Function(int, __m256h, __m256h)>();

  __m512h _mm512_mask_blend_ph(
    int arg0,
    __m512h arg1,
    __m512h arg2,
  ) {
    return __mm512_mask_blend_ph(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm512_mask_blend_phPtr = _lookup<
          ffi.NativeFunction<__m512h Function(__mmask32, __m512h, __m512h)>>(
      '_mm512_mask_blend_ph');
  late final __mm512_mask_blend_ph = __mm512_mask_blend_phPtr
      .asFunction<__m512h Function(int, __m512h, __m512h)>();

  __m128 _mm_macc_ps(
    __m128 arg0,
    __m128 arg1,
    __m128 arg2,
  ) {
    return __mm_macc_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_macc_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128, __m128)>>(
          '_mm_macc_ps');
  late final __mm_macc_ps =
      __mm_macc_psPtr.asFunction<__m128 Function(__m128, __m128, __m128)>();

  _m128d _mm_macc_pd(
    _m128d arg0,
    _m128d arg1,
    _m128d arg2,
  ) {
    return __mm_macc_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_macc_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d, _m128d)>>(
          '_mm_macc_pd');
  late final __mm_macc_pd =
      __mm_macc_pdPtr.asFunction<_m128d Function(_m128d, _m128d, _m128d)>();

  __m128 _mm_macc_ss(
    __m128 arg0,
    __m128 arg1,
    __m128 arg2,
  ) {
    return __mm_macc_ss(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_macc_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128, __m128)>>(
          '_mm_macc_ss');
  late final __mm_macc_ss =
      __mm_macc_ssPtr.asFunction<__m128 Function(__m128, __m128, __m128)>();

  _m128d _mm_macc_sd(
    _m128d arg0,
    _m128d arg1,
    _m128d arg2,
  ) {
    return __mm_macc_sd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_macc_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d, _m128d)>>(
          '_mm_macc_sd');
  late final __mm_macc_sd =
      __mm_macc_sdPtr.asFunction<_m128d Function(_m128d, _m128d, _m128d)>();

  __m128 _mm_maddsub_ps(
    __m128 arg0,
    __m128 arg1,
    __m128 arg2,
  ) {
    return __mm_maddsub_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maddsub_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128, __m128)>>(
          '_mm_maddsub_ps');
  late final __mm_maddsub_ps =
      __mm_maddsub_psPtr.asFunction<__m128 Function(__m128, __m128, __m128)>();

  _m128d _mm_maddsub_pd(
    _m128d arg0,
    _m128d arg1,
    _m128d arg2,
  ) {
    return __mm_maddsub_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maddsub_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d, _m128d)>>(
          '_mm_maddsub_pd');
  late final __mm_maddsub_pd =
      __mm_maddsub_pdPtr.asFunction<_m128d Function(_m128d, _m128d, _m128d)>();

  __m128 _mm_msubadd_ps(
    __m128 arg0,
    __m128 arg1,
    __m128 arg2,
  ) {
    return __mm_msubadd_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_msubadd_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128, __m128)>>(
          '_mm_msubadd_ps');
  late final __mm_msubadd_ps =
      __mm_msubadd_psPtr.asFunction<__m128 Function(__m128, __m128, __m128)>();

  _m128d _mm_msubadd_pd(
    _m128d arg0,
    _m128d arg1,
    _m128d arg2,
  ) {
    return __mm_msubadd_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_msubadd_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d, _m128d)>>(
          '_mm_msubadd_pd');
  late final __mm_msubadd_pd =
      __mm_msubadd_pdPtr.asFunction<_m128d Function(_m128d, _m128d, _m128d)>();

  __m128 _mm_msub_ps(
    __m128 arg0,
    __m128 arg1,
    __m128 arg2,
  ) {
    return __mm_msub_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_msub_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128, __m128)>>(
          '_mm_msub_ps');
  late final __mm_msub_ps =
      __mm_msub_psPtr.asFunction<__m128 Function(__m128, __m128, __m128)>();

  _m128d _mm_msub_pd(
    _m128d arg0,
    _m128d arg1,
    _m128d arg2,
  ) {
    return __mm_msub_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_msub_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d, _m128d)>>(
          '_mm_msub_pd');
  late final __mm_msub_pd =
      __mm_msub_pdPtr.asFunction<_m128d Function(_m128d, _m128d, _m128d)>();

  __m128 _mm_msub_ss(
    __m128 arg0,
    __m128 arg1,
    __m128 arg2,
  ) {
    return __mm_msub_ss(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_msub_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128, __m128)>>(
          '_mm_msub_ss');
  late final __mm_msub_ss =
      __mm_msub_ssPtr.asFunction<__m128 Function(__m128, __m128, __m128)>();

  _m128d _mm_msub_sd(
    _m128d arg0,
    _m128d arg1,
    _m128d arg2,
  ) {
    return __mm_msub_sd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_msub_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d, _m128d)>>(
          '_mm_msub_sd');
  late final __mm_msub_sd =
      __mm_msub_sdPtr.asFunction<_m128d Function(_m128d, _m128d, _m128d)>();

  __m128 _mm_nmacc_ps(
    __m128 arg0,
    __m128 arg1,
    __m128 arg2,
  ) {
    return __mm_nmacc_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_nmacc_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128, __m128)>>(
          '_mm_nmacc_ps');
  late final __mm_nmacc_ps =
      __mm_nmacc_psPtr.asFunction<__m128 Function(__m128, __m128, __m128)>();

  _m128d _mm_nmacc_pd(
    _m128d arg0,
    _m128d arg1,
    _m128d arg2,
  ) {
    return __mm_nmacc_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_nmacc_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d, _m128d)>>(
          '_mm_nmacc_pd');
  late final __mm_nmacc_pd =
      __mm_nmacc_pdPtr.asFunction<_m128d Function(_m128d, _m128d, _m128d)>();

  __m128 _mm_nmacc_ss(
    __m128 arg0,
    __m128 arg1,
    __m128 arg2,
  ) {
    return __mm_nmacc_ss(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_nmacc_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128, __m128)>>(
          '_mm_nmacc_ss');
  late final __mm_nmacc_ss =
      __mm_nmacc_ssPtr.asFunction<__m128 Function(__m128, __m128, __m128)>();

  _m128d _mm_nmacc_sd(
    _m128d arg0,
    _m128d arg1,
    _m128d arg2,
  ) {
    return __mm_nmacc_sd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_nmacc_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d, _m128d)>>(
          '_mm_nmacc_sd');
  late final __mm_nmacc_sd =
      __mm_nmacc_sdPtr.asFunction<_m128d Function(_m128d, _m128d, _m128d)>();

  __m128 _mm_nmsub_ps(
    __m128 arg0,
    __m128 arg1,
    __m128 arg2,
  ) {
    return __mm_nmsub_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_nmsub_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128, __m128)>>(
          '_mm_nmsub_ps');
  late final __mm_nmsub_ps =
      __mm_nmsub_psPtr.asFunction<__m128 Function(__m128, __m128, __m128)>();

  _m128d _mm_nmsub_pd(
    _m128d arg0,
    _m128d arg1,
    _m128d arg2,
  ) {
    return __mm_nmsub_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_nmsub_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d, _m128d)>>(
          '_mm_nmsub_pd');
  late final __mm_nmsub_pd =
      __mm_nmsub_pdPtr.asFunction<_m128d Function(_m128d, _m128d, _m128d)>();

  __m128 _mm_nmsub_ss(
    __m128 arg0,
    __m128 arg1,
    __m128 arg2,
  ) {
    return __mm_nmsub_ss(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_nmsub_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128, __m128)>>(
          '_mm_nmsub_ss');
  late final __mm_nmsub_ss =
      __mm_nmsub_ssPtr.asFunction<__m128 Function(__m128, __m128, __m128)>();

  _m128d _mm_nmsub_sd(
    _m128d arg0,
    _m128d arg1,
    _m128d arg2,
  ) {
    return __mm_nmsub_sd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_nmsub_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d, _m128d)>>(
          '_mm_nmsub_sd');
  late final __mm_nmsub_sd =
      __mm_nmsub_sdPtr.asFunction<_m128d Function(_m128d, _m128d, _m128d)>();

  __m128i _mm_maccs_epi16(
    __m128i arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maccs_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maccs_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i, __m128i)>>(
          '_mm_maccs_epi16');
  late final __mm_maccs_epi16 = __mm_maccs_epi16Ptr
      .asFunction<__m128i Function(__m128i, __m128i, __m128i)>();

  __m128i _mm_macc_epi16(
    __m128i arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_macc_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_macc_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i, __m128i)>>(
          '_mm_macc_epi16');
  late final __mm_macc_epi16 = __mm_macc_epi16Ptr
      .asFunction<__m128i Function(__m128i, __m128i, __m128i)>();

  __m128i _mm_maccsd_epi16(
    __m128i arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maccsd_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maccsd_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i, __m128i)>>(
          '_mm_maccsd_epi16');
  late final __mm_maccsd_epi16 = __mm_maccsd_epi16Ptr
      .asFunction<__m128i Function(__m128i, __m128i, __m128i)>();

  __m128i _mm_maccd_epi16(
    __m128i arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maccd_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maccd_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i, __m128i)>>(
          '_mm_maccd_epi16');
  late final __mm_maccd_epi16 = __mm_maccd_epi16Ptr
      .asFunction<__m128i Function(__m128i, __m128i, __m128i)>();

  __m128i _mm_maccs_epi32(
    __m128i arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maccs_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maccs_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i, __m128i)>>(
          '_mm_maccs_epi32');
  late final __mm_maccs_epi32 = __mm_maccs_epi32Ptr
      .asFunction<__m128i Function(__m128i, __m128i, __m128i)>();

  __m128i _mm_macc_epi32(
    __m128i arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_macc_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_macc_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i, __m128i)>>(
          '_mm_macc_epi32');
  late final __mm_macc_epi32 = __mm_macc_epi32Ptr
      .asFunction<__m128i Function(__m128i, __m128i, __m128i)>();

  __m128i _mm_maccslo_epi32(
    __m128i arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maccslo_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maccslo_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i, __m128i)>>(
          '_mm_maccslo_epi32');
  late final __mm_maccslo_epi32 = __mm_maccslo_epi32Ptr
      .asFunction<__m128i Function(__m128i, __m128i, __m128i)>();

  __m128i _mm_macclo_epi32(
    __m128i arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_macclo_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_macclo_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i, __m128i)>>(
          '_mm_macclo_epi32');
  late final __mm_macclo_epi32 = __mm_macclo_epi32Ptr
      .asFunction<__m128i Function(__m128i, __m128i, __m128i)>();

  __m128i _mm_maccshi_epi32(
    __m128i arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maccshi_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maccshi_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i, __m128i)>>(
          '_mm_maccshi_epi32');
  late final __mm_maccshi_epi32 = __mm_maccshi_epi32Ptr
      .asFunction<__m128i Function(__m128i, __m128i, __m128i)>();

  __m128i _mm_macchi_epi32(
    __m128i arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_macchi_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_macchi_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i, __m128i)>>(
          '_mm_macchi_epi32');
  late final __mm_macchi_epi32 = __mm_macchi_epi32Ptr
      .asFunction<__m128i Function(__m128i, __m128i, __m128i)>();

  __m128i _mm_maddsd_epi16(
    __m128i arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maddsd_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maddsd_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i, __m128i)>>(
          '_mm_maddsd_epi16');
  late final __mm_maddsd_epi16 = __mm_maddsd_epi16Ptr
      .asFunction<__m128i Function(__m128i, __m128i, __m128i)>();

  __m128i _mm_maddd_epi16(
    __m128i arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_maddd_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_maddd_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i, __m128i)>>(
          '_mm_maddd_epi16');
  late final __mm_maddd_epi16 = __mm_maddd_epi16Ptr
      .asFunction<__m128i Function(__m128i, __m128i, __m128i)>();

  __m128i _mm_haddw_epi8(
    __m128i arg0,
  ) {
    return __mm_haddw_epi8(
      arg0,
    );
  }

  late final __mm_haddw_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i)>>('_mm_haddw_epi8');
  late final __mm_haddw_epi8 =
      __mm_haddw_epi8Ptr.asFunction<__m128i Function(__m128i)>();

  __m128i _mm_haddd_epi8(
    __m128i arg0,
  ) {
    return __mm_haddd_epi8(
      arg0,
    );
  }

  late final __mm_haddd_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i)>>('_mm_haddd_epi8');
  late final __mm_haddd_epi8 =
      __mm_haddd_epi8Ptr.asFunction<__m128i Function(__m128i)>();

  __m128i _mm_haddq_epi8(
    __m128i arg0,
  ) {
    return __mm_haddq_epi8(
      arg0,
    );
  }

  late final __mm_haddq_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i)>>('_mm_haddq_epi8');
  late final __mm_haddq_epi8 =
      __mm_haddq_epi8Ptr.asFunction<__m128i Function(__m128i)>();

  __m128i _mm_haddd_epi16(
    __m128i arg0,
  ) {
    return __mm_haddd_epi16(
      arg0,
    );
  }

  late final __mm_haddd_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i)>>('_mm_haddd_epi16');
  late final __mm_haddd_epi16 =
      __mm_haddd_epi16Ptr.asFunction<__m128i Function(__m128i)>();

  __m128i _mm_haddq_epi16(
    __m128i arg0,
  ) {
    return __mm_haddq_epi16(
      arg0,
    );
  }

  late final __mm_haddq_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i)>>('_mm_haddq_epi16');
  late final __mm_haddq_epi16 =
      __mm_haddq_epi16Ptr.asFunction<__m128i Function(__m128i)>();

  __m128i _mm_haddq_epi32(
    __m128i arg0,
  ) {
    return __mm_haddq_epi32(
      arg0,
    );
  }

  late final __mm_haddq_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i)>>('_mm_haddq_epi32');
  late final __mm_haddq_epi32 =
      __mm_haddq_epi32Ptr.asFunction<__m128i Function(__m128i)>();

  __m128i _mm_haddw_epu8(
    __m128i arg0,
  ) {
    return __mm_haddw_epu8(
      arg0,
    );
  }

  late final __mm_haddw_epu8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i)>>('_mm_haddw_epu8');
  late final __mm_haddw_epu8 =
      __mm_haddw_epu8Ptr.asFunction<__m128i Function(__m128i)>();

  __m128i _mm_haddd_epu8(
    __m128i arg0,
  ) {
    return __mm_haddd_epu8(
      arg0,
    );
  }

  late final __mm_haddd_epu8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i)>>('_mm_haddd_epu8');
  late final __mm_haddd_epu8 =
      __mm_haddd_epu8Ptr.asFunction<__m128i Function(__m128i)>();

  __m128i _mm_haddq_epu8(
    __m128i arg0,
  ) {
    return __mm_haddq_epu8(
      arg0,
    );
  }

  late final __mm_haddq_epu8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i)>>('_mm_haddq_epu8');
  late final __mm_haddq_epu8 =
      __mm_haddq_epu8Ptr.asFunction<__m128i Function(__m128i)>();

  __m128i _mm_haddd_epu16(
    __m128i arg0,
  ) {
    return __mm_haddd_epu16(
      arg0,
    );
  }

  late final __mm_haddd_epu16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i)>>('_mm_haddd_epu16');
  late final __mm_haddd_epu16 =
      __mm_haddd_epu16Ptr.asFunction<__m128i Function(__m128i)>();

  __m128i _mm_haddq_epu16(
    __m128i arg0,
  ) {
    return __mm_haddq_epu16(
      arg0,
    );
  }

  late final __mm_haddq_epu16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i)>>('_mm_haddq_epu16');
  late final __mm_haddq_epu16 =
      __mm_haddq_epu16Ptr.asFunction<__m128i Function(__m128i)>();

  __m128i _mm_haddq_epu32(
    __m128i arg0,
  ) {
    return __mm_haddq_epu32(
      arg0,
    );
  }

  late final __mm_haddq_epu32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i)>>('_mm_haddq_epu32');
  late final __mm_haddq_epu32 =
      __mm_haddq_epu32Ptr.asFunction<__m128i Function(__m128i)>();

  __m128i _mm_hsubw_epi8(
    __m128i arg0,
  ) {
    return __mm_hsubw_epi8(
      arg0,
    );
  }

  late final __mm_hsubw_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i)>>('_mm_hsubw_epi8');
  late final __mm_hsubw_epi8 =
      __mm_hsubw_epi8Ptr.asFunction<__m128i Function(__m128i)>();

  __m128i _mm_hsubd_epi16(
    __m128i arg0,
  ) {
    return __mm_hsubd_epi16(
      arg0,
    );
  }

  late final __mm_hsubd_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i)>>('_mm_hsubd_epi16');
  late final __mm_hsubd_epi16 =
      __mm_hsubd_epi16Ptr.asFunction<__m128i Function(__m128i)>();

  __m128i _mm_hsubq_epi32(
    __m128i arg0,
  ) {
    return __mm_hsubq_epi32(
      arg0,
    );
  }

  late final __mm_hsubq_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i)>>('_mm_hsubq_epi32');
  late final __mm_hsubq_epi32 =
      __mm_hsubq_epi32Ptr.asFunction<__m128i Function(__m128i)>();

  __m128i _mm_cmov_si128(
    __m128i arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_cmov_si128(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_cmov_si128Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i, __m128i)>>(
          '_mm_cmov_si128');
  late final __mm_cmov_si128 = __mm_cmov_si128Ptr
      .asFunction<__m128i Function(__m128i, __m128i, __m128i)>();

  __m128i _mm_perm_epi8(
    __m128i arg0,
    __m128i arg1,
    __m128i arg2,
  ) {
    return __mm_perm_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_perm_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i, __m128i)>>(
          '_mm_perm_epi8');
  late final __mm_perm_epi8 = __mm_perm_epi8Ptr
      .asFunction<__m128i Function(__m128i, __m128i, __m128i)>();

  __m128i _mm_rot_epi8(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_rot_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm_rot_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_rot_epi8');
  late final __mm_rot_epi8 =
      __mm_rot_epi8Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_rot_epi16(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_rot_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm_rot_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_rot_epi16');
  late final __mm_rot_epi16 =
      __mm_rot_epi16Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_rot_epi32(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_rot_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm_rot_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_rot_epi32');
  late final __mm_rot_epi32 =
      __mm_rot_epi32Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_rot_epi64(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_rot_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm_rot_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_rot_epi64');
  late final __mm_rot_epi64 =
      __mm_rot_epi64Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_roti_epi8(
    __m128i arg0,
    int arg1,
  ) {
    return __mm_roti_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm_roti_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, ffi.Int32)>>(
          '_mm_roti_epi8');
  late final __mm_roti_epi8 =
      __mm_roti_epi8Ptr.asFunction<__m128i Function(__m128i, int)>();

  __m128i _mm_roti_epi16(
    __m128i arg0,
    int arg1,
  ) {
    return __mm_roti_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm_roti_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, ffi.Int32)>>(
          '_mm_roti_epi16');
  late final __mm_roti_epi16 =
      __mm_roti_epi16Ptr.asFunction<__m128i Function(__m128i, int)>();

  __m128i _mm_roti_epi32(
    __m128i arg0,
    int arg1,
  ) {
    return __mm_roti_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm_roti_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, ffi.Int32)>>(
          '_mm_roti_epi32');
  late final __mm_roti_epi32 =
      __mm_roti_epi32Ptr.asFunction<__m128i Function(__m128i, int)>();

  __m128i _mm_roti_epi64(
    __m128i arg0,
    int arg1,
  ) {
    return __mm_roti_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm_roti_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, ffi.Int32)>>(
          '_mm_roti_epi64');
  late final __mm_roti_epi64 =
      __mm_roti_epi64Ptr.asFunction<__m128i Function(__m128i, int)>();

  __m128i _mm_shl_epi8(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_shl_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm_shl_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_shl_epi8');
  late final __mm_shl_epi8 =
      __mm_shl_epi8Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_shl_epi16(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_shl_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm_shl_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_shl_epi16');
  late final __mm_shl_epi16 =
      __mm_shl_epi16Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_shl_epi32(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_shl_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm_shl_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_shl_epi32');
  late final __mm_shl_epi32 =
      __mm_shl_epi32Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_shl_epi64(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_shl_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm_shl_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_shl_epi64');
  late final __mm_shl_epi64 =
      __mm_shl_epi64Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_sha_epi8(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_sha_epi8(
      arg0,
      arg1,
    );
  }

  late final __mm_sha_epi8Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_sha_epi8');
  late final __mm_sha_epi8 =
      __mm_sha_epi8Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_sha_epi16(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_sha_epi16(
      arg0,
      arg1,
    );
  }

  late final __mm_sha_epi16Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_sha_epi16');
  late final __mm_sha_epi16 =
      __mm_sha_epi16Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_sha_epi32(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_sha_epi32(
      arg0,
      arg1,
    );
  }

  late final __mm_sha_epi32Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_sha_epi32');
  late final __mm_sha_epi32 =
      __mm_sha_epi32Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_sha_epi64(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_sha_epi64(
      arg0,
      arg1,
    );
  }

  late final __mm_sha_epi64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_sha_epi64');
  late final __mm_sha_epi64 =
      __mm_sha_epi64Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_com_epu8(
    __m128i arg0,
    __m128i arg1,
    int arg2,
  ) {
    return __mm_com_epu8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_com_epu8Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__m128i, __m128i, ffi.Int32)>>(
      '_mm_com_epu8');
  late final __mm_com_epu8 =
      __mm_com_epu8Ptr.asFunction<__m128i Function(__m128i, __m128i, int)>();

  __m128i _mm_com_epu16(
    __m128i arg0,
    __m128i arg1,
    int arg2,
  ) {
    return __mm_com_epu16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_com_epu16Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__m128i, __m128i, ffi.Int32)>>(
      '_mm_com_epu16');
  late final __mm_com_epu16 =
      __mm_com_epu16Ptr.asFunction<__m128i Function(__m128i, __m128i, int)>();

  __m128i _mm_com_epu32(
    __m128i arg0,
    __m128i arg1,
    int arg2,
  ) {
    return __mm_com_epu32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_com_epu32Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__m128i, __m128i, ffi.Int32)>>(
      '_mm_com_epu32');
  late final __mm_com_epu32 =
      __mm_com_epu32Ptr.asFunction<__m128i Function(__m128i, __m128i, int)>();

  __m128i _mm_com_epu64(
    __m128i arg0,
    __m128i arg1,
    int arg2,
  ) {
    return __mm_com_epu64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_com_epu64Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__m128i, __m128i, ffi.Int32)>>(
      '_mm_com_epu64');
  late final __mm_com_epu64 =
      __mm_com_epu64Ptr.asFunction<__m128i Function(__m128i, __m128i, int)>();

  __m128i _mm_com_epi8(
    __m128i arg0,
    __m128i arg1,
    int arg2,
  ) {
    return __mm_com_epi8(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_com_epi8Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__m128i, __m128i, ffi.Int32)>>(
      '_mm_com_epi8');
  late final __mm_com_epi8 =
      __mm_com_epi8Ptr.asFunction<__m128i Function(__m128i, __m128i, int)>();

  __m128i _mm_com_epi16(
    __m128i arg0,
    __m128i arg1,
    int arg2,
  ) {
    return __mm_com_epi16(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_com_epi16Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__m128i, __m128i, ffi.Int32)>>(
      '_mm_com_epi16');
  late final __mm_com_epi16 =
      __mm_com_epi16Ptr.asFunction<__m128i Function(__m128i, __m128i, int)>();

  __m128i _mm_com_epi32(
    __m128i arg0,
    __m128i arg1,
    int arg2,
  ) {
    return __mm_com_epi32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_com_epi32Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__m128i, __m128i, ffi.Int32)>>(
      '_mm_com_epi32');
  late final __mm_com_epi32 =
      __mm_com_epi32Ptr.asFunction<__m128i Function(__m128i, __m128i, int)>();

  __m128i _mm_com_epi64(
    __m128i arg0,
    __m128i arg1,
    int arg2,
  ) {
    return __mm_com_epi64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_com_epi64Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__m128i, __m128i, ffi.Int32)>>(
      '_mm_com_epi64');
  late final __mm_com_epi64 =
      __mm_com_epi64Ptr.asFunction<__m128i Function(__m128i, __m128i, int)>();

  __m128 _mm_frcz_ps(
    __m128 arg0,
  ) {
    return __mm_frcz_ps(
      arg0,
    );
  }

  late final __mm_frcz_psPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128)>>('_mm_frcz_ps');
  late final __mm_frcz_ps =
      __mm_frcz_psPtr.asFunction<__m128 Function(__m128)>();

  _m128d _mm_frcz_pd(
    _m128d arg0,
  ) {
    return __mm_frcz_pd(
      arg0,
    );
  }

  late final __mm_frcz_pdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d)>>('_mm_frcz_pd');
  late final __mm_frcz_pd =
      __mm_frcz_pdPtr.asFunction<_m128d Function(_m128d)>();

  __m128 _mm_frcz_ss(
    __m128 arg0,
    __m128 arg1,
  ) {
    return __mm_frcz_ss(
      arg0,
      arg1,
    );
  }

  late final __mm_frcz_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, __m128)>>(
          '_mm_frcz_ss');
  late final __mm_frcz_ss =
      __mm_frcz_ssPtr.asFunction<__m128 Function(__m128, __m128)>();

  _m128d _mm_frcz_sd(
    _m128d arg0,
    _m128d arg1,
  ) {
    return __mm_frcz_sd(
      arg0,
      arg1,
    );
  }

  late final __mm_frcz_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, _m128d)>>(
          '_mm_frcz_sd');
  late final __mm_frcz_sd =
      __mm_frcz_sdPtr.asFunction<_m128d Function(_m128d, _m128d)>();

  __m128 _mm_permute2_ps(
    __m128 arg0,
    __m128 arg1,
    __m128i arg2,
    int arg3,
  ) {
    return __mm_permute2_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_permute2_psPtr = _lookup<
      ffi.NativeFunction<
          __m128 Function(
              __m128, __m128, __m128i, ffi.Int32)>>('_mm_permute2_ps');
  late final __mm_permute2_ps = __mm_permute2_psPtr
      .asFunction<__m128 Function(__m128, __m128, __m128i, int)>();

  _m128d _mm_permute2_pd(
    _m128d arg0,
    _m128d arg1,
    __m128i arg2,
    int arg3,
  ) {
    return __mm_permute2_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_permute2_pdPtr = _lookup<
      ffi.NativeFunction<
          _m128d Function(
              _m128d, _m128d, __m128i, ffi.Int32)>>('_mm_permute2_pd');
  late final __mm_permute2_pd = __mm_permute2_pdPtr
      .asFunction<_m128d Function(_m128d, _m128d, __m128i, int)>();

  __m256 _mm256_macc_ps(
    __m256 arg0,
    __m256 arg1,
    __m256 arg2,
  ) {
    return __mm256_macc_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_macc_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256, __m256, __m256)>>(
          '_mm256_macc_ps');
  late final __mm256_macc_ps =
      __mm256_macc_psPtr.asFunction<__m256 Function(__m256, __m256, __m256)>();

  _m256d _mm256_macc_pd(
    _m256d arg0,
    _m256d arg1,
    _m256d arg2,
  ) {
    return __mm256_macc_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_macc_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d, _m256d, _m256d)>>(
          '_mm256_macc_pd');
  late final __mm256_macc_pd =
      __mm256_macc_pdPtr.asFunction<_m256d Function(_m256d, _m256d, _m256d)>();

  __m256 _mm256_maddsub_ps(
    __m256 arg0,
    __m256 arg1,
    __m256 arg2,
  ) {
    return __mm256_maddsub_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maddsub_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256, __m256, __m256)>>(
          '_mm256_maddsub_ps');
  late final __mm256_maddsub_ps = __mm256_maddsub_psPtr
      .asFunction<__m256 Function(__m256, __m256, __m256)>();

  _m256d _mm256_maddsub_pd(
    _m256d arg0,
    _m256d arg1,
    _m256d arg2,
  ) {
    return __mm256_maddsub_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_maddsub_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d, _m256d, _m256d)>>(
          '_mm256_maddsub_pd');
  late final __mm256_maddsub_pd = __mm256_maddsub_pdPtr
      .asFunction<_m256d Function(_m256d, _m256d, _m256d)>();

  __m256 _mm256_msubadd_ps(
    __m256 arg0,
    __m256 arg1,
    __m256 arg2,
  ) {
    return __mm256_msubadd_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_msubadd_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256, __m256, __m256)>>(
          '_mm256_msubadd_ps');
  late final __mm256_msubadd_ps = __mm256_msubadd_psPtr
      .asFunction<__m256 Function(__m256, __m256, __m256)>();

  _m256d _mm256_msubadd_pd(
    _m256d arg0,
    _m256d arg1,
    _m256d arg2,
  ) {
    return __mm256_msubadd_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_msubadd_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d, _m256d, _m256d)>>(
          '_mm256_msubadd_pd');
  late final __mm256_msubadd_pd = __mm256_msubadd_pdPtr
      .asFunction<_m256d Function(_m256d, _m256d, _m256d)>();

  __m256 _mm256_msub_ps(
    __m256 arg0,
    __m256 arg1,
    __m256 arg2,
  ) {
    return __mm256_msub_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_msub_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256, __m256, __m256)>>(
          '_mm256_msub_ps');
  late final __mm256_msub_ps =
      __mm256_msub_psPtr.asFunction<__m256 Function(__m256, __m256, __m256)>();

  _m256d _mm256_msub_pd(
    _m256d arg0,
    _m256d arg1,
    _m256d arg2,
  ) {
    return __mm256_msub_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_msub_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d, _m256d, _m256d)>>(
          '_mm256_msub_pd');
  late final __mm256_msub_pd =
      __mm256_msub_pdPtr.asFunction<_m256d Function(_m256d, _m256d, _m256d)>();

  __m256 _mm256_nmacc_ps(
    __m256 arg0,
    __m256 arg1,
    __m256 arg2,
  ) {
    return __mm256_nmacc_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_nmacc_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256, __m256, __m256)>>(
          '_mm256_nmacc_ps');
  late final __mm256_nmacc_ps =
      __mm256_nmacc_psPtr.asFunction<__m256 Function(__m256, __m256, __m256)>();

  _m256d _mm256_nmacc_pd(
    _m256d arg0,
    _m256d arg1,
    _m256d arg2,
  ) {
    return __mm256_nmacc_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_nmacc_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d, _m256d, _m256d)>>(
          '_mm256_nmacc_pd');
  late final __mm256_nmacc_pd =
      __mm256_nmacc_pdPtr.asFunction<_m256d Function(_m256d, _m256d, _m256d)>();

  __m256 _mm256_nmsub_ps(
    __m256 arg0,
    __m256 arg1,
    __m256 arg2,
  ) {
    return __mm256_nmsub_ps(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_nmsub_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256, __m256, __m256)>>(
          '_mm256_nmsub_ps');
  late final __mm256_nmsub_ps =
      __mm256_nmsub_psPtr.asFunction<__m256 Function(__m256, __m256, __m256)>();

  _m256d _mm256_nmsub_pd(
    _m256d arg0,
    _m256d arg1,
    _m256d arg2,
  ) {
    return __mm256_nmsub_pd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_nmsub_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d, _m256d, _m256d)>>(
          '_mm256_nmsub_pd');
  late final __mm256_nmsub_pd =
      __mm256_nmsub_pdPtr.asFunction<_m256d Function(_m256d, _m256d, _m256d)>();

  __m256i _mm256_cmov_si256(
    __m256i arg0,
    __m256i arg1,
    __m256i arg2,
  ) {
    return __mm256_cmov_si256(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm256_cmov_si256Ptr =
      _lookup<ffi.NativeFunction<__m256i Function(__m256i, __m256i, __m256i)>>(
          '_mm256_cmov_si256');
  late final __mm256_cmov_si256 = __mm256_cmov_si256Ptr
      .asFunction<__m256i Function(__m256i, __m256i, __m256i)>();

  __m256 _mm256_frcz_ps(
    __m256 arg0,
  ) {
    return __mm256_frcz_ps(
      arg0,
    );
  }

  late final __mm256_frcz_psPtr =
      _lookup<ffi.NativeFunction<__m256 Function(__m256)>>('_mm256_frcz_ps');
  late final __mm256_frcz_ps =
      __mm256_frcz_psPtr.asFunction<__m256 Function(__m256)>();

  _m256d _mm256_frcz_pd(
    _m256d arg0,
  ) {
    return __mm256_frcz_pd(
      arg0,
    );
  }

  late final __mm256_frcz_pdPtr =
      _lookup<ffi.NativeFunction<_m256d Function(_m256d)>>('_mm256_frcz_pd');
  late final __mm256_frcz_pd =
      __mm256_frcz_pdPtr.asFunction<_m256d Function(_m256d)>();

  __m256 _mm256_permute2_ps(
    __m256 arg0,
    __m256 arg1,
    __m256i arg2,
    int arg3,
  ) {
    return __mm256_permute2_ps(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_permute2_psPtr = _lookup<
      ffi.NativeFunction<
          __m256 Function(
              __m256, __m256, __m256i, ffi.Int32)>>('_mm256_permute2_ps');
  late final __mm256_permute2_ps = __mm256_permute2_psPtr
      .asFunction<__m256 Function(__m256, __m256, __m256i, int)>();

  _m256d _mm256_permute2_pd(
    _m256d arg0,
    _m256d arg1,
    __m256i arg2,
    int arg3,
  ) {
    return __mm256_permute2_pd(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm256_permute2_pdPtr = _lookup<
      ffi.NativeFunction<
          _m256d Function(
              _m256d, _m256d, __m256i, ffi.Int32)>>('_mm256_permute2_pd');
  late final __mm256_permute2_pd = __mm256_permute2_pdPtr
      .asFunction<_m256d Function(_m256d, _m256d, __m256i, int)>();

  void __llwpcb(
    ffi.Pointer<ffi.Void> arg0,
  ) {
    return ___llwpcb(
      arg0,
    );
  }

  late final ___llwpcbPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ffi.Void>)>>(
          '__llwpcb');
  late final ___llwpcb =
      ___llwpcbPtr.asFunction<void Function(ffi.Pointer<ffi.Void>)>();

  ffi.Pointer<ffi.Void> __slwpcb() {
    return ___slwpcb();
  }

  late final ___slwpcbPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Void> Function()>>('__slwpcb');
  late final ___slwpcb =
      ___slwpcbPtr.asFunction<ffi.Pointer<ffi.Void> Function()>();

  void __lwpval32(
    int arg0,
    int arg1,
    int arg2,
  ) {
    return ___lwpval32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final ___lwpval32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Uint32, ffi.Uint32, ffi.Uint32)>>('__lwpval32');
  late final ___lwpval32 =
      ___lwpval32Ptr.asFunction<void Function(int, int, int)>();

  int __lwpins32(
    int arg0,
    int arg1,
    int arg2,
  ) {
    return ___lwpins32(
      arg0,
      arg1,
      arg2,
    );
  }

  late final ___lwpins32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Uint8 Function(
              ffi.Uint32, ffi.Uint32, ffi.Uint32)>>('__lwpins32');
  late final ___lwpins32 =
      ___lwpins32Ptr.asFunction<int Function(int, int, int)>();

  void __lwpval64(
    int arg0,
    int arg1,
    int arg2,
  ) {
    return ___lwpval64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final ___lwpval64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Uint64, ffi.Uint32, ffi.Uint32)>>('__lwpval64');
  late final ___lwpval64 =
      ___lwpval64Ptr.asFunction<void Function(int, int, int)>();

  int __lwpins64(
    int arg0,
    int arg1,
    int arg2,
  ) {
    return ___lwpins64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final ___lwpins64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Uint8 Function(
              ffi.Uint64, ffi.Uint32, ffi.Uint32)>>('__lwpins64');
  late final ___lwpins64 =
      ___lwpins64Ptr.asFunction<int Function(int, int, int)>();

  int _andn_u32(
    int arg0,
    int arg1,
  ) {
    return __andn_u32(
      arg0,
      arg1,
    );
  }

  late final __andn_u32Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint32 Function(ffi.Uint32, ffi.Uint32)>>(
          '_andn_u32');
  late final __andn_u32 = __andn_u32Ptr.asFunction<int Function(int, int)>();

  int _andn_u64(
    int arg0,
    int arg1,
  ) {
    return __andn_u64(
      arg0,
      arg1,
    );
  }

  late final __andn_u64Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function(ffi.Uint64, ffi.Uint64)>>(
          '_andn_u64');
  late final __andn_u64 = __andn_u64Ptr.asFunction<int Function(int, int)>();

  int _bextri_u32(
    int arg0,
    int arg1,
  ) {
    return __bextri_u32(
      arg0,
      arg1,
    );
  }

  late final __bextri_u32Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint32 Function(ffi.Uint32, ffi.Uint32)>>(
          '_bextri_u32');
  late final __bextri_u32 =
      __bextri_u32Ptr.asFunction<int Function(int, int)>();

  int _blcfill_u32(
    int arg0,
  ) {
    return __blcfill_u32(
      arg0,
    );
  }

  late final __blcfill_u32Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint32 Function(ffi.Uint32)>>(
          '_blcfill_u32');
  late final __blcfill_u32 = __blcfill_u32Ptr.asFunction<int Function(int)>();

  int _blsfill_u32(
    int arg0,
  ) {
    return __blsfill_u32(
      arg0,
    );
  }

  late final __blsfill_u32Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint32 Function(ffi.Uint32)>>(
          '_blsfill_u32');
  late final __blsfill_u32 = __blsfill_u32Ptr.asFunction<int Function(int)>();

  int _blcs_u32(
    int arg0,
  ) {
    return __blcs_u32(
      arg0,
    );
  }

  late final __blcs_u32Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint32 Function(ffi.Uint32)>>('_blcs_u32');
  late final __blcs_u32 = __blcs_u32Ptr.asFunction<int Function(int)>();

  int _tzmsk_u32(
    int arg0,
  ) {
    return __tzmsk_u32(
      arg0,
    );
  }

  late final __tzmsk_u32Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint32 Function(ffi.Uint32)>>(
          '_tzmsk_u32');
  late final __tzmsk_u32 = __tzmsk_u32Ptr.asFunction<int Function(int)>();

  int _blcic_u32(
    int arg0,
  ) {
    return __blcic_u32(
      arg0,
    );
  }

  late final __blcic_u32Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint32 Function(ffi.Uint32)>>(
          '_blcic_u32');
  late final __blcic_u32 = __blcic_u32Ptr.asFunction<int Function(int)>();

  int _blsic_u32(
    int arg0,
  ) {
    return __blsic_u32(
      arg0,
    );
  }

  late final __blsic_u32Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint32 Function(ffi.Uint32)>>(
          '_blsic_u32');
  late final __blsic_u32 = __blsic_u32Ptr.asFunction<int Function(int)>();

  int _t1mskc_u32(
    int arg0,
  ) {
    return __t1mskc_u32(
      arg0,
    );
  }

  late final __t1mskc_u32Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint32 Function(ffi.Uint32)>>(
          '_t1mskc_u32');
  late final __t1mskc_u32 = __t1mskc_u32Ptr.asFunction<int Function(int)>();

  int _blcmsk_u32(
    int arg0,
  ) {
    return __blcmsk_u32(
      arg0,
    );
  }

  late final __blcmsk_u32Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint32 Function(ffi.Uint32)>>(
          '_blcmsk_u32');
  late final __blcmsk_u32 = __blcmsk_u32Ptr.asFunction<int Function(int)>();

  int _blci_u32(
    int arg0,
  ) {
    return __blci_u32(
      arg0,
    );
  }

  late final __blci_u32Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint32 Function(ffi.Uint32)>>('_blci_u32');
  late final __blci_u32 = __blci_u32Ptr.asFunction<int Function(int)>();

  int _bextri_u64(
    int arg0,
    int arg1,
  ) {
    return __bextri_u64(
      arg0,
      arg1,
    );
  }

  late final __bextri_u64Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function(ffi.Uint64, ffi.Uint32)>>(
          '_bextri_u64');
  late final __bextri_u64 =
      __bextri_u64Ptr.asFunction<int Function(int, int)>();

  int _blcfill_u64(
    int arg0,
  ) {
    return __blcfill_u64(
      arg0,
    );
  }

  late final __blcfill_u64Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function(ffi.Uint64)>>(
          '_blcfill_u64');
  late final __blcfill_u64 = __blcfill_u64Ptr.asFunction<int Function(int)>();

  int _blsfill_u64(
    int arg0,
  ) {
    return __blsfill_u64(
      arg0,
    );
  }

  late final __blsfill_u64Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function(ffi.Uint64)>>(
          '_blsfill_u64');
  late final __blsfill_u64 = __blsfill_u64Ptr.asFunction<int Function(int)>();

  int _blcs_u64(
    int arg0,
  ) {
    return __blcs_u64(
      arg0,
    );
  }

  late final __blcs_u64Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function(ffi.Uint64)>>('_blcs_u64');
  late final __blcs_u64 = __blcs_u64Ptr.asFunction<int Function(int)>();

  int _tzmsk_u64(
    int arg0,
  ) {
    return __tzmsk_u64(
      arg0,
    );
  }

  late final __tzmsk_u64Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function(ffi.Uint64)>>(
          '_tzmsk_u64');
  late final __tzmsk_u64 = __tzmsk_u64Ptr.asFunction<int Function(int)>();

  int _blcic_u64(
    int arg0,
  ) {
    return __blcic_u64(
      arg0,
    );
  }

  late final __blcic_u64Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function(ffi.Uint64)>>(
          '_blcic_u64');
  late final __blcic_u64 = __blcic_u64Ptr.asFunction<int Function(int)>();

  int _blsic_u64(
    int arg0,
  ) {
    return __blsic_u64(
      arg0,
    );
  }

  late final __blsic_u64Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function(ffi.Uint64)>>(
          '_blsic_u64');
  late final __blsic_u64 = __blsic_u64Ptr.asFunction<int Function(int)>();

  int _t1mskc_u64(
    int arg0,
  ) {
    return __t1mskc_u64(
      arg0,
    );
  }

  late final __t1mskc_u64Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function(ffi.Uint64)>>(
          '_t1mskc_u64');
  late final __t1mskc_u64 = __t1mskc_u64Ptr.asFunction<int Function(int)>();

  int _blcmsk_u64(
    int arg0,
  ) {
    return __blcmsk_u64(
      arg0,
    );
  }

  late final __blcmsk_u64Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function(ffi.Uint64)>>(
          '_blcmsk_u64');
  late final __blcmsk_u64 = __blcmsk_u64Ptr.asFunction<int Function(int)>();

  int _blci_u64(
    int arg0,
  ) {
    return __blci_u64(
      arg0,
    );
  }

  late final __blci_u64Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function(ffi.Uint64)>>('_blci_u64');
  late final __blci_u64 = __blci_u64Ptr.asFunction<int Function(int)>();

  void _mm_monitorx(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
    int arg2,
  ) {
    return __mm_monitorx(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_monitorxPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<ffi.Void>, ffi.Uint32, ffi.Uint32)>>('_mm_monitorx');
  late final __mm_monitorx = __mm_monitorxPtr
      .asFunction<void Function(ffi.Pointer<ffi.Void>, int, int)>();

  void _mm_mwaitx(
    int arg0,
    int arg1,
    int arg2,
  ) {
    return __mm_mwaitx(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_mwaitxPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Uint32, ffi.Uint32, ffi.Uint32)>>('_mm_mwaitx');
  late final __mm_mwaitx =
      __mm_mwaitxPtr.asFunction<void Function(int, int, int)>();

  void _mm_clzero(
    ffi.Pointer<ffi.Void> arg0,
  ) {
    return __mm_clzero(
      arg0,
    );
  }

  late final __mm_clzeroPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ffi.Void>)>>(
          '_mm_clzero');
  late final __mm_clzero =
      __mm_clzeroPtr.asFunction<void Function(ffi.Pointer<ffi.Void>)>();

  int __rmpupdate(
    int arg0,
    ffi.Pointer<rmp_seg> arg1,
    int arg2,
  ) {
    return ___rmpupdate(
      arg0,
      arg1,
      arg2,
    );
  }

  late final ___rmpupdatePtr = _lookup<
      ffi.NativeFunction<
          ffi.Uint32 Function(
              ffi.Uint64, ffi.Pointer<rmp_seg>, ffi.Int32)>>('__rmpupdate');
  late final ___rmpupdate = ___rmpupdatePtr
      .asFunction<int Function(int, ffi.Pointer<rmp_seg>, int)>();

  int __pvalidate(
    int arg0,
    int arg1,
    int arg2,
    ffi.Pointer<ffi.Int32> arg3,
  ) {
    return ___pvalidate(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final ___pvalidatePtr = _lookup<
      ffi.NativeFunction<
          ffi.Uint32 Function(ffi.Uint64, ffi.Int32, ffi.Int32,
              ffi.Pointer<ffi.Int32>)>>('__pvalidate');
  late final ___pvalidate = ___pvalidatePtr
      .asFunction<int Function(int, int, int, ffi.Pointer<ffi.Int32>)>();

  int __psmash(
    int arg0,
  ) {
    return ___psmash(
      arg0,
    );
  }

  late final ___psmashPtr =
      _lookup<ffi.NativeFunction<ffi.Uint32 Function(ffi.Uint64)>>('__psmash');
  late final ___psmash = ___psmashPtr.asFunction<int Function(int)>();

  int __rmpadjust(
    int arg0,
    int arg1,
    int arg2,
  ) {
    return ___rmpadjust(
      arg0,
      arg1,
      arg2,
    );
  }

  late final ___rmpadjustPtr = _lookup<
      ffi.NativeFunction<
          ffi.Uint32 Function(
              ffi.Uint64, ffi.Int32, ffi.Int32)>>('__rmpadjust');
  late final ___rmpadjust =
      ___rmpadjustPtr.asFunction<int Function(int, int, int)>();

  void __svm_invlpgb(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
  ) {
    return ___svm_invlpgb(
      arg0,
      arg1,
    );
  }

  late final ___svm_invlpgbPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<ffi.Void>, ffi.Int32)>>('__svm_invlpgb');
  late final ___svm_invlpgb =
      ___svm_invlpgbPtr.asFunction<void Function(ffi.Pointer<ffi.Void>, int)>();

  void __svm_tlbsync() {
    return ___svm_tlbsync();
  }

  late final ___svm_tlbsyncPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('__svm_tlbsync');
  late final ___svm_tlbsync = ___svm_tlbsyncPtr.asFunction<void Function()>();

  ffi.Pointer<ffi.Void> _AddressOfReturnAddress() {
    return __AddressOfReturnAddress();
  }

  late final __AddressOfReturnAddressPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Void> Function()>>(
          '_AddressOfReturnAddress');
  late final __AddressOfReturnAddress = __AddressOfReturnAddressPtr
      .asFunction<ffi.Pointer<ffi.Void> Function()>();

  int _cvt_dtoi_fast(
    double arg0,
  ) {
    return __cvt_dtoi_fast(
      arg0,
    );
  }

  late final __cvt_dtoi_fastPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Double)>>(
          '_cvt_dtoi_fast');
  late final __cvt_dtoi_fast =
      __cvt_dtoi_fastPtr.asFunction<int Function(double)>();

  int _cvt_dtoll_fast(
    double arg0,
  ) {
    return __cvt_dtoll_fast(
      arg0,
    );
  }

  late final __cvt_dtoll_fastPtr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(ffi.Double)>>(
          '_cvt_dtoll_fast');
  late final __cvt_dtoll_fast =
      __cvt_dtoll_fastPtr.asFunction<int Function(double)>();

  int _cvt_dtoui_fast(
    double arg0,
  ) {
    return __cvt_dtoui_fast(
      arg0,
    );
  }

  late final __cvt_dtoui_fastPtr =
      _lookup<ffi.NativeFunction<ffi.Uint32 Function(ffi.Double)>>(
          '_cvt_dtoui_fast');
  late final __cvt_dtoui_fast =
      __cvt_dtoui_fastPtr.asFunction<int Function(double)>();

  int _cvt_dtoull_fast(
    double arg0,
  ) {
    return __cvt_dtoull_fast(
      arg0,
    );
  }

  late final __cvt_dtoull_fastPtr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function(ffi.Double)>>(
          '_cvt_dtoull_fast');
  late final __cvt_dtoull_fast =
      __cvt_dtoull_fastPtr.asFunction<int Function(double)>();

  int _cvt_ftoi_fast(
    double arg0,
  ) {
    return __cvt_ftoi_fast(
      arg0,
    );
  }

  late final __cvt_ftoi_fastPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Float)>>(
          '_cvt_ftoi_fast');
  late final __cvt_ftoi_fast =
      __cvt_ftoi_fastPtr.asFunction<int Function(double)>();

  int _cvt_ftoll_fast(
    double arg0,
  ) {
    return __cvt_ftoll_fast(
      arg0,
    );
  }

  late final __cvt_ftoll_fastPtr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(ffi.Float)>>(
          '_cvt_ftoll_fast');
  late final __cvt_ftoll_fast =
      __cvt_ftoll_fastPtr.asFunction<int Function(double)>();

  int _cvt_ftoui_fast(
    double arg0,
  ) {
    return __cvt_ftoui_fast(
      arg0,
    );
  }

  late final __cvt_ftoui_fastPtr =
      _lookup<ffi.NativeFunction<ffi.Uint32 Function(ffi.Float)>>(
          '_cvt_ftoui_fast');
  late final __cvt_ftoui_fast =
      __cvt_ftoui_fastPtr.asFunction<int Function(double)>();

  int _cvt_ftoull_fast(
    double arg0,
  ) {
    return __cvt_ftoull_fast(
      arg0,
    );
  }

  late final __cvt_ftoull_fastPtr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function(ffi.Float)>>(
          '_cvt_ftoull_fast');
  late final __cvt_ftoull_fast =
      __cvt_ftoull_fastPtr.asFunction<int Function(double)>();

  int _interlockedadd(
    ffi.Pointer<ffi.Int64> _Addend,
    int _Value,
  ) {
    return __interlockedadd(
      _Addend,
      _Value,
    );
  }

  late final __interlockedaddPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int64 Function(
              ffi.Pointer<ffi.Int64>, ffi.Int64)>>('_interlockedadd');
  late final __interlockedadd = __interlockedaddPtr
      .asFunction<int Function(ffi.Pointer<ffi.Int64>, int)>();

  int _interlockedadd64(
    ffi.Pointer<ffi.Int64> _Addend,
    int _Value,
  ) {
    return __interlockedadd64(
      _Addend,
      _Value,
    );
  }

  late final __interlockedadd64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Int64 Function(
              ffi.Pointer<ffi.Int64>, ffi.Int64)>>('_interlockedadd64');
  late final __interlockedadd64 = __interlockedadd64Ptr
      .asFunction<int Function(ffi.Pointer<ffi.Int64>, int)>();

  int _InterlockedAnd16_np(
    ffi.Pointer<ffi.Int16> _Value,
    int _Mask,
  ) {
    return __InterlockedAnd16_np(
      _Value,
      _Mask,
    );
  }

  late final __InterlockedAnd16_npPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int16 Function(
              ffi.Pointer<ffi.Int16>, ffi.Int16)>>('_InterlockedAnd16_np');
  late final __InterlockedAnd16_np = __InterlockedAnd16_npPtr
      .asFunction<int Function(ffi.Pointer<ffi.Int16>, int)>();

  int _InterlockedAnd64_np(
    ffi.Pointer<ffi.Int64> _Value,
    int _Mask,
  ) {
    return __InterlockedAnd64_np(
      _Value,
      _Mask,
    );
  }

  late final __InterlockedAnd64_npPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int64 Function(
              ffi.Pointer<ffi.Int64>, ffi.Int64)>>('_InterlockedAnd64_np');
  late final __InterlockedAnd64_np = __InterlockedAnd64_npPtr
      .asFunction<int Function(ffi.Pointer<ffi.Int64>, int)>();

  int _InterlockedAnd8_np(
    ffi.Pointer<ffi.Int8> _Value,
    int _Mask,
  ) {
    return __InterlockedAnd8_np(
      _Value,
      _Mask,
    );
  }

  late final __InterlockedAnd8_npPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int8 Function(
              ffi.Pointer<ffi.Int8>, ffi.Int8)>>('_InterlockedAnd8_np');
  late final __InterlockedAnd8_np = __InterlockedAnd8_npPtr
      .asFunction<int Function(ffi.Pointer<ffi.Int8>, int)>();

  int _InterlockedAnd_np(
    ffi.Pointer<ffi.Int64> _Value,
    int _Mask,
  ) {
    return __InterlockedAnd_np(
      _Value,
      _Mask,
    );
  }

  late final __InterlockedAnd_npPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int64 Function(
              ffi.Pointer<ffi.Int64>, ffi.Int64)>>('_InterlockedAnd_np');
  late final __InterlockedAnd_np = __InterlockedAnd_npPtr
      .asFunction<int Function(ffi.Pointer<ffi.Int64>, int)>();

  int _InterlockedCompareExchange128_np(
    ffi.Pointer<ffi.Int64> _Destination,
    int _ExchangeHigh,
    int _ExchangeLow,
    ffi.Pointer<ffi.Int64> _ComparandResult,
  ) {
    return __InterlockedCompareExchange128_np(
      _Destination,
      _ExchangeHigh,
      _ExchangeLow,
      _ComparandResult,
    );
  }

  late final __InterlockedCompareExchange128_npPtr = _lookup<
      ffi.NativeFunction<
          ffi.Uint8 Function(ffi.Pointer<ffi.Int64>, ffi.Int64, ffi.Int64,
              ffi.Pointer<ffi.Int64>)>>('_InterlockedCompareExchange128_np');
  late final __InterlockedCompareExchange128_np =
      __InterlockedCompareExchange128_npPtr.asFunction<
          int Function(
              ffi.Pointer<ffi.Int64>, int, int, ffi.Pointer<ffi.Int64>)>();

  int _InterlockedCompareExchange16_np(
    ffi.Pointer<ffi.Int16> _Destination,
    int _Exchange,
    int _Comparand,
  ) {
    return __InterlockedCompareExchange16_np(
      _Destination,
      _Exchange,
      _Comparand,
    );
  }

  late final __InterlockedCompareExchange16_npPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int16 Function(ffi.Pointer<ffi.Int16>, ffi.Int16,
              ffi.Int16)>>('_InterlockedCompareExchange16_np');
  late final __InterlockedCompareExchange16_np =
      __InterlockedCompareExchange16_npPtr
          .asFunction<int Function(ffi.Pointer<ffi.Int16>, int, int)>();

  int _InterlockedCompareExchange64_np(
    ffi.Pointer<ffi.Int64> _Destination,
    int _Exchange,
    int _Comparand,
  ) {
    return __InterlockedCompareExchange64_np(
      _Destination,
      _Exchange,
      _Comparand,
    );
  }

  late final __InterlockedCompareExchange64_npPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int64 Function(ffi.Pointer<ffi.Int64>, ffi.Int64,
              ffi.Int64)>>('_InterlockedCompareExchange64_np');
  late final __InterlockedCompareExchange64_np =
      __InterlockedCompareExchange64_npPtr
          .asFunction<int Function(ffi.Pointer<ffi.Int64>, int, int)>();

  ffi.Pointer<ffi.Void> _InterlockedCompareExchangePointer(
    ffi.Pointer<ffi.Pointer<ffi.Void>> _Destination,
    ffi.Pointer<ffi.Void> _Exchange,
    ffi.Pointer<ffi.Void> _Comparand,
  ) {
    return __InterlockedCompareExchangePointer(
      _Destination,
      _Exchange,
      _Comparand,
    );
  }

  late final __InterlockedCompareExchangePointerPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Void> Function(
              ffi.Pointer<ffi.Pointer<ffi.Void>>,
              ffi.Pointer<ffi.Void>,
              ffi.Pointer<ffi.Void>)>>('_InterlockedCompareExchangePointer');
  late final __InterlockedCompareExchangePointer =
      __InterlockedCompareExchangePointerPtr.asFunction<
          ffi.Pointer<ffi.Void> Function(ffi.Pointer<ffi.Pointer<ffi.Void>>,
              ffi.Pointer<ffi.Void>, ffi.Pointer<ffi.Void>)>();

  ffi.Pointer<ffi.Void> _InterlockedCompareExchangePointer_np(
    ffi.Pointer<ffi.Pointer<ffi.Void>> _Destination,
    ffi.Pointer<ffi.Void> _Exchange,
    ffi.Pointer<ffi.Void> _Comparand,
  ) {
    return __InterlockedCompareExchangePointer_np(
      _Destination,
      _Exchange,
      _Comparand,
    );
  }

  late final __InterlockedCompareExchangePointer_npPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Void> Function(
              ffi.Pointer<ffi.Pointer<ffi.Void>>,
              ffi.Pointer<ffi.Void>,
              ffi.Pointer<ffi.Void>)>>('_InterlockedCompareExchangePointer_np');
  late final __InterlockedCompareExchangePointer_np =
      __InterlockedCompareExchangePointer_npPtr.asFunction<
          ffi.Pointer<ffi.Void> Function(ffi.Pointer<ffi.Pointer<ffi.Void>>,
              ffi.Pointer<ffi.Void>, ffi.Pointer<ffi.Void>)>();

  int _InterlockedCompareExchange_np(
    ffi.Pointer<ffi.Int64> _Destination,
    int _Exchange,
    int _Comparand,
  ) {
    return __InterlockedCompareExchange_np(
      _Destination,
      _Exchange,
      _Comparand,
    );
  }

  late final __InterlockedCompareExchange_npPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int64 Function(ffi.Pointer<ffi.Int64>, ffi.Int64,
              ffi.Int64)>>('_InterlockedCompareExchange_np');
  late final __InterlockedCompareExchange_np =
      __InterlockedCompareExchange_npPtr
          .asFunction<int Function(ffi.Pointer<ffi.Int64>, int, int)>();

  ffi.Pointer<ffi.Void> _InterlockedExchangePointer(
    ffi.Pointer<ffi.Pointer<ffi.Void>> _Target,
    ffi.Pointer<ffi.Void> _Value,
  ) {
    return __InterlockedExchangePointer(
      _Target,
      _Value,
    );
  }

  late final __InterlockedExchangePointerPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Void> Function(ffi.Pointer<ffi.Pointer<ffi.Void>>,
              ffi.Pointer<ffi.Void>)>>('_InterlockedExchangePointer');
  late final __InterlockedExchangePointer =
      __InterlockedExchangePointerPtr.asFunction<
          ffi.Pointer<ffi.Void> Function(
              ffi.Pointer<ffi.Pointer<ffi.Void>>, ffi.Pointer<ffi.Void>)>();

  int _InterlockedOr16_np(
    ffi.Pointer<ffi.Int16> _Value,
    int _Mask,
  ) {
    return __InterlockedOr16_np(
      _Value,
      _Mask,
    );
  }

  late final __InterlockedOr16_npPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int16 Function(
              ffi.Pointer<ffi.Int16>, ffi.Int16)>>('_InterlockedOr16_np');
  late final __InterlockedOr16_np = __InterlockedOr16_npPtr
      .asFunction<int Function(ffi.Pointer<ffi.Int16>, int)>();

  int _InterlockedOr64_np(
    ffi.Pointer<ffi.Int64> _Value,
    int _Mask,
  ) {
    return __InterlockedOr64_np(
      _Value,
      _Mask,
    );
  }

  late final __InterlockedOr64_npPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int64 Function(
              ffi.Pointer<ffi.Int64>, ffi.Int64)>>('_InterlockedOr64_np');
  late final __InterlockedOr64_np = __InterlockedOr64_npPtr
      .asFunction<int Function(ffi.Pointer<ffi.Int64>, int)>();

  int _InterlockedOr8_np(
    ffi.Pointer<ffi.Int8> _Value,
    int _Mask,
  ) {
    return __InterlockedOr8_np(
      _Value,
      _Mask,
    );
  }

  late final __InterlockedOr8_npPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int8 Function(
              ffi.Pointer<ffi.Int8>, ffi.Int8)>>('_InterlockedOr8_np');
  late final __InterlockedOr8_np = __InterlockedOr8_npPtr
      .asFunction<int Function(ffi.Pointer<ffi.Int8>, int)>();

  int _InterlockedOr_np(
    ffi.Pointer<ffi.Int64> _Value,
    int _Mask,
  ) {
    return __InterlockedOr_np(
      _Value,
      _Mask,
    );
  }

  late final __InterlockedOr_npPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int64 Function(
              ffi.Pointer<ffi.Int64>, ffi.Int64)>>('_InterlockedOr_np');
  late final __InterlockedOr_np = __InterlockedOr_npPtr
      .asFunction<int Function(ffi.Pointer<ffi.Int64>, int)>();

  int _InterlockedXor16_np(
    ffi.Pointer<ffi.Int16> _Value,
    int _Mask,
  ) {
    return __InterlockedXor16_np(
      _Value,
      _Mask,
    );
  }

  late final __InterlockedXor16_npPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int16 Function(
              ffi.Pointer<ffi.Int16>, ffi.Int16)>>('_InterlockedXor16_np');
  late final __InterlockedXor16_np = __InterlockedXor16_npPtr
      .asFunction<int Function(ffi.Pointer<ffi.Int16>, int)>();

  int _InterlockedXor64_np(
    ffi.Pointer<ffi.Int64> _Value,
    int _Mask,
  ) {
    return __InterlockedXor64_np(
      _Value,
      _Mask,
    );
  }

  late final __InterlockedXor64_npPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int64 Function(
              ffi.Pointer<ffi.Int64>, ffi.Int64)>>('_InterlockedXor64_np');
  late final __InterlockedXor64_np = __InterlockedXor64_npPtr
      .asFunction<int Function(ffi.Pointer<ffi.Int64>, int)>();

  int _InterlockedXor8_np(
    ffi.Pointer<ffi.Int8> _Value,
    int _Mask,
  ) {
    return __InterlockedXor8_np(
      _Value,
      _Mask,
    );
  }

  late final __InterlockedXor8_npPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int8 Function(
              ffi.Pointer<ffi.Int8>, ffi.Int8)>>('_InterlockedXor8_np');
  late final __InterlockedXor8_np = __InterlockedXor8_npPtr
      .asFunction<int Function(ffi.Pointer<ffi.Int8>, int)>();

  int _InterlockedXor_np(
    ffi.Pointer<ffi.Int64> _Value,
    int _Mask,
  ) {
    return __InterlockedXor_np(
      _Value,
      _Mask,
    );
  }

  late final __InterlockedXor_npPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int64 Function(
              ffi.Pointer<ffi.Int64>, ffi.Int64)>>('_InterlockedXor_np');
  late final __InterlockedXor_np = __InterlockedXor_npPtr
      .asFunction<int Function(ffi.Pointer<ffi.Int64>, int)>();

  void _ReadBarrier() {
    return __ReadBarrier();
  }

  late final __ReadBarrierPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('_ReadBarrier');
  late final __ReadBarrier = __ReadBarrierPtr.asFunction<void Function()>();

  ffi.Pointer<ffi.Void> _ReturnAddress() {
    return __ReturnAddress();
  }

  late final __ReturnAddressPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Void> Function()>>(
          '_ReturnAddress');
  late final __ReturnAddress =
      __ReturnAddressPtr.asFunction<ffi.Pointer<ffi.Void> Function()>();

  void _WriteBarrier() {
    return __WriteBarrier();
  }

  late final __WriteBarrierPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('_WriteBarrier');
  late final __WriteBarrier = __WriteBarrierPtr.asFunction<void Function()>();

  void __addgsbyte(
    int arg0,
    int arg1,
  ) {
    return ___addgsbyte(
      arg0,
      arg1,
    );
  }

  late final ___addgsbytePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Uint64, ffi.Uint8)>>(
          '__addgsbyte');
  late final ___addgsbyte =
      ___addgsbytePtr.asFunction<void Function(int, int)>();

  void __addgsdword(
    int arg0,
    int arg1,
  ) {
    return ___addgsdword(
      arg0,
      arg1,
    );
  }

  late final ___addgsdwordPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Uint64, ffi.Uint64)>>(
          '__addgsdword');
  late final ___addgsdword =
      ___addgsdwordPtr.asFunction<void Function(int, int)>();

  void __addgsqword(
    int arg0,
    int arg1,
  ) {
    return ___addgsqword(
      arg0,
      arg1,
    );
  }

  late final ___addgsqwordPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Uint64, ffi.Uint64)>>(
          '__addgsqword');
  late final ___addgsqword =
      ___addgsqwordPtr.asFunction<void Function(int, int)>();

  void __addgsword(
    int arg0,
    int arg1,
  ) {
    return ___addgsword(
      arg0,
      arg1,
    );
  }

  late final ___addgswordPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Uint64, ffi.Uint16)>>(
          '__addgsword');
  late final ___addgsword =
      ___addgswordPtr.asFunction<void Function(int, int)>();

  void __clts() {
    return ___clts();
  }

  late final ___cltsPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('__clts');
  late final ___clts = ___cltsPtr.asFunction<void Function()>();

  void __code_seg(
    ffi.Pointer<ffi.Int8> arg0,
  ) {
    return ___code_seg(
      arg0,
    );
  }

  late final ___code_segPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ffi.Int8>)>>(
          '__code_seg');
  late final ___code_seg =
      ___code_segPtr.asFunction<void Function(ffi.Pointer<ffi.Int8>)>();

  void __cpuid(
    ffi.Pointer<ffi.Int32> arg0,
    int arg1,
  ) {
    return ___cpuid(
      arg0,
      arg1,
    );
  }

  late final ___cpuidPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Int32>, ffi.Int32)>>('__cpuid');
  late final ___cpuid =
      ___cpuidPtr.asFunction<void Function(ffi.Pointer<ffi.Int32>, int)>();

  void __cpuidex(
    ffi.Pointer<ffi.Int32> arg0,
    int arg1,
    int arg2,
  ) {
    return ___cpuidex(
      arg0,
      arg1,
      arg2,
    );
  }

  late final ___cpuidexPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<ffi.Int32>, ffi.Int32, ffi.Int32)>>('__cpuidex');
  late final ___cpuidex = ___cpuidexPtr
      .asFunction<void Function(ffi.Pointer<ffi.Int32>, int, int)>();

  int __emul(
    int arg0,
    int arg1,
  ) {
    return ___emul(
      arg0,
      arg1,
    );
  }

  late final ___emulPtr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(ffi.Int32, ffi.Int32)>>(
          '__emul');
  late final ___emul = ___emulPtr.asFunction<int Function(int, int)>();

  int __emulu(
    int arg0,
    int arg1,
  ) {
    return ___emulu(
      arg0,
      arg1,
    );
  }

  late final ___emuluPtr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function(ffi.Uint32, ffi.Uint32)>>(
          '__emulu');
  late final ___emulu = ___emuluPtr.asFunction<int Function(int, int)>();

  void __fastfail(
    int arg0,
  ) {
    return ___fastfail(
      arg0,
    );
  }

  late final ___fastfailPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Uint32)>>('__fastfail');
  late final ___fastfail = ___fastfailPtr.asFunction<void Function(int)>();

  void __faststorefence() {
    return ___faststorefence();
  }

  late final ___faststorefencePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('__faststorefence');
  late final ___faststorefence =
      ___faststorefencePtr.asFunction<void Function()>();

  int __getcallerseflags() {
    return ___getcallerseflags();
  }

  late final ___getcallerseflagsPtr =
      _lookup<ffi.NativeFunction<ffi.Uint32 Function()>>('__getcallerseflags');
  late final ___getcallerseflags =
      ___getcallerseflagsPtr.asFunction<int Function()>();

  void __halt() {
    return ___halt();
  }

  late final ___haltPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('__halt');
  late final ___halt = ___haltPtr.asFunction<void Function()>();

  int __inbyte(
    int arg0,
  ) {
    return ___inbyte(
      arg0,
    );
  }

  late final ___inbytePtr =
      _lookup<ffi.NativeFunction<ffi.Uint8 Function(ffi.Uint16)>>('__inbyte');
  late final ___inbyte = ___inbytePtr.asFunction<int Function(int)>();

  void __inbytestring(
    int arg0,
    ffi.Pointer<ffi.Uint8> arg1,
    int arg2,
  ) {
    return ___inbytestring(
      arg0,
      arg1,
      arg2,
    );
  }

  late final ___inbytestringPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Uint16, ffi.Pointer<ffi.Uint8>,
              ffi.Uint64)>>('__inbytestring');
  late final ___inbytestring = ___inbytestringPtr
      .asFunction<void Function(int, ffi.Pointer<ffi.Uint8>, int)>();

  void __incgsbyte(
    int arg0,
  ) {
    return ___incgsbyte(
      arg0,
    );
  }

  late final ___incgsbytePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Uint64)>>('__incgsbyte');
  late final ___incgsbyte = ___incgsbytePtr.asFunction<void Function(int)>();

  void __incgsdword(
    int arg0,
  ) {
    return ___incgsdword(
      arg0,
    );
  }

  late final ___incgsdwordPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Uint64)>>(
          '__incgsdword');
  late final ___incgsdword = ___incgsdwordPtr.asFunction<void Function(int)>();

  void __incgsqword(
    int arg0,
  ) {
    return ___incgsqword(
      arg0,
    );
  }

  late final ___incgsqwordPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Uint64)>>(
          '__incgsqword');
  late final ___incgsqword = ___incgsqwordPtr.asFunction<void Function(int)>();

  void __incgsword(
    int arg0,
  ) {
    return ___incgsword(
      arg0,
    );
  }

  late final ___incgswordPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Uint64)>>('__incgsword');
  late final ___incgsword = ___incgswordPtr.asFunction<void Function(int)>();

  int __indword(
    int arg0,
  ) {
    return ___indword(
      arg0,
    );
  }

  late final ___indwordPtr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function(ffi.Uint16)>>('__indword');
  late final ___indword = ___indwordPtr.asFunction<int Function(int)>();

  void __indwordstring(
    int arg0,
    ffi.Pointer<ffi.Uint64> arg1,
    int arg2,
  ) {
    return ___indwordstring(
      arg0,
      arg1,
      arg2,
    );
  }

  late final ___indwordstringPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Uint16, ffi.Pointer<ffi.Uint64>,
              ffi.Uint64)>>('__indwordstring');
  late final ___indwordstring = ___indwordstringPtr
      .asFunction<void Function(int, ffi.Pointer<ffi.Uint64>, int)>();

  void __int2c() {
    return ___int2c();
  }

  late final ___int2cPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('__int2c');
  late final ___int2c = ___int2cPtr.asFunction<void Function()>();

  void __invlpg(
    ffi.Pointer<ffi.Void> arg0,
  ) {
    return ___invlpg(
      arg0,
    );
  }

  late final ___invlpgPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ffi.Void>)>>(
          '__invlpg');
  late final ___invlpg =
      ___invlpgPtr.asFunction<void Function(ffi.Pointer<ffi.Void>)>();

  int __inword(
    int arg0,
  ) {
    return ___inword(
      arg0,
    );
  }

  late final ___inwordPtr =
      _lookup<ffi.NativeFunction<ffi.Uint16 Function(ffi.Uint16)>>('__inword');
  late final ___inword = ___inwordPtr.asFunction<int Function(int)>();

  void __inwordstring(
    int arg0,
    ffi.Pointer<ffi.Uint16> arg1,
    int arg2,
  ) {
    return ___inwordstring(
      arg0,
      arg1,
      arg2,
    );
  }

  late final ___inwordstringPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Uint16, ffi.Pointer<ffi.Uint16>,
              ffi.Uint64)>>('__inwordstring');
  late final ___inwordstring = ___inwordstringPtr
      .asFunction<void Function(int, ffi.Pointer<ffi.Uint16>, int)>();

  void __lidt(
    ffi.Pointer<ffi.Void> arg0,
  ) {
    return ___lidt(
      arg0,
    );
  }

  late final ___lidtPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ffi.Void>)>>(
          '__lidt');
  late final ___lidt =
      ___lidtPtr.asFunction<void Function(ffi.Pointer<ffi.Void>)>();

  int __ll_lshift(
    int arg0,
    int arg1,
  ) {
    return ___ll_lshift(
      arg0,
      arg1,
    );
  }

  late final ___ll_lshiftPtr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function(ffi.Uint64, ffi.Int32)>>(
          '__ll_lshift');
  late final ___ll_lshift =
      ___ll_lshiftPtr.asFunction<int Function(int, int)>();

  int __ll_rshift(
    int arg0,
    int arg1,
  ) {
    return ___ll_rshift(
      arg0,
      arg1,
    );
  }

  late final ___ll_rshiftPtr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(ffi.Int64, ffi.Int32)>>(
          '__ll_rshift');
  late final ___ll_rshift =
      ___ll_rshiftPtr.asFunction<int Function(int, int)>();

  void __movsb(
    ffi.Pointer<ffi.Uint8> arg0,
    ffi.Pointer<ffi.Uint8> arg1,
    int arg2,
  ) {
    return ___movsb(
      arg0,
      arg1,
      arg2,
    );
  }

  late final ___movsbPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Uint8>, ffi.Pointer<ffi.Uint8>,
              size_t)>>('__movsb');
  late final ___movsb = ___movsbPtr.asFunction<
      void Function(ffi.Pointer<ffi.Uint8>, ffi.Pointer<ffi.Uint8>, int)>();

  void __movsd(
    ffi.Pointer<ffi.Uint64> arg0,
    ffi.Pointer<ffi.Uint64> arg1,
    int arg2,
  ) {
    return ___movsd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final ___movsdPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Uint64>, ffi.Pointer<ffi.Uint64>,
              size_t)>>('__movsd');
  late final ___movsd = ___movsdPtr.asFunction<
      void Function(ffi.Pointer<ffi.Uint64>, ffi.Pointer<ffi.Uint64>, int)>();

  void __movsq(
    ffi.Pointer<ffi.Uint64> arg0,
    ffi.Pointer<ffi.Uint64> arg1,
    int arg2,
  ) {
    return ___movsq(
      arg0,
      arg1,
      arg2,
    );
  }

  late final ___movsqPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Uint64>, ffi.Pointer<ffi.Uint64>,
              size_t)>>('__movsq');
  late final ___movsq = ___movsqPtr.asFunction<
      void Function(ffi.Pointer<ffi.Uint64>, ffi.Pointer<ffi.Uint64>, int)>();

  void __movsw(
    ffi.Pointer<ffi.Uint16> arg0,
    ffi.Pointer<ffi.Uint16> arg1,
    int arg2,
  ) {
    return ___movsw(
      arg0,
      arg1,
      arg2,
    );
  }

  late final ___movswPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Uint16>, ffi.Pointer<ffi.Uint16>,
              size_t)>>('__movsw');
  late final ___movsw = ___movswPtr.asFunction<
      void Function(ffi.Pointer<ffi.Uint16>, ffi.Pointer<ffi.Uint16>, int)>();

  int __mulh(
    int arg0,
    int arg1,
  ) {
    return ___mulh(
      arg0,
      arg1,
    );
  }

  late final ___mulhPtr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(ffi.Int64, ffi.Int64)>>(
          '__mulh');
  late final ___mulh = ___mulhPtr.asFunction<int Function(int, int)>();

  void __nop() {
    return ___nop();
  }

  late final ___nopPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('__nop');
  late final ___nop = ___nopPtr.asFunction<void Function()>();

  void __nvreg_restore_fence() {
    return ___nvreg_restore_fence();
  }

  late final ___nvreg_restore_fencePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('__nvreg_restore_fence');
  late final ___nvreg_restore_fence =
      ___nvreg_restore_fencePtr.asFunction<void Function()>();

  void __nvreg_save_fence() {
    return ___nvreg_save_fence();
  }

  late final ___nvreg_save_fencePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('__nvreg_save_fence');
  late final ___nvreg_save_fence =
      ___nvreg_save_fencePtr.asFunction<void Function()>();

  void __outbyte(
    int arg0,
    int arg1,
  ) {
    return ___outbyte(
      arg0,
      arg1,
    );
  }

  late final ___outbytePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Uint16, ffi.Uint8)>>(
          '__outbyte');
  late final ___outbyte = ___outbytePtr.asFunction<void Function(int, int)>();

  void __outbytestring(
    int arg0,
    ffi.Pointer<ffi.Uint8> arg1,
    int arg2,
  ) {
    return ___outbytestring(
      arg0,
      arg1,
      arg2,
    );
  }

  late final ___outbytestringPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Uint16, ffi.Pointer<ffi.Uint8>,
              ffi.Uint64)>>('__outbytestring');
  late final ___outbytestring = ___outbytestringPtr
      .asFunction<void Function(int, ffi.Pointer<ffi.Uint8>, int)>();

  void __outdword(
    int arg0,
    int arg1,
  ) {
    return ___outdword(
      arg0,
      arg1,
    );
  }

  late final ___outdwordPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Uint16, ffi.Uint64)>>(
          '__outdword');
  late final ___outdword = ___outdwordPtr.asFunction<void Function(int, int)>();

  void __outdwordstring(
    int arg0,
    ffi.Pointer<ffi.Uint64> arg1,
    int arg2,
  ) {
    return ___outdwordstring(
      arg0,
      arg1,
      arg2,
    );
  }

  late final ___outdwordstringPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Uint16, ffi.Pointer<ffi.Uint64>,
              ffi.Uint64)>>('__outdwordstring');
  late final ___outdwordstring = ___outdwordstringPtr
      .asFunction<void Function(int, ffi.Pointer<ffi.Uint64>, int)>();

  void __outword(
    int arg0,
    int arg1,
  ) {
    return ___outword(
      arg0,
      arg1,
    );
  }

  late final ___outwordPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Uint16, ffi.Uint16)>>(
          '__outword');
  late final ___outword = ___outwordPtr.asFunction<void Function(int, int)>();

  void __outwordstring(
    int arg0,
    ffi.Pointer<ffi.Uint16> arg1,
    int arg2,
  ) {
    return ___outwordstring(
      arg0,
      arg1,
      arg2,
    );
  }

  late final ___outwordstringPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Uint16, ffi.Pointer<ffi.Uint16>,
              ffi.Uint64)>>('__outwordstring');
  late final ___outwordstring = ___outwordstringPtr
      .asFunction<void Function(int, ffi.Pointer<ffi.Uint16>, int)>();

  int __rdtsc() {
    return ___rdtsc();
  }

  late final ___rdtscPtr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function()>>('__rdtsc');
  late final ___rdtsc = ___rdtscPtr.asFunction<int Function()>();

  int __rdtscp(
    ffi.Pointer<ffi.Uint32> arg0,
  ) {
    return ___rdtscp(
      arg0,
    );
  }

  late final ___rdtscpPtr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function(ffi.Pointer<ffi.Uint32>)>>(
          '__rdtscp');
  late final ___rdtscp =
      ___rdtscpPtr.asFunction<int Function(ffi.Pointer<ffi.Uint32>)>();

  int __readcr0() {
    return ___readcr0();
  }

  late final ___readcr0Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function()>>('__readcr0');
  late final ___readcr0 = ___readcr0Ptr.asFunction<int Function()>();

  int __readcr2() {
    return ___readcr2();
  }

  late final ___readcr2Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function()>>('__readcr2');
  late final ___readcr2 = ___readcr2Ptr.asFunction<int Function()>();

  int __readcr3() {
    return ___readcr3();
  }

  late final ___readcr3Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function()>>('__readcr3');
  late final ___readcr3 = ___readcr3Ptr.asFunction<int Function()>();

  int __readcr4() {
    return ___readcr4();
  }

  late final ___readcr4Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function()>>('__readcr4');
  late final ___readcr4 = ___readcr4Ptr.asFunction<int Function()>();

  int __readcr8() {
    return ___readcr8();
  }

  late final ___readcr8Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function()>>('__readcr8');
  late final ___readcr8 = ___readcr8Ptr.asFunction<int Function()>();

  int __readdr(
    int arg0,
  ) {
    return ___readdr(
      arg0,
    );
  }

  late final ___readdrPtr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function(ffi.Uint32)>>('__readdr');
  late final ___readdr = ___readdrPtr.asFunction<int Function(int)>();

  int __readeflags() {
    return ___readeflags();
  }

  late final ___readeflagsPtr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function()>>('__readeflags');
  late final ___readeflags = ___readeflagsPtr.asFunction<int Function()>();

  int __readgsbyte(
    int arg0,
  ) {
    return ___readgsbyte(
      arg0,
    );
  }

  late final ___readgsbytePtr =
      _lookup<ffi.NativeFunction<ffi.Uint8 Function(ffi.Uint64)>>(
          '__readgsbyte');
  late final ___readgsbyte = ___readgsbytePtr.asFunction<int Function(int)>();

  int __readgsdword(
    int arg0,
  ) {
    return ___readgsdword(
      arg0,
    );
  }

  late final ___readgsdwordPtr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function(ffi.Uint64)>>(
          '__readgsdword');
  late final ___readgsdword = ___readgsdwordPtr.asFunction<int Function(int)>();

  int __readgsqword(
    int arg0,
  ) {
    return ___readgsqword(
      arg0,
    );
  }

  late final ___readgsqwordPtr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function(ffi.Uint64)>>(
          '__readgsqword');
  late final ___readgsqword = ___readgsqwordPtr.asFunction<int Function(int)>();

  int __readgsword(
    int arg0,
  ) {
    return ___readgsword(
      arg0,
    );
  }

  late final ___readgswordPtr =
      _lookup<ffi.NativeFunction<ffi.Uint16 Function(ffi.Uint64)>>(
          '__readgsword');
  late final ___readgsword = ___readgswordPtr.asFunction<int Function(int)>();

  int __readmsr(
    int arg0,
  ) {
    return ___readmsr(
      arg0,
    );
  }

  late final ___readmsrPtr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function(ffi.Uint64)>>('__readmsr');
  late final ___readmsr = ___readmsrPtr.asFunction<int Function(int)>();

  int __readpmc(
    int arg0,
  ) {
    return ___readpmc(
      arg0,
    );
  }

  late final ___readpmcPtr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function(ffi.Uint64)>>('__readpmc');
  late final ___readpmc = ___readpmcPtr.asFunction<int Function(int)>();

  int __segmentlimit(
    int arg0,
  ) {
    return ___segmentlimit(
      arg0,
    );
  }

  late final ___segmentlimitPtr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function(ffi.Uint64)>>(
          '__segmentlimit');
  late final ___segmentlimit =
      ___segmentlimitPtr.asFunction<int Function(int)>();

  int __shiftleft128(
    int _LowPart,
    int _HighPart,
    int _Shift,
  ) {
    return ___shiftleft128(
      _LowPart,
      _HighPart,
      _Shift,
    );
  }

  late final ___shiftleft128Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Uint64 Function(
              ffi.Uint64, ffi.Uint64, ffi.Uint8)>>('__shiftleft128');
  late final ___shiftleft128 =
      ___shiftleft128Ptr.asFunction<int Function(int, int, int)>();

  void __sidt(
    ffi.Pointer<ffi.Void> arg0,
  ) {
    return ___sidt(
      arg0,
    );
  }

  late final ___sidtPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ffi.Void>)>>(
          '__sidt');
  late final ___sidt =
      ___sidtPtr.asFunction<void Function(ffi.Pointer<ffi.Void>)>();

  void __stosb(
    ffi.Pointer<ffi.Uint8> arg0,
    int arg1,
    int arg2,
  ) {
    return ___stosb(
      arg0,
      arg1,
      arg2,
    );
  }

  late final ___stosbPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<ffi.Uint8>, ffi.Uint8, size_t)>>('__stosb');
  late final ___stosb =
      ___stosbPtr.asFunction<void Function(ffi.Pointer<ffi.Uint8>, int, int)>();

  void __stosd(
    ffi.Pointer<ffi.Uint64> arg0,
    int arg1,
    int arg2,
  ) {
    return ___stosd(
      arg0,
      arg1,
      arg2,
    );
  }

  late final ___stosdPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<ffi.Uint64>, ffi.Uint64, size_t)>>('__stosd');
  late final ___stosd = ___stosdPtr
      .asFunction<void Function(ffi.Pointer<ffi.Uint64>, int, int)>();

  void __stosq(
    ffi.Pointer<ffi.Uint64> arg0,
    int arg1,
    int arg2,
  ) {
    return ___stosq(
      arg0,
      arg1,
      arg2,
    );
  }

  late final ___stosqPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<ffi.Uint64>, ffi.Uint64, size_t)>>('__stosq');
  late final ___stosq = ___stosqPtr
      .asFunction<void Function(ffi.Pointer<ffi.Uint64>, int, int)>();

  void __stosw(
    ffi.Pointer<ffi.Uint16> arg0,
    int arg1,
    int arg2,
  ) {
    return ___stosw(
      arg0,
      arg1,
      arg2,
    );
  }

  late final ___stoswPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<ffi.Uint16>, ffi.Uint16, size_t)>>('__stosw');
  late final ___stosw = ___stoswPtr
      .asFunction<void Function(ffi.Pointer<ffi.Uint16>, int, int)>();

  void __svm_clgi() {
    return ___svm_clgi();
  }

  late final ___svm_clgiPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('__svm_clgi');
  late final ___svm_clgi = ___svm_clgiPtr.asFunction<void Function()>();

  void __svm_invlpga(
    ffi.Pointer<ffi.Void> arg0,
    int arg1,
  ) {
    return ___svm_invlpga(
      arg0,
      arg1,
    );
  }

  late final ___svm_invlpgaPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<ffi.Void>, ffi.Int32)>>('__svm_invlpga');
  late final ___svm_invlpga =
      ___svm_invlpgaPtr.asFunction<void Function(ffi.Pointer<ffi.Void>, int)>();

  void __svm_skinit(
    int arg0,
  ) {
    return ___svm_skinit(
      arg0,
    );
  }

  late final ___svm_skinitPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Int32)>>('__svm_skinit');
  late final ___svm_skinit = ___svm_skinitPtr.asFunction<void Function(int)>();

  void __svm_stgi() {
    return ___svm_stgi();
  }

  late final ___svm_stgiPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('__svm_stgi');
  late final ___svm_stgi = ___svm_stgiPtr.asFunction<void Function()>();

  void __svm_vmload(
    int arg0,
  ) {
    return ___svm_vmload(
      arg0,
    );
  }

  late final ___svm_vmloadPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(size_t)>>('__svm_vmload');
  late final ___svm_vmload = ___svm_vmloadPtr.asFunction<void Function(int)>();

  void __svm_vmrun(
    int arg0,
  ) {
    return ___svm_vmrun(
      arg0,
    );
  }

  late final ___svm_vmrunPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(size_t)>>('__svm_vmrun');
  late final ___svm_vmrun = ___svm_vmrunPtr.asFunction<void Function(int)>();

  void __svm_vmsave(
    int arg0,
  ) {
    return ___svm_vmsave(
      arg0,
    );
  }

  late final ___svm_vmsavePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(size_t)>>('__svm_vmsave');
  late final ___svm_vmsave = ___svm_vmsavePtr.asFunction<void Function(int)>();

  void __ud2() {
    return ___ud2();
  }

  late final ___ud2Ptr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('__ud2');
  late final ___ud2 = ___ud2Ptr.asFunction<void Function()>();

  int __ull_rshift(
    int arg0,
    int arg1,
  ) {
    return ___ull_rshift(
      arg0,
      arg1,
    );
  }

  late final ___ull_rshiftPtr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function(ffi.Uint64, ffi.Int32)>>(
          '__ull_rshift');
  late final ___ull_rshift =
      ___ull_rshiftPtr.asFunction<int Function(int, int)>();

  int __umulh(
    int arg0,
    int arg1,
  ) {
    return ___umulh(
      arg0,
      arg1,
    );
  }

  late final ___umulhPtr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function(ffi.Uint64, ffi.Uint64)>>(
          '__umulh');
  late final ___umulh = ___umulhPtr.asFunction<int Function(int, int)>();

  void __vmx_off() {
    return ___vmx_off();
  }

  late final ___vmx_offPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('__vmx_off');
  late final ___vmx_off = ___vmx_offPtr.asFunction<void Function()>();

  int __vmx_on(
    ffi.Pointer<ffi.Uint64> arg0,
  ) {
    return ___vmx_on(
      arg0,
    );
  }

  late final ___vmx_onPtr =
      _lookup<ffi.NativeFunction<ffi.Uint8 Function(ffi.Pointer<ffi.Uint64>)>>(
          '__vmx_on');
  late final ___vmx_on =
      ___vmx_onPtr.asFunction<int Function(ffi.Pointer<ffi.Uint64>)>();

  int __vmx_vmclear(
    ffi.Pointer<ffi.Uint64> arg0,
  ) {
    return ___vmx_vmclear(
      arg0,
    );
  }

  late final ___vmx_vmclearPtr =
      _lookup<ffi.NativeFunction<ffi.Uint8 Function(ffi.Pointer<ffi.Uint64>)>>(
          '__vmx_vmclear');
  late final ___vmx_vmclear =
      ___vmx_vmclearPtr.asFunction<int Function(ffi.Pointer<ffi.Uint64>)>();

  int __vmx_vmlaunch() {
    return ___vmx_vmlaunch();
  }

  late final ___vmx_vmlaunchPtr =
      _lookup<ffi.NativeFunction<ffi.Uint8 Function()>>('__vmx_vmlaunch');
  late final ___vmx_vmlaunch = ___vmx_vmlaunchPtr.asFunction<int Function()>();

  int __vmx_vmptrld(
    ffi.Pointer<ffi.Uint64> arg0,
  ) {
    return ___vmx_vmptrld(
      arg0,
    );
  }

  late final ___vmx_vmptrldPtr =
      _lookup<ffi.NativeFunction<ffi.Uint8 Function(ffi.Pointer<ffi.Uint64>)>>(
          '__vmx_vmptrld');
  late final ___vmx_vmptrld =
      ___vmx_vmptrldPtr.asFunction<int Function(ffi.Pointer<ffi.Uint64>)>();

  void __vmx_vmptrst(
    ffi.Pointer<ffi.Uint64> arg0,
  ) {
    return ___vmx_vmptrst(
      arg0,
    );
  }

  late final ___vmx_vmptrstPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ffi.Uint64>)>>(
          '__vmx_vmptrst');
  late final ___vmx_vmptrst =
      ___vmx_vmptrstPtr.asFunction<void Function(ffi.Pointer<ffi.Uint64>)>();

  int __vmx_vmread(
    int arg0,
    ffi.Pointer<size_t> arg1,
  ) {
    return ___vmx_vmread(
      arg0,
      arg1,
    );
  }

  late final ___vmx_vmreadPtr = _lookup<
          ffi.NativeFunction<ffi.Uint8 Function(size_t, ffi.Pointer<size_t>)>>(
      '__vmx_vmread');
  late final ___vmx_vmread =
      ___vmx_vmreadPtr.asFunction<int Function(int, ffi.Pointer<size_t>)>();

  int __vmx_vmresume() {
    return ___vmx_vmresume();
  }

  late final ___vmx_vmresumePtr =
      _lookup<ffi.NativeFunction<ffi.Uint8 Function()>>('__vmx_vmresume');
  late final ___vmx_vmresume = ___vmx_vmresumePtr.asFunction<int Function()>();

  int __vmx_vmwrite(
    int arg0,
    int arg1,
  ) {
    return ___vmx_vmwrite(
      arg0,
      arg1,
    );
  }

  late final ___vmx_vmwritePtr =
      _lookup<ffi.NativeFunction<ffi.Uint8 Function(size_t, size_t)>>(
          '__vmx_vmwrite');
  late final ___vmx_vmwrite =
      ___vmx_vmwritePtr.asFunction<int Function(int, int)>();

  void __wbinvd() {
    return ___wbinvd();
  }

  late final ___wbinvdPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('__wbinvd');
  late final ___wbinvd = ___wbinvdPtr.asFunction<void Function()>();

  void __writecr0(
    int arg0,
  ) {
    return ___writecr0(
      arg0,
    );
  }

  late final ___writecr0Ptr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Uint64)>>('__writecr0');
  late final ___writecr0 = ___writecr0Ptr.asFunction<void Function(int)>();

  void __writecr2(
    int arg0,
  ) {
    return ___writecr2(
      arg0,
    );
  }

  late final ___writecr2Ptr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Uint64)>>('__writecr2');
  late final ___writecr2 = ___writecr2Ptr.asFunction<void Function(int)>();

  void __writecr3(
    int arg0,
  ) {
    return ___writecr3(
      arg0,
    );
  }

  late final ___writecr3Ptr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Uint64)>>('__writecr3');
  late final ___writecr3 = ___writecr3Ptr.asFunction<void Function(int)>();

  void __writecr4(
    int arg0,
  ) {
    return ___writecr4(
      arg0,
    );
  }

  late final ___writecr4Ptr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Uint64)>>('__writecr4');
  late final ___writecr4 = ___writecr4Ptr.asFunction<void Function(int)>();

  void __writecr8(
    int arg0,
  ) {
    return ___writecr8(
      arg0,
    );
  }

  late final ___writecr8Ptr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Uint64)>>('__writecr8');
  late final ___writecr8 = ___writecr8Ptr.asFunction<void Function(int)>();

  void __writedr(
    int arg0,
    int arg1,
  ) {
    return ___writedr(
      arg0,
      arg1,
    );
  }

  late final ___writedrPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Uint32, ffi.Uint64)>>(
          '__writedr');
  late final ___writedr = ___writedrPtr.asFunction<void Function(int, int)>();

  void __writeeflags(
    int arg0,
  ) {
    return ___writeeflags(
      arg0,
    );
  }

  late final ___writeeflagsPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Uint64)>>(
          '__writeeflags');
  late final ___writeeflags =
      ___writeeflagsPtr.asFunction<void Function(int)>();

  void __writegsbyte(
    int arg0,
    int arg1,
  ) {
    return ___writegsbyte(
      arg0,
      arg1,
    );
  }

  late final ___writegsbytePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Uint64, ffi.Uint8)>>(
          '__writegsbyte');
  late final ___writegsbyte =
      ___writegsbytePtr.asFunction<void Function(int, int)>();

  void __writegsdword(
    int arg0,
    int arg1,
  ) {
    return ___writegsdword(
      arg0,
      arg1,
    );
  }

  late final ___writegsdwordPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Uint64, ffi.Uint64)>>(
          '__writegsdword');
  late final ___writegsdword =
      ___writegsdwordPtr.asFunction<void Function(int, int)>();

  void __writegsqword(
    int arg0,
    int arg1,
  ) {
    return ___writegsqword(
      arg0,
      arg1,
    );
  }

  late final ___writegsqwordPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Uint64, ffi.Uint64)>>(
          '__writegsqword');
  late final ___writegsqword =
      ___writegsqwordPtr.asFunction<void Function(int, int)>();

  void __writegsword(
    int arg0,
    int arg1,
  ) {
    return ___writegsword(
      arg0,
      arg1,
    );
  }

  late final ___writegswordPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Uint64, ffi.Uint16)>>(
          '__writegsword');
  late final ___writegsword =
      ___writegswordPtr.asFunction<void Function(int, int)>();

  void __writemsr(
    int arg0,
    int arg1,
  ) {
    return ___writemsr(
      arg0,
      arg1,
    );
  }

  late final ___writemsrPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Uint64, ffi.Uint64)>>(
          '__writemsr');
  late final ___writemsr = ___writemsrPtr.asFunction<void Function(int, int)>();

  int _bittest64(
    ffi.Pointer<ffi.Int64> arg0,
    int arg1,
  ) {
    return __bittest64(
      arg0,
      arg1,
    );
  }

  late final __bittest64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Uint8 Function(ffi.Pointer<ffi.Int64>, ffi.Int64)>>('_bittest64');
  late final __bittest64 =
      __bittest64Ptr.asFunction<int Function(ffi.Pointer<ffi.Int64>, int)>();

  int _bittestandcomplement(
    ffi.Pointer<ffi.Int64> arg0,
    int arg1,
  ) {
    return __bittestandcomplement(
      arg0,
      arg1,
    );
  }

  late final __bittestandcomplementPtr = _lookup<
      ffi.NativeFunction<
          ffi.Uint8 Function(
              ffi.Pointer<ffi.Int64>, ffi.Int64)>>('_bittestandcomplement');
  late final __bittestandcomplement = __bittestandcomplementPtr
      .asFunction<int Function(ffi.Pointer<ffi.Int64>, int)>();

  int _bittestandcomplement64(
    ffi.Pointer<ffi.Int64> arg0,
    int arg1,
  ) {
    return __bittestandcomplement64(
      arg0,
      arg1,
    );
  }

  late final __bittestandcomplement64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Uint8 Function(
              ffi.Pointer<ffi.Int64>, ffi.Int64)>>('_bittestandcomplement64');
  late final __bittestandcomplement64 = __bittestandcomplement64Ptr
      .asFunction<int Function(ffi.Pointer<ffi.Int64>, int)>();

  int _bittestandreset(
    ffi.Pointer<ffi.Int64> arg0,
    int arg1,
  ) {
    return __bittestandreset(
      arg0,
      arg1,
    );
  }

  late final __bittestandresetPtr = _lookup<
      ffi.NativeFunction<
          ffi.Uint8 Function(
              ffi.Pointer<ffi.Int64>, ffi.Int64)>>('_bittestandreset');
  late final __bittestandreset = __bittestandresetPtr
      .asFunction<int Function(ffi.Pointer<ffi.Int64>, int)>();

  int _bittestandreset64(
    ffi.Pointer<ffi.Int64> arg0,
    int arg1,
  ) {
    return __bittestandreset64(
      arg0,
      arg1,
    );
  }

  late final __bittestandreset64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Uint8 Function(
              ffi.Pointer<ffi.Int64>, ffi.Int64)>>('_bittestandreset64');
  late final __bittestandreset64 = __bittestandreset64Ptr
      .asFunction<int Function(ffi.Pointer<ffi.Int64>, int)>();

  int _bittestandset(
    ffi.Pointer<ffi.Int64> arg0,
    int arg1,
  ) {
    return __bittestandset(
      arg0,
      arg1,
    );
  }

  late final __bittestandsetPtr = _lookup<
      ffi.NativeFunction<
          ffi.Uint8 Function(
              ffi.Pointer<ffi.Int64>, ffi.Int64)>>('_bittestandset');
  late final __bittestandset = __bittestandsetPtr
      .asFunction<int Function(ffi.Pointer<ffi.Int64>, int)>();

  int _bittestandset64(
    ffi.Pointer<ffi.Int64> arg0,
    int arg1,
  ) {
    return __bittestandset64(
      arg0,
      arg1,
    );
  }

  late final __bittestandset64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Uint8 Function(
              ffi.Pointer<ffi.Int64>, ffi.Int64)>>('_bittestandset64');
  late final __bittestandset64 = __bittestandset64Ptr
      .asFunction<int Function(ffi.Pointer<ffi.Int64>, int)>();

  int _byteswap_uint64(
    int arg0,
  ) {
    return __byteswap_uint64(
      arg0,
    );
  }

  late final __byteswap_uint64Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function(ffi.Uint64)>>(
          '_byteswap_uint64');
  late final __byteswap_uint64 =
      __byteswap_uint64Ptr.asFunction<int Function(int)>();

  int _byteswap_ulong(
    int arg0,
  ) {
    return __byteswap_ulong(
      arg0,
    );
  }

  late final __byteswap_ulongPtr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function(ffi.Uint64)>>(
          '_byteswap_ulong');
  late final __byteswap_ulong =
      __byteswap_ulongPtr.asFunction<int Function(int)>();

  int _byteswap_ushort(
    int arg0,
  ) {
    return __byteswap_ushort(
      arg0,
    );
  }

  late final __byteswap_ushortPtr =
      _lookup<ffi.NativeFunction<ffi.Uint16 Function(ffi.Uint16)>>(
          '_byteswap_ushort');
  late final __byteswap_ushort =
      __byteswap_ushortPtr.asFunction<int Function(int)>();

  void _disable() {
    return __disable();
  }

  late final __disablePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('_disable');
  late final __disable = __disablePtr.asFunction<void Function()>();

  void _enable() {
    return __enable();
  }

  late final __enablePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('_enable');
  late final __enable = __enablePtr.asFunction<void Function()>();

  int _interlockedbittestandreset(
    ffi.Pointer<ffi.Int64> arg0,
    int arg1,
  ) {
    return __interlockedbittestandreset(
      arg0,
      arg1,
    );
  }

  late final __interlockedbittestandresetPtr = _lookup<
      ffi.NativeFunction<
          ffi.Uint8 Function(ffi.Pointer<ffi.Int64>,
              ffi.Int64)>>('_interlockedbittestandreset');
  late final __interlockedbittestandreset = __interlockedbittestandresetPtr
      .asFunction<int Function(ffi.Pointer<ffi.Int64>, int)>();

  int _interlockedbittestandreset64(
    ffi.Pointer<ffi.Int64> arg0,
    int arg1,
  ) {
    return __interlockedbittestandreset64(
      arg0,
      arg1,
    );
  }

  late final __interlockedbittestandreset64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Uint8 Function(ffi.Pointer<ffi.Int64>,
              ffi.Int64)>>('_interlockedbittestandreset64');
  late final __interlockedbittestandreset64 = __interlockedbittestandreset64Ptr
      .asFunction<int Function(ffi.Pointer<ffi.Int64>, int)>();

  int _interlockedbittestandset64(
    ffi.Pointer<ffi.Int64> arg0,
    int arg1,
  ) {
    return __interlockedbittestandset64(
      arg0,
      arg1,
    );
  }

  late final __interlockedbittestandset64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Uint8 Function(ffi.Pointer<ffi.Int64>,
              ffi.Int64)>>('_interlockedbittestandset64');
  late final __interlockedbittestandset64 = __interlockedbittestandset64Ptr
      .asFunction<int Function(ffi.Pointer<ffi.Int64>, int)>();

  int _lrotl(
    int arg0,
    int arg1,
  ) {
    return __lrotl(
      arg0,
      arg1,
    );
  }

  late final __lrotlPtr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function(ffi.Uint64, ffi.Int32)>>(
          '_lrotl');
  late final __lrotl = __lrotlPtr.asFunction<int Function(int, int)>();

  int _lrotr(
    int arg0,
    int arg1,
  ) {
    return __lrotr(
      arg0,
      arg1,
    );
  }

  late final __lrotrPtr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function(ffi.Uint64, ffi.Int32)>>(
          '_lrotr');
  late final __lrotr = __lrotrPtr.asFunction<int Function(int, int)>();

  void _m_prefetchw(
    ffi.Pointer<ffi.Void> arg0,
  ) {
    return __m_prefetchw(
      arg0,
    );
  }

  late final __m_prefetchwPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ffi.Void>)>>(
          '_m_prefetchw');
  late final __m_prefetchw =
      __m_prefetchwPtr.asFunction<void Function(ffi.Pointer<ffi.Void>)>();

  void _mm_clflushopt(
    ffi.Pointer<ffi.Void> arg0,
  ) {
    return __mm_clflushopt(
      arg0,
    );
  }

  late final __mm_clflushoptPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ffi.Void>)>>(
          '_mm_clflushopt');
  late final __mm_clflushopt =
      __mm_clflushoptPtr.asFunction<void Function(ffi.Pointer<ffi.Void>)>();

  void _mm_clwb(
    ffi.Pointer<ffi.Void> arg0,
  ) {
    return __mm_clwb(
      arg0,
    );
  }

  late final __mm_clwbPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ffi.Void>)>>(
          '_mm_clwb');
  late final __mm_clwb =
      __mm_clwbPtr.asFunction<void Function(ffi.Pointer<ffi.Void>)>();

  int _mm_cvtsd_si64x(
    _m128d arg0,
  ) {
    return __mm_cvtsd_si64x(
      arg0,
    );
  }

  late final __mm_cvtsd_si64xPtr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(_m128d)>>(
          '_mm_cvtsd_si64x');
  late final __mm_cvtsd_si64x =
      __mm_cvtsd_si64xPtr.asFunction<int Function(_m128d)>();

  int _mm_cvtsi128_si64x(
    __m128i arg0,
  ) {
    return __mm_cvtsi128_si64x(
      arg0,
    );
  }

  late final __mm_cvtsi128_si64xPtr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(__m128i)>>(
          '_mm_cvtsi128_si64x');
  late final __mm_cvtsi128_si64x =
      __mm_cvtsi128_si64xPtr.asFunction<int Function(__m128i)>();

  _m128d _mm_cvtsi64x_sd(
    _m128d arg0,
    int arg1,
  ) {
    return __mm_cvtsi64x_sd(
      arg0,
      arg1,
    );
  }

  late final __mm_cvtsi64x_sdPtr =
      _lookup<ffi.NativeFunction<_m128d Function(_m128d, ffi.Int64)>>(
          '_mm_cvtsi64x_sd');
  late final __mm_cvtsi64x_sd =
      __mm_cvtsi64x_sdPtr.asFunction<_m128d Function(_m128d, int)>();

  __m128i _mm_cvtsi64x_si128(
    int arg0,
  ) {
    return __mm_cvtsi64x_si128(
      arg0,
    );
  }

  late final __mm_cvtsi64x_si128Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(ffi.Int64)>>(
          '_mm_cvtsi64x_si128');
  late final __mm_cvtsi64x_si128 =
      __mm_cvtsi64x_si128Ptr.asFunction<__m128i Function(int)>();

  __m128 _mm_cvtsi64x_ss(
    __m128 arg0,
    int arg1,
  ) {
    return __mm_cvtsi64x_ss(
      arg0,
      arg1,
    );
  }

  late final __mm_cvtsi64x_ssPtr =
      _lookup<ffi.NativeFunction<__m128 Function(__m128, ffi.Int64)>>(
          '_mm_cvtsi64x_ss');
  late final __mm_cvtsi64x_ss =
      __mm_cvtsi64x_ssPtr.asFunction<__m128 Function(__m128, int)>();

  int _mm_cvtss_si64x(
    __m128 arg0,
  ) {
    return __mm_cvtss_si64x(
      arg0,
    );
  }

  late final __mm_cvtss_si64xPtr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(__m128)>>(
          '_mm_cvtss_si64x');
  late final __mm_cvtss_si64x =
      __mm_cvtss_si64xPtr.asFunction<int Function(__m128)>();

  int _mm_cvttsd_si64x(
    _m128d arg0,
  ) {
    return __mm_cvttsd_si64x(
      arg0,
    );
  }

  late final __mm_cvttsd_si64xPtr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(_m128d)>>(
          '_mm_cvttsd_si64x');
  late final __mm_cvttsd_si64x =
      __mm_cvttsd_si64xPtr.asFunction<int Function(_m128d)>();

  int _mm_cvttss_si64x(
    __m128 arg0,
  ) {
    return __mm_cvttss_si64x(
      arg0,
    );
  }

  late final __mm_cvttss_si64xPtr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(__m128)>>(
          '_mm_cvttss_si64x');
  late final __mm_cvttss_si64x =
      __mm_cvttss_si64xPtr.asFunction<int Function(__m128)>();

  __m128i _mm_extract_si64(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_extract_si64(
      arg0,
      arg1,
    );
  }

  late final __mm_extract_si64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_extract_si64');
  late final __mm_extract_si64 =
      __mm_extract_si64Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_extracti_si64(
    __m128i arg0,
    int arg1,
    int arg2,
  ) {
    return __mm_extracti_si64(
      arg0,
      arg1,
      arg2,
    );
  }

  late final __mm_extracti_si64Ptr = _lookup<
          ffi.NativeFunction<__m128i Function(__m128i, ffi.Int32, ffi.Int32)>>(
      '_mm_extracti_si64');
  late final __mm_extracti_si64 =
      __mm_extracti_si64Ptr.asFunction<__m128i Function(__m128i, int, int)>();

  __m128i _mm_insert_si64(
    __m128i arg0,
    __m128i arg1,
  ) {
    return __mm_insert_si64(
      arg0,
      arg1,
    );
  }

  late final __mm_insert_si64Ptr =
      _lookup<ffi.NativeFunction<__m128i Function(__m128i, __m128i)>>(
          '_mm_insert_si64');
  late final __mm_insert_si64 =
      __mm_insert_si64Ptr.asFunction<__m128i Function(__m128i, __m128i)>();

  __m128i _mm_inserti_si64(
    __m128i arg0,
    __m128i arg1,
    int arg2,
    int arg3,
  ) {
    return __mm_inserti_si64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __mm_inserti_si64Ptr = _lookup<
      ffi.NativeFunction<
          __m128i Function(
              __m128i, __m128i, ffi.Int32, ffi.Int32)>>('_mm_inserti_si64');
  late final __mm_inserti_si64 = __mm_inserti_si64Ptr
      .asFunction<__m128i Function(__m128i, __m128i, int, int)>();

  __m128i _mm_setr_epi64x(
    int arg0,
    int arg1,
  ) {
    return __mm_setr_epi64x(
      arg0,
      arg1,
    );
  }

  late final __mm_setr_epi64xPtr =
      _lookup<ffi.NativeFunction<__m128i Function(ffi.Int64, ffi.Int64)>>(
          '_mm_setr_epi64x');
  late final __mm_setr_epi64x =
      __mm_setr_epi64xPtr.asFunction<__m128i Function(int, int)>();

  void _mm_stream_sd(
    ffi.Pointer<ffi.Double> arg0,
    _m128d arg1,
  ) {
    return __mm_stream_sd(
      arg0,
      arg1,
    );
  }

  late final __mm_stream_sdPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Double>, _m128d)>>('_mm_stream_sd');
  late final __mm_stream_sd = __mm_stream_sdPtr
      .asFunction<void Function(ffi.Pointer<ffi.Double>, _m128d)>();

  void _mm_stream_si64x(
    ffi.Pointer<ffi.Int64> arg0,
    int arg1,
  ) {
    return __mm_stream_si64x(
      arg0,
      arg1,
    );
  }

  late final __mm_stream_si64xPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<ffi.Int64>, ffi.Int64)>>('_mm_stream_si64x');
  late final __mm_stream_si64x = __mm_stream_si64xPtr
      .asFunction<void Function(ffi.Pointer<ffi.Int64>, int)>();

  void _mm_stream_ss(
    ffi.Pointer<ffi.Float> arg0,
    __m128 arg1,
  ) {
    return __mm_stream_ss(
      arg0,
      arg1,
    );
  }

  late final __mm_stream_ssPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Float>, __m128)>>('_mm_stream_ss');
  late final __mm_stream_ss = __mm_stream_ssPtr
      .asFunction<void Function(ffi.Pointer<ffi.Float>, __m128)>();

  int _mul128(
    int _Multiplier,
    int _Multiplicand,
    ffi.Pointer<ffi.Int64> _HighProduct,
  ) {
    return __mul128(
      _Multiplier,
      _Multiplicand,
      _HighProduct,
    );
  }

  late final __mul128Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Int64 Function(
              ffi.Int64, ffi.Int64, ffi.Pointer<ffi.Int64>)>>('_mul128');
  late final __mul128 =
      __mul128Ptr.asFunction<int Function(int, int, ffi.Pointer<ffi.Int64>)>();

  int _rotl(
    int _Value,
    int _Shift,
  ) {
    return __rotl(
      _Value,
      _Shift,
    );
  }

  late final __rotlPtr =
      _lookup<ffi.NativeFunction<ffi.Uint32 Function(ffi.Uint32, ffi.Int32)>>(
          '_rotl');
  late final __rotl = __rotlPtr.asFunction<int Function(int, int)>();

  int _rotl16(
    int _Value,
    int _Shift,
  ) {
    return __rotl16(
      _Value,
      _Shift,
    );
  }

  late final __rotl16Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint16 Function(ffi.Uint16, ffi.Uint8)>>(
          '_rotl16');
  late final __rotl16 = __rotl16Ptr.asFunction<int Function(int, int)>();

  int _rotl64(
    int _Value,
    int _Shift,
  ) {
    return __rotl64(
      _Value,
      _Shift,
    );
  }

  late final __rotl64Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function(ffi.Uint64, ffi.Int32)>>(
          '_rotl64');
  late final __rotl64 = __rotl64Ptr.asFunction<int Function(int, int)>();

  int _rotl8(
    int _Value,
    int _Shift,
  ) {
    return __rotl8(
      _Value,
      _Shift,
    );
  }

  late final __rotl8Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint8 Function(ffi.Uint8, ffi.Uint8)>>(
          '_rotl8');
  late final __rotl8 = __rotl8Ptr.asFunction<int Function(int, int)>();

  int _rotr(
    int _Value,
    int _Shift,
  ) {
    return __rotr(
      _Value,
      _Shift,
    );
  }

  late final __rotrPtr =
      _lookup<ffi.NativeFunction<ffi.Uint32 Function(ffi.Uint32, ffi.Int32)>>(
          '_rotr');
  late final __rotr = __rotrPtr.asFunction<int Function(int, int)>();

  int _rotr16(
    int _Value,
    int _Shift,
  ) {
    return __rotr16(
      _Value,
      _Shift,
    );
  }

  late final __rotr16Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint16 Function(ffi.Uint16, ffi.Uint8)>>(
          '_rotr16');
  late final __rotr16 = __rotr16Ptr.asFunction<int Function(int, int)>();

  int _rotr64(
    int _Value,
    int _Shift,
  ) {
    return __rotr64(
      _Value,
      _Shift,
    );
  }

  late final __rotr64Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint64 Function(ffi.Uint64, ffi.Int32)>>(
          '_rotr64');
  late final __rotr64 = __rotr64Ptr.asFunction<int Function(int, int)>();

  int _rotr8(
    int _Value,
    int _Shift,
  ) {
    return __rotr8(
      _Value,
      _Shift,
    );
  }

  late final __rotr8Ptr =
      _lookup<ffi.NativeFunction<ffi.Uint8 Function(ffi.Uint8, ffi.Uint8)>>(
          '_rotr8');
  late final __rotr8 = __rotr8Ptr.asFunction<int Function(int, int)>();

  int _setjmpex(
    ffi.Pointer<_JBTYPE> arg0,
  ) {
    return __setjmpex(
      arg0,
    );
  }

  late final __setjmpexPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<_JBTYPE>)>>(
          '_setjmpex');
  late final __setjmpex =
      __setjmpexPtr.asFunction<int Function(ffi.Pointer<_JBTYPE>)>();

  void _rsm() {
    return __rsm();
  }

  late final __rsmPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('_rsm');
  late final __rsm = __rsmPtr.asFunction<void Function()>();

  void _lgdt(
    ffi.Pointer<ffi.Void> arg0,
  ) {
    return __lgdt(
      arg0,
    );
  }

  late final __lgdtPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ffi.Void>)>>(
          '_lgdt');
  late final __lgdt =
      __lgdtPtr.asFunction<void Function(ffi.Pointer<ffi.Void>)>();

  void _sgdt(
    ffi.Pointer<ffi.Void> arg0,
  ) {
    return __sgdt(
      arg0,
    );
  }

  late final __sgdtPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ffi.Void>)>>(
          '_sgdt');
  late final __sgdt =
      __sgdtPtr.asFunction<void Function(ffi.Pointer<ffi.Void>)>();

  void _clac() {
    return __clac();
  }

  late final __clacPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('_clac');
  late final __clac = __clacPtr.asFunction<void Function()>();

  void _stac() {
    return __stac();
  }

  late final __stacPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('_stac');
  late final __stac = __stacPtr.asFunction<void Function()>();

  int _addcarry_u8(
    int arg0,
    int arg1,
    int arg2,
    ffi.Pointer<ffi.Uint8> arg3,
  ) {
    return __addcarry_u8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __addcarry_u8Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Uint8 Function(ffi.Uint8, ffi.Uint8, ffi.Uint8,
              ffi.Pointer<ffi.Uint8>)>>('_addcarry_u8');
  late final __addcarry_u8 = __addcarry_u8Ptr
      .asFunction<int Function(int, int, int, ffi.Pointer<ffi.Uint8>)>();

  int _subborrow_u8(
    int arg0,
    int arg1,
    int arg2,
    ffi.Pointer<ffi.Uint8> arg3,
  ) {
    return __subborrow_u8(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __subborrow_u8Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Uint8 Function(ffi.Uint8, ffi.Uint8, ffi.Uint8,
              ffi.Pointer<ffi.Uint8>)>>('_subborrow_u8');
  late final __subborrow_u8 = __subborrow_u8Ptr
      .asFunction<int Function(int, int, int, ffi.Pointer<ffi.Uint8>)>();

  int _addcarry_u16(
    int arg0,
    int arg1,
    int arg2,
    ffi.Pointer<ffi.Uint16> arg3,
  ) {
    return __addcarry_u16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __addcarry_u16Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Uint8 Function(ffi.Uint8, ffi.Uint16, ffi.Uint16,
              ffi.Pointer<ffi.Uint16>)>>('_addcarry_u16');
  late final __addcarry_u16 = __addcarry_u16Ptr
      .asFunction<int Function(int, int, int, ffi.Pointer<ffi.Uint16>)>();

  int _subborrow_u16(
    int arg0,
    int arg1,
    int arg2,
    ffi.Pointer<ffi.Uint16> arg3,
  ) {
    return __subborrow_u16(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __subborrow_u16Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Uint8 Function(ffi.Uint8, ffi.Uint16, ffi.Uint16,
              ffi.Pointer<ffi.Uint16>)>>('_subborrow_u16');
  late final __subborrow_u16 = __subborrow_u16Ptr
      .asFunction<int Function(int, int, int, ffi.Pointer<ffi.Uint16>)>();

  int _addcarry_u32(
    int arg0,
    int arg1,
    int arg2,
    ffi.Pointer<ffi.Uint32> arg3,
  ) {
    return __addcarry_u32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __addcarry_u32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Uint8 Function(ffi.Uint8, ffi.Uint32, ffi.Uint32,
              ffi.Pointer<ffi.Uint32>)>>('_addcarry_u32');
  late final __addcarry_u32 = __addcarry_u32Ptr
      .asFunction<int Function(int, int, int, ffi.Pointer<ffi.Uint32>)>();

  int _subborrow_u32(
    int arg0,
    int arg1,
    int arg2,
    ffi.Pointer<ffi.Uint32> arg3,
  ) {
    return __subborrow_u32(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __subborrow_u32Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Uint8 Function(ffi.Uint8, ffi.Uint32, ffi.Uint32,
              ffi.Pointer<ffi.Uint32>)>>('_subborrow_u32');
  late final __subborrow_u32 = __subborrow_u32Ptr
      .asFunction<int Function(int, int, int, ffi.Pointer<ffi.Uint32>)>();

  int _addcarry_u64(
    int arg0,
    int arg1,
    int arg2,
    ffi.Pointer<ffi.Uint64> arg3,
  ) {
    return __addcarry_u64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __addcarry_u64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Uint8 Function(ffi.Uint8, ffi.Uint64, ffi.Uint64,
              ffi.Pointer<ffi.Uint64>)>>('_addcarry_u64');
  late final __addcarry_u64 = __addcarry_u64Ptr
      .asFunction<int Function(int, int, int, ffi.Pointer<ffi.Uint64>)>();

  int _subborrow_u64(
    int arg0,
    int arg1,
    int arg2,
    ffi.Pointer<ffi.Uint64> arg3,
  ) {
    return __subborrow_u64(
      arg0,
      arg1,
      arg2,
      arg3,
    );
  }

  late final __subborrow_u64Ptr = _lookup<
      ffi.NativeFunction<
          ffi.Uint8 Function(ffi.Uint8, ffi.Uint64, ffi.Uint64,
              ffi.Pointer<ffi.Uint64>)>>('_subborrow_u64');
  late final __subborrow_u64 = __subborrow_u64Ptr
      .asFunction<int Function(int, int, int, ffi.Pointer<ffi.Uint64>)>();

  /// Create a new mutex.
  ///
  /// All newly-created mutexes begin in the _unlocked_ state.
  ///
  /// Calls to SDL_LockMutex() will not return while the mutex is locked by
  /// another thread. See SDL_TryLockMutex() to attempt to lock without blocking.
  ///
  /// SDL mutexes are reentrant.
  ///
  /// \returns the initialized and unlocked mutex or NULL on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_DestroyMutex
  /// \sa SDL_LockMutex
  /// \sa SDL_TryLockMutex
  /// \sa SDL_UnlockMutex
  ffi.Pointer<SDL_mutex> SDL_CreateMutex() {
    return _SDL_CreateMutex();
  }

  late final _SDL_CreateMutexPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<SDL_mutex> Function()>>(
          'SDL_CreateMutex');
  late final _SDL_CreateMutex =
      _SDL_CreateMutexPtr.asFunction<ffi.Pointer<SDL_mutex> Function()>();

  /// Lock the mutex.
  ///
  /// This will block until the mutex is available, which is to say it is in the
  /// unlocked state and the OS has chosen the caller as the next thread to lock
  /// it. Of all threads waiting to lock the mutex, only one may do so at a time.
  ///
  /// It is legal for the owning thread to lock an already-locked mutex. It must
  /// unlock it the same number of times before it is actually made available for
  /// other threads in the system (this is known as a "recursive mutex").
  ///
  /// \param mutex the mutex to lock
  /// \return 0, or -1 on error.
  ///
  /// \since This function is available since SDL 2.0.0.
  int SDL_LockMutex(
    ffi.Pointer<SDL_mutex> mutex,
  ) {
    return _SDL_LockMutex(
      mutex,
    );
  }

  late final _SDL_LockMutexPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<SDL_mutex>)>>(
          'SDL_LockMutex');
  late final _SDL_LockMutex =
      _SDL_LockMutexPtr.asFunction<int Function(ffi.Pointer<SDL_mutex>)>();

  /// Try to lock a mutex without blocking.
  ///
  /// This works just like SDL_LockMutex(), but if the mutex is not available,
  /// this function returns `SDL_MUTEX_TIMEOUT` immediately.
  ///
  /// This technique is useful if you need exclusive access to a resource but
  /// don't want to wait for it, and will return to it to try again later.
  ///
  /// \param mutex the mutex to try to lock
  /// \returns 0, `SDL_MUTEX_TIMEDOUT`, or -1 on error; call SDL_GetError() for
  /// more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_CreateMutex
  /// \sa SDL_DestroyMutex
  /// \sa SDL_LockMutex
  /// \sa SDL_UnlockMutex
  int SDL_TryLockMutex(
    ffi.Pointer<SDL_mutex> mutex,
  ) {
    return _SDL_TryLockMutex(
      mutex,
    );
  }

  late final _SDL_TryLockMutexPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<SDL_mutex>)>>(
          'SDL_TryLockMutex');
  late final _SDL_TryLockMutex =
      _SDL_TryLockMutexPtr.asFunction<int Function(ffi.Pointer<SDL_mutex>)>();

  /// Unlock the mutex.
  ///
  /// It is legal for the owning thread to lock an already-locked mutex. It must
  /// unlock it the same number of times before it is actually made available for
  /// other threads in the system (this is known as a "recursive mutex").
  ///
  /// It is an error to unlock a mutex that has not been locked by the current
  /// thread, and doing so results in undefined behavior.
  ///
  /// It is also an error to unlock a mutex that isn't locked at all.
  ///
  /// \param mutex the mutex to unlock.
  /// \returns 0, or -1 on error.
  ///
  /// \since This function is available since SDL 2.0.0.
  int SDL_UnlockMutex(
    ffi.Pointer<SDL_mutex> mutex,
  ) {
    return _SDL_UnlockMutex(
      mutex,
    );
  }

  late final _SDL_UnlockMutexPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<SDL_mutex>)>>(
          'SDL_UnlockMutex');
  late final _SDL_UnlockMutex =
      _SDL_UnlockMutexPtr.asFunction<int Function(ffi.Pointer<SDL_mutex>)>();

  /// Destroy a mutex created with SDL_CreateMutex().
  ///
  /// This function must be called on any mutex that is no longer needed. Failure
  /// to destroy a mutex will result in a system memory or resource leak. While
  /// it is safe to destroy a mutex that is _unlocked_, it is not safe to attempt
  /// to destroy a locked mutex, and may result in undefined behavior depending
  /// on the platform.
  ///
  /// \param mutex the mutex to destroy
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_CreateMutex
  /// \sa SDL_LockMutex
  /// \sa SDL_TryLockMutex
  /// \sa SDL_UnlockMutex
  void SDL_DestroyMutex(
    ffi.Pointer<SDL_mutex> mutex,
  ) {
    return _SDL_DestroyMutex(
      mutex,
    );
  }

  late final _SDL_DestroyMutexPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<SDL_mutex>)>>(
          'SDL_DestroyMutex');
  late final _SDL_DestroyMutex =
      _SDL_DestroyMutexPtr.asFunction<void Function(ffi.Pointer<SDL_mutex>)>();

  /// Create a semaphore.
  ///
  /// This function creates a new semaphore and initializes it with the value
  /// `initial_value`. Each wait operation on the semaphore will atomically
  /// decrement the semaphore value and potentially block if the semaphore value
  /// is 0. Each post operation will atomically increment the semaphore value and
  /// wake waiting threads and allow them to retry the wait operation.
  ///
  /// \param initial_value the starting value of the semaphore
  /// \returns a new semaphore or NULL on failure; call SDL_GetError() for more
  /// information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_DestroySemaphore
  /// \sa SDL_SemPost
  /// \sa SDL_SemTryWait
  /// \sa SDL_SemValue
  /// \sa SDL_SemWait
  /// \sa SDL_SemWaitTimeout
  ffi.Pointer<SDL_sem> SDL_CreateSemaphore(
    int initial_value,
  ) {
    return _SDL_CreateSemaphore(
      initial_value,
    );
  }

  late final _SDL_CreateSemaphorePtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<SDL_sem> Function(Uint32)>>(
          'SDL_CreateSemaphore');
  late final _SDL_CreateSemaphore =
      _SDL_CreateSemaphorePtr.asFunction<ffi.Pointer<SDL_sem> Function(int)>();

  /// Destroy a semaphore.
  ///
  /// It is not safe to destroy a semaphore if there are threads currently
  /// waiting on it.
  ///
  /// \param sem the semaphore to destroy
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_CreateSemaphore
  /// \sa SDL_SemPost
  /// \sa SDL_SemTryWait
  /// \sa SDL_SemValue
  /// \sa SDL_SemWait
  /// \sa SDL_SemWaitTimeout
  void SDL_DestroySemaphore(
    ffi.Pointer<SDL_sem> sem,
  ) {
    return _SDL_DestroySemaphore(
      sem,
    );
  }

  late final _SDL_DestroySemaphorePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<SDL_sem>)>>(
          'SDL_DestroySemaphore');
  late final _SDL_DestroySemaphore = _SDL_DestroySemaphorePtr.asFunction<
      void Function(ffi.Pointer<SDL_sem>)>();

  /// Wait until a semaphore has a positive value and then decrements it.
  ///
  /// This function suspends the calling thread until either the semaphore
  /// pointed to by `sem` has a positive value or the call is interrupted by a
  /// signal or error. If the call is successful it will atomically decrement the
  /// semaphore value.
  ///
  /// This function is the equivalent of calling SDL_SemWaitTimeout() with a time
  /// length of `SDL_MUTEX_MAXWAIT`.
  ///
  /// \param sem the semaphore wait on
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_CreateSemaphore
  /// \sa SDL_DestroySemaphore
  /// \sa SDL_SemPost
  /// \sa SDL_SemTryWait
  /// \sa SDL_SemValue
  /// \sa SDL_SemWait
  /// \sa SDL_SemWaitTimeout
  int SDL_SemWait(
    ffi.Pointer<SDL_sem> sem,
  ) {
    return _SDL_SemWait(
      sem,
    );
  }

  late final _SDL_SemWaitPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<SDL_sem>)>>(
          'SDL_SemWait');
  late final _SDL_SemWait =
      _SDL_SemWaitPtr.asFunction<int Function(ffi.Pointer<SDL_sem>)>();

  /// See if a semaphore has a positive value and decrement it if it does.
  ///
  /// This function checks to see if the semaphore pointed to by `sem` has a
  /// positive value and atomically decrements the semaphore value if it does. If
  /// the semaphore doesn't have a positive value, the function immediately
  /// returns SDL_MUTEX_TIMEDOUT.
  ///
  /// \param sem the semaphore to wait on
  /// \returns 0 if the wait succeeds, `SDL_MUTEX_TIMEDOUT` if the wait would
  /// block, or a negative error code on failure; call SDL_GetError()
  /// for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_CreateSemaphore
  /// \sa SDL_DestroySemaphore
  /// \sa SDL_SemPost
  /// \sa SDL_SemValue
  /// \sa SDL_SemWait
  /// \sa SDL_SemWaitTimeout
  int SDL_SemTryWait(
    ffi.Pointer<SDL_sem> sem,
  ) {
    return _SDL_SemTryWait(
      sem,
    );
  }

  late final _SDL_SemTryWaitPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<SDL_sem>)>>(
          'SDL_SemTryWait');
  late final _SDL_SemTryWait =
      _SDL_SemTryWaitPtr.asFunction<int Function(ffi.Pointer<SDL_sem>)>();

  /// Wait until a semaphore has a positive value and then decrements it.
  ///
  /// This function suspends the calling thread until either the semaphore
  /// pointed to by `sem` has a positive value, the call is interrupted by a
  /// signal or error, or the specified time has elapsed. If the call is
  /// successful it will atomically decrement the semaphore value.
  ///
  /// \param sem the semaphore to wait on
  /// \param ms the length of the timeout, in milliseconds
  /// \returns 0 if the wait succeeds, `SDL_MUTEX_TIMEDOUT` if the wait does not
  /// succeed in the allotted time, or a negative error code on failure;
  /// call SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_CreateSemaphore
  /// \sa SDL_DestroySemaphore
  /// \sa SDL_SemPost
  /// \sa SDL_SemTryWait
  /// \sa SDL_SemValue
  /// \sa SDL_SemWait
  int SDL_SemWaitTimeout(
    ffi.Pointer<SDL_sem> sem,
    int ms,
  ) {
    return _SDL_SemWaitTimeout(
      sem,
      ms,
    );
  }

  late final _SDL_SemWaitTimeoutPtr = _lookup<
          ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<SDL_sem>, Uint32)>>(
      'SDL_SemWaitTimeout');
  late final _SDL_SemWaitTimeout = _SDL_SemWaitTimeoutPtr.asFunction<
      int Function(ffi.Pointer<SDL_sem>, int)>();

  /// Atomically increment a semaphore's value and wake waiting threads.
  ///
  /// \param sem the semaphore to increment
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_CreateSemaphore
  /// \sa SDL_DestroySemaphore
  /// \sa SDL_SemTryWait
  /// \sa SDL_SemValue
  /// \sa SDL_SemWait
  /// \sa SDL_SemWaitTimeout
  int SDL_SemPost(
    ffi.Pointer<SDL_sem> sem,
  ) {
    return _SDL_SemPost(
      sem,
    );
  }

  late final _SDL_SemPostPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<SDL_sem>)>>(
          'SDL_SemPost');
  late final _SDL_SemPost =
      _SDL_SemPostPtr.asFunction<int Function(ffi.Pointer<SDL_sem>)>();

  /// Get the current value of a semaphore.
  ///
  /// \param sem the semaphore to query
  /// \returns the current value of the semaphore.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_CreateSemaphore
  int SDL_SemValue(
    ffi.Pointer<SDL_sem> sem,
  ) {
    return _SDL_SemValue(
      sem,
    );
  }

  late final _SDL_SemValuePtr =
      _lookup<ffi.NativeFunction<Uint32 Function(ffi.Pointer<SDL_sem>)>>(
          'SDL_SemValue');
  late final _SDL_SemValue =
      _SDL_SemValuePtr.asFunction<int Function(ffi.Pointer<SDL_sem>)>();

  /// Create a condition variable.
  ///
  /// \returns a new condition variable or NULL on failure; call SDL_GetError()
  /// for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_CondBroadcast
  /// \sa SDL_CondSignal
  /// \sa SDL_CondWait
  /// \sa SDL_CondWaitTimeout
  /// \sa SDL_DestroyCond
  ffi.Pointer<SDL_cond> SDL_CreateCond() {
    return _SDL_CreateCond();
  }

  late final _SDL_CreateCondPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<SDL_cond> Function()>>(
          'SDL_CreateCond');
  late final _SDL_CreateCond =
      _SDL_CreateCondPtr.asFunction<ffi.Pointer<SDL_cond> Function()>();

  /// Destroy a condition variable.
  ///
  /// \param cond the condition variable to destroy
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_CondBroadcast
  /// \sa SDL_CondSignal
  /// \sa SDL_CondWait
  /// \sa SDL_CondWaitTimeout
  /// \sa SDL_CreateCond
  void SDL_DestroyCond(
    ffi.Pointer<SDL_cond> cond,
  ) {
    return _SDL_DestroyCond(
      cond,
    );
  }

  late final _SDL_DestroyCondPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<SDL_cond>)>>(
          'SDL_DestroyCond');
  late final _SDL_DestroyCond =
      _SDL_DestroyCondPtr.asFunction<void Function(ffi.Pointer<SDL_cond>)>();

  /// Restart one of the threads that are waiting on the condition variable.
  ///
  /// \param cond the condition variable to signal
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_CondBroadcast
  /// \sa SDL_CondWait
  /// \sa SDL_CondWaitTimeout
  /// \sa SDL_CreateCond
  /// \sa SDL_DestroyCond
  int SDL_CondSignal(
    ffi.Pointer<SDL_cond> cond,
  ) {
    return _SDL_CondSignal(
      cond,
    );
  }

  late final _SDL_CondSignalPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<SDL_cond>)>>(
          'SDL_CondSignal');
  late final _SDL_CondSignal =
      _SDL_CondSignalPtr.asFunction<int Function(ffi.Pointer<SDL_cond>)>();

  /// Restart all threads that are waiting on the condition variable.
  ///
  /// \param cond the condition variable to signal
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_CondSignal
  /// \sa SDL_CondWait
  /// \sa SDL_CondWaitTimeout
  /// \sa SDL_CreateCond
  /// \sa SDL_DestroyCond
  int SDL_CondBroadcast(
    ffi.Pointer<SDL_cond> cond,
  ) {
    return _SDL_CondBroadcast(
      cond,
    );
  }

  late final _SDL_CondBroadcastPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<SDL_cond>)>>(
          'SDL_CondBroadcast');
  late final _SDL_CondBroadcast =
      _SDL_CondBroadcastPtr.asFunction<int Function(ffi.Pointer<SDL_cond>)>();

  /// Wait until a condition variable is signaled.
  ///
  /// This function unlocks the specified `mutex` and waits for another thread to
  /// call SDL_CondSignal() or SDL_CondBroadcast() on the condition variable
  /// `cond`. Once the condition variable is signaled, the mutex is re-locked and
  /// the function returns.
  ///
  /// The mutex must be locked before calling this function.
  ///
  /// This function is the equivalent of calling SDL_CondWaitTimeout() with a
  /// time length of `SDL_MUTEX_MAXWAIT`.
  ///
  /// \param cond the condition variable to wait on
  /// \param mutex the mutex used to coordinate thread access
  /// \returns 0 when it is signaled or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_CondBroadcast
  /// \sa SDL_CondSignal
  /// \sa SDL_CondWaitTimeout
  /// \sa SDL_CreateCond
  /// \sa SDL_DestroyCond
  int SDL_CondWait(
    ffi.Pointer<SDL_cond> cond,
    ffi.Pointer<SDL_mutex> mutex,
  ) {
    return _SDL_CondWait(
      cond,
      mutex,
    );
  }

  late final _SDL_CondWaitPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<SDL_cond>, ffi.Pointer<SDL_mutex>)>>('SDL_CondWait');
  late final _SDL_CondWait = _SDL_CondWaitPtr.asFunction<
      int Function(ffi.Pointer<SDL_cond>, ffi.Pointer<SDL_mutex>)>();

  /// Wait until a condition variable is signaled or a certain time has passed.
  ///
  /// This function unlocks the specified `mutex` and waits for another thread to
  /// call SDL_CondSignal() or SDL_CondBroadcast() on the condition variable
  /// `cond`, or for the specified time to elapse. Once the condition variable is
  /// signaled or the time elapsed, the mutex is re-locked and the function
  /// returns.
  ///
  /// The mutex must be locked before calling this function.
  ///
  /// \param cond the condition variable to wait on
  /// \param mutex the mutex used to coordinate thread access
  /// \param ms the maximum time to wait, in milliseconds, or `SDL_MUTEX_MAXWAIT`
  /// to wait indefinitely
  /// \returns 0 if the condition variable is signaled, `SDL_MUTEX_TIMEDOUT` if
  /// the condition is not signaled in the allotted time, or a negative
  /// error code on failure; call SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_CondBroadcast
  /// \sa SDL_CondSignal
  /// \sa SDL_CondWait
  /// \sa SDL_CreateCond
  /// \sa SDL_DestroyCond
  int SDL_CondWaitTimeout(
    ffi.Pointer<SDL_cond> cond,
    ffi.Pointer<SDL_mutex> mutex,
    int ms,
  ) {
    return _SDL_CondWaitTimeout(
      cond,
      mutex,
      ms,
    );
  }

  late final _SDL_CondWaitTimeoutPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_cond>, ffi.Pointer<SDL_mutex>,
              Uint32)>>('SDL_CondWaitTimeout');
  late final _SDL_CondWaitTimeout = _SDL_CondWaitTimeoutPtr.asFunction<
      int Function(ffi.Pointer<SDL_cond>, ffi.Pointer<SDL_mutex>, int)>();

  late final ffi.Pointer<ffi.Double> __HUGE = _lookup<ffi.Double>('_HUGE');

  double get _HUGE => __HUGE.value;

  set _HUGE(double value) => __HUGE.value = value;

  void _fperrraise(
    int _Except,
  ) {
    return __fperrraise(
      _Except,
    );
  }

  late final __fperrraisePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Int32)>>('_fperrraise');
  late final __fperrraise = __fperrraisePtr.asFunction<void Function(int)>();

  int _dclass(
    double _X,
  ) {
    return __dclass(
      _X,
    );
  }

  late final __dclassPtr =
      _lookup<ffi.NativeFunction<ffi.Int16 Function(ffi.Double)>>('_dclass');
  late final __dclass = __dclassPtr.asFunction<int Function(double)>();

  int _fdclass(
    double _X,
  ) {
    return __fdclass(
      _X,
    );
  }

  late final __fdclassPtr =
      _lookup<ffi.NativeFunction<ffi.Int16 Function(ffi.Float)>>('_fdclass');
  late final __fdclass = __fdclassPtr.asFunction<int Function(double)>();

  int _dsign(
    double _X,
  ) {
    return __dsign(
      _X,
    );
  }

  late final __dsignPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Double)>>('_dsign');
  late final __dsign = __dsignPtr.asFunction<int Function(double)>();

  int _fdsign(
    double _X,
  ) {
    return __fdsign(
      _X,
    );
  }

  late final __fdsignPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Float)>>('_fdsign');
  late final __fdsign = __fdsignPtr.asFunction<int Function(double)>();

  int _dpcomp(
    double _X,
    double _Y,
  ) {
    return __dpcomp(
      _X,
      _Y,
    );
  }

  late final __dpcompPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Double, ffi.Double)>>(
          '_dpcomp');
  late final __dpcomp = __dpcompPtr.asFunction<int Function(double, double)>();

  int _fdpcomp(
    double _X,
    double _Y,
  ) {
    return __fdpcomp(
      _X,
      _Y,
    );
  }

  late final __fdpcompPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Float, ffi.Float)>>(
          '_fdpcomp');
  late final __fdpcomp =
      __fdpcompPtr.asFunction<int Function(double, double)>();

  int _dtest(
    ffi.Pointer<ffi.Double> _Px,
  ) {
    return __dtest(
      _Px,
    );
  }

  late final __dtestPtr =
      _lookup<ffi.NativeFunction<ffi.Int16 Function(ffi.Pointer<ffi.Double>)>>(
          '_dtest');
  late final __dtest =
      __dtestPtr.asFunction<int Function(ffi.Pointer<ffi.Double>)>();

  int _fdtest(
    ffi.Pointer<ffi.Float> _Px,
  ) {
    return __fdtest(
      _Px,
    );
  }

  late final __fdtestPtr =
      _lookup<ffi.NativeFunction<ffi.Int16 Function(ffi.Pointer<ffi.Float>)>>(
          '_fdtest');
  late final __fdtest =
      __fdtestPtr.asFunction<int Function(ffi.Pointer<ffi.Float>)>();

  int _d_int(
    ffi.Pointer<ffi.Double> _Px,
    int _Xexp,
  ) {
    return __d_int(
      _Px,
      _Xexp,
    );
  }

  late final __d_intPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int16 Function(ffi.Pointer<ffi.Double>, ffi.Int16)>>('_d_int');
  late final __d_int =
      __d_intPtr.asFunction<int Function(ffi.Pointer<ffi.Double>, int)>();

  int _fd_int(
    ffi.Pointer<ffi.Float> _Px,
    int _Xexp,
  ) {
    return __fd_int(
      _Px,
      _Xexp,
    );
  }

  late final __fd_intPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int16 Function(ffi.Pointer<ffi.Float>, ffi.Int16)>>('_fd_int');
  late final __fd_int =
      __fd_intPtr.asFunction<int Function(ffi.Pointer<ffi.Float>, int)>();

  int _dscale(
    ffi.Pointer<ffi.Double> _Px,
    int _Lexp,
  ) {
    return __dscale(
      _Px,
      _Lexp,
    );
  }

  late final __dscalePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int16 Function(ffi.Pointer<ffi.Double>, ffi.Int64)>>('_dscale');
  late final __dscale =
      __dscalePtr.asFunction<int Function(ffi.Pointer<ffi.Double>, int)>();

  int _fdscale(
    ffi.Pointer<ffi.Float> _Px,
    int _Lexp,
  ) {
    return __fdscale(
      _Px,
      _Lexp,
    );
  }

  late final __fdscalePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int16 Function(ffi.Pointer<ffi.Float>, ffi.Int64)>>('_fdscale');
  late final __fdscale =
      __fdscalePtr.asFunction<int Function(ffi.Pointer<ffi.Float>, int)>();

  int _dunscale(
    ffi.Pointer<ffi.Int16> _Pex,
    ffi.Pointer<ffi.Double> _Px,
  ) {
    return __dunscale(
      _Pex,
      _Px,
    );
  }

  late final __dunscalePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int16 Function(
              ffi.Pointer<ffi.Int16>, ffi.Pointer<ffi.Double>)>>('_dunscale');
  late final __dunscale = __dunscalePtr.asFunction<
      int Function(ffi.Pointer<ffi.Int16>, ffi.Pointer<ffi.Double>)>();

  int _fdunscale(
    ffi.Pointer<ffi.Int16> _Pex,
    ffi.Pointer<ffi.Float> _Px,
  ) {
    return __fdunscale(
      _Pex,
      _Px,
    );
  }

  late final __fdunscalePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int16 Function(
              ffi.Pointer<ffi.Int16>, ffi.Pointer<ffi.Float>)>>('_fdunscale');
  late final __fdunscale = __fdunscalePtr.asFunction<
      int Function(ffi.Pointer<ffi.Int16>, ffi.Pointer<ffi.Float>)>();

  int _dexp(
    ffi.Pointer<ffi.Double> _Px,
    double _Y,
    int _Eoff,
  ) {
    return __dexp(
      _Px,
      _Y,
      _Eoff,
    );
  }

  late final __dexpPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int16 Function(
              ffi.Pointer<ffi.Double>, ffi.Double, ffi.Int64)>>('_dexp');
  late final __dexp = __dexpPtr
      .asFunction<int Function(ffi.Pointer<ffi.Double>, double, int)>();

  int _fdexp(
    ffi.Pointer<ffi.Float> _Px,
    double _Y,
    int _Eoff,
  ) {
    return __fdexp(
      _Px,
      _Y,
      _Eoff,
    );
  }

  late final __fdexpPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int16 Function(
              ffi.Pointer<ffi.Float>, ffi.Float, ffi.Int64)>>('_fdexp');
  late final __fdexp = __fdexpPtr
      .asFunction<int Function(ffi.Pointer<ffi.Float>, double, int)>();

  int _dnorm(
    ffi.Pointer<ffi.Uint16> _Ps,
  ) {
    return __dnorm(
      _Ps,
    );
  }

  late final __dnormPtr =
      _lookup<ffi.NativeFunction<ffi.Int16 Function(ffi.Pointer<ffi.Uint16>)>>(
          '_dnorm');
  late final __dnorm =
      __dnormPtr.asFunction<int Function(ffi.Pointer<ffi.Uint16>)>();

  int _fdnorm(
    ffi.Pointer<ffi.Uint16> _Ps,
  ) {
    return __fdnorm(
      _Ps,
    );
  }

  late final __fdnormPtr =
      _lookup<ffi.NativeFunction<ffi.Int16 Function(ffi.Pointer<ffi.Uint16>)>>(
          '_fdnorm');
  late final __fdnorm =
      __fdnormPtr.asFunction<int Function(ffi.Pointer<ffi.Uint16>)>();

  double _dpoly(
    double _X,
    ffi.Pointer<ffi.Double> _Tab,
    int _N,
  ) {
    return __dpoly(
      _X,
      _Tab,
      _N,
    );
  }

  late final __dpolyPtr = _lookup<
      ffi.NativeFunction<
          ffi.Double Function(
              ffi.Double, ffi.Pointer<ffi.Double>, ffi.Int32)>>('_dpoly');
  late final __dpoly = __dpolyPtr
      .asFunction<double Function(double, ffi.Pointer<ffi.Double>, int)>();

  double _fdpoly(
    double _X,
    ffi.Pointer<ffi.Float> _Tab,
    int _N,
  ) {
    return __fdpoly(
      _X,
      _Tab,
      _N,
    );
  }

  late final __fdpolyPtr = _lookup<
      ffi.NativeFunction<
          ffi.Float Function(
              ffi.Float, ffi.Pointer<ffi.Float>, ffi.Int32)>>('_fdpoly');
  late final __fdpoly = __fdpolyPtr
      .asFunction<double Function(double, ffi.Pointer<ffi.Float>, int)>();

  double _dlog(
    double _X,
    int _Baseflag,
  ) {
    return __dlog(
      _X,
      _Baseflag,
    );
  }

  late final __dlogPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double, ffi.Int32)>>(
          '_dlog');
  late final __dlog = __dlogPtr.asFunction<double Function(double, int)>();

  double _fdlog(
    double _X,
    int _Baseflag,
  ) {
    return __fdlog(
      _X,
      _Baseflag,
    );
  }

  late final __fdlogPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float, ffi.Int32)>>(
          '_fdlog');
  late final __fdlog = __fdlogPtr.asFunction<double Function(double, int)>();

  double _dsin(
    double _X,
    int _Qoff,
  ) {
    return __dsin(
      _X,
      _Qoff,
    );
  }

  late final __dsinPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double, ffi.Uint32)>>(
          '_dsin');
  late final __dsin = __dsinPtr.asFunction<double Function(double, int)>();

  double _fdsin(
    double _X,
    int _Qoff,
  ) {
    return __fdsin(
      _X,
      _Qoff,
    );
  }

  late final __fdsinPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float, ffi.Uint32)>>(
          '_fdsin');
  late final __fdsin = __fdsinPtr.asFunction<double Function(double, int)>();

  late final ffi.Pointer<_float_const> __Denorm_C =
      _lookup<_float_const>('_Denorm_C');

  ffi.Pointer<_float_const> get _Denorm_C => __Denorm_C;

  late final ffi.Pointer<_float_const> __Inf_C =
      _lookup<_float_const>('_Inf_C');

  ffi.Pointer<_float_const> get _Inf_C => __Inf_C;

  late final ffi.Pointer<_float_const> __Nan_C =
      _lookup<_float_const>('_Nan_C');

  ffi.Pointer<_float_const> get _Nan_C => __Nan_C;

  late final ffi.Pointer<_float_const> __Snan_C =
      _lookup<_float_const>('_Snan_C');

  ffi.Pointer<_float_const> get _Snan_C => __Snan_C;

  late final ffi.Pointer<_float_const> __Hugeval_C =
      _lookup<_float_const>('_Hugeval_C');

  ffi.Pointer<_float_const> get _Hugeval_C => __Hugeval_C;

  late final ffi.Pointer<_float_const> __FDenorm_C =
      _lookup<_float_const>('_FDenorm_C');

  ffi.Pointer<_float_const> get _FDenorm_C => __FDenorm_C;

  late final ffi.Pointer<_float_const> __FInf_C =
      _lookup<_float_const>('_FInf_C');

  ffi.Pointer<_float_const> get _FInf_C => __FInf_C;

  late final ffi.Pointer<_float_const> __FNan_C =
      _lookup<_float_const>('_FNan_C');

  ffi.Pointer<_float_const> get _FNan_C => __FNan_C;

  late final ffi.Pointer<_float_const> __FSnan_C =
      _lookup<_float_const>('_FSnan_C');

  ffi.Pointer<_float_const> get _FSnan_C => __FSnan_C;

  late final ffi.Pointer<_float_const> __LDenorm_C =
      _lookup<_float_const>('_LDenorm_C');

  ffi.Pointer<_float_const> get _LDenorm_C => __LDenorm_C;

  late final ffi.Pointer<_float_const> __LInf_C =
      _lookup<_float_const>('_LInf_C');

  ffi.Pointer<_float_const> get _LInf_C => __LInf_C;

  late final ffi.Pointer<_float_const> __LNan_C =
      _lookup<_float_const>('_LNan_C');

  ffi.Pointer<_float_const> get _LNan_C => __LNan_C;

  late final ffi.Pointer<_float_const> __LSnan_C =
      _lookup<_float_const>('_LSnan_C');

  ffi.Pointer<_float_const> get _LSnan_C => __LSnan_C;

  late final ffi.Pointer<_float_const> __Eps_C =
      _lookup<_float_const>('_Eps_C');

  ffi.Pointer<_float_const> get _Eps_C => __Eps_C;

  late final ffi.Pointer<_float_const> __Rteps_C =
      _lookup<_float_const>('_Rteps_C');

  ffi.Pointer<_float_const> get _Rteps_C => __Rteps_C;

  late final ffi.Pointer<_float_const> __FEps_C =
      _lookup<_float_const>('_FEps_C');

  ffi.Pointer<_float_const> get _FEps_C => __FEps_C;

  late final ffi.Pointer<_float_const> __FRteps_C =
      _lookup<_float_const>('_FRteps_C');

  ffi.Pointer<_float_const> get _FRteps_C => __FRteps_C;

  late final ffi.Pointer<_float_const> __LEps_C =
      _lookup<_float_const>('_LEps_C');

  ffi.Pointer<_float_const> get _LEps_C => __LEps_C;

  late final ffi.Pointer<_float_const> __LRteps_C =
      _lookup<_float_const>('_LRteps_C');

  ffi.Pointer<_float_const> get _LRteps_C => __LRteps_C;

  late final ffi.Pointer<ffi.Double> __Zero_C = _lookup<ffi.Double>('_Zero_C');

  double get _Zero_C => __Zero_C.value;

  set _Zero_C(double value) => __Zero_C.value = value;

  late final ffi.Pointer<ffi.Double> __Xbig_C = _lookup<ffi.Double>('_Xbig_C');

  double get _Xbig_C => __Xbig_C.value;

  set _Xbig_C(double value) => __Xbig_C.value = value;

  late final ffi.Pointer<ffi.Float> __FZero_C = _lookup<ffi.Float>('_FZero_C');

  double get _FZero_C => __FZero_C.value;

  set _FZero_C(double value) => __FZero_C.value = value;

  late final ffi.Pointer<ffi.Float> __FXbig_C = _lookup<ffi.Float>('_FXbig_C');

  double get _FXbig_C => __FXbig_C.value;

  set _FXbig_C(double value) => __FXbig_C.value = value;

  int abs(
    int _X,
  ) {
    return _abs(
      _X,
    );
  }

  late final _absPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Int32)>>('abs');
  late final _abs = _absPtr.asFunction<int Function(int)>();

  int labs(
    int _X,
  ) {
    return _labs(
      _X,
    );
  }

  late final _labsPtr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(ffi.Int64)>>('labs');
  late final _labs = _labsPtr.asFunction<int Function(int)>();

  int llabs(
    int _X,
  ) {
    return _llabs(
      _X,
    );
  }

  late final _llabsPtr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(ffi.Int64)>>('llabs');
  late final _llabs = _llabsPtr.asFunction<int Function(int)>();

  double acos(
    double _X,
  ) {
    return _acos(
      _X,
    );
  }

  late final _acosPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double)>>('acos');
  late final _acos = _acosPtr.asFunction<double Function(double)>();

  double asin(
    double _X,
  ) {
    return _asin(
      _X,
    );
  }

  late final _asinPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double)>>('asin');
  late final _asin = _asinPtr.asFunction<double Function(double)>();

  double atan(
    double _X,
  ) {
    return _atan(
      _X,
    );
  }

  late final _atanPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double)>>('atan');
  late final _atan = _atanPtr.asFunction<double Function(double)>();

  double atan2(
    double _Y,
    double _X,
  ) {
    return _atan2(
      _Y,
      _X,
    );
  }

  late final _atan2Ptr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double, ffi.Double)>>(
          'atan2');
  late final _atan2 = _atan2Ptr.asFunction<double Function(double, double)>();

  double cos(
    double _X,
  ) {
    return _cos(
      _X,
    );
  }

  late final _cosPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double)>>('cos');
  late final _cos = _cosPtr.asFunction<double Function(double)>();

  double cosh(
    double _X,
  ) {
    return _cosh(
      _X,
    );
  }

  late final _coshPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double)>>('cosh');
  late final _cosh = _coshPtr.asFunction<double Function(double)>();

  double exp(
    double _X,
  ) {
    return _exp(
      _X,
    );
  }

  late final _expPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double)>>('exp');
  late final _exp = _expPtr.asFunction<double Function(double)>();

  double fabs(
    double _X,
  ) {
    return _fabs(
      _X,
    );
  }

  late final _fabsPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double)>>('fabs');
  late final _fabs = _fabsPtr.asFunction<double Function(double)>();

  double fmod(
    double _X,
    double _Y,
  ) {
    return _fmod(
      _X,
      _Y,
    );
  }

  late final _fmodPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double, ffi.Double)>>(
          'fmod');
  late final _fmod = _fmodPtr.asFunction<double Function(double, double)>();

  double log(
    double _X,
  ) {
    return _log(
      _X,
    );
  }

  late final _logPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double)>>('log');
  late final _log = _logPtr.asFunction<double Function(double)>();

  double log10(
    double _X,
  ) {
    return _log10(
      _X,
    );
  }

  late final _log10Ptr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double)>>('log10');
  late final _log10 = _log10Ptr.asFunction<double Function(double)>();

  double pow(
    double _X,
    double _Y,
  ) {
    return _pow(
      _X,
      _Y,
    );
  }

  late final _powPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double, ffi.Double)>>(
          'pow');
  late final _pow = _powPtr.asFunction<double Function(double, double)>();

  double sin(
    double _X,
  ) {
    return _sin(
      _X,
    );
  }

  late final _sinPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double)>>('sin');
  late final _sin = _sinPtr.asFunction<double Function(double)>();

  double sinh(
    double _X,
  ) {
    return _sinh(
      _X,
    );
  }

  late final _sinhPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double)>>('sinh');
  late final _sinh = _sinhPtr.asFunction<double Function(double)>();

  double sqrt(
    double _X,
  ) {
    return _sqrt(
      _X,
    );
  }

  late final _sqrtPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double)>>('sqrt');
  late final _sqrt = _sqrtPtr.asFunction<double Function(double)>();

  double tan(
    double _X,
  ) {
    return _tan(
      _X,
    );
  }

  late final _tanPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double)>>('tan');
  late final _tan = _tanPtr.asFunction<double Function(double)>();

  double tanh(
    double _X,
  ) {
    return _tanh(
      _X,
    );
  }

  late final _tanhPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double)>>('tanh');
  late final _tanh = _tanhPtr.asFunction<double Function(double)>();

  double acosh(
    double _X,
  ) {
    return _acosh(
      _X,
    );
  }

  late final _acoshPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double)>>('acosh');
  late final _acosh = _acoshPtr.asFunction<double Function(double)>();

  double asinh(
    double _X,
  ) {
    return _asinh(
      _X,
    );
  }

  late final _asinhPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double)>>('asinh');
  late final _asinh = _asinhPtr.asFunction<double Function(double)>();

  double atanh(
    double _X,
  ) {
    return _atanh(
      _X,
    );
  }

  late final _atanhPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double)>>('atanh');
  late final _atanh = _atanhPtr.asFunction<double Function(double)>();

  double atof(
    ffi.Pointer<ffi.Int8> _String,
  ) {
    return _atof(
      _String,
    );
  }

  late final _atofPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Pointer<ffi.Int8>)>>(
          'atof');
  late final _atof =
      _atofPtr.asFunction<double Function(ffi.Pointer<ffi.Int8>)>();

  double _atof_l(
    ffi.Pointer<ffi.Int8> _String,
    _locale_t _Locale,
  ) {
    return __atof_l(
      _String,
      _Locale,
    );
  }

  late final __atof_lPtr = _lookup<
      ffi.NativeFunction<
          ffi.Double Function(ffi.Pointer<ffi.Int8>, _locale_t)>>('_atof_l');
  late final __atof_l = __atof_lPtr
      .asFunction<double Function(ffi.Pointer<ffi.Int8>, _locale_t)>();

  double _cabs(
    complex _Complex_value,
  ) {
    return __cabs(
      _Complex_value,
    );
  }

  late final __cabsPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(complex)>>('_cabs');
  late final __cabs = __cabsPtr.asFunction<double Function(complex)>();

  double cbrt(
    double _X,
  ) {
    return _cbrt(
      _X,
    );
  }

  late final _cbrtPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double)>>('cbrt');
  late final _cbrt = _cbrtPtr.asFunction<double Function(double)>();

  double ceil(
    double _X,
  ) {
    return _ceil(
      _X,
    );
  }

  late final _ceilPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double)>>('ceil');
  late final _ceil = _ceilPtr.asFunction<double Function(double)>();

  double _chgsign(
    double _X,
  ) {
    return __chgsign(
      _X,
    );
  }

  late final __chgsignPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double)>>('_chgsign');
  late final __chgsign = __chgsignPtr.asFunction<double Function(double)>();

  double copysign(
    double _Number,
    double _Sign,
  ) {
    return _copysign1(
      _Number,
      _Sign,
    );
  }

  late final _copysignPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double, ffi.Double)>>(
          'copysign');
  late final _copysign1 =
      _copysignPtr.asFunction<double Function(double, double)>();

  double _copysign(
    double _Number,
    double _Sign,
  ) {
    return __copysign1(
      _Number,
      _Sign,
    );
  }

  late final __copysignPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double, ffi.Double)>>(
          '_copysign');
  late final __copysign1 =
      __copysignPtr.asFunction<double Function(double, double)>();

  double erf(
    double _X,
  ) {
    return _erf(
      _X,
    );
  }

  late final _erfPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double)>>('erf');
  late final _erf = _erfPtr.asFunction<double Function(double)>();

  double erfc(
    double _X,
  ) {
    return _erfc(
      _X,
    );
  }

  late final _erfcPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double)>>('erfc');
  late final _erfc = _erfcPtr.asFunction<double Function(double)>();

  double exp2(
    double _X,
  ) {
    return _exp2(
      _X,
    );
  }

  late final _exp2Ptr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double)>>('exp2');
  late final _exp2 = _exp2Ptr.asFunction<double Function(double)>();

  double expm1(
    double _X,
  ) {
    return _expm1(
      _X,
    );
  }

  late final _expm1Ptr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double)>>('expm1');
  late final _expm1 = _expm1Ptr.asFunction<double Function(double)>();

  double fdim(
    double _X,
    double _Y,
  ) {
    return _fdim(
      _X,
      _Y,
    );
  }

  late final _fdimPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double, ffi.Double)>>(
          'fdim');
  late final _fdim = _fdimPtr.asFunction<double Function(double, double)>();

  double floor(
    double _X,
  ) {
    return _floor(
      _X,
    );
  }

  late final _floorPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double)>>('floor');
  late final _floor = _floorPtr.asFunction<double Function(double)>();

  double fma(
    double _X,
    double _Y,
    double _Z,
  ) {
    return _fma(
      _X,
      _Y,
      _Z,
    );
  }

  late final _fmaPtr = _lookup<
      ffi.NativeFunction<
          ffi.Double Function(ffi.Double, ffi.Double, ffi.Double)>>('fma');
  late final _fma =
      _fmaPtr.asFunction<double Function(double, double, double)>();

  double fmax(
    double _X,
    double _Y,
  ) {
    return _fmax(
      _X,
      _Y,
    );
  }

  late final _fmaxPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double, ffi.Double)>>(
          'fmax');
  late final _fmax = _fmaxPtr.asFunction<double Function(double, double)>();

  double fmin(
    double _X,
    double _Y,
  ) {
    return _fmin(
      _X,
      _Y,
    );
  }

  late final _fminPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double, ffi.Double)>>(
          'fmin');
  late final _fmin = _fminPtr.asFunction<double Function(double, double)>();

  double frexp(
    double _X,
    ffi.Pointer<ffi.Int32> _Y,
  ) {
    return _frexp(
      _X,
      _Y,
    );
  }

  late final _frexpPtr = _lookup<
      ffi.NativeFunction<
          ffi.Double Function(ffi.Double, ffi.Pointer<ffi.Int32>)>>('frexp');
  late final _frexp =
      _frexpPtr.asFunction<double Function(double, ffi.Pointer<ffi.Int32>)>();

  double hypot(
    double _X,
    double _Y,
  ) {
    return _hypot1(
      _X,
      _Y,
    );
  }

  late final _hypotPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double, ffi.Double)>>(
          'hypot');
  late final _hypot1 = _hypotPtr.asFunction<double Function(double, double)>();

  double _hypot(
    double _X,
    double _Y,
  ) {
    return __hypot(
      _X,
      _Y,
    );
  }

  late final __hypotPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double, ffi.Double)>>(
          '_hypot');
  late final __hypot = __hypotPtr.asFunction<double Function(double, double)>();

  int ilogb(
    double _X,
  ) {
    return _ilogb(
      _X,
    );
  }

  late final _ilogbPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Double)>>('ilogb');
  late final _ilogb = _ilogbPtr.asFunction<int Function(double)>();

  double ldexp(
    double _X,
    int _Y,
  ) {
    return _ldexp(
      _X,
      _Y,
    );
  }

  late final _ldexpPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double, ffi.Int32)>>(
          'ldexp');
  late final _ldexp = _ldexpPtr.asFunction<double Function(double, int)>();

  double lgamma(
    double _X,
  ) {
    return _lgamma(
      _X,
    );
  }

  late final _lgammaPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double)>>('lgamma');
  late final _lgamma = _lgammaPtr.asFunction<double Function(double)>();

  int llrint(
    double _X,
  ) {
    return _llrint(
      _X,
    );
  }

  late final _llrintPtr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(ffi.Double)>>('llrint');
  late final _llrint = _llrintPtr.asFunction<int Function(double)>();

  int llround(
    double _X,
  ) {
    return _llround(
      _X,
    );
  }

  late final _llroundPtr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(ffi.Double)>>('llround');
  late final _llround = _llroundPtr.asFunction<int Function(double)>();

  double log1p(
    double _X,
  ) {
    return _log1p(
      _X,
    );
  }

  late final _log1pPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double)>>('log1p');
  late final _log1p = _log1pPtr.asFunction<double Function(double)>();

  double log2(
    double _X,
  ) {
    return _log2(
      _X,
    );
  }

  late final _log2Ptr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double)>>('log2');
  late final _log2 = _log2Ptr.asFunction<double Function(double)>();

  double logb(
    double _X,
  ) {
    return _logb(
      _X,
    );
  }

  late final _logbPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double)>>('logb');
  late final _logb = _logbPtr.asFunction<double Function(double)>();

  int lrint(
    double _X,
  ) {
    return _lrint(
      _X,
    );
  }

  late final _lrintPtr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(ffi.Double)>>('lrint');
  late final _lrint = _lrintPtr.asFunction<int Function(double)>();

  int lround(
    double _X,
  ) {
    return _lround(
      _X,
    );
  }

  late final _lroundPtr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(ffi.Double)>>('lround');
  late final _lround = _lroundPtr.asFunction<int Function(double)>();

  int _matherr(
    ffi.Pointer<exception> _Except,
  ) {
    return __matherr(
      _Except,
    );
  }

  late final __matherrPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<exception>)>>(
          '_matherr');
  late final __matherr =
      __matherrPtr.asFunction<int Function(ffi.Pointer<exception>)>();

  double modf(
    double _X,
    ffi.Pointer<ffi.Double> _Y,
  ) {
    return _modf(
      _X,
      _Y,
    );
  }

  late final _modfPtr = _lookup<
      ffi.NativeFunction<
          ffi.Double Function(ffi.Double, ffi.Pointer<ffi.Double>)>>('modf');
  late final _modf =
      _modfPtr.asFunction<double Function(double, ffi.Pointer<ffi.Double>)>();

  double nan(
    ffi.Pointer<ffi.Int8> _X,
  ) {
    return _nan(
      _X,
    );
  }

  late final _nanPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Pointer<ffi.Int8>)>>(
          'nan');
  late final _nan =
      _nanPtr.asFunction<double Function(ffi.Pointer<ffi.Int8>)>();

  double nearbyint(
    double _X,
  ) {
    return _nearbyint(
      _X,
    );
  }

  late final _nearbyintPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double)>>('nearbyint');
  late final _nearbyint = _nearbyintPtr.asFunction<double Function(double)>();

  double nextafter(
    double _X,
    double _Y,
  ) {
    return _nextafter(
      _X,
      _Y,
    );
  }

  late final _nextafterPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double, ffi.Double)>>(
          'nextafter');
  late final _nextafter =
      _nextafterPtr.asFunction<double Function(double, double)>();

  double remainder(
    double _X,
    double _Y,
  ) {
    return _remainder(
      _X,
      _Y,
    );
  }

  late final _remainderPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double, ffi.Double)>>(
          'remainder');
  late final _remainder =
      _remainderPtr.asFunction<double Function(double, double)>();

  double remquo(
    double _X,
    double _Y,
    ffi.Pointer<ffi.Int32> _Z,
  ) {
    return _remquo(
      _X,
      _Y,
      _Z,
    );
  }

  late final _remquoPtr = _lookup<
      ffi.NativeFunction<
          ffi.Double Function(
              ffi.Double, ffi.Double, ffi.Pointer<ffi.Int32>)>>('remquo');
  late final _remquo = _remquoPtr
      .asFunction<double Function(double, double, ffi.Pointer<ffi.Int32>)>();

  double rint(
    double _X,
  ) {
    return _rint(
      _X,
    );
  }

  late final _rintPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double)>>('rint');
  late final _rint = _rintPtr.asFunction<double Function(double)>();

  double round(
    double _X,
  ) {
    return _round(
      _X,
    );
  }

  late final _roundPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double)>>('round');
  late final _round = _roundPtr.asFunction<double Function(double)>();

  double scalbln(
    double _X,
    int _Y,
  ) {
    return _scalbln(
      _X,
      _Y,
    );
  }

  late final _scalblnPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double, ffi.Int64)>>(
          'scalbln');
  late final _scalbln = _scalblnPtr.asFunction<double Function(double, int)>();

  double scalbn(
    double _X,
    int _Y,
  ) {
    return _scalbn(
      _X,
      _Y,
    );
  }

  late final _scalbnPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double, ffi.Int32)>>(
          'scalbn');
  late final _scalbn = _scalbnPtr.asFunction<double Function(double, int)>();

  double tgamma(
    double _X,
  ) {
    return _tgamma(
      _X,
    );
  }

  late final _tgammaPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double)>>('tgamma');
  late final _tgamma = _tgammaPtr.asFunction<double Function(double)>();

  double trunc(
    double _X,
  ) {
    return _trunc(
      _X,
    );
  }

  late final _truncPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double)>>('trunc');
  late final _trunc = _truncPtr.asFunction<double Function(double)>();

  double _j0(
    double _X,
  ) {
    return __j0(
      _X,
    );
  }

  late final __j0Ptr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double)>>('_j0');
  late final __j0 = __j0Ptr.asFunction<double Function(double)>();

  double _j1(
    double _X,
  ) {
    return __j1(
      _X,
    );
  }

  late final __j1Ptr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double)>>('_j1');
  late final __j1 = __j1Ptr.asFunction<double Function(double)>();

  double _jn(
    int _X,
    double _Y,
  ) {
    return __jn(
      _X,
      _Y,
    );
  }

  late final __jnPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Int32, ffi.Double)>>(
          '_jn');
  late final __jn = __jnPtr.asFunction<double Function(int, double)>();

  double _y0(
    double _X,
  ) {
    return __y0(
      _X,
    );
  }

  late final __y0Ptr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double)>>('_y0');
  late final __y0 = __y0Ptr.asFunction<double Function(double)>();

  double _y1(
    double _X,
  ) {
    return __y1(
      _X,
    );
  }

  late final __y1Ptr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double)>>('_y1');
  late final __y1 = __y1Ptr.asFunction<double Function(double)>();

  double _yn(
    int _X,
    double _Y,
  ) {
    return __yn(
      _X,
      _Y,
    );
  }

  late final __ynPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Int32, ffi.Double)>>(
          '_yn');
  late final __yn = __ynPtr.asFunction<double Function(int, double)>();

  double acoshf(
    double _X,
  ) {
    return _acoshf(
      _X,
    );
  }

  late final _acoshfPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float)>>('acoshf');
  late final _acoshf = _acoshfPtr.asFunction<double Function(double)>();

  double asinhf(
    double _X,
  ) {
    return _asinhf(
      _X,
    );
  }

  late final _asinhfPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float)>>('asinhf');
  late final _asinhf = _asinhfPtr.asFunction<double Function(double)>();

  double atanhf(
    double _X,
  ) {
    return _atanhf(
      _X,
    );
  }

  late final _atanhfPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float)>>('atanhf');
  late final _atanhf = _atanhfPtr.asFunction<double Function(double)>();

  double cbrtf(
    double _X,
  ) {
    return _cbrtf(
      _X,
    );
  }

  late final _cbrtfPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float)>>('cbrtf');
  late final _cbrtf = _cbrtfPtr.asFunction<double Function(double)>();

  double _chgsignf(
    double _X,
  ) {
    return __chgsignf(
      _X,
    );
  }

  late final __chgsignfPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float)>>('_chgsignf');
  late final __chgsignf = __chgsignfPtr.asFunction<double Function(double)>();

  double copysignf(
    double _Number,
    double _Sign,
  ) {
    return _copysignf1(
      _Number,
      _Sign,
    );
  }

  late final _copysignfPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float, ffi.Float)>>(
          'copysignf');
  late final _copysignf1 =
      _copysignfPtr.asFunction<double Function(double, double)>();

  double _copysignf(
    double _Number,
    double _Sign,
  ) {
    return __copysignf1(
      _Number,
      _Sign,
    );
  }

  late final __copysignfPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float, ffi.Float)>>(
          '_copysignf');
  late final __copysignf1 =
      __copysignfPtr.asFunction<double Function(double, double)>();

  double erff(
    double _X,
  ) {
    return _erff(
      _X,
    );
  }

  late final _erffPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float)>>('erff');
  late final _erff = _erffPtr.asFunction<double Function(double)>();

  double erfcf(
    double _X,
  ) {
    return _erfcf(
      _X,
    );
  }

  late final _erfcfPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float)>>('erfcf');
  late final _erfcf = _erfcfPtr.asFunction<double Function(double)>();

  double expm1f(
    double _X,
  ) {
    return _expm1f(
      _X,
    );
  }

  late final _expm1fPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float)>>('expm1f');
  late final _expm1f = _expm1fPtr.asFunction<double Function(double)>();

  double exp2f(
    double _X,
  ) {
    return _exp2f(
      _X,
    );
  }

  late final _exp2fPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float)>>('exp2f');
  late final _exp2f = _exp2fPtr.asFunction<double Function(double)>();

  double fdimf(
    double _X,
    double _Y,
  ) {
    return _fdimf(
      _X,
      _Y,
    );
  }

  late final _fdimfPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float, ffi.Float)>>(
          'fdimf');
  late final _fdimf = _fdimfPtr.asFunction<double Function(double, double)>();

  double fmaf(
    double _X,
    double _Y,
    double _Z,
  ) {
    return _fmaf(
      _X,
      _Y,
      _Z,
    );
  }

  late final _fmafPtr = _lookup<
      ffi.NativeFunction<
          ffi.Float Function(ffi.Float, ffi.Float, ffi.Float)>>('fmaf');
  late final _fmaf =
      _fmafPtr.asFunction<double Function(double, double, double)>();

  double fmaxf(
    double _X,
    double _Y,
  ) {
    return _fmaxf(
      _X,
      _Y,
    );
  }

  late final _fmaxfPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float, ffi.Float)>>(
          'fmaxf');
  late final _fmaxf = _fmaxfPtr.asFunction<double Function(double, double)>();

  double fminf(
    double _X,
    double _Y,
  ) {
    return _fminf(
      _X,
      _Y,
    );
  }

  late final _fminfPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float, ffi.Float)>>(
          'fminf');
  late final _fminf = _fminfPtr.asFunction<double Function(double, double)>();

  double _hypotf(
    double _X,
    double _Y,
  ) {
    return __hypotf(
      _X,
      _Y,
    );
  }

  late final __hypotfPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float, ffi.Float)>>(
          '_hypotf');
  late final __hypotf =
      __hypotfPtr.asFunction<double Function(double, double)>();

  int ilogbf(
    double _X,
  ) {
    return _ilogbf(
      _X,
    );
  }

  late final _ilogbfPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Float)>>('ilogbf');
  late final _ilogbf = _ilogbfPtr.asFunction<int Function(double)>();

  double lgammaf(
    double _X,
  ) {
    return _lgammaf(
      _X,
    );
  }

  late final _lgammafPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float)>>('lgammaf');
  late final _lgammaf = _lgammafPtr.asFunction<double Function(double)>();

  int llrintf(
    double _X,
  ) {
    return _llrintf(
      _X,
    );
  }

  late final _llrintfPtr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(ffi.Float)>>('llrintf');
  late final _llrintf = _llrintfPtr.asFunction<int Function(double)>();

  int llroundf(
    double _X,
  ) {
    return _llroundf(
      _X,
    );
  }

  late final _llroundfPtr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(ffi.Float)>>('llroundf');
  late final _llroundf = _llroundfPtr.asFunction<int Function(double)>();

  double log1pf(
    double _X,
  ) {
    return _log1pf(
      _X,
    );
  }

  late final _log1pfPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float)>>('log1pf');
  late final _log1pf = _log1pfPtr.asFunction<double Function(double)>();

  double log2f(
    double _X,
  ) {
    return _log2f(
      _X,
    );
  }

  late final _log2fPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float)>>('log2f');
  late final _log2f = _log2fPtr.asFunction<double Function(double)>();

  double logbf(
    double _X,
  ) {
    return _logbf1(
      _X,
    );
  }

  late final _logbfPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float)>>('logbf');
  late final _logbf1 = _logbfPtr.asFunction<double Function(double)>();

  int lrintf(
    double _X,
  ) {
    return _lrintf(
      _X,
    );
  }

  late final _lrintfPtr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(ffi.Float)>>('lrintf');
  late final _lrintf = _lrintfPtr.asFunction<int Function(double)>();

  int lroundf(
    double _X,
  ) {
    return _lroundf(
      _X,
    );
  }

  late final _lroundfPtr =
      _lookup<ffi.NativeFunction<ffi.Int64 Function(ffi.Float)>>('lroundf');
  late final _lroundf = _lroundfPtr.asFunction<int Function(double)>();

  double nanf(
    ffi.Pointer<ffi.Int8> _X,
  ) {
    return _nanf(
      _X,
    );
  }

  late final _nanfPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Pointer<ffi.Int8>)>>(
          'nanf');
  late final _nanf =
      _nanfPtr.asFunction<double Function(ffi.Pointer<ffi.Int8>)>();

  double nearbyintf(
    double _X,
  ) {
    return _nearbyintf(
      _X,
    );
  }

  late final _nearbyintfPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float)>>('nearbyintf');
  late final _nearbyintf = _nearbyintfPtr.asFunction<double Function(double)>();

  double nextafterf(
    double _X,
    double _Y,
  ) {
    return _nextafterf1(
      _X,
      _Y,
    );
  }

  late final _nextafterfPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float, ffi.Float)>>(
          'nextafterf');
  late final _nextafterf1 =
      _nextafterfPtr.asFunction<double Function(double, double)>();

  double remainderf(
    double _X,
    double _Y,
  ) {
    return _remainderf(
      _X,
      _Y,
    );
  }

  late final _remainderfPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float, ffi.Float)>>(
          'remainderf');
  late final _remainderf =
      _remainderfPtr.asFunction<double Function(double, double)>();

  double remquof(
    double _X,
    double _Y,
    ffi.Pointer<ffi.Int32> _Z,
  ) {
    return _remquof(
      _X,
      _Y,
      _Z,
    );
  }

  late final _remquofPtr = _lookup<
      ffi.NativeFunction<
          ffi.Float Function(
              ffi.Float, ffi.Float, ffi.Pointer<ffi.Int32>)>>('remquof');
  late final _remquof = _remquofPtr
      .asFunction<double Function(double, double, ffi.Pointer<ffi.Int32>)>();

  double rintf(
    double _X,
  ) {
    return _rintf(
      _X,
    );
  }

  late final _rintfPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float)>>('rintf');
  late final _rintf = _rintfPtr.asFunction<double Function(double)>();

  double roundf(
    double _X,
  ) {
    return _roundf(
      _X,
    );
  }

  late final _roundfPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float)>>('roundf');
  late final _roundf = _roundfPtr.asFunction<double Function(double)>();

  double scalblnf(
    double _X,
    int _Y,
  ) {
    return _scalblnf(
      _X,
      _Y,
    );
  }

  late final _scalblnfPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float, ffi.Int64)>>(
          'scalblnf');
  late final _scalblnf =
      _scalblnfPtr.asFunction<double Function(double, int)>();

  double scalbnf(
    double _X,
    int _Y,
  ) {
    return _scalbnf(
      _X,
      _Y,
    );
  }

  late final _scalbnfPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float, ffi.Int32)>>(
          'scalbnf');
  late final _scalbnf = _scalbnfPtr.asFunction<double Function(double, int)>();

  double tgammaf(
    double _X,
  ) {
    return _tgammaf(
      _X,
    );
  }

  late final _tgammafPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float)>>('tgammaf');
  late final _tgammaf = _tgammafPtr.asFunction<double Function(double)>();

  double truncf(
    double _X,
  ) {
    return _truncf(
      _X,
    );
  }

  late final _truncfPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float)>>('truncf');
  late final _truncf = _truncfPtr.asFunction<double Function(double)>();

  double _logbf(
    double _X,
  ) {
    return __logbf(
      _X,
    );
  }

  late final __logbfPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float)>>('_logbf');
  late final __logbf = __logbfPtr.asFunction<double Function(double)>();

  double _nextafterf(
    double _X,
    double _Y,
  ) {
    return __nextafterf(
      _X,
      _Y,
    );
  }

  late final __nextafterfPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float, ffi.Float)>>(
          '_nextafterf');
  late final __nextafterf =
      __nextafterfPtr.asFunction<double Function(double, double)>();

  int _finitef(
    double _X,
  ) {
    return __finitef(
      _X,
    );
  }

  late final __finitefPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Float)>>('_finitef');
  late final __finitef = __finitefPtr.asFunction<int Function(double)>();

  int _isnanf(
    double _X,
  ) {
    return __isnanf(
      _X,
    );
  }

  late final __isnanfPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Float)>>('_isnanf');
  late final __isnanf = __isnanfPtr.asFunction<int Function(double)>();

  int _fpclassf(
    double _X,
  ) {
    return __fpclassf(
      _X,
    );
  }

  late final __fpclassfPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Float)>>('_fpclassf');
  late final __fpclassf = __fpclassfPtr.asFunction<int Function(double)>();

  int _set_FMA3_enable(
    int _Flag,
  ) {
    return __set_FMA3_enable(
      _Flag,
    );
  }

  late final __set_FMA3_enablePtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Int32)>>(
          '_set_FMA3_enable');
  late final __set_FMA3_enable =
      __set_FMA3_enablePtr.asFunction<int Function(int)>();

  int _get_FMA3_enable() {
    return __get_FMA3_enable();
  }

  late final __get_FMA3_enablePtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function()>>('_get_FMA3_enable');
  late final __get_FMA3_enable =
      __get_FMA3_enablePtr.asFunction<int Function()>();

  double acosf(
    double _X,
  ) {
    return _acosf(
      _X,
    );
  }

  late final _acosfPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float)>>('acosf');
  late final _acosf = _acosfPtr.asFunction<double Function(double)>();

  double asinf(
    double _X,
  ) {
    return _asinf(
      _X,
    );
  }

  late final _asinfPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float)>>('asinf');
  late final _asinf = _asinfPtr.asFunction<double Function(double)>();

  double atan2f(
    double _Y,
    double _X,
  ) {
    return _atan2f(
      _Y,
      _X,
    );
  }

  late final _atan2fPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float, ffi.Float)>>(
          'atan2f');
  late final _atan2f = _atan2fPtr.asFunction<double Function(double, double)>();

  double atanf(
    double _X,
  ) {
    return _atanf(
      _X,
    );
  }

  late final _atanfPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float)>>('atanf');
  late final _atanf = _atanfPtr.asFunction<double Function(double)>();

  double ceilf(
    double _X,
  ) {
    return _ceilf(
      _X,
    );
  }

  late final _ceilfPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float)>>('ceilf');
  late final _ceilf = _ceilfPtr.asFunction<double Function(double)>();

  double cosf(
    double _X,
  ) {
    return _cosf(
      _X,
    );
  }

  late final _cosfPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float)>>('cosf');
  late final _cosf = _cosfPtr.asFunction<double Function(double)>();

  double coshf(
    double _X,
  ) {
    return _coshf(
      _X,
    );
  }

  late final _coshfPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float)>>('coshf');
  late final _coshf = _coshfPtr.asFunction<double Function(double)>();

  double expf(
    double _X,
  ) {
    return _expf(
      _X,
    );
  }

  late final _expfPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float)>>('expf');
  late final _expf = _expfPtr.asFunction<double Function(double)>();

  double floorf(
    double _X,
  ) {
    return _floorf(
      _X,
    );
  }

  late final _floorfPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float)>>('floorf');
  late final _floorf = _floorfPtr.asFunction<double Function(double)>();

  double fmodf(
    double _X,
    double _Y,
  ) {
    return _fmodf(
      _X,
      _Y,
    );
  }

  late final _fmodfPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float, ffi.Float)>>(
          'fmodf');
  late final _fmodf = _fmodfPtr.asFunction<double Function(double, double)>();

  double log10f(
    double _X,
  ) {
    return _log10f(
      _X,
    );
  }

  late final _log10fPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float)>>('log10f');
  late final _log10f = _log10fPtr.asFunction<double Function(double)>();

  double logf(
    double _X,
  ) {
    return _logf(
      _X,
    );
  }

  late final _logfPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float)>>('logf');
  late final _logf = _logfPtr.asFunction<double Function(double)>();

  double modff(
    double _X,
    ffi.Pointer<ffi.Float> _Y,
  ) {
    return _modff(
      _X,
      _Y,
    );
  }

  late final _modffPtr = _lookup<
      ffi.NativeFunction<
          ffi.Float Function(ffi.Float, ffi.Pointer<ffi.Float>)>>('modff');
  late final _modff =
      _modffPtr.asFunction<double Function(double, ffi.Pointer<ffi.Float>)>();

  double powf(
    double _X,
    double _Y,
  ) {
    return _powf(
      _X,
      _Y,
    );
  }

  late final _powfPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float, ffi.Float)>>(
          'powf');
  late final _powf = _powfPtr.asFunction<double Function(double, double)>();

  double sinf(
    double _X,
  ) {
    return _sinf(
      _X,
    );
  }

  late final _sinfPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float)>>('sinf');
  late final _sinf = _sinfPtr.asFunction<double Function(double)>();

  double sinhf(
    double _X,
  ) {
    return _sinhf(
      _X,
    );
  }

  late final _sinhfPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float)>>('sinhf');
  late final _sinhf = _sinhfPtr.asFunction<double Function(double)>();

  double sqrtf(
    double _X,
  ) {
    return _sqrtf(
      _X,
    );
  }

  late final _sqrtfPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float)>>('sqrtf');
  late final _sqrtf = _sqrtfPtr.asFunction<double Function(double)>();

  double tanf(
    double _X,
  ) {
    return _tanf(
      _X,
    );
  }

  late final _tanfPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float)>>('tanf');
  late final _tanf = _tanfPtr.asFunction<double Function(double)>();

  double tanhf(
    double _X,
  ) {
    return _tanhf(
      _X,
    );
  }

  late final _tanhfPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Float)>>('tanhf');
  late final _tanhf = _tanhfPtr.asFunction<double Function(double)>();

  late final ffi.Pointer<ffi.Double> _HUGE1 = _lookup<ffi.Double>('HUGE');

  double get HUGE => _HUGE1.value;

  set HUGE(double value) => _HUGE1.value = value;

  double j0(
    double _X,
  ) {
    return _j01(
      _X,
    );
  }

  late final _j0Ptr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double)>>('j0');
  late final _j01 = _j0Ptr.asFunction<double Function(double)>();

  double j1(
    double _X,
  ) {
    return _j11(
      _X,
    );
  }

  late final _j1Ptr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double)>>('j1');
  late final _j11 = _j1Ptr.asFunction<double Function(double)>();

  double jn(
    int _X,
    double _Y,
  ) {
    return _jn1(
      _X,
      _Y,
    );
  }

  late final _jnPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Int32, ffi.Double)>>(
          'jn');
  late final _jn1 = _jnPtr.asFunction<double Function(int, double)>();

  double y0(
    double _X,
  ) {
    return _y01(
      _X,
    );
  }

  late final _y0Ptr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double)>>('y0');
  late final _y01 = _y0Ptr.asFunction<double Function(double)>();

  double y1(
    double _X,
  ) {
    return _y11(
      _X,
    );
  }

  late final _y1Ptr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Double)>>('y1');
  late final _y11 = _y1Ptr.asFunction<double Function(double)>();

  double yn(
    int _X,
    double _Y,
  ) {
    return _yn1(
      _X,
      _Y,
    );
  }

  late final _ynPtr =
      _lookup<ffi.NativeFunction<ffi.Double Function(ffi.Int32, ffi.Double)>>(
          'yn');
  late final _yn1 = _ynPtr.asFunction<double Function(int, double)>();

  late final ffi.Pointer<ffi.Int32> ___current_exit_return_mode =
      _lookup<ffi.Int32>('__current_exit_return_mode');

  int get __current_exit_return_mode => ___current_exit_return_mode.value;

  set __current_exit_return_mode(int value) =>
      ___current_exit_return_mode.value = value;

  bool __vcrt_initialize() {
    return ___vcrt_initialize() != 0;
  }

  late final ___vcrt_initializePtr =
      _lookup<ffi.NativeFunction<ffi.Uint8 Function()>>('__vcrt_initialize');
  late final ___vcrt_initialize =
      ___vcrt_initializePtr.asFunction<int Function()>();

  bool __vcrt_uninitialize(
    bool _Terminating,
  ) {
    return ___vcrt_uninitialize(
          _Terminating ? 1 : 0,
        ) !=
        0;
  }

  late final ___vcrt_uninitializePtr =
      _lookup<ffi.NativeFunction<ffi.Uint8 Function(ffi.Uint8)>>(
          '__vcrt_uninitialize');
  late final ___vcrt_uninitialize =
      ___vcrt_uninitializePtr.asFunction<int Function(int)>();

  bool __vcrt_uninitialize_critical() {
    return ___vcrt_uninitialize_critical() != 0;
  }

  late final ___vcrt_uninitialize_criticalPtr =
      _lookup<ffi.NativeFunction<ffi.Uint8 Function()>>(
          '__vcrt_uninitialize_critical');
  late final ___vcrt_uninitialize_critical =
      ___vcrt_uninitialize_criticalPtr.asFunction<int Function()>();

  bool __vcrt_thread_attach() {
    return ___vcrt_thread_attach() != 0;
  }

  late final ___vcrt_thread_attachPtr =
      _lookup<ffi.NativeFunction<ffi.Uint8 Function()>>('__vcrt_thread_attach');
  late final ___vcrt_thread_attach =
      ___vcrt_thread_attachPtr.asFunction<int Function()>();

  bool __vcrt_thread_detach() {
    return ___vcrt_thread_detach() != 0;
  }

  late final ___vcrt_thread_detachPtr =
      _lookup<ffi.NativeFunction<ffi.Uint8 Function()>>('__vcrt_thread_detach');
  late final ___vcrt_thread_detach =
      ___vcrt_thread_detachPtr.asFunction<int Function()>();

  int __isa_available_init() {
    return ___isa_available_init();
  }

  late final ___isa_available_initPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function()>>('__isa_available_init');
  late final ___isa_available_init =
      ___isa_available_initPtr.asFunction<int Function()>();

  int _get_startup_argv_mode() {
    return __get_startup_argv_mode();
  }

  late final __get_startup_argv_modePtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function()>>(
          '_get_startup_argv_mode');
  late final __get_startup_argv_mode =
      __get_startup_argv_modePtr.asFunction<int Function()>();

  int _seh_filter_dll(
    int _ExceptionNum,
    ffi.Pointer<EXCEPTION_POINTERS> _ExceptionPtr,
  ) {
    return __seh_filter_dll(
      _ExceptionNum,
      _ExceptionPtr,
    );
  }

  late final __seh_filter_dllPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Uint64, ffi.Pointer<EXCEPTION_POINTERS>)>>('_seh_filter_dll');
  late final __seh_filter_dll = __seh_filter_dllPtr
      .asFunction<int Function(int, ffi.Pointer<EXCEPTION_POINTERS>)>();

  int _seh_filter_exe(
    int _ExceptionNum,
    ffi.Pointer<EXCEPTION_POINTERS> _ExceptionPtr,
  ) {
    return __seh_filter_exe(
      _ExceptionNum,
      _ExceptionPtr,
    );
  }

  late final __seh_filter_exePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Uint64, ffi.Pointer<EXCEPTION_POINTERS>)>>('_seh_filter_exe');
  late final __seh_filter_exe = __seh_filter_exePtr
      .asFunction<int Function(int, ffi.Pointer<EXCEPTION_POINTERS>)>();

  int _query_app_type() {
    return __query_app_type();
  }

  late final __query_app_typePtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function()>>('_query_app_type');
  late final __query_app_type =
      __query_app_typePtr.asFunction<int Function()>();

  void _set_app_type(
    int _Type,
  ) {
    return __set_app_type(
      _Type,
    );
  }

  late final __set_app_typePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Int32)>>(
          '_set_app_type');
  late final __set_app_type =
      __set_app_typePtr.asFunction<void Function(int)>();

  void __setusermatherr(
    _UserMathErrorFunctionPointer _UserMathErrorFunction,
  ) {
    return ___setusermatherr(
      _UserMathErrorFunction,
    );
  }

  late final ___setusermatherrPtr = _lookup<
          ffi.NativeFunction<ffi.Void Function(_UserMathErrorFunctionPointer)>>(
      '__setusermatherr');
  late final ___setusermatherr = ___setusermatherrPtr
      .asFunction<void Function(_UserMathErrorFunctionPointer)>();

  int _is_c_termination_complete() {
    return __is_c_termination_complete();
  }

  late final __is_c_termination_completePtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function()>>(
          '_is_c_termination_complete');
  late final __is_c_termination_complete =
      __is_c_termination_completePtr.asFunction<int Function()>();

  int _configure_narrow_argv(
    int mode,
  ) {
    return __configure_narrow_argv(
      mode,
    );
  }

  late final __configure_narrow_argvPtr =
      _lookup<ffi.NativeFunction<errno_t Function(ffi.Int32)>>(
          '_configure_narrow_argv');
  late final __configure_narrow_argv =
      __configure_narrow_argvPtr.asFunction<int Function(int)>();

  int _configure_wide_argv(
    int mode,
  ) {
    return __configure_wide_argv(
      mode,
    );
  }

  late final __configure_wide_argvPtr =
      _lookup<ffi.NativeFunction<errno_t Function(ffi.Int32)>>(
          '_configure_wide_argv');
  late final __configure_wide_argv =
      __configure_wide_argvPtr.asFunction<int Function(int)>();

  int _initialize_narrow_environment() {
    return __initialize_narrow_environment();
  }

  late final __initialize_narrow_environmentPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function()>>(
          '_initialize_narrow_environment');
  late final __initialize_narrow_environment =
      __initialize_narrow_environmentPtr.asFunction<int Function()>();

  int _initialize_wide_environment() {
    return __initialize_wide_environment();
  }

  late final __initialize_wide_environmentPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function()>>(
          '_initialize_wide_environment');
  late final __initialize_wide_environment =
      __initialize_wide_environmentPtr.asFunction<int Function()>();

  ffi.Pointer<ffi.Pointer<ffi.Int8>> _get_initial_narrow_environment() {
    return __get_initial_narrow_environment();
  }

  late final __get_initial_narrow_environmentPtr = _lookup<
          ffi.NativeFunction<ffi.Pointer<ffi.Pointer<ffi.Int8>> Function()>>(
      '_get_initial_narrow_environment');
  late final __get_initial_narrow_environment =
      __get_initial_narrow_environmentPtr
          .asFunction<ffi.Pointer<ffi.Pointer<ffi.Int8>> Function()>();

  ffi.Pointer<ffi.Pointer<wchar_t>> _get_initial_wide_environment() {
    return __get_initial_wide_environment();
  }

  late final __get_initial_wide_environmentPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Pointer<wchar_t>> Function()>>(
          '_get_initial_wide_environment');
  late final __get_initial_wide_environment = __get_initial_wide_environmentPtr
      .asFunction<ffi.Pointer<ffi.Pointer<wchar_t>> Function()>();

  ffi.Pointer<ffi.Int8> _get_narrow_winmain_command_line() {
    return __get_narrow_winmain_command_line();
  }

  late final __get_narrow_winmain_command_linePtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Int8> Function()>>(
          '_get_narrow_winmain_command_line');
  late final __get_narrow_winmain_command_line =
      __get_narrow_winmain_command_linePtr
          .asFunction<ffi.Pointer<ffi.Int8> Function()>();

  ffi.Pointer<wchar_t> _get_wide_winmain_command_line() {
    return __get_wide_winmain_command_line();
  }

  late final __get_wide_winmain_command_linePtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<wchar_t> Function()>>(
          '_get_wide_winmain_command_line');
  late final __get_wide_winmain_command_line =
      __get_wide_winmain_command_linePtr
          .asFunction<ffi.Pointer<wchar_t> Function()>();

  ffi.Pointer<ffi.Pointer<ffi.Int8>> __p__acmdln() {
    return ___p__acmdln();
  }

  late final ___p__acmdlnPtr = _lookup<
          ffi.NativeFunction<ffi.Pointer<ffi.Pointer<ffi.Int8>> Function()>>(
      '__p__acmdln');
  late final ___p__acmdln = ___p__acmdlnPtr
      .asFunction<ffi.Pointer<ffi.Pointer<ffi.Int8>> Function()>();

  ffi.Pointer<ffi.Pointer<wchar_t>> __p__wcmdln() {
    return ___p__wcmdln();
  }

  late final ___p__wcmdlnPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Pointer<wchar_t>> Function()>>(
          '__p__wcmdln');
  late final ___p__wcmdln = ___p__wcmdlnPtr
      .asFunction<ffi.Pointer<ffi.Pointer<wchar_t>> Function()>();

  void _initterm(
    ffi.Pointer<_PVFV> _First,
    ffi.Pointer<_PVFV> _Last,
  ) {
    return __initterm(
      _First,
      _Last,
    );
  }

  late final __inittermPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<_PVFV>, ffi.Pointer<_PVFV>)>>('_initterm');
  late final __initterm = __inittermPtr
      .asFunction<void Function(ffi.Pointer<_PVFV>, ffi.Pointer<_PVFV>)>();

  int _initterm_e(
    ffi.Pointer<_PIFV> _First,
    ffi.Pointer<_PIFV> _Last,
  ) {
    return __initterm_e(
      _First,
      _Last,
    );
  }

  late final __initterm_ePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<_PIFV>, ffi.Pointer<_PIFV>)>>('_initterm_e');
  late final __initterm_e = __initterm_ePtr
      .asFunction<int Function(ffi.Pointer<_PIFV>, ffi.Pointer<_PIFV>)>();

  int _initialize_onexit_table(
    ffi.Pointer<onexit_table_t> _Table,
  ) {
    return __initialize_onexit_table(
      _Table,
    );
  }

  late final __initialize_onexit_tablePtr = _lookup<
          ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<onexit_table_t>)>>(
      '_initialize_onexit_table');
  late final __initialize_onexit_table = __initialize_onexit_tablePtr
      .asFunction<int Function(ffi.Pointer<onexit_table_t>)>();

  int _register_onexit_function(
    ffi.Pointer<onexit_table_t> _Table,
    _onexit_t _Function,
  ) {
    return __register_onexit_function(
      _Table,
      _Function,
    );
  }

  late final __register_onexit_functionPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<onexit_table_t>,
              _onexit_t)>>('_register_onexit_function');
  late final __register_onexit_function = __register_onexit_functionPtr
      .asFunction<int Function(ffi.Pointer<onexit_table_t>, _onexit_t)>();

  int _execute_onexit_table(
    ffi.Pointer<onexit_table_t> _Table,
  ) {
    return __execute_onexit_table(
      _Table,
    );
  }

  late final __execute_onexit_tablePtr = _lookup<
          ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<onexit_table_t>)>>(
      '_execute_onexit_table');
  late final __execute_onexit_table = __execute_onexit_tablePtr
      .asFunction<int Function(ffi.Pointer<onexit_table_t>)>();

  int _crt_atexit(
    _PVFV _Function,
  ) {
    return __crt_atexit(
      _Function,
    );
  }

  late final __crt_atexitPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(_PVFV)>>('_crt_atexit');
  late final __crt_atexit = __crt_atexitPtr.asFunction<int Function(_PVFV)>();

  int _crt_at_quick_exit(
    _PVFV _Function,
  ) {
    return __crt_at_quick_exit(
      _Function,
    );
  }

  late final __crt_at_quick_exitPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(_PVFV)>>(
          '_crt_at_quick_exit');
  late final __crt_at_quick_exit =
      __crt_at_quick_exitPtr.asFunction<int Function(_PVFV)>();

  bool __acrt_initialize() {
    return ___acrt_initialize() != 0;
  }

  late final ___acrt_initializePtr =
      _lookup<ffi.NativeFunction<ffi.Uint8 Function()>>('__acrt_initialize');
  late final ___acrt_initialize =
      ___acrt_initializePtr.asFunction<int Function()>();

  bool __acrt_uninitialize(
    bool _Terminating,
  ) {
    return ___acrt_uninitialize(
          _Terminating ? 1 : 0,
        ) !=
        0;
  }

  late final ___acrt_uninitializePtr =
      _lookup<ffi.NativeFunction<ffi.Uint8 Function(ffi.Uint8)>>(
          '__acrt_uninitialize');
  late final ___acrt_uninitialize =
      ___acrt_uninitializePtr.asFunction<int Function(int)>();

  bool __acrt_uninitialize_critical(
    bool _Terminating,
  ) {
    return ___acrt_uninitialize_critical(
          _Terminating ? 1 : 0,
        ) !=
        0;
  }

  late final ___acrt_uninitialize_criticalPtr =
      _lookup<ffi.NativeFunction<ffi.Uint8 Function(ffi.Uint8)>>(
          '__acrt_uninitialize_critical');
  late final ___acrt_uninitialize_critical =
      ___acrt_uninitialize_criticalPtr.asFunction<int Function(int)>();

  bool __acrt_thread_attach() {
    return ___acrt_thread_attach() != 0;
  }

  late final ___acrt_thread_attachPtr =
      _lookup<ffi.NativeFunction<ffi.Uint8 Function()>>('__acrt_thread_attach');
  late final ___acrt_thread_attach =
      ___acrt_thread_attachPtr.asFunction<int Function()>();

  bool __acrt_thread_detach() {
    return ___acrt_thread_detach() != 0;
  }

  late final ___acrt_thread_detachPtr =
      _lookup<ffi.NativeFunction<ffi.Uint8 Function()>>('__acrt_thread_detach');
  late final ___acrt_thread_detach =
      ___acrt_thread_detachPtr.asFunction<int Function()>();

  int _wexecl(
    ffi.Pointer<wchar_t> _FileName,
    ffi.Pointer<wchar_t> _ArgList,
  ) {
    return __wexecl(
      _FileName,
      _ArgList,
    );
  }

  late final __wexeclPtr = _lookup<
      ffi.NativeFunction<
          ffi.IntPtr Function(
              ffi.Pointer<wchar_t>, ffi.Pointer<wchar_t>)>>('_wexecl');
  late final __wexecl = __wexeclPtr
      .asFunction<int Function(ffi.Pointer<wchar_t>, ffi.Pointer<wchar_t>)>();

  int _wexecle(
    ffi.Pointer<wchar_t> _FileName,
    ffi.Pointer<wchar_t> _ArgList,
  ) {
    return __wexecle(
      _FileName,
      _ArgList,
    );
  }

  late final __wexeclePtr = _lookup<
      ffi.NativeFunction<
          ffi.IntPtr Function(
              ffi.Pointer<wchar_t>, ffi.Pointer<wchar_t>)>>('_wexecle');
  late final __wexecle = __wexeclePtr
      .asFunction<int Function(ffi.Pointer<wchar_t>, ffi.Pointer<wchar_t>)>();

  int _wexeclp(
    ffi.Pointer<wchar_t> _FileName,
    ffi.Pointer<wchar_t> _ArgList,
  ) {
    return __wexeclp(
      _FileName,
      _ArgList,
    );
  }

  late final __wexeclpPtr = _lookup<
      ffi.NativeFunction<
          ffi.IntPtr Function(
              ffi.Pointer<wchar_t>, ffi.Pointer<wchar_t>)>>('_wexeclp');
  late final __wexeclp = __wexeclpPtr
      .asFunction<int Function(ffi.Pointer<wchar_t>, ffi.Pointer<wchar_t>)>();

  int _wexeclpe(
    ffi.Pointer<wchar_t> _FileName,
    ffi.Pointer<wchar_t> _ArgList,
  ) {
    return __wexeclpe(
      _FileName,
      _ArgList,
    );
  }

  late final __wexeclpePtr = _lookup<
      ffi.NativeFunction<
          ffi.IntPtr Function(
              ffi.Pointer<wchar_t>, ffi.Pointer<wchar_t>)>>('_wexeclpe');
  late final __wexeclpe = __wexeclpePtr
      .asFunction<int Function(ffi.Pointer<wchar_t>, ffi.Pointer<wchar_t>)>();

  int _wexecv(
    ffi.Pointer<wchar_t> _FileName,
    ffi.Pointer<ffi.Pointer<wchar_t>> _ArgList,
  ) {
    return __wexecv(
      _FileName,
      _ArgList,
    );
  }

  late final __wexecvPtr = _lookup<
      ffi.NativeFunction<
          ffi.IntPtr Function(ffi.Pointer<wchar_t>,
              ffi.Pointer<ffi.Pointer<wchar_t>>)>>('_wexecv');
  late final __wexecv = __wexecvPtr.asFunction<
      int Function(ffi.Pointer<wchar_t>, ffi.Pointer<ffi.Pointer<wchar_t>>)>();

  int _wexecve(
    ffi.Pointer<wchar_t> _FileName,
    ffi.Pointer<ffi.Pointer<wchar_t>> _ArgList,
    ffi.Pointer<ffi.Pointer<wchar_t>> _Env,
  ) {
    return __wexecve(
      _FileName,
      _ArgList,
      _Env,
    );
  }

  late final __wexecvePtr = _lookup<
      ffi.NativeFunction<
          ffi.IntPtr Function(
              ffi.Pointer<wchar_t>,
              ffi.Pointer<ffi.Pointer<wchar_t>>,
              ffi.Pointer<ffi.Pointer<wchar_t>>)>>('_wexecve');
  late final __wexecve = __wexecvePtr.asFunction<
      int Function(ffi.Pointer<wchar_t>, ffi.Pointer<ffi.Pointer<wchar_t>>,
          ffi.Pointer<ffi.Pointer<wchar_t>>)>();

  int _wexecvp(
    ffi.Pointer<wchar_t> _FileName,
    ffi.Pointer<ffi.Pointer<wchar_t>> _ArgList,
  ) {
    return __wexecvp(
      _FileName,
      _ArgList,
    );
  }

  late final __wexecvpPtr = _lookup<
      ffi.NativeFunction<
          ffi.IntPtr Function(ffi.Pointer<wchar_t>,
              ffi.Pointer<ffi.Pointer<wchar_t>>)>>('_wexecvp');
  late final __wexecvp = __wexecvpPtr.asFunction<
      int Function(ffi.Pointer<wchar_t>, ffi.Pointer<ffi.Pointer<wchar_t>>)>();

  int _wexecvpe(
    ffi.Pointer<wchar_t> _FileName,
    ffi.Pointer<ffi.Pointer<wchar_t>> _ArgList,
    ffi.Pointer<ffi.Pointer<wchar_t>> _Env,
  ) {
    return __wexecvpe(
      _FileName,
      _ArgList,
      _Env,
    );
  }

  late final __wexecvpePtr = _lookup<
      ffi.NativeFunction<
          ffi.IntPtr Function(
              ffi.Pointer<wchar_t>,
              ffi.Pointer<ffi.Pointer<wchar_t>>,
              ffi.Pointer<ffi.Pointer<wchar_t>>)>>('_wexecvpe');
  late final __wexecvpe = __wexecvpePtr.asFunction<
      int Function(ffi.Pointer<wchar_t>, ffi.Pointer<ffi.Pointer<wchar_t>>,
          ffi.Pointer<ffi.Pointer<wchar_t>>)>();

  int _wspawnl(
    int _Mode,
    ffi.Pointer<wchar_t> _FileName,
    ffi.Pointer<wchar_t> _ArgList,
  ) {
    return __wspawnl(
      _Mode,
      _FileName,
      _ArgList,
    );
  }

  late final __wspawnlPtr = _lookup<
      ffi.NativeFunction<
          ffi.IntPtr Function(ffi.Int32, ffi.Pointer<wchar_t>,
              ffi.Pointer<wchar_t>)>>('_wspawnl');
  late final __wspawnl = __wspawnlPtr.asFunction<
      int Function(int, ffi.Pointer<wchar_t>, ffi.Pointer<wchar_t>)>();

  int _wspawnle(
    int _Mode,
    ffi.Pointer<wchar_t> _FileName,
    ffi.Pointer<wchar_t> _ArgList,
  ) {
    return __wspawnle(
      _Mode,
      _FileName,
      _ArgList,
    );
  }

  late final __wspawnlePtr = _lookup<
      ffi.NativeFunction<
          ffi.IntPtr Function(ffi.Int32, ffi.Pointer<wchar_t>,
              ffi.Pointer<wchar_t>)>>('_wspawnle');
  late final __wspawnle = __wspawnlePtr.asFunction<
      int Function(int, ffi.Pointer<wchar_t>, ffi.Pointer<wchar_t>)>();

  int _wspawnlp(
    int _Mode,
    ffi.Pointer<wchar_t> _FileName,
    ffi.Pointer<wchar_t> _ArgList,
  ) {
    return __wspawnlp(
      _Mode,
      _FileName,
      _ArgList,
    );
  }

  late final __wspawnlpPtr = _lookup<
      ffi.NativeFunction<
          ffi.IntPtr Function(ffi.Int32, ffi.Pointer<wchar_t>,
              ffi.Pointer<wchar_t>)>>('_wspawnlp');
  late final __wspawnlp = __wspawnlpPtr.asFunction<
      int Function(int, ffi.Pointer<wchar_t>, ffi.Pointer<wchar_t>)>();

  int _wspawnlpe(
    int _Mode,
    ffi.Pointer<wchar_t> _FileName,
    ffi.Pointer<wchar_t> _ArgList,
  ) {
    return __wspawnlpe(
      _Mode,
      _FileName,
      _ArgList,
    );
  }

  late final __wspawnlpePtr = _lookup<
      ffi.NativeFunction<
          ffi.IntPtr Function(ffi.Int32, ffi.Pointer<wchar_t>,
              ffi.Pointer<wchar_t>)>>('_wspawnlpe');
  late final __wspawnlpe = __wspawnlpePtr.asFunction<
      int Function(int, ffi.Pointer<wchar_t>, ffi.Pointer<wchar_t>)>();

  int _wspawnv(
    int _Mode,
    ffi.Pointer<wchar_t> _FileName,
    ffi.Pointer<ffi.Pointer<wchar_t>> _ArgList,
  ) {
    return __wspawnv(
      _Mode,
      _FileName,
      _ArgList,
    );
  }

  late final __wspawnvPtr = _lookup<
      ffi.NativeFunction<
          ffi.IntPtr Function(ffi.Int32, ffi.Pointer<wchar_t>,
              ffi.Pointer<ffi.Pointer<wchar_t>>)>>('_wspawnv');
  late final __wspawnv = __wspawnvPtr.asFunction<
      int Function(
          int, ffi.Pointer<wchar_t>, ffi.Pointer<ffi.Pointer<wchar_t>>)>();

  int _wspawnve(
    int _Mode,
    ffi.Pointer<wchar_t> _FileName,
    ffi.Pointer<ffi.Pointer<wchar_t>> _ArgList,
    ffi.Pointer<ffi.Pointer<wchar_t>> _Env,
  ) {
    return __wspawnve(
      _Mode,
      _FileName,
      _ArgList,
      _Env,
    );
  }

  late final __wspawnvePtr = _lookup<
      ffi.NativeFunction<
          ffi.IntPtr Function(
              ffi.Int32,
              ffi.Pointer<wchar_t>,
              ffi.Pointer<ffi.Pointer<wchar_t>>,
              ffi.Pointer<ffi.Pointer<wchar_t>>)>>('_wspawnve');
  late final __wspawnve = __wspawnvePtr.asFunction<
      int Function(int, ffi.Pointer<wchar_t>, ffi.Pointer<ffi.Pointer<wchar_t>>,
          ffi.Pointer<ffi.Pointer<wchar_t>>)>();

  int _wspawnvp(
    int _Mode,
    ffi.Pointer<wchar_t> _FileName,
    ffi.Pointer<ffi.Pointer<wchar_t>> _ArgList,
  ) {
    return __wspawnvp(
      _Mode,
      _FileName,
      _ArgList,
    );
  }

  late final __wspawnvpPtr = _lookup<
      ffi.NativeFunction<
          ffi.IntPtr Function(ffi.Int32, ffi.Pointer<wchar_t>,
              ffi.Pointer<ffi.Pointer<wchar_t>>)>>('_wspawnvp');
  late final __wspawnvp = __wspawnvpPtr.asFunction<
      int Function(
          int, ffi.Pointer<wchar_t>, ffi.Pointer<ffi.Pointer<wchar_t>>)>();

  int _wspawnvpe(
    int _Mode,
    ffi.Pointer<wchar_t> _FileName,
    ffi.Pointer<ffi.Pointer<wchar_t>> _ArgList,
    ffi.Pointer<ffi.Pointer<wchar_t>> _Env,
  ) {
    return __wspawnvpe(
      _Mode,
      _FileName,
      _ArgList,
      _Env,
    );
  }

  late final __wspawnvpePtr = _lookup<
      ffi.NativeFunction<
          ffi.IntPtr Function(
              ffi.Int32,
              ffi.Pointer<wchar_t>,
              ffi.Pointer<ffi.Pointer<wchar_t>>,
              ffi.Pointer<ffi.Pointer<wchar_t>>)>>('_wspawnvpe');
  late final __wspawnvpe = __wspawnvpePtr.asFunction<
      int Function(int, ffi.Pointer<wchar_t>, ffi.Pointer<ffi.Pointer<wchar_t>>,
          ffi.Pointer<ffi.Pointer<wchar_t>>)>();

  int _wsystem(
    ffi.Pointer<wchar_t> _Command,
  ) {
    return __wsystem(
      _Command,
    );
  }

  late final __wsystemPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<wchar_t>)>>(
          '_wsystem');
  late final __wsystem =
      __wsystemPtr.asFunction<int Function(ffi.Pointer<wchar_t>)>();

  void exit(
    int _Code,
  ) {
    return _exit1(
      _Code,
    );
  }

  late final _exitPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Int32)>>('exit');
  late final _exit1 = _exitPtr.asFunction<void Function(int)>();

  void _exit(
    int _Code,
  ) {
    return __exit(
      _Code,
    );
  }

  late final __exitPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Int32)>>('_exit');
  late final __exit = __exitPtr.asFunction<void Function(int)>();

  void _Exit(
    int _Code,
  ) {
    return __Exit(
      _Code,
    );
  }

  late final __ExitPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Int32)>>('_Exit');
  late final __Exit = __ExitPtr.asFunction<void Function(int)>();

  void quick_exit(
    int _Code,
  ) {
    return _quick_exit(
      _Code,
    );
  }

  late final _quick_exitPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Int32)>>('quick_exit');
  late final _quick_exit = _quick_exitPtr.asFunction<void Function(int)>();

  void abort() {
    return _abort();
  }

  late final _abortPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('abort');
  late final _abort = _abortPtr.asFunction<void Function()>();

  int system(
    ffi.Pointer<ffi.Int8> _Command,
  ) {
    return _system(
      _Command,
    );
  }

  late final _systemPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<ffi.Int8>)>>(
          'system');
  late final _system =
      _systemPtr.asFunction<int Function(ffi.Pointer<ffi.Int8>)>();

  void _cexit() {
    return __cexit();
  }

  late final __cexitPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('_cexit');
  late final __cexit = __cexitPtr.asFunction<void Function()>();

  void _c_exit() {
    return __c_exit();
  }

  late final __c_exitPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('_c_exit');
  late final __c_exit = __c_exitPtr.asFunction<void Function()>();

  void _register_thread_local_exe_atexit_callback(
    _tls_callback_type _Callback,
  ) {
    return __register_thread_local_exe_atexit_callback(
      _Callback,
    );
  }

  late final __register_thread_local_exe_atexit_callbackPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(_tls_callback_type)>>(
          '_register_thread_local_exe_atexit_callback');
  late final __register_thread_local_exe_atexit_callback =
      __register_thread_local_exe_atexit_callbackPtr
          .asFunction<void Function(_tls_callback_type)>();

  int _beginthread(
    _beginthread_proc_type _StartAddress,
    int _StackSize,
    ffi.Pointer<ffi.Void> _ArgList,
  ) {
    return __beginthread(
      _StartAddress,
      _StackSize,
      _ArgList,
    );
  }

  late final __beginthreadPtr = _lookup<
      ffi.NativeFunction<
          uintptr_t Function(_beginthread_proc_type, ffi.Uint32,
              ffi.Pointer<ffi.Void>)>>('_beginthread');
  late final __beginthread = __beginthreadPtr.asFunction<
      int Function(_beginthread_proc_type, int, ffi.Pointer<ffi.Void>)>();

  void _endthread() {
    return __endthread();
  }

  late final __endthreadPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('_endthread');
  late final __endthread = __endthreadPtr.asFunction<void Function()>();

  int _beginthreadex(
    ffi.Pointer<ffi.Void> _Security,
    int _StackSize,
    _beginthreadex_proc_type _StartAddress,
    ffi.Pointer<ffi.Void> _ArgList,
    int _InitFlag,
    ffi.Pointer<ffi.Uint32> _ThrdAddr,
  ) {
    return __beginthreadex(
      _Security,
      _StackSize,
      _StartAddress,
      _ArgList,
      _InitFlag,
      _ThrdAddr,
    );
  }

  late final __beginthreadexPtr = _lookup<
      ffi.NativeFunction<
          uintptr_t Function(
              ffi.Pointer<ffi.Void>,
              ffi.Uint32,
              _beginthreadex_proc_type,
              ffi.Pointer<ffi.Void>,
              ffi.Uint32,
              ffi.Pointer<ffi.Uint32>)>>('_beginthreadex');
  late final __beginthreadex = __beginthreadexPtr.asFunction<
      int Function(ffi.Pointer<ffi.Void>, int, _beginthreadex_proc_type,
          ffi.Pointer<ffi.Void>, int, ffi.Pointer<ffi.Uint32>)>();

  void _endthreadex(
    int _ReturnCode,
  ) {
    return __endthreadex(
      _ReturnCode,
    );
  }

  late final __endthreadexPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Uint32)>>(
          '_endthreadex');
  late final __endthreadex = __endthreadexPtr.asFunction<void Function(int)>();

  int _getpid() {
    return __getpid();
  }

  late final __getpidPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function()>>('_getpid');
  late final __getpid = __getpidPtr.asFunction<int Function()>();

  int _cwait(
    ffi.Pointer<ffi.Int32> _TermStat,
    int _ProcHandle,
    int _Action,
  ) {
    return __cwait(
      _TermStat,
      _ProcHandle,
      _Action,
    );
  }

  late final __cwaitPtr = _lookup<
      ffi.NativeFunction<
          ffi.IntPtr Function(
              ffi.Pointer<ffi.Int32>, ffi.IntPtr, ffi.Int32)>>('_cwait');
  late final __cwait =
      __cwaitPtr.asFunction<int Function(ffi.Pointer<ffi.Int32>, int, int)>();

  int _execl(
    ffi.Pointer<ffi.Int8> _FileName,
    ffi.Pointer<ffi.Int8> _Arguments,
  ) {
    return __execl(
      _FileName,
      _Arguments,
    );
  }

  late final __execlPtr = _lookup<
      ffi.NativeFunction<
          ffi.IntPtr Function(
              ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Int8>)>>('_execl');
  late final __execl = __execlPtr
      .asFunction<int Function(ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Int8>)>();

  int _execle(
    ffi.Pointer<ffi.Int8> _FileName,
    ffi.Pointer<ffi.Int8> _Arguments,
  ) {
    return __execle(
      _FileName,
      _Arguments,
    );
  }

  late final __execlePtr = _lookup<
      ffi.NativeFunction<
          ffi.IntPtr Function(
              ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Int8>)>>('_execle');
  late final __execle = __execlePtr
      .asFunction<int Function(ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Int8>)>();

  int _execlp(
    ffi.Pointer<ffi.Int8> _FileName,
    ffi.Pointer<ffi.Int8> _Arguments,
  ) {
    return __execlp(
      _FileName,
      _Arguments,
    );
  }

  late final __execlpPtr = _lookup<
      ffi.NativeFunction<
          ffi.IntPtr Function(
              ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Int8>)>>('_execlp');
  late final __execlp = __execlpPtr
      .asFunction<int Function(ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Int8>)>();

  int _execlpe(
    ffi.Pointer<ffi.Int8> _FileName,
    ffi.Pointer<ffi.Int8> _Arguments,
  ) {
    return __execlpe(
      _FileName,
      _Arguments,
    );
  }

  late final __execlpePtr = _lookup<
      ffi.NativeFunction<
          ffi.IntPtr Function(
              ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Int8>)>>('_execlpe');
  late final __execlpe = __execlpePtr
      .asFunction<int Function(ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Int8>)>();

  int _execv(
    ffi.Pointer<ffi.Int8> _FileName,
    ffi.Pointer<ffi.Pointer<ffi.Int8>> _Arguments,
  ) {
    return __execv(
      _FileName,
      _Arguments,
    );
  }

  late final __execvPtr = _lookup<
      ffi.NativeFunction<
          ffi.IntPtr Function(ffi.Pointer<ffi.Int8>,
              ffi.Pointer<ffi.Pointer<ffi.Int8>>)>>('_execv');
  late final __execv = __execvPtr.asFunction<
      int Function(
          ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Pointer<ffi.Int8>>)>();

  int _execve(
    ffi.Pointer<ffi.Int8> _FileName,
    ffi.Pointer<ffi.Pointer<ffi.Int8>> _Arguments,
    ffi.Pointer<ffi.Pointer<ffi.Int8>> _Environment,
  ) {
    return __execve(
      _FileName,
      _Arguments,
      _Environment,
    );
  }

  late final __execvePtr = _lookup<
      ffi.NativeFunction<
          ffi.IntPtr Function(
              ffi.Pointer<ffi.Int8>,
              ffi.Pointer<ffi.Pointer<ffi.Int8>>,
              ffi.Pointer<ffi.Pointer<ffi.Int8>>)>>('_execve');
  late final __execve = __execvePtr.asFunction<
      int Function(ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Pointer<ffi.Int8>>,
          ffi.Pointer<ffi.Pointer<ffi.Int8>>)>();

  int _execvp(
    ffi.Pointer<ffi.Int8> _FileName,
    ffi.Pointer<ffi.Pointer<ffi.Int8>> _Arguments,
  ) {
    return __execvp(
      _FileName,
      _Arguments,
    );
  }

  late final __execvpPtr = _lookup<
      ffi.NativeFunction<
          ffi.IntPtr Function(ffi.Pointer<ffi.Int8>,
              ffi.Pointer<ffi.Pointer<ffi.Int8>>)>>('_execvp');
  late final __execvp = __execvpPtr.asFunction<
      int Function(
          ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Pointer<ffi.Int8>>)>();

  int _execvpe(
    ffi.Pointer<ffi.Int8> _FileName,
    ffi.Pointer<ffi.Pointer<ffi.Int8>> _Arguments,
    ffi.Pointer<ffi.Pointer<ffi.Int8>> _Environment,
  ) {
    return __execvpe(
      _FileName,
      _Arguments,
      _Environment,
    );
  }

  late final __execvpePtr = _lookup<
      ffi.NativeFunction<
          ffi.IntPtr Function(
              ffi.Pointer<ffi.Int8>,
              ffi.Pointer<ffi.Pointer<ffi.Int8>>,
              ffi.Pointer<ffi.Pointer<ffi.Int8>>)>>('_execvpe');
  late final __execvpe = __execvpePtr.asFunction<
      int Function(ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Pointer<ffi.Int8>>,
          ffi.Pointer<ffi.Pointer<ffi.Int8>>)>();

  int _spawnl(
    int _Mode,
    ffi.Pointer<ffi.Int8> _FileName,
    ffi.Pointer<ffi.Int8> _Arguments,
  ) {
    return __spawnl(
      _Mode,
      _FileName,
      _Arguments,
    );
  }

  late final __spawnlPtr = _lookup<
      ffi.NativeFunction<
          ffi.IntPtr Function(ffi.Int32, ffi.Pointer<ffi.Int8>,
              ffi.Pointer<ffi.Int8>)>>('_spawnl');
  late final __spawnl = __spawnlPtr.asFunction<
      int Function(int, ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Int8>)>();

  int _spawnle(
    int _Mode,
    ffi.Pointer<ffi.Int8> _FileName,
    ffi.Pointer<ffi.Int8> _Arguments,
  ) {
    return __spawnle(
      _Mode,
      _FileName,
      _Arguments,
    );
  }

  late final __spawnlePtr = _lookup<
      ffi.NativeFunction<
          ffi.IntPtr Function(ffi.Int32, ffi.Pointer<ffi.Int8>,
              ffi.Pointer<ffi.Int8>)>>('_spawnle');
  late final __spawnle = __spawnlePtr.asFunction<
      int Function(int, ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Int8>)>();

  int _spawnlp(
    int _Mode,
    ffi.Pointer<ffi.Int8> _FileName,
    ffi.Pointer<ffi.Int8> _Arguments,
  ) {
    return __spawnlp(
      _Mode,
      _FileName,
      _Arguments,
    );
  }

  late final __spawnlpPtr = _lookup<
      ffi.NativeFunction<
          ffi.IntPtr Function(ffi.Int32, ffi.Pointer<ffi.Int8>,
              ffi.Pointer<ffi.Int8>)>>('_spawnlp');
  late final __spawnlp = __spawnlpPtr.asFunction<
      int Function(int, ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Int8>)>();

  int _spawnlpe(
    int _Mode,
    ffi.Pointer<ffi.Int8> _FileName,
    ffi.Pointer<ffi.Int8> _Arguments,
  ) {
    return __spawnlpe(
      _Mode,
      _FileName,
      _Arguments,
    );
  }

  late final __spawnlpePtr = _lookup<
      ffi.NativeFunction<
          ffi.IntPtr Function(ffi.Int32, ffi.Pointer<ffi.Int8>,
              ffi.Pointer<ffi.Int8>)>>('_spawnlpe');
  late final __spawnlpe = __spawnlpePtr.asFunction<
      int Function(int, ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Int8>)>();

  int _spawnv(
    int _Mode,
    ffi.Pointer<ffi.Int8> _FileName,
    ffi.Pointer<ffi.Pointer<ffi.Int8>> _Arguments,
  ) {
    return __spawnv(
      _Mode,
      _FileName,
      _Arguments,
    );
  }

  late final __spawnvPtr = _lookup<
      ffi.NativeFunction<
          ffi.IntPtr Function(ffi.Int32, ffi.Pointer<ffi.Int8>,
              ffi.Pointer<ffi.Pointer<ffi.Int8>>)>>('_spawnv');
  late final __spawnv = __spawnvPtr.asFunction<
      int Function(
          int, ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Pointer<ffi.Int8>>)>();

  int _spawnve(
    int _Mode,
    ffi.Pointer<ffi.Int8> _FileName,
    ffi.Pointer<ffi.Pointer<ffi.Int8>> _Arguments,
    ffi.Pointer<ffi.Pointer<ffi.Int8>> _Environment,
  ) {
    return __spawnve(
      _Mode,
      _FileName,
      _Arguments,
      _Environment,
    );
  }

  late final __spawnvePtr = _lookup<
      ffi.NativeFunction<
          ffi.IntPtr Function(
              ffi.Int32,
              ffi.Pointer<ffi.Int8>,
              ffi.Pointer<ffi.Pointer<ffi.Int8>>,
              ffi.Pointer<ffi.Pointer<ffi.Int8>>)>>('_spawnve');
  late final __spawnve = __spawnvePtr.asFunction<
      int Function(
          int,
          ffi.Pointer<ffi.Int8>,
          ffi.Pointer<ffi.Pointer<ffi.Int8>>,
          ffi.Pointer<ffi.Pointer<ffi.Int8>>)>();

  int _spawnvp(
    int _Mode,
    ffi.Pointer<ffi.Int8> _FileName,
    ffi.Pointer<ffi.Pointer<ffi.Int8>> _Arguments,
  ) {
    return __spawnvp(
      _Mode,
      _FileName,
      _Arguments,
    );
  }

  late final __spawnvpPtr = _lookup<
      ffi.NativeFunction<
          ffi.IntPtr Function(ffi.Int32, ffi.Pointer<ffi.Int8>,
              ffi.Pointer<ffi.Pointer<ffi.Int8>>)>>('_spawnvp');
  late final __spawnvp = __spawnvpPtr.asFunction<
      int Function(
          int, ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Pointer<ffi.Int8>>)>();

  int _spawnvpe(
    int _Mode,
    ffi.Pointer<ffi.Int8> _FileName,
    ffi.Pointer<ffi.Pointer<ffi.Int8>> _Arguments,
    ffi.Pointer<ffi.Pointer<ffi.Int8>> _Environment,
  ) {
    return __spawnvpe(
      _Mode,
      _FileName,
      _Arguments,
      _Environment,
    );
  }

  late final __spawnvpePtr = _lookup<
      ffi.NativeFunction<
          ffi.IntPtr Function(
              ffi.Int32,
              ffi.Pointer<ffi.Int8>,
              ffi.Pointer<ffi.Pointer<ffi.Int8>>,
              ffi.Pointer<ffi.Pointer<ffi.Int8>>)>>('_spawnvpe');
  late final __spawnvpe = __spawnvpePtr.asFunction<
      int Function(
          int,
          ffi.Pointer<ffi.Int8>,
          ffi.Pointer<ffi.Pointer<ffi.Int8>>,
          ffi.Pointer<ffi.Pointer<ffi.Int8>>)>();

  int _loaddll(
    ffi.Pointer<ffi.Int8> _FileName,
  ) {
    return __loaddll(
      _FileName,
    );
  }

  late final __loaddllPtr =
      _lookup<ffi.NativeFunction<ffi.IntPtr Function(ffi.Pointer<ffi.Int8>)>>(
          '_loaddll');
  late final __loaddll =
      __loaddllPtr.asFunction<int Function(ffi.Pointer<ffi.Int8>)>();

  int _unloaddll(
    int _Handle,
  ) {
    return __unloaddll(
      _Handle,
    );
  }

  late final __unloaddllPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.IntPtr)>>('_unloaddll');
  late final __unloaddll = __unloaddllPtr.asFunction<int Function(int)>();

  _GetDllProcAddrProcType _getdllprocaddr(
    int _Handle,
    ffi.Pointer<ffi.Int8> _ProcedureName,
    int _Ordinal,
  ) {
    return __getdllprocaddr(
      _Handle,
      _ProcedureName,
      _Ordinal,
    );
  }

  late final __getdllprocaddrPtr = _lookup<
      ffi.NativeFunction<
          _GetDllProcAddrProcType Function(ffi.IntPtr, ffi.Pointer<ffi.Int8>,
              ffi.IntPtr)>>('_getdllprocaddr');
  late final __getdllprocaddr = __getdllprocaddrPtr.asFunction<
      _GetDllProcAddrProcType Function(int, ffi.Pointer<ffi.Int8>, int)>();

  int cwait(
    ffi.Pointer<ffi.Int32> _TermStat,
    int _ProcHandle,
    int _Action,
  ) {
    return _cwait1(
      _TermStat,
      _ProcHandle,
      _Action,
    );
  }

  late final _cwaitPtr = _lookup<
      ffi.NativeFunction<
          ffi.IntPtr Function(
              ffi.Pointer<ffi.Int32>, ffi.IntPtr, ffi.Int32)>>('cwait');
  late final _cwait1 =
      _cwaitPtr.asFunction<int Function(ffi.Pointer<ffi.Int32>, int, int)>();

  int execl(
    ffi.Pointer<ffi.Int8> _FileName,
    ffi.Pointer<ffi.Int8> _Arguments,
  ) {
    return _execl1(
      _FileName,
      _Arguments,
    );
  }

  late final _execlPtr = _lookup<
      ffi.NativeFunction<
          ffi.IntPtr Function(
              ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Int8>)>>('execl');
  late final _execl1 = _execlPtr
      .asFunction<int Function(ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Int8>)>();

  int execle(
    ffi.Pointer<ffi.Int8> _FileName,
    ffi.Pointer<ffi.Int8> _Arguments,
  ) {
    return _execle1(
      _FileName,
      _Arguments,
    );
  }

  late final _execlePtr = _lookup<
      ffi.NativeFunction<
          ffi.IntPtr Function(
              ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Int8>)>>('execle');
  late final _execle1 = _execlePtr
      .asFunction<int Function(ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Int8>)>();

  int execlp(
    ffi.Pointer<ffi.Int8> _FileName,
    ffi.Pointer<ffi.Int8> _Arguments,
  ) {
    return _execlp1(
      _FileName,
      _Arguments,
    );
  }

  late final _execlpPtr = _lookup<
      ffi.NativeFunction<
          ffi.IntPtr Function(
              ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Int8>)>>('execlp');
  late final _execlp1 = _execlpPtr
      .asFunction<int Function(ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Int8>)>();

  int execlpe(
    ffi.Pointer<ffi.Int8> _FileName,
    ffi.Pointer<ffi.Int8> _Arguments,
  ) {
    return _execlpe1(
      _FileName,
      _Arguments,
    );
  }

  late final _execlpePtr = _lookup<
      ffi.NativeFunction<
          ffi.IntPtr Function(
              ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Int8>)>>('execlpe');
  late final _execlpe1 = _execlpePtr
      .asFunction<int Function(ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Int8>)>();

  int execv(
    ffi.Pointer<ffi.Int8> _FileName,
    ffi.Pointer<ffi.Pointer<ffi.Int8>> _Arguments,
  ) {
    return _execv1(
      _FileName,
      _Arguments,
    );
  }

  late final _execvPtr = _lookup<
      ffi.NativeFunction<
          ffi.IntPtr Function(ffi.Pointer<ffi.Int8>,
              ffi.Pointer<ffi.Pointer<ffi.Int8>>)>>('execv');
  late final _execv1 = _execvPtr.asFunction<
      int Function(
          ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Pointer<ffi.Int8>>)>();

  int execve(
    ffi.Pointer<ffi.Int8> _FileName,
    ffi.Pointer<ffi.Pointer<ffi.Int8>> _Arguments,
    ffi.Pointer<ffi.Pointer<ffi.Int8>> _Environment,
  ) {
    return _execve1(
      _FileName,
      _Arguments,
      _Environment,
    );
  }

  late final _execvePtr = _lookup<
      ffi.NativeFunction<
          ffi.IntPtr Function(
              ffi.Pointer<ffi.Int8>,
              ffi.Pointer<ffi.Pointer<ffi.Int8>>,
              ffi.Pointer<ffi.Pointer<ffi.Int8>>)>>('execve');
  late final _execve1 = _execvePtr.asFunction<
      int Function(ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Pointer<ffi.Int8>>,
          ffi.Pointer<ffi.Pointer<ffi.Int8>>)>();

  int execvp(
    ffi.Pointer<ffi.Int8> _FileName,
    ffi.Pointer<ffi.Pointer<ffi.Int8>> _Arguments,
  ) {
    return _execvp1(
      _FileName,
      _Arguments,
    );
  }

  late final _execvpPtr = _lookup<
      ffi.NativeFunction<
          ffi.IntPtr Function(ffi.Pointer<ffi.Int8>,
              ffi.Pointer<ffi.Pointer<ffi.Int8>>)>>('execvp');
  late final _execvp1 = _execvpPtr.asFunction<
      int Function(
          ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Pointer<ffi.Int8>>)>();

  int execvpe(
    ffi.Pointer<ffi.Int8> _FileName,
    ffi.Pointer<ffi.Pointer<ffi.Int8>> _Arguments,
    ffi.Pointer<ffi.Pointer<ffi.Int8>> _Environment,
  ) {
    return _execvpe1(
      _FileName,
      _Arguments,
      _Environment,
    );
  }

  late final _execvpePtr = _lookup<
      ffi.NativeFunction<
          ffi.IntPtr Function(
              ffi.Pointer<ffi.Int8>,
              ffi.Pointer<ffi.Pointer<ffi.Int8>>,
              ffi.Pointer<ffi.Pointer<ffi.Int8>>)>>('execvpe');
  late final _execvpe1 = _execvpePtr.asFunction<
      int Function(ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Pointer<ffi.Int8>>,
          ffi.Pointer<ffi.Pointer<ffi.Int8>>)>();

  int spawnl(
    int _Mode,
    ffi.Pointer<ffi.Int8> _FileName,
    ffi.Pointer<ffi.Int8> _Arguments,
  ) {
    return _spawnl1(
      _Mode,
      _FileName,
      _Arguments,
    );
  }

  late final _spawnlPtr = _lookup<
      ffi.NativeFunction<
          ffi.IntPtr Function(ffi.Int32, ffi.Pointer<ffi.Int8>,
              ffi.Pointer<ffi.Int8>)>>('spawnl');
  late final _spawnl1 = _spawnlPtr.asFunction<
      int Function(int, ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Int8>)>();

  int spawnle(
    int _Mode,
    ffi.Pointer<ffi.Int8> _FileName,
    ffi.Pointer<ffi.Int8> _Arguments,
  ) {
    return _spawnle1(
      _Mode,
      _FileName,
      _Arguments,
    );
  }

  late final _spawnlePtr = _lookup<
      ffi.NativeFunction<
          ffi.IntPtr Function(ffi.Int32, ffi.Pointer<ffi.Int8>,
              ffi.Pointer<ffi.Int8>)>>('spawnle');
  late final _spawnle1 = _spawnlePtr.asFunction<
      int Function(int, ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Int8>)>();

  int spawnlp(
    int _Mode,
    ffi.Pointer<ffi.Int8> _FileName,
    ffi.Pointer<ffi.Int8> _Arguments,
  ) {
    return _spawnlp1(
      _Mode,
      _FileName,
      _Arguments,
    );
  }

  late final _spawnlpPtr = _lookup<
      ffi.NativeFunction<
          ffi.IntPtr Function(ffi.Int32, ffi.Pointer<ffi.Int8>,
              ffi.Pointer<ffi.Int8>)>>('spawnlp');
  late final _spawnlp1 = _spawnlpPtr.asFunction<
      int Function(int, ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Int8>)>();

  int spawnlpe(
    int _Mode,
    ffi.Pointer<ffi.Int8> _FileName,
    ffi.Pointer<ffi.Int8> _Arguments,
  ) {
    return _spawnlpe1(
      _Mode,
      _FileName,
      _Arguments,
    );
  }

  late final _spawnlpePtr = _lookup<
      ffi.NativeFunction<
          ffi.IntPtr Function(ffi.Int32, ffi.Pointer<ffi.Int8>,
              ffi.Pointer<ffi.Int8>)>>('spawnlpe');
  late final _spawnlpe1 = _spawnlpePtr.asFunction<
      int Function(int, ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Int8>)>();

  int spawnv(
    int _Mode,
    ffi.Pointer<ffi.Int8> _FileName,
    ffi.Pointer<ffi.Pointer<ffi.Int8>> _Arguments,
  ) {
    return _spawnv1(
      _Mode,
      _FileName,
      _Arguments,
    );
  }

  late final _spawnvPtr = _lookup<
      ffi.NativeFunction<
          ffi.IntPtr Function(ffi.Int32, ffi.Pointer<ffi.Int8>,
              ffi.Pointer<ffi.Pointer<ffi.Int8>>)>>('spawnv');
  late final _spawnv1 = _spawnvPtr.asFunction<
      int Function(
          int, ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Pointer<ffi.Int8>>)>();

  int spawnve(
    int _Mode,
    ffi.Pointer<ffi.Int8> _FileName,
    ffi.Pointer<ffi.Pointer<ffi.Int8>> _Arguments,
    ffi.Pointer<ffi.Pointer<ffi.Int8>> _Environment,
  ) {
    return _spawnve1(
      _Mode,
      _FileName,
      _Arguments,
      _Environment,
    );
  }

  late final _spawnvePtr = _lookup<
      ffi.NativeFunction<
          ffi.IntPtr Function(
              ffi.Int32,
              ffi.Pointer<ffi.Int8>,
              ffi.Pointer<ffi.Pointer<ffi.Int8>>,
              ffi.Pointer<ffi.Pointer<ffi.Int8>>)>>('spawnve');
  late final _spawnve1 = _spawnvePtr.asFunction<
      int Function(
          int,
          ffi.Pointer<ffi.Int8>,
          ffi.Pointer<ffi.Pointer<ffi.Int8>>,
          ffi.Pointer<ffi.Pointer<ffi.Int8>>)>();

  int spawnvp(
    int _Mode,
    ffi.Pointer<ffi.Int8> _FileName,
    ffi.Pointer<ffi.Pointer<ffi.Int8>> _Arguments,
  ) {
    return _spawnvp1(
      _Mode,
      _FileName,
      _Arguments,
    );
  }

  late final _spawnvpPtr = _lookup<
      ffi.NativeFunction<
          ffi.IntPtr Function(ffi.Int32, ffi.Pointer<ffi.Int8>,
              ffi.Pointer<ffi.Pointer<ffi.Int8>>)>>('spawnvp');
  late final _spawnvp1 = _spawnvpPtr.asFunction<
      int Function(
          int, ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Pointer<ffi.Int8>>)>();

  int spawnvpe(
    int _Mode,
    ffi.Pointer<ffi.Int8> _FileName,
    ffi.Pointer<ffi.Pointer<ffi.Int8>> _Arguments,
    ffi.Pointer<ffi.Pointer<ffi.Int8>> _Environment,
  ) {
    return _spawnvpe1(
      _Mode,
      _FileName,
      _Arguments,
      _Environment,
    );
  }

  late final _spawnvpePtr = _lookup<
      ffi.NativeFunction<
          ffi.IntPtr Function(
              ffi.Int32,
              ffi.Pointer<ffi.Int8>,
              ffi.Pointer<ffi.Pointer<ffi.Int8>>,
              ffi.Pointer<ffi.Pointer<ffi.Int8>>)>>('spawnvpe');
  late final _spawnvpe1 = _spawnvpePtr.asFunction<
      int Function(
          int,
          ffi.Pointer<ffi.Int8>,
          ffi.Pointer<ffi.Pointer<ffi.Int8>>,
          ffi.Pointer<ffi.Pointer<ffi.Int8>>)>();

  int getpid() {
    return _getpid1();
  }

  late final _getpidPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function()>>('getpid');
  late final _getpid1 = _getpidPtr.asFunction<int Function()>();

  ffi.Pointer<SDL_Thread> SDL_CreateThread(
    SDL_ThreadFunction fn,
    ffi.Pointer<ffi.Int8> name,
    ffi.Pointer<ffi.Void> data,
    pfnSDL_CurrentBeginThread pfnBeginThread,
    pfnSDL_CurrentEndThread pfnEndThread,
  ) {
    return _SDL_CreateThread(
      fn,
      name,
      data,
      pfnBeginThread,
      pfnEndThread,
    );
  }

  late final _SDL_CreateThreadPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<SDL_Thread> Function(
              SDL_ThreadFunction,
              ffi.Pointer<ffi.Int8>,
              ffi.Pointer<ffi.Void>,
              pfnSDL_CurrentBeginThread,
              pfnSDL_CurrentEndThread)>>('SDL_CreateThread');
  late final _SDL_CreateThread = _SDL_CreateThreadPtr.asFunction<
      ffi.Pointer<SDL_Thread> Function(
          SDL_ThreadFunction,
          ffi.Pointer<ffi.Int8>,
          ffi.Pointer<ffi.Void>,
          pfnSDL_CurrentBeginThread,
          pfnSDL_CurrentEndThread)>();

  ffi.Pointer<SDL_Thread> SDL_CreateThreadWithStackSize(
    ffi.Pointer<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<ffi.Void>)>>
        fn,
    ffi.Pointer<ffi.Int8> name,
    int stacksize,
    ffi.Pointer<ffi.Void> data,
    pfnSDL_CurrentBeginThread pfnBeginThread,
    pfnSDL_CurrentEndThread pfnEndThread,
  ) {
    return _SDL_CreateThreadWithStackSize(
      fn,
      name,
      stacksize,
      data,
      pfnBeginThread,
      pfnEndThread,
    );
  }

  late final _SDL_CreateThreadWithStackSizePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<SDL_Thread> Function(
              ffi.Pointer<
                  ffi.NativeFunction<
                      ffi.Int32 Function(ffi.Pointer<ffi.Void>)>>,
              ffi.Pointer<ffi.Int8>,
              size_t,
              ffi.Pointer<ffi.Void>,
              pfnSDL_CurrentBeginThread,
              pfnSDL_CurrentEndThread)>>('SDL_CreateThreadWithStackSize');
  late final _SDL_CreateThreadWithStackSize =
      _SDL_CreateThreadWithStackSizePtr.asFunction<
          ffi.Pointer<SDL_Thread> Function(
              ffi.Pointer<
                  ffi.NativeFunction<
                      ffi.Int32 Function(ffi.Pointer<ffi.Void>)>>,
              ffi.Pointer<ffi.Int8>,
              int,
              ffi.Pointer<ffi.Void>,
              pfnSDL_CurrentBeginThread,
              pfnSDL_CurrentEndThread)>();

  /// Get the thread name as it was specified in SDL_CreateThread().
  ///
  /// This is internal memory, not to be freed by the caller, and remains valid
  /// until the specified thread is cleaned up by SDL_WaitThread().
  ///
  /// \param thread the thread to query
  /// \returns a pointer to a UTF-8 string that names the specified thread, or
  /// NULL if it doesn't have a name.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_CreateThread
  ffi.Pointer<ffi.Int8> SDL_GetThreadName(
    ffi.Pointer<SDL_Thread> thread,
  ) {
    return _SDL_GetThreadName(
      thread,
    );
  }

  late final _SDL_GetThreadNamePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Int8> Function(
              ffi.Pointer<SDL_Thread>)>>('SDL_GetThreadName');
  late final _SDL_GetThreadName = _SDL_GetThreadNamePtr.asFunction<
      ffi.Pointer<ffi.Int8> Function(ffi.Pointer<SDL_Thread>)>();

  /// Get the thread identifier for the current thread.
  ///
  /// This thread identifier is as reported by the underlying operating system.
  /// If SDL is running on a platform that does not support threads the return
  /// value will always be zero.
  ///
  /// This function also returns a valid thread ID when called from the main
  /// thread.
  ///
  /// \returns the ID of the current thread.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetThreadID
  int SDL_ThreadID() {
    return _SDL_ThreadID();
  }

  late final _SDL_ThreadIDPtr =
      _lookup<ffi.NativeFunction<SDL_threadID Function()>>('SDL_ThreadID');
  late final _SDL_ThreadID = _SDL_ThreadIDPtr.asFunction<int Function()>();

  /// Get the thread identifier for the specified thread.
  ///
  /// This thread identifier is as reported by the underlying operating system.
  /// If SDL is running on a platform that does not support threads the return
  /// value will always be zero.
  ///
  /// \param thread the thread to query
  /// \returns the ID of the specified thread, or the ID of the current thread if
  /// `thread` is NULL.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_ThreadID
  int SDL_GetThreadID(
    ffi.Pointer<SDL_Thread> thread,
  ) {
    return _SDL_GetThreadID(
      thread,
    );
  }

  late final _SDL_GetThreadIDPtr = _lookup<
          ffi.NativeFunction<SDL_threadID Function(ffi.Pointer<SDL_Thread>)>>(
      'SDL_GetThreadID');
  late final _SDL_GetThreadID =
      _SDL_GetThreadIDPtr.asFunction<int Function(ffi.Pointer<SDL_Thread>)>();

  /// Set the priority for the current thread.
  ///
  /// Note that some platforms will not let you alter the priority (or at least,
  /// promote the thread to a higher priority) at all, and some require you to be
  /// an administrator account. Be prepared for this to fail.
  ///
  /// \param priority the SDL_ThreadPriority to set
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  int SDL_SetThreadPriority(
    int priority,
  ) {
    return _SDL_SetThreadPriority(
      priority,
    );
  }

  late final _SDL_SetThreadPriorityPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Int32)>>(
          'SDL_SetThreadPriority');
  late final _SDL_SetThreadPriority =
      _SDL_SetThreadPriorityPtr.asFunction<int Function(int)>();

  /// Wait for a thread to finish.
  ///
  /// Threads that haven't been detached will remain (as a "zombie") until this
  /// function cleans them up. Not doing so is a resource leak.
  ///
  /// Once a thread has been cleaned up through this function, the SDL_Thread
  /// that references it becomes invalid and should not be referenced again. As
  /// such, only one thread may call SDL_WaitThread() on another.
  ///
  /// The return code for the thread function is placed in the area pointed to by
  /// `status`, if `status` is not NULL.
  ///
  /// You may not wait on a thread that has been used in a call to
  /// SDL_DetachThread(). Use either that function or this one, but not both, or
  /// behavior is undefined.
  ///
  /// It is safe to pass a NULL thread to this function; it is a no-op.
  ///
  /// Note that the thread pointer is freed by this function and is not valid
  /// afterward.
  ///
  /// \param thread the SDL_Thread pointer that was returned from the
  /// SDL_CreateThread() call that started this thread
  /// \param status pointer to an integer that will receive the value returned
  /// from the thread function by its 'return', or NULL to not
  /// receive such value back.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_CreateThread
  /// \sa SDL_DetachThread
  void SDL_WaitThread(
    ffi.Pointer<SDL_Thread> thread,
    ffi.Pointer<ffi.Int32> status,
  ) {
    return _SDL_WaitThread(
      thread,
      status,
    );
  }

  late final _SDL_WaitThreadPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<SDL_Thread>,
              ffi.Pointer<ffi.Int32>)>>('SDL_WaitThread');
  late final _SDL_WaitThread = _SDL_WaitThreadPtr.asFunction<
      void Function(ffi.Pointer<SDL_Thread>, ffi.Pointer<ffi.Int32>)>();

  /// Let a thread clean up on exit without intervention.
  ///
  /// A thread may be "detached" to signify that it should not remain until
  /// another thread has called SDL_WaitThread() on it. Detaching a thread is
  /// useful for long-running threads that nothing needs to synchronize with or
  /// further manage. When a detached thread is done, it simply goes away.
  ///
  /// There is no way to recover the return code of a detached thread. If you
  /// need this, don't detach the thread and instead use SDL_WaitThread().
  ///
  /// Once a thread is detached, you should usually assume the SDL_Thread isn't
  /// safe to reference again, as it will become invalid immediately upon the
  /// detached thread's exit, instead of remaining until someone has called
  /// SDL_WaitThread() to finally clean it up. As such, don't detach the same
  /// thread more than once.
  ///
  /// If a thread has already exited when passed to SDL_DetachThread(), it will
  /// stop waiting for a call to SDL_WaitThread() and clean up immediately. It is
  /// not safe to detach a thread that might be used with SDL_WaitThread().
  ///
  /// You may not call SDL_WaitThread() on a thread that has been detached. Use
  /// either that function or this one, but not both, or behavior is undefined.
  ///
  /// It is safe to pass NULL to this function; it is a no-op.
  ///
  /// \param thread the SDL_Thread pointer that was returned from the
  /// SDL_CreateThread() call that started this thread
  ///
  /// \since This function is available since SDL 2.0.2.
  ///
  /// \sa SDL_CreateThread
  /// \sa SDL_WaitThread
  void SDL_DetachThread(
    ffi.Pointer<SDL_Thread> thread,
  ) {
    return _SDL_DetachThread(
      thread,
    );
  }

  late final _SDL_DetachThreadPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<SDL_Thread>)>>(
          'SDL_DetachThread');
  late final _SDL_DetachThread =
      _SDL_DetachThreadPtr.asFunction<void Function(ffi.Pointer<SDL_Thread>)>();

  /// Create a piece of thread-local storage.
  ///
  /// This creates an identifier that is globally visible to all threads but
  /// refers to data that is thread-specific.
  ///
  /// \returns the newly created thread local storage identifier or 0 on error.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_TLSGet
  /// \sa SDL_TLSSet
  int SDL_TLSCreate() {
    return _SDL_TLSCreate();
  }

  late final _SDL_TLSCreatePtr =
      _lookup<ffi.NativeFunction<SDL_TLSID Function()>>('SDL_TLSCreate');
  late final _SDL_TLSCreate = _SDL_TLSCreatePtr.asFunction<int Function()>();

  /// Get the current thread's value associated with a thread local storage ID.
  ///
  /// \param id the thread local storage ID
  /// \returns the value associated with the ID for the current thread or NULL if
  /// no value has been set; call SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_TLSCreate
  /// \sa SDL_TLSSet
  ffi.Pointer<ffi.Void> SDL_TLSGet(
    int id,
  ) {
    return _SDL_TLSGet(
      id,
    );
  }

  late final _SDL_TLSGetPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Void> Function(SDL_TLSID)>>(
          'SDL_TLSGet');
  late final _SDL_TLSGet =
      _SDL_TLSGetPtr.asFunction<ffi.Pointer<ffi.Void> Function(int)>();

  /// Set the current thread's value associated with a thread local storage ID.
  ///
  /// The function prototype for `destructor` is:
  ///
  /// ```c
  /// void destructor(void *value)
  /// ```
  ///
  /// where its parameter `value` is what was passed as `value` to SDL_TLSSet().
  ///
  /// \param id the thread local storage ID
  /// \param value the value to associate with the ID for the current thread
  /// \param destructor a function called when the thread exits, to free the
  /// value
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_TLSCreate
  /// \sa SDL_TLSGet
  int SDL_TLSSet(
    int id,
    ffi.Pointer<ffi.Void> value,
    ffi.Pointer<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ffi.Void>)>>
        destructor,
  ) {
    return _SDL_TLSSet(
      id,
      value,
      destructor,
    );
  }

  late final _SDL_TLSSetPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              SDL_TLSID,
              ffi.Pointer<ffi.Void>,
              ffi.Pointer<
                  ffi.NativeFunction<
                      ffi.Void Function(
                          ffi.Pointer<ffi.Void>)>>)>>('SDL_TLSSet');
  late final _SDL_TLSSet = _SDL_TLSSetPtr.asFunction<
      int Function(
          int,
          ffi.Pointer<ffi.Void>,
          ffi.Pointer<
              ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ffi.Void>)>>)>();

  /// Cleanup all TLS data for this thread.
  ///
  /// \since This function is available since SDL 2.0.16.
  void SDL_TLSCleanup() {
    return _SDL_TLSCleanup();
  }

  late final _SDL_TLSCleanupPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('SDL_TLSCleanup');
  late final _SDL_TLSCleanup = _SDL_TLSCleanupPtr.asFunction<void Function()>();

  /// Use this function to create a new SDL_RWops structure for reading from
  /// and/or writing to a named file.
  ///
  /// The `mode` string is treated roughly the same as in a call to the C
  /// library's fopen(), even if SDL doesn't happen to use fopen() behind the
  /// scenes.
  ///
  /// Available `mode` strings:
  ///
  /// - "r": Open a file for reading. The file must exist.
  /// - "w": Create an empty file for writing. If a file with the same name
  /// already exists its content is erased and the file is treated as a new
  /// empty file.
  /// - "a": Append to a file. Writing operations append data at the end of the
  /// file. The file is created if it does not exist.
  /// - "r+": Open a file for update both reading and writing. The file must
  /// exist.
  /// - "w+": Create an empty file for both reading and writing. If a file with
  /// the same name already exists its content is erased and the file is
  /// treated as a new empty file.
  /// - "a+": Open a file for reading and appending. All writing operations are
  /// performed at the end of the file, protecting the previous content to be
  /// overwritten. You can reposition (fseek, rewind) the internal pointer to
  /// anywhere in the file for reading, but writing operations will move it
  /// back to the end of file. The file is created if it does not exist.
  ///
  /// **NOTE**: In order to open a file as a binary file, a "b" character has to
  /// be included in the `mode` string. This additional "b" character can either
  /// be appended at the end of the string (thus making the following compound
  /// modes: "rb", "wb", "ab", "r+b", "w+b", "a+b") or be inserted between the
  /// letter and the "+" sign for the mixed modes ("rb+", "wb+", "ab+").
  /// Additional characters may follow the sequence, although they should have no
  /// effect. For example, "t" is sometimes appended to make explicit the file is
  /// a text file.
  ///
  /// This function supports Unicode filenames, but they must be encoded in UTF-8
  /// format, regardless of the underlying operating system.
  ///
  /// As a fallback, SDL_RWFromFile() will transparently open a matching filename
  /// in an Android app's `assets`.
  ///
  /// Closing the SDL_RWops will close the file handle SDL is holding internally.
  ///
  /// \param file a UTF-8 string representing the filename to open
  /// \param mode an ASCII string representing the mode to be used for opening
  /// the file.
  /// \returns a pointer to the SDL_RWops structure that is created, or NULL on
  /// failure; call SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_RWclose
  /// \sa SDL_RWFromConstMem
  /// \sa SDL_RWFromFP
  /// \sa SDL_RWFromMem
  /// \sa SDL_RWread
  /// \sa SDL_RWseek
  /// \sa SDL_RWtell
  /// \sa SDL_RWwrite
  ffi.Pointer<SDL_RWops> SDL_RWFromFile(
    ffi.Pointer<ffi.Int8> file,
    ffi.Pointer<ffi.Int8> mode,
  ) {
    return _SDL_RWFromFile(
      file,
      mode,
    );
  }

  late final _SDL_RWFromFilePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<SDL_RWops> Function(
              ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Int8>)>>('SDL_RWFromFile');
  late final _SDL_RWFromFile = _SDL_RWFromFilePtr.asFunction<
      ffi.Pointer<SDL_RWops> Function(
          ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Int8>)>();

  /// Use this function to create an SDL_RWops structure from a standard I/O file
  /// pointer (stdio.h's `FILE*`).
  ///
  /// This function is not available on Windows, since files opened in an
  /// application on that platform cannot be used by a dynamically linked
  /// library.
  ///
  /// On some platforms, the first parameter is a `void*`, on others, it's a
  /// `FILE*`, depending on what system headers are available to SDL. It is
  /// always intended to be the `FILE*` type from the C runtime's stdio.h.
  ///
  /// \param fp the `FILE*` that feeds the SDL_RWops stream
  /// \param autoclose SDL_TRUE to close the `FILE*` when closing the SDL_RWops,
  /// SDL_FALSE to leave the `FILE*` open when the RWops is
  /// closed
  /// \returns a pointer to the SDL_RWops structure that is created, or NULL on
  /// failure; call SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_RWclose
  /// \sa SDL_RWFromConstMem
  /// \sa SDL_RWFromFile
  /// \sa SDL_RWFromMem
  /// \sa SDL_RWread
  /// \sa SDL_RWseek
  /// \sa SDL_RWtell
  /// \sa SDL_RWwrite
  ffi.Pointer<SDL_RWops> SDL_RWFromFP(
    ffi.Pointer<ffi.Void> fp,
    int autoclose,
  ) {
    return _SDL_RWFromFP(
      fp,
      autoclose,
    );
  }

  late final _SDL_RWFromFPPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<SDL_RWops> Function(
              ffi.Pointer<ffi.Void>, ffi.Int32)>>('SDL_RWFromFP');
  late final _SDL_RWFromFP = _SDL_RWFromFPPtr.asFunction<
      ffi.Pointer<SDL_RWops> Function(ffi.Pointer<ffi.Void>, int)>();

  /// Use this function to prepare a read-write memory buffer for use with
  /// SDL_RWops.
  ///
  /// This function sets up an SDL_RWops struct based on a memory area of a
  /// certain size, for both read and write access.
  ///
  /// This memory buffer is not copied by the RWops; the pointer you provide must
  /// remain valid until you close the stream. Closing the stream will not free
  /// the original buffer.
  ///
  /// If you need to make sure the RWops never writes to the memory buffer, you
  /// should use SDL_RWFromConstMem() with a read-only buffer of memory instead.
  ///
  /// \param mem a pointer to a buffer to feed an SDL_RWops stream
  /// \param size the buffer size, in bytes
  /// \returns a pointer to a new SDL_RWops structure, or NULL if it fails; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_RWclose
  /// \sa SDL_RWFromConstMem
  /// \sa SDL_RWFromFile
  /// \sa SDL_RWFromFP
  /// \sa SDL_RWFromMem
  /// \sa SDL_RWread
  /// \sa SDL_RWseek
  /// \sa SDL_RWtell
  /// \sa SDL_RWwrite
  ffi.Pointer<SDL_RWops> SDL_RWFromMem(
    ffi.Pointer<ffi.Void> mem,
    int size,
  ) {
    return _SDL_RWFromMem(
      mem,
      size,
    );
  }

  late final _SDL_RWFromMemPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<SDL_RWops> Function(
              ffi.Pointer<ffi.Void>, ffi.Int32)>>('SDL_RWFromMem');
  late final _SDL_RWFromMem = _SDL_RWFromMemPtr.asFunction<
      ffi.Pointer<SDL_RWops> Function(ffi.Pointer<ffi.Void>, int)>();

  /// Use this function to prepare a read-only memory buffer for use with RWops.
  ///
  /// This function sets up an SDL_RWops struct based on a memory area of a
  /// certain size. It assumes the memory area is not writable.
  ///
  /// Attempting to write to this RWops stream will report an error without
  /// writing to the memory buffer.
  ///
  /// This memory buffer is not copied by the RWops; the pointer you provide must
  /// remain valid until you close the stream. Closing the stream will not free
  /// the original buffer.
  ///
  /// If you need to write to a memory buffer, you should use SDL_RWFromMem()
  /// with a writable buffer of memory instead.
  ///
  /// \param mem a pointer to a read-only buffer to feed an SDL_RWops stream
  /// \param size the buffer size, in bytes
  /// \returns a pointer to a new SDL_RWops structure, or NULL if it fails; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_RWclose
  /// \sa SDL_RWFromConstMem
  /// \sa SDL_RWFromFile
  /// \sa SDL_RWFromFP
  /// \sa SDL_RWFromMem
  /// \sa SDL_RWread
  /// \sa SDL_RWseek
  /// \sa SDL_RWtell
  ffi.Pointer<SDL_RWops> SDL_RWFromConstMem(
    ffi.Pointer<ffi.Void> mem,
    int size,
  ) {
    return _SDL_RWFromConstMem(
      mem,
      size,
    );
  }

  late final _SDL_RWFromConstMemPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<SDL_RWops> Function(
              ffi.Pointer<ffi.Void>, ffi.Int32)>>('SDL_RWFromConstMem');
  late final _SDL_RWFromConstMem = _SDL_RWFromConstMemPtr.asFunction<
      ffi.Pointer<SDL_RWops> Function(ffi.Pointer<ffi.Void>, int)>();

  /// Use this function to allocate an empty, unpopulated SDL_RWops structure.
  ///
  /// Applications do not need to use this function unless they are providing
  /// their own SDL_RWops implementation. If you just need a SDL_RWops to
  /// read/write a common data source, you should use the built-in
  /// implementations in SDL, like SDL_RWFromFile() or SDL_RWFromMem(), etc.
  ///
  /// You must free the returned pointer with SDL_FreeRW(). Depending on your
  /// operating system and compiler, there may be a difference between the
  /// malloc() and free() your program uses and the versions SDL calls
  /// internally. Trying to mix the two can cause crashing such as segmentation
  /// faults. Since all SDL_RWops must free themselves when their **close**
  /// method is called, all SDL_RWops must be allocated through this function, so
  /// they can all be freed correctly with SDL_FreeRW().
  ///
  /// \returns a pointer to the allocated memory on success, or NULL on failure;
  /// call SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_FreeRW
  ffi.Pointer<SDL_RWops> SDL_AllocRW() {
    return _SDL_AllocRW();
  }

  late final _SDL_AllocRWPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<SDL_RWops> Function()>>(
          'SDL_AllocRW');
  late final _SDL_AllocRW =
      _SDL_AllocRWPtr.asFunction<ffi.Pointer<SDL_RWops> Function()>();

  /// Use this function to free an SDL_RWops structure allocated by
  /// SDL_AllocRW().
  ///
  /// Applications do not need to use this function unless they are providing
  /// their own SDL_RWops implementation. If you just need a SDL_RWops to
  /// read/write a common data source, you should use the built-in
  /// implementations in SDL, like SDL_RWFromFile() or SDL_RWFromMem(), etc, and
  /// call the **close** method on those SDL_RWops pointers when you are done
  /// with them.
  ///
  /// Only use SDL_FreeRW() on pointers returned by SDL_AllocRW(). The pointer is
  /// invalid as soon as this function returns. Any extra memory allocated during
  /// creation of the SDL_RWops is not freed by SDL_FreeRW(); the programmer must
  /// be responsible for managing that memory in their **close** method.
  ///
  /// \param area the SDL_RWops structure to be freed
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_AllocRW
  void SDL_FreeRW(
    ffi.Pointer<SDL_RWops> area,
  ) {
    return _SDL_FreeRW(
      area,
    );
  }

  late final _SDL_FreeRWPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<SDL_RWops>)>>(
          'SDL_FreeRW');
  late final _SDL_FreeRW =
      _SDL_FreeRWPtr.asFunction<void Function(ffi.Pointer<SDL_RWops>)>();

  /// Use this function to get the size of the data stream in an SDL_RWops.
  ///
  /// Prior to SDL 2.0.10, this function was a macro.
  ///
  /// \param context the SDL_RWops to get the size of the data stream from
  /// \returns the size of the data stream in the SDL_RWops on success, -1 if
  /// unknown or a negative error code on failure; call SDL_GetError()
  /// for more information.
  ///
  /// \since This function is available since SDL 2.0.10.
  int SDL_RWsize(
    ffi.Pointer<SDL_RWops> context,
  ) {
    return _SDL_RWsize(
      context,
    );
  }

  late final _SDL_RWsizePtr =
      _lookup<ffi.NativeFunction<Sint64 Function(ffi.Pointer<SDL_RWops>)>>(
          'SDL_RWsize');
  late final _SDL_RWsize =
      _SDL_RWsizePtr.asFunction<int Function(ffi.Pointer<SDL_RWops>)>();

  /// Seek within an SDL_RWops data stream.
  ///
  /// This function seeks to byte `offset`, relative to `whence`.
  ///
  /// `whence` may be any of the following values:
  ///
  /// - `RW_SEEK_SET`: seek from the beginning of data
  /// - `RW_SEEK_CUR`: seek relative to current read point
  /// - `RW_SEEK_END`: seek relative to the end of data
  ///
  /// If this stream can not seek, it will return -1.
  ///
  /// SDL_RWseek() is actually a wrapper function that calls the SDL_RWops's
  /// `seek` method appropriately, to simplify application development.
  ///
  /// Prior to SDL 2.0.10, this function was a macro.
  ///
  /// \param context a pointer to an SDL_RWops structure
  /// \param offset an offset in bytes, relative to **whence** location; can be
  /// negative
  /// \param whence any of `RW_SEEK_SET`, `RW_SEEK_CUR`, `RW_SEEK_END`
  /// \returns the final offset in the data stream after the seek or -1 on error.
  ///
  /// \since This function is available since SDL 2.0.10.
  ///
  /// \sa SDL_RWclose
  /// \sa SDL_RWFromConstMem
  /// \sa SDL_RWFromFile
  /// \sa SDL_RWFromFP
  /// \sa SDL_RWFromMem
  /// \sa SDL_RWread
  /// \sa SDL_RWtell
  /// \sa SDL_RWwrite
  int SDL_RWseek(
    ffi.Pointer<SDL_RWops> context,
    int offset,
    int whence,
  ) {
    return _SDL_RWseek(
      context,
      offset,
      whence,
    );
  }

  late final _SDL_RWseekPtr = _lookup<
      ffi.NativeFunction<
          Sint64 Function(
              ffi.Pointer<SDL_RWops>, Sint64, ffi.Int32)>>('SDL_RWseek');
  late final _SDL_RWseek = _SDL_RWseekPtr.asFunction<
      int Function(ffi.Pointer<SDL_RWops>, int, int)>();

  /// Determine the current read/write offset in an SDL_RWops data stream.
  ///
  /// SDL_RWtell is actually a wrapper function that calls the SDL_RWops's `seek`
  /// method, with an offset of 0 bytes from `RW_SEEK_CUR`, to simplify
  /// application development.
  ///
  /// Prior to SDL 2.0.10, this function was a macro.
  ///
  /// \param context a SDL_RWops data stream object from which to get the current
  /// offset
  /// \returns the current offset in the stream, or -1 if the information can not
  /// be determined.
  ///
  /// \since This function is available since SDL 2.0.10.
  ///
  /// \sa SDL_RWclose
  /// \sa SDL_RWFromConstMem
  /// \sa SDL_RWFromFile
  /// \sa SDL_RWFromFP
  /// \sa SDL_RWFromMem
  /// \sa SDL_RWread
  /// \sa SDL_RWseek
  /// \sa SDL_RWwrite
  int SDL_RWtell(
    ffi.Pointer<SDL_RWops> context,
  ) {
    return _SDL_RWtell(
      context,
    );
  }

  late final _SDL_RWtellPtr =
      _lookup<ffi.NativeFunction<Sint64 Function(ffi.Pointer<SDL_RWops>)>>(
          'SDL_RWtell');
  late final _SDL_RWtell =
      _SDL_RWtellPtr.asFunction<int Function(ffi.Pointer<SDL_RWops>)>();

  /// Read from a data source.
  ///
  /// This function reads up to `maxnum` objects each of size `size` from the
  /// data source to the area pointed at by `ptr`. This function may read less
  /// objects than requested. It will return zero when there has been an error or
  /// the data stream is completely read.
  ///
  /// SDL_RWread() is actually a function wrapper that calls the SDL_RWops's
  /// `read` method appropriately, to simplify application development.
  ///
  /// Prior to SDL 2.0.10, this function was a macro.
  ///
  /// \param context a pointer to an SDL_RWops structure
  /// \param ptr a pointer to a buffer to read data into
  /// \param size the size of each object to read, in bytes
  /// \param maxnum the maximum number of objects to be read
  /// \returns the number of objects read, or 0 at error or end of file; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.10.
  ///
  /// \sa SDL_RWclose
  /// \sa SDL_RWFromConstMem
  /// \sa SDL_RWFromFile
  /// \sa SDL_RWFromFP
  /// \sa SDL_RWFromMem
  /// \sa SDL_RWseek
  /// \sa SDL_RWwrite
  int SDL_RWread(
    ffi.Pointer<SDL_RWops> context,
    ffi.Pointer<ffi.Void> ptr,
    int size,
    int maxnum,
  ) {
    return _SDL_RWread(
      context,
      ptr,
      size,
      maxnum,
    );
  }

  late final _SDL_RWreadPtr = _lookup<
      ffi.NativeFunction<
          size_t Function(ffi.Pointer<SDL_RWops>, ffi.Pointer<ffi.Void>, size_t,
              size_t)>>('SDL_RWread');
  late final _SDL_RWread = _SDL_RWreadPtr.asFunction<
      int Function(ffi.Pointer<SDL_RWops>, ffi.Pointer<ffi.Void>, int, int)>();

  /// Write to an SDL_RWops data stream.
  ///
  /// This function writes exactly `num` objects each of size `size` from the
  /// area pointed at by `ptr` to the stream. If this fails for any reason, it'll
  /// return less than `num` to demonstrate how far the write progressed. On
  /// success, it returns `num`.
  ///
  /// SDL_RWwrite is actually a function wrapper that calls the SDL_RWops's
  /// `write` method appropriately, to simplify application development.
  ///
  /// Prior to SDL 2.0.10, this function was a macro.
  ///
  /// \param context a pointer to an SDL_RWops structure
  /// \param ptr a pointer to a buffer containing data to write
  /// \param size the size of an object to write, in bytes
  /// \param num the number of objects to write
  /// \returns the number of objects written, which will be less than **num** on
  /// error; call SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.10.
  ///
  /// \sa SDL_RWclose
  /// \sa SDL_RWFromConstMem
  /// \sa SDL_RWFromFile
  /// \sa SDL_RWFromFP
  /// \sa SDL_RWFromMem
  /// \sa SDL_RWread
  /// \sa SDL_RWseek
  int SDL_RWwrite(
    ffi.Pointer<SDL_RWops> context,
    ffi.Pointer<ffi.Void> ptr,
    int size,
    int num,
  ) {
    return _SDL_RWwrite(
      context,
      ptr,
      size,
      num,
    );
  }

  late final _SDL_RWwritePtr = _lookup<
      ffi.NativeFunction<
          size_t Function(ffi.Pointer<SDL_RWops>, ffi.Pointer<ffi.Void>, size_t,
              size_t)>>('SDL_RWwrite');
  late final _SDL_RWwrite = _SDL_RWwritePtr.asFunction<
      int Function(ffi.Pointer<SDL_RWops>, ffi.Pointer<ffi.Void>, int, int)>();

  /// Close and free an allocated SDL_RWops structure.
  ///
  /// SDL_RWclose() closes and cleans up the SDL_RWops stream. It releases any
  /// resources used by the stream and frees the SDL_RWops itself with
  /// SDL_FreeRW(). This returns 0 on success, or -1 if the stream failed to
  /// flush to its output (e.g. to disk).
  ///
  /// Note that if this fails to flush the stream to disk, this function reports
  /// an error, but the SDL_RWops is still invalid once this function returns.
  ///
  /// Prior to SDL 2.0.10, this function was a macro.
  ///
  /// \param context SDL_RWops structure to close
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.10.
  ///
  /// \sa SDL_RWFromConstMem
  /// \sa SDL_RWFromFile
  /// \sa SDL_RWFromFP
  /// \sa SDL_RWFromMem
  /// \sa SDL_RWread
  /// \sa SDL_RWseek
  /// \sa SDL_RWwrite
  int SDL_RWclose(
    ffi.Pointer<SDL_RWops> context,
  ) {
    return _SDL_RWclose(
      context,
    );
  }

  late final _SDL_RWclosePtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<SDL_RWops>)>>(
          'SDL_RWclose');
  late final _SDL_RWclose =
      _SDL_RWclosePtr.asFunction<int Function(ffi.Pointer<SDL_RWops>)>();

  /// Load all the data from an SDL data stream.
  ///
  /// The data is allocated with a zero byte at the end (null terminated) for
  /// convenience. This extra byte is not included in the value reported via
  /// `datasize`.
  ///
  /// The data should be freed with SDL_free().
  ///
  /// \param src the SDL_RWops to read all available data from
  /// \param datasize if not NULL, will store the number of bytes read
  /// \param freesrc if non-zero, calls SDL_RWclose() on `src` before returning
  /// \returns the data, or NULL if there was an error.
  ///
  /// \since This function is available since SDL 2.0.6.
  ffi.Pointer<ffi.Void> SDL_LoadFile_RW(
    ffi.Pointer<SDL_RWops> src,
    ffi.Pointer<size_t> datasize,
    int freesrc,
  ) {
    return _SDL_LoadFile_RW(
      src,
      datasize,
      freesrc,
    );
  }

  late final _SDL_LoadFile_RWPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Void> Function(ffi.Pointer<SDL_RWops>,
              ffi.Pointer<size_t>, ffi.Int32)>>('SDL_LoadFile_RW');
  late final _SDL_LoadFile_RW = _SDL_LoadFile_RWPtr.asFunction<
      ffi.Pointer<ffi.Void> Function(
          ffi.Pointer<SDL_RWops>, ffi.Pointer<size_t>, int)>();

  /// Load all the data from a file path.
  ///
  /// The data is allocated with a zero byte at the end (null terminated) for
  /// convenience. This extra byte is not included in the value reported via
  /// `datasize`.
  ///
  /// The data should be freed with SDL_free().
  ///
  /// Prior to SDL 2.0.10, this function was a macro wrapping around
  /// SDL_LoadFile_RW.
  ///
  /// \param file the path to read all available data from
  /// \param datasize if not NULL, will store the number of bytes read
  /// \returns the data, or NULL if there was an error.
  ///
  /// \since This function is available since SDL 2.0.10.
  ffi.Pointer<ffi.Void> SDL_LoadFile(
    ffi.Pointer<ffi.Int8> file,
    ffi.Pointer<size_t> datasize,
  ) {
    return _SDL_LoadFile(
      file,
      datasize,
    );
  }

  late final _SDL_LoadFilePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Void> Function(
              ffi.Pointer<ffi.Int8>, ffi.Pointer<size_t>)>>('SDL_LoadFile');
  late final _SDL_LoadFile = _SDL_LoadFilePtr.asFunction<
      ffi.Pointer<ffi.Void> Function(
          ffi.Pointer<ffi.Int8>, ffi.Pointer<size_t>)>();

  /// Use this function to read a byte from an SDL_RWops.
  ///
  /// \param src the SDL_RWops to read from
  /// \returns the read byte on success or 0 on failure; call SDL_GetError() for
  /// more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_WriteU8
  int SDL_ReadU8(
    ffi.Pointer<SDL_RWops> src,
  ) {
    return _SDL_ReadU8(
      src,
    );
  }

  late final _SDL_ReadU8Ptr =
      _lookup<ffi.NativeFunction<Uint8 Function(ffi.Pointer<SDL_RWops>)>>(
          'SDL_ReadU8');
  late final _SDL_ReadU8 =
      _SDL_ReadU8Ptr.asFunction<int Function(ffi.Pointer<SDL_RWops>)>();

  /// Use this function to read 16 bits of little-endian data from an SDL_RWops
  /// and return in native format.
  ///
  /// SDL byteswaps the data only if necessary, so the data returned will be in
  /// the native byte order.
  ///
  /// \param src the stream from which to read data
  /// \returns 16 bits of data in the native byte order of the platform.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_ReadBE16
  int SDL_ReadLE16(
    ffi.Pointer<SDL_RWops> src,
  ) {
    return _SDL_ReadLE16(
      src,
    );
  }

  late final _SDL_ReadLE16Ptr =
      _lookup<ffi.NativeFunction<Uint16 Function(ffi.Pointer<SDL_RWops>)>>(
          'SDL_ReadLE16');
  late final _SDL_ReadLE16 =
      _SDL_ReadLE16Ptr.asFunction<int Function(ffi.Pointer<SDL_RWops>)>();

  /// Use this function to read 16 bits of big-endian data from an SDL_RWops and
  /// return in native format.
  ///
  /// SDL byteswaps the data only if necessary, so the data returned will be in
  /// the native byte order.
  ///
  /// \param src the stream from which to read data
  /// \returns 16 bits of data in the native byte order of the platform.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_ReadLE16
  int SDL_ReadBE16(
    ffi.Pointer<SDL_RWops> src,
  ) {
    return _SDL_ReadBE16(
      src,
    );
  }

  late final _SDL_ReadBE16Ptr =
      _lookup<ffi.NativeFunction<Uint16 Function(ffi.Pointer<SDL_RWops>)>>(
          'SDL_ReadBE16');
  late final _SDL_ReadBE16 =
      _SDL_ReadBE16Ptr.asFunction<int Function(ffi.Pointer<SDL_RWops>)>();

  /// Use this function to read 32 bits of little-endian data from an SDL_RWops
  /// and return in native format.
  ///
  /// SDL byteswaps the data only if necessary, so the data returned will be in
  /// the native byte order.
  ///
  /// \param src the stream from which to read data
  /// \returns 32 bits of data in the native byte order of the platform.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_ReadBE32
  int SDL_ReadLE32(
    ffi.Pointer<SDL_RWops> src,
  ) {
    return _SDL_ReadLE32(
      src,
    );
  }

  late final _SDL_ReadLE32Ptr =
      _lookup<ffi.NativeFunction<Uint32 Function(ffi.Pointer<SDL_RWops>)>>(
          'SDL_ReadLE32');
  late final _SDL_ReadLE32 =
      _SDL_ReadLE32Ptr.asFunction<int Function(ffi.Pointer<SDL_RWops>)>();

  /// Use this function to read 32 bits of big-endian data from an SDL_RWops and
  /// return in native format.
  ///
  /// SDL byteswaps the data only if necessary, so the data returned will be in
  /// the native byte order.
  ///
  /// \param src the stream from which to read data
  /// \returns 32 bits of data in the native byte order of the platform.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_ReadLE32
  int SDL_ReadBE32(
    ffi.Pointer<SDL_RWops> src,
  ) {
    return _SDL_ReadBE32(
      src,
    );
  }

  late final _SDL_ReadBE32Ptr =
      _lookup<ffi.NativeFunction<Uint32 Function(ffi.Pointer<SDL_RWops>)>>(
          'SDL_ReadBE32');
  late final _SDL_ReadBE32 =
      _SDL_ReadBE32Ptr.asFunction<int Function(ffi.Pointer<SDL_RWops>)>();

  /// Use this function to read 64 bits of little-endian data from an SDL_RWops
  /// and return in native format.
  ///
  /// SDL byteswaps the data only if necessary, so the data returned will be in
  /// the native byte order.
  ///
  /// \param src the stream from which to read data
  /// \returns 64 bits of data in the native byte order of the platform.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_ReadBE64
  int SDL_ReadLE64(
    ffi.Pointer<SDL_RWops> src,
  ) {
    return _SDL_ReadLE64(
      src,
    );
  }

  late final _SDL_ReadLE64Ptr =
      _lookup<ffi.NativeFunction<Uint64 Function(ffi.Pointer<SDL_RWops>)>>(
          'SDL_ReadLE64');
  late final _SDL_ReadLE64 =
      _SDL_ReadLE64Ptr.asFunction<int Function(ffi.Pointer<SDL_RWops>)>();

  /// Use this function to read 64 bits of big-endian data from an SDL_RWops and
  /// return in native format.
  ///
  /// SDL byteswaps the data only if necessary, so the data returned will be in
  /// the native byte order.
  ///
  /// \param src the stream from which to read data
  /// \returns 64 bits of data in the native byte order of the platform.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_ReadLE64
  int SDL_ReadBE64(
    ffi.Pointer<SDL_RWops> src,
  ) {
    return _SDL_ReadBE64(
      src,
    );
  }

  late final _SDL_ReadBE64Ptr =
      _lookup<ffi.NativeFunction<Uint64 Function(ffi.Pointer<SDL_RWops>)>>(
          'SDL_ReadBE64');
  late final _SDL_ReadBE64 =
      _SDL_ReadBE64Ptr.asFunction<int Function(ffi.Pointer<SDL_RWops>)>();

  /// Use this function to write a byte to an SDL_RWops.
  ///
  /// \param dst the SDL_RWops to write to
  /// \param value the byte value to write
  /// \returns 1 on success or 0 on failure; call SDL_GetError() for more
  /// information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_ReadU8
  int SDL_WriteU8(
    ffi.Pointer<SDL_RWops> dst,
    int value,
  ) {
    return _SDL_WriteU8(
      dst,
      value,
    );
  }

  late final _SDL_WriteU8Ptr = _lookup<
          ffi.NativeFunction<size_t Function(ffi.Pointer<SDL_RWops>, Uint8)>>(
      'SDL_WriteU8');
  late final _SDL_WriteU8 =
      _SDL_WriteU8Ptr.asFunction<int Function(ffi.Pointer<SDL_RWops>, int)>();

  /// Use this function to write 16 bits in native format to a SDL_RWops as
  /// little-endian data.
  ///
  /// SDL byteswaps the data only if necessary, so the application always
  /// specifies native format, and the data written will be in little-endian
  /// format.
  ///
  /// \param dst the stream to which data will be written
  /// \param value the data to be written, in native format
  /// \returns 1 on successful write, 0 on error.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_WriteBE16
  int SDL_WriteLE16(
    ffi.Pointer<SDL_RWops> dst,
    int value,
  ) {
    return _SDL_WriteLE16(
      dst,
      value,
    );
  }

  late final _SDL_WriteLE16Ptr = _lookup<
          ffi.NativeFunction<size_t Function(ffi.Pointer<SDL_RWops>, Uint16)>>(
      'SDL_WriteLE16');
  late final _SDL_WriteLE16 =
      _SDL_WriteLE16Ptr.asFunction<int Function(ffi.Pointer<SDL_RWops>, int)>();

  /// Use this function to write 16 bits in native format to a SDL_RWops as
  /// big-endian data.
  ///
  /// SDL byteswaps the data only if necessary, so the application always
  /// specifies native format, and the data written will be in big-endian format.
  ///
  /// \param dst the stream to which data will be written
  /// \param value the data to be written, in native format
  /// \returns 1 on successful write, 0 on error.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_WriteLE16
  int SDL_WriteBE16(
    ffi.Pointer<SDL_RWops> dst,
    int value,
  ) {
    return _SDL_WriteBE16(
      dst,
      value,
    );
  }

  late final _SDL_WriteBE16Ptr = _lookup<
          ffi.NativeFunction<size_t Function(ffi.Pointer<SDL_RWops>, Uint16)>>(
      'SDL_WriteBE16');
  late final _SDL_WriteBE16 =
      _SDL_WriteBE16Ptr.asFunction<int Function(ffi.Pointer<SDL_RWops>, int)>();

  /// Use this function to write 32 bits in native format to a SDL_RWops as
  /// little-endian data.
  ///
  /// SDL byteswaps the data only if necessary, so the application always
  /// specifies native format, and the data written will be in little-endian
  /// format.
  ///
  /// \param dst the stream to which data will be written
  /// \param value the data to be written, in native format
  /// \returns 1 on successful write, 0 on error.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_WriteBE32
  int SDL_WriteLE32(
    ffi.Pointer<SDL_RWops> dst,
    int value,
  ) {
    return _SDL_WriteLE32(
      dst,
      value,
    );
  }

  late final _SDL_WriteLE32Ptr = _lookup<
          ffi.NativeFunction<size_t Function(ffi.Pointer<SDL_RWops>, Uint32)>>(
      'SDL_WriteLE32');
  late final _SDL_WriteLE32 =
      _SDL_WriteLE32Ptr.asFunction<int Function(ffi.Pointer<SDL_RWops>, int)>();

  /// Use this function to write 32 bits in native format to a SDL_RWops as
  /// big-endian data.
  ///
  /// SDL byteswaps the data only if necessary, so the application always
  /// specifies native format, and the data written will be in big-endian format.
  ///
  /// \param dst the stream to which data will be written
  /// \param value the data to be written, in native format
  /// \returns 1 on successful write, 0 on error.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_WriteLE32
  int SDL_WriteBE32(
    ffi.Pointer<SDL_RWops> dst,
    int value,
  ) {
    return _SDL_WriteBE32(
      dst,
      value,
    );
  }

  late final _SDL_WriteBE32Ptr = _lookup<
          ffi.NativeFunction<size_t Function(ffi.Pointer<SDL_RWops>, Uint32)>>(
      'SDL_WriteBE32');
  late final _SDL_WriteBE32 =
      _SDL_WriteBE32Ptr.asFunction<int Function(ffi.Pointer<SDL_RWops>, int)>();

  /// Use this function to write 64 bits in native format to a SDL_RWops as
  /// little-endian data.
  ///
  /// SDL byteswaps the data only if necessary, so the application always
  /// specifies native format, and the data written will be in little-endian
  /// format.
  ///
  /// \param dst the stream to which data will be written
  /// \param value the data to be written, in native format
  /// \returns 1 on successful write, 0 on error.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_WriteBE64
  int SDL_WriteLE64(
    ffi.Pointer<SDL_RWops> dst,
    int value,
  ) {
    return _SDL_WriteLE64(
      dst,
      value,
    );
  }

  late final _SDL_WriteLE64Ptr = _lookup<
          ffi.NativeFunction<size_t Function(ffi.Pointer<SDL_RWops>, Uint64)>>(
      'SDL_WriteLE64');
  late final _SDL_WriteLE64 =
      _SDL_WriteLE64Ptr.asFunction<int Function(ffi.Pointer<SDL_RWops>, int)>();

  /// Use this function to write 64 bits in native format to a SDL_RWops as
  /// big-endian data.
  ///
  /// SDL byteswaps the data only if necessary, so the application always
  /// specifies native format, and the data written will be in big-endian format.
  ///
  /// \param dst the stream to which data will be written
  /// \param value the data to be written, in native format
  /// \returns 1 on successful write, 0 on error.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_WriteLE64
  int SDL_WriteBE64(
    ffi.Pointer<SDL_RWops> dst,
    int value,
  ) {
    return _SDL_WriteBE64(
      dst,
      value,
    );
  }

  late final _SDL_WriteBE64Ptr = _lookup<
          ffi.NativeFunction<size_t Function(ffi.Pointer<SDL_RWops>, Uint64)>>(
      'SDL_WriteBE64');
  late final _SDL_WriteBE64 =
      _SDL_WriteBE64Ptr.asFunction<int Function(ffi.Pointer<SDL_RWops>, int)>();

  /// Use this function to get the number of built-in audio drivers.
  ///
  /// This function returns a hardcoded number. This never returns a negative
  /// value; if there are no drivers compiled into this build of SDL, this
  /// function returns zero. The presence of a driver in this list does not mean
  /// it will function, it just means SDL is capable of interacting with that
  /// interface. For example, a build of SDL might have esound support, but if
  /// there's no esound server available, SDL's esound driver would fail if used.
  ///
  /// By default, SDL tries all drivers, in its preferred order, until one is
  /// found to be usable.
  ///
  /// \returns the number of built-in audio drivers.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetAudioDriver
  int SDL_GetNumAudioDrivers() {
    return _SDL_GetNumAudioDrivers();
  }

  late final _SDL_GetNumAudioDriversPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function()>>(
          'SDL_GetNumAudioDrivers');
  late final _SDL_GetNumAudioDrivers =
      _SDL_GetNumAudioDriversPtr.asFunction<int Function()>();

  /// Use this function to get the name of a built in audio driver.
  ///
  /// The list of audio drivers is given in the order that they are normally
  /// initialized by default; the drivers that seem more reasonable to choose
  /// first (as far as the SDL developers believe) are earlier in the list.
  ///
  /// The names of drivers are all simple, low-ASCII identifiers, like "alsa",
  /// "coreaudio" or "xaudio2". These never have Unicode characters, and are not
  /// meant to be proper names.
  ///
  /// \param index the index of the audio driver; the value ranges from 0 to
  /// SDL_GetNumAudioDrivers() - 1
  /// \returns the name of the audio driver at the requested index, or NULL if an
  /// invalid index was specified.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetNumAudioDrivers
  ffi.Pointer<ffi.Int8> SDL_GetAudioDriver(
    int index,
  ) {
    return _SDL_GetAudioDriver(
      index,
    );
  }

  late final _SDL_GetAudioDriverPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Int8> Function(ffi.Int32)>>(
          'SDL_GetAudioDriver');
  late final _SDL_GetAudioDriver =
      _SDL_GetAudioDriverPtr.asFunction<ffi.Pointer<ffi.Int8> Function(int)>();

  /// Use this function to initialize a particular audio driver.
  ///
  /// This function is used internally, and should not be used unless you have a
  /// specific need to designate the audio driver you want to use. You should
  /// normally use SDL_Init() or SDL_InitSubSystem().
  ///
  /// \param driver_name the name of the desired audio driver
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_AudioQuit
  int SDL_AudioInit(
    ffi.Pointer<ffi.Int8> driver_name,
  ) {
    return _SDL_AudioInit(
      driver_name,
    );
  }

  late final _SDL_AudioInitPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<ffi.Int8>)>>(
          'SDL_AudioInit');
  late final _SDL_AudioInit =
      _SDL_AudioInitPtr.asFunction<int Function(ffi.Pointer<ffi.Int8>)>();

  /// Use this function to shut down audio if you initialized it with
  /// SDL_AudioInit().
  ///
  /// This function is used internally, and should not be used unless you have a
  /// specific need to specify the audio driver you want to use. You should
  /// normally use SDL_Quit() or SDL_QuitSubSystem().
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_AudioInit
  void SDL_AudioQuit() {
    return _SDL_AudioQuit();
  }

  late final _SDL_AudioQuitPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('SDL_AudioQuit');
  late final _SDL_AudioQuit = _SDL_AudioQuitPtr.asFunction<void Function()>();

  /// Get the name of the current audio driver.
  ///
  /// The returned string points to internal static memory and thus never becomes
  /// invalid, even if you quit the audio subsystem and initialize a new driver
  /// (although such a case would return a different static string from another
  /// call to this function, of course). As such, you should not modify or free
  /// the returned string.
  ///
  /// \returns the name of the current audio driver or NULL if no driver has been
  /// initialized.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_AudioInit
  ffi.Pointer<ffi.Int8> SDL_GetCurrentAudioDriver() {
    return _SDL_GetCurrentAudioDriver();
  }

  late final _SDL_GetCurrentAudioDriverPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Int8> Function()>>(
          'SDL_GetCurrentAudioDriver');
  late final _SDL_GetCurrentAudioDriver = _SDL_GetCurrentAudioDriverPtr
      .asFunction<ffi.Pointer<ffi.Int8> Function()>();

  /// This function is a legacy means of opening the audio device.
  ///
  /// This function remains for compatibility with SDL 1.2, but also because it's
  /// slightly easier to use than the new functions in SDL 2.0. The new, more
  /// powerful, and preferred way to do this is SDL_OpenAudioDevice().
  ///
  /// This function is roughly equivalent to:
  ///
  /// ```c
  /// SDL_OpenAudioDevice(NULL, 0, desired, obtained, SDL_AUDIO_ALLOW_ANY_CHANGE);
  /// ```
  ///
  /// With two notable exceptions:
  ///
  /// - If `obtained` is NULL, we use `desired` (and allow no changes), which
  /// means desired will be modified to have the correct values for silence,
  /// etc, and SDL will convert any differences between your app's specific
  /// request and the hardware behind the scenes.
  /// - The return value is always success or failure, and not a device ID, which
  /// means you can only have one device open at a time with this function.
  ///
  /// \param desired an SDL_AudioSpec structure representing the desired output
  /// format. Please refer to the SDL_OpenAudioDevice
  /// documentation for details on how to prepare this structure.
  /// \param obtained an SDL_AudioSpec structure filled in with the actual
  /// parameters, or NULL.
  /// \returns 0 if successful, placing the actual hardware parameters in the
  /// structure pointed to by `obtained`.
  ///
  /// If `obtained` is NULL, the audio data passed to the callback
  /// function will be guaranteed to be in the requested format, and
  /// will be automatically converted to the actual hardware audio
  /// format if necessary. If `obtained` is NULL, `desired` will have
  /// fields modified.
  ///
  /// This function returns a negative error code on failure to open the
  /// audio device or failure to set up the audio thread; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_CloseAudio
  /// \sa SDL_LockAudio
  /// \sa SDL_PauseAudio
  /// \sa SDL_UnlockAudio
  int SDL_OpenAudio(
    ffi.Pointer<SDL_AudioSpec> desired,
    ffi.Pointer<SDL_AudioSpec> obtained,
  ) {
    return _SDL_OpenAudio(
      desired,
      obtained,
    );
  }

  late final _SDL_OpenAudioPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_AudioSpec>,
              ffi.Pointer<SDL_AudioSpec>)>>('SDL_OpenAudio');
  late final _SDL_OpenAudio = _SDL_OpenAudioPtr.asFunction<
      int Function(ffi.Pointer<SDL_AudioSpec>, ffi.Pointer<SDL_AudioSpec>)>();

  /// Get the number of built-in audio devices.
  ///
  /// This function is only valid after successfully initializing the audio
  /// subsystem.
  ///
  /// Note that audio capture support is not implemented as of SDL 2.0.4, so the
  /// `iscapture` parameter is for future expansion and should always be zero for
  /// now.
  ///
  /// This function will return -1 if an explicit list of devices can't be
  /// determined. Returning -1 is not an error. For example, if SDL is set up to
  /// talk to a remote audio server, it can't list every one available on the
  /// Internet, but it will still allow a specific host to be specified in
  /// SDL_OpenAudioDevice().
  ///
  /// In many common cases, when this function returns a value <= 0, it can still
  /// successfully open the default device (NULL for first argument of
  /// SDL_OpenAudioDevice()).
  ///
  /// This function may trigger a complete redetect of available hardware. It
  /// should not be called for each iteration of a loop, but rather once at the
  /// start of a loop:
  ///
  /// ```c
  /// // Don't do this:
  /// for (int i = 0; i < SDL_GetNumAudioDevices(0); i++)
  ///
  /// // do this instead:
  /// const int count = SDL_GetNumAudioDevices(0);
  /// for (int i = 0; i < count; ++i) { do_something_here(); }
  /// ```
  ///
  /// \param iscapture zero to request playback devices, non-zero to request
  /// recording devices
  /// \returns the number of available devices exposed by the current driver or
  /// -1 if an explicit list of devices can't be determined. A return
  /// value of -1 does not necessarily mean an error condition.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetAudioDeviceName
  /// \sa SDL_OpenAudioDevice
  int SDL_GetNumAudioDevices(
    int iscapture,
  ) {
    return _SDL_GetNumAudioDevices(
      iscapture,
    );
  }

  late final _SDL_GetNumAudioDevicesPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Int32)>>(
          'SDL_GetNumAudioDevices');
  late final _SDL_GetNumAudioDevices =
      _SDL_GetNumAudioDevicesPtr.asFunction<int Function(int)>();

  /// Get the human-readable name of a specific audio device.
  ///
  /// This function is only valid after successfully initializing the audio
  /// subsystem. The values returned by this function reflect the latest call to
  /// SDL_GetNumAudioDevices(); re-call that function to redetect available
  /// hardware.
  ///
  /// The string returned by this function is UTF-8 encoded, read-only, and
  /// managed internally. You are not to free it. If you need to keep the string
  /// for any length of time, you should make your own copy of it, as it will be
  /// invalid next time any of several other SDL functions are called.
  ///
  /// \param index the index of the audio device; valid values range from 0 to
  /// SDL_GetNumAudioDevices() - 1
  /// \param iscapture non-zero to query the list of recording devices, zero to
  /// query the list of output devices.
  /// \returns the name of the audio device at the requested index, or NULL on
  /// error.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetNumAudioDevices
  ffi.Pointer<ffi.Int8> SDL_GetAudioDeviceName(
    int index,
    int iscapture,
  ) {
    return _SDL_GetAudioDeviceName(
      index,
      iscapture,
    );
  }

  late final _SDL_GetAudioDeviceNamePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Int8> Function(
              ffi.Int32, ffi.Int32)>>('SDL_GetAudioDeviceName');
  late final _SDL_GetAudioDeviceName = _SDL_GetAudioDeviceNamePtr.asFunction<
      ffi.Pointer<ffi.Int8> Function(int, int)>();

  /// Get the preferred audio format of a specific audio device.
  ///
  /// This function is only valid after a successfully initializing the audio
  /// subsystem. The values returned by this function reflect the latest call to
  /// SDL_GetNumAudioDevices(); re-call that function to redetect available
  /// hardware.
  ///
  /// `spec` will be filled with the sample rate, sample format, and channel
  /// count. All other values in the structure are filled with 0. When the
  /// supported struct members are 0, SDL was unable to get the property from the
  /// backend.
  ///
  /// \param index the index of the audio device; valid values range from 0 to
  /// SDL_GetNumAudioDevices() - 1
  /// \param iscapture non-zero to query the list of recording devices, zero to
  /// query the list of output devices.
  /// \param spec The SDL_AudioSpec to be initialized by this function.
  /// \returns 0 on success, nonzero on error
  ///
  /// \since This function is available since SDL 2.0.16.
  ///
  /// \sa SDL_GetNumAudioDevices
  int SDL_GetAudioDeviceSpec(
    int index,
    int iscapture,
    ffi.Pointer<SDL_AudioSpec> spec,
  ) {
    return _SDL_GetAudioDeviceSpec(
      index,
      iscapture,
      spec,
    );
  }

  late final _SDL_GetAudioDeviceSpecPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Int32, ffi.Int32,
              ffi.Pointer<SDL_AudioSpec>)>>('SDL_GetAudioDeviceSpec');
  late final _SDL_GetAudioDeviceSpec = _SDL_GetAudioDeviceSpecPtr.asFunction<
      int Function(int, int, ffi.Pointer<SDL_AudioSpec>)>();

  /// Open a specific audio device.
  ///
  /// SDL_OpenAudio(), unlike this function, always acts on device ID 1. As such,
  /// this function will never return a 1 so as not to conflict with the legacy
  /// function.
  ///
  /// Please note that SDL 2.0 before 2.0.5 did not support recording; as such,
  /// this function would fail if `iscapture` was not zero. Starting with SDL
  /// 2.0.5, recording is implemented and this value can be non-zero.
  ///
  /// Passing in a `device` name of NULL requests the most reasonable default
  /// (and is equivalent to what SDL_OpenAudio() does to choose a device). The
  /// `device` name is a UTF-8 string reported by SDL_GetAudioDeviceName(), but
  /// some drivers allow arbitrary and driver-specific strings, such as a
  /// hostname/IP address for a remote audio server, or a filename in the
  /// diskaudio driver.
  ///
  /// An opened audio device starts out paused, and should be enabled for playing
  /// by calling SDL_PauseAudioDevice(devid, 0) when you are ready for your audio
  /// callback function to be called. Since the audio driver may modify the
  /// requested size of the audio buffer, you should allocate any local mixing
  /// buffers after you open the audio device.
  ///
  /// The audio callback runs in a separate thread in most cases; you can prevent
  /// race conditions between your callback and other threads without fully
  /// pausing playback with SDL_LockAudioDevice(). For more information about the
  /// callback, see SDL_AudioSpec.
  ///
  /// Managing the audio spec via 'desired' and 'obtained':
  ///
  /// When filling in the desired audio spec structure:
  ///
  /// - `desired->freq` should be the frequency in sample-frames-per-second (Hz).
  /// - `desired->format` should be the audio format (`AUDIO_S16SYS`, etc).
  /// - `desired->samples` is the desired size of the audio buffer, in _sample
  /// frames_ (with stereo output, two samples--left and right--would make a
  /// single sample frame). This number should be a power of two, and may be
  /// adjusted by the audio driver to a value more suitable for the hardware.
  /// Good values seem to range between 512 and 8096 inclusive, depending on
  /// the application and CPU speed. Smaller values reduce latency, but can
  /// lead to underflow if the application is doing heavy processing and cannot
  /// fill the audio buffer in time. Note that the number of sample frames is
  /// directly related to time by the following formula: `ms =
  /// (sampleframes*1000)/freq`
  /// - `desired->size` is the size in _bytes_ of the audio buffer, and is
  /// calculated by SDL_OpenAudioDevice(). You don't initialize this.
  /// - `desired->silence` is the value used to set the buffer to silence, and is
  /// calculated by SDL_OpenAudioDevice(). You don't initialize this.
  /// - `desired->callback` should be set to a function that will be called when
  /// the audio device is ready for more data. It is passed a pointer to the
  /// audio buffer, and the length in bytes of the audio buffer. This function
  /// usually runs in a separate thread, and so you should protect data
  /// structures that it accesses by calling SDL_LockAudioDevice() and
  /// SDL_UnlockAudioDevice() in your code. Alternately, you may pass a NULL
  /// pointer here, and call SDL_QueueAudio() with some frequency, to queue
  /// more audio samples to be played (or for capture devices, call
  /// SDL_DequeueAudio() with some frequency, to obtain audio samples).
  /// - `desired->userdata` is passed as the first parameter to your callback
  /// function. If you passed a NULL callback, this value is ignored.
  ///
  /// `allowed_changes` can have the following flags OR'd together:
  ///
  /// - `SDL_AUDIO_ALLOW_FREQUENCY_CHANGE`
  /// - `SDL_AUDIO_ALLOW_FORMAT_CHANGE`
  /// - `SDL_AUDIO_ALLOW_CHANNELS_CHANGE`
  /// - `SDL_AUDIO_ALLOW_ANY_CHANGE`
  ///
  /// These flags specify how SDL should behave when a device cannot offer a
  /// specific feature. If the application requests a feature that the hardware
  /// doesn't offer, SDL will always try to get the closest equivalent.
  ///
  /// For example, if you ask for float32 audio format, but the sound card only
  /// supports int16, SDL will set the hardware to int16. If you had set
  /// SDL_AUDIO_ALLOW_FORMAT_CHANGE, SDL will change the format in the `obtained`
  /// structure. If that flag was *not* set, SDL will prepare to convert your
  /// callback's float32 audio to int16 before feeding it to the hardware and
  /// will keep the originally requested format in the `obtained` structure.
  ///
  /// The resulting audio specs, varying depending on hardware and on what
  /// changes were allowed, will then be written back to `obtained`.
  ///
  /// If your application can only handle one specific data format, pass a zero
  /// for `allowed_changes` and let SDL transparently handle any differences.
  ///
  /// \param device a UTF-8 string reported by SDL_GetAudioDeviceName() or a
  /// driver-specific name as appropriate. NULL requests the most
  /// reasonable default device.
  /// \param iscapture non-zero to specify a device should be opened for
  /// recording, not playback
  /// \param desired an SDL_AudioSpec structure representing the desired output
  /// format; see SDL_OpenAudio() for more information
  /// \param obtained an SDL_AudioSpec structure filled in with the actual output
  /// format; see SDL_OpenAudio() for more information
  /// \param allowed_changes 0, or one or more flags OR'd together
  /// \returns a valid device ID that is > 0 on success or 0 on failure; call
  /// SDL_GetError() for more information.
  ///
  /// For compatibility with SDL 1.2, this will never return 1, since
  /// SDL reserves that ID for the legacy SDL_OpenAudio() function.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_CloseAudioDevice
  /// \sa SDL_GetAudioDeviceName
  /// \sa SDL_LockAudioDevice
  /// \sa SDL_OpenAudio
  /// \sa SDL_PauseAudioDevice
  /// \sa SDL_UnlockAudioDevice
  int SDL_OpenAudioDevice(
    ffi.Pointer<ffi.Int8> device,
    int iscapture,
    ffi.Pointer<SDL_AudioSpec> desired,
    ffi.Pointer<SDL_AudioSpec> obtained,
    int allowed_changes,
  ) {
    return _SDL_OpenAudioDevice(
      device,
      iscapture,
      desired,
      obtained,
      allowed_changes,
    );
  }

  late final _SDL_OpenAudioDevicePtr = _lookup<
      ffi.NativeFunction<
          SDL_AudioDeviceID Function(
              ffi.Pointer<ffi.Int8>,
              ffi.Int32,
              ffi.Pointer<SDL_AudioSpec>,
              ffi.Pointer<SDL_AudioSpec>,
              ffi.Int32)>>('SDL_OpenAudioDevice');
  late final _SDL_OpenAudioDevice = _SDL_OpenAudioDevicePtr.asFunction<
      int Function(ffi.Pointer<ffi.Int8>, int, ffi.Pointer<SDL_AudioSpec>,
          ffi.Pointer<SDL_AudioSpec>, int)>();

  /// This function is a legacy means of querying the audio device.
  ///
  /// New programs might want to use SDL_GetAudioDeviceStatus() instead. This
  /// function is equivalent to calling...
  ///
  /// ```c
  /// SDL_GetAudioDeviceStatus(1);
  /// ```
  ///
  /// ...and is only useful if you used the legacy SDL_OpenAudio() function.
  ///
  /// \returns the SDL_AudioStatus of the audio device opened by SDL_OpenAudio().
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetAudioDeviceStatus
  int SDL_GetAudioStatus() {
    return _SDL_GetAudioStatus();
  }

  late final _SDL_GetAudioStatusPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function()>>('SDL_GetAudioStatus');
  late final _SDL_GetAudioStatus =
      _SDL_GetAudioStatusPtr.asFunction<int Function()>();

  /// Use this function to get the current audio state of an audio device.
  ///
  /// \param dev the ID of an audio device previously opened with
  /// SDL_OpenAudioDevice()
  /// \returns the SDL_AudioStatus of the specified audio device.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_PauseAudioDevice
  int SDL_GetAudioDeviceStatus(
    int dev,
  ) {
    return _SDL_GetAudioDeviceStatus(
      dev,
    );
  }

  late final _SDL_GetAudioDeviceStatusPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(SDL_AudioDeviceID)>>(
          'SDL_GetAudioDeviceStatus');
  late final _SDL_GetAudioDeviceStatus =
      _SDL_GetAudioDeviceStatusPtr.asFunction<int Function(int)>();

  /// This function is a legacy means of pausing the audio device.
  ///
  /// New programs might want to use SDL_PauseAudioDevice() instead. This
  /// function is equivalent to calling...
  ///
  /// ```c
  /// SDL_PauseAudioDevice(1, pause_on);
  /// ```
  ///
  /// ...and is only useful if you used the legacy SDL_OpenAudio() function.
  ///
  /// \param pause_on non-zero to pause, 0 to unpause
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetAudioStatus
  /// \sa SDL_PauseAudioDevice
  void SDL_PauseAudio(
    int pause_on,
  ) {
    return _SDL_PauseAudio(
      pause_on,
    );
  }

  late final _SDL_PauseAudioPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Int32)>>(
          'SDL_PauseAudio');
  late final _SDL_PauseAudio =
      _SDL_PauseAudioPtr.asFunction<void Function(int)>();

  /// Use this function to pause and unpause audio playback on a specified
  /// device.
  ///
  /// This function pauses and unpauses the audio callback processing for a given
  /// device. Newly-opened audio devices start in the paused state, so you must
  /// call this function with **pause_on**=0 after opening the specified audio
  /// device to start playing sound. This allows you to safely initialize data
  /// for your callback function after opening the audio device. Silence will be
  /// written to the audio device while paused, and the audio callback is
  /// guaranteed to not be called. Pausing one device does not prevent other
  /// unpaused devices from running their callbacks.
  ///
  /// Pausing state does not stack; even if you pause a device several times, a
  /// single unpause will start the device playing again, and vice versa. This is
  /// different from how SDL_LockAudioDevice() works.
  ///
  /// If you just need to protect a few variables from race conditions vs your
  /// callback, you shouldn't pause the audio device, as it will lead to dropouts
  /// in the audio playback. Instead, you should use SDL_LockAudioDevice().
  ///
  /// \param dev a device opened by SDL_OpenAudioDevice()
  /// \param pause_on non-zero to pause, 0 to unpause
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_LockAudioDevice
  void SDL_PauseAudioDevice(
    int dev,
    int pause_on,
  ) {
    return _SDL_PauseAudioDevice(
      dev,
      pause_on,
    );
  }

  late final _SDL_PauseAudioDevicePtr = _lookup<
          ffi.NativeFunction<ffi.Void Function(SDL_AudioDeviceID, ffi.Int32)>>(
      'SDL_PauseAudioDevice');
  late final _SDL_PauseAudioDevice =
      _SDL_PauseAudioDevicePtr.asFunction<void Function(int, int)>();

  /// Load the audio data of a WAVE file into memory.
  ///
  /// Loading a WAVE file requires `src`, `spec`, `audio_buf` and `audio_len` to
  /// be valid pointers. The entire data portion of the file is then loaded into
  /// memory and decoded if necessary.
  ///
  /// If `freesrc` is non-zero, the data source gets automatically closed and
  /// freed before the function returns.
  ///
  /// Supported formats are RIFF WAVE files with the formats PCM (8, 16, 24, and
  /// 32 bits), IEEE Float (32 bits), Microsoft ADPCM and IMA ADPCM (4 bits), and
  /// A-law and mu-law (8 bits). Other formats are currently unsupported and
  /// cause an error.
  ///
  /// If this function succeeds, the pointer returned by it is equal to `spec`
  /// and the pointer to the audio data allocated by the function is written to
  /// `audio_buf` and its length in bytes to `audio_len`. The SDL_AudioSpec
  /// members `freq`, `channels`, and `format` are set to the values of the audio
  /// data in the buffer. The `samples` member is set to a sane default and all
  /// others are set to zero.
  ///
  /// It's necessary to use SDL_FreeWAV() to free the audio data returned in
  /// `audio_buf` when it is no longer used.
  ///
  /// Because of the underspecification of the .WAV format, there are many
  /// problematic files in the wild that cause issues with strict decoders. To
  /// provide compatibility with these files, this decoder is lenient in regards
  /// to the truncation of the file, the fact chunk, and the size of the RIFF
  /// chunk. The hints `SDL_HINT_WAVE_RIFF_CHUNK_SIZE`,
  /// `SDL_HINT_WAVE_TRUNCATION`, and `SDL_HINT_WAVE_FACT_CHUNK` can be used to
  /// tune the behavior of the loading process.
  ///
  /// Any file that is invalid (due to truncation, corruption, or wrong values in
  /// the headers), too big, or unsupported causes an error. Additionally, any
  /// critical I/O error from the data source will terminate the loading process
  /// with an error. The function returns NULL on error and in all cases (with
  /// the exception of `src` being NULL), an appropriate error message will be
  /// set.
  ///
  /// It is required that the data source supports seeking.
  ///
  /// Example:
  ///
  /// ```c
  /// SDL_LoadWAV_RW(SDL_RWFromFile("sample.wav", "rb"), 1, &spec, &buf, &len);
  /// ```
  ///
  /// Note that the SDL_LoadWAV macro does this same thing for you, but in a less
  /// messy way:
  ///
  /// ```c
  /// SDL_LoadWAV("sample.wav", &spec, &buf, &len);
  /// ```
  ///
  /// \param src The data source for the WAVE data
  /// \param freesrc If non-zero, SDL will _always_ free the data source
  /// \param spec An SDL_AudioSpec that will be filled in with the wave file's
  /// format details
  /// \param audio_buf A pointer filled with the audio data, allocated by the
  /// function.
  /// \param audio_len A pointer filled with the length of the audio data buffer
  /// in bytes
  /// \returns This function, if successfully called, returns `spec`, which will
  /// be filled with the audio data format of the wave source data.
  /// `audio_buf` will be filled with a pointer to an allocated buffer
  /// containing the audio data, and `audio_len` is filled with the
  /// length of that audio buffer in bytes.
  ///
  /// This function returns NULL if the .WAV file cannot be opened, uses
  /// an unknown data format, or is corrupt; call SDL_GetError() for
  /// more information.
  ///
  /// When the application is done with the data returned in
  /// `audio_buf`, it should call SDL_FreeWAV() to dispose of it.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_FreeWAV
  /// \sa SDL_LoadWAV
  ffi.Pointer<SDL_AudioSpec> SDL_LoadWAV_RW(
    ffi.Pointer<SDL_RWops> src,
    int freesrc,
    ffi.Pointer<SDL_AudioSpec> spec,
    ffi.Pointer<ffi.Pointer<Uint8>> audio_buf,
    ffi.Pointer<Uint32> audio_len,
  ) {
    return _SDL_LoadWAV_RW(
      src,
      freesrc,
      spec,
      audio_buf,
      audio_len,
    );
  }

  late final _SDL_LoadWAV_RWPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<SDL_AudioSpec> Function(
              ffi.Pointer<SDL_RWops>,
              ffi.Int32,
              ffi.Pointer<SDL_AudioSpec>,
              ffi.Pointer<ffi.Pointer<Uint8>>,
              ffi.Pointer<Uint32>)>>('SDL_LoadWAV_RW');
  late final _SDL_LoadWAV_RW = _SDL_LoadWAV_RWPtr.asFunction<
      ffi.Pointer<SDL_AudioSpec> Function(
          ffi.Pointer<SDL_RWops>,
          int,
          ffi.Pointer<SDL_AudioSpec>,
          ffi.Pointer<ffi.Pointer<Uint8>>,
          ffi.Pointer<Uint32>)>();

  /// Free data previously allocated with SDL_LoadWAV() or SDL_LoadWAV_RW().
  ///
  /// After a WAVE file has been opened with SDL_LoadWAV() or SDL_LoadWAV_RW()
  /// its data can eventually be freed with SDL_FreeWAV(). It is safe to call
  /// this function with a NULL pointer.
  ///
  /// \param audio_buf a pointer to the buffer created by SDL_LoadWAV() or
  /// SDL_LoadWAV_RW()
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_LoadWAV
  /// \sa SDL_LoadWAV_RW
  void SDL_FreeWAV(
    ffi.Pointer<Uint8> audio_buf,
  ) {
    return _SDL_FreeWAV(
      audio_buf,
    );
  }

  late final _SDL_FreeWAVPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<Uint8>)>>(
          'SDL_FreeWAV');
  late final _SDL_FreeWAV =
      _SDL_FreeWAVPtr.asFunction<void Function(ffi.Pointer<Uint8>)>();

  /// Initialize an SDL_AudioCVT structure for conversion.
  ///
  /// Before an SDL_AudioCVT structure can be used to convert audio data it must
  /// be initialized with source and destination information.
  ///
  /// This function will zero out every field of the SDL_AudioCVT, so it must be
  /// called before the application fills in the final buffer information.
  ///
  /// Once this function has returned successfully, and reported that a
  /// conversion is necessary, the application fills in the rest of the fields in
  /// SDL_AudioCVT, now that it knows how large a buffer it needs to allocate,
  /// and then can call SDL_ConvertAudio() to complete the conversion.
  ///
  /// \param cvt an SDL_AudioCVT structure filled in with audio conversion
  /// information
  /// \param src_format the source format of the audio data; for more info see
  /// SDL_AudioFormat
  /// \param src_channels the number of channels in the source
  /// \param src_rate the frequency (sample-frames-per-second) of the source
  /// \param dst_format the destination format of the audio data; for more info
  /// see SDL_AudioFormat
  /// \param dst_channels the number of channels in the destination
  /// \param dst_rate the frequency (sample-frames-per-second) of the destination
  /// \returns 1 if the audio filter is prepared, 0 if no conversion is needed,
  /// or a negative error code on failure; call SDL_GetError() for more
  /// information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_ConvertAudio
  int SDL_BuildAudioCVT(
    ffi.Pointer<SDL_AudioCVT> cvt,
    int src_format,
    int src_channels,
    int src_rate,
    int dst_format,
    int dst_channels,
    int dst_rate,
  ) {
    return _SDL_BuildAudioCVT(
      cvt,
      src_format,
      src_channels,
      src_rate,
      dst_format,
      dst_channels,
      dst_rate,
    );
  }

  late final _SDL_BuildAudioCVTPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<SDL_AudioCVT>,
              SDL_AudioFormat,
              Uint8,
              ffi.Int32,
              SDL_AudioFormat,
              Uint8,
              ffi.Int32)>>('SDL_BuildAudioCVT');
  late final _SDL_BuildAudioCVT = _SDL_BuildAudioCVTPtr.asFunction<
      int Function(ffi.Pointer<SDL_AudioCVT>, int, int, int, int, int, int)>();

  /// Convert audio data to a desired audio format.
  ///
  /// This function does the actual audio data conversion, after the application
  /// has called SDL_BuildAudioCVT() to prepare the conversion information and
  /// then filled in the buffer details.
  ///
  /// Once the application has initialized the `cvt` structure using
  /// SDL_BuildAudioCVT(), allocated an audio buffer and filled it with audio
  /// data in the source format, this function will convert the buffer, in-place,
  /// to the desired format.
  ///
  /// The data conversion may go through several passes; any given pass may
  /// possibly temporarily increase the size of the data. For example, SDL might
  /// expand 16-bit data to 32 bits before resampling to a lower frequency,
  /// shrinking the data size after having grown it briefly. Since the supplied
  /// buffer will be both the source and destination, converting as necessary
  /// in-place, the application must allocate a buffer that will fully contain
  /// the data during its largest conversion pass. After SDL_BuildAudioCVT()
  /// returns, the application should set the `cvt->len` field to the size, in
  /// bytes, of the source data, and allocate a buffer that is `cvt->len *
  /// cvt->len_mult` bytes long for the `buf` field.
  ///
  /// The source data should be copied into this buffer before the call to
  /// SDL_ConvertAudio(). Upon successful return, this buffer will contain the
  /// converted audio, and `cvt->len_cvt` will be the size of the converted data,
  /// in bytes. Any bytes in the buffer past `cvt->len_cvt` are undefined once
  /// this function returns.
  ///
  /// \param cvt an SDL_AudioCVT structure that was previously set up by
  /// SDL_BuildAudioCVT().
  /// \returns 0 if the conversion was completed successfully or a negative error
  /// code on failure; call SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_BuildAudioCVT
  int SDL_ConvertAudio(
    ffi.Pointer<SDL_AudioCVT> cvt,
  ) {
    return _SDL_ConvertAudio(
      cvt,
    );
  }

  late final _SDL_ConvertAudioPtr = _lookup<
          ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<SDL_AudioCVT>)>>(
      'SDL_ConvertAudio');
  late final _SDL_ConvertAudio = _SDL_ConvertAudioPtr.asFunction<
      int Function(ffi.Pointer<SDL_AudioCVT>)>();

  /// Create a new audio stream.
  ///
  /// \param src_format The format of the source audio
  /// \param src_channels The number of channels of the source audio
  /// \param src_rate The sampling rate of the source audio
  /// \param dst_format The format of the desired audio output
  /// \param dst_channels The number of channels of the desired audio output
  /// \param dst_rate The sampling rate of the desired audio output
  /// \returns 0 on success, or -1 on error.
  ///
  /// \since This function is available since SDL 2.0.7.
  ///
  /// \sa SDL_AudioStreamPut
  /// \sa SDL_AudioStreamGet
  /// \sa SDL_AudioStreamAvailable
  /// \sa SDL_AudioStreamFlush
  /// \sa SDL_AudioStreamClear
  /// \sa SDL_FreeAudioStream
  ffi.Pointer<SDL_AudioStream1> SDL_NewAudioStream(
    int src_format,
    int src_channels,
    int src_rate,
    int dst_format,
    int dst_channels,
    int dst_rate,
  ) {
    return _SDL_NewAudioStream(
      src_format,
      src_channels,
      src_rate,
      dst_format,
      dst_channels,
      dst_rate,
    );
  }

  late final _SDL_NewAudioStreamPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<SDL_AudioStream1> Function(
              SDL_AudioFormat,
              Uint8,
              ffi.Int32,
              SDL_AudioFormat,
              Uint8,
              ffi.Int32)>>('SDL_NewAudioStream');
  late final _SDL_NewAudioStream = _SDL_NewAudioStreamPtr.asFunction<
      ffi.Pointer<SDL_AudioStream1> Function(int, int, int, int, int, int)>();

  /// Add data to be converted/resampled to the stream.
  ///
  /// \param stream The stream the audio data is being added to
  /// \param buf A pointer to the audio data to add
  /// \param len The number of bytes to write to the stream
  /// \returns 0 on success, or -1 on error.
  ///
  /// \since This function is available since SDL 2.0.7.
  ///
  /// \sa SDL_NewAudioStream
  /// \sa SDL_AudioStreamGet
  /// \sa SDL_AudioStreamAvailable
  /// \sa SDL_AudioStreamFlush
  /// \sa SDL_AudioStreamClear
  /// \sa SDL_FreeAudioStream
  int SDL_AudioStreamPut(
    ffi.Pointer<SDL_AudioStream1> stream,
    ffi.Pointer<ffi.Void> buf,
    int len,
  ) {
    return _SDL_AudioStreamPut(
      stream,
      buf,
      len,
    );
  }

  late final _SDL_AudioStreamPutPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_AudioStream1>,
              ffi.Pointer<ffi.Void>, ffi.Int32)>>('SDL_AudioStreamPut');
  late final _SDL_AudioStreamPut = _SDL_AudioStreamPutPtr.asFunction<
      int Function(
          ffi.Pointer<SDL_AudioStream1>, ffi.Pointer<ffi.Void>, int)>();

  /// Get converted/resampled data from the stream
  ///
  /// \param stream The stream the audio is being requested from
  /// \param buf A buffer to fill with audio data
  /// \param len The maximum number of bytes to fill
  /// \returns the number of bytes read from the stream, or -1 on error
  ///
  /// \since This function is available since SDL 2.0.7.
  ///
  /// \sa SDL_NewAudioStream
  /// \sa SDL_AudioStreamPut
  /// \sa SDL_AudioStreamAvailable
  /// \sa SDL_AudioStreamFlush
  /// \sa SDL_AudioStreamClear
  /// \sa SDL_FreeAudioStream
  int SDL_AudioStreamGet(
    ffi.Pointer<SDL_AudioStream1> stream,
    ffi.Pointer<ffi.Void> buf,
    int len,
  ) {
    return _SDL_AudioStreamGet(
      stream,
      buf,
      len,
    );
  }

  late final _SDL_AudioStreamGetPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_AudioStream1>,
              ffi.Pointer<ffi.Void>, ffi.Int32)>>('SDL_AudioStreamGet');
  late final _SDL_AudioStreamGet = _SDL_AudioStreamGetPtr.asFunction<
      int Function(
          ffi.Pointer<SDL_AudioStream1>, ffi.Pointer<ffi.Void>, int)>();

  /// Get the number of converted/resampled bytes available.
  ///
  /// The stream may be buffering data behind the scenes until it has enough to
  /// resample correctly, so this number might be lower than what you expect, or
  /// even be zero. Add more data or flush the stream if you need the data now.
  ///
  /// \since This function is available since SDL 2.0.7.
  ///
  /// \sa SDL_NewAudioStream
  /// \sa SDL_AudioStreamPut
  /// \sa SDL_AudioStreamGet
  /// \sa SDL_AudioStreamFlush
  /// \sa SDL_AudioStreamClear
  /// \sa SDL_FreeAudioStream
  int SDL_AudioStreamAvailable(
    ffi.Pointer<SDL_AudioStream1> stream,
  ) {
    return _SDL_AudioStreamAvailable(
      stream,
    );
  }

  late final _SDL_AudioStreamAvailablePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<SDL_AudioStream1>)>>('SDL_AudioStreamAvailable');
  late final _SDL_AudioStreamAvailable = _SDL_AudioStreamAvailablePtr
      .asFunction<int Function(ffi.Pointer<SDL_AudioStream1>)>();

  /// Tell the stream that you're done sending data, and anything being buffered
  /// should be converted/resampled and made available immediately.
  ///
  /// It is legal to add more data to a stream after flushing, but there will be
  /// audio gaps in the output. Generally this is intended to signal the end of
  /// input, so the complete output becomes available.
  ///
  /// \since This function is available since SDL 2.0.7.
  ///
  /// \sa SDL_NewAudioStream
  /// \sa SDL_AudioStreamPut
  /// \sa SDL_AudioStreamGet
  /// \sa SDL_AudioStreamAvailable
  /// \sa SDL_AudioStreamClear
  /// \sa SDL_FreeAudioStream
  int SDL_AudioStreamFlush(
    ffi.Pointer<SDL_AudioStream1> stream,
  ) {
    return _SDL_AudioStreamFlush(
      stream,
    );
  }

  late final _SDL_AudioStreamFlushPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<SDL_AudioStream1>)>>('SDL_AudioStreamFlush');
  late final _SDL_AudioStreamFlush = _SDL_AudioStreamFlushPtr.asFunction<
      int Function(ffi.Pointer<SDL_AudioStream1>)>();

  /// Clear any pending data in the stream without converting it
  ///
  /// \since This function is available since SDL 2.0.7.
  ///
  /// \sa SDL_NewAudioStream
  /// \sa SDL_AudioStreamPut
  /// \sa SDL_AudioStreamGet
  /// \sa SDL_AudioStreamAvailable
  /// \sa SDL_AudioStreamFlush
  /// \sa SDL_FreeAudioStream
  void SDL_AudioStreamClear(
    ffi.Pointer<SDL_AudioStream1> stream,
  ) {
    return _SDL_AudioStreamClear(
      stream,
    );
  }

  late final _SDL_AudioStreamClearPtr = _lookup<
          ffi.NativeFunction<ffi.Void Function(ffi.Pointer<SDL_AudioStream1>)>>(
      'SDL_AudioStreamClear');
  late final _SDL_AudioStreamClear = _SDL_AudioStreamClearPtr.asFunction<
      void Function(ffi.Pointer<SDL_AudioStream1>)>();

  /// Free an audio stream
  ///
  /// \since This function is available since SDL 2.0.7.
  ///
  /// \sa SDL_NewAudioStream
  /// \sa SDL_AudioStreamPut
  /// \sa SDL_AudioStreamGet
  /// \sa SDL_AudioStreamAvailable
  /// \sa SDL_AudioStreamFlush
  /// \sa SDL_AudioStreamClear
  void SDL_FreeAudioStream(
    ffi.Pointer<SDL_AudioStream1> stream,
  ) {
    return _SDL_FreeAudioStream(
      stream,
    );
  }

  late final _SDL_FreeAudioStreamPtr = _lookup<
          ffi.NativeFunction<ffi.Void Function(ffi.Pointer<SDL_AudioStream1>)>>(
      'SDL_FreeAudioStream');
  late final _SDL_FreeAudioStream = _SDL_FreeAudioStreamPtr.asFunction<
      void Function(ffi.Pointer<SDL_AudioStream1>)>();

  /// This function is a legacy means of mixing audio.
  ///
  /// This function is equivalent to calling...
  ///
  /// ```c
  /// SDL_MixAudioFormat(dst, src, format, len, volume);
  /// ```
  ///
  /// ...where `format` is the obtained format of the audio device from the
  /// legacy SDL_OpenAudio() function.
  ///
  /// \param dst the destination for the mixed audio
  /// \param src the source audio buffer to be mixed
  /// \param len the length of the audio buffer in bytes
  /// \param volume ranges from 0 - 128, and should be set to SDL_MIX_MAXVOLUME
  /// for full audio volume
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_MixAudioFormat
  void SDL_MixAudio(
    ffi.Pointer<Uint8> dst,
    ffi.Pointer<Uint8> src,
    int len,
    int volume,
  ) {
    return _SDL_MixAudio(
      dst,
      src,
      len,
      volume,
    );
  }

  late final _SDL_MixAudioPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<Uint8>, ffi.Pointer<Uint8>, Uint32,
              ffi.Int32)>>('SDL_MixAudio');
  late final _SDL_MixAudio = _SDL_MixAudioPtr.asFunction<
      void Function(ffi.Pointer<Uint8>, ffi.Pointer<Uint8>, int, int)>();

  /// Mix audio data in a specified format.
  ///
  /// This takes an audio buffer `src` of `len` bytes of `format` data and mixes
  /// it into `dst`, performing addition, volume adjustment, and overflow
  /// clipping. The buffer pointed to by `dst` must also be `len` bytes of
  /// `format` data.
  ///
  /// This is provided for convenience -- you can mix your own audio data.
  ///
  /// Do not use this function for mixing together more than two streams of
  /// sample data. The output from repeated application of this function may be
  /// distorted by clipping, because there is no accumulator with greater range
  /// than the input (not to mention this being an inefficient way of doing it).
  ///
  /// It is a common misconception that this function is required to write audio
  /// data to an output stream in an audio callback. While you can do that,
  /// SDL_MixAudioFormat() is really only needed when you're mixing a single
  /// audio stream with a volume adjustment.
  ///
  /// \param dst the destination for the mixed audio
  /// \param src the source audio buffer to be mixed
  /// \param format the SDL_AudioFormat structure representing the desired audio
  /// format
  /// \param len the length of the audio buffer in bytes
  /// \param volume ranges from 0 - 128, and should be set to SDL_MIX_MAXVOLUME
  /// for full audio volume
  ///
  /// \since This function is available since SDL 2.0.0.
  void SDL_MixAudioFormat(
    ffi.Pointer<Uint8> dst,
    ffi.Pointer<Uint8> src,
    int format,
    int len,
    int volume,
  ) {
    return _SDL_MixAudioFormat(
      dst,
      src,
      format,
      len,
      volume,
    );
  }

  late final _SDL_MixAudioFormatPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<Uint8>, ffi.Pointer<Uint8>,
              SDL_AudioFormat, Uint32, ffi.Int32)>>('SDL_MixAudioFormat');
  late final _SDL_MixAudioFormat = _SDL_MixAudioFormatPtr.asFunction<
      void Function(ffi.Pointer<Uint8>, ffi.Pointer<Uint8>, int, int, int)>();

  /// Queue more audio on non-callback devices.
  ///
  /// If you are looking to retrieve queued audio from a non-callback capture
  /// device, you want SDL_DequeueAudio() instead. SDL_QueueAudio() will return
  /// -1 to signify an error if you use it with capture devices.
  ///
  /// SDL offers two ways to feed audio to the device: you can either supply a
  /// callback that SDL triggers with some frequency to obtain more audio (pull
  /// method), or you can supply no callback, and then SDL will expect you to
  /// supply data at regular intervals (push method) with this function.
  ///
  /// There are no limits on the amount of data you can queue, short of
  /// exhaustion of address space. Queued data will drain to the device as
  /// necessary without further intervention from you. If the device needs audio
  /// but there is not enough queued, it will play silence to make up the
  /// difference. This means you will have skips in your audio playback if you
  /// aren't routinely queueing sufficient data.
  ///
  /// This function copies the supplied data, so you are safe to free it when the
  /// function returns. This function is thread-safe, but queueing to the same
  /// device from two threads at once does not promise which buffer will be
  /// queued first.
  ///
  /// You may not queue audio on a device that is using an application-supplied
  /// callback; doing so returns an error. You have to use the audio callback or
  /// queue audio with this function, but not both.
  ///
  /// You should not call SDL_LockAudio() on the device before queueing; SDL
  /// handles locking internally for this function.
  ///
  /// Note that SDL2 does not support planar audio. You will need to resample
  /// from planar audio formats into a non-planar one (see SDL_AudioFormat)
  /// before queuing audio.
  ///
  /// \param dev the device ID to which we will queue audio
  /// \param data the data to queue to the device for later playback
  /// \param len the number of bytes (not samples!) to which `data` points
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.4.
  ///
  /// \sa SDL_ClearQueuedAudio
  /// \sa SDL_GetQueuedAudioSize
  int SDL_QueueAudio(
    int dev,
    ffi.Pointer<ffi.Void> data,
    int len,
  ) {
    return _SDL_QueueAudio(
      dev,
      data,
      len,
    );
  }

  late final _SDL_QueueAudioPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(SDL_AudioDeviceID, ffi.Pointer<ffi.Void>,
              Uint32)>>('SDL_QueueAudio');
  late final _SDL_QueueAudio = _SDL_QueueAudioPtr.asFunction<
      int Function(int, ffi.Pointer<ffi.Void>, int)>();

  /// Dequeue more audio on non-callback devices.
  ///
  /// If you are looking to queue audio for output on a non-callback playback
  /// device, you want SDL_QueueAudio() instead. SDL_DequeueAudio() will always
  /// return 0 if you use it with playback devices.
  ///
  /// SDL offers two ways to retrieve audio from a capture device: you can either
  /// supply a callback that SDL triggers with some frequency as the device
  /// records more audio data, (push method), or you can supply no callback, and
  /// then SDL will expect you to retrieve data at regular intervals (pull
  /// method) with this function.
  ///
  /// There are no limits on the amount of data you can queue, short of
  /// exhaustion of address space. Data from the device will keep queuing as
  /// necessary without further intervention from you. This means you will
  /// eventually run out of memory if you aren't routinely dequeueing data.
  ///
  /// Capture devices will not queue data when paused; if you are expecting to
  /// not need captured audio for some length of time, use SDL_PauseAudioDevice()
  /// to stop the capture device from queueing more data. This can be useful
  /// during, say, level loading times. When unpaused, capture devices will start
  /// queueing data from that point, having flushed any capturable data available
  /// while paused.
  ///
  /// This function is thread-safe, but dequeueing from the same device from two
  /// threads at once does not promise which thread will dequeue data first.
  ///
  /// You may not dequeue audio from a device that is using an
  /// application-supplied callback; doing so returns an error. You have to use
  /// the audio callback, or dequeue audio with this function, but not both.
  ///
  /// You should not call SDL_LockAudio() on the device before dequeueing; SDL
  /// handles locking internally for this function.
  ///
  /// \param dev the device ID from which we will dequeue audio
  /// \param data a pointer into where audio data should be copied
  /// \param len the number of bytes (not samples!) to which (data) points
  /// \returns the number of bytes dequeued, which could be less than requested;
  /// call SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.5.
  ///
  /// \sa SDL_ClearQueuedAudio
  /// \sa SDL_GetQueuedAudioSize
  int SDL_DequeueAudio(
    int dev,
    ffi.Pointer<ffi.Void> data,
    int len,
  ) {
    return _SDL_DequeueAudio(
      dev,
      data,
      len,
    );
  }

  late final _SDL_DequeueAudioPtr = _lookup<
      ffi.NativeFunction<
          Uint32 Function(SDL_AudioDeviceID, ffi.Pointer<ffi.Void>,
              Uint32)>>('SDL_DequeueAudio');
  late final _SDL_DequeueAudio = _SDL_DequeueAudioPtr.asFunction<
      int Function(int, ffi.Pointer<ffi.Void>, int)>();

  /// Get the number of bytes of still-queued audio.
  ///
  /// For playback devices: this is the number of bytes that have been queued for
  /// playback with SDL_QueueAudio(), but have not yet been sent to the hardware.
  ///
  /// Once we've sent it to the hardware, this function can not decide the exact
  /// byte boundary of what has been played. It's possible that we just gave the
  /// hardware several kilobytes right before you called this function, but it
  /// hasn't played any of it yet, or maybe half of it, etc.
  ///
  /// For capture devices, this is the number of bytes that have been captured by
  /// the device and are waiting for you to dequeue. This number may grow at any
  /// time, so this only informs of the lower-bound of available data.
  ///
  /// You may not queue or dequeue audio on a device that is using an
  /// application-supplied callback; calling this function on such a device
  /// always returns 0. You have to use the audio callback or queue audio, but
  /// not both.
  ///
  /// You should not call SDL_LockAudio() on the device before querying; SDL
  /// handles locking internally for this function.
  ///
  /// \param dev the device ID of which we will query queued audio size
  /// \returns the number of bytes (not samples!) of queued audio.
  ///
  /// \since This function is available since SDL 2.0.4.
  ///
  /// \sa SDL_ClearQueuedAudio
  /// \sa SDL_QueueAudio
  /// \sa SDL_DequeueAudio
  int SDL_GetQueuedAudioSize(
    int dev,
  ) {
    return _SDL_GetQueuedAudioSize(
      dev,
    );
  }

  late final _SDL_GetQueuedAudioSizePtr =
      _lookup<ffi.NativeFunction<Uint32 Function(SDL_AudioDeviceID)>>(
          'SDL_GetQueuedAudioSize');
  late final _SDL_GetQueuedAudioSize =
      _SDL_GetQueuedAudioSizePtr.asFunction<int Function(int)>();

  /// Drop any queued audio data waiting to be sent to the hardware.
  ///
  /// Immediately after this call, SDL_GetQueuedAudioSize() will return 0. For
  /// output devices, the hardware will start playing silence if more audio isn't
  /// queued. For capture devices, the hardware will start filling the empty
  /// queue with new data if the capture device isn't paused.
  ///
  /// This will not prevent playback of queued audio that's already been sent to
  /// the hardware, as we can not undo that, so expect there to be some fraction
  /// of a second of audio that might still be heard. This can be useful if you
  /// want to, say, drop any pending music or any unprocessed microphone input
  /// during a level change in your game.
  ///
  /// You may not queue or dequeue audio on a device that is using an
  /// application-supplied callback; calling this function on such a device
  /// always returns 0. You have to use the audio callback or queue audio, but
  /// not both.
  ///
  /// You should not call SDL_LockAudio() on the device before clearing the
  /// queue; SDL handles locking internally for this function.
  ///
  /// This function always succeeds and thus returns void.
  ///
  /// \param dev the device ID of which to clear the audio queue
  ///
  /// \since This function is available since SDL 2.0.4.
  ///
  /// \sa SDL_GetQueuedAudioSize
  /// \sa SDL_QueueAudio
  /// \sa SDL_DequeueAudio
  void SDL_ClearQueuedAudio(
    int dev,
  ) {
    return _SDL_ClearQueuedAudio(
      dev,
    );
  }

  late final _SDL_ClearQueuedAudioPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(SDL_AudioDeviceID)>>(
          'SDL_ClearQueuedAudio');
  late final _SDL_ClearQueuedAudio =
      _SDL_ClearQueuedAudioPtr.asFunction<void Function(int)>();

  /// This function is a legacy means of locking the audio device.
  ///
  /// New programs might want to use SDL_LockAudioDevice() instead. This function
  /// is equivalent to calling...
  ///
  /// ```c
  /// SDL_LockAudioDevice(1);
  /// ```
  ///
  /// ...and is only useful if you used the legacy SDL_OpenAudio() function.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_LockAudioDevice
  /// \sa SDL_UnlockAudio
  /// \sa SDL_UnlockAudioDevice
  void SDL_LockAudio() {
    return _SDL_LockAudio();
  }

  late final _SDL_LockAudioPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('SDL_LockAudio');
  late final _SDL_LockAudio = _SDL_LockAudioPtr.asFunction<void Function()>();

  /// Use this function to lock out the audio callback function for a specified
  /// device.
  ///
  /// The lock manipulated by these functions protects the audio callback
  /// function specified in SDL_OpenAudioDevice(). During a
  /// SDL_LockAudioDevice()/SDL_UnlockAudioDevice() pair, you can be guaranteed
  /// that the callback function for that device is not running, even if the
  /// device is not paused. While a device is locked, any other unpaused,
  /// unlocked devices may still run their callbacks.
  ///
  /// Calling this function from inside your audio callback is unnecessary. SDL
  /// obtains this lock before calling your function, and releases it when the
  /// function returns.
  ///
  /// You should not hold the lock longer than absolutely necessary. If you hold
  /// it too long, you'll experience dropouts in your audio playback. Ideally,
  /// your application locks the device, sets a few variables and unlocks again.
  /// Do not do heavy work while holding the lock for a device.
  ///
  /// It is safe to lock the audio device multiple times, as long as you unlock
  /// it an equivalent number of times. The callback will not run until the
  /// device has been unlocked completely in this way. If your application fails
  /// to unlock the device appropriately, your callback will never run, you might
  /// hear repeating bursts of audio, and SDL_CloseAudioDevice() will probably
  /// deadlock.
  ///
  /// Internally, the audio device lock is a mutex; if you lock from two threads
  /// at once, not only will you block the audio callback, you'll block the other
  /// thread.
  ///
  /// \param dev the ID of the device to be locked
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_UnlockAudioDevice
  void SDL_LockAudioDevice(
    int dev,
  ) {
    return _SDL_LockAudioDevice(
      dev,
    );
  }

  late final _SDL_LockAudioDevicePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(SDL_AudioDeviceID)>>(
          'SDL_LockAudioDevice');
  late final _SDL_LockAudioDevice =
      _SDL_LockAudioDevicePtr.asFunction<void Function(int)>();

  /// This function is a legacy means of unlocking the audio device.
  ///
  /// New programs might want to use SDL_UnlockAudioDevice() instead. This
  /// function is equivalent to calling...
  ///
  /// ```c
  /// SDL_UnlockAudioDevice(1);
  /// ```
  ///
  /// ...and is only useful if you used the legacy SDL_OpenAudio() function.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_LockAudio
  /// \sa SDL_UnlockAudioDevice
  void SDL_UnlockAudio() {
    return _SDL_UnlockAudio();
  }

  late final _SDL_UnlockAudioPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('SDL_UnlockAudio');
  late final _SDL_UnlockAudio =
      _SDL_UnlockAudioPtr.asFunction<void Function()>();

  /// Use this function to unlock the audio callback function for a specified
  /// device.
  ///
  /// This function should be paired with a previous SDL_LockAudioDevice() call.
  ///
  /// \param dev the ID of the device to be unlocked
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_LockAudioDevice
  void SDL_UnlockAudioDevice(
    int dev,
  ) {
    return _SDL_UnlockAudioDevice(
      dev,
    );
  }

  late final _SDL_UnlockAudioDevicePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(SDL_AudioDeviceID)>>(
          'SDL_UnlockAudioDevice');
  late final _SDL_UnlockAudioDevice =
      _SDL_UnlockAudioDevicePtr.asFunction<void Function(int)>();

  /// This function is a legacy means of closing the audio device.
  ///
  /// This function is equivalent to calling...
  ///
  /// ```c
  /// SDL_CloseAudioDevice(1);
  /// ```
  ///
  /// ...and is only useful if you used the legacy SDL_OpenAudio() function.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_OpenAudio
  void SDL_CloseAudio() {
    return _SDL_CloseAudio();
  }

  late final _SDL_CloseAudioPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('SDL_CloseAudio');
  late final _SDL_CloseAudio = _SDL_CloseAudioPtr.asFunction<void Function()>();

  /// Use this function to shut down audio processing and close the audio device.
  ///
  /// The application should close open audio devices once they are no longer
  /// needed. Calling this function will wait until the device's audio callback
  /// is not running, release the audio hardware and then clean up internal
  /// state. No further audio will play from this device once this function
  /// returns.
  ///
  /// This function may block briefly while pending audio data is played by the
  /// hardware, so that applications don't drop the last buffer of data they
  /// supplied.
  ///
  /// The device ID is invalid as soon as the device is closed, and is eligible
  /// for reuse in a new SDL_OpenAudioDevice() call immediately.
  ///
  /// \param dev an audio device previously opened with SDL_OpenAudioDevice()
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_OpenAudioDevice
  void SDL_CloseAudioDevice(
    int dev,
  ) {
    return _SDL_CloseAudioDevice(
      dev,
    );
  }

  late final _SDL_CloseAudioDevicePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(SDL_AudioDeviceID)>>(
          'SDL_CloseAudioDevice');
  late final _SDL_CloseAudioDevice =
      _SDL_CloseAudioDevicePtr.asFunction<void Function(int)>();

  /// Put UTF-8 text into the clipboard.
  ///
  /// \param text the text to store in the clipboard
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetClipboardText
  /// \sa SDL_HasClipboardText
  int SDL_SetClipboardText(
    ffi.Pointer<ffi.Int8> text,
  ) {
    return _SDL_SetClipboardText(
      text,
    );
  }

  late final _SDL_SetClipboardTextPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<ffi.Int8>)>>(
          'SDL_SetClipboardText');
  late final _SDL_SetClipboardText = _SDL_SetClipboardTextPtr.asFunction<
      int Function(ffi.Pointer<ffi.Int8>)>();

  /// Get UTF-8 text from the clipboard, which must be freed with SDL_free().
  ///
  /// This functions returns empty string if there was not enough memory left for
  /// a copy of the clipboard's content.
  ///
  /// \returns the clipboard text on success or an empty string on failure; call
  /// SDL_GetError() for more information. Caller must call SDL_free()
  /// on the returned pointer when done with it (even if there was an
  /// error).
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_HasClipboardText
  /// \sa SDL_SetClipboardText
  ffi.Pointer<ffi.Int8> SDL_GetClipboardText() {
    return _SDL_GetClipboardText();
  }

  late final _SDL_GetClipboardTextPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Int8> Function()>>(
          'SDL_GetClipboardText');
  late final _SDL_GetClipboardText =
      _SDL_GetClipboardTextPtr.asFunction<ffi.Pointer<ffi.Int8> Function()>();

  /// Query whether the clipboard exists and contains a non-empty text string.
  ///
  /// \returns SDL_TRUE if the clipboard has text, or SDL_FALSE if it does not.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetClipboardText
  /// \sa SDL_SetClipboardText
  int SDL_HasClipboardText() {
    return _SDL_HasClipboardText();
  }

  late final _SDL_HasClipboardTextPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function()>>('SDL_HasClipboardText');
  late final _SDL_HasClipboardText =
      _SDL_HasClipboardTextPtr.asFunction<int Function()>();

  /// Get the number of CPU cores available.
  ///
  /// \returns the total number of logical CPU cores. On CPUs that include
  /// technologies such as hyperthreading, the number of logical cores
  /// may be more than the number of physical cores.
  ///
  /// \since This function is available since SDL 2.0.0.
  int SDL_GetCPUCount() {
    return _SDL_GetCPUCount();
  }

  late final _SDL_GetCPUCountPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function()>>('SDL_GetCPUCount');
  late final _SDL_GetCPUCount =
      _SDL_GetCPUCountPtr.asFunction<int Function()>();

  /// Determine the L1 cache line size of the CPU.
  ///
  /// This is useful for determining multi-threaded structure padding or SIMD
  /// prefetch sizes.
  ///
  /// \returns the L1 cache line size of the CPU, in bytes.
  ///
  /// \since This function is available since SDL 2.0.0.
  int SDL_GetCPUCacheLineSize() {
    return _SDL_GetCPUCacheLineSize();
  }

  late final _SDL_GetCPUCacheLineSizePtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function()>>(
          'SDL_GetCPUCacheLineSize');
  late final _SDL_GetCPUCacheLineSize =
      _SDL_GetCPUCacheLineSizePtr.asFunction<int Function()>();

  /// Determine whether the CPU has the RDTSC instruction.
  ///
  /// This always returns false on CPUs that aren't using Intel instruction sets.
  ///
  /// \returns SDL_TRUE if the CPU has the RDTSC instruction or SDL_FALSE if not.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_Has3DNow
  /// \sa SDL_HasAltiVec
  /// \sa SDL_HasAVX
  /// \sa SDL_HasAVX2
  /// \sa SDL_HasMMX
  /// \sa SDL_HasSSE
  /// \sa SDL_HasSSE2
  /// \sa SDL_HasSSE3
  /// \sa SDL_HasSSE41
  /// \sa SDL_HasSSE42
  int SDL_HasRDTSC() {
    return _SDL_HasRDTSC();
  }

  late final _SDL_HasRDTSCPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function()>>('SDL_HasRDTSC');
  late final _SDL_HasRDTSC = _SDL_HasRDTSCPtr.asFunction<int Function()>();

  /// Determine whether the CPU has AltiVec features.
  ///
  /// This always returns false on CPUs that aren't using PowerPC instruction
  /// sets.
  ///
  /// \returns SDL_TRUE if the CPU has AltiVec features or SDL_FALSE if not.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_Has3DNow
  /// \sa SDL_HasAVX
  /// \sa SDL_HasAVX2
  /// \sa SDL_HasMMX
  /// \sa SDL_HasRDTSC
  /// \sa SDL_HasSSE
  /// \sa SDL_HasSSE2
  /// \sa SDL_HasSSE3
  /// \sa SDL_HasSSE41
  /// \sa SDL_HasSSE42
  int SDL_HasAltiVec() {
    return _SDL_HasAltiVec();
  }

  late final _SDL_HasAltiVecPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function()>>('SDL_HasAltiVec');
  late final _SDL_HasAltiVec = _SDL_HasAltiVecPtr.asFunction<int Function()>();

  /// Determine whether the CPU has MMX features.
  ///
  /// This always returns false on CPUs that aren't using Intel instruction sets.
  ///
  /// \returns SDL_TRUE if the CPU has MMX features or SDL_FALSE if not.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_Has3DNow
  /// \sa SDL_HasAltiVec
  /// \sa SDL_HasAVX
  /// \sa SDL_HasAVX2
  /// \sa SDL_HasRDTSC
  /// \sa SDL_HasSSE
  /// \sa SDL_HasSSE2
  /// \sa SDL_HasSSE3
  /// \sa SDL_HasSSE41
  /// \sa SDL_HasSSE42
  int SDL_HasMMX() {
    return _SDL_HasMMX();
  }

  late final _SDL_HasMMXPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function()>>('SDL_HasMMX');
  late final _SDL_HasMMX = _SDL_HasMMXPtr.asFunction<int Function()>();

  /// Determine whether the CPU has 3DNow! features.
  ///
  /// This always returns false on CPUs that aren't using AMD instruction sets.
  ///
  /// \returns SDL_TRUE if the CPU has 3DNow! features or SDL_FALSE if not.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_HasAltiVec
  /// \sa SDL_HasAVX
  /// \sa SDL_HasAVX2
  /// \sa SDL_HasMMX
  /// \sa SDL_HasRDTSC
  /// \sa SDL_HasSSE
  /// \sa SDL_HasSSE2
  /// \sa SDL_HasSSE3
  /// \sa SDL_HasSSE41
  /// \sa SDL_HasSSE42
  int SDL_Has3DNow() {
    return _SDL_Has3DNow();
  }

  late final _SDL_Has3DNowPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function()>>('SDL_Has3DNow');
  late final _SDL_Has3DNow = _SDL_Has3DNowPtr.asFunction<int Function()>();

  /// Determine whether the CPU has SSE features.
  ///
  /// This always returns false on CPUs that aren't using Intel instruction sets.
  ///
  /// \returns SDL_TRUE if the CPU has SSE features or SDL_FALSE if not.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_Has3DNow
  /// \sa SDL_HasAltiVec
  /// \sa SDL_HasAVX
  /// \sa SDL_HasAVX2
  /// \sa SDL_HasMMX
  /// \sa SDL_HasRDTSC
  /// \sa SDL_HasSSE2
  /// \sa SDL_HasSSE3
  /// \sa SDL_HasSSE41
  /// \sa SDL_HasSSE42
  int SDL_HasSSE() {
    return _SDL_HasSSE();
  }

  late final _SDL_HasSSEPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function()>>('SDL_HasSSE');
  late final _SDL_HasSSE = _SDL_HasSSEPtr.asFunction<int Function()>();

  /// Determine whether the CPU has SSE2 features.
  ///
  /// This always returns false on CPUs that aren't using Intel instruction sets.
  ///
  /// \returns SDL_TRUE if the CPU has SSE2 features or SDL_FALSE if not.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_Has3DNow
  /// \sa SDL_HasAltiVec
  /// \sa SDL_HasAVX
  /// \sa SDL_HasAVX2
  /// \sa SDL_HasMMX
  /// \sa SDL_HasRDTSC
  /// \sa SDL_HasSSE
  /// \sa SDL_HasSSE3
  /// \sa SDL_HasSSE41
  /// \sa SDL_HasSSE42
  int SDL_HasSSE2() {
    return _SDL_HasSSE2();
  }

  late final _SDL_HasSSE2Ptr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function()>>('SDL_HasSSE2');
  late final _SDL_HasSSE2 = _SDL_HasSSE2Ptr.asFunction<int Function()>();

  /// Determine whether the CPU has SSE3 features.
  ///
  /// This always returns false on CPUs that aren't using Intel instruction sets.
  ///
  /// \returns SDL_TRUE if the CPU has SSE3 features or SDL_FALSE if not.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_Has3DNow
  /// \sa SDL_HasAltiVec
  /// \sa SDL_HasAVX
  /// \sa SDL_HasAVX2
  /// \sa SDL_HasMMX
  /// \sa SDL_HasRDTSC
  /// \sa SDL_HasSSE
  /// \sa SDL_HasSSE2
  /// \sa SDL_HasSSE41
  /// \sa SDL_HasSSE42
  int SDL_HasSSE3() {
    return _SDL_HasSSE3();
  }

  late final _SDL_HasSSE3Ptr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function()>>('SDL_HasSSE3');
  late final _SDL_HasSSE3 = _SDL_HasSSE3Ptr.asFunction<int Function()>();

  /// Determine whether the CPU has SSE4.1 features.
  ///
  /// This always returns false on CPUs that aren't using Intel instruction sets.
  ///
  /// \returns SDL_TRUE if the CPU has SSE4.1 features or SDL_FALSE if not.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_Has3DNow
  /// \sa SDL_HasAltiVec
  /// \sa SDL_HasAVX
  /// \sa SDL_HasAVX2
  /// \sa SDL_HasMMX
  /// \sa SDL_HasRDTSC
  /// \sa SDL_HasSSE
  /// \sa SDL_HasSSE2
  /// \sa SDL_HasSSE3
  /// \sa SDL_HasSSE42
  int SDL_HasSSE41() {
    return _SDL_HasSSE41();
  }

  late final _SDL_HasSSE41Ptr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function()>>('SDL_HasSSE41');
  late final _SDL_HasSSE41 = _SDL_HasSSE41Ptr.asFunction<int Function()>();

  /// Determine whether the CPU has SSE4.2 features.
  ///
  /// This always returns false on CPUs that aren't using Intel instruction sets.
  ///
  /// \returns SDL_TRUE if the CPU has SSE4.2 features or SDL_FALSE if not.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_Has3DNow
  /// \sa SDL_HasAltiVec
  /// \sa SDL_HasAVX
  /// \sa SDL_HasAVX2
  /// \sa SDL_HasMMX
  /// \sa SDL_HasRDTSC
  /// \sa SDL_HasSSE
  /// \sa SDL_HasSSE2
  /// \sa SDL_HasSSE3
  /// \sa SDL_HasSSE41
  int SDL_HasSSE42() {
    return _SDL_HasSSE42();
  }

  late final _SDL_HasSSE42Ptr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function()>>('SDL_HasSSE42');
  late final _SDL_HasSSE42 = _SDL_HasSSE42Ptr.asFunction<int Function()>();

  /// Determine whether the CPU has AVX features.
  ///
  /// This always returns false on CPUs that aren't using Intel instruction sets.
  ///
  /// \returns SDL_TRUE if the CPU has AVX features or SDL_FALSE if not.
  ///
  /// \since This function is available since SDL 2.0.2.
  ///
  /// \sa SDL_Has3DNow
  /// \sa SDL_HasAltiVec
  /// \sa SDL_HasAVX2
  /// \sa SDL_HasMMX
  /// \sa SDL_HasRDTSC
  /// \sa SDL_HasSSE
  /// \sa SDL_HasSSE2
  /// \sa SDL_HasSSE3
  /// \sa SDL_HasSSE41
  /// \sa SDL_HasSSE42
  int SDL_HasAVX() {
    return _SDL_HasAVX();
  }

  late final _SDL_HasAVXPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function()>>('SDL_HasAVX');
  late final _SDL_HasAVX = _SDL_HasAVXPtr.asFunction<int Function()>();

  /// Determine whether the CPU has AVX2 features.
  ///
  /// This always returns false on CPUs that aren't using Intel instruction sets.
  ///
  /// \returns SDL_TRUE if the CPU has AVX2 features or SDL_FALSE if not.
  ///
  /// \since This function is available since SDL 2.0.4.
  ///
  /// \sa SDL_Has3DNow
  /// \sa SDL_HasAltiVec
  /// \sa SDL_HasAVX
  /// \sa SDL_HasMMX
  /// \sa SDL_HasRDTSC
  /// \sa SDL_HasSSE
  /// \sa SDL_HasSSE2
  /// \sa SDL_HasSSE3
  /// \sa SDL_HasSSE41
  /// \sa SDL_HasSSE42
  int SDL_HasAVX2() {
    return _SDL_HasAVX2();
  }

  late final _SDL_HasAVX2Ptr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function()>>('SDL_HasAVX2');
  late final _SDL_HasAVX2 = _SDL_HasAVX2Ptr.asFunction<int Function()>();

  /// Determine whether the CPU has AVX-512F (foundation) features.
  ///
  /// This always returns false on CPUs that aren't using Intel instruction sets.
  ///
  /// \returns SDL_TRUE if the CPU has AVX-512F features or SDL_FALSE if not.
  ///
  /// \since This function is available since SDL 2.0.9.
  ///
  /// \sa SDL_HasAVX
  int SDL_HasAVX512F() {
    return _SDL_HasAVX512F();
  }

  late final _SDL_HasAVX512FPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function()>>('SDL_HasAVX512F');
  late final _SDL_HasAVX512F = _SDL_HasAVX512FPtr.asFunction<int Function()>();

  /// Determine whether the CPU has ARM SIMD (ARMv6) features.
  ///
  /// This is different from ARM NEON, which is a different instruction set.
  ///
  /// This always returns false on CPUs that aren't using ARM instruction sets.
  ///
  /// \returns SDL_TRUE if the CPU has ARM SIMD features or SDL_FALSE if not.
  ///
  /// \since This function is available since SDL 2.0.12.
  ///
  /// \sa SDL_HasNEON
  int SDL_HasARMSIMD() {
    return _SDL_HasARMSIMD();
  }

  late final _SDL_HasARMSIMDPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function()>>('SDL_HasARMSIMD');
  late final _SDL_HasARMSIMD = _SDL_HasARMSIMDPtr.asFunction<int Function()>();

  /// Determine whether the CPU has NEON (ARM SIMD) features.
  ///
  /// This always returns false on CPUs that aren't using ARM instruction sets.
  ///
  /// \returns SDL_TRUE if the CPU has ARM NEON features or SDL_FALSE if not.
  ///
  /// \since This function is available since SDL 2.0.6.
  int SDL_HasNEON() {
    return _SDL_HasNEON();
  }

  late final _SDL_HasNEONPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function()>>('SDL_HasNEON');
  late final _SDL_HasNEON = _SDL_HasNEONPtr.asFunction<int Function()>();

  /// Get the amount of RAM configured in the system.
  ///
  /// \returns the amount of RAM configured in the system in MB.
  ///
  /// \since This function is available since SDL 2.0.1.
  int SDL_GetSystemRAM() {
    return _SDL_GetSystemRAM();
  }

  late final _SDL_GetSystemRAMPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function()>>('SDL_GetSystemRAM');
  late final _SDL_GetSystemRAM =
      _SDL_GetSystemRAMPtr.asFunction<int Function()>();

  /// Report the alignment this system needs for SIMD allocations.
  ///
  /// This will return the minimum number of bytes to which a pointer must be
  /// aligned to be compatible with SIMD instructions on the current machine. For
  /// example, if the machine supports SSE only, it will return 16, but if it
  /// supports AVX-512F, it'll return 64 (etc). This only reports values for
  /// instruction sets SDL knows about, so if your SDL build doesn't have
  /// SDL_HasAVX512F(), then it might return 16 for the SSE support it sees and
  /// not 64 for the AVX-512 instructions that exist but SDL doesn't know about.
  /// Plan accordingly.
  ///
  /// \returns the alignment in bytes needed for available, known SIMD
  /// instructions.
  ///
  /// \since This function is available since SDL 2.0.10.
  int SDL_SIMDGetAlignment() {
    return _SDL_SIMDGetAlignment();
  }

  late final _SDL_SIMDGetAlignmentPtr =
      _lookup<ffi.NativeFunction<size_t Function()>>('SDL_SIMDGetAlignment');
  late final _SDL_SIMDGetAlignment =
      _SDL_SIMDGetAlignmentPtr.asFunction<int Function()>();

  /// Allocate memory in a SIMD-friendly way.
  ///
  /// This will allocate a block of memory that is suitable for use with SIMD
  /// instructions. Specifically, it will be properly aligned and padded for the
  /// system's supported vector instructions.
  ///
  /// The memory returned will be padded such that it is safe to read or write an
  /// incomplete vector at the end of the memory block. This can be useful so you
  /// don't have to drop back to a scalar fallback at the end of your SIMD
  /// processing loop to deal with the final elements without overflowing the
  /// allocated buffer.
  ///
  /// You must free this memory with SDL_FreeSIMD(), not free() or SDL_free() or
  /// delete[], etc.
  ///
  /// Note that SDL will only deal with SIMD instruction sets it is aware of; for
  /// example, SDL 2.0.8 knows that SSE wants 16-byte vectors (SDL_HasSSE()), and
  /// AVX2 wants 32 bytes (SDL_HasAVX2()), but doesn't know that AVX-512 wants
  /// 64. To be clear: if you can't decide to use an instruction set with an
  /// SDL_Has*() function, don't use that instruction set with memory allocated
  /// through here.
  ///
  /// SDL_AllocSIMD(0) will return a non-NULL pointer, assuming the system isn't
  /// out of memory, but you are not allowed to dereference it (because you only
  /// own zero bytes of that buffer).
  ///
  /// \param len The length, in bytes, of the block to allocate. The actual
  /// allocated block might be larger due to padding, etc.
  /// \returns a pointer to the newly-allocated block, NULL if out of memory.
  ///
  /// \since This function is available since SDL 2.0.10.
  ///
  /// \sa SDL_SIMDAlignment
  /// \sa SDL_SIMDRealloc
  /// \sa SDL_SIMDFree
  ffi.Pointer<ffi.Void> SDL_SIMDAlloc(
    int len,
  ) {
    return _SDL_SIMDAlloc(
      len,
    );
  }

  late final _SDL_SIMDAllocPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Void> Function(size_t)>>(
          'SDL_SIMDAlloc');
  late final _SDL_SIMDAlloc =
      _SDL_SIMDAllocPtr.asFunction<ffi.Pointer<ffi.Void> Function(int)>();

  /// Reallocate memory obtained from SDL_SIMDAlloc
  ///
  /// It is not valid to use this function on a pointer from anything but
  /// SDL_SIMDAlloc(). It can't be used on pointers from malloc, realloc,
  /// SDL_malloc, memalign, new[], etc.
  ///
  /// \param mem The pointer obtained from SDL_SIMDAlloc. This function also
  /// accepts NULL, at which point this function is the same as
  /// calling SDL_SIMDAlloc with a NULL pointer.
  /// \param len The length, in bytes, of the block to allocated. The actual
  /// allocated block might be larger due to padding, etc. Passing 0
  /// will return a non-NULL pointer, assuming the system isn't out of
  /// memory.
  /// \returns a pointer to the newly-reallocated block, NULL if out of memory.
  ///
  /// \since This function is available since SDL 2.0.14.
  ///
  /// \sa SDL_SIMDAlignment
  /// \sa SDL_SIMDAlloc
  /// \sa SDL_SIMDFree
  ffi.Pointer<ffi.Void> SDL_SIMDRealloc(
    ffi.Pointer<ffi.Void> mem,
    int len,
  ) {
    return _SDL_SIMDRealloc(
      mem,
      len,
    );
  }

  late final _SDL_SIMDReallocPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Void> Function(
              ffi.Pointer<ffi.Void>, size_t)>>('SDL_SIMDRealloc');
  late final _SDL_SIMDRealloc = _SDL_SIMDReallocPtr.asFunction<
      ffi.Pointer<ffi.Void> Function(ffi.Pointer<ffi.Void>, int)>();

  /// Deallocate memory obtained from SDL_SIMDAlloc
  ///
  /// It is not valid to use this function on a pointer from anything but
  /// SDL_SIMDAlloc() or SDL_SIMDRealloc(). It can't be used on pointers from
  /// malloc, realloc, SDL_malloc, memalign, new[], etc.
  ///
  /// However, SDL_SIMDFree(NULL) is a legal no-op.
  ///
  /// The memory pointed to by `ptr` is no longer valid for access upon return,
  /// and may be returned to the system or reused by a future allocation. The
  /// pointer passed to this function is no longer safe to dereference once this
  /// function returns, and should be discarded.
  ///
  /// \param ptr The pointer, returned from SDL_SIMDAlloc or SDL_SIMDRealloc, to
  /// deallocate. NULL is a legal no-op.
  ///
  /// \since This function is available since SDL 2.0.10.
  ///
  /// \sa SDL_SIMDAlloc
  /// \sa SDL_SIMDRealloc
  void SDL_SIMDFree(
    ffi.Pointer<ffi.Void> ptr,
  ) {
    return _SDL_SIMDFree(
      ptr,
    );
  }

  late final _SDL_SIMDFreePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ffi.Void>)>>(
          'SDL_SIMDFree');
  late final _SDL_SIMDFree =
      _SDL_SIMDFreePtr.asFunction<void Function(ffi.Pointer<ffi.Void>)>();

  /// Get the human readable name of a pixel format.
  ///
  /// \param format the pixel format to query
  /// \returns the human readable name of the specified pixel format or
  /// `SDL_PIXELFORMAT_UNKNOWN` if the format isn't recognized.
  ///
  /// \since This function is available since SDL 2.0.0.
  ffi.Pointer<ffi.Int8> SDL_GetPixelFormatName(
    int format,
  ) {
    return _SDL_GetPixelFormatName(
      format,
    );
  }

  late final _SDL_GetPixelFormatNamePtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Int8> Function(Uint32)>>(
          'SDL_GetPixelFormatName');
  late final _SDL_GetPixelFormatName = _SDL_GetPixelFormatNamePtr.asFunction<
      ffi.Pointer<ffi.Int8> Function(int)>();

  /// Convert one of the enumerated pixel formats to a bpp value and RGBA masks.
  ///
  /// \param format one of the SDL_PixelFormatEnum values
  /// \param bpp a bits per pixel value; usually 15, 16, or 32
  /// \param Rmask a pointer filled in with the red mask for the format
  /// \param Gmask a pointer filled in with the green mask for the format
  /// \param Bmask a pointer filled in with the blue mask for the format
  /// \param Amask a pointer filled in with the alpha mask for the format
  /// \returns SDL_TRUE on success or SDL_FALSE if the conversion wasn't
  /// possible; call SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_MasksToPixelFormatEnum
  int SDL_PixelFormatEnumToMasks(
    int format,
    ffi.Pointer<ffi.Int32> bpp,
    ffi.Pointer<Uint32> Rmask,
    ffi.Pointer<Uint32> Gmask,
    ffi.Pointer<Uint32> Bmask,
    ffi.Pointer<Uint32> Amask,
  ) {
    return _SDL_PixelFormatEnumToMasks(
      format,
      bpp,
      Rmask,
      Gmask,
      Bmask,
      Amask,
    );
  }

  late final _SDL_PixelFormatEnumToMasksPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              Uint32,
              ffi.Pointer<ffi.Int32>,
              ffi.Pointer<Uint32>,
              ffi.Pointer<Uint32>,
              ffi.Pointer<Uint32>,
              ffi.Pointer<Uint32>)>>('SDL_PixelFormatEnumToMasks');
  late final _SDL_PixelFormatEnumToMasks =
      _SDL_PixelFormatEnumToMasksPtr.asFunction<
          int Function(int, ffi.Pointer<ffi.Int32>, ffi.Pointer<Uint32>,
              ffi.Pointer<Uint32>, ffi.Pointer<Uint32>, ffi.Pointer<Uint32>)>();

  /// Convert a bpp value and RGBA masks to an enumerated pixel format.
  ///
  /// This will return `SDL_PIXELFORMAT_UNKNOWN` if the conversion wasn't
  /// possible.
  ///
  /// \param bpp a bits per pixel value; usually 15, 16, or 32
  /// \param Rmask the red mask for the format
  /// \param Gmask the green mask for the format
  /// \param Bmask the blue mask for the format
  /// \param Amask the alpha mask for the format
  /// \returns one of the SDL_PixelFormatEnum values
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_PixelFormatEnumToMasks
  int SDL_MasksToPixelFormatEnum(
    int bpp,
    int Rmask,
    int Gmask,
    int Bmask,
    int Amask,
  ) {
    return _SDL_MasksToPixelFormatEnum(
      bpp,
      Rmask,
      Gmask,
      Bmask,
      Amask,
    );
  }

  late final _SDL_MasksToPixelFormatEnumPtr = _lookup<
      ffi.NativeFunction<
          Uint32 Function(ffi.Int32, Uint32, Uint32, Uint32,
              Uint32)>>('SDL_MasksToPixelFormatEnum');
  late final _SDL_MasksToPixelFormatEnum = _SDL_MasksToPixelFormatEnumPtr
      .asFunction<int Function(int, int, int, int, int)>();

  /// Create an SDL_PixelFormat structure corresponding to a pixel format.
  ///
  /// Returned structure may come from a shared global cache (i.e. not newly
  /// allocated), and hence should not be modified, especially the palette. Weird
  /// errors such as `Blit combination not supported` may occur.
  ///
  /// \param pixel_format one of the SDL_PixelFormatEnum values
  /// \returns the new SDL_PixelFormat structure or NULL on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_FreeFormat
  ffi.Pointer<SDL_PixelFormat> SDL_AllocFormat(
    int pixel_format,
  ) {
    return _SDL_AllocFormat(
      pixel_format,
    );
  }

  late final _SDL_AllocFormatPtr = _lookup<
          ffi.NativeFunction<ffi.Pointer<SDL_PixelFormat> Function(Uint32)>>(
      'SDL_AllocFormat');
  late final _SDL_AllocFormat = _SDL_AllocFormatPtr.asFunction<
      ffi.Pointer<SDL_PixelFormat> Function(int)>();

  /// Free an SDL_PixelFormat structure allocated by SDL_AllocFormat().
  ///
  /// \param format the SDL_PixelFormat structure to free
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_AllocFormat
  void SDL_FreeFormat(
    ffi.Pointer<SDL_PixelFormat> format,
  ) {
    return _SDL_FreeFormat(
      format,
    );
  }

  late final _SDL_FreeFormatPtr = _lookup<
          ffi.NativeFunction<ffi.Void Function(ffi.Pointer<SDL_PixelFormat>)>>(
      'SDL_FreeFormat');
  late final _SDL_FreeFormat = _SDL_FreeFormatPtr.asFunction<
      void Function(ffi.Pointer<SDL_PixelFormat>)>();

  /// Create a palette structure with the specified number of color entries.
  ///
  /// The palette entries are initialized to white.
  ///
  /// \param ncolors represents the number of color entries in the color palette
  /// \returns a new SDL_Palette structure on success or NULL on failure (e.g. if
  /// there wasn't enough memory); call SDL_GetError() for more
  /// information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_FreePalette
  ffi.Pointer<SDL_Palette> SDL_AllocPalette(
    int ncolors,
  ) {
    return _SDL_AllocPalette(
      ncolors,
    );
  }

  late final _SDL_AllocPalettePtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<SDL_Palette> Function(ffi.Int32)>>(
          'SDL_AllocPalette');
  late final _SDL_AllocPalette =
      _SDL_AllocPalettePtr.asFunction<ffi.Pointer<SDL_Palette> Function(int)>();

  /// Set the palette for a pixel format structure.
  ///
  /// \param format the SDL_PixelFormat structure that will use the palette
  /// \param palette the SDL_Palette structure that will be used
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_AllocPalette
  /// \sa SDL_FreePalette
  int SDL_SetPixelFormatPalette(
    ffi.Pointer<SDL_PixelFormat> format,
    ffi.Pointer<SDL_Palette> palette,
  ) {
    return _SDL_SetPixelFormatPalette(
      format,
      palette,
    );
  }

  late final _SDL_SetPixelFormatPalettePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_PixelFormat>,
              ffi.Pointer<SDL_Palette>)>>('SDL_SetPixelFormatPalette');
  late final _SDL_SetPixelFormatPalette =
      _SDL_SetPixelFormatPalettePtr.asFunction<
          int Function(
              ffi.Pointer<SDL_PixelFormat>, ffi.Pointer<SDL_Palette>)>();

  /// Set a range of colors in a palette.
  ///
  /// \param palette the SDL_Palette structure to modify
  /// \param colors an array of SDL_Color structures to copy into the palette
  /// \param firstcolor the index of the first palette entry to modify
  /// \param ncolors the number of entries to modify
  /// \returns 0 on success or a negative error code if not all of the colors
  /// could be set; call SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_AllocPalette
  /// \sa SDL_CreateRGBSurface
  int SDL_SetPaletteColors(
    ffi.Pointer<SDL_Palette> palette,
    ffi.Pointer<SDL_Color> colors,
    int firstcolor,
    int ncolors,
  ) {
    return _SDL_SetPaletteColors(
      palette,
      colors,
      firstcolor,
      ncolors,
    );
  }

  late final _SDL_SetPaletteColorsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_Palette>, ffi.Pointer<SDL_Color>,
              ffi.Int32, ffi.Int32)>>('SDL_SetPaletteColors');
  late final _SDL_SetPaletteColors = _SDL_SetPaletteColorsPtr.asFunction<
      int Function(
          ffi.Pointer<SDL_Palette>, ffi.Pointer<SDL_Color>, int, int)>();

  /// Free a palette created with SDL_AllocPalette().
  ///
  /// \param palette the SDL_Palette structure to be freed
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_AllocPalette
  void SDL_FreePalette(
    ffi.Pointer<SDL_Palette> palette,
  ) {
    return _SDL_FreePalette(
      palette,
    );
  }

  late final _SDL_FreePalettePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<SDL_Palette>)>>(
          'SDL_FreePalette');
  late final _SDL_FreePalette =
      _SDL_FreePalettePtr.asFunction<void Function(ffi.Pointer<SDL_Palette>)>();

  /// Map an RGB triple to an opaque pixel value for a given pixel format.
  ///
  /// This function maps the RGB color value to the specified pixel format and
  /// returns the pixel value best approximating the given RGB color value for
  /// the given pixel format.
  ///
  /// If the format has a palette (8-bit) the index of the closest matching color
  /// in the palette will be returned.
  ///
  /// If the specified pixel format has an alpha component it will be returned as
  /// all 1 bits (fully opaque).
  ///
  /// If the pixel format bpp (color depth) is less than 32-bpp then the unused
  /// upper bits of the return value can safely be ignored (e.g., with a 16-bpp
  /// format the return value can be assigned to a Uint16, and similarly a Uint8
  /// for an 8-bpp format).
  ///
  /// \param format an SDL_PixelFormat structure describing the pixel format
  /// \param r the red component of the pixel in the range 0-255
  /// \param g the green component of the pixel in the range 0-255
  /// \param b the blue component of the pixel in the range 0-255
  /// \returns a pixel value
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetRGB
  /// \sa SDL_GetRGBA
  /// \sa SDL_MapRGBA
  int SDL_MapRGB(
    ffi.Pointer<SDL_PixelFormat> format,
    int r,
    int g,
    int b,
  ) {
    return _SDL_MapRGB(
      format,
      r,
      g,
      b,
    );
  }

  late final _SDL_MapRGBPtr = _lookup<
      ffi.NativeFunction<
          Uint32 Function(ffi.Pointer<SDL_PixelFormat>, Uint8, Uint8,
              Uint8)>>('SDL_MapRGB');
  late final _SDL_MapRGB = _SDL_MapRGBPtr.asFunction<
      int Function(ffi.Pointer<SDL_PixelFormat>, int, int, int)>();

  /// Map an RGBA quadruple to a pixel value for a given pixel format.
  ///
  /// This function maps the RGBA color value to the specified pixel format and
  /// returns the pixel value best approximating the given RGBA color value for
  /// the given pixel format.
  ///
  /// If the specified pixel format has no alpha component the alpha value will
  /// be ignored (as it will be in formats with a palette).
  ///
  /// If the format has a palette (8-bit) the index of the closest matching color
  /// in the palette will be returned.
  ///
  /// If the pixel format bpp (color depth) is less than 32-bpp then the unused
  /// upper bits of the return value can safely be ignored (e.g., with a 16-bpp
  /// format the return value can be assigned to a Uint16, and similarly a Uint8
  /// for an 8-bpp format).
  ///
  /// \param format an SDL_PixelFormat structure describing the format of the
  /// pixel
  /// \param r the red component of the pixel in the range 0-255
  /// \param g the green component of the pixel in the range 0-255
  /// \param b the blue component of the pixel in the range 0-255
  /// \param a the alpha component of the pixel in the range 0-255
  /// \returns a pixel value
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetRGB
  /// \sa SDL_GetRGBA
  /// \sa SDL_MapRGB
  int SDL_MapRGBA(
    ffi.Pointer<SDL_PixelFormat> format,
    int r,
    int g,
    int b,
    int a,
  ) {
    return _SDL_MapRGBA(
      format,
      r,
      g,
      b,
      a,
    );
  }

  late final _SDL_MapRGBAPtr = _lookup<
      ffi.NativeFunction<
          Uint32 Function(ffi.Pointer<SDL_PixelFormat>, Uint8, Uint8, Uint8,
              Uint8)>>('SDL_MapRGBA');
  late final _SDL_MapRGBA = _SDL_MapRGBAPtr.asFunction<
      int Function(ffi.Pointer<SDL_PixelFormat>, int, int, int, int)>();

  /// Get RGB values from a pixel in the specified format.
  ///
  /// This function uses the entire 8-bit [0..255] range when converting color
  /// components from pixel formats with less than 8-bits per RGB component
  /// (e.g., a completely white pixel in 16-bit RGB565 format would return [0xff,
  /// 0xff, 0xff] not [0xf8, 0xfc, 0xf8]).
  ///
  /// \param pixel a pixel value
  /// \param format an SDL_PixelFormat structure describing the format of the
  /// pixel
  /// \param r a pointer filled in with the red component
  /// \param g a pointer filled in with the green component
  /// \param b a pointer filled in with the blue component
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetRGBA
  /// \sa SDL_MapRGB
  /// \sa SDL_MapRGBA
  void SDL_GetRGB(
    int pixel,
    ffi.Pointer<SDL_PixelFormat> format,
    ffi.Pointer<Uint8> r,
    ffi.Pointer<Uint8> g,
    ffi.Pointer<Uint8> b,
  ) {
    return _SDL_GetRGB(
      pixel,
      format,
      r,
      g,
      b,
    );
  }

  late final _SDL_GetRGBPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              Uint32,
              ffi.Pointer<SDL_PixelFormat>,
              ffi.Pointer<Uint8>,
              ffi.Pointer<Uint8>,
              ffi.Pointer<Uint8>)>>('SDL_GetRGB');
  late final _SDL_GetRGB = _SDL_GetRGBPtr.asFunction<
      void Function(int, ffi.Pointer<SDL_PixelFormat>, ffi.Pointer<Uint8>,
          ffi.Pointer<Uint8>, ffi.Pointer<Uint8>)>();

  /// Get RGBA values from a pixel in the specified format.
  ///
  /// This function uses the entire 8-bit [0..255] range when converting color
  /// components from pixel formats with less than 8-bits per RGB component
  /// (e.g., a completely white pixel in 16-bit RGB565 format would return [0xff,
  /// 0xff, 0xff] not [0xf8, 0xfc, 0xf8]).
  ///
  /// If the surface has no alpha component, the alpha will be returned as 0xff
  /// (100% opaque).
  ///
  /// \param pixel a pixel value
  /// \param format an SDL_PixelFormat structure describing the format of the
  /// pixel
  /// \param r a pointer filled in with the red component
  /// \param g a pointer filled in with the green component
  /// \param b a pointer filled in with the blue component
  /// \param a a pointer filled in with the alpha component
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetRGB
  /// \sa SDL_MapRGB
  /// \sa SDL_MapRGBA
  void SDL_GetRGBA(
    int pixel,
    ffi.Pointer<SDL_PixelFormat> format,
    ffi.Pointer<Uint8> r,
    ffi.Pointer<Uint8> g,
    ffi.Pointer<Uint8> b,
    ffi.Pointer<Uint8> a,
  ) {
    return _SDL_GetRGBA(
      pixel,
      format,
      r,
      g,
      b,
      a,
    );
  }

  late final _SDL_GetRGBAPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              Uint32,
              ffi.Pointer<SDL_PixelFormat>,
              ffi.Pointer<Uint8>,
              ffi.Pointer<Uint8>,
              ffi.Pointer<Uint8>,
              ffi.Pointer<Uint8>)>>('SDL_GetRGBA');
  late final _SDL_GetRGBA = _SDL_GetRGBAPtr.asFunction<
      void Function(int, ffi.Pointer<SDL_PixelFormat>, ffi.Pointer<Uint8>,
          ffi.Pointer<Uint8>, ffi.Pointer<Uint8>, ffi.Pointer<Uint8>)>();

  /// Calculate a 256 entry gamma ramp for a gamma value.
  ///
  /// \param gamma a gamma value where 0.0 is black and 1.0 is identity
  /// \param ramp an array of 256 values filled in with the gamma ramp
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_SetWindowGammaRamp
  void SDL_CalculateGammaRamp(
    double gamma,
    ffi.Pointer<Uint16> ramp,
  ) {
    return _SDL_CalculateGammaRamp(
      gamma,
      ramp,
    );
  }

  late final _SDL_CalculateGammaRampPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Float, ffi.Pointer<Uint16>)>>('SDL_CalculateGammaRamp');
  late final _SDL_CalculateGammaRamp = _SDL_CalculateGammaRampPtr.asFunction<
      void Function(double, ffi.Pointer<Uint16>)>();

  /// Determine whether two rectangles intersect.
  ///
  /// If either pointer is NULL the function will return SDL_FALSE.
  ///
  /// \param A an SDL_Rect structure representing the first rectangle
  /// \param B an SDL_Rect structure representing the second rectangle
  /// \returns SDL_TRUE if there is an intersection, SDL_FALSE otherwise.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_IntersectRect
  int SDL_HasIntersection(
    ffi.Pointer<SDL_Rect> A,
    ffi.Pointer<SDL_Rect> B,
  ) {
    return _SDL_HasIntersection(
      A,
      B,
    );
  }

  late final _SDL_HasIntersectionPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_Rect>,
              ffi.Pointer<SDL_Rect>)>>('SDL_HasIntersection');
  late final _SDL_HasIntersection = _SDL_HasIntersectionPtr.asFunction<
      int Function(ffi.Pointer<SDL_Rect>, ffi.Pointer<SDL_Rect>)>();

  /// Calculate the intersection of two rectangles.
  ///
  /// If `result` is NULL then this function will return SDL_FALSE.
  ///
  /// \param A an SDL_Rect structure representing the first rectangle
  /// \param B an SDL_Rect structure representing the second rectangle
  /// \param result an SDL_Rect structure filled in with the intersection of
  /// rectangles `A` and `B`
  /// \returns SDL_TRUE if there is an intersection, SDL_FALSE otherwise.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_HasIntersection
  int SDL_IntersectRect(
    ffi.Pointer<SDL_Rect> A,
    ffi.Pointer<SDL_Rect> B,
    ffi.Pointer<SDL_Rect> result,
  ) {
    return _SDL_IntersectRect(
      A,
      B,
      result,
    );
  }

  late final _SDL_IntersectRectPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_Rect>, ffi.Pointer<SDL_Rect>,
              ffi.Pointer<SDL_Rect>)>>('SDL_IntersectRect');
  late final _SDL_IntersectRect = _SDL_IntersectRectPtr.asFunction<
      int Function(ffi.Pointer<SDL_Rect>, ffi.Pointer<SDL_Rect>,
          ffi.Pointer<SDL_Rect>)>();

  /// Calculate the union of two rectangles.
  ///
  /// \param A an SDL_Rect structure representing the first rectangle
  /// \param B an SDL_Rect structure representing the second rectangle
  /// \param result an SDL_Rect structure filled in with the union of rectangles
  /// `A` and `B`
  ///
  /// \since This function is available since SDL 2.0.0.
  void SDL_UnionRect(
    ffi.Pointer<SDL_Rect> A,
    ffi.Pointer<SDL_Rect> B,
    ffi.Pointer<SDL_Rect> result,
  ) {
    return _SDL_UnionRect(
      A,
      B,
      result,
    );
  }

  late final _SDL_UnionRectPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<SDL_Rect>, ffi.Pointer<SDL_Rect>,
              ffi.Pointer<SDL_Rect>)>>('SDL_UnionRect');
  late final _SDL_UnionRect = _SDL_UnionRectPtr.asFunction<
      void Function(ffi.Pointer<SDL_Rect>, ffi.Pointer<SDL_Rect>,
          ffi.Pointer<SDL_Rect>)>();

  /// Calculate a minimal rectangle enclosing a set of points.
  ///
  /// If `clip` is not NULL then only points inside of the clipping rectangle are
  /// considered.
  ///
  /// \param points an array of SDL_Point structures representing points to be
  /// enclosed
  /// \param count the number of structures in the `points` array
  /// \param clip an SDL_Rect used for clipping or NULL to enclose all points
  /// \param result an SDL_Rect structure filled in with the minimal enclosing
  /// rectangle
  /// \returns SDL_TRUE if any points were enclosed or SDL_FALSE if all the
  /// points were outside of the clipping rectangle.
  ///
  /// \since This function is available since SDL 2.0.0.
  int SDL_EnclosePoints(
    ffi.Pointer<SDL_Point> points,
    int count,
    ffi.Pointer<SDL_Rect> clip,
    ffi.Pointer<SDL_Rect> result,
  ) {
    return _SDL_EnclosePoints(
      points,
      count,
      clip,
      result,
    );
  }

  late final _SDL_EnclosePointsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<SDL_Point>,
              ffi.Int32,
              ffi.Pointer<SDL_Rect>,
              ffi.Pointer<SDL_Rect>)>>('SDL_EnclosePoints');
  late final _SDL_EnclosePoints = _SDL_EnclosePointsPtr.asFunction<
      int Function(ffi.Pointer<SDL_Point>, int, ffi.Pointer<SDL_Rect>,
          ffi.Pointer<SDL_Rect>)>();

  /// Calculate the intersection of a rectangle and line segment.
  ///
  /// This function is used to clip a line segment to a rectangle. A line segment
  /// contained entirely within the rectangle or that does not intersect will
  /// remain unchanged. A line segment that crosses the rectangle at either or
  /// both ends will be clipped to the boundary of the rectangle and the new
  /// coordinates saved in `X1`, `Y1`, `X2`, and/or `Y2` as necessary.
  ///
  /// \param rect an SDL_Rect structure representing the rectangle to intersect
  /// \param X1 a pointer to the starting X-coordinate of the line
  /// \param Y1 a pointer to the starting Y-coordinate of the line
  /// \param X2 a pointer to the ending X-coordinate of the line
  /// \param Y2 a pointer to the ending Y-coordinate of the line
  /// \returns SDL_TRUE if there is an intersection, SDL_FALSE otherwise.
  ///
  /// \since This function is available since SDL 2.0.0.
  int SDL_IntersectRectAndLine(
    ffi.Pointer<SDL_Rect> rect,
    ffi.Pointer<ffi.Int32> X1,
    ffi.Pointer<ffi.Int32> Y1,
    ffi.Pointer<ffi.Int32> X2,
    ffi.Pointer<ffi.Int32> Y2,
  ) {
    return _SDL_IntersectRectAndLine(
      rect,
      X1,
      Y1,
      X2,
      Y2,
    );
  }

  late final _SDL_IntersectRectAndLinePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<SDL_Rect>,
              ffi.Pointer<ffi.Int32>,
              ffi.Pointer<ffi.Int32>,
              ffi.Pointer<ffi.Int32>,
              ffi.Pointer<ffi.Int32>)>>('SDL_IntersectRectAndLine');
  late final _SDL_IntersectRectAndLine =
      _SDL_IntersectRectAndLinePtr.asFunction<
          int Function(
              ffi.Pointer<SDL_Rect>,
              ffi.Pointer<ffi.Int32>,
              ffi.Pointer<ffi.Int32>,
              ffi.Pointer<ffi.Int32>,
              ffi.Pointer<ffi.Int32>)>();

  /// Compose a custom blend mode for renderers.
  ///
  /// The functions SDL_SetRenderDrawBlendMode and SDL_SetTextureBlendMode accept
  /// the SDL_BlendMode returned by this function if the renderer supports it.
  ///
  /// A blend mode controls how the pixels from a drawing operation (source) get
  /// combined with the pixels from the render target (destination). First, the
  /// components of the source and destination pixels get multiplied with their
  /// blend factors. Then, the blend operation takes the two products and
  /// calculates the result that will get stored in the render target.
  ///
  /// Expressed in pseudocode, it would look like this:
  ///
  /// ```c
  /// dstRGB = colorOperation(srcRGB * srcColorFactor, dstRGB * dstColorFactor);
  /// dstA = alphaOperation(srcA * srcAlphaFactor, dstA * dstAlphaFactor);
  /// ```
  ///
  /// Where the functions `colorOperation(src, dst)` and `alphaOperation(src,
  /// dst)` can return one of the following:
  ///
  /// - `src + dst`
  /// - `src - dst`
  /// - `dst - src`
  /// - `min(src, dst)`
  /// - `max(src, dst)`
  ///
  /// The red, green, and blue components are always multiplied with the first,
  /// second, and third components of the SDL_BlendFactor, respectively. The
  /// fourth component is not used.
  ///
  /// The alpha component is always multiplied with the fourth component of the
  /// SDL_BlendFactor. The other components are not used in the alpha
  /// calculation.
  ///
  /// Support for these blend modes varies for each renderer. To check if a
  /// specific SDL_BlendMode is supported, create a renderer and pass it to
  /// either SDL_SetRenderDrawBlendMode or SDL_SetTextureBlendMode. They will
  /// return with an error if the blend mode is not supported.
  ///
  /// This list describes the support of custom blend modes for each renderer in
  /// SDL 2.0.6. All renderers support the four blend modes listed in the
  /// SDL_BlendMode enumeration.
  ///
  /// - **direct3d**: Supports `SDL_BLENDOPERATION_ADD` with all factors.
  /// - **direct3d11**: Supports all operations with all factors. However, some
  /// factors produce unexpected results with `SDL_BLENDOPERATION_MINIMUM` and
  /// `SDL_BLENDOPERATION_MAXIMUM`.
  /// - **opengl**: Supports the `SDL_BLENDOPERATION_ADD` operation with all
  /// factors. OpenGL versions 1.1, 1.2, and 1.3 do not work correctly with SDL
  /// 2.0.6.
  /// - **opengles**: Supports the `SDL_BLENDOPERATION_ADD` operation with all
  /// factors. Color and alpha factors need to be the same. OpenGL ES 1
  /// implementation specific: May also support `SDL_BLENDOPERATION_SUBTRACT`
  /// and `SDL_BLENDOPERATION_REV_SUBTRACT`. May support color and alpha
  /// operations being different from each other. May support color and alpha
  /// factors being different from each other.
  /// - **opengles2**: Supports the `SDL_BLENDOPERATION_ADD`,
  /// `SDL_BLENDOPERATION_SUBTRACT`, `SDL_BLENDOPERATION_REV_SUBTRACT`
  /// operations with all factors.
  /// - **psp**: No custom blend mode support.
  /// - **software**: No custom blend mode support.
  ///
  /// Some renderers do not provide an alpha component for the default render
  /// target. The `SDL_BLENDFACTOR_DST_ALPHA` and
  /// `SDL_BLENDFACTOR_ONE_MINUS_DST_ALPHA` factors do not have an effect in this
  /// case.
  ///
  /// \param srcColorFactor the SDL_BlendFactor applied to the red, green, and
  /// blue components of the source pixels
  /// \param dstColorFactor the SDL_BlendFactor applied to the red, green, and
  /// blue components of the destination pixels
  /// \param colorOperation the SDL_BlendOperation used to combine the red,
  /// green, and blue components of the source and
  /// destination pixels
  /// \param srcAlphaFactor the SDL_BlendFactor applied to the alpha component of
  /// the source pixels
  /// \param dstAlphaFactor the SDL_BlendFactor applied to the alpha component of
  /// the destination pixels
  /// \param alphaOperation the SDL_BlendOperation used to combine the alpha
  /// component of the source and destination pixels
  /// \returns an SDL_BlendMode that represents the chosen factors and
  /// operations.
  ///
  /// \since This function is available since SDL 2.0.6.
  ///
  /// \sa SDL_SetRenderDrawBlendMode
  /// \sa SDL_GetRenderDrawBlendMode
  /// \sa SDL_SetTextureBlendMode
  /// \sa SDL_GetTextureBlendMode
  int SDL_ComposeCustomBlendMode(
    int srcColorFactor,
    int dstColorFactor,
    int colorOperation,
    int srcAlphaFactor,
    int dstAlphaFactor,
    int alphaOperation,
  ) {
    return _SDL_ComposeCustomBlendMode(
      srcColorFactor,
      dstColorFactor,
      colorOperation,
      srcAlphaFactor,
      dstAlphaFactor,
      alphaOperation,
    );
  }

  late final _SDL_ComposeCustomBlendModePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Int32, ffi.Int32, ffi.Int32, ffi.Int32,
              ffi.Int32, ffi.Int32)>>('SDL_ComposeCustomBlendMode');
  late final _SDL_ComposeCustomBlendMode = _SDL_ComposeCustomBlendModePtr
      .asFunction<int Function(int, int, int, int, int, int)>();

  /// Allocate a new RGB surface.
  ///
  /// If `depth` is 4 or 8 bits, an empty palette is allocated for the surface.
  /// If `depth` is greater than 8 bits, the pixel format is set using the
  /// [RGBA]mask parameters.
  ///
  /// The [RGBA]mask parameters are the bitmasks used to extract that color from
  /// a pixel. For instance, `Rmask` being 0xFF000000 means the red data is
  /// stored in the most significant byte. Using zeros for the RGB masks sets a
  /// default value, based on the depth. For example:
  ///
  /// ```c++
  /// SDL_CreateRGBSurface(0,w,h,32,0,0,0,0);
  /// ```
  ///
  /// However, using zero for the Amask results in an Amask of 0.
  ///
  /// By default surfaces with an alpha mask are set up for blending as with:
  ///
  /// ```c++
  /// SDL_SetSurfaceBlendMode(surface, SDL_BLENDMODE_BLEND)
  /// ```
  ///
  /// You can change this by calling SDL_SetSurfaceBlendMode() and selecting a
  /// different `blendMode`.
  ///
  /// \param flags the flags are unused and should be set to 0
  /// \param width the width of the surface
  /// \param height the height of the surface
  /// \param depth the depth of the surface in bits
  /// \param Rmask the red mask for the pixels
  /// \param Gmask the green mask for the pixels
  /// \param Bmask the blue mask for the pixels
  /// \param Amask the alpha mask for the pixels
  /// \returns the new SDL_Surface structure that is created or NULL if it fails;
  /// call SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_CreateRGBSurfaceFrom
  /// \sa SDL_CreateRGBSurfaceWithFormat
  /// \sa SDL_FreeSurface
  ffi.Pointer<SDL_Surface> SDL_CreateRGBSurface(
    int flags,
    int width,
    int height,
    int depth,
    int Rmask,
    int Gmask,
    int Bmask,
    int Amask,
  ) {
    return _SDL_CreateRGBSurface(
      flags,
      width,
      height,
      depth,
      Rmask,
      Gmask,
      Bmask,
      Amask,
    );
  }

  late final _SDL_CreateRGBSurfacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<SDL_Surface> Function(
              Uint32,
              ffi.Int32,
              ffi.Int32,
              ffi.Int32,
              Uint32,
              Uint32,
              Uint32,
              Uint32)>>('SDL_CreateRGBSurface');
  late final _SDL_CreateRGBSurface = _SDL_CreateRGBSurfacePtr.asFunction<
      ffi.Pointer<SDL_Surface> Function(
          int, int, int, int, int, int, int, int)>();

  /// Allocate a new RGB surface with a specific pixel format.
  ///
  /// This function operates mostly like SDL_CreateRGBSurface(), except instead
  /// of providing pixel color masks, you provide it with a predefined format
  /// from SDL_PixelFormatEnum.
  ///
  /// \param flags the flags are unused and should be set to 0
  /// \param width the width of the surface
  /// \param height the height of the surface
  /// \param depth the depth of the surface in bits
  /// \param format the SDL_PixelFormatEnum for the new surface's pixel format.
  /// \returns the new SDL_Surface structure that is created or NULL if it fails;
  /// call SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.5.
  ///
  /// \sa SDL_CreateRGBSurface
  /// \sa SDL_CreateRGBSurfaceFrom
  /// \sa SDL_FreeSurface
  ffi.Pointer<SDL_Surface> SDL_CreateRGBSurfaceWithFormat(
    int flags,
    int width,
    int height,
    int depth,
    int format,
  ) {
    return _SDL_CreateRGBSurfaceWithFormat(
      flags,
      width,
      height,
      depth,
      format,
    );
  }

  late final _SDL_CreateRGBSurfaceWithFormatPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<SDL_Surface> Function(Uint32, ffi.Int32, ffi.Int32,
              ffi.Int32, Uint32)>>('SDL_CreateRGBSurfaceWithFormat');
  late final _SDL_CreateRGBSurfaceWithFormat =
      _SDL_CreateRGBSurfaceWithFormatPtr.asFunction<
          ffi.Pointer<SDL_Surface> Function(int, int, int, int, int)>();

  /// Allocate a new RGB surface with existing pixel data.
  ///
  /// This function operates mostly like SDL_CreateRGBSurface(), except it does
  /// not allocate memory for the pixel data, instead the caller provides an
  /// existing buffer of data for the surface to use.
  ///
  /// No copy is made of the pixel data. Pixel data is not managed automatically;
  /// you must free the surface before you free the pixel data.
  ///
  /// \param pixels a pointer to existing pixel data
  /// \param width the width of the surface
  /// \param height the height of the surface
  /// \param depth the depth of the surface in bits
  /// \param pitch the pitch of the surface in bytes
  /// \param Rmask the red mask for the pixels
  /// \param Gmask the green mask for the pixels
  /// \param Bmask the blue mask for the pixels
  /// \param Amask the alpha mask for the pixels
  /// \returns the new SDL_Surface structure that is created or NULL if it fails;
  /// call SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_CreateRGBSurface
  /// \sa SDL_CreateRGBSurfaceWithFormat
  /// \sa SDL_FreeSurface
  ffi.Pointer<SDL_Surface> SDL_CreateRGBSurfaceFrom(
    ffi.Pointer<ffi.Void> pixels,
    int width,
    int height,
    int depth,
    int pitch,
    int Rmask,
    int Gmask,
    int Bmask,
    int Amask,
  ) {
    return _SDL_CreateRGBSurfaceFrom(
      pixels,
      width,
      height,
      depth,
      pitch,
      Rmask,
      Gmask,
      Bmask,
      Amask,
    );
  }

  late final _SDL_CreateRGBSurfaceFromPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<SDL_Surface> Function(
              ffi.Pointer<ffi.Void>,
              ffi.Int32,
              ffi.Int32,
              ffi.Int32,
              ffi.Int32,
              Uint32,
              Uint32,
              Uint32,
              Uint32)>>('SDL_CreateRGBSurfaceFrom');
  late final _SDL_CreateRGBSurfaceFrom =
      _SDL_CreateRGBSurfaceFromPtr.asFunction<
          ffi.Pointer<SDL_Surface> Function(
              ffi.Pointer<ffi.Void>, int, int, int, int, int, int, int, int)>();

  /// Allocate a new RGB surface with with a specific pixel format and existing
  /// pixel data.
  ///
  /// This function operates mostly like SDL_CreateRGBSurfaceFrom(), except
  /// instead of providing pixel color masks, you provide it with a predefined
  /// format from SDL_PixelFormatEnum.
  ///
  /// No copy is made of the pixel data. Pixel data is not managed automatically;
  /// you must free the surface before you free the pixel data.
  ///
  /// \param pixels a pointer to existing pixel data
  /// \param width the width of the surface
  /// \param height the height of the surface
  /// \param depth the depth of the surface in bits
  /// \param pitch the pitch of the surface in bytes
  /// \param format the SDL_PixelFormatEnum for the new surface's pixel format.
  /// \returns the new SDL_Surface structure that is created or NULL if it fails;
  /// call SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.5.
  ///
  /// \sa SDL_CreateRGBSurfaceFrom
  /// \sa SDL_CreateRGBSurfaceWithFormat
  /// \sa SDL_FreeSurface
  ffi.Pointer<SDL_Surface> SDL_CreateRGBSurfaceWithFormatFrom(
    ffi.Pointer<ffi.Void> pixels,
    int width,
    int height,
    int depth,
    int pitch,
    int format,
  ) {
    return _SDL_CreateRGBSurfaceWithFormatFrom(
      pixels,
      width,
      height,
      depth,
      pitch,
      format,
    );
  }

  late final _SDL_CreateRGBSurfaceWithFormatFromPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<SDL_Surface> Function(
              ffi.Pointer<ffi.Void>,
              ffi.Int32,
              ffi.Int32,
              ffi.Int32,
              ffi.Int32,
              Uint32)>>('SDL_CreateRGBSurfaceWithFormatFrom');
  late final _SDL_CreateRGBSurfaceWithFormatFrom =
      _SDL_CreateRGBSurfaceWithFormatFromPtr.asFunction<
          ffi.Pointer<SDL_Surface> Function(
              ffi.Pointer<ffi.Void>, int, int, int, int, int)>();

  /// Free an RGB surface.
  ///
  /// It is safe to pass NULL to this function.
  ///
  /// \param surface the SDL_Surface to free.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_CreateRGBSurface
  /// \sa SDL_CreateRGBSurfaceFrom
  /// \sa SDL_LoadBMP
  /// \sa SDL_LoadBMP_RW
  void SDL_FreeSurface(
    ffi.Pointer<SDL_Surface> surface,
  ) {
    return _SDL_FreeSurface(
      surface,
    );
  }

  late final _SDL_FreeSurfacePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<SDL_Surface>)>>(
          'SDL_FreeSurface');
  late final _SDL_FreeSurface =
      _SDL_FreeSurfacePtr.asFunction<void Function(ffi.Pointer<SDL_Surface>)>();

  /// Set the palette used by a surface.
  ///
  /// A single palette can be shared with many surfaces.
  ///
  /// \param surface the SDL_Surface structure to update
  /// \param palette the SDL_Palette structure to use
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  int SDL_SetSurfacePalette(
    ffi.Pointer<SDL_Surface> surface,
    ffi.Pointer<SDL_Palette> palette,
  ) {
    return _SDL_SetSurfacePalette(
      surface,
      palette,
    );
  }

  late final _SDL_SetSurfacePalettePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_Surface>,
              ffi.Pointer<SDL_Palette>)>>('SDL_SetSurfacePalette');
  late final _SDL_SetSurfacePalette = _SDL_SetSurfacePalettePtr.asFunction<
      int Function(ffi.Pointer<SDL_Surface>, ffi.Pointer<SDL_Palette>)>();

  /// Set up a surface for directly accessing the pixels.
  ///
  /// Between calls to SDL_LockSurface() / SDL_UnlockSurface(), you can write to
  /// and read from `surface->pixels`, using the pixel format stored in
  /// `surface->format`. Once you are done accessing the surface, you should use
  /// SDL_UnlockSurface() to release it.
  ///
  /// Not all surfaces require locking. If `SDL_MUSTLOCK(surface)` evaluates to
  /// 0, then you can read and write to the surface at any time, and the pixel
  /// format of the surface will not change.
  ///
  /// \param surface the SDL_Surface structure to be locked
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_MUSTLOCK
  /// \sa SDL_UnlockSurface
  int SDL_LockSurface(
    ffi.Pointer<SDL_Surface> surface,
  ) {
    return _SDL_LockSurface(
      surface,
    );
  }

  late final _SDL_LockSurfacePtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<SDL_Surface>)>>(
          'SDL_LockSurface');
  late final _SDL_LockSurface =
      _SDL_LockSurfacePtr.asFunction<int Function(ffi.Pointer<SDL_Surface>)>();

  /// Release a surface after directly accessing the pixels.
  ///
  /// \param surface the SDL_Surface structure to be unlocked
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_LockSurface
  void SDL_UnlockSurface(
    ffi.Pointer<SDL_Surface> surface,
  ) {
    return _SDL_UnlockSurface(
      surface,
    );
  }

  late final _SDL_UnlockSurfacePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<SDL_Surface>)>>(
          'SDL_UnlockSurface');
  late final _SDL_UnlockSurface = _SDL_UnlockSurfacePtr.asFunction<
      void Function(ffi.Pointer<SDL_Surface>)>();

  /// Load a BMP image from a seekable SDL data stream.
  ///
  /// The new surface should be freed with SDL_FreeSurface(). Not doing so will
  /// result in a memory leak.
  ///
  /// src is an open SDL_RWops buffer, typically loaded with SDL_RWFromFile.
  /// Alternitavely, you might also use the macro SDL_LoadBMP to load a bitmap
  /// from a file, convert it to an SDL_Surface and then close the file.
  ///
  /// \param src the data stream for the surface
  /// \param freesrc non-zero to close the stream after being read
  /// \returns a pointer to a new SDL_Surface structure or NULL if there was an
  /// error; call SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_FreeSurface
  /// \sa SDL_RWFromFile
  /// \sa SDL_LoadBMP
  /// \sa SDL_SaveBMP_RW
  ffi.Pointer<SDL_Surface> SDL_LoadBMP_RW(
    ffi.Pointer<SDL_RWops> src,
    int freesrc,
  ) {
    return _SDL_LoadBMP_RW(
      src,
      freesrc,
    );
  }

  late final _SDL_LoadBMP_RWPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<SDL_Surface> Function(
              ffi.Pointer<SDL_RWops>, ffi.Int32)>>('SDL_LoadBMP_RW');
  late final _SDL_LoadBMP_RW = _SDL_LoadBMP_RWPtr.asFunction<
      ffi.Pointer<SDL_Surface> Function(ffi.Pointer<SDL_RWops>, int)>();

  /// Save a surface to a seekable SDL data stream in BMP format.
  ///
  /// Surfaces with a 24-bit, 32-bit and paletted 8-bit format get saved in the
  /// BMP directly. Other RGB formats with 8-bit or higher get converted to a
  /// 24-bit surface or, if they have an alpha mask or a colorkey, to a 32-bit
  /// surface before they are saved. YUV and paletted 1-bit and 4-bit formats are
  /// not supported.
  ///
  /// \param surface the SDL_Surface structure containing the image to be saved
  /// \param dst a data stream to save to
  /// \param freedst non-zero to close the stream after being written
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_LoadBMP_RW
  /// \sa SDL_SaveBMP
  int SDL_SaveBMP_RW(
    ffi.Pointer<SDL_Surface> surface,
    ffi.Pointer<SDL_RWops> dst,
    int freedst,
  ) {
    return _SDL_SaveBMP_RW(
      surface,
      dst,
      freedst,
    );
  }

  late final _SDL_SaveBMP_RWPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_Surface>, ffi.Pointer<SDL_RWops>,
              ffi.Int32)>>('SDL_SaveBMP_RW');
  late final _SDL_SaveBMP_RW = _SDL_SaveBMP_RWPtr.asFunction<
      int Function(ffi.Pointer<SDL_Surface>, ffi.Pointer<SDL_RWops>, int)>();

  /// Set the RLE acceleration hint for a surface.
  ///
  /// If RLE is enabled, color key and alpha blending blits are much faster, but
  /// the surface must be locked before directly accessing the pixels.
  ///
  /// \param surface the SDL_Surface structure to optimize
  /// \param flag 0 to disable, non-zero to enable RLE acceleration
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_BlitSurface
  /// \sa SDL_LockSurface
  /// \sa SDL_UnlockSurface
  int SDL_SetSurfaceRLE(
    ffi.Pointer<SDL_Surface> surface,
    int flag,
  ) {
    return _SDL_SetSurfaceRLE(
      surface,
      flag,
    );
  }

  late final _SDL_SetSurfaceRLEPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<SDL_Surface>, ffi.Int32)>>('SDL_SetSurfaceRLE');
  late final _SDL_SetSurfaceRLE = _SDL_SetSurfaceRLEPtr.asFunction<
      int Function(ffi.Pointer<SDL_Surface>, int)>();

  /// Returns whether the surface is RLE enabled
  ///
  /// It is safe to pass a NULL `surface` here; it will return SDL_FALSE.
  ///
  /// \param surface the SDL_Surface structure to query
  /// \returns SDL_TRUE if the surface is RLE enabled, SDL_FALSE otherwise.
  ///
  /// \since This function is available since SDL 2.0.14.
  ///
  /// \sa SDL_SetSurfaceRLE
  int SDL_HasSurfaceRLE(
    ffi.Pointer<SDL_Surface> surface,
  ) {
    return _SDL_HasSurfaceRLE(
      surface,
    );
  }

  late final _SDL_HasSurfaceRLEPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<SDL_Surface>)>>(
          'SDL_HasSurfaceRLE');
  late final _SDL_HasSurfaceRLE = _SDL_HasSurfaceRLEPtr.asFunction<
      int Function(ffi.Pointer<SDL_Surface>)>();

  /// Set the color key (transparent pixel) in a surface.
  ///
  /// The color key defines a pixel value that will be treated as transparent in
  /// a blit. For example, one can use this to specify that cyan pixels should be
  /// considered transparent, and therefore not rendered.
  ///
  /// It is a pixel of the format used by the surface, as generated by
  /// SDL_MapRGB().
  ///
  /// RLE acceleration can substantially speed up blitting of images with large
  /// horizontal runs of transparent pixels. See SDL_SetSurfaceRLE() for details.
  ///
  /// \param surface the SDL_Surface structure to update
  /// \param flag SDL_TRUE to enable color key, SDL_FALSE to disable color key
  /// \param key the transparent pixel
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_BlitSurface
  /// \sa SDL_GetColorKey
  int SDL_SetColorKey(
    ffi.Pointer<SDL_Surface> surface,
    int flag,
    int key,
  ) {
    return _SDL_SetColorKey(
      surface,
      flag,
      key,
    );
  }

  late final _SDL_SetColorKeyPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<SDL_Surface>, ffi.Int32, Uint32)>>('SDL_SetColorKey');
  late final _SDL_SetColorKey = _SDL_SetColorKeyPtr.asFunction<
      int Function(ffi.Pointer<SDL_Surface>, int, int)>();

  /// Returns whether the surface has a color key
  ///
  /// It is safe to pass a NULL `surface` here; it will return SDL_FALSE.
  ///
  /// \param surface the SDL_Surface structure to query
  /// \return SDL_TRUE if the surface has a color key, SDL_FALSE otherwise.
  ///
  /// \since This function is available since SDL 2.0.9.
  ///
  /// \sa SDL_SetColorKey
  /// \sa SDL_GetColorKey
  int SDL_HasColorKey(
    ffi.Pointer<SDL_Surface> surface,
  ) {
    return _SDL_HasColorKey(
      surface,
    );
  }

  late final _SDL_HasColorKeyPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<SDL_Surface>)>>(
          'SDL_HasColorKey');
  late final _SDL_HasColorKey =
      _SDL_HasColorKeyPtr.asFunction<int Function(ffi.Pointer<SDL_Surface>)>();

  /// Get the color key (transparent pixel) for a surface.
  ///
  /// The color key is a pixel of the format used by the surface, as generated by
  /// SDL_MapRGB().
  ///
  /// If the surface doesn't have color key enabled this function returns -1.
  ///
  /// \param surface the SDL_Surface structure to query
  /// \param key a pointer filled in with the transparent pixel
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_BlitSurface
  /// \sa SDL_SetColorKey
  int SDL_GetColorKey(
    ffi.Pointer<SDL_Surface> surface,
    ffi.Pointer<Uint32> key,
  ) {
    return _SDL_GetColorKey(
      surface,
      key,
    );
  }

  late final _SDL_GetColorKeyPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_Surface>,
              ffi.Pointer<Uint32>)>>('SDL_GetColorKey');
  late final _SDL_GetColorKey = _SDL_GetColorKeyPtr.asFunction<
      int Function(ffi.Pointer<SDL_Surface>, ffi.Pointer<Uint32>)>();

  /// Set an additional color value multiplied into blit operations.
  ///
  /// When this surface is blitted, during the blit operation each source color
  /// channel is modulated by the appropriate color value according to the
  /// following formula:
  ///
  /// `srcC = srcC * (color / 255)`
  ///
  /// \param surface the SDL_Surface structure to update
  /// \param r the red color value multiplied into blit operations
  /// \param g the green color value multiplied into blit operations
  /// \param b the blue color value multiplied into blit operations
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetSurfaceColorMod
  /// \sa SDL_SetSurfaceAlphaMod
  int SDL_SetSurfaceColorMod(
    ffi.Pointer<SDL_Surface> surface,
    int r,
    int g,
    int b,
  ) {
    return _SDL_SetSurfaceColorMod(
      surface,
      r,
      g,
      b,
    );
  }

  late final _SDL_SetSurfaceColorModPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_Surface>, Uint8, Uint8,
              Uint8)>>('SDL_SetSurfaceColorMod');
  late final _SDL_SetSurfaceColorMod = _SDL_SetSurfaceColorModPtr.asFunction<
      int Function(ffi.Pointer<SDL_Surface>, int, int, int)>();

  /// Get the additional color value multiplied into blit operations.
  ///
  /// \param surface the SDL_Surface structure to query
  /// \param r a pointer filled in with the current red color value
  /// \param g a pointer filled in with the current green color value
  /// \param b a pointer filled in with the current blue color value
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetSurfaceAlphaMod
  /// \sa SDL_SetSurfaceColorMod
  int SDL_GetSurfaceColorMod(
    ffi.Pointer<SDL_Surface> surface,
    ffi.Pointer<Uint8> r,
    ffi.Pointer<Uint8> g,
    ffi.Pointer<Uint8> b,
  ) {
    return _SDL_GetSurfaceColorMod(
      surface,
      r,
      g,
      b,
    );
  }

  late final _SDL_GetSurfaceColorModPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<SDL_Surface>,
              ffi.Pointer<Uint8>,
              ffi.Pointer<Uint8>,
              ffi.Pointer<Uint8>)>>('SDL_GetSurfaceColorMod');
  late final _SDL_GetSurfaceColorMod = _SDL_GetSurfaceColorModPtr.asFunction<
      int Function(ffi.Pointer<SDL_Surface>, ffi.Pointer<Uint8>,
          ffi.Pointer<Uint8>, ffi.Pointer<Uint8>)>();

  /// Set an additional alpha value used in blit operations.
  ///
  /// When this surface is blitted, during the blit operation the source alpha
  /// value is modulated by this alpha value according to the following formula:
  ///
  /// `srcA = srcA * (alpha / 255)`
  ///
  /// \param surface the SDL_Surface structure to update
  /// \param alpha the alpha value multiplied into blit operations
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetSurfaceAlphaMod
  /// \sa SDL_SetSurfaceColorMod
  int SDL_SetSurfaceAlphaMod(
    ffi.Pointer<SDL_Surface> surface,
    int alpha,
  ) {
    return _SDL_SetSurfaceAlphaMod(
      surface,
      alpha,
    );
  }

  late final _SDL_SetSurfaceAlphaModPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<SDL_Surface>, Uint8)>>('SDL_SetSurfaceAlphaMod');
  late final _SDL_SetSurfaceAlphaMod = _SDL_SetSurfaceAlphaModPtr.asFunction<
      int Function(ffi.Pointer<SDL_Surface>, int)>();

  /// Get the additional alpha value used in blit operations.
  ///
  /// \param surface the SDL_Surface structure to query
  /// \param alpha a pointer filled in with the current alpha value
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetSurfaceColorMod
  /// \sa SDL_SetSurfaceAlphaMod
  int SDL_GetSurfaceAlphaMod(
    ffi.Pointer<SDL_Surface> surface,
    ffi.Pointer<Uint8> alpha,
  ) {
    return _SDL_GetSurfaceAlphaMod(
      surface,
      alpha,
    );
  }

  late final _SDL_GetSurfaceAlphaModPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_Surface>,
              ffi.Pointer<Uint8>)>>('SDL_GetSurfaceAlphaMod');
  late final _SDL_GetSurfaceAlphaMod = _SDL_GetSurfaceAlphaModPtr.asFunction<
      int Function(ffi.Pointer<SDL_Surface>, ffi.Pointer<Uint8>)>();

  /// Set the blend mode used for blit operations.
  ///
  /// To copy a surface to another surface (or texture) without blending with the
  /// existing data, the blendmode of the SOURCE surface should be set to
  /// `SDL_BLENDMODE_NONE`.
  ///
  /// \param surface the SDL_Surface structure to update
  /// \param blendMode the SDL_BlendMode to use for blit blending
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetSurfaceBlendMode
  int SDL_SetSurfaceBlendMode(
    ffi.Pointer<SDL_Surface> surface,
    int blendMode,
  ) {
    return _SDL_SetSurfaceBlendMode(
      surface,
      blendMode,
    );
  }

  late final _SDL_SetSurfaceBlendModePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<SDL_Surface>, ffi.Int32)>>('SDL_SetSurfaceBlendMode');
  late final _SDL_SetSurfaceBlendMode = _SDL_SetSurfaceBlendModePtr.asFunction<
      int Function(ffi.Pointer<SDL_Surface>, int)>();

  /// Get the blend mode used for blit operations.
  ///
  /// \param surface the SDL_Surface structure to query
  /// \param blendMode a pointer filled in with the current SDL_BlendMode
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_SetSurfaceBlendMode
  int SDL_GetSurfaceBlendMode(
    ffi.Pointer<SDL_Surface> surface,
    ffi.Pointer<ffi.Int32> blendMode,
  ) {
    return _SDL_GetSurfaceBlendMode(
      surface,
      blendMode,
    );
  }

  late final _SDL_GetSurfaceBlendModePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_Surface>,
              ffi.Pointer<ffi.Int32>)>>('SDL_GetSurfaceBlendMode');
  late final _SDL_GetSurfaceBlendMode = _SDL_GetSurfaceBlendModePtr.asFunction<
      int Function(ffi.Pointer<SDL_Surface>, ffi.Pointer<ffi.Int32>)>();

  /// Set the clipping rectangle for a surface.
  ///
  /// When `surface` is the destination of a blit, only the area within the clip
  /// rectangle is drawn into.
  ///
  /// Note that blits are automatically clipped to the edges of the source and
  /// destination surfaces.
  ///
  /// \param surface the SDL_Surface structure to be clipped
  /// \param rect the SDL_Rect structure representing the clipping rectangle, or
  /// NULL to disable clipping
  /// \returns SDL_TRUE if the rectangle intersects the surface, otherwise
  /// SDL_FALSE and blits will be completely clipped.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_BlitSurface
  /// \sa SDL_GetClipRect
  int SDL_SetClipRect(
    ffi.Pointer<SDL_Surface> surface,
    ffi.Pointer<SDL_Rect> rect,
  ) {
    return _SDL_SetClipRect(
      surface,
      rect,
    );
  }

  late final _SDL_SetClipRectPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_Surface>,
              ffi.Pointer<SDL_Rect>)>>('SDL_SetClipRect');
  late final _SDL_SetClipRect = _SDL_SetClipRectPtr.asFunction<
      int Function(ffi.Pointer<SDL_Surface>, ffi.Pointer<SDL_Rect>)>();

  /// Get the clipping rectangle for a surface.
  ///
  /// When `surface` is the destination of a blit, only the area within the clip
  /// rectangle is drawn into.
  ///
  /// \param surface the SDL_Surface structure representing the surface to be
  /// clipped
  /// \param rect an SDL_Rect structure filled in with the clipping rectangle for
  /// the surface
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_BlitSurface
  /// \sa SDL_SetClipRect
  void SDL_GetClipRect(
    ffi.Pointer<SDL_Surface> surface,
    ffi.Pointer<SDL_Rect> rect,
  ) {
    return _SDL_GetClipRect(
      surface,
      rect,
    );
  }

  late final _SDL_GetClipRectPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<SDL_Surface>,
              ffi.Pointer<SDL_Rect>)>>('SDL_GetClipRect');
  late final _SDL_GetClipRect = _SDL_GetClipRectPtr.asFunction<
      void Function(ffi.Pointer<SDL_Surface>, ffi.Pointer<SDL_Rect>)>();

  ffi.Pointer<SDL_Surface> SDL_DuplicateSurface(
    ffi.Pointer<SDL_Surface> surface,
  ) {
    return _SDL_DuplicateSurface(
      surface,
    );
  }

  late final _SDL_DuplicateSurfacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<SDL_Surface> Function(
              ffi.Pointer<SDL_Surface>)>>('SDL_DuplicateSurface');
  late final _SDL_DuplicateSurface = _SDL_DuplicateSurfacePtr.asFunction<
      ffi.Pointer<SDL_Surface> Function(ffi.Pointer<SDL_Surface>)>();

  /// Copy an existing surface to a new surface of the specified format.
  ///
  /// This function is used to optimize images for faster *repeat* blitting. This
  /// is accomplished by converting the original and storing the result as a new
  /// surface. The new, optimized surface can then be used as the source for
  /// future blits, making them faster.
  ///
  /// \param src the existing SDL_Surface structure to convert
  /// \param fmt the SDL_PixelFormat structure that the new surface is optimized
  /// for
  /// \param flags the flags are unused and should be set to 0; this is a
  /// leftover from SDL 1.2's API
  /// \returns the new SDL_Surface structure that is created or NULL if it fails;
  /// call SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_AllocFormat
  /// \sa SDL_ConvertSurfaceFormat
  /// \sa SDL_CreateRGBSurface
  ffi.Pointer<SDL_Surface> SDL_ConvertSurface(
    ffi.Pointer<SDL_Surface> src,
    ffi.Pointer<SDL_PixelFormat> fmt,
    int flags,
  ) {
    return _SDL_ConvertSurface(
      src,
      fmt,
      flags,
    );
  }

  late final _SDL_ConvertSurfacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<SDL_Surface> Function(ffi.Pointer<SDL_Surface>,
              ffi.Pointer<SDL_PixelFormat>, Uint32)>>('SDL_ConvertSurface');
  late final _SDL_ConvertSurface = _SDL_ConvertSurfacePtr.asFunction<
      ffi.Pointer<SDL_Surface> Function(
          ffi.Pointer<SDL_Surface>, ffi.Pointer<SDL_PixelFormat>, int)>();

  /// Copy an existing surface to a new surface of the specified format enum.
  ///
  /// This function operates just like SDL_ConvertSurface(), but accepts an
  /// SDL_PixelFormatEnum value instead of an SDL_PixelFormat structure. As such,
  /// it might be easier to call but it doesn't have access to palette
  /// information for the destination surface, in case that would be important.
  ///
  /// \param src the existing SDL_Surface structure to convert
  /// \param pixel_format the SDL_PixelFormatEnum that the new surface is
  /// optimized for
  /// \param flags the flags are unused and should be set to 0; this is a
  /// leftover from SDL 1.2's API
  /// \returns the new SDL_Surface structure that is created or NULL if it fails;
  /// call SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_AllocFormat
  /// \sa SDL_ConvertSurface
  /// \sa SDL_CreateRGBSurface
  ffi.Pointer<SDL_Surface> SDL_ConvertSurfaceFormat(
    ffi.Pointer<SDL_Surface> src,
    int pixel_format,
    int flags,
  ) {
    return _SDL_ConvertSurfaceFormat(
      src,
      pixel_format,
      flags,
    );
  }

  late final _SDL_ConvertSurfaceFormatPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<SDL_Surface> Function(ffi.Pointer<SDL_Surface>, Uint32,
              Uint32)>>('SDL_ConvertSurfaceFormat');
  late final _SDL_ConvertSurfaceFormat =
      _SDL_ConvertSurfaceFormatPtr.asFunction<
          ffi.Pointer<SDL_Surface> Function(
              ffi.Pointer<SDL_Surface>, int, int)>();

  /// Copy a block of pixels of one format to another format.
  ///
  /// \param width the width of the block to copy, in pixels
  /// \param height the height of the block to copy, in pixels
  /// \param src_format an SDL_PixelFormatEnum value of the `src` pixels format
  /// \param src a pointer to the source pixels
  /// \param src_pitch the pitch of the source pixels, in bytes
  /// \param dst_format an SDL_PixelFormatEnum value of the `dst` pixels format
  /// \param dst a pointer to be filled in with new pixel data
  /// \param dst_pitch the pitch of the destination pixels, in bytes
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  int SDL_ConvertPixels(
    int width,
    int height,
    int src_format,
    ffi.Pointer<ffi.Void> src,
    int src_pitch,
    int dst_format,
    ffi.Pointer<ffi.Void> dst,
    int dst_pitch,
  ) {
    return _SDL_ConvertPixels(
      width,
      height,
      src_format,
      src,
      src_pitch,
      dst_format,
      dst,
      dst_pitch,
    );
  }

  late final _SDL_ConvertPixelsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Int32,
              ffi.Int32,
              Uint32,
              ffi.Pointer<ffi.Void>,
              ffi.Int32,
              Uint32,
              ffi.Pointer<ffi.Void>,
              ffi.Int32)>>('SDL_ConvertPixels');
  late final _SDL_ConvertPixels = _SDL_ConvertPixelsPtr.asFunction<
      int Function(int, int, int, ffi.Pointer<ffi.Void>, int, int,
          ffi.Pointer<ffi.Void>, int)>();

  /// Premultiply the alpha on a block of pixels.
  ///
  /// This is safe to use with src == dst, but not for other overlapping areas.
  ///
  /// This function is currently only implemented for SDL_PIXELFORMAT_ARGB8888.
  ///
  /// \param width the width of the block to convert, in pixels
  /// \param height the height of the block to convert, in pixels
  /// \param src_format an SDL_PixelFormatEnum value of the `src` pixels format
  /// \param src a pointer to the source pixels
  /// \param src_pitch the pitch of the source pixels, in bytes
  /// \param dst_format an SDL_PixelFormatEnum value of the `dst` pixels format
  /// \param dst a pointer to be filled in with premultiplied pixel data
  /// \param dst_pitch the pitch of the destination pixels, in bytes
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.18.
  int SDL_PremultiplyAlpha(
    int width,
    int height,
    int src_format,
    ffi.Pointer<ffi.Void> src,
    int src_pitch,
    int dst_format,
    ffi.Pointer<ffi.Void> dst,
    int dst_pitch,
  ) {
    return _SDL_PremultiplyAlpha(
      width,
      height,
      src_format,
      src,
      src_pitch,
      dst_format,
      dst,
      dst_pitch,
    );
  }

  late final _SDL_PremultiplyAlphaPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Int32,
              ffi.Int32,
              Uint32,
              ffi.Pointer<ffi.Void>,
              ffi.Int32,
              Uint32,
              ffi.Pointer<ffi.Void>,
              ffi.Int32)>>('SDL_PremultiplyAlpha');
  late final _SDL_PremultiplyAlpha = _SDL_PremultiplyAlphaPtr.asFunction<
      int Function(int, int, int, ffi.Pointer<ffi.Void>, int, int,
          ffi.Pointer<ffi.Void>, int)>();

  /// Perform a fast fill of a rectangle with a specific color.
  ///
  /// `color` should be a pixel of the format used by the surface, and can be
  /// generated by SDL_MapRGB() or SDL_MapRGBA(). If the color value contains an
  /// alpha component then the destination is simply filled with that alpha
  /// information, no blending takes place.
  ///
  /// If there is a clip rectangle set on the destination (set via
  /// SDL_SetClipRect()), then this function will fill based on the intersection
  /// of the clip rectangle and `rect`.
  ///
  /// \param dst the SDL_Surface structure that is the drawing target
  /// \param rect the SDL_Rect structure representing the rectangle to fill, or
  /// NULL to fill the entire surface
  /// \param color the color to fill with
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_FillRects
  int SDL_FillRect(
    ffi.Pointer<SDL_Surface> dst,
    ffi.Pointer<SDL_Rect> rect,
    int color,
  ) {
    return _SDL_FillRect(
      dst,
      rect,
      color,
    );
  }

  late final _SDL_FillRectPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_Surface>, ffi.Pointer<SDL_Rect>,
              Uint32)>>('SDL_FillRect');
  late final _SDL_FillRect = _SDL_FillRectPtr.asFunction<
      int Function(ffi.Pointer<SDL_Surface>, ffi.Pointer<SDL_Rect>, int)>();

  /// Perform a fast fill of a set of rectangles with a specific color.
  ///
  /// `color` should be a pixel of the format used by the surface, and can be
  /// generated by SDL_MapRGB() or SDL_MapRGBA(). If the color value contains an
  /// alpha component then the destination is simply filled with that alpha
  /// information, no blending takes place.
  ///
  /// If there is a clip rectangle set on the destination (set via
  /// SDL_SetClipRect()), then this function will fill based on the intersection
  /// of the clip rectangle and `rect`.
  ///
  /// \param dst the SDL_Surface structure that is the drawing target
  /// \param rects an array of SDL_Rects representing the rectangles to fill.
  /// \param count the number of rectangles in the array
  /// \param color the color to fill with
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_FillRect
  int SDL_FillRects(
    ffi.Pointer<SDL_Surface> dst,
    ffi.Pointer<SDL_Rect> rects,
    int count,
    int color,
  ) {
    return _SDL_FillRects(
      dst,
      rects,
      count,
      color,
    );
  }

  late final _SDL_FillRectsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_Surface>, ffi.Pointer<SDL_Rect>,
              ffi.Int32, Uint32)>>('SDL_FillRects');
  late final _SDL_FillRects = _SDL_FillRectsPtr.asFunction<
      int Function(
          ffi.Pointer<SDL_Surface>, ffi.Pointer<SDL_Rect>, int, int)>();

  /// Perform a fast blit from the source surface to the destination surface.
  ///
  /// SDL_UpperBlit() has been replaced by SDL_BlitSurface(), which is merely a
  /// macro for this function with a less confusing name.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_BlitSurface
  int SDL_UpperBlit(
    ffi.Pointer<SDL_Surface> src,
    ffi.Pointer<SDL_Rect> srcrect,
    ffi.Pointer<SDL_Surface> dst,
    ffi.Pointer<SDL_Rect> dstrect,
  ) {
    return _SDL_UpperBlit(
      src,
      srcrect,
      dst,
      dstrect,
    );
  }

  late final _SDL_UpperBlitPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<SDL_Surface>,
              ffi.Pointer<SDL_Rect>,
              ffi.Pointer<SDL_Surface>,
              ffi.Pointer<SDL_Rect>)>>('SDL_UpperBlit');
  late final _SDL_UpperBlit = _SDL_UpperBlitPtr.asFunction<
      int Function(ffi.Pointer<SDL_Surface>, ffi.Pointer<SDL_Rect>,
          ffi.Pointer<SDL_Surface>, ffi.Pointer<SDL_Rect>)>();

  /// Perform low-level surface blitting only.
  ///
  /// This is a semi-private blit function and it performs low-level surface
  /// blitting, assuming the input rectangles have already been clipped.
  ///
  /// Unless you know what you're doing, you should be using SDL_BlitSurface()
  /// instead.
  ///
  /// \param src the SDL_Surface structure to be copied from
  /// \param srcrect the SDL_Rect structure representing the rectangle to be
  /// copied, or NULL to copy the entire surface
  /// \param dst the SDL_Surface structure that is the blit target
  /// \param dstrect the SDL_Rect structure representing the rectangle that is
  /// copied into
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_BlitSurface
  int SDL_LowerBlit(
    ffi.Pointer<SDL_Surface> src,
    ffi.Pointer<SDL_Rect> srcrect,
    ffi.Pointer<SDL_Surface> dst,
    ffi.Pointer<SDL_Rect> dstrect,
  ) {
    return _SDL_LowerBlit(
      src,
      srcrect,
      dst,
      dstrect,
    );
  }

  late final _SDL_LowerBlitPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<SDL_Surface>,
              ffi.Pointer<SDL_Rect>,
              ffi.Pointer<SDL_Surface>,
              ffi.Pointer<SDL_Rect>)>>('SDL_LowerBlit');
  late final _SDL_LowerBlit = _SDL_LowerBlitPtr.asFunction<
      int Function(ffi.Pointer<SDL_Surface>, ffi.Pointer<SDL_Rect>,
          ffi.Pointer<SDL_Surface>, ffi.Pointer<SDL_Rect>)>();

  /// Perform a fast, low quality, stretch blit between two surfaces of the same
  /// format.
  ///
  /// Please use SDL_BlitScaled() instead.
  ///
  /// \since This function is available since SDL 2.0.0.
  int SDL_SoftStretch(
    ffi.Pointer<SDL_Surface> src,
    ffi.Pointer<SDL_Rect> srcrect,
    ffi.Pointer<SDL_Surface> dst,
    ffi.Pointer<SDL_Rect> dstrect,
  ) {
    return _SDL_SoftStretch(
      src,
      srcrect,
      dst,
      dstrect,
    );
  }

  late final _SDL_SoftStretchPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<SDL_Surface>,
              ffi.Pointer<SDL_Rect>,
              ffi.Pointer<SDL_Surface>,
              ffi.Pointer<SDL_Rect>)>>('SDL_SoftStretch');
  late final _SDL_SoftStretch = _SDL_SoftStretchPtr.asFunction<
      int Function(ffi.Pointer<SDL_Surface>, ffi.Pointer<SDL_Rect>,
          ffi.Pointer<SDL_Surface>, ffi.Pointer<SDL_Rect>)>();

  /// Perform bilinear scaling between two surfaces of the same format, 32BPP.
  ///
  /// \since This function is available since SDL 2.0.16.
  int SDL_SoftStretchLinear(
    ffi.Pointer<SDL_Surface> src,
    ffi.Pointer<SDL_Rect> srcrect,
    ffi.Pointer<SDL_Surface> dst,
    ffi.Pointer<SDL_Rect> dstrect,
  ) {
    return _SDL_SoftStretchLinear(
      src,
      srcrect,
      dst,
      dstrect,
    );
  }

  late final _SDL_SoftStretchLinearPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<SDL_Surface>,
              ffi.Pointer<SDL_Rect>,
              ffi.Pointer<SDL_Surface>,
              ffi.Pointer<SDL_Rect>)>>('SDL_SoftStretchLinear');
  late final _SDL_SoftStretchLinear = _SDL_SoftStretchLinearPtr.asFunction<
      int Function(ffi.Pointer<SDL_Surface>, ffi.Pointer<SDL_Rect>,
          ffi.Pointer<SDL_Surface>, ffi.Pointer<SDL_Rect>)>();

  /// Perform a scaled surface copy to a destination surface.
  ///
  /// SDL_UpperBlitScaled() has been replaced by SDL_BlitScaled(), which is
  /// merely a macro for this function with a less confusing name.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_BlitScaled
  int SDL_UpperBlitScaled(
    ffi.Pointer<SDL_Surface> src,
    ffi.Pointer<SDL_Rect> srcrect,
    ffi.Pointer<SDL_Surface> dst,
    ffi.Pointer<SDL_Rect> dstrect,
  ) {
    return _SDL_UpperBlitScaled(
      src,
      srcrect,
      dst,
      dstrect,
    );
  }

  late final _SDL_UpperBlitScaledPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<SDL_Surface>,
              ffi.Pointer<SDL_Rect>,
              ffi.Pointer<SDL_Surface>,
              ffi.Pointer<SDL_Rect>)>>('SDL_UpperBlitScaled');
  late final _SDL_UpperBlitScaled = _SDL_UpperBlitScaledPtr.asFunction<
      int Function(ffi.Pointer<SDL_Surface>, ffi.Pointer<SDL_Rect>,
          ffi.Pointer<SDL_Surface>, ffi.Pointer<SDL_Rect>)>();

  /// Perform low-level surface scaled blitting only.
  ///
  /// This is a semi-private function and it performs low-level surface blitting,
  /// assuming the input rectangles have already been clipped.
  ///
  /// \param src the SDL_Surface structure to be copied from
  /// \param srcrect the SDL_Rect structure representing the rectangle to be
  /// copied
  /// \param dst the SDL_Surface structure that is the blit target
  /// \param dstrect the SDL_Rect structure representing the rectangle that is
  /// copied into
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_BlitScaled
  int SDL_LowerBlitScaled(
    ffi.Pointer<SDL_Surface> src,
    ffi.Pointer<SDL_Rect> srcrect,
    ffi.Pointer<SDL_Surface> dst,
    ffi.Pointer<SDL_Rect> dstrect,
  ) {
    return _SDL_LowerBlitScaled(
      src,
      srcrect,
      dst,
      dstrect,
    );
  }

  late final _SDL_LowerBlitScaledPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<SDL_Surface>,
              ffi.Pointer<SDL_Rect>,
              ffi.Pointer<SDL_Surface>,
              ffi.Pointer<SDL_Rect>)>>('SDL_LowerBlitScaled');
  late final _SDL_LowerBlitScaled = _SDL_LowerBlitScaledPtr.asFunction<
      int Function(ffi.Pointer<SDL_Surface>, ffi.Pointer<SDL_Rect>,
          ffi.Pointer<SDL_Surface>, ffi.Pointer<SDL_Rect>)>();

  /// Set the YUV conversion mode
  ///
  /// \since This function is available since SDL 2.0.8.
  void SDL_SetYUVConversionMode(
    int mode,
  ) {
    return _SDL_SetYUVConversionMode(
      mode,
    );
  }

  late final _SDL_SetYUVConversionModePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Int32)>>(
          'SDL_SetYUVConversionMode');
  late final _SDL_SetYUVConversionMode =
      _SDL_SetYUVConversionModePtr.asFunction<void Function(int)>();

  /// Get the YUV conversion mode
  ///
  /// \since This function is available since SDL 2.0.8.
  int SDL_GetYUVConversionMode() {
    return _SDL_GetYUVConversionMode();
  }

  late final _SDL_GetYUVConversionModePtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function()>>(
          'SDL_GetYUVConversionMode');
  late final _SDL_GetYUVConversionMode =
      _SDL_GetYUVConversionModePtr.asFunction<int Function()>();

  /// Get the YUV conversion mode, returning the correct mode for the resolution
  /// when the current conversion mode is SDL_YUV_CONVERSION_AUTOMATIC
  ///
  /// \since This function is available since SDL 2.0.8.
  int SDL_GetYUVConversionModeForResolution(
    int width,
    int height,
  ) {
    return _SDL_GetYUVConversionModeForResolution(
      width,
      height,
    );
  }

  late final _SDL_GetYUVConversionModeForResolutionPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Int32, ffi.Int32)>>(
          'SDL_GetYUVConversionModeForResolution');
  late final _SDL_GetYUVConversionModeForResolution =
      _SDL_GetYUVConversionModeForResolutionPtr.asFunction<
          int Function(int, int)>();

  /// Get the number of video drivers compiled into SDL.
  ///
  /// \returns a number >= 1 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetVideoDriver
  int SDL_GetNumVideoDrivers() {
    return _SDL_GetNumVideoDrivers();
  }

  late final _SDL_GetNumVideoDriversPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function()>>(
          'SDL_GetNumVideoDrivers');
  late final _SDL_GetNumVideoDrivers =
      _SDL_GetNumVideoDriversPtr.asFunction<int Function()>();

  /// Get the name of a built in video driver.
  ///
  /// The video drivers are presented in the order in which they are normally
  /// checked during initialization.
  ///
  /// \param index the index of a video driver
  /// \returns the name of the video driver with the given **index**.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetNumVideoDrivers
  ffi.Pointer<ffi.Int8> SDL_GetVideoDriver(
    int index,
  ) {
    return _SDL_GetVideoDriver(
      index,
    );
  }

  late final _SDL_GetVideoDriverPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Int8> Function(ffi.Int32)>>(
          'SDL_GetVideoDriver');
  late final _SDL_GetVideoDriver =
      _SDL_GetVideoDriverPtr.asFunction<ffi.Pointer<ffi.Int8> Function(int)>();

  /// Initialize the video subsystem, optionally specifying a video driver.
  ///
  /// This function initializes the video subsystem, setting up a connection to
  /// the window manager, etc, and determines the available display modes and
  /// pixel formats, but does not initialize a window or graphics mode.
  ///
  /// If you use this function and you haven't used the SDL_INIT_VIDEO flag with
  /// either SDL_Init() or SDL_InitSubSystem(), you should call SDL_VideoQuit()
  /// before calling SDL_Quit().
  ///
  /// It is safe to call this function multiple times. SDL_VideoInit() will call
  /// SDL_VideoQuit() itself if the video subsystem has already been initialized.
  ///
  /// You can use SDL_GetNumVideoDrivers() and SDL_GetVideoDriver() to find a
  /// specific `driver_name`.
  ///
  /// \param driver_name the name of a video driver to initialize, or NULL for
  /// the default driver
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetNumVideoDrivers
  /// \sa SDL_GetVideoDriver
  /// \sa SDL_InitSubSystem
  /// \sa SDL_VideoQuit
  int SDL_VideoInit(
    ffi.Pointer<ffi.Int8> driver_name,
  ) {
    return _SDL_VideoInit(
      driver_name,
    );
  }

  late final _SDL_VideoInitPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<ffi.Int8>)>>(
          'SDL_VideoInit');
  late final _SDL_VideoInit =
      _SDL_VideoInitPtr.asFunction<int Function(ffi.Pointer<ffi.Int8>)>();

  /// Shut down the video subsystem, if initialized with SDL_VideoInit().
  ///
  /// This function closes all windows, and restores the original video mode.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_VideoInit
  void SDL_VideoQuit() {
    return _SDL_VideoQuit();
  }

  late final _SDL_VideoQuitPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('SDL_VideoQuit');
  late final _SDL_VideoQuit = _SDL_VideoQuitPtr.asFunction<void Function()>();

  /// Get the name of the currently initialized video driver.
  ///
  /// \returns the name of the current video driver or NULL if no driver has been
  /// initialized.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetNumVideoDrivers
  /// \sa SDL_GetVideoDriver
  ffi.Pointer<ffi.Int8> SDL_GetCurrentVideoDriver() {
    return _SDL_GetCurrentVideoDriver();
  }

  late final _SDL_GetCurrentVideoDriverPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Int8> Function()>>(
          'SDL_GetCurrentVideoDriver');
  late final _SDL_GetCurrentVideoDriver = _SDL_GetCurrentVideoDriverPtr
      .asFunction<ffi.Pointer<ffi.Int8> Function()>();

  /// Get the number of available video displays.
  ///
  /// \returns a number >= 1 or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetDisplayBounds
  int SDL_GetNumVideoDisplays() {
    return _SDL_GetNumVideoDisplays();
  }

  late final _SDL_GetNumVideoDisplaysPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function()>>(
          'SDL_GetNumVideoDisplays');
  late final _SDL_GetNumVideoDisplays =
      _SDL_GetNumVideoDisplaysPtr.asFunction<int Function()>();

  /// Get the name of a display in UTF-8 encoding.
  ///
  /// \param displayIndex the index of display from which the name should be
  /// queried
  /// \returns the name of a display or NULL for an invalid display index or
  /// failure; call SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetNumVideoDisplays
  ffi.Pointer<ffi.Int8> SDL_GetDisplayName(
    int displayIndex,
  ) {
    return _SDL_GetDisplayName(
      displayIndex,
    );
  }

  late final _SDL_GetDisplayNamePtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Int8> Function(ffi.Int32)>>(
          'SDL_GetDisplayName');
  late final _SDL_GetDisplayName =
      _SDL_GetDisplayNamePtr.asFunction<ffi.Pointer<ffi.Int8> Function(int)>();

  /// Get the desktop area represented by a display.
  ///
  /// The primary display (`displayIndex` zero) is always located at 0,0.
  ///
  /// \param displayIndex the index of the display to query
  /// \param rect the SDL_Rect structure filled in with the display bounds
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetNumVideoDisplays
  int SDL_GetDisplayBounds(
    int displayIndex,
    ffi.Pointer<SDL_Rect> rect,
  ) {
    return _SDL_GetDisplayBounds(
      displayIndex,
      rect,
    );
  }

  late final _SDL_GetDisplayBoundsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Int32, ffi.Pointer<SDL_Rect>)>>('SDL_GetDisplayBounds');
  late final _SDL_GetDisplayBounds = _SDL_GetDisplayBoundsPtr.asFunction<
      int Function(int, ffi.Pointer<SDL_Rect>)>();

  /// Get the usable desktop area represented by a display.
  ///
  /// The primary display (`displayIndex` zero) is always located at 0,0.
  ///
  /// This is the same area as SDL_GetDisplayBounds() reports, but with portions
  /// reserved by the system removed. For example, on Apple's macOS, this
  /// subtracts the area occupied by the menu bar and dock.
  ///
  /// Setting a window to be fullscreen generally bypasses these unusable areas,
  /// so these are good guidelines for the maximum space available to a
  /// non-fullscreen window.
  ///
  /// The parameter `rect` is ignored if it is NULL.
  ///
  /// This function also returns -1 if the parameter `displayIndex` is out of
  /// range.
  ///
  /// \param displayIndex the index of the display to query the usable bounds
  /// from
  /// \param rect the SDL_Rect structure filled in with the display bounds
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.5.
  ///
  /// \sa SDL_GetDisplayBounds
  /// \sa SDL_GetNumVideoDisplays
  int SDL_GetDisplayUsableBounds(
    int displayIndex,
    ffi.Pointer<SDL_Rect> rect,
  ) {
    return _SDL_GetDisplayUsableBounds(
      displayIndex,
      rect,
    );
  }

  late final _SDL_GetDisplayUsableBoundsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Int32, ffi.Pointer<SDL_Rect>)>>('SDL_GetDisplayUsableBounds');
  late final _SDL_GetDisplayUsableBounds = _SDL_GetDisplayUsableBoundsPtr
      .asFunction<int Function(int, ffi.Pointer<SDL_Rect>)>();

  /// Get the dots/pixels-per-inch for a display.
  ///
  /// Diagonal, horizontal and vertical DPI can all be optionally returned if the
  /// appropriate parameter is non-NULL.
  ///
  /// A failure of this function usually means that either no DPI information is
  /// available or the `displayIndex` is out of range.
  ///
  /// \param displayIndex the index of the display from which DPI information
  /// should be queried
  /// \param ddpi a pointer filled in with the diagonal DPI of the display; may
  /// be NULL
  /// \param hdpi a pointer filled in with the horizontal DPI of the display; may
  /// be NULL
  /// \param vdpi a pointer filled in with the vertical DPI of the display; may
  /// be NULL
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.4.
  ///
  /// \sa SDL_GetNumVideoDisplays
  int SDL_GetDisplayDPI(
    int displayIndex,
    ffi.Pointer<ffi.Float> ddpi,
    ffi.Pointer<ffi.Float> hdpi,
    ffi.Pointer<ffi.Float> vdpi,
  ) {
    return _SDL_GetDisplayDPI(
      displayIndex,
      ddpi,
      hdpi,
      vdpi,
    );
  }

  late final _SDL_GetDisplayDPIPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Int32,
              ffi.Pointer<ffi.Float>,
              ffi.Pointer<ffi.Float>,
              ffi.Pointer<ffi.Float>)>>('SDL_GetDisplayDPI');
  late final _SDL_GetDisplayDPI = _SDL_GetDisplayDPIPtr.asFunction<
      int Function(int, ffi.Pointer<ffi.Float>, ffi.Pointer<ffi.Float>,
          ffi.Pointer<ffi.Float>)>();

  /// Get the orientation of a display.
  ///
  /// \param displayIndex the index of the display to query
  /// \returns The SDL_DisplayOrientation enum value of the display, or
  /// `SDL_ORIENTATION_UNKNOWN` if it isn't available.
  ///
  /// \since This function is available since SDL 2.0.9.
  ///
  /// \sa SDL_GetNumVideoDisplays
  int SDL_GetDisplayOrientation(
    int displayIndex,
  ) {
    return _SDL_GetDisplayOrientation(
      displayIndex,
    );
  }

  late final _SDL_GetDisplayOrientationPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Int32)>>(
          'SDL_GetDisplayOrientation');
  late final _SDL_GetDisplayOrientation =
      _SDL_GetDisplayOrientationPtr.asFunction<int Function(int)>();

  /// Get the number of available display modes.
  ///
  /// The `displayIndex` needs to be in the range from 0 to
  /// SDL_GetNumVideoDisplays() - 1.
  ///
  /// \param displayIndex the index of the display to query
  /// \returns a number >= 1 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetDisplayMode
  /// \sa SDL_GetNumVideoDisplays
  int SDL_GetNumDisplayModes(
    int displayIndex,
  ) {
    return _SDL_GetNumDisplayModes(
      displayIndex,
    );
  }

  late final _SDL_GetNumDisplayModesPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Int32)>>(
          'SDL_GetNumDisplayModes');
  late final _SDL_GetNumDisplayModes =
      _SDL_GetNumDisplayModesPtr.asFunction<int Function(int)>();

  /// Get information about a specific display mode.
  ///
  /// The display modes are sorted in this priority:
  ///
  /// - width -> largest to smallest
  /// - height -> largest to smallest
  /// - bits per pixel -> more colors to fewer colors
  /// - packed pixel layout -> largest to smallest
  /// - refresh rate -> highest to lowest
  ///
  /// \param displayIndex the index of the display to query
  /// \param modeIndex the index of the display mode to query
  /// \param mode an SDL_DisplayMode structure filled in with the mode at
  /// `modeIndex`
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetNumDisplayModes
  int SDL_GetDisplayMode(
    int displayIndex,
    int modeIndex,
    ffi.Pointer<SDL_DisplayMode> mode,
  ) {
    return _SDL_GetDisplayMode(
      displayIndex,
      modeIndex,
      mode,
    );
  }

  late final _SDL_GetDisplayModePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Int32, ffi.Int32,
              ffi.Pointer<SDL_DisplayMode>)>>('SDL_GetDisplayMode');
  late final _SDL_GetDisplayMode = _SDL_GetDisplayModePtr.asFunction<
      int Function(int, int, ffi.Pointer<SDL_DisplayMode>)>();

  /// Get information about the desktop's display mode.
  ///
  /// There's a difference between this function and SDL_GetCurrentDisplayMode()
  /// when SDL runs fullscreen and has changed the resolution. In that case this
  /// function will return the previous native display mode, and not the current
  /// display mode.
  ///
  /// \param displayIndex the index of the display to query
  /// \param mode an SDL_DisplayMode structure filled in with the current display
  /// mode
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetCurrentDisplayMode
  /// \sa SDL_GetDisplayMode
  /// \sa SDL_SetWindowDisplayMode
  int SDL_GetDesktopDisplayMode(
    int displayIndex,
    ffi.Pointer<SDL_DisplayMode> mode,
  ) {
    return _SDL_GetDesktopDisplayMode(
      displayIndex,
      mode,
    );
  }

  late final _SDL_GetDesktopDisplayModePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Int32,
              ffi.Pointer<SDL_DisplayMode>)>>('SDL_GetDesktopDisplayMode');
  late final _SDL_GetDesktopDisplayMode = _SDL_GetDesktopDisplayModePtr
      .asFunction<int Function(int, ffi.Pointer<SDL_DisplayMode>)>();

  /// Get information about the current display mode.
  ///
  /// There's a difference between this function and SDL_GetDesktopDisplayMode()
  /// when SDL runs fullscreen and has changed the resolution. In that case this
  /// function will return the current display mode, and not the previous native
  /// display mode.
  ///
  /// \param displayIndex the index of the display to query
  /// \param mode an SDL_DisplayMode structure filled in with the current display
  /// mode
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetDesktopDisplayMode
  /// \sa SDL_GetDisplayMode
  /// \sa SDL_GetNumVideoDisplays
  /// \sa SDL_SetWindowDisplayMode
  int SDL_GetCurrentDisplayMode(
    int displayIndex,
    ffi.Pointer<SDL_DisplayMode> mode,
  ) {
    return _SDL_GetCurrentDisplayMode(
      displayIndex,
      mode,
    );
  }

  late final _SDL_GetCurrentDisplayModePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Int32,
              ffi.Pointer<SDL_DisplayMode>)>>('SDL_GetCurrentDisplayMode');
  late final _SDL_GetCurrentDisplayMode = _SDL_GetCurrentDisplayModePtr
      .asFunction<int Function(int, ffi.Pointer<SDL_DisplayMode>)>();

  /// Get the closest match to the requested display mode.
  ///
  /// The available display modes are scanned and `closest` is filled in with the
  /// closest mode matching the requested mode and returned. The mode format and
  /// refresh rate default to the desktop mode if they are set to 0. The modes
  /// are scanned with size being first priority, format being second priority,
  /// and finally checking the refresh rate. If all the available modes are too
  /// small, then NULL is returned.
  ///
  /// \param displayIndex the index of the display to query
  /// \param mode an SDL_DisplayMode structure containing the desired display
  /// mode
  /// \param closest an SDL_DisplayMode structure filled in with the closest
  /// match of the available display modes
  /// \returns the passed in value `closest` or NULL if no matching video mode
  /// was available; call SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetDisplayMode
  /// \sa SDL_GetNumDisplayModes
  ffi.Pointer<SDL_DisplayMode> SDL_GetClosestDisplayMode(
    int displayIndex,
    ffi.Pointer<SDL_DisplayMode> mode,
    ffi.Pointer<SDL_DisplayMode> closest,
  ) {
    return _SDL_GetClosestDisplayMode(
      displayIndex,
      mode,
      closest,
    );
  }

  late final _SDL_GetClosestDisplayModePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<SDL_DisplayMode> Function(
              ffi.Int32,
              ffi.Pointer<SDL_DisplayMode>,
              ffi.Pointer<SDL_DisplayMode>)>>('SDL_GetClosestDisplayMode');
  late final _SDL_GetClosestDisplayMode =
      _SDL_GetClosestDisplayModePtr.asFunction<
          ffi.Pointer<SDL_DisplayMode> Function(int,
              ffi.Pointer<SDL_DisplayMode>, ffi.Pointer<SDL_DisplayMode>)>();

  /// Get the index of the display associated with a window.
  ///
  /// \param window the window to query
  /// \returns the index of the display containing the center of the window on
  /// success or a negative error code on failure; call SDL_GetError()
  /// for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetDisplayBounds
  /// \sa SDL_GetNumVideoDisplays
  int SDL_GetWindowDisplayIndex(
    ffi.Pointer<SDL_Window> window,
  ) {
    return _SDL_GetWindowDisplayIndex(
      window,
    );
  }

  late final _SDL_GetWindowDisplayIndexPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<SDL_Window>)>>(
          'SDL_GetWindowDisplayIndex');
  late final _SDL_GetWindowDisplayIndex = _SDL_GetWindowDisplayIndexPtr
      .asFunction<int Function(ffi.Pointer<SDL_Window>)>();

  /// Set the display mode to use when a window is visible at fullscreen.
  ///
  /// This only affects the display mode used when the window is fullscreen. To
  /// change the window size when the window is not fullscreen, use
  /// SDL_SetWindowSize().
  ///
  /// \param window the window to affect
  /// \param mode the SDL_DisplayMode structure representing the mode to use, or
  /// NULL to use the window's dimensions and the desktop's format
  /// and refresh rate
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetWindowDisplayMode
  /// \sa SDL_SetWindowFullscreen
  int SDL_SetWindowDisplayMode(
    ffi.Pointer<SDL_Window> window,
    ffi.Pointer<SDL_DisplayMode> mode,
  ) {
    return _SDL_SetWindowDisplayMode(
      window,
      mode,
    );
  }

  late final _SDL_SetWindowDisplayModePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_Window>,
              ffi.Pointer<SDL_DisplayMode>)>>('SDL_SetWindowDisplayMode');
  late final _SDL_SetWindowDisplayMode =
      _SDL_SetWindowDisplayModePtr.asFunction<
          int Function(
              ffi.Pointer<SDL_Window>, ffi.Pointer<SDL_DisplayMode>)>();

  /// Query the display mode to use when a window is visible at fullscreen.
  ///
  /// \param window the window to query
  /// \param mode an SDL_DisplayMode structure filled in with the fullscreen
  /// display mode
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_SetWindowDisplayMode
  /// \sa SDL_SetWindowFullscreen
  int SDL_GetWindowDisplayMode(
    ffi.Pointer<SDL_Window> window,
    ffi.Pointer<SDL_DisplayMode> mode,
  ) {
    return _SDL_GetWindowDisplayMode(
      window,
      mode,
    );
  }

  late final _SDL_GetWindowDisplayModePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_Window>,
              ffi.Pointer<SDL_DisplayMode>)>>('SDL_GetWindowDisplayMode');
  late final _SDL_GetWindowDisplayMode =
      _SDL_GetWindowDisplayModePtr.asFunction<
          int Function(
              ffi.Pointer<SDL_Window>, ffi.Pointer<SDL_DisplayMode>)>();

  /// Get the raw ICC profile data for the screen the window is currently on.
  ///
  /// Data returned should be freed with SDL_free.
  ///
  /// \param window the window to query
  /// \param size the size of the ICC profile
  /// \returns the raw ICC profile data on success or NULL on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.18.
  ffi.Pointer<ffi.Void> SDL_GetWindowICCProfile(
    ffi.Pointer<SDL_Window> window,
    ffi.Pointer<size_t> size,
  ) {
    return _SDL_GetWindowICCProfile(
      window,
      size,
    );
  }

  late final _SDL_GetWindowICCProfilePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Void> Function(ffi.Pointer<SDL_Window>,
              ffi.Pointer<size_t>)>>('SDL_GetWindowICCProfile');
  late final _SDL_GetWindowICCProfile = _SDL_GetWindowICCProfilePtr.asFunction<
      ffi.Pointer<ffi.Void> Function(
          ffi.Pointer<SDL_Window>, ffi.Pointer<size_t>)>();

  /// Get the pixel format associated with the window.
  ///
  /// \param window the window to query
  /// \returns the pixel format of the window on success or
  /// SDL_PIXELFORMAT_UNKNOWN on failure; call SDL_GetError() for more
  /// information.
  ///
  /// \since This function is available since SDL 2.0.0.
  int SDL_GetWindowPixelFormat(
    ffi.Pointer<SDL_Window> window,
  ) {
    return _SDL_GetWindowPixelFormat(
      window,
    );
  }

  late final _SDL_GetWindowPixelFormatPtr =
      _lookup<ffi.NativeFunction<Uint32 Function(ffi.Pointer<SDL_Window>)>>(
          'SDL_GetWindowPixelFormat');
  late final _SDL_GetWindowPixelFormat = _SDL_GetWindowPixelFormatPtr
      .asFunction<int Function(ffi.Pointer<SDL_Window>)>();

  /// Create a window with the specified position, dimensions, and flags.
  ///
  /// `flags` may be any of the following OR'd together:
  ///
  /// - `SDL_WINDOW_FULLSCREEN`: fullscreen window
  /// - `SDL_WINDOW_FULLSCREEN_DESKTOP`: fullscreen window at desktop resolution
  /// - `SDL_WINDOW_OPENGL`: window usable with an OpenGL context
  /// - `SDL_WINDOW_VULKAN`: window usable with a Vulkan instance
  /// - `SDL_WINDOW_METAL`: window usable with a Metal instance
  /// - `SDL_WINDOW_HIDDEN`: window is not visible
  /// - `SDL_WINDOW_BORDERLESS`: no window decoration
  /// - `SDL_WINDOW_RESIZABLE`: window can be resized
  /// - `SDL_WINDOW_MINIMIZED`: window is minimized
  /// - `SDL_WINDOW_MAXIMIZED`: window is maximized
  /// - `SDL_WINDOW_INPUT_GRABBED`: window has grabbed input focus
  /// - `SDL_WINDOW_ALLOW_HIGHDPI`: window should be created in high-DPI mode if
  /// supported (>= SDL 2.0.1)
  ///
  /// `SDL_WINDOW_SHOWN` is ignored by SDL_CreateWindow(). The SDL_Window is
  /// implicitly shown if SDL_WINDOW_HIDDEN is not set. `SDL_WINDOW_SHOWN` may be
  /// queried later using SDL_GetWindowFlags().
  ///
  /// On Apple's macOS, you **must** set the NSHighResolutionCapable Info.plist
  /// property to YES, otherwise you will not receive a High-DPI OpenGL canvas.
  ///
  /// If the window is created with the `SDL_WINDOW_ALLOW_HIGHDPI` flag, its size
  /// in pixels may differ from its size in screen coordinates on platforms with
  /// high-DPI support (e.g. iOS and macOS). Use SDL_GetWindowSize() to query the
  /// client area's size in screen coordinates, and SDL_GL_GetDrawableSize() or
  /// SDL_GetRendererOutputSize() to query the drawable size in pixels.
  ///
  /// If the window is set fullscreen, the width and height parameters `w` and
  /// `h` will not be used. However, invalid size parameters (e.g. too large) may
  /// still fail. Window size is actually limited to 16384 x 16384 for all
  /// platforms at window creation.
  ///
  /// If the window is created with any of the SDL_WINDOW_OPENGL or
  /// SDL_WINDOW_VULKAN flags, then the corresponding LoadLibrary function
  /// (SDL_GL_LoadLibrary or SDL_Vulkan_LoadLibrary) is called and the
  /// corresponding UnloadLibrary function is called by SDL_DestroyWindow().
  ///
  /// If SDL_WINDOW_VULKAN is specified and there isn't a working Vulkan driver,
  /// SDL_CreateWindow() will fail because SDL_Vulkan_LoadLibrary() will fail.
  ///
  /// If SDL_WINDOW_METAL is specified on an OS that does not support Metal,
  /// SDL_CreateWindow() will fail.
  ///
  /// On non-Apple devices, SDL requires you to either not link to the Vulkan
  /// loader or link to a dynamic library version. This limitation may be removed
  /// in a future version of SDL.
  ///
  /// \param title the title of the window, in UTF-8 encoding
  /// \param x the x position of the window, `SDL_WINDOWPOS_CENTERED`, or
  /// `SDL_WINDOWPOS_UNDEFINED`
  /// \param y the y position of the window, `SDL_WINDOWPOS_CENTERED`, or
  /// `SDL_WINDOWPOS_UNDEFINED`
  /// \param w the width of the window, in screen coordinates
  /// \param h the height of the window, in screen coordinates
  /// \param flags 0, or one or more SDL_WindowFlags OR'd together
  /// \returns the window that was created or NULL on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_CreateWindowFrom
  /// \sa SDL_DestroyWindow
  ffi.Pointer<SDL_Window> SDL_CreateWindow(
    ffi.Pointer<ffi.Int8> title,
    int x,
    int y,
    int w,
    int h,
    int flags,
  ) {
    return _SDL_CreateWindow(
      title,
      x,
      y,
      w,
      h,
      flags,
    );
  }

  late final _SDL_CreateWindowPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<SDL_Window> Function(ffi.Pointer<ffi.Int8>, ffi.Int32,
              ffi.Int32, ffi.Int32, ffi.Int32, Uint32)>>('SDL_CreateWindow');
  late final _SDL_CreateWindow = _SDL_CreateWindowPtr.asFunction<
      ffi.Pointer<SDL_Window> Function(
          ffi.Pointer<ffi.Int8>, int, int, int, int, int)>();

  /// Create an SDL window from an existing native window.
  ///
  /// In some cases (e.g. OpenGL) and on some platforms (e.g. Microsoft Windows)
  /// the hint `SDL_HINT_VIDEO_WINDOW_SHARE_PIXEL_FORMAT` needs to be configured
  /// before using SDL_CreateWindowFrom().
  ///
  /// \param data a pointer to driver-dependent window creation data, typically
  /// your native window cast to a void*
  /// \returns the window that was created or NULL on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_CreateWindow
  /// \sa SDL_DestroyWindow
  ffi.Pointer<SDL_Window> SDL_CreateWindowFrom(
    ffi.Pointer<ffi.Void> data,
  ) {
    return _SDL_CreateWindowFrom(
      data,
    );
  }

  late final _SDL_CreateWindowFromPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<SDL_Window> Function(
              ffi.Pointer<ffi.Void>)>>('SDL_CreateWindowFrom');
  late final _SDL_CreateWindowFrom = _SDL_CreateWindowFromPtr.asFunction<
      ffi.Pointer<SDL_Window> Function(ffi.Pointer<ffi.Void>)>();

  /// Get the numeric ID of a window.
  ///
  /// The numeric ID is what SDL_WindowEvent references, and is necessary to map
  /// these events to specific SDL_Window objects.
  ///
  /// \param window the window to query
  /// \returns the ID of the window on success or 0 on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetWindowFromID
  int SDL_GetWindowID(
    ffi.Pointer<SDL_Window> window,
  ) {
    return _SDL_GetWindowID(
      window,
    );
  }

  late final _SDL_GetWindowIDPtr =
      _lookup<ffi.NativeFunction<Uint32 Function(ffi.Pointer<SDL_Window>)>>(
          'SDL_GetWindowID');
  late final _SDL_GetWindowID =
      _SDL_GetWindowIDPtr.asFunction<int Function(ffi.Pointer<SDL_Window>)>();

  /// Get a window from a stored ID.
  ///
  /// The numeric ID is what SDL_WindowEvent references, and is necessary to map
  /// these events to specific SDL_Window objects.
  ///
  /// \param id the ID of the window
  /// \returns the window associated with `id` or NULL if it doesn't exist; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetWindowID
  ffi.Pointer<SDL_Window> SDL_GetWindowFromID(
    int id,
  ) {
    return _SDL_GetWindowFromID(
      id,
    );
  }

  late final _SDL_GetWindowFromIDPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<SDL_Window> Function(Uint32)>>(
          'SDL_GetWindowFromID');
  late final _SDL_GetWindowFromID = _SDL_GetWindowFromIDPtr.asFunction<
      ffi.Pointer<SDL_Window> Function(int)>();

  /// Get the window flags.
  ///
  /// \param window the window to query
  /// \returns a mask of the SDL_WindowFlags associated with `window`
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_CreateWindow
  /// \sa SDL_HideWindow
  /// \sa SDL_MaximizeWindow
  /// \sa SDL_MinimizeWindow
  /// \sa SDL_SetWindowFullscreen
  /// \sa SDL_SetWindowGrab
  /// \sa SDL_ShowWindow
  int SDL_GetWindowFlags(
    ffi.Pointer<SDL_Window> window,
  ) {
    return _SDL_GetWindowFlags(
      window,
    );
  }

  late final _SDL_GetWindowFlagsPtr =
      _lookup<ffi.NativeFunction<Uint32 Function(ffi.Pointer<SDL_Window>)>>(
          'SDL_GetWindowFlags');
  late final _SDL_GetWindowFlags = _SDL_GetWindowFlagsPtr.asFunction<
      int Function(ffi.Pointer<SDL_Window>)>();

  /// Set the title of a window.
  ///
  /// This string is expected to be in UTF-8 encoding.
  ///
  /// \param window the window to change
  /// \param title the desired window title in UTF-8 format
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetWindowTitle
  void SDL_SetWindowTitle(
    ffi.Pointer<SDL_Window> window,
    ffi.Pointer<ffi.Int8> title,
  ) {
    return _SDL_SetWindowTitle(
      window,
      title,
    );
  }

  late final _SDL_SetWindowTitlePtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<SDL_Window>,
              ffi.Pointer<ffi.Int8>)>>('SDL_SetWindowTitle');
  late final _SDL_SetWindowTitle = _SDL_SetWindowTitlePtr.asFunction<
      void Function(ffi.Pointer<SDL_Window>, ffi.Pointer<ffi.Int8>)>();

  /// Get the title of a window.
  ///
  /// \param window the window to query
  /// \returns the title of the window in UTF-8 format or "" if there is no
  /// title.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_SetWindowTitle
  ffi.Pointer<ffi.Int8> SDL_GetWindowTitle(
    ffi.Pointer<SDL_Window> window,
  ) {
    return _SDL_GetWindowTitle(
      window,
    );
  }

  late final _SDL_GetWindowTitlePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Int8> Function(
              ffi.Pointer<SDL_Window>)>>('SDL_GetWindowTitle');
  late final _SDL_GetWindowTitle = _SDL_GetWindowTitlePtr.asFunction<
      ffi.Pointer<ffi.Int8> Function(ffi.Pointer<SDL_Window>)>();

  /// Set the icon for a window.
  ///
  /// \param window the window to change
  /// \param icon an SDL_Surface structure containing the icon for the window
  ///
  /// \since This function is available since SDL 2.0.0.
  void SDL_SetWindowIcon(
    ffi.Pointer<SDL_Window> window,
    ffi.Pointer<SDL_Surface> icon,
  ) {
    return _SDL_SetWindowIcon(
      window,
      icon,
    );
  }

  late final _SDL_SetWindowIconPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<SDL_Window>,
              ffi.Pointer<SDL_Surface>)>>('SDL_SetWindowIcon');
  late final _SDL_SetWindowIcon = _SDL_SetWindowIconPtr.asFunction<
      void Function(ffi.Pointer<SDL_Window>, ffi.Pointer<SDL_Surface>)>();

  /// Associate an arbitrary named pointer with a window.
  ///
  /// `name` is case-sensitive.
  ///
  /// \param window the window to associate with the pointer
  /// \param name the name of the pointer
  /// \param userdata the associated pointer
  /// \returns the previous value associated with `name`.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetWindowData
  ffi.Pointer<ffi.Void> SDL_SetWindowData(
    ffi.Pointer<SDL_Window> window,
    ffi.Pointer<ffi.Int8> name,
    ffi.Pointer<ffi.Void> userdata,
  ) {
    return _SDL_SetWindowData(
      window,
      name,
      userdata,
    );
  }

  late final _SDL_SetWindowDataPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Void> Function(
              ffi.Pointer<SDL_Window>,
              ffi.Pointer<ffi.Int8>,
              ffi.Pointer<ffi.Void>)>>('SDL_SetWindowData');
  late final _SDL_SetWindowData = _SDL_SetWindowDataPtr.asFunction<
      ffi.Pointer<ffi.Void> Function(ffi.Pointer<SDL_Window>,
          ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Void>)>();

  /// Retrieve the data pointer associated with a window.
  ///
  /// \param window the window to query
  /// \param name the name of the pointer
  /// \returns the value associated with `name`.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_SetWindowData
  ffi.Pointer<ffi.Void> SDL_GetWindowData(
    ffi.Pointer<SDL_Window> window,
    ffi.Pointer<ffi.Int8> name,
  ) {
    return _SDL_GetWindowData(
      window,
      name,
    );
  }

  late final _SDL_GetWindowDataPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Void> Function(ffi.Pointer<SDL_Window>,
              ffi.Pointer<ffi.Int8>)>>('SDL_GetWindowData');
  late final _SDL_GetWindowData = _SDL_GetWindowDataPtr.asFunction<
      ffi.Pointer<ffi.Void> Function(
          ffi.Pointer<SDL_Window>, ffi.Pointer<ffi.Int8>)>();

  /// Set the position of a window.
  ///
  /// The window coordinate origin is the upper left of the display.
  ///
  /// \param window the window to reposition
  /// \param x the x coordinate of the window in screen coordinates, or
  /// `SDL_WINDOWPOS_CENTERED` or `SDL_WINDOWPOS_UNDEFINED`
  /// \param y the y coordinate of the window in screen coordinates, or
  /// `SDL_WINDOWPOS_CENTERED` or `SDL_WINDOWPOS_UNDEFINED`
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetWindowPosition
  void SDL_SetWindowPosition(
    ffi.Pointer<SDL_Window> window,
    int x,
    int y,
  ) {
    return _SDL_SetWindowPosition(
      window,
      x,
      y,
    );
  }

  late final _SDL_SetWindowPositionPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<SDL_Window>, ffi.Int32,
              ffi.Int32)>>('SDL_SetWindowPosition');
  late final _SDL_SetWindowPosition = _SDL_SetWindowPositionPtr.asFunction<
      void Function(ffi.Pointer<SDL_Window>, int, int)>();

  /// Get the position of a window.
  ///
  /// If you do not need the value for one of the positions a NULL may be passed
  /// in the `x` or `y` parameter.
  ///
  /// \param window the window to query
  /// \param x a pointer filled in with the x position of the window, in screen
  /// coordinates, may be NULL
  /// \param y a pointer filled in with the y position of the window, in screen
  /// coordinates, may be NULL
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_SetWindowPosition
  void SDL_GetWindowPosition(
    ffi.Pointer<SDL_Window> window,
    ffi.Pointer<ffi.Int32> x,
    ffi.Pointer<ffi.Int32> y,
  ) {
    return _SDL_GetWindowPosition(
      window,
      x,
      y,
    );
  }

  late final _SDL_GetWindowPositionPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<SDL_Window>, ffi.Pointer<ffi.Int32>,
              ffi.Pointer<ffi.Int32>)>>('SDL_GetWindowPosition');
  late final _SDL_GetWindowPosition = _SDL_GetWindowPositionPtr.asFunction<
      void Function(ffi.Pointer<SDL_Window>, ffi.Pointer<ffi.Int32>,
          ffi.Pointer<ffi.Int32>)>();

  /// Set the size of a window's client area.
  ///
  /// The window size in screen coordinates may differ from the size in pixels,
  /// if the window was created with `SDL_WINDOW_ALLOW_HIGHDPI` on a platform
  /// with high-dpi support (e.g. iOS or macOS). Use SDL_GL_GetDrawableSize() or
  /// SDL_GetRendererOutputSize() to get the real client area size in pixels.
  ///
  /// Fullscreen windows automatically match the size of the display mode, and
  /// you should use SDL_SetWindowDisplayMode() to change their size.
  ///
  /// \param window the window to change
  /// \param w the width of the window in pixels, in screen coordinates, must be
  /// > 0
  /// \param h the height of the window in pixels, in screen coordinates, must be
  /// > 0
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetWindowSize
  /// \sa SDL_SetWindowDisplayMode
  void SDL_SetWindowSize(
    ffi.Pointer<SDL_Window> window,
    int w,
    int h,
  ) {
    return _SDL_SetWindowSize(
      window,
      w,
      h,
    );
  }

  late final _SDL_SetWindowSizePtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<SDL_Window>, ffi.Int32,
              ffi.Int32)>>('SDL_SetWindowSize');
  late final _SDL_SetWindowSize = _SDL_SetWindowSizePtr.asFunction<
      void Function(ffi.Pointer<SDL_Window>, int, int)>();

  /// Get the size of a window's client area.
  ///
  /// NULL can safely be passed as the `w` or `h` parameter if the width or
  /// height value is not desired.
  ///
  /// The window size in screen coordinates may differ from the size in pixels,
  /// if the window was created with `SDL_WINDOW_ALLOW_HIGHDPI` on a platform
  /// with high-dpi support (e.g. iOS or macOS). Use SDL_GL_GetDrawableSize(),
  /// SDL_Vulkan_GetDrawableSize(), or SDL_GetRendererOutputSize() to get the
  /// real client area size in pixels.
  ///
  /// \param window the window to query the width and height from
  /// \param w a pointer filled in with the width of the window, in screen
  /// coordinates, may be NULL
  /// \param h a pointer filled in with the height of the window, in screen
  /// coordinates, may be NULL
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GL_GetDrawableSize
  /// \sa SDL_Vulkan_GetDrawableSize
  /// \sa SDL_SetWindowSize
  void SDL_GetWindowSize(
    ffi.Pointer<SDL_Window> window,
    ffi.Pointer<ffi.Int32> w,
    ffi.Pointer<ffi.Int32> h,
  ) {
    return _SDL_GetWindowSize(
      window,
      w,
      h,
    );
  }

  late final _SDL_GetWindowSizePtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<SDL_Window>, ffi.Pointer<ffi.Int32>,
              ffi.Pointer<ffi.Int32>)>>('SDL_GetWindowSize');
  late final _SDL_GetWindowSize = _SDL_GetWindowSizePtr.asFunction<
      void Function(ffi.Pointer<SDL_Window>, ffi.Pointer<ffi.Int32>,
          ffi.Pointer<ffi.Int32>)>();

  /// Get the size of a window's borders (decorations) around the client area.
  ///
  /// Note: If this function fails (returns -1), the size values will be
  /// initialized to 0, 0, 0, 0 (if a non-NULL pointer is provided), as if the
  /// window in question was borderless.
  ///
  /// Note: This function may fail on systems where the window has not yet been
  /// decorated by the display server (for example, immediately after calling
  /// SDL_CreateWindow). It is recommended that you wait at least until the
  /// window has been presented and composited, so that the window system has a
  /// chance to decorate the window and provide the border dimensions to SDL.
  ///
  /// This function also returns -1 if getting the information is not supported.
  ///
  /// \param window the window to query the size values of the border
  /// (decorations) from
  /// \param top pointer to variable for storing the size of the top border; NULL
  /// is permitted
  /// \param left pointer to variable for storing the size of the left border;
  /// NULL is permitted
  /// \param bottom pointer to variable for storing the size of the bottom
  /// border; NULL is permitted
  /// \param right pointer to variable for storing the size of the right border;
  /// NULL is permitted
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.5.
  ///
  /// \sa SDL_GetWindowSize
  int SDL_GetWindowBordersSize(
    ffi.Pointer<SDL_Window> window,
    ffi.Pointer<ffi.Int32> top,
    ffi.Pointer<ffi.Int32> left,
    ffi.Pointer<ffi.Int32> bottom,
    ffi.Pointer<ffi.Int32> right,
  ) {
    return _SDL_GetWindowBordersSize(
      window,
      top,
      left,
      bottom,
      right,
    );
  }

  late final _SDL_GetWindowBordersSizePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<SDL_Window>,
              ffi.Pointer<ffi.Int32>,
              ffi.Pointer<ffi.Int32>,
              ffi.Pointer<ffi.Int32>,
              ffi.Pointer<ffi.Int32>)>>('SDL_GetWindowBordersSize');
  late final _SDL_GetWindowBordersSize =
      _SDL_GetWindowBordersSizePtr.asFunction<
          int Function(
              ffi.Pointer<SDL_Window>,
              ffi.Pointer<ffi.Int32>,
              ffi.Pointer<ffi.Int32>,
              ffi.Pointer<ffi.Int32>,
              ffi.Pointer<ffi.Int32>)>();

  /// Set the minimum size of a window's client area.
  ///
  /// \param window the window to change
  /// \param min_w the minimum width of the window in pixels
  /// \param min_h the minimum height of the window in pixels
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetWindowMinimumSize
  /// \sa SDL_SetWindowMaximumSize
  void SDL_SetWindowMinimumSize(
    ffi.Pointer<SDL_Window> window,
    int min_w,
    int min_h,
  ) {
    return _SDL_SetWindowMinimumSize(
      window,
      min_w,
      min_h,
    );
  }

  late final _SDL_SetWindowMinimumSizePtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<SDL_Window>, ffi.Int32,
              ffi.Int32)>>('SDL_SetWindowMinimumSize');
  late final _SDL_SetWindowMinimumSize = _SDL_SetWindowMinimumSizePtr
      .asFunction<void Function(ffi.Pointer<SDL_Window>, int, int)>();

  /// Get the minimum size of a window's client area.
  ///
  /// \param window the window to query
  /// \param w a pointer filled in with the minimum width of the window, may be
  /// NULL
  /// \param h a pointer filled in with the minimum height of the window, may be
  /// NULL
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetWindowMaximumSize
  /// \sa SDL_SetWindowMinimumSize
  void SDL_GetWindowMinimumSize(
    ffi.Pointer<SDL_Window> window,
    ffi.Pointer<ffi.Int32> w,
    ffi.Pointer<ffi.Int32> h,
  ) {
    return _SDL_GetWindowMinimumSize(
      window,
      w,
      h,
    );
  }

  late final _SDL_GetWindowMinimumSizePtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<SDL_Window>, ffi.Pointer<ffi.Int32>,
              ffi.Pointer<ffi.Int32>)>>('SDL_GetWindowMinimumSize');
  late final _SDL_GetWindowMinimumSize =
      _SDL_GetWindowMinimumSizePtr.asFunction<
          void Function(ffi.Pointer<SDL_Window>, ffi.Pointer<ffi.Int32>,
              ffi.Pointer<ffi.Int32>)>();

  /// Set the maximum size of a window's client area.
  ///
  /// \param window the window to change
  /// \param max_w the maximum width of the window in pixels
  /// \param max_h the maximum height of the window in pixels
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetWindowMaximumSize
  /// \sa SDL_SetWindowMinimumSize
  void SDL_SetWindowMaximumSize(
    ffi.Pointer<SDL_Window> window,
    int max_w,
    int max_h,
  ) {
    return _SDL_SetWindowMaximumSize(
      window,
      max_w,
      max_h,
    );
  }

  late final _SDL_SetWindowMaximumSizePtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<SDL_Window>, ffi.Int32,
              ffi.Int32)>>('SDL_SetWindowMaximumSize');
  late final _SDL_SetWindowMaximumSize = _SDL_SetWindowMaximumSizePtr
      .asFunction<void Function(ffi.Pointer<SDL_Window>, int, int)>();

  /// Get the maximum size of a window's client area.
  ///
  /// \param window the window to query
  /// \param w a pointer filled in with the maximum width of the window, may be
  /// NULL
  /// \param h a pointer filled in with the maximum height of the window, may be
  /// NULL
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetWindowMinimumSize
  /// \sa SDL_SetWindowMaximumSize
  void SDL_GetWindowMaximumSize(
    ffi.Pointer<SDL_Window> window,
    ffi.Pointer<ffi.Int32> w,
    ffi.Pointer<ffi.Int32> h,
  ) {
    return _SDL_GetWindowMaximumSize(
      window,
      w,
      h,
    );
  }

  late final _SDL_GetWindowMaximumSizePtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<SDL_Window>, ffi.Pointer<ffi.Int32>,
              ffi.Pointer<ffi.Int32>)>>('SDL_GetWindowMaximumSize');
  late final _SDL_GetWindowMaximumSize =
      _SDL_GetWindowMaximumSizePtr.asFunction<
          void Function(ffi.Pointer<SDL_Window>, ffi.Pointer<ffi.Int32>,
              ffi.Pointer<ffi.Int32>)>();

  /// Set the border state of a window.
  ///
  /// This will add or remove the window's `SDL_WINDOW_BORDERLESS` flag and add
  /// or remove the border from the actual window. This is a no-op if the
  /// window's border already matches the requested state.
  ///
  /// You can't change the border state of a fullscreen window.
  ///
  /// \param window the window of which to change the border state
  /// \param bordered SDL_FALSE to remove border, SDL_TRUE to add border
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetWindowFlags
  void SDL_SetWindowBordered(
    ffi.Pointer<SDL_Window> window,
    int bordered,
  ) {
    return _SDL_SetWindowBordered(
      window,
      bordered,
    );
  }

  late final _SDL_SetWindowBorderedPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<SDL_Window>, ffi.Int32)>>('SDL_SetWindowBordered');
  late final _SDL_SetWindowBordered = _SDL_SetWindowBorderedPtr.asFunction<
      void Function(ffi.Pointer<SDL_Window>, int)>();

  /// Set the user-resizable state of a window.
  ///
  /// This will add or remove the window's `SDL_WINDOW_RESIZABLE` flag and
  /// allow/disallow user resizing of the window. This is a no-op if the window's
  /// resizable state already matches the requested state.
  ///
  /// You can't change the resizable state of a fullscreen window.
  ///
  /// \param window the window of which to change the resizable state
  /// \param resizable SDL_TRUE to allow resizing, SDL_FALSE to disallow
  ///
  /// \since This function is available since SDL 2.0.5.
  ///
  /// \sa SDL_GetWindowFlags
  void SDL_SetWindowResizable(
    ffi.Pointer<SDL_Window> window,
    int resizable,
  ) {
    return _SDL_SetWindowResizable(
      window,
      resizable,
    );
  }

  late final _SDL_SetWindowResizablePtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<SDL_Window>, ffi.Int32)>>('SDL_SetWindowResizable');
  late final _SDL_SetWindowResizable = _SDL_SetWindowResizablePtr.asFunction<
      void Function(ffi.Pointer<SDL_Window>, int)>();

  /// Set the window to always be above the others.
  ///
  /// This will add or remove the window's `SDL_WINDOW_ALWAYS_ON_TOP` flag. This
  /// will bring the window to the front and keep the window above the rest.
  ///
  /// \param window The window of which to change the always on top state
  /// \param on_top SDL_TRUE to set the window always on top, SDL_FALSE to
  /// disable
  ///
  /// \since This function is available since SDL 2.0.16.
  ///
  /// \sa SDL_GetWindowFlags
  void SDL_SetWindowAlwaysOnTop(
    ffi.Pointer<SDL_Window> window,
    int on_top,
  ) {
    return _SDL_SetWindowAlwaysOnTop(
      window,
      on_top,
    );
  }

  late final _SDL_SetWindowAlwaysOnTopPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<SDL_Window>, ffi.Int32)>>('SDL_SetWindowAlwaysOnTop');
  late final _SDL_SetWindowAlwaysOnTop = _SDL_SetWindowAlwaysOnTopPtr
      .asFunction<void Function(ffi.Pointer<SDL_Window>, int)>();

  /// Show a window.
  ///
  /// \param window the window to show
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_HideWindow
  /// \sa SDL_RaiseWindow
  void SDL_ShowWindow(
    ffi.Pointer<SDL_Window> window,
  ) {
    return _SDL_ShowWindow(
      window,
    );
  }

  late final _SDL_ShowWindowPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<SDL_Window>)>>(
          'SDL_ShowWindow');
  late final _SDL_ShowWindow =
      _SDL_ShowWindowPtr.asFunction<void Function(ffi.Pointer<SDL_Window>)>();

  /// Hide a window.
  ///
  /// \param window the window to hide
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_ShowWindow
  void SDL_HideWindow(
    ffi.Pointer<SDL_Window> window,
  ) {
    return _SDL_HideWindow(
      window,
    );
  }

  late final _SDL_HideWindowPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<SDL_Window>)>>(
          'SDL_HideWindow');
  late final _SDL_HideWindow =
      _SDL_HideWindowPtr.asFunction<void Function(ffi.Pointer<SDL_Window>)>();

  /// Raise a window above other windows and set the input focus.
  ///
  /// \param window the window to raise
  ///
  /// \since This function is available since SDL 2.0.0.
  void SDL_RaiseWindow(
    ffi.Pointer<SDL_Window> window,
  ) {
    return _SDL_RaiseWindow(
      window,
    );
  }

  late final _SDL_RaiseWindowPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<SDL_Window>)>>(
          'SDL_RaiseWindow');
  late final _SDL_RaiseWindow =
      _SDL_RaiseWindowPtr.asFunction<void Function(ffi.Pointer<SDL_Window>)>();

  /// Make a window as large as possible.
  ///
  /// \param window the window to maximize
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_MinimizeWindow
  /// \sa SDL_RestoreWindow
  void SDL_MaximizeWindow(
    ffi.Pointer<SDL_Window> window,
  ) {
    return _SDL_MaximizeWindow(
      window,
    );
  }

  late final _SDL_MaximizeWindowPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<SDL_Window>)>>(
          'SDL_MaximizeWindow');
  late final _SDL_MaximizeWindow = _SDL_MaximizeWindowPtr.asFunction<
      void Function(ffi.Pointer<SDL_Window>)>();

  /// Minimize a window to an iconic representation.
  ///
  /// \param window the window to minimize
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_MaximizeWindow
  /// \sa SDL_RestoreWindow
  void SDL_MinimizeWindow(
    ffi.Pointer<SDL_Window> window,
  ) {
    return _SDL_MinimizeWindow(
      window,
    );
  }

  late final _SDL_MinimizeWindowPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<SDL_Window>)>>(
          'SDL_MinimizeWindow');
  late final _SDL_MinimizeWindow = _SDL_MinimizeWindowPtr.asFunction<
      void Function(ffi.Pointer<SDL_Window>)>();

  /// Restore the size and position of a minimized or maximized window.
  ///
  /// \param window the window to restore
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_MaximizeWindow
  /// \sa SDL_MinimizeWindow
  void SDL_RestoreWindow(
    ffi.Pointer<SDL_Window> window,
  ) {
    return _SDL_RestoreWindow(
      window,
    );
  }

  late final _SDL_RestoreWindowPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<SDL_Window>)>>(
          'SDL_RestoreWindow');
  late final _SDL_RestoreWindow = _SDL_RestoreWindowPtr.asFunction<
      void Function(ffi.Pointer<SDL_Window>)>();

  /// Set a window's fullscreen state.
  ///
  /// `flags` may be `SDL_WINDOW_FULLSCREEN`, for "real" fullscreen with a
  /// videomode change; `SDL_WINDOW_FULLSCREEN_DESKTOP` for "fake" fullscreen
  /// that takes the size of the desktop; and 0 for windowed mode.
  ///
  /// \param window the window to change
  /// \param flags `SDL_WINDOW_FULLSCREEN`, `SDL_WINDOW_FULLSCREEN_DESKTOP` or 0
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetWindowDisplayMode
  /// \sa SDL_SetWindowDisplayMode
  int SDL_SetWindowFullscreen(
    ffi.Pointer<SDL_Window> window,
    int flags,
  ) {
    return _SDL_SetWindowFullscreen(
      window,
      flags,
    );
  }

  late final _SDL_SetWindowFullscreenPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<SDL_Window>, Uint32)>>('SDL_SetWindowFullscreen');
  late final _SDL_SetWindowFullscreen = _SDL_SetWindowFullscreenPtr.asFunction<
      int Function(ffi.Pointer<SDL_Window>, int)>();

  /// Get the SDL surface associated with the window.
  ///
  /// A new surface will be created with the optimal format for the window, if
  /// necessary. This surface will be freed when the window is destroyed. Do not
  /// free this surface.
  ///
  /// This surface will be invalidated if the window is resized. After resizing a
  /// window this function must be called again to return a valid surface.
  ///
  /// You may not combine this with 3D or the rendering API on this window.
  ///
  /// This function is affected by `SDL_HINT_FRAMEBUFFER_ACCELERATION`.
  ///
  /// \param window the window to query
  /// \returns the surface associated with the window, or NULL on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_UpdateWindowSurface
  /// \sa SDL_UpdateWindowSurfaceRects
  ffi.Pointer<SDL_Surface> SDL_GetWindowSurface(
    ffi.Pointer<SDL_Window> window,
  ) {
    return _SDL_GetWindowSurface(
      window,
    );
  }

  late final _SDL_GetWindowSurfacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<SDL_Surface> Function(
              ffi.Pointer<SDL_Window>)>>('SDL_GetWindowSurface');
  late final _SDL_GetWindowSurface = _SDL_GetWindowSurfacePtr.asFunction<
      ffi.Pointer<SDL_Surface> Function(ffi.Pointer<SDL_Window>)>();

  /// Copy the window surface to the screen.
  ///
  /// This is the function you use to reflect any changes to the surface on the
  /// screen.
  ///
  /// This function is equivalent to the SDL 1.2 API SDL_Flip().
  ///
  /// \param window the window to update
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetWindowSurface
  /// \sa SDL_UpdateWindowSurfaceRects
  int SDL_UpdateWindowSurface(
    ffi.Pointer<SDL_Window> window,
  ) {
    return _SDL_UpdateWindowSurface(
      window,
    );
  }

  late final _SDL_UpdateWindowSurfacePtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<SDL_Window>)>>(
          'SDL_UpdateWindowSurface');
  late final _SDL_UpdateWindowSurface = _SDL_UpdateWindowSurfacePtr.asFunction<
      int Function(ffi.Pointer<SDL_Window>)>();

  /// Copy areas of the window surface to the screen.
  ///
  /// This is the function you use to reflect changes to portions of the surface
  /// on the screen.
  ///
  /// This function is equivalent to the SDL 1.2 API SDL_UpdateRects().
  ///
  /// \param window the window to update
  /// \param rects an array of SDL_Rect structures representing areas of the
  /// surface to copy
  /// \param numrects the number of rectangles
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetWindowSurface
  /// \sa SDL_UpdateWindowSurface
  int SDL_UpdateWindowSurfaceRects(
    ffi.Pointer<SDL_Window> window,
    ffi.Pointer<SDL_Rect> rects,
    int numrects,
  ) {
    return _SDL_UpdateWindowSurfaceRects(
      window,
      rects,
      numrects,
    );
  }

  late final _SDL_UpdateWindowSurfaceRectsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_Window>, ffi.Pointer<SDL_Rect>,
              ffi.Int32)>>('SDL_UpdateWindowSurfaceRects');
  late final _SDL_UpdateWindowSurfaceRects =
      _SDL_UpdateWindowSurfaceRectsPtr.asFunction<
          int Function(ffi.Pointer<SDL_Window>, ffi.Pointer<SDL_Rect>, int)>();

  /// Set a window's input grab mode.
  ///
  /// When input is grabbed, the mouse is confined to the window. This function
  /// will also grab the keyboard if `SDL_HINT_GRAB_KEYBOARD` is set. To grab the
  /// keyboard without also grabbing the mouse, use SDL_SetWindowKeyboardGrab().
  ///
  /// If the caller enables a grab while another window is currently grabbed, the
  /// other window loses its grab in favor of the caller's window.
  ///
  /// \param window the window for which the input grab mode should be set
  /// \param grabbed SDL_TRUE to grab input or SDL_FALSE to release input
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetGrabbedWindow
  /// \sa SDL_GetWindowGrab
  void SDL_SetWindowGrab(
    ffi.Pointer<SDL_Window> window,
    int grabbed,
  ) {
    return _SDL_SetWindowGrab(
      window,
      grabbed,
    );
  }

  late final _SDL_SetWindowGrabPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<SDL_Window>, ffi.Int32)>>('SDL_SetWindowGrab');
  late final _SDL_SetWindowGrab = _SDL_SetWindowGrabPtr.asFunction<
      void Function(ffi.Pointer<SDL_Window>, int)>();

  /// Set a window's keyboard grab mode.
  ///
  /// Keyboard grab enables capture of system keyboard shortcuts like Alt+Tab or
  /// the Meta/Super key. Note that not all system keyboard shortcuts can be
  /// captured by applications (one example is Ctrl+Alt+Del on Windows).
  ///
  /// This is primarily intended for specialized applications such as VNC clients
  /// or VM frontends. Normal games should not use keyboard grab.
  ///
  /// When keyboard grab is enabled, SDL will continue to handle Alt+Tab when the
  /// window is full-screen to ensure the user is not trapped in your
  /// application. If you have a custom keyboard shortcut to exit fullscreen
  /// mode, you may suppress this behavior with
  /// `SDL_HINT_ALLOW_ALT_TAB_WHILE_GRABBED`.
  ///
  /// If the caller enables a grab while another window is currently grabbed, the
  /// other window loses its grab in favor of the caller's window.
  ///
  /// \param window The window for which the keyboard grab mode should be set.
  /// \param grabbed This is SDL_TRUE to grab keyboard, and SDL_FALSE to release.
  ///
  /// \since This function is available since SDL 2.0.16.
  ///
  /// \sa SDL_GetWindowKeyboardGrab
  /// \sa SDL_SetWindowMouseGrab
  /// \sa SDL_SetWindowGrab
  void SDL_SetWindowKeyboardGrab(
    ffi.Pointer<SDL_Window> window,
    int grabbed,
  ) {
    return _SDL_SetWindowKeyboardGrab(
      window,
      grabbed,
    );
  }

  late final _SDL_SetWindowKeyboardGrabPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<SDL_Window>,
              ffi.Int32)>>('SDL_SetWindowKeyboardGrab');
  late final _SDL_SetWindowKeyboardGrab = _SDL_SetWindowKeyboardGrabPtr
      .asFunction<void Function(ffi.Pointer<SDL_Window>, int)>();

  /// Set a window's mouse grab mode.
  ///
  /// Mouse grab confines the mouse cursor to the window.
  ///
  /// \param window The window for which the mouse grab mode should be set.
  ///
  /// \since This function is available since SDL 2.0.16.
  ///
  /// \sa SDL_GetWindowMouseGrab
  /// \sa SDL_SetWindowKeyboardGrab
  /// \sa SDL_SetWindowGrab
  void SDL_SetWindowMouseGrab(
    ffi.Pointer<SDL_Window> window,
    int grabbed,
  ) {
    return _SDL_SetWindowMouseGrab(
      window,
      grabbed,
    );
  }

  late final _SDL_SetWindowMouseGrabPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<SDL_Window>, ffi.Int32)>>('SDL_SetWindowMouseGrab');
  late final _SDL_SetWindowMouseGrab = _SDL_SetWindowMouseGrabPtr.asFunction<
      void Function(ffi.Pointer<SDL_Window>, int)>();

  /// Get a window's input grab mode.
  ///
  /// \param window the window to query
  /// \returns SDL_TRUE if input is grabbed, SDL_FALSE otherwise.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_SetWindowGrab
  int SDL_GetWindowGrab(
    ffi.Pointer<SDL_Window> window,
  ) {
    return _SDL_GetWindowGrab(
      window,
    );
  }

  late final _SDL_GetWindowGrabPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<SDL_Window>)>>(
          'SDL_GetWindowGrab');
  late final _SDL_GetWindowGrab =
      _SDL_GetWindowGrabPtr.asFunction<int Function(ffi.Pointer<SDL_Window>)>();

  /// Get a window's keyboard grab mode.
  ///
  /// \param window the window to query
  /// \returns SDL_TRUE if keyboard is grabbed, and SDL_FALSE otherwise.
  ///
  /// \since This function is available since SDL 2.0.16.
  ///
  /// \sa SDL_SetWindowKeyboardGrab
  /// \sa SDL_GetWindowGrab
  int SDL_GetWindowKeyboardGrab(
    ffi.Pointer<SDL_Window> window,
  ) {
    return _SDL_GetWindowKeyboardGrab(
      window,
    );
  }

  late final _SDL_GetWindowKeyboardGrabPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<SDL_Window>)>>(
          'SDL_GetWindowKeyboardGrab');
  late final _SDL_GetWindowKeyboardGrab = _SDL_GetWindowKeyboardGrabPtr
      .asFunction<int Function(ffi.Pointer<SDL_Window>)>();

  /// Get a window's mouse grab mode.
  ///
  /// \param window the window to query
  /// \returns SDL_TRUE if mouse is grabbed, and SDL_FALSE otherwise.
  ///
  /// \since This function is available since SDL 2.0.16.
  ///
  /// \sa SDL_SetWindowKeyboardGrab
  /// \sa SDL_GetWindowGrab
  int SDL_GetWindowMouseGrab(
    ffi.Pointer<SDL_Window> window,
  ) {
    return _SDL_GetWindowMouseGrab(
      window,
    );
  }

  late final _SDL_GetWindowMouseGrabPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<SDL_Window>)>>(
          'SDL_GetWindowMouseGrab');
  late final _SDL_GetWindowMouseGrab = _SDL_GetWindowMouseGrabPtr.asFunction<
      int Function(ffi.Pointer<SDL_Window>)>();

  /// Get the window that currently has an input grab enabled.
  ///
  /// \returns the window if input is grabbed or NULL otherwise.
  ///
  /// \since This function is available since SDL 2.0.4.
  ///
  /// \sa SDL_GetWindowGrab
  /// \sa SDL_SetWindowGrab
  ffi.Pointer<SDL_Window> SDL_GetGrabbedWindow() {
    return _SDL_GetGrabbedWindow();
  }

  late final _SDL_GetGrabbedWindowPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<SDL_Window> Function()>>(
          'SDL_GetGrabbedWindow');
  late final _SDL_GetGrabbedWindow =
      _SDL_GetGrabbedWindowPtr.asFunction<ffi.Pointer<SDL_Window> Function()>();

  /// Confines the cursor to the specified area of a window.
  ///
  /// Note that this does NOT grab the cursor, it only defines the area a cursor
  /// is restricted to when the window has mouse focus.
  ///
  /// \param window The window that will be associated with the barrier.
  /// \param rect A rectangle area in window-relative coordinates. If NULL the
  /// barrier for the specified window will be destroyed.
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.18.
  ///
  /// \sa SDL_GetWindowMouseRect
  /// \sa SDL_SetWindowMouseGrab
  int SDL_SetWindowMouseRect(
    ffi.Pointer<SDL_Window> window,
    ffi.Pointer<SDL_Rect> rect,
  ) {
    return _SDL_SetWindowMouseRect(
      window,
      rect,
    );
  }

  late final _SDL_SetWindowMouseRectPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_Window>,
              ffi.Pointer<SDL_Rect>)>>('SDL_SetWindowMouseRect');
  late final _SDL_SetWindowMouseRect = _SDL_SetWindowMouseRectPtr.asFunction<
      int Function(ffi.Pointer<SDL_Window>, ffi.Pointer<SDL_Rect>)>();

  /// Get the mouse confinement rectangle of a window.
  ///
  /// \param window The window to query
  /// \returns A pointer to the mouse confinement rectangle of a window, or NULL
  /// if there isn't one.
  ///
  /// \since This function is available since SDL 2.0.18.
  ///
  /// \sa SDL_SetWindowMouseRect
  ffi.Pointer<SDL_Rect> SDL_GetWindowMouseRect(
    ffi.Pointer<SDL_Window> window,
  ) {
    return _SDL_GetWindowMouseRect(
      window,
    );
  }

  late final _SDL_GetWindowMouseRectPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<SDL_Rect> Function(
              ffi.Pointer<SDL_Window>)>>('SDL_GetWindowMouseRect');
  late final _SDL_GetWindowMouseRect = _SDL_GetWindowMouseRectPtr.asFunction<
      ffi.Pointer<SDL_Rect> Function(ffi.Pointer<SDL_Window>)>();

  /// Set the brightness (gamma multiplier) for a given window's display.
  ///
  /// Despite the name and signature, this method sets the brightness of the
  /// entire display, not an individual window. A window is considered to be
  /// owned by the display that contains the window's center pixel. (The index of
  /// this display can be retrieved using SDL_GetWindowDisplayIndex().) The
  /// brightness set will not follow the window if it is moved to another
  /// display.
  ///
  /// Many platforms will refuse to set the display brightness in modern times.
  /// You are better off using a shader to adjust gamma during rendering, or
  /// something similar.
  ///
  /// \param window the window used to select the display whose brightness will
  /// be changed
  /// \param brightness the brightness (gamma multiplier) value to set where 0.0
  /// is completely dark and 1.0 is normal brightness
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetWindowBrightness
  /// \sa SDL_SetWindowGammaRamp
  int SDL_SetWindowBrightness(
    ffi.Pointer<SDL_Window> window,
    double brightness,
  ) {
    return _SDL_SetWindowBrightness(
      window,
      brightness,
    );
  }

  late final _SDL_SetWindowBrightnessPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<SDL_Window>, ffi.Float)>>('SDL_SetWindowBrightness');
  late final _SDL_SetWindowBrightness = _SDL_SetWindowBrightnessPtr.asFunction<
      int Function(ffi.Pointer<SDL_Window>, double)>();

  /// Get the brightness (gamma multiplier) for a given window's display.
  ///
  /// Despite the name and signature, this method retrieves the brightness of the
  /// entire display, not an individual window. A window is considered to be
  /// owned by the display that contains the window's center pixel. (The index of
  /// this display can be retrieved using SDL_GetWindowDisplayIndex().)
  ///
  /// \param window the window used to select the display whose brightness will
  /// be queried
  /// \returns the brightness for the display where 0.0 is completely dark and
  /// 1.0 is normal brightness.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_SetWindowBrightness
  double SDL_GetWindowBrightness(
    ffi.Pointer<SDL_Window> window,
  ) {
    return _SDL_GetWindowBrightness(
      window,
    );
  }

  late final _SDL_GetWindowBrightnessPtr =
      _lookup<ffi.NativeFunction<ffi.Float Function(ffi.Pointer<SDL_Window>)>>(
          'SDL_GetWindowBrightness');
  late final _SDL_GetWindowBrightness = _SDL_GetWindowBrightnessPtr.asFunction<
      double Function(ffi.Pointer<SDL_Window>)>();

  /// Set the opacity for a window.
  ///
  /// The parameter `opacity` will be clamped internally between 0.0f
  /// (transparent) and 1.0f (opaque).
  ///
  /// This function also returns -1 if setting the opacity isn't supported.
  ///
  /// \param window the window which will be made transparent or opaque
  /// \param opacity the opacity value (0.0f - transparent, 1.0f - opaque)
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.5.
  ///
  /// \sa SDL_GetWindowOpacity
  int SDL_SetWindowOpacity(
    ffi.Pointer<SDL_Window> window,
    double opacity,
  ) {
    return _SDL_SetWindowOpacity(
      window,
      opacity,
    );
  }

  late final _SDL_SetWindowOpacityPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<SDL_Window>, ffi.Float)>>('SDL_SetWindowOpacity');
  late final _SDL_SetWindowOpacity = _SDL_SetWindowOpacityPtr.asFunction<
      int Function(ffi.Pointer<SDL_Window>, double)>();

  /// Get the opacity of a window.
  ///
  /// If transparency isn't supported on this platform, opacity will be reported
  /// as 1.0f without error.
  ///
  /// The parameter `opacity` is ignored if it is NULL.
  ///
  /// This function also returns -1 if an invalid window was provided.
  ///
  /// \param window the window to get the current opacity value from
  /// \param out_opacity the float filled in (0.0f - transparent, 1.0f - opaque)
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.5.
  ///
  /// \sa SDL_SetWindowOpacity
  int SDL_GetWindowOpacity(
    ffi.Pointer<SDL_Window> window,
    ffi.Pointer<ffi.Float> out_opacity,
  ) {
    return _SDL_GetWindowOpacity(
      window,
      out_opacity,
    );
  }

  late final _SDL_GetWindowOpacityPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_Window>,
              ffi.Pointer<ffi.Float>)>>('SDL_GetWindowOpacity');
  late final _SDL_GetWindowOpacity = _SDL_GetWindowOpacityPtr.asFunction<
      int Function(ffi.Pointer<SDL_Window>, ffi.Pointer<ffi.Float>)>();

  /// Set the window as a modal for another window.
  ///
  /// \param modal_window the window that should be set modal
  /// \param parent_window the parent window for the modal window
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.5.
  int SDL_SetWindowModalFor(
    ffi.Pointer<SDL_Window> modal_window,
    ffi.Pointer<SDL_Window> parent_window,
  ) {
    return _SDL_SetWindowModalFor(
      modal_window,
      parent_window,
    );
  }

  late final _SDL_SetWindowModalForPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_Window>,
              ffi.Pointer<SDL_Window>)>>('SDL_SetWindowModalFor');
  late final _SDL_SetWindowModalFor = _SDL_SetWindowModalForPtr.asFunction<
      int Function(ffi.Pointer<SDL_Window>, ffi.Pointer<SDL_Window>)>();

  /// Explicitly set input focus to the window.
  ///
  /// You almost certainly want SDL_RaiseWindow() instead of this function. Use
  /// this with caution, as you might give focus to a window that is completely
  /// obscured by other windows.
  ///
  /// \param window the window that should get the input focus
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.5.
  ///
  /// \sa SDL_RaiseWindow
  int SDL_SetWindowInputFocus(
    ffi.Pointer<SDL_Window> window,
  ) {
    return _SDL_SetWindowInputFocus(
      window,
    );
  }

  late final _SDL_SetWindowInputFocusPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<SDL_Window>)>>(
          'SDL_SetWindowInputFocus');
  late final _SDL_SetWindowInputFocus = _SDL_SetWindowInputFocusPtr.asFunction<
      int Function(ffi.Pointer<SDL_Window>)>();

  /// Set the gamma ramp for the display that owns a given window.
  ///
  /// Set the gamma translation table for the red, green, and blue channels of
  /// the video hardware. Each table is an array of 256 16-bit quantities,
  /// representing a mapping between the input and output for that channel. The
  /// input is the index into the array, and the output is the 16-bit gamma value
  /// at that index, scaled to the output color precision.
  ///
  /// Despite the name and signature, this method sets the gamma ramp of the
  /// entire display, not an individual window. A window is considered to be
  /// owned by the display that contains the window's center pixel. (The index of
  /// this display can be retrieved using SDL_GetWindowDisplayIndex().) The gamma
  /// ramp set will not follow the window if it is moved to another display.
  ///
  /// \param window the window used to select the display whose gamma ramp will
  /// be changed
  /// \param red a 256 element array of 16-bit quantities representing the
  /// translation table for the red channel, or NULL
  /// \param green a 256 element array of 16-bit quantities representing the
  /// translation table for the green channel, or NULL
  /// \param blue a 256 element array of 16-bit quantities representing the
  /// translation table for the blue channel, or NULL
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetWindowGammaRamp
  int SDL_SetWindowGammaRamp(
    ffi.Pointer<SDL_Window> window,
    ffi.Pointer<Uint16> red,
    ffi.Pointer<Uint16> green,
    ffi.Pointer<Uint16> blue,
  ) {
    return _SDL_SetWindowGammaRamp(
      window,
      red,
      green,
      blue,
    );
  }

  late final _SDL_SetWindowGammaRampPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<SDL_Window>,
              ffi.Pointer<Uint16>,
              ffi.Pointer<Uint16>,
              ffi.Pointer<Uint16>)>>('SDL_SetWindowGammaRamp');
  late final _SDL_SetWindowGammaRamp = _SDL_SetWindowGammaRampPtr.asFunction<
      int Function(ffi.Pointer<SDL_Window>, ffi.Pointer<Uint16>,
          ffi.Pointer<Uint16>, ffi.Pointer<Uint16>)>();

  /// Get the gamma ramp for a given window's display.
  ///
  /// Despite the name and signature, this method retrieves the gamma ramp of the
  /// entire display, not an individual window. A window is considered to be
  /// owned by the display that contains the window's center pixel. (The index of
  /// this display can be retrieved using SDL_GetWindowDisplayIndex().)
  ///
  /// \param window the window used to select the display whose gamma ramp will
  /// be queried
  /// \param red a 256 element array of 16-bit quantities filled in with the
  /// translation table for the red channel, or NULL
  /// \param green a 256 element array of 16-bit quantities filled in with the
  /// translation table for the green channel, or NULL
  /// \param blue a 256 element array of 16-bit quantities filled in with the
  /// translation table for the blue channel, or NULL
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_SetWindowGammaRamp
  int SDL_GetWindowGammaRamp(
    ffi.Pointer<SDL_Window> window,
    ffi.Pointer<Uint16> red,
    ffi.Pointer<Uint16> green,
    ffi.Pointer<Uint16> blue,
  ) {
    return _SDL_GetWindowGammaRamp(
      window,
      red,
      green,
      blue,
    );
  }

  late final _SDL_GetWindowGammaRampPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<SDL_Window>,
              ffi.Pointer<Uint16>,
              ffi.Pointer<Uint16>,
              ffi.Pointer<Uint16>)>>('SDL_GetWindowGammaRamp');
  late final _SDL_GetWindowGammaRamp = _SDL_GetWindowGammaRampPtr.asFunction<
      int Function(ffi.Pointer<SDL_Window>, ffi.Pointer<Uint16>,
          ffi.Pointer<Uint16>, ffi.Pointer<Uint16>)>();

  /// Provide a callback that decides if a window region has special properties.
  ///
  /// Normally windows are dragged and resized by decorations provided by the
  /// system window manager (a title bar, borders, etc), but for some apps, it
  /// makes sense to drag them from somewhere else inside the window itself; for
  /// example, one might have a borderless window that wants to be draggable from
  /// any part, or simulate its own title bar, etc.
  ///
  /// This function lets the app provide a callback that designates pieces of a
  /// given window as special. This callback is run during event processing if we
  /// need to tell the OS to treat a region of the window specially; the use of
  /// this callback is known as "hit testing."
  ///
  /// Mouse input may not be delivered to your application if it is within a
  /// special area; the OS will often apply that input to moving the window or
  /// resizing the window and not deliver it to the application.
  ///
  /// Specifying NULL for a callback disables hit-testing. Hit-testing is
  /// disabled by default.
  ///
  /// Platforms that don't support this functionality will return -1
  /// unconditionally, even if you're attempting to disable hit-testing.
  ///
  /// Your callback may fire at any time, and its firing does not indicate any
  /// specific behavior (for example, on Windows, this certainly might fire when
  /// the OS is deciding whether to drag your window, but it fires for lots of
  /// other reasons, too, some unrelated to anything you probably care about _and
  /// when the mouse isn't actually at the location it is testing_). Since this
  /// can fire at any time, you should try to keep your callback efficient,
  /// devoid of allocations, etc.
  ///
  /// \param window the window to set hit-testing on
  /// \param callback the function to call when doing a hit-test
  /// \param callback_data an app-defined void pointer passed to **callback**
  /// \returns 0 on success or -1 on error (including unsupported); call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.4.
  int SDL_SetWindowHitTest(
    ffi.Pointer<SDL_Window> window,
    SDL_HitTest callback,
    ffi.Pointer<ffi.Void> callback_data,
  ) {
    return _SDL_SetWindowHitTest(
      window,
      callback,
      callback_data,
    );
  }

  late final _SDL_SetWindowHitTestPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_Window>, SDL_HitTest,
              ffi.Pointer<ffi.Void>)>>('SDL_SetWindowHitTest');
  late final _SDL_SetWindowHitTest = _SDL_SetWindowHitTestPtr.asFunction<
      int Function(
          ffi.Pointer<SDL_Window>, SDL_HitTest, ffi.Pointer<ffi.Void>)>();

  /// Request a window to demand attention from the user.
  ///
  /// \param window the window to be flashed
  /// \param operation the flash operation
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.16.
  int SDL_FlashWindow(
    ffi.Pointer<SDL_Window> window,
    int operation,
  ) {
    return _SDL_FlashWindow(
      window,
      operation,
    );
  }

  late final _SDL_FlashWindowPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<SDL_Window>, ffi.Int32)>>('SDL_FlashWindow');
  late final _SDL_FlashWindow = _SDL_FlashWindowPtr.asFunction<
      int Function(ffi.Pointer<SDL_Window>, int)>();

  /// Destroy a window.
  ///
  /// If `window` is NULL, this function will return immediately after setting
  /// the SDL error message to "Invalid window". See SDL_GetError().
  ///
  /// \param window the window to destroy
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_CreateWindow
  /// \sa SDL_CreateWindowFrom
  void SDL_DestroyWindow(
    ffi.Pointer<SDL_Window> window,
  ) {
    return _SDL_DestroyWindow(
      window,
    );
  }

  late final _SDL_DestroyWindowPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<SDL_Window>)>>(
          'SDL_DestroyWindow');
  late final _SDL_DestroyWindow = _SDL_DestroyWindowPtr.asFunction<
      void Function(ffi.Pointer<SDL_Window>)>();

  /// Check whether the screensaver is currently enabled.
  ///
  /// The screensaver is disabled by default since SDL 2.0.2. Before SDL 2.0.2
  /// the screensaver was enabled by default.
  ///
  /// The default can also be changed using `SDL_HINT_VIDEO_ALLOW_SCREENSAVER`.
  ///
  /// \returns SDL_TRUE if the screensaver is enabled, SDL_FALSE if it is
  /// disabled.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_DisableScreenSaver
  /// \sa SDL_EnableScreenSaver
  int SDL_IsScreenSaverEnabled() {
    return _SDL_IsScreenSaverEnabled();
  }

  late final _SDL_IsScreenSaverEnabledPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function()>>(
          'SDL_IsScreenSaverEnabled');
  late final _SDL_IsScreenSaverEnabled =
      _SDL_IsScreenSaverEnabledPtr.asFunction<int Function()>();

  /// Allow the screen to be blanked by a screen saver.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_DisableScreenSaver
  /// \sa SDL_IsScreenSaverEnabled
  void SDL_EnableScreenSaver() {
    return _SDL_EnableScreenSaver();
  }

  late final _SDL_EnableScreenSaverPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('SDL_EnableScreenSaver');
  late final _SDL_EnableScreenSaver =
      _SDL_EnableScreenSaverPtr.asFunction<void Function()>();

  /// Prevent the screen from being blanked by a screen saver.
  ///
  /// If you disable the screensaver, it is automatically re-enabled when SDL
  /// quits.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_EnableScreenSaver
  /// \sa SDL_IsScreenSaverEnabled
  void SDL_DisableScreenSaver() {
    return _SDL_DisableScreenSaver();
  }

  late final _SDL_DisableScreenSaverPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>(
          'SDL_DisableScreenSaver');
  late final _SDL_DisableScreenSaver =
      _SDL_DisableScreenSaverPtr.asFunction<void Function()>();

  /// Dynamically load an OpenGL library.
  ///
  /// This should be done after initializing the video driver, but before
  /// creating any OpenGL windows. If no OpenGL library is loaded, the default
  /// library will be loaded upon creation of the first OpenGL window.
  ///
  /// If you do this, you need to retrieve all of the GL functions used in your
  /// program from the dynamic library using SDL_GL_GetProcAddress().
  ///
  /// \param path the platform dependent OpenGL library name, or NULL to open the
  /// default OpenGL library
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GL_GetProcAddress
  /// \sa SDL_GL_UnloadLibrary
  int SDL_GL_LoadLibrary(
    ffi.Pointer<ffi.Int8> path,
  ) {
    return _SDL_GL_LoadLibrary(
      path,
    );
  }

  late final _SDL_GL_LoadLibraryPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<ffi.Int8>)>>(
          'SDL_GL_LoadLibrary');
  late final _SDL_GL_LoadLibrary =
      _SDL_GL_LoadLibraryPtr.asFunction<int Function(ffi.Pointer<ffi.Int8>)>();

  /// Get an OpenGL function by name.
  ///
  /// If the GL library is loaded at runtime with SDL_GL_LoadLibrary(), then all
  /// GL functions must be retrieved this way. Usually this is used to retrieve
  /// function pointers to OpenGL extensions.
  ///
  /// There are some quirks to looking up OpenGL functions that require some
  /// extra care from the application. If you code carefully, you can handle
  /// these quirks without any platform-specific code, though:
  ///
  /// - On Windows, function pointers are specific to the current GL context;
  /// this means you need to have created a GL context and made it current
  /// before calling SDL_GL_GetProcAddress(). If you recreate your context or
  /// create a second context, you should assume that any existing function
  /// pointers aren't valid to use with it. This is (currently) a
  /// Windows-specific limitation, and in practice lots of drivers don't suffer
  /// this limitation, but it is still the way the wgl API is documented to
  /// work and you should expect crashes if you don't respect it. Store a copy
  /// of the function pointers that comes and goes with context lifespan.
  /// - On X11, function pointers returned by this function are valid for any
  /// context, and can even be looked up before a context is created at all.
  /// This means that, for at least some common OpenGL implementations, if you
  /// look up a function that doesn't exist, you'll get a non-NULL result that
  /// is _NOT_ safe to call. You must always make sure the function is actually
  /// available for a given GL context before calling it, by checking for the
  /// existence of the appropriate extension with SDL_GL_ExtensionSupported(),
  /// or verifying that the version of OpenGL you're using offers the function
  /// as core functionality.
  /// - Some OpenGL drivers, on all platforms, *will* return NULL if a function
  /// isn't supported, but you can't count on this behavior. Check for
  /// extensions you use, and if you get a NULL anyway, act as if that
  /// extension wasn't available. This is probably a bug in the driver, but you
  /// can code defensively for this scenario anyhow.
  /// - Just because you're on Linux/Unix, don't assume you'll be using X11.
  /// Next-gen display servers are waiting to replace it, and may or may not
  /// make the same promises about function pointers.
  /// - OpenGL function pointers must be declared `APIENTRY` as in the example
  /// code. This will ensure the proper calling convention is followed on
  /// platforms where this matters (Win32) thereby avoiding stack corruption.
  ///
  /// \param proc the name of an OpenGL function
  /// \returns a pointer to the named OpenGL function. The returned pointer
  /// should be cast to the appropriate function signature.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GL_ExtensionSupported
  /// \sa SDL_GL_LoadLibrary
  /// \sa SDL_GL_UnloadLibrary
  ffi.Pointer<ffi.Void> SDL_GL_GetProcAddress(
    ffi.Pointer<ffi.Int8> proc,
  ) {
    return _SDL_GL_GetProcAddress(
      proc,
    );
  }

  late final _SDL_GL_GetProcAddressPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Void> Function(
              ffi.Pointer<ffi.Int8>)>>('SDL_GL_GetProcAddress');
  late final _SDL_GL_GetProcAddress = _SDL_GL_GetProcAddressPtr.asFunction<
      ffi.Pointer<ffi.Void> Function(ffi.Pointer<ffi.Int8>)>();

  /// Unload the OpenGL library previously loaded by SDL_GL_LoadLibrary().
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GL_LoadLibrary
  void SDL_GL_UnloadLibrary() {
    return _SDL_GL_UnloadLibrary();
  }

  late final _SDL_GL_UnloadLibraryPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('SDL_GL_UnloadLibrary');
  late final _SDL_GL_UnloadLibrary =
      _SDL_GL_UnloadLibraryPtr.asFunction<void Function()>();

  /// Check if an OpenGL extension is supported for the current context.
  ///
  /// This function operates on the current GL context; you must have created a
  /// context and it must be current before calling this function. Do not assume
  /// that all contexts you create will have the same set of extensions
  /// available, or that recreating an existing context will offer the same
  /// extensions again.
  ///
  /// While it's probably not a massive overhead, this function is not an O(1)
  /// operation. Check the extensions you care about after creating the GL
  /// context and save that information somewhere instead of calling the function
  /// every time you need to know.
  ///
  /// \param extension the name of the extension to check
  /// \returns SDL_TRUE if the extension is supported, SDL_FALSE otherwise.
  ///
  /// \since This function is available since SDL 2.0.0.
  int SDL_GL_ExtensionSupported(
    ffi.Pointer<ffi.Int8> extension1,
  ) {
    return _SDL_GL_ExtensionSupported(
      extension1,
    );
  }

  late final _SDL_GL_ExtensionSupportedPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<ffi.Int8>)>>(
          'SDL_GL_ExtensionSupported');
  late final _SDL_GL_ExtensionSupported = _SDL_GL_ExtensionSupportedPtr
      .asFunction<int Function(ffi.Pointer<ffi.Int8>)>();

  /// Reset all previously set OpenGL context attributes to their default values.
  ///
  /// \since This function is available since SDL 2.0.2.
  ///
  /// \sa SDL_GL_GetAttribute
  /// \sa SDL_GL_SetAttribute
  void SDL_GL_ResetAttributes() {
    return _SDL_GL_ResetAttributes();
  }

  late final _SDL_GL_ResetAttributesPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>(
          'SDL_GL_ResetAttributes');
  late final _SDL_GL_ResetAttributes =
      _SDL_GL_ResetAttributesPtr.asFunction<void Function()>();

  /// Set an OpenGL window attribute before window creation.
  ///
  /// This function sets the OpenGL attribute `attr` to `value`. The requested
  /// attributes should be set before creating an OpenGL window. You should use
  /// SDL_GL_GetAttribute() to check the values after creating the OpenGL
  /// context, since the values obtained can differ from the requested ones.
  ///
  /// \param attr an SDL_GLattr enum value specifying the OpenGL attribute to set
  /// \param value the desired value for the attribute
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GL_GetAttribute
  /// \sa SDL_GL_ResetAttributes
  int SDL_GL_SetAttribute(
    int attr,
    int value,
  ) {
    return _SDL_GL_SetAttribute(
      attr,
      value,
    );
  }

  late final _SDL_GL_SetAttributePtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Int32, ffi.Int32)>>(
          'SDL_GL_SetAttribute');
  late final _SDL_GL_SetAttribute =
      _SDL_GL_SetAttributePtr.asFunction<int Function(int, int)>();

  /// Get the actual value for an attribute from the current context.
  ///
  /// \param attr an SDL_GLattr enum value specifying the OpenGL attribute to get
  /// \param value a pointer filled in with the current value of `attr`
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GL_ResetAttributes
  /// \sa SDL_GL_SetAttribute
  int SDL_GL_GetAttribute(
    int attr,
    ffi.Pointer<ffi.Int32> value,
  ) {
    return _SDL_GL_GetAttribute(
      attr,
      value,
    );
  }

  late final _SDL_GL_GetAttributePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Int32, ffi.Pointer<ffi.Int32>)>>('SDL_GL_GetAttribute');
  late final _SDL_GL_GetAttribute = _SDL_GL_GetAttributePtr.asFunction<
      int Function(int, ffi.Pointer<ffi.Int32>)>();

  /// Create an OpenGL context for an OpenGL window, and make it current.
  ///
  /// Windows users new to OpenGL should note that, for historical reasons, GL
  /// functions added after OpenGL version 1.1 are not available by default.
  /// Those functions must be loaded at run-time, either with an OpenGL
  /// extension-handling library or with SDL_GL_GetProcAddress() and its related
  /// functions.
  ///
  /// SDL_GLContext is an alias for `void *`. It's opaque to the application.
  ///
  /// \param window the window to associate with the context
  /// \returns the OpenGL context associated with `window` or NULL on error; call
  /// SDL_GetError() for more details.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GL_DeleteContext
  /// \sa SDL_GL_MakeCurrent
  SDL_GLContext SDL_GL_CreateContext(
    ffi.Pointer<SDL_Window> window,
  ) {
    return _SDL_GL_CreateContext(
      window,
    );
  }

  late final _SDL_GL_CreateContextPtr = _lookup<
          ffi.NativeFunction<SDL_GLContext Function(ffi.Pointer<SDL_Window>)>>(
      'SDL_GL_CreateContext');
  late final _SDL_GL_CreateContext = _SDL_GL_CreateContextPtr.asFunction<
      SDL_GLContext Function(ffi.Pointer<SDL_Window>)>();

  /// Set up an OpenGL context for rendering into an OpenGL window.
  ///
  /// The context must have been created with a compatible window.
  ///
  /// \param window the window to associate with the context
  /// \param context the OpenGL context to associate with the window
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GL_CreateContext
  int SDL_GL_MakeCurrent(
    ffi.Pointer<SDL_Window> window,
    SDL_GLContext context,
  ) {
    return _SDL_GL_MakeCurrent(
      window,
      context,
    );
  }

  late final _SDL_GL_MakeCurrentPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<SDL_Window>, SDL_GLContext)>>('SDL_GL_MakeCurrent');
  late final _SDL_GL_MakeCurrent = _SDL_GL_MakeCurrentPtr.asFunction<
      int Function(ffi.Pointer<SDL_Window>, SDL_GLContext)>();

  /// Get the currently active OpenGL window.
  ///
  /// \returns the currently active OpenGL window on success or NULL on failure;
  /// call SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ffi.Pointer<SDL_Window> SDL_GL_GetCurrentWindow() {
    return _SDL_GL_GetCurrentWindow();
  }

  late final _SDL_GL_GetCurrentWindowPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<SDL_Window> Function()>>(
          'SDL_GL_GetCurrentWindow');
  late final _SDL_GL_GetCurrentWindow = _SDL_GL_GetCurrentWindowPtr.asFunction<
      ffi.Pointer<SDL_Window> Function()>();

  /// Get the currently active OpenGL context.
  ///
  /// \returns the currently active OpenGL context or NULL on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GL_MakeCurrent
  SDL_GLContext SDL_GL_GetCurrentContext() {
    return _SDL_GL_GetCurrentContext();
  }

  late final _SDL_GL_GetCurrentContextPtr =
      _lookup<ffi.NativeFunction<SDL_GLContext Function()>>(
          'SDL_GL_GetCurrentContext');
  late final _SDL_GL_GetCurrentContext =
      _SDL_GL_GetCurrentContextPtr.asFunction<SDL_GLContext Function()>();

  /// Get the size of a window's underlying drawable in pixels.
  ///
  /// This returns info useful for calling glViewport().
  ///
  /// This may differ from SDL_GetWindowSize() if we're rendering to a high-DPI
  /// drawable, i.e. the window was created with `SDL_WINDOW_ALLOW_HIGHDPI` on a
  /// platform with high-DPI support (Apple calls this "Retina"), and not
  /// disabled by the `SDL_HINT_VIDEO_HIGHDPI_DISABLED` hint.
  ///
  /// \param window the window from which the drawable size should be queried
  /// \param w a pointer to variable for storing the width in pixels, may be NULL
  /// \param h a pointer to variable for storing the height in pixels, may be
  /// NULL
  ///
  /// \since This function is available since SDL 2.0.1.
  ///
  /// \sa SDL_CreateWindow
  /// \sa SDL_GetWindowSize
  void SDL_GL_GetDrawableSize(
    ffi.Pointer<SDL_Window> window,
    ffi.Pointer<ffi.Int32> w,
    ffi.Pointer<ffi.Int32> h,
  ) {
    return _SDL_GL_GetDrawableSize(
      window,
      w,
      h,
    );
  }

  late final _SDL_GL_GetDrawableSizePtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<SDL_Window>, ffi.Pointer<ffi.Int32>,
              ffi.Pointer<ffi.Int32>)>>('SDL_GL_GetDrawableSize');
  late final _SDL_GL_GetDrawableSize = _SDL_GL_GetDrawableSizePtr.asFunction<
      void Function(ffi.Pointer<SDL_Window>, ffi.Pointer<ffi.Int32>,
          ffi.Pointer<ffi.Int32>)>();

  /// Set the swap interval for the current OpenGL context.
  ///
  /// Some systems allow specifying -1 for the interval, to enable adaptive
  /// vsync. Adaptive vsync works the same as vsync, but if you've already missed
  /// the vertical retrace for a given frame, it swaps buffers immediately, which
  /// might be less jarring for the user during occasional framerate drops. If an
  /// application requests adaptive vsync and the system does not support it,
  /// this function will fail and return -1. In such a case, you should probably
  /// retry the call with 1 for the interval.
  ///
  /// Adaptive vsync is implemented for some glX drivers with
  /// GLX_EXT_swap_control_tear:
  ///
  /// https://www.opengl.org/registry/specs/EXT/glx_swap_control_tear.txt
  ///
  /// and for some Windows drivers with WGL_EXT_swap_control_tear:
  ///
  /// https://www.opengl.org/registry/specs/EXT/wgl_swap_control_tear.txt
  ///
  /// Read more on the Khronos wiki:
  /// https://www.khronos.org/opengl/wiki/Swap_Interval#Adaptive_Vsync
  ///
  /// \param interval 0 for immediate updates, 1 for updates synchronized with
  /// the vertical retrace, -1 for adaptive vsync
  /// \returns 0 on success or -1 if setting the swap interval is not supported;
  /// call SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GL_GetSwapInterval
  int SDL_GL_SetSwapInterval(
    int interval,
  ) {
    return _SDL_GL_SetSwapInterval(
      interval,
    );
  }

  late final _SDL_GL_SetSwapIntervalPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Int32)>>(
          'SDL_GL_SetSwapInterval');
  late final _SDL_GL_SetSwapInterval =
      _SDL_GL_SetSwapIntervalPtr.asFunction<int Function(int)>();

  /// Get the swap interval for the current OpenGL context.
  ///
  /// If the system can't determine the swap interval, or there isn't a valid
  /// current context, this function will return 0 as a safe default.
  ///
  /// \returns 0 if there is no vertical retrace synchronization, 1 if the buffer
  /// swap is synchronized with the vertical retrace, and -1 if late
  /// swaps happen immediately instead of waiting for the next retrace;
  /// call SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GL_SetSwapInterval
  int SDL_GL_GetSwapInterval() {
    return _SDL_GL_GetSwapInterval();
  }

  late final _SDL_GL_GetSwapIntervalPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function()>>(
          'SDL_GL_GetSwapInterval');
  late final _SDL_GL_GetSwapInterval =
      _SDL_GL_GetSwapIntervalPtr.asFunction<int Function()>();

  /// Update a window with OpenGL rendering.
  ///
  /// This is used with double-buffered OpenGL contexts, which are the default.
  ///
  /// On macOS, make sure you bind 0 to the draw framebuffer before swapping the
  /// window, otherwise nothing will happen. If you aren't using
  /// glBindFramebuffer(), this is the default and you won't have to do anything
  /// extra.
  ///
  /// \param window the window to change
  ///
  /// \since This function is available since SDL 2.0.0.
  void SDL_GL_SwapWindow(
    ffi.Pointer<SDL_Window> window,
  ) {
    return _SDL_GL_SwapWindow(
      window,
    );
  }

  late final _SDL_GL_SwapWindowPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<SDL_Window>)>>(
          'SDL_GL_SwapWindow');
  late final _SDL_GL_SwapWindow = _SDL_GL_SwapWindowPtr.asFunction<
      void Function(ffi.Pointer<SDL_Window>)>();

  /// Delete an OpenGL context.
  ///
  /// \param context the OpenGL context to be deleted
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GL_CreateContext
  void SDL_GL_DeleteContext(
    SDL_GLContext context,
  ) {
    return _SDL_GL_DeleteContext(
      context,
    );
  }

  late final _SDL_GL_DeleteContextPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(SDL_GLContext)>>(
          'SDL_GL_DeleteContext');
  late final _SDL_GL_DeleteContext =
      _SDL_GL_DeleteContextPtr.asFunction<void Function(SDL_GLContext)>();

  /// Query the window which currently has keyboard focus.
  ///
  /// \returns the window with keyboard focus.
  ///
  /// \since This function is available since SDL 2.0.0.
  ffi.Pointer<SDL_Window> SDL_GetKeyboardFocus() {
    return _SDL_GetKeyboardFocus();
  }

  late final _SDL_GetKeyboardFocusPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<SDL_Window> Function()>>(
          'SDL_GetKeyboardFocus');
  late final _SDL_GetKeyboardFocus =
      _SDL_GetKeyboardFocusPtr.asFunction<ffi.Pointer<SDL_Window> Function()>();

  /// Get a snapshot of the current state of the keyboard.
  ///
  /// The pointer returned is a pointer to an internal SDL array. It will be
  /// valid for the whole lifetime of the application and should not be freed by
  /// the caller.
  ///
  /// A array element with a value of 1 means that the key is pressed and a value
  /// of 0 means that it is not. Indexes into this array are obtained by using
  /// SDL_Scancode values.
  ///
  /// Use SDL_PumpEvents() to update the state array.
  ///
  /// This function gives you the current state after all events have been
  /// processed, so if a key or button has been pressed and released before you
  /// process events, then the pressed state will never show up in the
  /// SDL_GetKeyboardState() calls.
  ///
  /// Note: This function doesn't take into account whether shift has been
  /// pressed or not.
  ///
  /// \param numkeys if non-NULL, receives the length of the returned array
  /// \returns a pointer to an array of key states.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_PumpEvents
  ffi.Pointer<Uint8> SDL_GetKeyboardState(
    ffi.Pointer<ffi.Int32> numkeys,
  ) {
    return _SDL_GetKeyboardState(
      numkeys,
    );
  }

  late final _SDL_GetKeyboardStatePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<Uint8> Function(
              ffi.Pointer<ffi.Int32>)>>('SDL_GetKeyboardState');
  late final _SDL_GetKeyboardState = _SDL_GetKeyboardStatePtr.asFunction<
      ffi.Pointer<Uint8> Function(ffi.Pointer<ffi.Int32>)>();

  /// Get the current key modifier state for the keyboard.
  ///
  /// \returns an OR'd combination of the modifier keys for the keyboard. See
  /// SDL_Keymod for details.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetKeyboardState
  /// \sa SDL_SetModState
  int SDL_GetModState() {
    return _SDL_GetModState();
  }

  late final _SDL_GetModStatePtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function()>>('SDL_GetModState');
  late final _SDL_GetModState =
      _SDL_GetModStatePtr.asFunction<int Function()>();

  /// Set the current key modifier state for the keyboard.
  ///
  /// The inverse of SDL_GetModState(), SDL_SetModState() allows you to impose
  /// modifier key states on your application. Simply pass your desired modifier
  /// states into `modstate`. This value may be a bitwise, OR'd combination of
  /// SDL_Keymod values.
  ///
  /// This does not change the keyboard state, only the key modifier flags that
  /// SDL reports.
  ///
  /// \param modstate the desired SDL_Keymod for the keyboard
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetModState
  void SDL_SetModState(
    int modstate,
  ) {
    return _SDL_SetModState(
      modstate,
    );
  }

  late final _SDL_SetModStatePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Int32)>>(
          'SDL_SetModState');
  late final _SDL_SetModState =
      _SDL_SetModStatePtr.asFunction<void Function(int)>();

  /// Get the key code corresponding to the given scancode according to the
  /// current keyboard layout.
  ///
  /// See SDL_Keycode for details.
  ///
  /// \param scancode the desired SDL_Scancode to query
  /// \returns the SDL_Keycode that corresponds to the given SDL_Scancode.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetKeyName
  /// \sa SDL_GetScancodeFromKey
  int SDL_GetKeyFromScancode(
    int scancode,
  ) {
    return _SDL_GetKeyFromScancode(
      scancode,
    );
  }

  late final _SDL_GetKeyFromScancodePtr =
      _lookup<ffi.NativeFunction<SDL_Keycode Function(ffi.Int32)>>(
          'SDL_GetKeyFromScancode');
  late final _SDL_GetKeyFromScancode =
      _SDL_GetKeyFromScancodePtr.asFunction<int Function(int)>();

  /// Get the scancode corresponding to the given key code according to the
  /// current keyboard layout.
  ///
  /// See SDL_Scancode for details.
  ///
  /// \param key the desired SDL_Keycode to query
  /// \returns the SDL_Scancode that corresponds to the given SDL_Keycode.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetKeyFromScancode
  /// \sa SDL_GetScancodeName
  int SDL_GetScancodeFromKey(
    int key,
  ) {
    return _SDL_GetScancodeFromKey(
      key,
    );
  }

  late final _SDL_GetScancodeFromKeyPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(SDL_Keycode)>>(
          'SDL_GetScancodeFromKey');
  late final _SDL_GetScancodeFromKey =
      _SDL_GetScancodeFromKeyPtr.asFunction<int Function(int)>();

  /// Get a human-readable name for a scancode.
  ///
  /// See SDL_Scancode for details.
  ///
  /// **Warning**: The returned name is by design not stable across platforms,
  /// e.g. the name for `SDL_SCANCODE_LGUI` is "Left GUI" under Linux but "Left
  /// Windows" under Microsoft Windows, and some scancodes like
  /// `SDL_SCANCODE_NONUSBACKSLASH` don't have any name at all. There are even
  /// scancodes that share names, e.g. `SDL_SCANCODE_RETURN` and
  /// `SDL_SCANCODE_RETURN2` (both called "Return"). This function is therefore
  /// unsuitable for creating a stable cross-platform two-way mapping between
  /// strings and scancodes.
  ///
  /// \param scancode the desired SDL_Scancode to query
  /// \returns a pointer to the name for the scancode. If the scancode doesn't
  /// have a name this function returns an empty string ("").
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetScancodeFromKey
  /// \sa SDL_GetScancodeFromName
  ffi.Pointer<ffi.Int8> SDL_GetScancodeName(
    int scancode,
  ) {
    return _SDL_GetScancodeName(
      scancode,
    );
  }

  late final _SDL_GetScancodeNamePtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Int8> Function(ffi.Int32)>>(
          'SDL_GetScancodeName');
  late final _SDL_GetScancodeName =
      _SDL_GetScancodeNamePtr.asFunction<ffi.Pointer<ffi.Int8> Function(int)>();

  /// Get a scancode from a human-readable name.
  ///
  /// \param name the human-readable scancode name
  /// \returns the SDL_Scancode, or `SDL_SCANCODE_UNKNOWN` if the name wasn't
  /// recognized; call SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetKeyFromName
  /// \sa SDL_GetScancodeFromKey
  /// \sa SDL_GetScancodeName
  int SDL_GetScancodeFromName(
    ffi.Pointer<ffi.Int8> name,
  ) {
    return _SDL_GetScancodeFromName(
      name,
    );
  }

  late final _SDL_GetScancodeFromNamePtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<ffi.Int8>)>>(
          'SDL_GetScancodeFromName');
  late final _SDL_GetScancodeFromName = _SDL_GetScancodeFromNamePtr.asFunction<
      int Function(ffi.Pointer<ffi.Int8>)>();

  /// Get a human-readable name for a key.
  ///
  /// See SDL_Scancode and SDL_Keycode for details.
  ///
  /// \param key the desired SDL_Keycode to query
  /// \returns a pointer to a UTF-8 string that stays valid at least until the
  /// next call to this function. If you need it around any longer, you
  /// must copy it. If the key doesn't have a name, this function
  /// returns an empty string ("").
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetKeyFromName
  /// \sa SDL_GetKeyFromScancode
  /// \sa SDL_GetScancodeFromKey
  ffi.Pointer<ffi.Int8> SDL_GetKeyName(
    int key,
  ) {
    return _SDL_GetKeyName(
      key,
    );
  }

  late final _SDL_GetKeyNamePtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Int8> Function(SDL_Keycode)>>(
          'SDL_GetKeyName');
  late final _SDL_GetKeyName =
      _SDL_GetKeyNamePtr.asFunction<ffi.Pointer<ffi.Int8> Function(int)>();

  /// Get a key code from a human-readable name.
  ///
  /// \param name the human-readable key name
  /// \returns key code, or `SDLK_UNKNOWN` if the name wasn't recognized; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetKeyFromScancode
  /// \sa SDL_GetKeyName
  /// \sa SDL_GetScancodeFromName
  int SDL_GetKeyFromName(
    ffi.Pointer<ffi.Int8> name,
  ) {
    return _SDL_GetKeyFromName(
      name,
    );
  }

  late final _SDL_GetKeyFromNamePtr =
      _lookup<ffi.NativeFunction<SDL_Keycode Function(ffi.Pointer<ffi.Int8>)>>(
          'SDL_GetKeyFromName');
  late final _SDL_GetKeyFromName =
      _SDL_GetKeyFromNamePtr.asFunction<int Function(ffi.Pointer<ffi.Int8>)>();

  /// Start accepting Unicode text input events.
  ///
  /// This function will start accepting Unicode text input events in the focused
  /// SDL window, and start emitting SDL_TextInputEvent (SDL_TEXTINPUT) and
  /// SDL_TextEditingEvent (SDL_TEXTEDITING) events. Please use this function in
  /// pair with SDL_StopTextInput().
  ///
  /// On some platforms using this function activates the screen keyboard.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_SetTextInputRect
  /// \sa SDL_StopTextInput
  void SDL_StartTextInput() {
    return _SDL_StartTextInput();
  }

  late final _SDL_StartTextInputPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('SDL_StartTextInput');
  late final _SDL_StartTextInput =
      _SDL_StartTextInputPtr.asFunction<void Function()>();

  /// Check whether or not Unicode text input events are enabled.
  ///
  /// \returns SDL_TRUE if text input events are enabled else SDL_FALSE.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_StartTextInput
  int SDL_IsTextInputActive() {
    return _SDL_IsTextInputActive();
  }

  late final _SDL_IsTextInputActivePtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function()>>(
          'SDL_IsTextInputActive');
  late final _SDL_IsTextInputActive =
      _SDL_IsTextInputActivePtr.asFunction<int Function()>();

  /// Stop receiving any text input events.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_StartTextInput
  void SDL_StopTextInput() {
    return _SDL_StopTextInput();
  }

  late final _SDL_StopTextInputPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('SDL_StopTextInput');
  late final _SDL_StopTextInput =
      _SDL_StopTextInputPtr.asFunction<void Function()>();

  /// Set the rectangle used to type Unicode text inputs.
  ///
  /// \param rect the SDL_Rect structure representing the rectangle to receive
  /// text (ignored if NULL)
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_StartTextInput
  void SDL_SetTextInputRect(
    ffi.Pointer<SDL_Rect> rect,
  ) {
    return _SDL_SetTextInputRect(
      rect,
    );
  }

  late final _SDL_SetTextInputRectPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<SDL_Rect>)>>(
          'SDL_SetTextInputRect');
  late final _SDL_SetTextInputRect = _SDL_SetTextInputRectPtr.asFunction<
      void Function(ffi.Pointer<SDL_Rect>)>();

  /// Check whether the platform has screen keyboard support.
  ///
  /// \returns SDL_TRUE if the platform has some screen keyboard support or
  /// SDL_FALSE if not.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_StartTextInput
  /// \sa SDL_IsScreenKeyboardShown
  int SDL_HasScreenKeyboardSupport() {
    return _SDL_HasScreenKeyboardSupport();
  }

  late final _SDL_HasScreenKeyboardSupportPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function()>>(
          'SDL_HasScreenKeyboardSupport');
  late final _SDL_HasScreenKeyboardSupport =
      _SDL_HasScreenKeyboardSupportPtr.asFunction<int Function()>();

  /// Check whether the screen keyboard is shown for given window.
  ///
  /// \param window the window for which screen keyboard should be queried
  /// \returns SDL_TRUE if screen keyboard is shown or SDL_FALSE if not.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_HasScreenKeyboardSupport
  int SDL_IsScreenKeyboardShown(
    ffi.Pointer<SDL_Window> window,
  ) {
    return _SDL_IsScreenKeyboardShown(
      window,
    );
  }

  late final _SDL_IsScreenKeyboardShownPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<SDL_Window>)>>(
          'SDL_IsScreenKeyboardShown');
  late final _SDL_IsScreenKeyboardShown = _SDL_IsScreenKeyboardShownPtr
      .asFunction<int Function(ffi.Pointer<SDL_Window>)>();

  /// Get the window which currently has mouse focus.
  ///
  /// \returns the window with mouse focus.
  ///
  /// \since This function is available since SDL 2.0.0.
  ffi.Pointer<SDL_Window> SDL_GetMouseFocus() {
    return _SDL_GetMouseFocus();
  }

  late final _SDL_GetMouseFocusPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<SDL_Window> Function()>>(
          'SDL_GetMouseFocus');
  late final _SDL_GetMouseFocus =
      _SDL_GetMouseFocusPtr.asFunction<ffi.Pointer<SDL_Window> Function()>();

  /// Retrieve the current state of the mouse.
  ///
  /// The current button state is returned as a button bitmask, which can be
  /// tested using the `SDL_BUTTON(X)` macros (where `X` is generally 1 for the
  /// left, 2 for middle, 3 for the right button), and `x` and `y` are set to the
  /// mouse cursor position relative to the focus window. You can pass NULL for
  /// either `x` or `y`.
  ///
  /// \param x the x coordinate of the mouse cursor position relative to the
  /// focus window
  /// \param y the y coordinate of the mouse cursor position relative to the
  /// focus window
  /// \returns a 32-bit button bitmask of the current button state.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetGlobalMouseState
  /// \sa SDL_GetRelativeMouseState
  /// \sa SDL_PumpEvents
  int SDL_GetMouseState(
    ffi.Pointer<ffi.Int32> x,
    ffi.Pointer<ffi.Int32> y,
  ) {
    return _SDL_GetMouseState(
      x,
      y,
    );
  }

  late final _SDL_GetMouseStatePtr = _lookup<
      ffi.NativeFunction<
          Uint32 Function(ffi.Pointer<ffi.Int32>,
              ffi.Pointer<ffi.Int32>)>>('SDL_GetMouseState');
  late final _SDL_GetMouseState = _SDL_GetMouseStatePtr.asFunction<
      int Function(ffi.Pointer<ffi.Int32>, ffi.Pointer<ffi.Int32>)>();

  /// Get the current state of the mouse in relation to the desktop.
  ///
  /// This works similarly to SDL_GetMouseState(), but the coordinates will be
  /// reported relative to the top-left of the desktop. This can be useful if you
  /// need to track the mouse outside of a specific window and SDL_CaptureMouse()
  /// doesn't fit your needs. For example, it could be useful if you need to
  /// track the mouse while dragging a window, where coordinates relative to a
  /// window might not be in sync at all times.
  ///
  /// Note: SDL_GetMouseState() returns the mouse position as SDL understands it
  /// from the last pump of the event queue. This function, however, queries the
  /// OS for the current mouse position, and as such, might be a slightly less
  /// efficient function. Unless you know what you're doing and have a good
  /// reason to use this function, you probably want SDL_GetMouseState() instead.
  ///
  /// \param x filled in with the current X coord relative to the desktop; can be
  /// NULL
  /// \param y filled in with the current Y coord relative to the desktop; can be
  /// NULL
  /// \returns the current button state as a bitmask which can be tested using
  /// the SDL_BUTTON(X) macros.
  ///
  /// \since This function is available since SDL 2.0.4.
  ///
  /// \sa SDL_CaptureMouse
  int SDL_GetGlobalMouseState(
    ffi.Pointer<ffi.Int32> x,
    ffi.Pointer<ffi.Int32> y,
  ) {
    return _SDL_GetGlobalMouseState(
      x,
      y,
    );
  }

  late final _SDL_GetGlobalMouseStatePtr = _lookup<
      ffi.NativeFunction<
          Uint32 Function(ffi.Pointer<ffi.Int32>,
              ffi.Pointer<ffi.Int32>)>>('SDL_GetGlobalMouseState');
  late final _SDL_GetGlobalMouseState = _SDL_GetGlobalMouseStatePtr.asFunction<
      int Function(ffi.Pointer<ffi.Int32>, ffi.Pointer<ffi.Int32>)>();

  /// Retrieve the relative state of the mouse.
  ///
  /// The current button state is returned as a button bitmask, which can be
  /// tested using the `SDL_BUTTON(X)` macros (where `X` is generally 1 for the
  /// left, 2 for middle, 3 for the right button), and `x` and `y` are set to the
  /// mouse deltas since the last call to SDL_GetRelativeMouseState() or since
  /// event initialization. You can pass NULL for either `x` or `y`.
  ///
  /// \param x a pointer filled with the last recorded x coordinate of the mouse
  /// \param y a pointer filled with the last recorded y coordinate of the mouse
  /// \returns a 32-bit button bitmask of the relative button state.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetMouseState
  int SDL_GetRelativeMouseState(
    ffi.Pointer<ffi.Int32> x,
    ffi.Pointer<ffi.Int32> y,
  ) {
    return _SDL_GetRelativeMouseState(
      x,
      y,
    );
  }

  late final _SDL_GetRelativeMouseStatePtr = _lookup<
      ffi.NativeFunction<
          Uint32 Function(ffi.Pointer<ffi.Int32>,
              ffi.Pointer<ffi.Int32>)>>('SDL_GetRelativeMouseState');
  late final _SDL_GetRelativeMouseState =
      _SDL_GetRelativeMouseStatePtr.asFunction<
          int Function(ffi.Pointer<ffi.Int32>, ffi.Pointer<ffi.Int32>)>();

  /// Move the mouse cursor to the given position within the window.
  ///
  /// This function generates a mouse motion event.
  ///
  /// Note that this function will appear to succeed, but not actually move the
  /// mouse when used over Microsoft Remote Desktop.
  ///
  /// \param window the window to move the mouse into, or NULL for the current
  /// mouse focus
  /// \param x the x coordinate within the window
  /// \param y the y coordinate within the window
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_WarpMouseGlobal
  void SDL_WarpMouseInWindow(
    ffi.Pointer<SDL_Window> window,
    int x,
    int y,
  ) {
    return _SDL_WarpMouseInWindow(
      window,
      x,
      y,
    );
  }

  late final _SDL_WarpMouseInWindowPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<SDL_Window>, ffi.Int32,
              ffi.Int32)>>('SDL_WarpMouseInWindow');
  late final _SDL_WarpMouseInWindow = _SDL_WarpMouseInWindowPtr.asFunction<
      void Function(ffi.Pointer<SDL_Window>, int, int)>();

  /// Move the mouse to the given position in global screen space.
  ///
  /// This function generates a mouse motion event.
  ///
  /// A failure of this function usually means that it is unsupported by a
  /// platform.
  ///
  /// Note that this function will appear to succeed, but not actually move the
  /// mouse when used over Microsoft Remote Desktop.
  ///
  /// \param x the x coordinate
  /// \param y the y coordinate
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.4.
  ///
  /// \sa SDL_WarpMouseInWindow
  int SDL_WarpMouseGlobal(
    int x,
    int y,
  ) {
    return _SDL_WarpMouseGlobal(
      x,
      y,
    );
  }

  late final _SDL_WarpMouseGlobalPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Int32, ffi.Int32)>>(
          'SDL_WarpMouseGlobal');
  late final _SDL_WarpMouseGlobal =
      _SDL_WarpMouseGlobalPtr.asFunction<int Function(int, int)>();

  /// Set relative mouse mode.
  ///
  /// While the mouse is in relative mode, the cursor is hidden, and the driver
  /// will try to report continuous motion in the current window. Only relative
  /// motion events will be delivered, the mouse position will not change.
  ///
  /// Note that this function will not be able to provide continuous relative
  /// motion when used over Microsoft Remote Desktop, instead motion is limited
  /// to the bounds of the screen.
  ///
  /// This function will flush any pending mouse motion.
  ///
  /// \param enabled SDL_TRUE to enable relative mode, SDL_FALSE to disable.
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// If relative mode is not supported, this returns -1.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetRelativeMouseMode
  int SDL_SetRelativeMouseMode(
    int enabled,
  ) {
    return _SDL_SetRelativeMouseMode(
      enabled,
    );
  }

  late final _SDL_SetRelativeMouseModePtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Int32)>>(
          'SDL_SetRelativeMouseMode');
  late final _SDL_SetRelativeMouseMode =
      _SDL_SetRelativeMouseModePtr.asFunction<int Function(int)>();

  /// Capture the mouse and to track input outside an SDL window.
  ///
  /// Capturing enables your app to obtain mouse events globally, instead of just
  /// within your window. Not all video targets support this function. When
  /// capturing is enabled, the current window will get all mouse events, but
  /// unlike relative mode, no change is made to the cursor and it is not
  /// restrained to your window.
  ///
  /// This function may also deny mouse input to other windows--both those in
  /// your application and others on the system--so you should use this function
  /// sparingly, and in small bursts. For example, you might want to track the
  /// mouse while the user is dragging something, until the user releases a mouse
  /// button. It is not recommended that you capture the mouse for long periods
  /// of time, such as the entire time your app is running. For that, you should
  /// probably use SDL_SetRelativeMouseMode() or SDL_SetWindowGrab(), depending
  /// on your goals.
  ///
  /// While captured, mouse events still report coordinates relative to the
  /// current (foreground) window, but those coordinates may be outside the
  /// bounds of the window (including negative values). Capturing is only allowed
  /// for the foreground window. If the window loses focus while capturing, the
  /// capture will be disabled automatically.
  ///
  /// While capturing is enabled, the current window will have the
  /// `SDL_WINDOW_MOUSE_CAPTURE` flag set.
  ///
  /// \param enabled SDL_TRUE to enable capturing, SDL_FALSE to disable.
  /// \returns 0 on success or -1 if not supported; call SDL_GetError() for more
  /// information.
  ///
  /// \since This function is available since SDL 2.0.4.
  ///
  /// \sa SDL_GetGlobalMouseState
  int SDL_CaptureMouse(
    int enabled,
  ) {
    return _SDL_CaptureMouse(
      enabled,
    );
  }

  late final _SDL_CaptureMousePtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Int32)>>(
          'SDL_CaptureMouse');
  late final _SDL_CaptureMouse =
      _SDL_CaptureMousePtr.asFunction<int Function(int)>();

  /// Query whether relative mouse mode is enabled.
  ///
  /// \returns SDL_TRUE if relative mode is enabled or SDL_FALSE otherwise.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_SetRelativeMouseMode
  int SDL_GetRelativeMouseMode() {
    return _SDL_GetRelativeMouseMode();
  }

  late final _SDL_GetRelativeMouseModePtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function()>>(
          'SDL_GetRelativeMouseMode');
  late final _SDL_GetRelativeMouseMode =
      _SDL_GetRelativeMouseModePtr.asFunction<int Function()>();

  /// Create a cursor using the specified bitmap data and mask (in MSB format).
  ///
  /// `mask` has to be in MSB (Most Significant Bit) format.
  ///
  /// The cursor width (`w`) must be a multiple of 8 bits.
  ///
  /// The cursor is created in black and white according to the following:
  ///
  /// - data=0, mask=1: white
  /// - data=1, mask=1: black
  /// - data=0, mask=0: transparent
  /// - data=1, mask=0: inverted color if possible, black if not.
  ///
  /// Cursors created with this function must be freed with SDL_FreeCursor().
  ///
  /// If you want to have a color cursor, or create your cursor from an
  /// SDL_Surface, you should use SDL_CreateColorCursor(). Alternately, you can
  /// hide the cursor and draw your own as part of your game's rendering, but it
  /// will be bound to the framerate.
  ///
  /// Also, since SDL 2.0.0, SDL_CreateSystemCursor() is available, which
  /// provides twelve readily available system cursors to pick from.
  ///
  /// \param data the color value for each pixel of the cursor
  /// \param mask the mask value for each pixel of the cursor
  /// \param w the width of the cursor
  /// \param h the height of the cursor
  /// \param hot_x the X-axis location of the upper left corner of the cursor
  /// relative to the actual mouse position
  /// \param hot_y the Y-axis location of the upper left corner of the cursor
  /// relative to the actual mouse position
  /// \returns a new cursor with the specified parameters on success or NULL on
  /// failure; call SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_FreeCursor
  /// \sa SDL_SetCursor
  /// \sa SDL_ShowCursor
  ffi.Pointer<SDL_Cursor> SDL_CreateCursor(
    ffi.Pointer<Uint8> data,
    ffi.Pointer<Uint8> mask,
    int w,
    int h,
    int hot_x,
    int hot_y,
  ) {
    return _SDL_CreateCursor(
      data,
      mask,
      w,
      h,
      hot_x,
      hot_y,
    );
  }

  late final _SDL_CreateCursorPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<SDL_Cursor> Function(
              ffi.Pointer<Uint8>,
              ffi.Pointer<Uint8>,
              ffi.Int32,
              ffi.Int32,
              ffi.Int32,
              ffi.Int32)>>('SDL_CreateCursor');
  late final _SDL_CreateCursor = _SDL_CreateCursorPtr.asFunction<
      ffi.Pointer<SDL_Cursor> Function(
          ffi.Pointer<Uint8>, ffi.Pointer<Uint8>, int, int, int, int)>();

  /// Create a color cursor.
  ///
  /// \param surface an SDL_Surface structure representing the cursor image
  /// \param hot_x the x position of the cursor hot spot
  /// \param hot_y the y position of the cursor hot spot
  /// \returns the new cursor on success or NULL on failure; call SDL_GetError()
  /// for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_CreateCursor
  /// \sa SDL_FreeCursor
  ffi.Pointer<SDL_Cursor> SDL_CreateColorCursor(
    ffi.Pointer<SDL_Surface> surface,
    int hot_x,
    int hot_y,
  ) {
    return _SDL_CreateColorCursor(
      surface,
      hot_x,
      hot_y,
    );
  }

  late final _SDL_CreateColorCursorPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<SDL_Cursor> Function(ffi.Pointer<SDL_Surface>, ffi.Int32,
              ffi.Int32)>>('SDL_CreateColorCursor');
  late final _SDL_CreateColorCursor = _SDL_CreateColorCursorPtr.asFunction<
      ffi.Pointer<SDL_Cursor> Function(ffi.Pointer<SDL_Surface>, int, int)>();

  /// Create a system cursor.
  ///
  /// \param id an SDL_SystemCursor enum value
  /// \returns a cursor on success or NULL on failure; call SDL_GetError() for
  /// more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_FreeCursor
  ffi.Pointer<SDL_Cursor> SDL_CreateSystemCursor(
    int id,
  ) {
    return _SDL_CreateSystemCursor(
      id,
    );
  }

  late final _SDL_CreateSystemCursorPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<SDL_Cursor> Function(ffi.Int32)>>(
          'SDL_CreateSystemCursor');
  late final _SDL_CreateSystemCursor = _SDL_CreateSystemCursorPtr.asFunction<
      ffi.Pointer<SDL_Cursor> Function(int)>();

  /// Set the active cursor.
  ///
  /// This function sets the currently active cursor to the specified one. If the
  /// cursor is currently visible, the change will be immediately represented on
  /// the display. SDL_SetCursor(NULL) can be used to force cursor redraw, if
  /// this is desired for any reason.
  ///
  /// \param cursor a cursor to make active
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_CreateCursor
  /// \sa SDL_GetCursor
  /// \sa SDL_ShowCursor
  void SDL_SetCursor(
    ffi.Pointer<SDL_Cursor> cursor,
  ) {
    return _SDL_SetCursor(
      cursor,
    );
  }

  late final _SDL_SetCursorPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<SDL_Cursor>)>>(
          'SDL_SetCursor');
  late final _SDL_SetCursor =
      _SDL_SetCursorPtr.asFunction<void Function(ffi.Pointer<SDL_Cursor>)>();

  /// Get the active cursor.
  ///
  /// This function returns a pointer to the current cursor which is owned by the
  /// library. It is not necessary to free the cursor with SDL_FreeCursor().
  ///
  /// \returns the active cursor or NULL if there is no mouse.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_SetCursor
  ffi.Pointer<SDL_Cursor> SDL_GetCursor() {
    return _SDL_GetCursor();
  }

  late final _SDL_GetCursorPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<SDL_Cursor> Function()>>(
          'SDL_GetCursor');
  late final _SDL_GetCursor =
      _SDL_GetCursorPtr.asFunction<ffi.Pointer<SDL_Cursor> Function()>();

  /// Get the default cursor.
  ///
  /// \returns the default cursor on success or NULL on failure.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_CreateSystemCursor
  ffi.Pointer<SDL_Cursor> SDL_GetDefaultCursor() {
    return _SDL_GetDefaultCursor();
  }

  late final _SDL_GetDefaultCursorPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<SDL_Cursor> Function()>>(
          'SDL_GetDefaultCursor');
  late final _SDL_GetDefaultCursor =
      _SDL_GetDefaultCursorPtr.asFunction<ffi.Pointer<SDL_Cursor> Function()>();

  /// Free a previously-created cursor.
  ///
  /// Use this function to free cursor resources created with SDL_CreateCursor(),
  /// SDL_CreateColorCursor() or SDL_CreateSystemCursor().
  ///
  /// \param cursor the cursor to free
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_CreateColorCursor
  /// \sa SDL_CreateCursor
  /// \sa SDL_CreateSystemCursor
  void SDL_FreeCursor(
    ffi.Pointer<SDL_Cursor> cursor,
  ) {
    return _SDL_FreeCursor(
      cursor,
    );
  }

  late final _SDL_FreeCursorPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<SDL_Cursor>)>>(
          'SDL_FreeCursor');
  late final _SDL_FreeCursor =
      _SDL_FreeCursorPtr.asFunction<void Function(ffi.Pointer<SDL_Cursor>)>();

  /// Toggle whether or not the cursor is shown.
  ///
  /// The cursor starts off displayed but can be turned off. Passing `SDL_ENABLE`
  /// displays the cursor and passing `SDL_DISABLE` hides it.
  ///
  /// The current state of the mouse cursor can be queried by passing
  /// `SDL_QUERY`; either `SDL_DISABLE` or `SDL_ENABLE` will be returned.
  ///
  /// \param toggle `SDL_ENABLE` to show the cursor, `SDL_DISABLE` to hide it,
  /// `SDL_QUERY` to query the current state without changing it.
  /// \returns `SDL_ENABLE` if the cursor is shown, or `SDL_DISABLE` if the
  /// cursor is hidden, or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_CreateCursor
  /// \sa SDL_SetCursor
  int SDL_ShowCursor(
    int toggle,
  ) {
    return _SDL_ShowCursor(
      toggle,
    );
  }

  late final _SDL_ShowCursorPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Int32)>>(
          'SDL_ShowCursor');
  late final _SDL_ShowCursor =
      _SDL_ShowCursorPtr.asFunction<int Function(int)>();

  /// Locking for multi-threaded access to the joystick API
  ///
  /// If you are using the joystick API or handling events from multiple threads
  /// you should use these locking functions to protect access to the joysticks.
  ///
  /// In particular, you are guaranteed that the joystick list won't change, so
  /// the API functions that take a joystick index will be valid, and joystick
  /// and game controller events will not be delivered.
  ///
  /// \since This function is available since SDL 2.0.7.
  void SDL_LockJoysticks() {
    return _SDL_LockJoysticks();
  }

  late final _SDL_LockJoysticksPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('SDL_LockJoysticks');
  late final _SDL_LockJoysticks =
      _SDL_LockJoysticksPtr.asFunction<void Function()>();

  /// Unlocking for multi-threaded access to the joystick API
  ///
  /// If you are using the joystick API or handling events from multiple threads
  /// you should use these locking functions to protect access to the joysticks.
  ///
  /// In particular, you are guaranteed that the joystick list won't change, so
  /// the API functions that take a joystick index will be valid, and joystick
  /// and game controller events will not be delivered.
  ///
  /// \since This function is available since SDL 2.0.7.
  void SDL_UnlockJoysticks() {
    return _SDL_UnlockJoysticks();
  }

  late final _SDL_UnlockJoysticksPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('SDL_UnlockJoysticks');
  late final _SDL_UnlockJoysticks =
      _SDL_UnlockJoysticksPtr.asFunction<void Function()>();

  /// Count the number of joysticks attached to the system.
  ///
  /// \returns the number of attached joysticks on success or a negative error
  /// code on failure; call SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_JoystickName
  /// \sa SDL_JoystickOpen
  int SDL_NumJoysticks() {
    return _SDL_NumJoysticks();
  }

  late final _SDL_NumJoysticksPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function()>>('SDL_NumJoysticks');
  late final _SDL_NumJoysticks =
      _SDL_NumJoysticksPtr.asFunction<int Function()>();

  /// Get the implementation dependent name of a joystick.
  ///
  /// This can be called before any joysticks are opened.
  ///
  /// \param device_index the index of the joystick to query (the N'th joystick
  /// on the system)
  /// \returns the name of the selected joystick. If no name can be found, this
  /// function returns NULL; call SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_JoystickName
  /// \sa SDL_JoystickOpen
  ffi.Pointer<ffi.Int8> SDL_JoystickNameForIndex(
    int device_index,
  ) {
    return _SDL_JoystickNameForIndex(
      device_index,
    );
  }

  late final _SDL_JoystickNameForIndexPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Int8> Function(ffi.Int32)>>(
          'SDL_JoystickNameForIndex');
  late final _SDL_JoystickNameForIndex = _SDL_JoystickNameForIndexPtr
      .asFunction<ffi.Pointer<ffi.Int8> Function(int)>();

  /// Get the player index of a joystick, or -1 if it's not available This can be
  /// called before any joysticks are opened.
  ///
  /// \since This function is available since SDL 2.0.9.
  int SDL_JoystickGetDevicePlayerIndex(
    int device_index,
  ) {
    return _SDL_JoystickGetDevicePlayerIndex(
      device_index,
    );
  }

  late final _SDL_JoystickGetDevicePlayerIndexPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Int32)>>(
          'SDL_JoystickGetDevicePlayerIndex');
  late final _SDL_JoystickGetDevicePlayerIndex =
      _SDL_JoystickGetDevicePlayerIndexPtr.asFunction<int Function(int)>();

  /// Get the implementation-dependent GUID for the joystick at a given device
  /// index.
  ///
  /// This function can be called before any joysticks are opened.
  ///
  /// \param device_index the index of the joystick to query (the N'th joystick
  /// on the system
  /// \returns the GUID of the selected joystick. If called on an invalid index,
  /// this function returns a zero GUID
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_JoystickGetGUID
  /// \sa SDL_JoystickGetGUIDString
  SDL_JoystickGUID SDL_JoystickGetDeviceGUID(
    int device_index,
  ) {
    return _SDL_JoystickGetDeviceGUID(
      device_index,
    );
  }

  late final _SDL_JoystickGetDeviceGUIDPtr =
      _lookup<ffi.NativeFunction<SDL_JoystickGUID Function(ffi.Int32)>>(
          'SDL_JoystickGetDeviceGUID');
  late final _SDL_JoystickGetDeviceGUID = _SDL_JoystickGetDeviceGUIDPtr
      .asFunction<SDL_JoystickGUID Function(int)>();

  /// Get the USB vendor ID of a joystick, if available.
  ///
  /// This can be called before any joysticks are opened. If the vendor ID isn't
  /// available this function returns 0.
  ///
  /// \param device_index the index of the joystick to query (the N'th joystick
  /// on the system
  /// \returns the USB vendor ID of the selected joystick. If called on an
  /// invalid index, this function returns zero
  ///
  /// \since This function is available since SDL 2.0.6.
  int SDL_JoystickGetDeviceVendor(
    int device_index,
  ) {
    return _SDL_JoystickGetDeviceVendor(
      device_index,
    );
  }

  late final _SDL_JoystickGetDeviceVendorPtr =
      _lookup<ffi.NativeFunction<Uint16 Function(ffi.Int32)>>(
          'SDL_JoystickGetDeviceVendor');
  late final _SDL_JoystickGetDeviceVendor =
      _SDL_JoystickGetDeviceVendorPtr.asFunction<int Function(int)>();

  /// Get the USB product ID of a joystick, if available.
  ///
  /// This can be called before any joysticks are opened. If the product ID isn't
  /// available this function returns 0.
  ///
  /// \param device_index the index of the joystick to query (the N'th joystick
  /// on the system
  /// \returns the USB product ID of the selected joystick. If called on an
  /// invalid index, this function returns zero
  ///
  /// \since This function is available since SDL 2.0.6.
  int SDL_JoystickGetDeviceProduct(
    int device_index,
  ) {
    return _SDL_JoystickGetDeviceProduct(
      device_index,
    );
  }

  late final _SDL_JoystickGetDeviceProductPtr =
      _lookup<ffi.NativeFunction<Uint16 Function(ffi.Int32)>>(
          'SDL_JoystickGetDeviceProduct');
  late final _SDL_JoystickGetDeviceProduct =
      _SDL_JoystickGetDeviceProductPtr.asFunction<int Function(int)>();

  /// Get the product version of a joystick, if available.
  ///
  /// This can be called before any joysticks are opened. If the product version
  /// isn't available this function returns 0.
  ///
  /// \param device_index the index of the joystick to query (the N'th joystick
  /// on the system
  /// \returns the product version of the selected joystick. If called on an
  /// invalid index, this function returns zero
  ///
  /// \since This function is available since SDL 2.0.6.
  int SDL_JoystickGetDeviceProductVersion(
    int device_index,
  ) {
    return _SDL_JoystickGetDeviceProductVersion(
      device_index,
    );
  }

  late final _SDL_JoystickGetDeviceProductVersionPtr =
      _lookup<ffi.NativeFunction<Uint16 Function(ffi.Int32)>>(
          'SDL_JoystickGetDeviceProductVersion');
  late final _SDL_JoystickGetDeviceProductVersion =
      _SDL_JoystickGetDeviceProductVersionPtr.asFunction<int Function(int)>();

  /// Get the type of a joystick, if available.
  ///
  /// This can be called before any joysticks are opened.
  ///
  /// \param device_index the index of the joystick to query (the N'th joystick
  /// on the system
  /// \returns the SDL_JoystickType of the selected joystick. If called on an
  /// invalid index, this function returns `SDL_JOYSTICK_TYPE_UNKNOWN`
  ///
  /// \since This function is available since SDL 2.0.6.
  int SDL_JoystickGetDeviceType(
    int device_index,
  ) {
    return _SDL_JoystickGetDeviceType(
      device_index,
    );
  }

  late final _SDL_JoystickGetDeviceTypePtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Int32)>>(
          'SDL_JoystickGetDeviceType');
  late final _SDL_JoystickGetDeviceType =
      _SDL_JoystickGetDeviceTypePtr.asFunction<int Function(int)>();

  /// Get the instance ID of a joystick.
  ///
  /// This can be called before any joysticks are opened. If the index is out of
  /// range, this function will return -1.
  ///
  /// \param device_index the index of the joystick to query (the N'th joystick
  /// on the system
  /// \returns the instance id of the selected joystick. If called on an invalid
  /// index, this function returns zero
  ///
  /// \since This function is available since SDL 2.0.6.
  int SDL_JoystickGetDeviceInstanceID(
    int device_index,
  ) {
    return _SDL_JoystickGetDeviceInstanceID(
      device_index,
    );
  }

  late final _SDL_JoystickGetDeviceInstanceIDPtr =
      _lookup<ffi.NativeFunction<SDL_JoystickID Function(ffi.Int32)>>(
          'SDL_JoystickGetDeviceInstanceID');
  late final _SDL_JoystickGetDeviceInstanceID =
      _SDL_JoystickGetDeviceInstanceIDPtr.asFunction<int Function(int)>();

  /// Open a joystick for use.
  ///
  /// The `device_index` argument refers to the N'th joystick presently
  /// recognized by SDL on the system. It is **NOT** the same as the instance ID
  /// used to identify the joystick in future events. See
  /// SDL_JoystickInstanceID() for more details about instance IDs.
  ///
  /// The joystick subsystem must be initialized before a joystick can be opened
  /// for use.
  ///
  /// \param device_index the index of the joystick to query
  /// \returns a joystick identifier or NULL if an error occurred; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_JoystickClose
  /// \sa SDL_JoystickInstanceID
  ffi.Pointer<SDL_Joystick1> SDL_JoystickOpen(
    int device_index,
  ) {
    return _SDL_JoystickOpen(
      device_index,
    );
  }

  late final _SDL_JoystickOpenPtr = _lookup<
          ffi.NativeFunction<ffi.Pointer<SDL_Joystick1> Function(ffi.Int32)>>(
      'SDL_JoystickOpen');
  late final _SDL_JoystickOpen = _SDL_JoystickOpenPtr.asFunction<
      ffi.Pointer<SDL_Joystick1> Function(int)>();

  /// Get the SDL_Joystick associated with an instance id.
  ///
  /// \param instance_id the instance id to get the SDL_Joystick for
  /// \returns an SDL_Joystick on success or NULL on failure; call SDL_GetError()
  /// for more information.
  ///
  /// \since This function is available since SDL 2.0.4.
  ffi.Pointer<SDL_Joystick1> SDL_JoystickFromInstanceID(
    int instance_id,
  ) {
    return _SDL_JoystickFromInstanceID(
      instance_id,
    );
  }

  late final _SDL_JoystickFromInstanceIDPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<SDL_Joystick1> Function(
              SDL_JoystickID)>>('SDL_JoystickFromInstanceID');
  late final _SDL_JoystickFromInstanceID = _SDL_JoystickFromInstanceIDPtr
      .asFunction<ffi.Pointer<SDL_Joystick1> Function(int)>();

  /// Get the SDL_Joystick associated with a player index.
  ///
  /// \param player_index the player index to get the SDL_Joystick for
  /// \returns an SDL_Joystick on success or NULL on failure; call SDL_GetError()
  /// for more information.
  ///
  /// \since This function is available since SDL 2.0.12.
  ffi.Pointer<SDL_Joystick1> SDL_JoystickFromPlayerIndex(
    int player_index,
  ) {
    return _SDL_JoystickFromPlayerIndex(
      player_index,
    );
  }

  late final _SDL_JoystickFromPlayerIndexPtr = _lookup<
          ffi.NativeFunction<ffi.Pointer<SDL_Joystick1> Function(ffi.Int32)>>(
      'SDL_JoystickFromPlayerIndex');
  late final _SDL_JoystickFromPlayerIndex = _SDL_JoystickFromPlayerIndexPtr
      .asFunction<ffi.Pointer<SDL_Joystick1> Function(int)>();

  /// Attach a new virtual joystick.
  ///
  /// \returns the joystick's device index, or -1 if an error occurred.
  ///
  /// \since This function is available since SDL 2.0.14.
  int SDL_JoystickAttachVirtual(
    int type,
    int naxes,
    int nbuttons,
    int nhats,
  ) {
    return _SDL_JoystickAttachVirtual(
      type,
      naxes,
      nbuttons,
      nhats,
    );
  }

  late final _SDL_JoystickAttachVirtualPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Int32, ffi.Int32, ffi.Int32,
              ffi.Int32)>>('SDL_JoystickAttachVirtual');
  late final _SDL_JoystickAttachVirtual = _SDL_JoystickAttachVirtualPtr
      .asFunction<int Function(int, int, int, int)>();

  /// Detach a virtual joystick.
  ///
  /// \param device_index a value previously returned from
  /// SDL_JoystickAttachVirtual()
  /// \returns 0 on success, or -1 if an error occurred.
  ///
  /// \since This function is available since SDL 2.0.14.
  int SDL_JoystickDetachVirtual(
    int device_index,
  ) {
    return _SDL_JoystickDetachVirtual(
      device_index,
    );
  }

  late final _SDL_JoystickDetachVirtualPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Int32)>>(
          'SDL_JoystickDetachVirtual');
  late final _SDL_JoystickDetachVirtual =
      _SDL_JoystickDetachVirtualPtr.asFunction<int Function(int)>();

  /// Query whether or not the joystick at a given device index is virtual.
  ///
  /// \param device_index a joystick device index.
  /// \returns SDL_TRUE if the joystick is virtual, SDL_FALSE otherwise.
  ///
  /// \since This function is available since SDL 2.0.14.
  int SDL_JoystickIsVirtual(
    int device_index,
  ) {
    return _SDL_JoystickIsVirtual(
      device_index,
    );
  }

  late final _SDL_JoystickIsVirtualPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Int32)>>(
          'SDL_JoystickIsVirtual');
  late final _SDL_JoystickIsVirtual =
      _SDL_JoystickIsVirtualPtr.asFunction<int Function(int)>();

  /// Set values on an opened, virtual-joystick's axis.
  ///
  /// Please note that values set here will not be applied until the next call to
  /// SDL_JoystickUpdate, which can either be called directly, or can be called
  /// indirectly through various other SDL APIs, including, but not limited to
  /// the following: SDL_PollEvent, SDL_PumpEvents, SDL_WaitEventTimeout,
  /// SDL_WaitEvent.
  ///
  /// \param joystick the virtual joystick on which to set state.
  /// \param axis the specific axis on the virtual joystick to set.
  /// \param value the new value for the specified axis.
  /// \returns 0 on success, -1 on error.
  ///
  /// \since This function is available since SDL 2.0.14.
  int SDL_JoystickSetVirtualAxis(
    ffi.Pointer<SDL_Joystick1> joystick,
    int axis,
    int value,
  ) {
    return _SDL_JoystickSetVirtualAxis(
      joystick,
      axis,
      value,
    );
  }

  late final _SDL_JoystickSetVirtualAxisPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_Joystick1>, ffi.Int32,
              Sint16)>>('SDL_JoystickSetVirtualAxis');
  late final _SDL_JoystickSetVirtualAxis = _SDL_JoystickSetVirtualAxisPtr
      .asFunction<int Function(ffi.Pointer<SDL_Joystick1>, int, int)>();

  /// Set values on an opened, virtual-joystick's button.
  ///
  /// Please note that values set here will not be applied until the next call to
  /// SDL_JoystickUpdate, which can either be called directly, or can be called
  /// indirectly through various other SDL APIs, including, but not limited to
  /// the following: SDL_PollEvent, SDL_PumpEvents, SDL_WaitEventTimeout,
  /// SDL_WaitEvent.
  ///
  /// \param joystick the virtual joystick on which to set state.
  /// \param button the specific button on the virtual joystick to set.
  /// \param value the new value for the specified button.
  /// \returns 0 on success, -1 on error.
  ///
  /// \since This function is available since SDL 2.0.14.
  int SDL_JoystickSetVirtualButton(
    ffi.Pointer<SDL_Joystick1> joystick,
    int button,
    int value,
  ) {
    return _SDL_JoystickSetVirtualButton(
      joystick,
      button,
      value,
    );
  }

  late final _SDL_JoystickSetVirtualButtonPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_Joystick1>, ffi.Int32,
              Uint8)>>('SDL_JoystickSetVirtualButton');
  late final _SDL_JoystickSetVirtualButton = _SDL_JoystickSetVirtualButtonPtr
      .asFunction<int Function(ffi.Pointer<SDL_Joystick1>, int, int)>();

  /// Set values on an opened, virtual-joystick's hat.
  ///
  /// Please note that values set here will not be applied until the next call to
  /// SDL_JoystickUpdate, which can either be called directly, or can be called
  /// indirectly through various other SDL APIs, including, but not limited to
  /// the following: SDL_PollEvent, SDL_PumpEvents, SDL_WaitEventTimeout,
  /// SDL_WaitEvent.
  ///
  /// \param joystick the virtual joystick on which to set state.
  /// \param hat the specific hat on the virtual joystick to set.
  /// \param value the new value for the specified hat.
  /// \returns 0 on success, -1 on error.
  ///
  /// \since This function is available since SDL 2.0.14.
  int SDL_JoystickSetVirtualHat(
    ffi.Pointer<SDL_Joystick1> joystick,
    int hat,
    int value,
  ) {
    return _SDL_JoystickSetVirtualHat(
      joystick,
      hat,
      value,
    );
  }

  late final _SDL_JoystickSetVirtualHatPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_Joystick1>, ffi.Int32,
              Uint8)>>('SDL_JoystickSetVirtualHat');
  late final _SDL_JoystickSetVirtualHat = _SDL_JoystickSetVirtualHatPtr
      .asFunction<int Function(ffi.Pointer<SDL_Joystick1>, int, int)>();

  /// Get the implementation dependent name of a joystick.
  ///
  /// \param joystick the SDL_Joystick obtained from SDL_JoystickOpen()
  /// \returns the name of the selected joystick. If no name can be found, this
  /// function returns NULL; call SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_JoystickNameForIndex
  /// \sa SDL_JoystickOpen
  ffi.Pointer<ffi.Int8> SDL_JoystickName(
    ffi.Pointer<SDL_Joystick1> joystick,
  ) {
    return _SDL_JoystickName(
      joystick,
    );
  }

  late final _SDL_JoystickNamePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Int8> Function(
              ffi.Pointer<SDL_Joystick1>)>>('SDL_JoystickName');
  late final _SDL_JoystickName = _SDL_JoystickNamePtr.asFunction<
      ffi.Pointer<ffi.Int8> Function(ffi.Pointer<SDL_Joystick1>)>();

  /// Get the player index of an opened joystick.
  ///
  /// For XInput controllers this returns the XInput user index. Many joysticks
  /// will not be able to supply this information.
  ///
  /// \param joystick the SDL_Joystick obtained from SDL_JoystickOpen()
  /// \returns the player index, or -1 if it's not available.
  ///
  /// \since This function is available since SDL 2.0.9.
  int SDL_JoystickGetPlayerIndex(
    ffi.Pointer<SDL_Joystick1> joystick,
  ) {
    return _SDL_JoystickGetPlayerIndex(
      joystick,
    );
  }

  late final _SDL_JoystickGetPlayerIndexPtr = _lookup<
          ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<SDL_Joystick1>)>>(
      'SDL_JoystickGetPlayerIndex');
  late final _SDL_JoystickGetPlayerIndex = _SDL_JoystickGetPlayerIndexPtr
      .asFunction<int Function(ffi.Pointer<SDL_Joystick1>)>();

  /// Set the player index of an opened joystick.
  ///
  /// \param joystick the SDL_Joystick obtained from SDL_JoystickOpen()
  /// \param player_index the player index to set.
  ///
  /// \since This function is available since SDL 2.0.12.
  void SDL_JoystickSetPlayerIndex(
    ffi.Pointer<SDL_Joystick1> joystick,
    int player_index,
  ) {
    return _SDL_JoystickSetPlayerIndex(
      joystick,
      player_index,
    );
  }

  late final _SDL_JoystickSetPlayerIndexPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<SDL_Joystick1>,
              ffi.Int32)>>('SDL_JoystickSetPlayerIndex');
  late final _SDL_JoystickSetPlayerIndex = _SDL_JoystickSetPlayerIndexPtr
      .asFunction<void Function(ffi.Pointer<SDL_Joystick1>, int)>();

  /// Get the implementation-dependent GUID for the joystick.
  ///
  /// This function requires an open joystick.
  ///
  /// \param joystick the SDL_Joystick obtained from SDL_JoystickOpen()
  /// \returns the GUID of the given joystick. If called on an invalid index,
  /// this function returns a zero GUID; call SDL_GetError() for more
  /// information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_JoystickGetDeviceGUID
  /// \sa SDL_JoystickGetGUIDString
  SDL_JoystickGUID SDL_JoystickGetGUID(
    ffi.Pointer<SDL_Joystick1> joystick,
  ) {
    return _SDL_JoystickGetGUID(
      joystick,
    );
  }

  late final _SDL_JoystickGetGUIDPtr = _lookup<
      ffi.NativeFunction<
          SDL_JoystickGUID Function(
              ffi.Pointer<SDL_Joystick1>)>>('SDL_JoystickGetGUID');
  late final _SDL_JoystickGetGUID = _SDL_JoystickGetGUIDPtr.asFunction<
      SDL_JoystickGUID Function(ffi.Pointer<SDL_Joystick1>)>();

  /// Get the USB vendor ID of an opened joystick, if available.
  ///
  /// If the vendor ID isn't available this function returns 0.
  ///
  /// \param joystick the SDL_Joystick obtained from SDL_JoystickOpen()
  /// \returns the USB vendor ID of the selected joystick, or 0 if unavailable.
  ///
  /// \since This function is available since SDL 2.0.6.
  int SDL_JoystickGetVendor(
    ffi.Pointer<SDL_Joystick1> joystick,
  ) {
    return _SDL_JoystickGetVendor(
      joystick,
    );
  }

  late final _SDL_JoystickGetVendorPtr =
      _lookup<ffi.NativeFunction<Uint16 Function(ffi.Pointer<SDL_Joystick1>)>>(
          'SDL_JoystickGetVendor');
  late final _SDL_JoystickGetVendor = _SDL_JoystickGetVendorPtr.asFunction<
      int Function(ffi.Pointer<SDL_Joystick1>)>();

  /// Get the USB product ID of an opened joystick, if available.
  ///
  /// If the product ID isn't available this function returns 0.
  ///
  /// \param joystick the SDL_Joystick obtained from SDL_JoystickOpen()
  /// \returns the USB product ID of the selected joystick, or 0 if unavailable.
  ///
  /// \since This function is available since SDL 2.0.6.
  int SDL_JoystickGetProduct(
    ffi.Pointer<SDL_Joystick1> joystick,
  ) {
    return _SDL_JoystickGetProduct(
      joystick,
    );
  }

  late final _SDL_JoystickGetProductPtr =
      _lookup<ffi.NativeFunction<Uint16 Function(ffi.Pointer<SDL_Joystick1>)>>(
          'SDL_JoystickGetProduct');
  late final _SDL_JoystickGetProduct = _SDL_JoystickGetProductPtr.asFunction<
      int Function(ffi.Pointer<SDL_Joystick1>)>();

  /// Get the product version of an opened joystick, if available.
  ///
  /// If the product version isn't available this function returns 0.
  ///
  /// \param joystick the SDL_Joystick obtained from SDL_JoystickOpen()
  /// \returns the product version of the selected joystick, or 0 if unavailable.
  ///
  /// \since This function is available since SDL 2.0.6.
  int SDL_JoystickGetProductVersion(
    ffi.Pointer<SDL_Joystick1> joystick,
  ) {
    return _SDL_JoystickGetProductVersion(
      joystick,
    );
  }

  late final _SDL_JoystickGetProductVersionPtr =
      _lookup<ffi.NativeFunction<Uint16 Function(ffi.Pointer<SDL_Joystick1>)>>(
          'SDL_JoystickGetProductVersion');
  late final _SDL_JoystickGetProductVersion = _SDL_JoystickGetProductVersionPtr
      .asFunction<int Function(ffi.Pointer<SDL_Joystick1>)>();

  /// Get the serial number of an opened joystick, if available.
  ///
  /// Returns the serial number of the joystick, or NULL if it is not available.
  ///
  /// \param joystick the SDL_Joystick obtained from SDL_JoystickOpen()
  /// \returns the serial number of the selected joystick, or NULL if
  /// unavailable.
  ///
  /// \since This function is available since SDL 2.0.14.
  ffi.Pointer<ffi.Int8> SDL_JoystickGetSerial(
    ffi.Pointer<SDL_Joystick1> joystick,
  ) {
    return _SDL_JoystickGetSerial(
      joystick,
    );
  }

  late final _SDL_JoystickGetSerialPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Int8> Function(
              ffi.Pointer<SDL_Joystick1>)>>('SDL_JoystickGetSerial');
  late final _SDL_JoystickGetSerial = _SDL_JoystickGetSerialPtr.asFunction<
      ffi.Pointer<ffi.Int8> Function(ffi.Pointer<SDL_Joystick1>)>();

  /// Get the type of an opened joystick.
  ///
  /// \param joystick the SDL_Joystick obtained from SDL_JoystickOpen()
  /// \returns the SDL_JoystickType of the selected joystick.
  ///
  /// \since This function is available since SDL 2.0.6.
  int SDL_JoystickGetType(
    ffi.Pointer<SDL_Joystick1> joystick,
  ) {
    return _SDL_JoystickGetType(
      joystick,
    );
  }

  late final _SDL_JoystickGetTypePtr = _lookup<
          ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<SDL_Joystick1>)>>(
      'SDL_JoystickGetType');
  late final _SDL_JoystickGetType = _SDL_JoystickGetTypePtr.asFunction<
      int Function(ffi.Pointer<SDL_Joystick1>)>();

  /// Get an ASCII string representation for a given SDL_JoystickGUID.
  ///
  /// You should supply at least 33 bytes for pszGUID.
  ///
  /// \param guid the SDL_JoystickGUID you wish to convert to string
  /// \param pszGUID buffer in which to write the ASCII string
  /// \param cbGUID the size of pszGUID
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_JoystickGetDeviceGUID
  /// \sa SDL_JoystickGetGUID
  /// \sa SDL_JoystickGetGUIDFromString
  void SDL_JoystickGetGUIDString(
    SDL_JoystickGUID guid,
    ffi.Pointer<ffi.Int8> pszGUID,
    int cbGUID,
  ) {
    return _SDL_JoystickGetGUIDString(
      guid,
      pszGUID,
      cbGUID,
    );
  }

  late final _SDL_JoystickGetGUIDStringPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(SDL_JoystickGUID, ffi.Pointer<ffi.Int8>,
              ffi.Int32)>>('SDL_JoystickGetGUIDString');
  late final _SDL_JoystickGetGUIDString =
      _SDL_JoystickGetGUIDStringPtr.asFunction<
          void Function(SDL_JoystickGUID, ffi.Pointer<ffi.Int8>, int)>();

  /// Convert a GUID string into a SDL_JoystickGUID structure.
  ///
  /// Performs no error checking. If this function is given a string containing
  /// an invalid GUID, the function will silently succeed, but the GUID generated
  /// will not be useful.
  ///
  /// \param pchGUID string containing an ASCII representation of a GUID
  /// \returns a SDL_JoystickGUID structure.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_JoystickGetGUIDString
  SDL_JoystickGUID SDL_JoystickGetGUIDFromString(
    ffi.Pointer<ffi.Int8> pchGUID,
  ) {
    return _SDL_JoystickGetGUIDFromString(
      pchGUID,
    );
  }

  late final _SDL_JoystickGetGUIDFromStringPtr = _lookup<
          ffi.NativeFunction<SDL_JoystickGUID Function(ffi.Pointer<ffi.Int8>)>>(
      'SDL_JoystickGetGUIDFromString');
  late final _SDL_JoystickGetGUIDFromString = _SDL_JoystickGetGUIDFromStringPtr
      .asFunction<SDL_JoystickGUID Function(ffi.Pointer<ffi.Int8>)>();

  /// Get the status of a specified joystick.
  ///
  /// \param joystick the joystick to query
  /// \returns SDL_TRUE if the joystick has been opened, SDL_FALSE if it has not;
  /// call SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_JoystickClose
  /// \sa SDL_JoystickOpen
  int SDL_JoystickGetAttached(
    ffi.Pointer<SDL_Joystick1> joystick,
  ) {
    return _SDL_JoystickGetAttached(
      joystick,
    );
  }

  late final _SDL_JoystickGetAttachedPtr = _lookup<
          ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<SDL_Joystick1>)>>(
      'SDL_JoystickGetAttached');
  late final _SDL_JoystickGetAttached = _SDL_JoystickGetAttachedPtr.asFunction<
      int Function(ffi.Pointer<SDL_Joystick1>)>();

  /// Get the instance ID of an opened joystick.
  ///
  /// \param joystick an SDL_Joystick structure containing joystick information
  /// \returns the instance ID of the specified joystick on success or a negative
  /// error code on failure; call SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_JoystickOpen
  int SDL_JoystickInstanceID(
    ffi.Pointer<SDL_Joystick1> joystick,
  ) {
    return _SDL_JoystickInstanceID(
      joystick,
    );
  }

  late final _SDL_JoystickInstanceIDPtr = _lookup<
      ffi.NativeFunction<
          SDL_JoystickID Function(
              ffi.Pointer<SDL_Joystick1>)>>('SDL_JoystickInstanceID');
  late final _SDL_JoystickInstanceID = _SDL_JoystickInstanceIDPtr.asFunction<
      int Function(ffi.Pointer<SDL_Joystick1>)>();

  /// Get the number of general axis controls on a joystick.
  ///
  /// Often, the directional pad on a game controller will either look like 4
  /// separate buttons or a POV hat, and not axes, but all of this is up to the
  /// device and platform.
  ///
  /// \param joystick an SDL_Joystick structure containing joystick information
  /// \returns the number of axis controls/number of axes on success or a
  /// negative error code on failure; call SDL_GetError() for more
  /// information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_JoystickGetAxis
  /// \sa SDL_JoystickOpen
  int SDL_JoystickNumAxes(
    ffi.Pointer<SDL_Joystick1> joystick,
  ) {
    return _SDL_JoystickNumAxes(
      joystick,
    );
  }

  late final _SDL_JoystickNumAxesPtr = _lookup<
          ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<SDL_Joystick1>)>>(
      'SDL_JoystickNumAxes');
  late final _SDL_JoystickNumAxes = _SDL_JoystickNumAxesPtr.asFunction<
      int Function(ffi.Pointer<SDL_Joystick1>)>();

  /// Get the number of trackballs on a joystick.
  ///
  /// Joystick trackballs have only relative motion events associated with them
  /// and their state cannot be polled.
  ///
  /// Most joysticks do not have trackballs.
  ///
  /// \param joystick an SDL_Joystick structure containing joystick information
  /// \returns the number of trackballs on success or a negative error code on
  /// failure; call SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_JoystickGetBall
  int SDL_JoystickNumBalls(
    ffi.Pointer<SDL_Joystick1> joystick,
  ) {
    return _SDL_JoystickNumBalls(
      joystick,
    );
  }

  late final _SDL_JoystickNumBallsPtr = _lookup<
          ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<SDL_Joystick1>)>>(
      'SDL_JoystickNumBalls');
  late final _SDL_JoystickNumBalls = _SDL_JoystickNumBallsPtr.asFunction<
      int Function(ffi.Pointer<SDL_Joystick1>)>();

  /// Get the number of POV hats on a joystick.
  ///
  /// \param joystick an SDL_Joystick structure containing joystick information
  /// \returns the number of POV hats on success or a negative error code on
  /// failure; call SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_JoystickGetHat
  /// \sa SDL_JoystickOpen
  int SDL_JoystickNumHats(
    ffi.Pointer<SDL_Joystick1> joystick,
  ) {
    return _SDL_JoystickNumHats(
      joystick,
    );
  }

  late final _SDL_JoystickNumHatsPtr = _lookup<
          ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<SDL_Joystick1>)>>(
      'SDL_JoystickNumHats');
  late final _SDL_JoystickNumHats = _SDL_JoystickNumHatsPtr.asFunction<
      int Function(ffi.Pointer<SDL_Joystick1>)>();

  /// Get the number of buttons on a joystick.
  ///
  /// \param joystick an SDL_Joystick structure containing joystick information
  /// \returns the number of buttons on success or a negative error code on
  /// failure; call SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_JoystickGetButton
  /// \sa SDL_JoystickOpen
  int SDL_JoystickNumButtons(
    ffi.Pointer<SDL_Joystick1> joystick,
  ) {
    return _SDL_JoystickNumButtons(
      joystick,
    );
  }

  late final _SDL_JoystickNumButtonsPtr = _lookup<
          ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<SDL_Joystick1>)>>(
      'SDL_JoystickNumButtons');
  late final _SDL_JoystickNumButtons = _SDL_JoystickNumButtonsPtr.asFunction<
      int Function(ffi.Pointer<SDL_Joystick1>)>();

  /// Update the current state of the open joysticks.
  ///
  /// This is called automatically by the event loop if any joystick events are
  /// enabled.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_JoystickEventState
  void SDL_JoystickUpdate() {
    return _SDL_JoystickUpdate();
  }

  late final _SDL_JoystickUpdatePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('SDL_JoystickUpdate');
  late final _SDL_JoystickUpdate =
      _SDL_JoystickUpdatePtr.asFunction<void Function()>();

  /// Enable/disable joystick event polling.
  ///
  /// If joystick events are disabled, you must call SDL_JoystickUpdate()
  /// yourself and manually check the state of the joystick when you want
  /// joystick information.
  ///
  /// It is recommended that you leave joystick event handling enabled.
  ///
  /// **WARNING**: Calling this function may delete all events currently in SDL's
  /// event queue.
  ///
  /// \param state can be one of `SDL_QUERY`, `SDL_IGNORE`, or `SDL_ENABLE`
  /// \returns 1 if enabled, 0 if disabled, or a negative error code on failure;
  /// call SDL_GetError() for more information.
  ///
  /// If `state` is `SDL_QUERY` then the current state is returned,
  /// otherwise the new processing state is returned.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GameControllerEventState
  int SDL_JoystickEventState(
    int state,
  ) {
    return _SDL_JoystickEventState(
      state,
    );
  }

  late final _SDL_JoystickEventStatePtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Int32)>>(
          'SDL_JoystickEventState');
  late final _SDL_JoystickEventState =
      _SDL_JoystickEventStatePtr.asFunction<int Function(int)>();

  /// Get the current state of an axis control on a joystick.
  ///
  /// SDL makes no promises about what part of the joystick any given axis refers
  /// to. Your game should have some sort of configuration UI to let users
  /// specify what each axis should be bound to. Alternately, SDL's higher-level
  /// Game Controller API makes a great effort to apply order to this lower-level
  /// interface, so you know that a specific axis is the "left thumb stick," etc.
  ///
  /// The value returned by SDL_JoystickGetAxis() is a signed integer (-32768 to
  /// 32767) representing the current position of the axis. It may be necessary
  /// to impose certain tolerances on these values to account for jitter.
  ///
  /// \param joystick an SDL_Joystick structure containing joystick information
  /// \param axis the axis to query; the axis indices start at index 0
  /// \returns a 16-bit signed integer representing the current position of the
  /// axis or 0 on failure; call SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_JoystickNumAxes
  int SDL_JoystickGetAxis(
    ffi.Pointer<SDL_Joystick1> joystick,
    int axis,
  ) {
    return _SDL_JoystickGetAxis(
      joystick,
      axis,
    );
  }

  late final _SDL_JoystickGetAxisPtr = _lookup<
      ffi.NativeFunction<
          Sint16 Function(
              ffi.Pointer<SDL_Joystick1>, ffi.Int32)>>('SDL_JoystickGetAxis');
  late final _SDL_JoystickGetAxis = _SDL_JoystickGetAxisPtr.asFunction<
      int Function(ffi.Pointer<SDL_Joystick1>, int)>();

  /// Get the initial state of an axis control on a joystick.
  ///
  /// The state is a value ranging from -32768 to 32767.
  ///
  /// The axis indices start at index 0.
  ///
  /// \param joystick an SDL_Joystick structure containing joystick information
  /// \param axis the axis to query; the axis indices start at index 0
  /// \param state Upon return, the initial value is supplied here.
  /// \return SDL_TRUE if this axis has any initial value, or SDL_FALSE if not.
  ///
  /// \since This function is available since SDL 2.0.6.
  int SDL_JoystickGetAxisInitialState(
    ffi.Pointer<SDL_Joystick1> joystick,
    int axis,
    ffi.Pointer<Sint16> state,
  ) {
    return _SDL_JoystickGetAxisInitialState(
      joystick,
      axis,
      state,
    );
  }

  late final _SDL_JoystickGetAxisInitialStatePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_Joystick1>, ffi.Int32,
              ffi.Pointer<Sint16>)>>('SDL_JoystickGetAxisInitialState');
  late final _SDL_JoystickGetAxisInitialState =
      _SDL_JoystickGetAxisInitialStatePtr.asFunction<
          int Function(ffi.Pointer<SDL_Joystick1>, int, ffi.Pointer<Sint16>)>();

  /// Get the current state of a POV hat on a joystick.
  ///
  /// The returned value will be one of the following positions:
  ///
  /// - `SDL_HAT_CENTERED`
  /// - `SDL_HAT_UP`
  /// - `SDL_HAT_RIGHT`
  /// - `SDL_HAT_DOWN`
  /// - `SDL_HAT_LEFT`
  /// - `SDL_HAT_RIGHTUP`
  /// - `SDL_HAT_RIGHTDOWN`
  /// - `SDL_HAT_LEFTUP`
  /// - `SDL_HAT_LEFTDOWN`
  ///
  /// \param joystick an SDL_Joystick structure containing joystick information
  /// \param hat the hat index to get the state from; indices start at index 0
  /// \returns the current hat position.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_JoystickNumHats
  int SDL_JoystickGetHat(
    ffi.Pointer<SDL_Joystick1> joystick,
    int hat,
  ) {
    return _SDL_JoystickGetHat(
      joystick,
      hat,
    );
  }

  late final _SDL_JoystickGetHatPtr = _lookup<
      ffi.NativeFunction<
          Uint8 Function(
              ffi.Pointer<SDL_Joystick1>, ffi.Int32)>>('SDL_JoystickGetHat');
  late final _SDL_JoystickGetHat = _SDL_JoystickGetHatPtr.asFunction<
      int Function(ffi.Pointer<SDL_Joystick1>, int)>();

  /// Get the ball axis change since the last poll.
  ///
  /// Trackballs can only return relative motion since the last call to
  /// SDL_JoystickGetBall(), these motion deltas are placed into `dx` and `dy`.
  ///
  /// Most joysticks do not have trackballs.
  ///
  /// \param joystick the SDL_Joystick to query
  /// \param ball the ball index to query; ball indices start at index 0
  /// \param dx stores the difference in the x axis position since the last poll
  /// \param dy stores the difference in the y axis position since the last poll
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_JoystickNumBalls
  int SDL_JoystickGetBall(
    ffi.Pointer<SDL_Joystick1> joystick,
    int ball,
    ffi.Pointer<ffi.Int32> dx,
    ffi.Pointer<ffi.Int32> dy,
  ) {
    return _SDL_JoystickGetBall(
      joystick,
      ball,
      dx,
      dy,
    );
  }

  late final _SDL_JoystickGetBallPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<SDL_Joystick1>,
              ffi.Int32,
              ffi.Pointer<ffi.Int32>,
              ffi.Pointer<ffi.Int32>)>>('SDL_JoystickGetBall');
  late final _SDL_JoystickGetBall = _SDL_JoystickGetBallPtr.asFunction<
      int Function(ffi.Pointer<SDL_Joystick1>, int, ffi.Pointer<ffi.Int32>,
          ffi.Pointer<ffi.Int32>)>();

  /// Get the current state of a button on a joystick.
  ///
  /// \param joystick an SDL_Joystick structure containing joystick information
  /// \param button the button index to get the state from; indices start at
  /// index 0
  /// \returns 1 if the specified button is pressed, 0 otherwise.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_JoystickNumButtons
  int SDL_JoystickGetButton(
    ffi.Pointer<SDL_Joystick1> joystick,
    int button,
  ) {
    return _SDL_JoystickGetButton(
      joystick,
      button,
    );
  }

  late final _SDL_JoystickGetButtonPtr = _lookup<
      ffi.NativeFunction<
          Uint8 Function(
              ffi.Pointer<SDL_Joystick1>, ffi.Int32)>>('SDL_JoystickGetButton');
  late final _SDL_JoystickGetButton = _SDL_JoystickGetButtonPtr.asFunction<
      int Function(ffi.Pointer<SDL_Joystick1>, int)>();

  /// Start a rumble effect.
  ///
  /// Each call to this function cancels any previous rumble effect, and calling
  /// it with 0 intensity stops any rumbling.
  ///
  /// \param joystick The joystick to vibrate
  /// \param low_frequency_rumble The intensity of the low frequency (left)
  /// rumble motor, from 0 to 0xFFFF
  /// \param high_frequency_rumble The intensity of the high frequency (right)
  /// rumble motor, from 0 to 0xFFFF
  /// \param duration_ms The duration of the rumble effect, in milliseconds
  /// \returns 0, or -1 if rumble isn't supported on this joystick
  ///
  /// \since This function is available since SDL 2.0.9.
  ///
  /// \sa SDL_JoystickHasRumble
  int SDL_JoystickRumble(
    ffi.Pointer<SDL_Joystick1> joystick,
    int low_frequency_rumble,
    int high_frequency_rumble,
    int duration_ms,
  ) {
    return _SDL_JoystickRumble(
      joystick,
      low_frequency_rumble,
      high_frequency_rumble,
      duration_ms,
    );
  }

  late final _SDL_JoystickRumblePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_Joystick1>, Uint16, Uint16,
              Uint32)>>('SDL_JoystickRumble');
  late final _SDL_JoystickRumble = _SDL_JoystickRumblePtr.asFunction<
      int Function(ffi.Pointer<SDL_Joystick1>, int, int, int)>();

  /// Start a rumble effect in the joystick's triggers
  ///
  /// Each call to this function cancels any previous trigger rumble effect, and
  /// calling it with 0 intensity stops any rumbling.
  ///
  /// Note that this function is for _trigger_ rumble; the first joystick to
  /// support this was the PlayStation 5's DualShock 5 controller. If you want
  /// the (more common) whole-controller rumble, use SDL_JoystickRumble()
  /// instead.
  ///
  /// \param joystick The joystick to vibrate
  /// \param left_rumble The intensity of the left trigger rumble motor, from 0
  /// to 0xFFFF
  /// \param right_rumble The intensity of the right trigger rumble motor, from 0
  /// to 0xFFFF
  /// \param duration_ms The duration of the rumble effect, in milliseconds
  /// \returns 0, or -1 if trigger rumble isn't supported on this joystick
  ///
  /// \since This function is available since SDL 2.0.14.
  ///
  /// \sa SDL_JoystickHasRumbleTriggers
  int SDL_JoystickRumbleTriggers(
    ffi.Pointer<SDL_Joystick1> joystick,
    int left_rumble,
    int right_rumble,
    int duration_ms,
  ) {
    return _SDL_JoystickRumbleTriggers(
      joystick,
      left_rumble,
      right_rumble,
      duration_ms,
    );
  }

  late final _SDL_JoystickRumbleTriggersPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_Joystick1>, Uint16, Uint16,
              Uint32)>>('SDL_JoystickRumbleTriggers');
  late final _SDL_JoystickRumbleTriggers = _SDL_JoystickRumbleTriggersPtr
      .asFunction<int Function(ffi.Pointer<SDL_Joystick1>, int, int, int)>();

  /// Query whether a joystick has an LED.
  ///
  /// An example of a joystick LED is the light on the back of a PlayStation 4's
  /// DualShock 4 controller.
  ///
  /// \param joystick The joystick to query
  /// \return SDL_TRUE if the joystick has a modifiable LED, SDL_FALSE otherwise.
  ///
  /// \since This function is available since SDL 2.0.14.
  int SDL_JoystickHasLED(
    ffi.Pointer<SDL_Joystick1> joystick,
  ) {
    return _SDL_JoystickHasLED(
      joystick,
    );
  }

  late final _SDL_JoystickHasLEDPtr = _lookup<
          ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<SDL_Joystick1>)>>(
      'SDL_JoystickHasLED');
  late final _SDL_JoystickHasLED = _SDL_JoystickHasLEDPtr.asFunction<
      int Function(ffi.Pointer<SDL_Joystick1>)>();

  /// Query whether a joystick has rumble support.
  ///
  /// \param joystick The joystick to query
  /// \return SDL_TRUE if the joystick has rumble, SDL_FALSE otherwise.
  ///
  /// \since This function is available since SDL 2.0.18.
  ///
  /// \sa SDL_JoystickRumble
  int SDL_JoystickHasRumble(
    ffi.Pointer<SDL_Joystick1> joystick,
  ) {
    return _SDL_JoystickHasRumble(
      joystick,
    );
  }

  late final _SDL_JoystickHasRumblePtr = _lookup<
          ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<SDL_Joystick1>)>>(
      'SDL_JoystickHasRumble');
  late final _SDL_JoystickHasRumble = _SDL_JoystickHasRumblePtr.asFunction<
      int Function(ffi.Pointer<SDL_Joystick1>)>();

  /// Query whether a joystick has rumble support on triggers.
  ///
  /// \param joystick The joystick to query
  /// \return SDL_TRUE if the joystick has trigger rumble, SDL_FALSE otherwise.
  ///
  /// \since This function is available since SDL 2.0.18.
  ///
  /// \sa SDL_JoystickRumbleTriggers
  int SDL_JoystickHasRumbleTriggers(
    ffi.Pointer<SDL_Joystick1> joystick,
  ) {
    return _SDL_JoystickHasRumbleTriggers(
      joystick,
    );
  }

  late final _SDL_JoystickHasRumbleTriggersPtr = _lookup<
          ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<SDL_Joystick1>)>>(
      'SDL_JoystickHasRumbleTriggers');
  late final _SDL_JoystickHasRumbleTriggers = _SDL_JoystickHasRumbleTriggersPtr
      .asFunction<int Function(ffi.Pointer<SDL_Joystick1>)>();

  /// Update a joystick's LED color.
  ///
  /// An example of a joystick LED is the light on the back of a PlayStation 4's
  /// DualShock 4 controller.
  ///
  /// \param joystick The joystick to update
  /// \param red The intensity of the red LED
  /// \param green The intensity of the green LED
  /// \param blue The intensity of the blue LED
  /// \returns 0 on success, -1 if this joystick does not have a modifiable LED
  ///
  /// \since This function is available since SDL 2.0.14.
  int SDL_JoystickSetLED(
    ffi.Pointer<SDL_Joystick1> joystick,
    int red,
    int green,
    int blue,
  ) {
    return _SDL_JoystickSetLED(
      joystick,
      red,
      green,
      blue,
    );
  }

  late final _SDL_JoystickSetLEDPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_Joystick1>, Uint8, Uint8,
              Uint8)>>('SDL_JoystickSetLED');
  late final _SDL_JoystickSetLED = _SDL_JoystickSetLEDPtr.asFunction<
      int Function(ffi.Pointer<SDL_Joystick1>, int, int, int)>();

  /// Send a joystick specific effect packet
  ///
  /// \param joystick The joystick to affect
  /// \param data The data to send to the joystick
  /// \param size The size of the data to send to the joystick
  /// \returns 0, or -1 if this joystick or driver doesn't support effect packets
  ///
  /// \since This function is available since SDL 2.0.16.
  int SDL_JoystickSendEffect(
    ffi.Pointer<SDL_Joystick1> joystick,
    ffi.Pointer<ffi.Void> data,
    int size,
  ) {
    return _SDL_JoystickSendEffect(
      joystick,
      data,
      size,
    );
  }

  late final _SDL_JoystickSendEffectPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_Joystick1>, ffi.Pointer<ffi.Void>,
              ffi.Int32)>>('SDL_JoystickSendEffect');
  late final _SDL_JoystickSendEffect = _SDL_JoystickSendEffectPtr.asFunction<
      int Function(ffi.Pointer<SDL_Joystick1>, ffi.Pointer<ffi.Void>, int)>();

  /// Close a joystick previously opened with SDL_JoystickOpen().
  ///
  /// \param joystick The joystick device to close
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_JoystickOpen
  void SDL_JoystickClose(
    ffi.Pointer<SDL_Joystick1> joystick,
  ) {
    return _SDL_JoystickClose(
      joystick,
    );
  }

  late final _SDL_JoystickClosePtr = _lookup<
          ffi.NativeFunction<ffi.Void Function(ffi.Pointer<SDL_Joystick1>)>>(
      'SDL_JoystickClose');
  late final _SDL_JoystickClose = _SDL_JoystickClosePtr.asFunction<
      void Function(ffi.Pointer<SDL_Joystick1>)>();

  /// Get the battery level of a joystick as SDL_JoystickPowerLevel.
  ///
  /// \param joystick the SDL_Joystick to query
  /// \returns the current battery level as SDL_JoystickPowerLevel on success or
  /// `SDL_JOYSTICK_POWER_UNKNOWN` if it is unknown
  ///
  /// \since This function is available since SDL 2.0.4.
  int SDL_JoystickCurrentPowerLevel(
    ffi.Pointer<SDL_Joystick1> joystick,
  ) {
    return _SDL_JoystickCurrentPowerLevel(
      joystick,
    );
  }

  late final _SDL_JoystickCurrentPowerLevelPtr = _lookup<
          ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<SDL_Joystick1>)>>(
      'SDL_JoystickCurrentPowerLevel');
  late final _SDL_JoystickCurrentPowerLevel = _SDL_JoystickCurrentPowerLevelPtr
      .asFunction<int Function(ffi.Pointer<SDL_Joystick1>)>();

  /// Locking for multi-threaded access to the sensor API
  ///
  /// If you are using the sensor API or handling events from multiple threads
  /// you should use these locking functions to protect access to the sensors.
  ///
  /// In particular, you are guaranteed that the sensor list won't change, so the
  /// API functions that take a sensor index will be valid, and sensor events
  /// will not be delivered.
  ///
  /// \since This function is available since SDL 2.0.14.
  void SDL_LockSensors() {
    return _SDL_LockSensors();
  }

  late final _SDL_LockSensorsPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('SDL_LockSensors');
  late final _SDL_LockSensors =
      _SDL_LockSensorsPtr.asFunction<void Function()>();

  void SDL_UnlockSensors() {
    return _SDL_UnlockSensors();
  }

  late final _SDL_UnlockSensorsPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('SDL_UnlockSensors');
  late final _SDL_UnlockSensors =
      _SDL_UnlockSensorsPtr.asFunction<void Function()>();

  /// Count the number of sensors attached to the system right now.
  ///
  /// \returns the number of sensors detected.
  ///
  /// \since This function is available since SDL 2.0.9.
  int SDL_NumSensors() {
    return _SDL_NumSensors();
  }

  late final _SDL_NumSensorsPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function()>>('SDL_NumSensors');
  late final _SDL_NumSensors = _SDL_NumSensorsPtr.asFunction<int Function()>();

  /// Get the implementation dependent name of a sensor.
  ///
  /// \param device_index The sensor to obtain name from
  /// \returns the sensor name, or NULL if `device_index` is out of range.
  ///
  /// \since This function is available since SDL 2.0.9.
  ffi.Pointer<ffi.Int8> SDL_SensorGetDeviceName(
    int device_index,
  ) {
    return _SDL_SensorGetDeviceName(
      device_index,
    );
  }

  late final _SDL_SensorGetDeviceNamePtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Int8> Function(ffi.Int32)>>(
          'SDL_SensorGetDeviceName');
  late final _SDL_SensorGetDeviceName = _SDL_SensorGetDeviceNamePtr.asFunction<
      ffi.Pointer<ffi.Int8> Function(int)>();

  /// Get the type of a sensor.
  ///
  /// \param device_index The sensor to get the type from
  /// \returns the SDL_SensorType, or `SDL_SENSOR_INVALID` if `device_index` is
  /// out of range.
  ///
  /// \since This function is available since SDL 2.0.9.
  int SDL_SensorGetDeviceType(
    int device_index,
  ) {
    return _SDL_SensorGetDeviceType(
      device_index,
    );
  }

  late final _SDL_SensorGetDeviceTypePtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Int32)>>(
          'SDL_SensorGetDeviceType');
  late final _SDL_SensorGetDeviceType =
      _SDL_SensorGetDeviceTypePtr.asFunction<int Function(int)>();

  /// Get the platform dependent type of a sensor.
  ///
  /// \param device_index The sensor to check
  /// \returns the sensor platform dependent type, or -1 if `device_index` is out
  /// of range.
  ///
  /// \since This function is available since SDL 2.0.9.
  int SDL_SensorGetDeviceNonPortableType(
    int device_index,
  ) {
    return _SDL_SensorGetDeviceNonPortableType(
      device_index,
    );
  }

  late final _SDL_SensorGetDeviceNonPortableTypePtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Int32)>>(
          'SDL_SensorGetDeviceNonPortableType');
  late final _SDL_SensorGetDeviceNonPortableType =
      _SDL_SensorGetDeviceNonPortableTypePtr.asFunction<int Function(int)>();

  /// Get the instance ID of a sensor.
  ///
  /// \param device_index The sensor to get instance id from
  /// \returns the sensor instance ID, or -1 if `device_index` is out of range.
  ///
  /// \since This function is available since SDL 2.0.9.
  int SDL_SensorGetDeviceInstanceID(
    int device_index,
  ) {
    return _SDL_SensorGetDeviceInstanceID(
      device_index,
    );
  }

  late final _SDL_SensorGetDeviceInstanceIDPtr =
      _lookup<ffi.NativeFunction<SDL_SensorID Function(ffi.Int32)>>(
          'SDL_SensorGetDeviceInstanceID');
  late final _SDL_SensorGetDeviceInstanceID =
      _SDL_SensorGetDeviceInstanceIDPtr.asFunction<int Function(int)>();

  /// Open a sensor for use.
  ///
  /// \param device_index The sensor to open
  /// \returns an SDL_Sensor sensor object, or NULL if an error occurred.
  ///
  /// \since This function is available since SDL 2.0.9.
  ffi.Pointer<SDL_Sensor1> SDL_SensorOpen(
    int device_index,
  ) {
    return _SDL_SensorOpen(
      device_index,
    );
  }

  late final _SDL_SensorOpenPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<SDL_Sensor1> Function(ffi.Int32)>>(
          'SDL_SensorOpen');
  late final _SDL_SensorOpen =
      _SDL_SensorOpenPtr.asFunction<ffi.Pointer<SDL_Sensor1> Function(int)>();

  /// Return the SDL_Sensor associated with an instance id.
  ///
  /// \param instance_id The sensor from instance id
  /// \returns an SDL_Sensor object.
  ///
  /// \since This function is available since SDL 2.0.9.
  ffi.Pointer<SDL_Sensor1> SDL_SensorFromInstanceID(
    int instance_id,
  ) {
    return _SDL_SensorFromInstanceID(
      instance_id,
    );
  }

  late final _SDL_SensorFromInstanceIDPtr = _lookup<
          ffi.NativeFunction<ffi.Pointer<SDL_Sensor1> Function(SDL_SensorID)>>(
      'SDL_SensorFromInstanceID');
  late final _SDL_SensorFromInstanceID = _SDL_SensorFromInstanceIDPtr
      .asFunction<ffi.Pointer<SDL_Sensor1> Function(int)>();

  /// Get the implementation dependent name of a sensor
  ///
  /// \param sensor The SDL_Sensor object
  /// \returns the sensor name, or NULL if `sensor` is NULL.
  ///
  /// \since This function is available since SDL 2.0.9.
  ffi.Pointer<ffi.Int8> SDL_SensorGetName(
    ffi.Pointer<SDL_Sensor1> sensor,
  ) {
    return _SDL_SensorGetName(
      sensor,
    );
  }

  late final _SDL_SensorGetNamePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Int8> Function(
              ffi.Pointer<SDL_Sensor1>)>>('SDL_SensorGetName');
  late final _SDL_SensorGetName = _SDL_SensorGetNamePtr.asFunction<
      ffi.Pointer<ffi.Int8> Function(ffi.Pointer<SDL_Sensor1>)>();

  /// Get the type of a sensor.
  ///
  /// \param sensor The SDL_Sensor object to inspect
  /// \returns the SDL_SensorType type, or `SDL_SENSOR_INVALID` if `sensor` is
  /// NULL.
  ///
  /// \since This function is available since SDL 2.0.9.
  int SDL_SensorGetType(
    ffi.Pointer<SDL_Sensor1> sensor,
  ) {
    return _SDL_SensorGetType(
      sensor,
    );
  }

  late final _SDL_SensorGetTypePtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<SDL_Sensor1>)>>(
          'SDL_SensorGetType');
  late final _SDL_SensorGetType = _SDL_SensorGetTypePtr.asFunction<
      int Function(ffi.Pointer<SDL_Sensor1>)>();

  /// Get the platform dependent type of a sensor.
  ///
  /// \param sensor The SDL_Sensor object to inspect
  /// \returns the sensor platform dependent type, or -1 if `sensor` is NULL.
  ///
  /// \since This function is available since SDL 2.0.9.
  int SDL_SensorGetNonPortableType(
    ffi.Pointer<SDL_Sensor1> sensor,
  ) {
    return _SDL_SensorGetNonPortableType(
      sensor,
    );
  }

  late final _SDL_SensorGetNonPortableTypePtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<SDL_Sensor1>)>>(
          'SDL_SensorGetNonPortableType');
  late final _SDL_SensorGetNonPortableType = _SDL_SensorGetNonPortableTypePtr
      .asFunction<int Function(ffi.Pointer<SDL_Sensor1>)>();

  /// Get the instance ID of a sensor.
  ///
  /// \param sensor The SDL_Sensor object to inspect
  /// \returns the sensor instance ID, or -1 if `sensor` is NULL.
  ///
  /// \since This function is available since SDL 2.0.9.
  int SDL_SensorGetInstanceID(
    ffi.Pointer<SDL_Sensor1> sensor,
  ) {
    return _SDL_SensorGetInstanceID(
      sensor,
    );
  }

  late final _SDL_SensorGetInstanceIDPtr = _lookup<
          ffi.NativeFunction<SDL_SensorID Function(ffi.Pointer<SDL_Sensor1>)>>(
      'SDL_SensorGetInstanceID');
  late final _SDL_SensorGetInstanceID = _SDL_SensorGetInstanceIDPtr.asFunction<
      int Function(ffi.Pointer<SDL_Sensor1>)>();

  /// Get the current state of an opened sensor.
  ///
  /// The number of values and interpretation of the data is sensor dependent.
  ///
  /// \param sensor The SDL_Sensor object to query
  /// \param data A pointer filled with the current sensor state
  /// \param num_values The number of values to write to data
  /// \returns 0 or -1 if an error occurred.
  ///
  /// \since This function is available since SDL 2.0.9.
  int SDL_SensorGetData(
    ffi.Pointer<SDL_Sensor1> sensor,
    ffi.Pointer<ffi.Float> data,
    int num_values,
  ) {
    return _SDL_SensorGetData(
      sensor,
      data,
      num_values,
    );
  }

  late final _SDL_SensorGetDataPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_Sensor1>, ffi.Pointer<ffi.Float>,
              ffi.Int32)>>('SDL_SensorGetData');
  late final _SDL_SensorGetData = _SDL_SensorGetDataPtr.asFunction<
      int Function(ffi.Pointer<SDL_Sensor1>, ffi.Pointer<ffi.Float>, int)>();

  /// Close a sensor previously opened with SDL_SensorOpen().
  ///
  /// \param sensor The SDL_Sensor object to close
  ///
  /// \since This function is available since SDL 2.0.9.
  void SDL_SensorClose(
    ffi.Pointer<SDL_Sensor1> sensor,
  ) {
    return _SDL_SensorClose(
      sensor,
    );
  }

  late final _SDL_SensorClosePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<SDL_Sensor1>)>>(
          'SDL_SensorClose');
  late final _SDL_SensorClose =
      _SDL_SensorClosePtr.asFunction<void Function(ffi.Pointer<SDL_Sensor1>)>();

  /// Update the current state of the open sensors.
  ///
  /// This is called automatically by the event loop if sensor events are
  /// enabled.
  ///
  /// This needs to be called from the thread that initialized the sensor
  /// subsystem.
  ///
  /// \since This function is available since SDL 2.0.9.
  void SDL_SensorUpdate() {
    return _SDL_SensorUpdate();
  }

  late final _SDL_SensorUpdatePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('SDL_SensorUpdate');
  late final _SDL_SensorUpdate =
      _SDL_SensorUpdatePtr.asFunction<void Function()>();

  /// Load a set of Game Controller mappings from a seekable SDL data stream.
  ///
  /// You can call this function several times, if needed, to load different
  /// database files.
  ///
  /// If a new mapping is loaded for an already known controller GUID, the later
  /// version will overwrite the one currently loaded.
  ///
  /// Mappings not belonging to the current platform or with no platform field
  /// specified will be ignored (i.e. mappings for Linux will be ignored in
  /// Windows, etc).
  ///
  /// This function will load the text database entirely in memory before
  /// processing it, so take this into consideration if you are in a memory
  /// constrained environment.
  ///
  /// \param rw the data stream for the mappings to be added
  /// \param freerw non-zero to close the stream after being read
  /// \returns the number of mappings added or -1 on error; call SDL_GetError()
  /// for more information.
  ///
  /// \since This function is available since SDL 2.0.2.
  ///
  /// \sa SDL_GameControllerAddMapping
  /// \sa SDL_GameControllerAddMappingsFromFile
  /// \sa SDL_GameControllerMappingForGUID
  int SDL_GameControllerAddMappingsFromRW(
    ffi.Pointer<SDL_RWops> rw,
    int freerw,
  ) {
    return _SDL_GameControllerAddMappingsFromRW(
      rw,
      freerw,
    );
  }

  late final _SDL_GameControllerAddMappingsFromRWPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_RWops>,
              ffi.Int32)>>('SDL_GameControllerAddMappingsFromRW');
  late final _SDL_GameControllerAddMappingsFromRW =
      _SDL_GameControllerAddMappingsFromRWPtr.asFunction<
          int Function(ffi.Pointer<SDL_RWops>, int)>();

  /// Add support for controllers that SDL is unaware of or to cause an existing
  /// controller to have a different binding.
  ///
  /// The mapping string has the format "GUID,name,mapping", where GUID is the
  /// string value from SDL_JoystickGetGUIDString(), name is the human readable
  /// string for the device and mappings are controller mappings to joystick
  /// ones. Under Windows there is a reserved GUID of "xinput" that covers all
  /// XInput devices. The mapping format for joystick is: {| |bX |a joystick
  /// button, index X |- |hX.Y |hat X with value Y |- |aX |axis X of the joystick
  /// |} Buttons can be used as a controller axes and vice versa.
  ///
  /// This string shows an example of a valid mapping for a controller:
  ///
  /// ```c
  /// "341a3608000000000000504944564944,Afterglow PS3 Controller,a:b1,b:b2,y:b3,x:b0,start:b9,guide:b12,back:b8,dpup:h0.1,dpleft:h0.8,dpdown:h0.4,dpright:h0.2,leftshoulder:b4,rightshoulder:b5,leftstick:b10,rightstick:b11,leftx:a0,lefty:a1,rightx:a2,righty:a3,lefttrigger:b6,righttrigger:b7"
  /// ```
  ///
  /// \param mappingString the mapping string
  /// \returns 1 if a new mapping is added, 0 if an existing mapping is updated,
  /// -1 on error; call SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GameControllerMapping
  /// \sa SDL_GameControllerMappingForGUID
  int SDL_GameControllerAddMapping(
    ffi.Pointer<ffi.Int8> mappingString,
  ) {
    return _SDL_GameControllerAddMapping(
      mappingString,
    );
  }

  late final _SDL_GameControllerAddMappingPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<ffi.Int8>)>>(
          'SDL_GameControllerAddMapping');
  late final _SDL_GameControllerAddMapping = _SDL_GameControllerAddMappingPtr
      .asFunction<int Function(ffi.Pointer<ffi.Int8>)>();

  /// Get the number of mappings installed.
  ///
  /// \returns the number of mappings.
  ///
  /// \since This function is available since SDL 2.0.6.
  int SDL_GameControllerNumMappings() {
    return _SDL_GameControllerNumMappings();
  }

  late final _SDL_GameControllerNumMappingsPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function()>>(
          'SDL_GameControllerNumMappings');
  late final _SDL_GameControllerNumMappings =
      _SDL_GameControllerNumMappingsPtr.asFunction<int Function()>();

  /// Get the mapping at a particular index.
  ///
  /// \returns the mapping string. Must be freed with SDL_free(). Returns NULL if
  /// the index is out of range.
  ///
  /// \since This function is available since SDL 2.0.6.
  ffi.Pointer<ffi.Int8> SDL_GameControllerMappingForIndex(
    int mapping_index,
  ) {
    return _SDL_GameControllerMappingForIndex(
      mapping_index,
    );
  }

  late final _SDL_GameControllerMappingForIndexPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Int8> Function(ffi.Int32)>>(
          'SDL_GameControllerMappingForIndex');
  late final _SDL_GameControllerMappingForIndex =
      _SDL_GameControllerMappingForIndexPtr.asFunction<
          ffi.Pointer<ffi.Int8> Function(int)>();

  /// Get the game controller mapping string for a given GUID.
  ///
  /// The returned string must be freed with SDL_free().
  ///
  /// \param guid a structure containing the GUID for which a mapping is desired
  /// \returns a mapping string or NULL on error; call SDL_GetError() for more
  /// information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_JoystickGetDeviceGUID
  /// \sa SDL_JoystickGetGUID
  ffi.Pointer<ffi.Int8> SDL_GameControllerMappingForGUID(
    SDL_JoystickGUID guid,
  ) {
    return _SDL_GameControllerMappingForGUID(
      guid,
    );
  }

  late final _SDL_GameControllerMappingForGUIDPtr = _lookup<
          ffi.NativeFunction<ffi.Pointer<ffi.Int8> Function(SDL_JoystickGUID)>>(
      'SDL_GameControllerMappingForGUID');
  late final _SDL_GameControllerMappingForGUID =
      _SDL_GameControllerMappingForGUIDPtr.asFunction<
          ffi.Pointer<ffi.Int8> Function(SDL_JoystickGUID)>();

  /// Get the current mapping of a Game Controller.
  ///
  /// The returned string must be freed with SDL_free().
  ///
  /// Details about mappings are discussed with SDL_GameControllerAddMapping().
  ///
  /// \param gamecontroller the game controller you want to get the current
  /// mapping for
  /// \returns a string that has the controller's mapping or NULL if no mapping
  /// is available; call SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GameControllerAddMapping
  /// \sa SDL_GameControllerMappingForGUID
  ffi.Pointer<ffi.Int8> SDL_GameControllerMapping(
    ffi.Pointer<SDL_GameController1> gamecontroller,
  ) {
    return _SDL_GameControllerMapping(
      gamecontroller,
    );
  }

  late final _SDL_GameControllerMappingPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Int8> Function(
              ffi.Pointer<SDL_GameController1>)>>('SDL_GameControllerMapping');
  late final _SDL_GameControllerMapping =
      _SDL_GameControllerMappingPtr.asFunction<
          ffi.Pointer<ffi.Int8> Function(ffi.Pointer<SDL_GameController1>)>();

  /// Check if the given joystick is supported by the game controller interface.
  ///
  /// `joystick_index` is the same as the `device_index` passed to
  /// SDL_JoystickOpen().
  ///
  /// \param joystick_index the device_index of a device, up to
  /// SDL_NumJoysticks()
  /// \returns SDL_TRUE if the given joystick is supported by the game controller
  /// interface, SDL_FALSE if it isn't or it's an invalid index.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GameControllerNameForIndex
  /// \sa SDL_GameControllerOpen
  int SDL_IsGameController(
    int joystick_index,
  ) {
    return _SDL_IsGameController(
      joystick_index,
    );
  }

  late final _SDL_IsGameControllerPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Int32)>>(
          'SDL_IsGameController');
  late final _SDL_IsGameController =
      _SDL_IsGameControllerPtr.asFunction<int Function(int)>();

  /// Get the implementation dependent name for the game controller.
  ///
  /// This function can be called before any controllers are opened.
  ///
  /// `joystick_index` is the same as the `device_index` passed to
  /// SDL_JoystickOpen().
  ///
  /// \param joystick_index the device_index of a device, from zero to
  /// SDL_NumJoysticks()-1
  /// \returns the implementation-dependent name for the game controller, or NULL
  /// if there is no name or the index is invalid.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GameControllerName
  /// \sa SDL_GameControllerOpen
  /// \sa SDL_IsGameController
  ffi.Pointer<ffi.Int8> SDL_GameControllerNameForIndex(
    int joystick_index,
  ) {
    return _SDL_GameControllerNameForIndex(
      joystick_index,
    );
  }

  late final _SDL_GameControllerNameForIndexPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Int8> Function(ffi.Int32)>>(
          'SDL_GameControllerNameForIndex');
  late final _SDL_GameControllerNameForIndex =
      _SDL_GameControllerNameForIndexPtr.asFunction<
          ffi.Pointer<ffi.Int8> Function(int)>();

  /// Get the type of a game controller.
  ///
  /// This can be called before any controllers are opened.
  ///
  /// \param joystick_index the device_index of a device, from zero to
  /// SDL_NumJoysticks()-1
  /// \returns the controller type.
  ///
  /// \since This function is available since SDL 2.0.12.
  int SDL_GameControllerTypeForIndex(
    int joystick_index,
  ) {
    return _SDL_GameControllerTypeForIndex(
      joystick_index,
    );
  }

  late final _SDL_GameControllerTypeForIndexPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Int32)>>(
          'SDL_GameControllerTypeForIndex');
  late final _SDL_GameControllerTypeForIndex =
      _SDL_GameControllerTypeForIndexPtr.asFunction<int Function(int)>();

  /// Get the mapping of a game controller.
  ///
  /// This can be called before any controllers are opened.
  ///
  /// \param joystick_index the device_index of a device, from zero to
  /// SDL_NumJoysticks()-1
  /// \returns the mapping string. Must be freed with SDL_free(). Returns NULL if
  /// no mapping is available.
  ///
  /// \since This function is available since SDL 2.0.9.
  ffi.Pointer<ffi.Int8> SDL_GameControllerMappingForDeviceIndex(
    int joystick_index,
  ) {
    return _SDL_GameControllerMappingForDeviceIndex(
      joystick_index,
    );
  }

  late final _SDL_GameControllerMappingForDeviceIndexPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Int8> Function(ffi.Int32)>>(
          'SDL_GameControllerMappingForDeviceIndex');
  late final _SDL_GameControllerMappingForDeviceIndex =
      _SDL_GameControllerMappingForDeviceIndexPtr.asFunction<
          ffi.Pointer<ffi.Int8> Function(int)>();

  /// Open a game controller for use.
  ///
  /// `joystick_index` is the same as the `device_index` passed to
  /// SDL_JoystickOpen().
  ///
  /// The index passed as an argument refers to the N'th game controller on the
  /// system. This index is not the value which will identify this controller in
  /// future controller events. The joystick's instance id (SDL_JoystickID) will
  /// be used there instead.
  ///
  /// \param joystick_index the device_index of a device, up to
  /// SDL_NumJoysticks()
  /// \returns a gamecontroller identifier or NULL if an error occurred; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GameControllerClose
  /// \sa SDL_GameControllerNameForIndex
  /// \sa SDL_IsGameController
  ffi.Pointer<SDL_GameController1> SDL_GameControllerOpen(
    int joystick_index,
  ) {
    return _SDL_GameControllerOpen(
      joystick_index,
    );
  }

  late final _SDL_GameControllerOpenPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<SDL_GameController1> Function(
              ffi.Int32)>>('SDL_GameControllerOpen');
  late final _SDL_GameControllerOpen = _SDL_GameControllerOpenPtr.asFunction<
      ffi.Pointer<SDL_GameController1> Function(int)>();

  /// Get the SDL_GameController associated with an instance id.
  ///
  /// \param joyid the instance id to get the SDL_GameController for
  /// \returns an SDL_GameController on success or NULL on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.4.
  ffi.Pointer<SDL_GameController1> SDL_GameControllerFromInstanceID(
    int joyid,
  ) {
    return _SDL_GameControllerFromInstanceID(
      joyid,
    );
  }

  late final _SDL_GameControllerFromInstanceIDPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<SDL_GameController1> Function(
              SDL_JoystickID)>>('SDL_GameControllerFromInstanceID');
  late final _SDL_GameControllerFromInstanceID =
      _SDL_GameControllerFromInstanceIDPtr.asFunction<
          ffi.Pointer<SDL_GameController1> Function(int)>();

  /// Get the SDL_GameController associated with a player index.
  ///
  /// Please note that the player index is _not_ the device index, nor is it the
  /// instance id!
  ///
  /// \param player_index the player index, which is not the device index or the
  /// instance id!
  /// \returns the SDL_GameController associated with a player index.
  ///
  /// \since This function is available since SDL 2.0.12.
  ///
  /// \sa SDL_GameControllerGetPlayerIndex
  /// \sa SDL_GameControllerSetPlayerIndex
  ffi.Pointer<SDL_GameController1> SDL_GameControllerFromPlayerIndex(
    int player_index,
  ) {
    return _SDL_GameControllerFromPlayerIndex(
      player_index,
    );
  }

  late final _SDL_GameControllerFromPlayerIndexPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<SDL_GameController1> Function(
              ffi.Int32)>>('SDL_GameControllerFromPlayerIndex');
  late final _SDL_GameControllerFromPlayerIndex =
      _SDL_GameControllerFromPlayerIndexPtr.asFunction<
          ffi.Pointer<SDL_GameController1> Function(int)>();

  /// Get the implementation-dependent name for an opened game controller.
  ///
  /// This is the same name as returned by SDL_GameControllerNameForIndex(), but
  /// it takes a controller identifier instead of the (unstable) device index.
  ///
  /// \param gamecontroller a game controller identifier previously returned by
  /// SDL_GameControllerOpen()
  /// \returns the implementation dependent name for the game controller, or NULL
  /// if there is no name or the identifier passed is invalid.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GameControllerNameForIndex
  /// \sa SDL_GameControllerOpen
  ffi.Pointer<ffi.Int8> SDL_GameControllerName(
    ffi.Pointer<SDL_GameController1> gamecontroller,
  ) {
    return _SDL_GameControllerName(
      gamecontroller,
    );
  }

  late final _SDL_GameControllerNamePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Int8> Function(
              ffi.Pointer<SDL_GameController1>)>>('SDL_GameControllerName');
  late final _SDL_GameControllerName = _SDL_GameControllerNamePtr.asFunction<
      ffi.Pointer<ffi.Int8> Function(ffi.Pointer<SDL_GameController1>)>();

  /// Get the type of this currently opened controller
  ///
  /// This is the same name as returned by SDL_GameControllerTypeForIndex(), but
  /// it takes a controller identifier instead of the (unstable) device index.
  ///
  /// \param gamecontroller the game controller object to query.
  /// \returns the controller type.
  ///
  /// \since This function is available since SDL 2.0.12.
  int SDL_GameControllerGetType(
    ffi.Pointer<SDL_GameController1> gamecontroller,
  ) {
    return _SDL_GameControllerGetType(
      gamecontroller,
    );
  }

  late final _SDL_GameControllerGetTypePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<SDL_GameController1>)>>('SDL_GameControllerGetType');
  late final _SDL_GameControllerGetType = _SDL_GameControllerGetTypePtr
      .asFunction<int Function(ffi.Pointer<SDL_GameController1>)>();

  /// Get the player index of an opened game controller.
  ///
  /// For XInput controllers this returns the XInput user index.
  ///
  /// \param gamecontroller the game controller object to query.
  /// \returns the player index for controller, or -1 if it's not available.
  ///
  /// \since This function is available since SDL 2.0.9.
  int SDL_GameControllerGetPlayerIndex(
    ffi.Pointer<SDL_GameController1> gamecontroller,
  ) {
    return _SDL_GameControllerGetPlayerIndex(
      gamecontroller,
    );
  }

  late final _SDL_GameControllerGetPlayerIndexPtr = _lookup<
          ffi.NativeFunction<
              ffi.Int32 Function(ffi.Pointer<SDL_GameController1>)>>(
      'SDL_GameControllerGetPlayerIndex');
  late final _SDL_GameControllerGetPlayerIndex =
      _SDL_GameControllerGetPlayerIndexPtr.asFunction<
          int Function(ffi.Pointer<SDL_GameController1>)>();

  /// Set the player index of an opened game controller.
  ///
  /// \param gamecontroller the game controller object to adjust.
  /// \param player_index Player index to assign to this controller.
  ///
  /// \since This function is available since SDL 2.0.12.
  void SDL_GameControllerSetPlayerIndex(
    ffi.Pointer<SDL_GameController1> gamecontroller,
    int player_index,
  ) {
    return _SDL_GameControllerSetPlayerIndex(
      gamecontroller,
      player_index,
    );
  }

  late final _SDL_GameControllerSetPlayerIndexPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<SDL_GameController1>,
              ffi.Int32)>>('SDL_GameControllerSetPlayerIndex');
  late final _SDL_GameControllerSetPlayerIndex =
      _SDL_GameControllerSetPlayerIndexPtr.asFunction<
          void Function(ffi.Pointer<SDL_GameController1>, int)>();

  /// Get the USB vendor ID of an opened controller, if available.
  ///
  /// If the vendor ID isn't available this function returns 0.
  ///
  /// \param gamecontroller the game controller object to query.
  /// \return the USB vendor ID, or zero if unavailable.
  ///
  /// \since This function is available since SDL 2.0.6.
  int SDL_GameControllerGetVendor(
    ffi.Pointer<SDL_GameController1> gamecontroller,
  ) {
    return _SDL_GameControllerGetVendor(
      gamecontroller,
    );
  }

  late final _SDL_GameControllerGetVendorPtr = _lookup<
          ffi.NativeFunction<
              Uint16 Function(ffi.Pointer<SDL_GameController1>)>>(
      'SDL_GameControllerGetVendor');
  late final _SDL_GameControllerGetVendor = _SDL_GameControllerGetVendorPtr
      .asFunction<int Function(ffi.Pointer<SDL_GameController1>)>();

  /// Get the USB product ID of an opened controller, if available.
  ///
  /// If the product ID isn't available this function returns 0.
  ///
  /// \param gamecontroller the game controller object to query.
  /// \return the USB product ID, or zero if unavailable.
  ///
  /// \since This function is available since SDL 2.0.6.
  int SDL_GameControllerGetProduct(
    ffi.Pointer<SDL_GameController1> gamecontroller,
  ) {
    return _SDL_GameControllerGetProduct(
      gamecontroller,
    );
  }

  late final _SDL_GameControllerGetProductPtr = _lookup<
          ffi.NativeFunction<
              Uint16 Function(ffi.Pointer<SDL_GameController1>)>>(
      'SDL_GameControllerGetProduct');
  late final _SDL_GameControllerGetProduct = _SDL_GameControllerGetProductPtr
      .asFunction<int Function(ffi.Pointer<SDL_GameController1>)>();

  /// Get the product version of an opened controller, if available.
  ///
  /// If the product version isn't available this function returns 0.
  ///
  /// \param gamecontroller the game controller object to query.
  /// \return the USB product version, or zero if unavailable.
  ///
  /// \since This function is available since SDL 2.0.6.
  int SDL_GameControllerGetProductVersion(
    ffi.Pointer<SDL_GameController1> gamecontroller,
  ) {
    return _SDL_GameControllerGetProductVersion(
      gamecontroller,
    );
  }

  late final _SDL_GameControllerGetProductVersionPtr = _lookup<
          ffi.NativeFunction<
              Uint16 Function(ffi.Pointer<SDL_GameController1>)>>(
      'SDL_GameControllerGetProductVersion');
  late final _SDL_GameControllerGetProductVersion =
      _SDL_GameControllerGetProductVersionPtr.asFunction<
          int Function(ffi.Pointer<SDL_GameController1>)>();

  /// Get the serial number of an opened controller, if available.
  ///
  /// Returns the serial number of the controller, or NULL if it is not
  /// available.
  ///
  /// \param gamecontroller the game controller object to query.
  /// \return the serial number, or NULL if unavailable.
  ///
  /// \since This function is available since SDL 2.0.14.
  ffi.Pointer<ffi.Int8> SDL_GameControllerGetSerial(
    ffi.Pointer<SDL_GameController1> gamecontroller,
  ) {
    return _SDL_GameControllerGetSerial(
      gamecontroller,
    );
  }

  late final _SDL_GameControllerGetSerialPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<ffi.Int8> Function(
                  ffi.Pointer<SDL_GameController1>)>>(
      'SDL_GameControllerGetSerial');
  late final _SDL_GameControllerGetSerial =
      _SDL_GameControllerGetSerialPtr.asFunction<
          ffi.Pointer<ffi.Int8> Function(ffi.Pointer<SDL_GameController1>)>();

  /// Check if a controller has been opened and is currently connected.
  ///
  /// \param gamecontroller a game controller identifier previously returned by
  /// SDL_GameControllerOpen()
  /// \returns SDL_TRUE if the controller has been opened and is currently
  /// connected, or SDL_FALSE if not.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GameControllerClose
  /// \sa SDL_GameControllerOpen
  int SDL_GameControllerGetAttached(
    ffi.Pointer<SDL_GameController1> gamecontroller,
  ) {
    return _SDL_GameControllerGetAttached(
      gamecontroller,
    );
  }

  late final _SDL_GameControllerGetAttachedPtr = _lookup<
          ffi.NativeFunction<
              ffi.Int32 Function(ffi.Pointer<SDL_GameController1>)>>(
      'SDL_GameControllerGetAttached');
  late final _SDL_GameControllerGetAttached = _SDL_GameControllerGetAttachedPtr
      .asFunction<int Function(ffi.Pointer<SDL_GameController1>)>();

  /// Get the Joystick ID from a Game Controller.
  ///
  /// This function will give you a SDL_Joystick object, which allows you to use
  /// the SDL_Joystick functions with a SDL_GameController object. This would be
  /// useful for getting a joystick's position at any given time, even if it
  /// hasn't moved (moving it would produce an event, which would have the axis'
  /// value).
  ///
  /// The pointer returned is owned by the SDL_GameController. You should not
  /// call SDL_JoystickClose() on it, for example, since doing so will likely
  /// cause SDL to crash.
  ///
  /// \param gamecontroller the game controller object that you want to get a
  /// joystick from
  /// \returns a SDL_Joystick object; call SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ffi.Pointer<SDL_Joystick1> SDL_GameControllerGetJoystick(
    ffi.Pointer<SDL_GameController1> gamecontroller,
  ) {
    return _SDL_GameControllerGetJoystick(
      gamecontroller,
    );
  }

  late final _SDL_GameControllerGetJoystickPtr = _lookup<
          ffi.NativeFunction<
              ffi.Pointer<SDL_Joystick1> Function(
                  ffi.Pointer<SDL_GameController1>)>>(
      'SDL_GameControllerGetJoystick');
  late final _SDL_GameControllerGetJoystick =
      _SDL_GameControllerGetJoystickPtr.asFunction<
          ffi.Pointer<SDL_Joystick1> Function(
              ffi.Pointer<SDL_GameController1>)>();

  /// Query or change current state of Game Controller events.
  ///
  /// If controller events are disabled, you must call SDL_GameControllerUpdate()
  /// yourself and check the state of the controller when you want controller
  /// information.
  ///
  /// Any number can be passed to SDL_GameControllerEventState(), but only -1, 0,
  /// and 1 will have any effect. Other numbers will just be returned.
  ///
  /// \param state can be one of `SDL_QUERY`, `SDL_IGNORE`, or `SDL_ENABLE`
  /// \returns the same value passed to the function, with exception to -1
  /// (SDL_QUERY), which will return the current state.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_JoystickEventState
  int SDL_GameControllerEventState(
    int state,
  ) {
    return _SDL_GameControllerEventState(
      state,
    );
  }

  late final _SDL_GameControllerEventStatePtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Int32)>>(
          'SDL_GameControllerEventState');
  late final _SDL_GameControllerEventState =
      _SDL_GameControllerEventStatePtr.asFunction<int Function(int)>();

  /// Manually pump game controller updates if not using the loop.
  ///
  /// This function is called automatically by the event loop if events are
  /// enabled. Under such circumstances, it will not be necessary to call this
  /// function.
  ///
  /// \since This function is available since SDL 2.0.0.
  void SDL_GameControllerUpdate() {
    return _SDL_GameControllerUpdate();
  }

  late final _SDL_GameControllerUpdatePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>(
          'SDL_GameControllerUpdate');
  late final _SDL_GameControllerUpdate =
      _SDL_GameControllerUpdatePtr.asFunction<void Function()>();

  /// Convert a string into SDL_GameControllerAxis enum.
  ///
  /// This function is called internally to translate SDL_GameController mapping
  /// strings for the underlying joystick device into the consistent
  /// SDL_GameController mapping. You do not normally need to call this function
  /// unless you are parsing SDL_GameController mappings in your own code.
  ///
  /// Note specially that "righttrigger" and "lefttrigger" map to
  /// `SDL_CONTROLLER_AXIS_TRIGGERRIGHT` and `SDL_CONTROLLER_AXIS_TRIGGERLEFT`,
  /// respectively.
  ///
  /// \param str string representing a SDL_GameController axis
  /// \returns the SDL_GameControllerAxis enum corresponding to the input string,
  /// or `SDL_CONTROLLER_AXIS_INVALID` if no match was found.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GameControllerGetStringForAxis
  int SDL_GameControllerGetAxisFromString(
    ffi.Pointer<ffi.Int8> str,
  ) {
    return _SDL_GameControllerGetAxisFromString(
      str,
    );
  }

  late final _SDL_GameControllerGetAxisFromStringPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<ffi.Int8>)>>(
          'SDL_GameControllerGetAxisFromString');
  late final _SDL_GameControllerGetAxisFromString =
      _SDL_GameControllerGetAxisFromStringPtr.asFunction<
          int Function(ffi.Pointer<ffi.Int8>)>();

  /// Convert from an SDL_GameControllerAxis enum to a string.
  ///
  /// The caller should not SDL_free() the returned string.
  ///
  /// \param axis an enum value for a given SDL_GameControllerAxis
  /// \returns a string for the given axis, or NULL if an invalid axis is
  /// specified. The string returned is of the format used by
  /// SDL_GameController mapping strings.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GameControllerGetAxisFromString
  ffi.Pointer<ffi.Int8> SDL_GameControllerGetStringForAxis(
    int axis,
  ) {
    return _SDL_GameControllerGetStringForAxis(
      axis,
    );
  }

  late final _SDL_GameControllerGetStringForAxisPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Int8> Function(ffi.Int32)>>(
          'SDL_GameControllerGetStringForAxis');
  late final _SDL_GameControllerGetStringForAxis =
      _SDL_GameControllerGetStringForAxisPtr.asFunction<
          ffi.Pointer<ffi.Int8> Function(int)>();

  /// Get the SDL joystick layer binding for a controller axis mapping.
  ///
  /// \param gamecontroller a game controller
  /// \param axis an axis enum value (one of the SDL_GameControllerAxis values)
  /// \returns a SDL_GameControllerButtonBind describing the bind. On failure
  /// (like the given Controller axis doesn't exist on the device), its
  /// `.bindType` will be `SDL_CONTROLLER_BINDTYPE_NONE`.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GameControllerGetBindForButton
  SDL_GameControllerButtonBind SDL_GameControllerGetBindForAxis(
    ffi.Pointer<SDL_GameController1> gamecontroller,
    int axis,
  ) {
    return _SDL_GameControllerGetBindForAxis(
      gamecontroller,
      axis,
    );
  }

  late final _SDL_GameControllerGetBindForAxisPtr = _lookup<
      ffi.NativeFunction<
          SDL_GameControllerButtonBind Function(
              ffi.Pointer<SDL_GameController1>,
              ffi.Int32)>>('SDL_GameControllerGetBindForAxis');
  late final _SDL_GameControllerGetBindForAxis =
      _SDL_GameControllerGetBindForAxisPtr.asFunction<
          SDL_GameControllerButtonBind Function(
              ffi.Pointer<SDL_GameController1>, int)>();

  /// Query whether a game controller has a given axis.
  ///
  /// This merely reports whether the controller's mapping defined this axis, as
  /// that is all the information SDL has about the physical device.
  ///
  /// \param gamecontroller a game controller
  /// \param axis an axis enum value (an SDL_GameControllerAxis value)
  /// \returns SDL_TRUE if the controller has this axis, SDL_FALSE otherwise.
  ///
  /// \since This function is available since SDL 2.0.14.
  int SDL_GameControllerHasAxis(
    ffi.Pointer<SDL_GameController1> gamecontroller,
    int axis,
  ) {
    return _SDL_GameControllerHasAxis(
      gamecontroller,
      axis,
    );
  }

  late final _SDL_GameControllerHasAxisPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_GameController1>,
              ffi.Int32)>>('SDL_GameControllerHasAxis');
  late final _SDL_GameControllerHasAxis = _SDL_GameControllerHasAxisPtr
      .asFunction<int Function(ffi.Pointer<SDL_GameController1>, int)>();

  /// Get the current state of an axis control on a game controller.
  ///
  /// The axis indices start at index 0.
  ///
  /// The state is a value ranging from -32768 to 32767. Triggers, however, range
  /// from 0 to 32767 (they never return a negative value).
  ///
  /// \param gamecontroller a game controller
  /// \param axis an axis index (one of the SDL_GameControllerAxis values)
  /// \returns axis state (including 0) on success or 0 (also) on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GameControllerGetButton
  int SDL_GameControllerGetAxis(
    ffi.Pointer<SDL_GameController1> gamecontroller,
    int axis,
  ) {
    return _SDL_GameControllerGetAxis(
      gamecontroller,
      axis,
    );
  }

  late final _SDL_GameControllerGetAxisPtr = _lookup<
      ffi.NativeFunction<
          Sint16 Function(ffi.Pointer<SDL_GameController1>,
              ffi.Int32)>>('SDL_GameControllerGetAxis');
  late final _SDL_GameControllerGetAxis = _SDL_GameControllerGetAxisPtr
      .asFunction<int Function(ffi.Pointer<SDL_GameController1>, int)>();

  /// Convert a string into an SDL_GameControllerButton enum.
  ///
  /// This function is called internally to translate SDL_GameController mapping
  /// strings for the underlying joystick device into the consistent
  /// SDL_GameController mapping. You do not normally need to call this function
  /// unless you are parsing SDL_GameController mappings in your own code.
  ///
  /// \param str string representing a SDL_GameController axis
  /// \returns the SDL_GameControllerButton enum corresponding to the input
  /// string, or `SDL_CONTROLLER_AXIS_INVALID` if no match was found.
  ///
  /// \since This function is available since SDL 2.0.0.
  int SDL_GameControllerGetButtonFromString(
    ffi.Pointer<ffi.Int8> str,
  ) {
    return _SDL_GameControllerGetButtonFromString(
      str,
    );
  }

  late final _SDL_GameControllerGetButtonFromStringPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<ffi.Int8>)>>(
          'SDL_GameControllerGetButtonFromString');
  late final _SDL_GameControllerGetButtonFromString =
      _SDL_GameControllerGetButtonFromStringPtr.asFunction<
          int Function(ffi.Pointer<ffi.Int8>)>();

  /// Convert from an SDL_GameControllerButton enum to a string.
  ///
  /// The caller should not SDL_free() the returned string.
  ///
  /// \param button an enum value for a given SDL_GameControllerButton
  /// \returns a string for the given button, or NULL if an invalid axis is
  /// specified. The string returned is of the format used by
  /// SDL_GameController mapping strings.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GameControllerGetButtonFromString
  ffi.Pointer<ffi.Int8> SDL_GameControllerGetStringForButton(
    int button,
  ) {
    return _SDL_GameControllerGetStringForButton(
      button,
    );
  }

  late final _SDL_GameControllerGetStringForButtonPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Int8> Function(ffi.Int32)>>(
          'SDL_GameControllerGetStringForButton');
  late final _SDL_GameControllerGetStringForButton =
      _SDL_GameControllerGetStringForButtonPtr.asFunction<
          ffi.Pointer<ffi.Int8> Function(int)>();

  /// Get the SDL joystick layer binding for a controller button mapping.
  ///
  /// \param gamecontroller a game controller
  /// \param button an button enum value (an SDL_GameControllerButton value)
  /// \returns a SDL_GameControllerButtonBind describing the bind. On failure
  /// (like the given Controller button doesn't exist on the device),
  /// its `.bindType` will be `SDL_CONTROLLER_BINDTYPE_NONE`.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GameControllerGetBindForAxis
  SDL_GameControllerButtonBind SDL_GameControllerGetBindForButton(
    ffi.Pointer<SDL_GameController1> gamecontroller,
    int button,
  ) {
    return _SDL_GameControllerGetBindForButton(
      gamecontroller,
      button,
    );
  }

  late final _SDL_GameControllerGetBindForButtonPtr = _lookup<
      ffi.NativeFunction<
          SDL_GameControllerButtonBind Function(
              ffi.Pointer<SDL_GameController1>,
              ffi.Int32)>>('SDL_GameControllerGetBindForButton');
  late final _SDL_GameControllerGetBindForButton =
      _SDL_GameControllerGetBindForButtonPtr.asFunction<
          SDL_GameControllerButtonBind Function(
              ffi.Pointer<SDL_GameController1>, int)>();

  /// Query whether a game controller has a given button.
  ///
  /// This merely reports whether the controller's mapping defined this button,
  /// as that is all the information SDL has about the physical device.
  ///
  /// \param gamecontroller a game controller
  /// \param button a button enum value (an SDL_GameControllerButton value)
  /// \returns SDL_TRUE if the controller has this button, SDL_FALSE otherwise.
  ///
  /// \since This function is available since SDL 2.0.14.
  int SDL_GameControllerHasButton(
    ffi.Pointer<SDL_GameController1> gamecontroller,
    int button,
  ) {
    return _SDL_GameControllerHasButton(
      gamecontroller,
      button,
    );
  }

  late final _SDL_GameControllerHasButtonPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_GameController1>,
              ffi.Int32)>>('SDL_GameControllerHasButton');
  late final _SDL_GameControllerHasButton = _SDL_GameControllerHasButtonPtr
      .asFunction<int Function(ffi.Pointer<SDL_GameController1>, int)>();

  /// Get the current state of a button on a game controller.
  ///
  /// \param gamecontroller a game controller
  /// \param button a button index (one of the SDL_GameControllerButton values)
  /// \returns 1 for pressed state or 0 for not pressed state or error; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GameControllerGetAxis
  int SDL_GameControllerGetButton(
    ffi.Pointer<SDL_GameController1> gamecontroller,
    int button,
  ) {
    return _SDL_GameControllerGetButton(
      gamecontroller,
      button,
    );
  }

  late final _SDL_GameControllerGetButtonPtr = _lookup<
      ffi.NativeFunction<
          Uint8 Function(ffi.Pointer<SDL_GameController1>,
              ffi.Int32)>>('SDL_GameControllerGetButton');
  late final _SDL_GameControllerGetButton = _SDL_GameControllerGetButtonPtr
      .asFunction<int Function(ffi.Pointer<SDL_GameController1>, int)>();

  /// Get the number of touchpads on a game controller.
  ///
  /// \since This function is available since SDL 2.0.14.
  int SDL_GameControllerGetNumTouchpads(
    ffi.Pointer<SDL_GameController1> gamecontroller,
  ) {
    return _SDL_GameControllerGetNumTouchpads(
      gamecontroller,
    );
  }

  late final _SDL_GameControllerGetNumTouchpadsPtr = _lookup<
          ffi.NativeFunction<
              ffi.Int32 Function(ffi.Pointer<SDL_GameController1>)>>(
      'SDL_GameControllerGetNumTouchpads');
  late final _SDL_GameControllerGetNumTouchpads =
      _SDL_GameControllerGetNumTouchpadsPtr.asFunction<
          int Function(ffi.Pointer<SDL_GameController1>)>();

  /// Get the number of supported simultaneous fingers on a touchpad on a game
  /// controller.
  ///
  /// \since This function is available since SDL 2.0.14.
  int SDL_GameControllerGetNumTouchpadFingers(
    ffi.Pointer<SDL_GameController1> gamecontroller,
    int touchpad,
  ) {
    return _SDL_GameControllerGetNumTouchpadFingers(
      gamecontroller,
      touchpad,
    );
  }

  late final _SDL_GameControllerGetNumTouchpadFingersPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_GameController1>,
              ffi.Int32)>>('SDL_GameControllerGetNumTouchpadFingers');
  late final _SDL_GameControllerGetNumTouchpadFingers =
      _SDL_GameControllerGetNumTouchpadFingersPtr.asFunction<
          int Function(ffi.Pointer<SDL_GameController1>, int)>();

  /// Get the current state of a finger on a touchpad on a game controller.
  ///
  /// \since This function is available since SDL 2.0.14.
  int SDL_GameControllerGetTouchpadFinger(
    ffi.Pointer<SDL_GameController1> gamecontroller,
    int touchpad,
    int finger,
    ffi.Pointer<Uint8> state,
    ffi.Pointer<ffi.Float> x,
    ffi.Pointer<ffi.Float> y,
    ffi.Pointer<ffi.Float> pressure,
  ) {
    return _SDL_GameControllerGetTouchpadFinger(
      gamecontroller,
      touchpad,
      finger,
      state,
      x,
      y,
      pressure,
    );
  }

  late final _SDL_GameControllerGetTouchpadFingerPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<SDL_GameController1>,
              ffi.Int32,
              ffi.Int32,
              ffi.Pointer<Uint8>,
              ffi.Pointer<ffi.Float>,
              ffi.Pointer<ffi.Float>,
              ffi.Pointer<ffi.Float>)>>('SDL_GameControllerGetTouchpadFinger');
  late final _SDL_GameControllerGetTouchpadFinger =
      _SDL_GameControllerGetTouchpadFingerPtr.asFunction<
          int Function(
              ffi.Pointer<SDL_GameController1>,
              int,
              int,
              ffi.Pointer<Uint8>,
              ffi.Pointer<ffi.Float>,
              ffi.Pointer<ffi.Float>,
              ffi.Pointer<ffi.Float>)>();

  /// Return whether a game controller has a particular sensor.
  ///
  /// \param gamecontroller The controller to query
  /// \param type The type of sensor to query
  /// \returns SDL_TRUE if the sensor exists, SDL_FALSE otherwise.
  ///
  /// \since This function is available since SDL 2.0.14.
  int SDL_GameControllerHasSensor(
    ffi.Pointer<SDL_GameController1> gamecontroller,
    int type,
  ) {
    return _SDL_GameControllerHasSensor(
      gamecontroller,
      type,
    );
  }

  late final _SDL_GameControllerHasSensorPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_GameController1>,
              ffi.Int32)>>('SDL_GameControllerHasSensor');
  late final _SDL_GameControllerHasSensor = _SDL_GameControllerHasSensorPtr
      .asFunction<int Function(ffi.Pointer<SDL_GameController1>, int)>();

  /// Set whether data reporting for a game controller sensor is enabled.
  ///
  /// \param gamecontroller The controller to update
  /// \param type The type of sensor to enable/disable
  /// \param enabled Whether data reporting should be enabled
  /// \returns 0 or -1 if an error occurred.
  ///
  /// \since This function is available since SDL 2.0.14.
  int SDL_GameControllerSetSensorEnabled(
    ffi.Pointer<SDL_GameController1> gamecontroller,
    int type,
    int enabled,
  ) {
    return _SDL_GameControllerSetSensorEnabled(
      gamecontroller,
      type,
      enabled,
    );
  }

  late final _SDL_GameControllerSetSensorEnabledPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_GameController1>, ffi.Int32,
              ffi.Int32)>>('SDL_GameControllerSetSensorEnabled');
  late final _SDL_GameControllerSetSensorEnabled =
      _SDL_GameControllerSetSensorEnabledPtr.asFunction<
          int Function(ffi.Pointer<SDL_GameController1>, int, int)>();

  /// Query whether sensor data reporting is enabled for a game controller.
  ///
  /// \param gamecontroller The controller to query
  /// \param type The type of sensor to query
  /// \returns SDL_TRUE if the sensor is enabled, SDL_FALSE otherwise.
  ///
  /// \since This function is available since SDL 2.0.14.
  int SDL_GameControllerIsSensorEnabled(
    ffi.Pointer<SDL_GameController1> gamecontroller,
    int type,
  ) {
    return _SDL_GameControllerIsSensorEnabled(
      gamecontroller,
      type,
    );
  }

  late final _SDL_GameControllerIsSensorEnabledPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_GameController1>,
              ffi.Int32)>>('SDL_GameControllerIsSensorEnabled');
  late final _SDL_GameControllerIsSensorEnabled =
      _SDL_GameControllerIsSensorEnabledPtr.asFunction<
          int Function(ffi.Pointer<SDL_GameController1>, int)>();

  /// Get the data rate (number of events per second) of a game controller
  /// sensor.
  ///
  /// \param gamecontroller The controller to query
  /// \param type The type of sensor to query
  /// \return the data rate, or 0.0f if the data rate is not available.
  ///
  /// \since This function is available since SDL 2.0.16.
  double SDL_GameControllerGetSensorDataRate(
    ffi.Pointer<SDL_GameController1> gamecontroller,
    int type,
  ) {
    return _SDL_GameControllerGetSensorDataRate(
      gamecontroller,
      type,
    );
  }

  late final _SDL_GameControllerGetSensorDataRatePtr = _lookup<
      ffi.NativeFunction<
          ffi.Float Function(ffi.Pointer<SDL_GameController1>,
              ffi.Int32)>>('SDL_GameControllerGetSensorDataRate');
  late final _SDL_GameControllerGetSensorDataRate =
      _SDL_GameControllerGetSensorDataRatePtr.asFunction<
          double Function(ffi.Pointer<SDL_GameController1>, int)>();

  /// Get the current state of a game controller sensor.
  ///
  /// The number of values and interpretation of the data is sensor dependent.
  /// See SDL_sensor.h for the details for each type of sensor.
  ///
  /// \param gamecontroller The controller to query
  /// \param type The type of sensor to query
  /// \param data A pointer filled with the current sensor state
  /// \param num_values The number of values to write to data
  /// \return 0 or -1 if an error occurred.
  ///
  /// \since This function is available since SDL 2.0.14.
  int SDL_GameControllerGetSensorData(
    ffi.Pointer<SDL_GameController1> gamecontroller,
    int type,
    ffi.Pointer<ffi.Float> data,
    int num_values,
  ) {
    return _SDL_GameControllerGetSensorData(
      gamecontroller,
      type,
      data,
      num_values,
    );
  }

  late final _SDL_GameControllerGetSensorDataPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<SDL_GameController1>,
              ffi.Int32,
              ffi.Pointer<ffi.Float>,
              ffi.Int32)>>('SDL_GameControllerGetSensorData');
  late final _SDL_GameControllerGetSensorData =
      _SDL_GameControllerGetSensorDataPtr.asFunction<
          int Function(ffi.Pointer<SDL_GameController1>, int,
              ffi.Pointer<ffi.Float>, int)>();

  /// Start a rumble effect on a game controller.
  ///
  /// Each call to this function cancels any previous rumble effect, and calling
  /// it with 0 intensity stops any rumbling.
  ///
  /// \param gamecontroller The controller to vibrate
  /// \param low_frequency_rumble The intensity of the low frequency (left)
  /// rumble motor, from 0 to 0xFFFF
  /// \param high_frequency_rumble The intensity of the high frequency (right)
  /// rumble motor, from 0 to 0xFFFF
  /// \param duration_ms The duration of the rumble effect, in milliseconds
  /// \returns 0, or -1 if rumble isn't supported on this controller
  ///
  /// \since This function is available since SDL 2.0.9.
  ///
  /// \sa SDL_GameControllerHasRumble
  int SDL_GameControllerRumble(
    ffi.Pointer<SDL_GameController1> gamecontroller,
    int low_frequency_rumble,
    int high_frequency_rumble,
    int duration_ms,
  ) {
    return _SDL_GameControllerRumble(
      gamecontroller,
      low_frequency_rumble,
      high_frequency_rumble,
      duration_ms,
    );
  }

  late final _SDL_GameControllerRumblePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_GameController1>, Uint16, Uint16,
              Uint32)>>('SDL_GameControllerRumble');
  late final _SDL_GameControllerRumble =
      _SDL_GameControllerRumblePtr.asFunction<
          int Function(ffi.Pointer<SDL_GameController1>, int, int, int)>();

  /// Start a rumble effect in the game controller's triggers.
  ///
  /// Each call to this function cancels any previous trigger rumble effect, and
  /// calling it with 0 intensity stops any rumbling.
  ///
  /// Note that this is rumbling of the _triggers_ and not the game controller as
  /// a whole. The first controller to offer this feature was the PlayStation 5's
  /// DualShock 5.
  ///
  /// \param gamecontroller The controller to vibrate
  /// \param left_rumble The intensity of the left trigger rumble motor, from 0
  /// to 0xFFFF
  /// \param right_rumble The intensity of the right trigger rumble motor, from 0
  /// to 0xFFFF
  /// \param duration_ms The duration of the rumble effect, in milliseconds
  /// \returns 0, or -1 if trigger rumble isn't supported on this controller
  ///
  /// \since This function is available since SDL 2.0.14.
  ///
  /// \sa SDL_GameControllerHasRumbleTriggers
  int SDL_GameControllerRumbleTriggers(
    ffi.Pointer<SDL_GameController1> gamecontroller,
    int left_rumble,
    int right_rumble,
    int duration_ms,
  ) {
    return _SDL_GameControllerRumbleTriggers(
      gamecontroller,
      left_rumble,
      right_rumble,
      duration_ms,
    );
  }

  late final _SDL_GameControllerRumbleTriggersPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_GameController1>, Uint16, Uint16,
              Uint32)>>('SDL_GameControllerRumbleTriggers');
  late final _SDL_GameControllerRumbleTriggers =
      _SDL_GameControllerRumbleTriggersPtr.asFunction<
          int Function(ffi.Pointer<SDL_GameController1>, int, int, int)>();

  /// Query whether a game controller has an LED.
  ///
  /// \param gamecontroller The controller to query
  /// \returns SDL_TRUE, or SDL_FALSE if this controller does not have a
  /// modifiable LED
  ///
  /// \since This function is available since SDL 2.0.14.
  int SDL_GameControllerHasLED(
    ffi.Pointer<SDL_GameController1> gamecontroller,
  ) {
    return _SDL_GameControllerHasLED(
      gamecontroller,
    );
  }

  late final _SDL_GameControllerHasLEDPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<SDL_GameController1>)>>('SDL_GameControllerHasLED');
  late final _SDL_GameControllerHasLED = _SDL_GameControllerHasLEDPtr
      .asFunction<int Function(ffi.Pointer<SDL_GameController1>)>();

  /// Query whether a game controller has rumble support.
  ///
  /// \param gamecontroller The controller to query
  /// \returns SDL_TRUE, or SDL_FALSE if this controller does not have rumble
  /// support
  ///
  /// \since This function is available since SDL 2.0.18.
  ///
  /// \sa SDL_GameControllerRumble
  int SDL_GameControllerHasRumble(
    ffi.Pointer<SDL_GameController1> gamecontroller,
  ) {
    return _SDL_GameControllerHasRumble(
      gamecontroller,
    );
  }

  late final _SDL_GameControllerHasRumblePtr = _lookup<
          ffi.NativeFunction<
              ffi.Int32 Function(ffi.Pointer<SDL_GameController1>)>>(
      'SDL_GameControllerHasRumble');
  late final _SDL_GameControllerHasRumble = _SDL_GameControllerHasRumblePtr
      .asFunction<int Function(ffi.Pointer<SDL_GameController1>)>();

  /// Query whether a game controller has rumble support on triggers.
  ///
  /// \param gamecontroller The controller to query
  /// \returns SDL_TRUE, or SDL_FALSE if this controller does not have trigger
  /// rumble support
  ///
  /// \since This function is available since SDL 2.0.18.
  ///
  /// \sa SDL_GameControllerRumbleTriggers
  int SDL_GameControllerHasRumbleTriggers(
    ffi.Pointer<SDL_GameController1> gamecontroller,
  ) {
    return _SDL_GameControllerHasRumbleTriggers(
      gamecontroller,
    );
  }

  late final _SDL_GameControllerHasRumbleTriggersPtr = _lookup<
          ffi.NativeFunction<
              ffi.Int32 Function(ffi.Pointer<SDL_GameController1>)>>(
      'SDL_GameControllerHasRumbleTriggers');
  late final _SDL_GameControllerHasRumbleTriggers =
      _SDL_GameControllerHasRumbleTriggersPtr.asFunction<
          int Function(ffi.Pointer<SDL_GameController1>)>();

  /// Update a game controller's LED color.
  ///
  /// \param gamecontroller The controller to update
  /// \param red The intensity of the red LED
  /// \param green The intensity of the green LED
  /// \param blue The intensity of the blue LED
  /// \returns 0, or -1 if this controller does not have a modifiable LED
  ///
  /// \since This function is available since SDL 2.0.14.
  int SDL_GameControllerSetLED(
    ffi.Pointer<SDL_GameController1> gamecontroller,
    int red,
    int green,
    int blue,
  ) {
    return _SDL_GameControllerSetLED(
      gamecontroller,
      red,
      green,
      blue,
    );
  }

  late final _SDL_GameControllerSetLEDPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_GameController1>, Uint8, Uint8,
              Uint8)>>('SDL_GameControllerSetLED');
  late final _SDL_GameControllerSetLED =
      _SDL_GameControllerSetLEDPtr.asFunction<
          int Function(ffi.Pointer<SDL_GameController1>, int, int, int)>();

  /// Send a controller specific effect packet
  ///
  /// \param gamecontroller The controller to affect
  /// \param data The data to send to the controller
  /// \param size The size of the data to send to the controller
  /// \returns 0, or -1 if this controller or driver doesn't support effect
  /// packets
  ///
  /// \since This function is available since SDL 2.0.16.
  int SDL_GameControllerSendEffect(
    ffi.Pointer<SDL_GameController1> gamecontroller,
    ffi.Pointer<ffi.Void> data,
    int size,
  ) {
    return _SDL_GameControllerSendEffect(
      gamecontroller,
      data,
      size,
    );
  }

  late final _SDL_GameControllerSendEffectPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<SDL_GameController1>,
              ffi.Pointer<ffi.Void>,
              ffi.Int32)>>('SDL_GameControllerSendEffect');
  late final _SDL_GameControllerSendEffect =
      _SDL_GameControllerSendEffectPtr.asFunction<
          int Function(
              ffi.Pointer<SDL_GameController1>, ffi.Pointer<ffi.Void>, int)>();

  /// Close a game controller previously opened with SDL_GameControllerOpen().
  ///
  /// \param gamecontroller a game controller identifier previously returned by
  /// SDL_GameControllerOpen()
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GameControllerOpen
  void SDL_GameControllerClose(
    ffi.Pointer<SDL_GameController1> gamecontroller,
  ) {
    return _SDL_GameControllerClose(
      gamecontroller,
    );
  }

  late final _SDL_GameControllerClosePtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<SDL_GameController1>)>>('SDL_GameControllerClose');
  late final _SDL_GameControllerClose = _SDL_GameControllerClosePtr.asFunction<
      void Function(ffi.Pointer<SDL_GameController1>)>();

  /// Return the sfSymbolsName for a given button on a game controller on Apple
  /// platforms.
  ///
  /// \param gamecontroller the controller to query
  /// \param button a button on the game controller
  /// \returns the sfSymbolsName or NULL if the name can't be found
  ///
  /// \since This function is available since SDL 2.0.18.
  ///
  /// \sa SDL_GameControllerGetAppleSFSymbolsNameForAxis
  ffi.Pointer<ffi.Int8> SDL_GameControllerGetAppleSFSymbolsNameForButton(
    ffi.Pointer<SDL_GameController1> gamecontroller,
    int button,
  ) {
    return _SDL_GameControllerGetAppleSFSymbolsNameForButton(
      gamecontroller,
      button,
    );
  }

  late final _SDL_GameControllerGetAppleSFSymbolsNameForButtonPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Int8> Function(ffi.Pointer<SDL_GameController1>,
              ffi.Int32)>>('SDL_GameControllerGetAppleSFSymbolsNameForButton');
  late final _SDL_GameControllerGetAppleSFSymbolsNameForButton =
      _SDL_GameControllerGetAppleSFSymbolsNameForButtonPtr.asFunction<
          ffi.Pointer<ffi.Int8> Function(
              ffi.Pointer<SDL_GameController1>, int)>();

  /// Return the sfSymbolsName for a given axis on a game controller on Apple
  /// platforms.
  ///
  /// \param gamecontroller the controller to query
  /// \param axis an axis on the game controller
  /// \returns the sfSymbolsName or NULL if the name can't be found
  ///
  /// \since This function is available since SDL 2.0.18.
  ///
  /// \sa SDL_GameControllerGetAppleSFSymbolsNameForButton
  ffi.Pointer<ffi.Int8> SDL_GameControllerGetAppleSFSymbolsNameForAxis(
    ffi.Pointer<SDL_GameController1> gamecontroller,
    int axis,
  ) {
    return _SDL_GameControllerGetAppleSFSymbolsNameForAxis(
      gamecontroller,
      axis,
    );
  }

  late final _SDL_GameControllerGetAppleSFSymbolsNameForAxisPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Int8> Function(ffi.Pointer<SDL_GameController1>,
              ffi.Int32)>>('SDL_GameControllerGetAppleSFSymbolsNameForAxis');
  late final _SDL_GameControllerGetAppleSFSymbolsNameForAxis =
      _SDL_GameControllerGetAppleSFSymbolsNameForAxisPtr.asFunction<
          ffi.Pointer<ffi.Int8> Function(
              ffi.Pointer<SDL_GameController1>, int)>();

  /// Get the number of registered touch devices.
  ///
  /// On some platforms SDL first sees the touch device if it was actually used.
  /// Therefore SDL_GetNumTouchDevices() may return 0 although devices are
  /// available. After using all devices at least once the number will be
  /// correct.
  ///
  /// This was fixed for Android in SDL 2.0.1.
  ///
  /// \returns the number of registered touch devices.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetTouchDevice
  int SDL_GetNumTouchDevices() {
    return _SDL_GetNumTouchDevices();
  }

  late final _SDL_GetNumTouchDevicesPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function()>>(
          'SDL_GetNumTouchDevices');
  late final _SDL_GetNumTouchDevices =
      _SDL_GetNumTouchDevicesPtr.asFunction<int Function()>();

  /// Get the touch ID with the given index.
  ///
  /// \param index the touch device index
  /// \returns the touch ID with the given index on success or 0 if the index is
  /// invalid; call SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetNumTouchDevices
  int SDL_GetTouchDevice(
    int index,
  ) {
    return _SDL_GetTouchDevice(
      index,
    );
  }

  late final _SDL_GetTouchDevicePtr =
      _lookup<ffi.NativeFunction<SDL_TouchID Function(ffi.Int32)>>(
          'SDL_GetTouchDevice');
  late final _SDL_GetTouchDevice =
      _SDL_GetTouchDevicePtr.asFunction<int Function(int)>();

  /// Get the type of the given touch device.
  ///
  /// \since This function is available since SDL 2.0.10.
  int SDL_GetTouchDeviceType(
    int touchID,
  ) {
    return _SDL_GetTouchDeviceType(
      touchID,
    );
  }

  late final _SDL_GetTouchDeviceTypePtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(SDL_TouchID)>>(
          'SDL_GetTouchDeviceType');
  late final _SDL_GetTouchDeviceType =
      _SDL_GetTouchDeviceTypePtr.asFunction<int Function(int)>();

  /// Get the number of active fingers for a given touch device.
  ///
  /// \param touchID the ID of a touch device
  /// \returns the number of active fingers for a given touch device on success
  /// or 0 on failure; call SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetTouchFinger
  int SDL_GetNumTouchFingers(
    int touchID,
  ) {
    return _SDL_GetNumTouchFingers(
      touchID,
    );
  }

  late final _SDL_GetNumTouchFingersPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(SDL_TouchID)>>(
          'SDL_GetNumTouchFingers');
  late final _SDL_GetNumTouchFingers =
      _SDL_GetNumTouchFingersPtr.asFunction<int Function(int)>();

  /// Get the finger object for specified touch device ID and finger index.
  ///
  /// The returned resource is owned by SDL and should not be deallocated.
  ///
  /// \param touchID the ID of the requested touch device
  /// \param index the index of the requested finger
  /// \returns a pointer to the SDL_Finger object or NULL if no object at the
  /// given ID and index could be found.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_RecordGesture
  ffi.Pointer<SDL_Finger> SDL_GetTouchFinger(
    int touchID,
    int index,
  ) {
    return _SDL_GetTouchFinger(
      touchID,
      index,
    );
  }

  late final _SDL_GetTouchFingerPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<SDL_Finger> Function(
              SDL_TouchID, ffi.Int32)>>('SDL_GetTouchFinger');
  late final _SDL_GetTouchFinger = _SDL_GetTouchFingerPtr.asFunction<
      ffi.Pointer<SDL_Finger> Function(int, int)>();

  /// Begin recording a gesture on a specified touch device or all touch devices.
  ///
  /// If the parameter `touchId` is -1 (i.e., all devices), this function will
  /// always return 1, regardless of whether there actually are any devices.
  ///
  /// \param touchId the touch device id, or -1 for all touch devices
  /// \returns 1 on success or 0 if the specified device could not be found.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetTouchDevice
  int SDL_RecordGesture(
    int touchId,
  ) {
    return _SDL_RecordGesture(
      touchId,
    );
  }

  late final _SDL_RecordGesturePtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(SDL_TouchID)>>(
          'SDL_RecordGesture');
  late final _SDL_RecordGesture =
      _SDL_RecordGesturePtr.asFunction<int Function(int)>();

  /// Save all currently loaded Dollar Gesture templates.
  ///
  /// \param dst a SDL_RWops to save to
  /// \returns the number of saved templates on success or 0 on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_LoadDollarTemplates
  /// \sa SDL_SaveDollarTemplate
  int SDL_SaveAllDollarTemplates(
    ffi.Pointer<SDL_RWops> dst,
  ) {
    return _SDL_SaveAllDollarTemplates(
      dst,
    );
  }

  late final _SDL_SaveAllDollarTemplatesPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<SDL_RWops>)>>(
          'SDL_SaveAllDollarTemplates');
  late final _SDL_SaveAllDollarTemplates = _SDL_SaveAllDollarTemplatesPtr
      .asFunction<int Function(ffi.Pointer<SDL_RWops>)>();

  /// Save a currently loaded Dollar Gesture template.
  ///
  /// \param gestureId a gesture id
  /// \param dst a SDL_RWops to save to
  /// \returns 1 on success or 0 on failure; call SDL_GetError() for more
  /// information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_LoadDollarTemplates
  /// \sa SDL_SaveAllDollarTemplates
  int SDL_SaveDollarTemplate(
    int gestureId,
    ffi.Pointer<SDL_RWops> dst,
  ) {
    return _SDL_SaveDollarTemplate(
      gestureId,
      dst,
    );
  }

  late final _SDL_SaveDollarTemplatePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(SDL_GestureID,
              ffi.Pointer<SDL_RWops>)>>('SDL_SaveDollarTemplate');
  late final _SDL_SaveDollarTemplate = _SDL_SaveDollarTemplatePtr.asFunction<
      int Function(int, ffi.Pointer<SDL_RWops>)>();

  /// Load Dollar Gesture templates from a file.
  ///
  /// \param touchId a touch id
  /// \param src a SDL_RWops to load from
  /// \returns the number of loaded templates on success or a negative error code
  /// (or 0) on failure; call SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_SaveAllDollarTemplates
  /// \sa SDL_SaveDollarTemplate
  int SDL_LoadDollarTemplates(
    int touchId,
    ffi.Pointer<SDL_RWops> src,
  ) {
    return _SDL_LoadDollarTemplates(
      touchId,
      src,
    );
  }

  late final _SDL_LoadDollarTemplatesPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              SDL_TouchID, ffi.Pointer<SDL_RWops>)>>('SDL_LoadDollarTemplates');
  late final _SDL_LoadDollarTemplates = _SDL_LoadDollarTemplatesPtr.asFunction<
      int Function(int, ffi.Pointer<SDL_RWops>)>();

  /// Pump the event loop, gathering events from the input devices.
  ///
  /// This function updates the event queue and internal input device state.
  ///
  /// **WARNING**: This should only be run in the thread that initialized the
  /// video subsystem, and for extra safety, you should consider only doing those
  /// things on the main thread in any case.
  ///
  /// SDL_PumpEvents() gathers all the pending input information from devices and
  /// places it in the event queue. Without calls to SDL_PumpEvents() no events
  /// would ever be placed on the queue. Often the need for calls to
  /// SDL_PumpEvents() is hidden from the user since SDL_PollEvent() and
  /// SDL_WaitEvent() implicitly call SDL_PumpEvents(). However, if you are not
  /// polling or waiting for events (e.g. you are filtering them), then you must
  /// call SDL_PumpEvents() to force an event queue update.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_PollEvent
  /// \sa SDL_WaitEvent
  void SDL_PumpEvents() {
    return _SDL_PumpEvents();
  }

  late final _SDL_PumpEventsPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('SDL_PumpEvents');
  late final _SDL_PumpEvents = _SDL_PumpEventsPtr.asFunction<void Function()>();

  /// Check the event queue for messages and optionally return them.
  ///
  /// `action` may be any of the following:
  ///
  /// - `SDL_ADDEVENT`: up to `numevents` events will be added to the back of the
  /// event queue.
  /// - `SDL_PEEKEVENT`: `numevents` events at the front of the event queue,
  /// within the specified minimum and maximum type, will be returned to the
  /// caller and will _not_ be removed from the queue.
  /// - `SDL_GETEVENT`: up to `numevents` events at the front of the event queue,
  /// within the specified minimum and maximum type, will be returned to the
  /// caller and will be removed from the queue.
  ///
  /// You may have to call SDL_PumpEvents() before calling this function.
  /// Otherwise, the events may not be ready to be filtered when you call
  /// SDL_PeepEvents().
  ///
  /// This function is thread-safe.
  ///
  /// \param events destination buffer for the retrieved events
  /// \param numevents if action is SDL_ADDEVENT, the number of events to add
  /// back to the event queue; if action is SDL_PEEKEVENT or
  /// SDL_GETEVENT, the maximum number of events to retrieve
  /// \param action action to take; see [[#action|Remarks]] for details
  /// \param minType minimum value of the event type to be considered;
  /// SDL_FIRSTEVENT is a safe choice
  /// \param maxType maximum value of the event type to be considered;
  /// SDL_LASTEVENT is a safe choice
  /// \returns the number of events actually stored or a negative error code on
  /// failure; call SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_PollEvent
  /// \sa SDL_PumpEvents
  /// \sa SDL_PushEvent
  int SDL_PeepEvents(
    ffi.Pointer<SDL_Event> events,
    int numevents,
    int action,
    int minType,
    int maxType,
  ) {
    return _SDL_PeepEvents(
      events,
      numevents,
      action,
      minType,
      maxType,
    );
  }

  late final _SDL_PeepEventsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_Event>, ffi.Int32, ffi.Int32,
              Uint32, Uint32)>>('SDL_PeepEvents');
  late final _SDL_PeepEvents = _SDL_PeepEventsPtr.asFunction<
      int Function(ffi.Pointer<SDL_Event>, int, int, int, int)>();

  /// Check for the existence of a certain event type in the event queue.
  ///
  /// If you need to check for a range of event types, use SDL_HasEvents()
  /// instead.
  ///
  /// \param type the type of event to be queried; see SDL_EventType for details
  /// \returns SDL_TRUE if events matching `type` are present, or SDL_FALSE if
  /// events matching `type` are not present.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_HasEvents
  int SDL_HasEvent(
    int type,
  ) {
    return _SDL_HasEvent(
      type,
    );
  }

  late final _SDL_HasEventPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(Uint32)>>('SDL_HasEvent');
  late final _SDL_HasEvent = _SDL_HasEventPtr.asFunction<int Function(int)>();

  /// Check for the existence of certain event types in the event queue.
  ///
  /// If you need to check for a single event type, use SDL_HasEvent() instead.
  ///
  /// \param minType the low end of event type to be queried, inclusive; see
  /// SDL_EventType for details
  /// \param maxType the high end of event type to be queried, inclusive; see
  /// SDL_EventType for details
  /// \returns SDL_TRUE if events with type >= `minType` and <= `maxType` are
  /// present, or SDL_FALSE if not.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_HasEvents
  int SDL_HasEvents(
    int minType,
    int maxType,
  ) {
    return _SDL_HasEvents(
      minType,
      maxType,
    );
  }

  late final _SDL_HasEventsPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(Uint32, Uint32)>>(
          'SDL_HasEvents');
  late final _SDL_HasEvents =
      _SDL_HasEventsPtr.asFunction<int Function(int, int)>();

  /// Clear events of a specific type from the event queue.
  ///
  /// This will unconditionally remove any events from the queue that match
  /// `type`. If you need to remove a range of event types, use SDL_FlushEvents()
  /// instead.
  ///
  /// It's also normal to just ignore events you don't care about in your event
  /// loop without calling this function.
  ///
  /// This function only affects currently queued events. If you want to make
  /// sure that all pending OS events are flushed, you can call SDL_PumpEvents()
  /// on the main thread immediately before the flush call.
  ///
  /// \param type the type of event to be cleared; see SDL_EventType for details
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_FlushEvents
  void SDL_FlushEvent(
    int type,
  ) {
    return _SDL_FlushEvent(
      type,
    );
  }

  late final _SDL_FlushEventPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(Uint32)>>('SDL_FlushEvent');
  late final _SDL_FlushEvent =
      _SDL_FlushEventPtr.asFunction<void Function(int)>();

  /// Clear events of a range of types from the event queue.
  ///
  /// This will unconditionally remove any events from the queue that are in the
  /// range of `minType` to `maxType`, inclusive. If you need to remove a single
  /// event type, use SDL_FlushEvent() instead.
  ///
  /// It's also normal to just ignore events you don't care about in your event
  /// loop without calling this function.
  ///
  /// This function only affects currently queued events. If you want to make
  /// sure that all pending OS events are flushed, you can call SDL_PumpEvents()
  /// on the main thread immediately before the flush call.
  ///
  /// \param minType the low end of event type to be cleared, inclusive; see
  /// SDL_EventType for details
  /// \param maxType the high end of event type to be cleared, inclusive; see
  /// SDL_EventType for details
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_FlushEvent
  void SDL_FlushEvents(
    int minType,
    int maxType,
  ) {
    return _SDL_FlushEvents(
      minType,
      maxType,
    );
  }

  late final _SDL_FlushEventsPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(Uint32, Uint32)>>(
          'SDL_FlushEvents');
  late final _SDL_FlushEvents =
      _SDL_FlushEventsPtr.asFunction<void Function(int, int)>();

  /// Poll for currently pending events.
  ///
  /// If `event` is not NULL, the next event is removed from the queue and stored
  /// in the SDL_Event structure pointed to by `event`. The 1 returned refers to
  /// this event, immediately stored in the SDL Event structure -- not an event
  /// to follow.
  ///
  /// If `event` is NULL, it simply returns 1 if there is an event in the queue,
  /// but will not remove it from the queue.
  ///
  /// As this function may implicitly call SDL_PumpEvents(), you can only call
  /// this function in the thread that set the video mode.
  ///
  /// SDL_PollEvent() is the favored way of receiving system events since it can
  /// be done from the main loop and does not suspend the main loop while waiting
  /// on an event to be posted.
  ///
  /// The common practice is to fully process the event queue once every frame,
  /// usually as a first step before updating the game's state:
  ///
  /// ```c
  /// while (game_is_still_running) {
  /// SDL_Event event;
  /// while (SDL_PollEvent(&event)) {  // poll until all events are handled!
  /// // decide what to do with this event.
  /// }
  ///
  /// // update game state, draw the current frame
  /// }
  /// ```
  ///
  /// \param event the SDL_Event structure to be filled with the next event from
  /// the queue, or NULL
  /// \returns 1 if there is a pending event or 0 if there are none available.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetEventFilter
  /// \sa SDL_PeepEvents
  /// \sa SDL_PushEvent
  /// \sa SDL_SetEventFilter
  /// \sa SDL_WaitEvent
  /// \sa SDL_WaitEventTimeout
  int SDL_PollEvent(
    ffi.Pointer<SDL_Event> event,
  ) {
    return _SDL_PollEvent(
      event,
    );
  }

  late final _SDL_PollEventPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<SDL_Event>)>>(
          'SDL_PollEvent');
  late final _SDL_PollEvent =
      _SDL_PollEventPtr.asFunction<int Function(ffi.Pointer<SDL_Event>)>();

  /// Wait indefinitely for the next available event.
  ///
  /// If `event` is not NULL, the next event is removed from the queue and stored
  /// in the SDL_Event structure pointed to by `event`.
  ///
  /// As this function may implicitly call SDL_PumpEvents(), you can only call
  /// this function in the thread that initialized the video subsystem.
  ///
  /// \param event the SDL_Event structure to be filled in with the next event
  /// from the queue, or NULL
  /// \returns 1 on success or 0 if there was an error while waiting for events;
  /// call SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_PollEvent
  /// \sa SDL_PumpEvents
  /// \sa SDL_WaitEventTimeout
  int SDL_WaitEvent(
    ffi.Pointer<SDL_Event> event,
  ) {
    return _SDL_WaitEvent(
      event,
    );
  }

  late final _SDL_WaitEventPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<SDL_Event>)>>(
          'SDL_WaitEvent');
  late final _SDL_WaitEvent =
      _SDL_WaitEventPtr.asFunction<int Function(ffi.Pointer<SDL_Event>)>();

  /// Wait until the specified timeout (in milliseconds) for the next available
  /// event.
  ///
  /// If `event` is not NULL, the next event is removed from the queue and stored
  /// in the SDL_Event structure pointed to by `event`.
  ///
  /// As this function may implicitly call SDL_PumpEvents(), you can only call
  /// this function in the thread that initialized the video subsystem.
  ///
  /// \param event the SDL_Event structure to be filled in with the next event
  /// from the queue, or NULL
  /// \param timeout the maximum number of milliseconds to wait for the next
  /// available event
  /// \returns 1 on success or 0 if there was an error while waiting for events;
  /// call SDL_GetError() for more information. This also returns 0 if
  /// the timeout elapsed without an event arriving.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_PollEvent
  /// \sa SDL_PumpEvents
  /// \sa SDL_WaitEvent
  int SDL_WaitEventTimeout(
    ffi.Pointer<SDL_Event> event,
    int timeout,
  ) {
    return _SDL_WaitEventTimeout(
      event,
      timeout,
    );
  }

  late final _SDL_WaitEventTimeoutPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<SDL_Event>, ffi.Int32)>>('SDL_WaitEventTimeout');
  late final _SDL_WaitEventTimeout = _SDL_WaitEventTimeoutPtr.asFunction<
      int Function(ffi.Pointer<SDL_Event>, int)>();

  /// Add an event to the event queue.
  ///
  /// The event queue can actually be used as a two way communication channel.
  /// Not only can events be read from the queue, but the user can also push
  /// their own events onto it. `event` is a pointer to the event structure you
  /// wish to push onto the queue. The event is copied into the queue, and the
  /// caller may dispose of the memory pointed to after SDL_PushEvent() returns.
  ///
  /// Note: Pushing device input events onto the queue doesn't modify the state
  /// of the device within SDL.
  ///
  /// This function is thread-safe, and can be called from other threads safely.
  ///
  /// Note: Events pushed onto the queue with SDL_PushEvent() get passed through
  /// the event filter but events added with SDL_PeepEvents() do not.
  ///
  /// For pushing application-specific events, please use SDL_RegisterEvents() to
  /// get an event type that does not conflict with other code that also wants
  /// its own custom event types.
  ///
  /// \param event the SDL_Event to be added to the queue
  /// \returns 1 on success, 0 if the event was filtered, or a negative error
  /// code on failure; call SDL_GetError() for more information. A
  /// common reason for error is the event queue being full.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_PeepEvents
  /// \sa SDL_PollEvent
  /// \sa SDL_RegisterEvents
  int SDL_PushEvent(
    ffi.Pointer<SDL_Event> event,
  ) {
    return _SDL_PushEvent(
      event,
    );
  }

  late final _SDL_PushEventPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<SDL_Event>)>>(
          'SDL_PushEvent');
  late final _SDL_PushEvent =
      _SDL_PushEventPtr.asFunction<int Function(ffi.Pointer<SDL_Event>)>();

  /// Set up a filter to process all events before they change internal state and
  /// are posted to the internal event queue.
  ///
  /// If the filter function returns 1 when called, then the event will be added
  /// to the internal queue. If it returns 0, then the event will be dropped from
  /// the queue, but the internal state will still be updated. This allows
  /// selective filtering of dynamically arriving events.
  ///
  /// **WARNING**: Be very careful of what you do in the event filter function,
  /// as it may run in a different thread!
  ///
  /// On platforms that support it, if the quit event is generated by an
  /// interrupt signal (e.g. pressing Ctrl-C), it will be delivered to the
  /// application at the next event poll.
  ///
  /// There is one caveat when dealing with the ::SDL_QuitEvent event type. The
  /// event filter is only called when the window manager desires to close the
  /// application window. If the event filter returns 1, then the window will be
  /// closed, otherwise the window will remain open if possible.
  ///
  /// Note: Disabled events never make it to the event filter function; see
  /// SDL_EventState().
  ///
  /// Note: If you just want to inspect events without filtering, you should use
  /// SDL_AddEventWatch() instead.
  ///
  /// Note: Events pushed onto the queue with SDL_PushEvent() get passed through
  /// the event filter, but events pushed onto the queue with SDL_PeepEvents() do
  /// not.
  ///
  /// \param filter An SDL_EventFilter function to call when an event happens
  /// \param userdata a pointer that is passed to `filter`
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_AddEventWatch
  /// \sa SDL_EventState
  /// \sa SDL_GetEventFilter
  /// \sa SDL_PeepEvents
  /// \sa SDL_PushEvent
  void SDL_SetEventFilter(
    SDL_EventFilter filter,
    ffi.Pointer<ffi.Void> userdata,
  ) {
    return _SDL_SetEventFilter(
      filter,
      userdata,
    );
  }

  late final _SDL_SetEventFilterPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              SDL_EventFilter, ffi.Pointer<ffi.Void>)>>('SDL_SetEventFilter');
  late final _SDL_SetEventFilter = _SDL_SetEventFilterPtr.asFunction<
      void Function(SDL_EventFilter, ffi.Pointer<ffi.Void>)>();

  /// Query the current event filter.
  ///
  /// This function can be used to "chain" filters, by saving the existing filter
  /// before replacing it with a function that will call that saved filter.
  ///
  /// \param filter the current callback function will be stored here
  /// \param userdata the pointer that is passed to the current event filter will
  /// be stored here
  /// \returns SDL_TRUE on success or SDL_FALSE if there is no event filter set.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_SetEventFilter
  int SDL_GetEventFilter(
    ffi.Pointer<SDL_EventFilter> filter,
    ffi.Pointer<ffi.Pointer<ffi.Void>> userdata,
  ) {
    return _SDL_GetEventFilter(
      filter,
      userdata,
    );
  }

  late final _SDL_GetEventFilterPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_EventFilter>,
              ffi.Pointer<ffi.Pointer<ffi.Void>>)>>('SDL_GetEventFilter');
  late final _SDL_GetEventFilter = _SDL_GetEventFilterPtr.asFunction<
      int Function(
          ffi.Pointer<SDL_EventFilter>, ffi.Pointer<ffi.Pointer<ffi.Void>>)>();

  /// Add a callback to be triggered when an event is added to the event queue.
  ///
  /// `filter` will be called when an event happens, and its return value is
  /// ignored.
  ///
  /// **WARNING**: Be very careful of what you do in the event filter function,
  /// as it may run in a different thread!
  ///
  /// If the quit event is generated by a signal (e.g. SIGINT), it will bypass
  /// the internal queue and be delivered to the watch callback immediately, and
  /// arrive at the next event poll.
  ///
  /// Note: the callback is called for events posted by the user through
  /// SDL_PushEvent(), but not for disabled events, nor for events by a filter
  /// callback set with SDL_SetEventFilter(), nor for events posted by the user
  /// through SDL_PeepEvents().
  ///
  /// \param filter an SDL_EventFilter function to call when an event happens.
  /// \param userdata a pointer that is passed to `filter`
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_DelEventWatch
  /// \sa SDL_SetEventFilter
  void SDL_AddEventWatch(
    SDL_EventFilter filter,
    ffi.Pointer<ffi.Void> userdata,
  ) {
    return _SDL_AddEventWatch(
      filter,
      userdata,
    );
  }

  late final _SDL_AddEventWatchPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              SDL_EventFilter, ffi.Pointer<ffi.Void>)>>('SDL_AddEventWatch');
  late final _SDL_AddEventWatch = _SDL_AddEventWatchPtr.asFunction<
      void Function(SDL_EventFilter, ffi.Pointer<ffi.Void>)>();

  /// Remove an event watch callback added with SDL_AddEventWatch().
  ///
  /// This function takes the same input as SDL_AddEventWatch() to identify and
  /// delete the corresponding callback.
  ///
  /// \param filter the function originally passed to SDL_AddEventWatch()
  /// \param userdata the pointer originally passed to SDL_AddEventWatch()
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_AddEventWatch
  void SDL_DelEventWatch(
    SDL_EventFilter filter,
    ffi.Pointer<ffi.Void> userdata,
  ) {
    return _SDL_DelEventWatch(
      filter,
      userdata,
    );
  }

  late final _SDL_DelEventWatchPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              SDL_EventFilter, ffi.Pointer<ffi.Void>)>>('SDL_DelEventWatch');
  late final _SDL_DelEventWatch = _SDL_DelEventWatchPtr.asFunction<
      void Function(SDL_EventFilter, ffi.Pointer<ffi.Void>)>();

  /// Run a specific filter function on the current event queue, removing any
  /// events for which the filter returns 0.
  ///
  /// See SDL_SetEventFilter() for more information. Unlike SDL_SetEventFilter(),
  /// this function does not change the filter permanently, it only uses the
  /// supplied filter until this function returns.
  ///
  /// \param filter the SDL_EventFilter function to call when an event happens
  /// \param userdata a pointer that is passed to `filter`
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetEventFilter
  /// \sa SDL_SetEventFilter
  void SDL_FilterEvents(
    SDL_EventFilter filter,
    ffi.Pointer<ffi.Void> userdata,
  ) {
    return _SDL_FilterEvents(
      filter,
      userdata,
    );
  }

  late final _SDL_FilterEventsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              SDL_EventFilter, ffi.Pointer<ffi.Void>)>>('SDL_FilterEvents');
  late final _SDL_FilterEvents = _SDL_FilterEventsPtr.asFunction<
      void Function(SDL_EventFilter, ffi.Pointer<ffi.Void>)>();

  /// Set the state of processing events by type.
  ///
  /// `state` may be any of the following:
  ///
  /// - `SDL_QUERY`: returns the current processing state of the specified event
  /// - `SDL_IGNORE` (aka `SDL_DISABLE`): the event will automatically be dropped
  /// from the event queue and will not be filtered
  /// - `SDL_ENABLE`: the event will be processed normally
  ///
  /// \param type the type of event; see SDL_EventType for details
  /// \param state how to process the event
  /// \returns `SDL_DISABLE` or `SDL_ENABLE`, representing the processing state
  /// of the event before this function makes any changes to it.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetEventState
  int SDL_EventState(
    int type,
    int state,
  ) {
    return _SDL_EventState(
      type,
      state,
    );
  }

  late final _SDL_EventStatePtr =
      _lookup<ffi.NativeFunction<Uint8 Function(Uint32, ffi.Int32)>>(
          'SDL_EventState');
  late final _SDL_EventState =
      _SDL_EventStatePtr.asFunction<int Function(int, int)>();

  /// Allocate a set of user-defined events, and return the beginning event
  /// number for that set of events.
  ///
  /// Calling this function with `numevents` <= 0 is an error and will return
  /// (Uint32)-1.
  ///
  /// Note, (Uint32)-1 means the maximum unsigned 32-bit integer value (or
  /// 0xFFFFFFFF), but is clearer to write.
  ///
  /// \param numevents the number of events to be allocated
  /// \returns the beginning event number, or (Uint32)-1 if there are not enough
  /// user-defined events left.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_PushEvent
  int SDL_RegisterEvents(
    int numevents,
  ) {
    return _SDL_RegisterEvents(
      numevents,
    );
  }

  late final _SDL_RegisterEventsPtr =
      _lookup<ffi.NativeFunction<Uint32 Function(ffi.Int32)>>(
          'SDL_RegisterEvents');
  late final _SDL_RegisterEvents =
      _SDL_RegisterEventsPtr.asFunction<int Function(int)>();

  /// Get the directory where the application was run from.
  ///
  /// This is not necessarily a fast call, so you should call this once near
  /// startup and save the string if you need it.
  ///
  /// **Mac OS X and iOS Specific Functionality**: If the application is in a
  /// ".app" bundle, this function returns the Resource directory (e.g.
  /// MyApp.app/Contents/Resources/). This behaviour can be overridden by adding
  /// a property to the Info.plist file. Adding a string key with the name
  /// SDL_FILESYSTEM_BASE_DIR_TYPE with a supported value will change the
  /// behaviour.
  ///
  /// Supported values for the SDL_FILESYSTEM_BASE_DIR_TYPE property (Given an
  /// application in /Applications/SDLApp/MyApp.app):
  ///
  /// - `resource`: bundle resource directory (the default). For example:
  /// `/Applications/SDLApp/MyApp.app/Contents/Resources`
  /// - `bundle`: the Bundle directory. For example:
  /// `/Applications/SDLApp/MyApp.app/`
  /// - `parent`: the containing directory of the bundle. For example:
  /// `/Applications/SDLApp/`
  ///
  /// The returned path is guaranteed to end with a path separator ('\' on
  /// Windows, '/' on most other platforms).
  ///
  /// The pointer returned is owned by the caller. Please call SDL_free() on the
  /// pointer when done with it.
  ///
  /// \returns an absolute path in UTF-8 encoding to the application data
  /// directory. NULL will be returned on error or when the platform
  /// doesn't implement this functionality, call SDL_GetError() for more
  /// information.
  ///
  /// \since This function is available since SDL 2.0.1.
  ///
  /// \sa SDL_GetPrefPath
  ffi.Pointer<ffi.Int8> SDL_GetBasePath() {
    return _SDL_GetBasePath();
  }

  late final _SDL_GetBasePathPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Int8> Function()>>(
          'SDL_GetBasePath');
  late final _SDL_GetBasePath =
      _SDL_GetBasePathPtr.asFunction<ffi.Pointer<ffi.Int8> Function()>();

  /// Get the user-and-app-specific path where files can be written.
  ///
  /// Get the "pref dir". This is meant to be where users can write personal
  /// files (preferences and save games, etc) that are specific to your
  /// application. This directory is unique per user, per application.
  ///
  /// This function will decide the appropriate location in the native
  /// filesystem, create the directory if necessary, and return a string of the
  /// absolute path to the directory in UTF-8 encoding.
  ///
  /// On Windows, the string might look like:
  ///
  /// `C:\\Users\\bob\\AppData\\Roaming\\My Company\\My Program Name\\`
  ///
  /// On Linux, the string might look like"
  ///
  /// `/home/bob/.local/share/My Program Name/`
  ///
  /// On Mac OS X, the string might look like:
  ///
  /// `/Users/bob/Library/Application Support/My Program Name/`
  ///
  /// You should assume the path returned by this function is the only safe place
  /// to write files (and that SDL_GetBasePath(), while it might be writable, or
  /// even the parent of the returned path, isn't where you should be writing
  /// things).
  ///
  /// Both the org and app strings may become part of a directory name, so please
  /// follow these rules:
  ///
  /// - Try to use the same org string (_including case-sensitivity_) for all
  /// your applications that use this function.
  /// - Always use a unique app string for each one, and make sure it never
  /// changes for an app once you've decided on it.
  /// - Unicode characters are legal, as long as it's UTF-8 encoded, but...
  /// - ...only use letters, numbers, and spaces. Avoid punctuation like "Game
  /// Name 2: Bad Guy's Revenge!" ... "Game Name 2" is sufficient.
  ///
  /// The returned path is guaranteed to end with a path separator ('\' on
  /// Windows, '/' on most other platforms).
  ///
  /// The pointer returned is owned by the caller. Please call SDL_free() on the
  /// pointer when done with it.
  ///
  /// \param org the name of your organization
  /// \param app the name of your application
  /// \returns a UTF-8 string of the user directory in platform-dependent
  /// notation. NULL if there's a problem (creating directory failed,
  /// etc.).
  ///
  /// \since This function is available since SDL 2.0.1.
  ///
  /// \sa SDL_GetBasePath
  ffi.Pointer<ffi.Int8> SDL_GetPrefPath(
    ffi.Pointer<ffi.Int8> org,
    ffi.Pointer<ffi.Int8> app,
  ) {
    return _SDL_GetPrefPath(
      org,
      app,
    );
  }

  late final _SDL_GetPrefPathPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Int8> Function(ffi.Pointer<ffi.Int8>,
              ffi.Pointer<ffi.Int8>)>>('SDL_GetPrefPath');
  late final _SDL_GetPrefPath = _SDL_GetPrefPathPtr.asFunction<
      ffi.Pointer<ffi.Int8> Function(
          ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Int8>)>();

  /// Count the number of haptic devices attached to the system.
  ///
  /// \returns the number of haptic devices detected on the system or a negative
  /// error code on failure; call SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_HapticName
  int SDL_NumHaptics() {
    return _SDL_NumHaptics();
  }

  late final _SDL_NumHapticsPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function()>>('SDL_NumHaptics');
  late final _SDL_NumHaptics = _SDL_NumHapticsPtr.asFunction<int Function()>();

  /// Get the implementation dependent name of a haptic device.
  ///
  /// This can be called before any joysticks are opened. If no name can be
  /// found, this function returns NULL.
  ///
  /// \param device_index index of the device to query.
  /// \returns the name of the device or NULL on failure; call SDL_GetError() for
  /// more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_NumHaptics
  ffi.Pointer<ffi.Int8> SDL_HapticName(
    int device_index,
  ) {
    return _SDL_HapticName(
      device_index,
    );
  }

  late final _SDL_HapticNamePtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Int8> Function(ffi.Int32)>>(
          'SDL_HapticName');
  late final _SDL_HapticName =
      _SDL_HapticNamePtr.asFunction<ffi.Pointer<ffi.Int8> Function(int)>();

  /// Open a haptic device for use.
  ///
  /// The index passed as an argument refers to the N'th haptic device on this
  /// system.
  ///
  /// When opening a haptic device, its gain will be set to maximum and
  /// autocenter will be disabled. To modify these values use SDL_HapticSetGain()
  /// and SDL_HapticSetAutocenter().
  ///
  /// \param device_index index of the device to open
  /// \returns the device identifier or NULL on failure; call SDL_GetError() for
  /// more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_HapticClose
  /// \sa SDL_HapticIndex
  /// \sa SDL_HapticOpenFromJoystick
  /// \sa SDL_HapticOpenFromMouse
  /// \sa SDL_HapticPause
  /// \sa SDL_HapticSetAutocenter
  /// \sa SDL_HapticSetGain
  /// \sa SDL_HapticStopAll
  ffi.Pointer<SDL_Haptic1> SDL_HapticOpen(
    int device_index,
  ) {
    return _SDL_HapticOpen(
      device_index,
    );
  }

  late final _SDL_HapticOpenPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<SDL_Haptic1> Function(ffi.Int32)>>(
          'SDL_HapticOpen');
  late final _SDL_HapticOpen =
      _SDL_HapticOpenPtr.asFunction<ffi.Pointer<SDL_Haptic1> Function(int)>();

  /// Check if the haptic device at the designated index has been opened.
  ///
  /// \param device_index the index of the device to query
  /// \returns 1 if it has been opened, 0 if it hasn't or on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_HapticIndex
  /// \sa SDL_HapticOpen
  int SDL_HapticOpened(
    int device_index,
  ) {
    return _SDL_HapticOpened(
      device_index,
    );
  }

  late final _SDL_HapticOpenedPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Int32)>>(
          'SDL_HapticOpened');
  late final _SDL_HapticOpened =
      _SDL_HapticOpenedPtr.asFunction<int Function(int)>();

  /// Get the index of a haptic device.
  ///
  /// \param haptic the SDL_Haptic device to query
  /// \returns the index of the specified haptic device or a negative error code
  /// on failure; call SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_HapticOpen
  /// \sa SDL_HapticOpened
  int SDL_HapticIndex(
    ffi.Pointer<SDL_Haptic1> haptic,
  ) {
    return _SDL_HapticIndex(
      haptic,
    );
  }

  late final _SDL_HapticIndexPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<SDL_Haptic1>)>>(
          'SDL_HapticIndex');
  late final _SDL_HapticIndex =
      _SDL_HapticIndexPtr.asFunction<int Function(ffi.Pointer<SDL_Haptic1>)>();

  /// Query whether or not the current mouse has haptic capabilities.
  ///
  /// \returns SDL_TRUE if the mouse is haptic or SDL_FALSE if it isn't.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_HapticOpenFromMouse
  int SDL_MouseIsHaptic() {
    return _SDL_MouseIsHaptic();
  }

  late final _SDL_MouseIsHapticPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function()>>('SDL_MouseIsHaptic');
  late final _SDL_MouseIsHaptic =
      _SDL_MouseIsHapticPtr.asFunction<int Function()>();

  /// Try to open a haptic device from the current mouse.
  ///
  /// \returns the haptic device identifier or NULL on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_HapticOpen
  /// \sa SDL_MouseIsHaptic
  ffi.Pointer<SDL_Haptic1> SDL_HapticOpenFromMouse() {
    return _SDL_HapticOpenFromMouse();
  }

  late final _SDL_HapticOpenFromMousePtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<SDL_Haptic1> Function()>>(
          'SDL_HapticOpenFromMouse');
  late final _SDL_HapticOpenFromMouse = _SDL_HapticOpenFromMousePtr.asFunction<
      ffi.Pointer<SDL_Haptic1> Function()>();

  /// Query if a joystick has haptic features.
  ///
  /// \param joystick the SDL_Joystick to test for haptic capabilities
  /// \returns SDL_TRUE if the joystick is haptic, SDL_FALSE if it isn't, or a
  /// negative error code on failure; call SDL_GetError() for more
  /// information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_HapticOpenFromJoystick
  int SDL_JoystickIsHaptic(
    ffi.Pointer<SDL_Joystick1> joystick,
  ) {
    return _SDL_JoystickIsHaptic(
      joystick,
    );
  }

  late final _SDL_JoystickIsHapticPtr = _lookup<
          ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<SDL_Joystick1>)>>(
      'SDL_JoystickIsHaptic');
  late final _SDL_JoystickIsHaptic = _SDL_JoystickIsHapticPtr.asFunction<
      int Function(ffi.Pointer<SDL_Joystick1>)>();

  /// Open a haptic device for use from a joystick device.
  ///
  /// You must still close the haptic device separately. It will not be closed
  /// with the joystick.
  ///
  /// When opened from a joystick you should first close the haptic device before
  /// closing the joystick device. If not, on some implementations the haptic
  /// device will also get unallocated and you'll be unable to use force feedback
  /// on that device.
  ///
  /// \param joystick the SDL_Joystick to create a haptic device from
  /// \returns a valid haptic device identifier on success or NULL on failure;
  /// call SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_HapticClose
  /// \sa SDL_HapticOpen
  /// \sa SDL_JoystickIsHaptic
  ffi.Pointer<SDL_Haptic1> SDL_HapticOpenFromJoystick(
    ffi.Pointer<SDL_Joystick1> joystick,
  ) {
    return _SDL_HapticOpenFromJoystick(
      joystick,
    );
  }

  late final _SDL_HapticOpenFromJoystickPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<SDL_Haptic1> Function(
              ffi.Pointer<SDL_Joystick1>)>>('SDL_HapticOpenFromJoystick');
  late final _SDL_HapticOpenFromJoystick =
      _SDL_HapticOpenFromJoystickPtr.asFunction<
          ffi.Pointer<SDL_Haptic1> Function(ffi.Pointer<SDL_Joystick1>)>();

  /// Close a haptic device previously opened with SDL_HapticOpen().
  ///
  /// \param haptic the SDL_Haptic device to close
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_HapticOpen
  void SDL_HapticClose(
    ffi.Pointer<SDL_Haptic1> haptic,
  ) {
    return _SDL_HapticClose(
      haptic,
    );
  }

  late final _SDL_HapticClosePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<SDL_Haptic1>)>>(
          'SDL_HapticClose');
  late final _SDL_HapticClose =
      _SDL_HapticClosePtr.asFunction<void Function(ffi.Pointer<SDL_Haptic1>)>();

  /// Get the number of effects a haptic device can store.
  ///
  /// On some platforms this isn't fully supported, and therefore is an
  /// approximation. Always check to see if your created effect was actually
  /// created and do not rely solely on SDL_HapticNumEffects().
  ///
  /// \param haptic the SDL_Haptic device to query
  /// \returns the number of effects the haptic device can store or a negative
  /// error code on failure; call SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_HapticNumEffectsPlaying
  /// \sa SDL_HapticQuery
  int SDL_HapticNumEffects(
    ffi.Pointer<SDL_Haptic1> haptic,
  ) {
    return _SDL_HapticNumEffects(
      haptic,
    );
  }

  late final _SDL_HapticNumEffectsPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<SDL_Haptic1>)>>(
          'SDL_HapticNumEffects');
  late final _SDL_HapticNumEffects = _SDL_HapticNumEffectsPtr.asFunction<
      int Function(ffi.Pointer<SDL_Haptic1>)>();

  /// Get the number of effects a haptic device can play at the same time.
  ///
  /// This is not supported on all platforms, but will always return a value.
  ///
  /// \param haptic the SDL_Haptic device to query maximum playing effects
  /// \returns the number of effects the haptic device can play at the same time
  /// or a negative error code on failure; call SDL_GetError() for more
  /// information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_HapticNumEffects
  /// \sa SDL_HapticQuery
  int SDL_HapticNumEffectsPlaying(
    ffi.Pointer<SDL_Haptic1> haptic,
  ) {
    return _SDL_HapticNumEffectsPlaying(
      haptic,
    );
  }

  late final _SDL_HapticNumEffectsPlayingPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<SDL_Haptic1>)>>(
          'SDL_HapticNumEffectsPlaying');
  late final _SDL_HapticNumEffectsPlaying = _SDL_HapticNumEffectsPlayingPtr
      .asFunction<int Function(ffi.Pointer<SDL_Haptic1>)>();

  /// Get the haptic device's supported features in bitwise manner.
  ///
  /// \param haptic the SDL_Haptic device to query
  /// \returns a list of supported haptic features in bitwise manner (OR'd), or 0
  /// on failure; call SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_HapticEffectSupported
  /// \sa SDL_HapticNumEffects
  int SDL_HapticQuery(
    ffi.Pointer<SDL_Haptic1> haptic,
  ) {
    return _SDL_HapticQuery(
      haptic,
    );
  }

  late final _SDL_HapticQueryPtr = _lookup<
          ffi.NativeFunction<ffi.Uint32 Function(ffi.Pointer<SDL_Haptic1>)>>(
      'SDL_HapticQuery');
  late final _SDL_HapticQuery =
      _SDL_HapticQueryPtr.asFunction<int Function(ffi.Pointer<SDL_Haptic1>)>();

  /// Get the number of haptic axes the device has.
  ///
  /// The number of haptic axes might be useful if working with the
  /// SDL_HapticDirection effect.
  ///
  /// \param haptic the SDL_Haptic device to query
  /// \returns the number of axes on success or a negative error code on failure;
  /// call SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  int SDL_HapticNumAxes(
    ffi.Pointer<SDL_Haptic1> haptic,
  ) {
    return _SDL_HapticNumAxes(
      haptic,
    );
  }

  late final _SDL_HapticNumAxesPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<SDL_Haptic1>)>>(
          'SDL_HapticNumAxes');
  late final _SDL_HapticNumAxes = _SDL_HapticNumAxesPtr.asFunction<
      int Function(ffi.Pointer<SDL_Haptic1>)>();

  /// Check to see if an effect is supported by a haptic device.
  ///
  /// \param haptic the SDL_Haptic device to query
  /// \param effect the desired effect to query
  /// \returns SDL_TRUE if effect is supported, SDL_FALSE if it isn't, or a
  /// negative error code on failure; call SDL_GetError() for more
  /// information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_HapticNewEffect
  /// \sa SDL_HapticQuery
  int SDL_HapticEffectSupported(
    ffi.Pointer<SDL_Haptic1> haptic,
    ffi.Pointer<SDL_HapticEffect> effect,
  ) {
    return _SDL_HapticEffectSupported(
      haptic,
      effect,
    );
  }

  late final _SDL_HapticEffectSupportedPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_Haptic1>,
              ffi.Pointer<SDL_HapticEffect>)>>('SDL_HapticEffectSupported');
  late final _SDL_HapticEffectSupported =
      _SDL_HapticEffectSupportedPtr.asFunction<
          int Function(
              ffi.Pointer<SDL_Haptic1>, ffi.Pointer<SDL_HapticEffect>)>();

  /// Create a new haptic effect on a specified device.
  ///
  /// \param haptic an SDL_Haptic device to create the effect on
  /// \param effect an SDL_HapticEffect structure containing the properties of
  /// the effect to create
  /// \returns the ID of the effect on success or a negative error code on
  /// failure; call SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_HapticDestroyEffect
  /// \sa SDL_HapticRunEffect
  /// \sa SDL_HapticUpdateEffect
  int SDL_HapticNewEffect(
    ffi.Pointer<SDL_Haptic1> haptic,
    ffi.Pointer<SDL_HapticEffect> effect,
  ) {
    return _SDL_HapticNewEffect(
      haptic,
      effect,
    );
  }

  late final _SDL_HapticNewEffectPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_Haptic1>,
              ffi.Pointer<SDL_HapticEffect>)>>('SDL_HapticNewEffect');
  late final _SDL_HapticNewEffect = _SDL_HapticNewEffectPtr.asFunction<
      int Function(ffi.Pointer<SDL_Haptic1>, ffi.Pointer<SDL_HapticEffect>)>();

  /// Update the properties of an effect.
  ///
  /// Can be used dynamically, although behavior when dynamically changing
  /// direction may be strange. Specifically the effect may re-upload itself and
  /// start playing from the start. You also cannot change the type either when
  /// running SDL_HapticUpdateEffect().
  ///
  /// \param haptic the SDL_Haptic device that has the effect
  /// \param effect the identifier of the effect to update
  /// \param data an SDL_HapticEffect structure containing the new effect
  /// properties to use
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_HapticDestroyEffect
  /// \sa SDL_HapticNewEffect
  /// \sa SDL_HapticRunEffect
  int SDL_HapticUpdateEffect(
    ffi.Pointer<SDL_Haptic1> haptic,
    int effect,
    ffi.Pointer<SDL_HapticEffect> data,
  ) {
    return _SDL_HapticUpdateEffect(
      haptic,
      effect,
      data,
    );
  }

  late final _SDL_HapticUpdateEffectPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_Haptic1>, ffi.Int32,
              ffi.Pointer<SDL_HapticEffect>)>>('SDL_HapticUpdateEffect');
  late final _SDL_HapticUpdateEffect = _SDL_HapticUpdateEffectPtr.asFunction<
      int Function(
          ffi.Pointer<SDL_Haptic1>, int, ffi.Pointer<SDL_HapticEffect>)>();

  /// Run the haptic effect on its associated haptic device.
  ///
  /// To repeat the effect over and over indefinitely, set `iterations` to
  /// `SDL_HAPTIC_INFINITY`. (Repeats the envelope - attack and fade.) To make
  /// one instance of the effect last indefinitely (so the effect does not fade),
  /// set the effect's `length` in its structure/union to `SDL_HAPTIC_INFINITY`
  /// instead.
  ///
  /// \param haptic the SDL_Haptic device to run the effect on
  /// \param effect the ID of the haptic effect to run
  /// \param iterations the number of iterations to run the effect; use
  /// `SDL_HAPTIC_INFINITY` to repeat forever
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_HapticDestroyEffect
  /// \sa SDL_HapticGetEffectStatus
  /// \sa SDL_HapticStopEffect
  int SDL_HapticRunEffect(
    ffi.Pointer<SDL_Haptic1> haptic,
    int effect,
    int iterations,
  ) {
    return _SDL_HapticRunEffect(
      haptic,
      effect,
      iterations,
    );
  }

  late final _SDL_HapticRunEffectPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_Haptic1>, ffi.Int32,
              Uint32)>>('SDL_HapticRunEffect');
  late final _SDL_HapticRunEffect = _SDL_HapticRunEffectPtr.asFunction<
      int Function(ffi.Pointer<SDL_Haptic1>, int, int)>();

  /// Stop the haptic effect on its associated haptic device.
  ///
  /// *
  ///
  /// \param haptic the SDL_Haptic device to stop the effect on
  /// \param effect the ID of the haptic effect to stop
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_HapticDestroyEffect
  /// \sa SDL_HapticRunEffect
  int SDL_HapticStopEffect(
    ffi.Pointer<SDL_Haptic1> haptic,
    int effect,
  ) {
    return _SDL_HapticStopEffect(
      haptic,
      effect,
    );
  }

  late final _SDL_HapticStopEffectPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<SDL_Haptic1>, ffi.Int32)>>('SDL_HapticStopEffect');
  late final _SDL_HapticStopEffect = _SDL_HapticStopEffectPtr.asFunction<
      int Function(ffi.Pointer<SDL_Haptic1>, int)>();

  /// Destroy a haptic effect on the device.
  ///
  /// This will stop the effect if it's running. Effects are automatically
  /// destroyed when the device is closed.
  ///
  /// \param haptic the SDL_Haptic device to destroy the effect on
  /// \param effect the ID of the haptic effect to destroy
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_HapticNewEffect
  void SDL_HapticDestroyEffect(
    ffi.Pointer<SDL_Haptic1> haptic,
    int effect,
  ) {
    return _SDL_HapticDestroyEffect(
      haptic,
      effect,
    );
  }

  late final _SDL_HapticDestroyEffectPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<SDL_Haptic1>, ffi.Int32)>>('SDL_HapticDestroyEffect');
  late final _SDL_HapticDestroyEffect = _SDL_HapticDestroyEffectPtr.asFunction<
      void Function(ffi.Pointer<SDL_Haptic1>, int)>();

  /// Get the status of the current effect on the specified haptic device.
  ///
  /// Device must support the SDL_HAPTIC_STATUS feature.
  ///
  /// \param haptic the SDL_Haptic device to query for the effect status on
  /// \param effect the ID of the haptic effect to query its status
  /// \returns 0 if it isn't playing, 1 if it is playing, or a negative error
  /// code on failure; call SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_HapticRunEffect
  /// \sa SDL_HapticStopEffect
  int SDL_HapticGetEffectStatus(
    ffi.Pointer<SDL_Haptic1> haptic,
    int effect,
  ) {
    return _SDL_HapticGetEffectStatus(
      haptic,
      effect,
    );
  }

  late final _SDL_HapticGetEffectStatusPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_Haptic1>,
              ffi.Int32)>>('SDL_HapticGetEffectStatus');
  late final _SDL_HapticGetEffectStatus = _SDL_HapticGetEffectStatusPtr
      .asFunction<int Function(ffi.Pointer<SDL_Haptic1>, int)>();

  /// Set the global gain of the specified haptic device.
  ///
  /// Device must support the SDL_HAPTIC_GAIN feature.
  ///
  /// The user may specify the maximum gain by setting the environment variable
  /// `SDL_HAPTIC_GAIN_MAX` which should be between 0 and 100. All calls to
  /// SDL_HapticSetGain() will scale linearly using `SDL_HAPTIC_GAIN_MAX` as the
  /// maximum.
  ///
  /// \param haptic the SDL_Haptic device to set the gain on
  /// \param gain value to set the gain to, should be between 0 and 100 (0 - 100)
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_HapticQuery
  int SDL_HapticSetGain(
    ffi.Pointer<SDL_Haptic1> haptic,
    int gain,
  ) {
    return _SDL_HapticSetGain(
      haptic,
      gain,
    );
  }

  late final _SDL_HapticSetGainPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<SDL_Haptic1>, ffi.Int32)>>('SDL_HapticSetGain');
  late final _SDL_HapticSetGain = _SDL_HapticSetGainPtr.asFunction<
      int Function(ffi.Pointer<SDL_Haptic1>, int)>();

  /// Set the global autocenter of the device.
  ///
  /// Autocenter should be between 0 and 100. Setting it to 0 will disable
  /// autocentering.
  ///
  /// Device must support the SDL_HAPTIC_AUTOCENTER feature.
  ///
  /// \param haptic the SDL_Haptic device to set autocentering on
  /// \param autocenter value to set autocenter to (0-100)
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_HapticQuery
  int SDL_HapticSetAutocenter(
    ffi.Pointer<SDL_Haptic1> haptic,
    int autocenter,
  ) {
    return _SDL_HapticSetAutocenter(
      haptic,
      autocenter,
    );
  }

  late final _SDL_HapticSetAutocenterPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<SDL_Haptic1>, ffi.Int32)>>('SDL_HapticSetAutocenter');
  late final _SDL_HapticSetAutocenter = _SDL_HapticSetAutocenterPtr.asFunction<
      int Function(ffi.Pointer<SDL_Haptic1>, int)>();

  /// Pause a haptic device.
  ///
  /// Device must support the `SDL_HAPTIC_PAUSE` feature. Call
  /// SDL_HapticUnpause() to resume playback.
  ///
  /// Do not modify the effects nor add new ones while the device is paused. That
  /// can cause all sorts of weird errors.
  ///
  /// \param haptic the SDL_Haptic device to pause
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_HapticUnpause
  int SDL_HapticPause(
    ffi.Pointer<SDL_Haptic1> haptic,
  ) {
    return _SDL_HapticPause(
      haptic,
    );
  }

  late final _SDL_HapticPausePtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<SDL_Haptic1>)>>(
          'SDL_HapticPause');
  late final _SDL_HapticPause =
      _SDL_HapticPausePtr.asFunction<int Function(ffi.Pointer<SDL_Haptic1>)>();

  /// Unpause a haptic device.
  ///
  /// Call to unpause after SDL_HapticPause().
  ///
  /// \param haptic the SDL_Haptic device to unpause
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_HapticPause
  int SDL_HapticUnpause(
    ffi.Pointer<SDL_Haptic1> haptic,
  ) {
    return _SDL_HapticUnpause(
      haptic,
    );
  }

  late final _SDL_HapticUnpausePtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<SDL_Haptic1>)>>(
          'SDL_HapticUnpause');
  late final _SDL_HapticUnpause = _SDL_HapticUnpausePtr.asFunction<
      int Function(ffi.Pointer<SDL_Haptic1>)>();

  /// Stop all the currently playing effects on a haptic device.
  ///
  /// \param haptic the SDL_Haptic device to stop
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  int SDL_HapticStopAll(
    ffi.Pointer<SDL_Haptic1> haptic,
  ) {
    return _SDL_HapticStopAll(
      haptic,
    );
  }

  late final _SDL_HapticStopAllPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<SDL_Haptic1>)>>(
          'SDL_HapticStopAll');
  late final _SDL_HapticStopAll = _SDL_HapticStopAllPtr.asFunction<
      int Function(ffi.Pointer<SDL_Haptic1>)>();

  /// Check whether rumble is supported on a haptic device.
  ///
  /// \param haptic haptic device to check for rumble support
  /// \returns SDL_TRUE if effect is supported, SDL_FALSE if it isn't, or a
  /// negative error code on failure; call SDL_GetError() for more
  /// information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_HapticRumbleInit
  /// \sa SDL_HapticRumblePlay
  /// \sa SDL_HapticRumbleStop
  int SDL_HapticRumbleSupported(
    ffi.Pointer<SDL_Haptic1> haptic,
  ) {
    return _SDL_HapticRumbleSupported(
      haptic,
    );
  }

  late final _SDL_HapticRumbleSupportedPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<SDL_Haptic1>)>>(
          'SDL_HapticRumbleSupported');
  late final _SDL_HapticRumbleSupported = _SDL_HapticRumbleSupportedPtr
      .asFunction<int Function(ffi.Pointer<SDL_Haptic1>)>();

  /// Initialize a haptic device for simple rumble playback.
  ///
  /// \param haptic the haptic device to initialize for simple rumble playback
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_HapticOpen
  /// \sa SDL_HapticRumblePlay
  /// \sa SDL_HapticRumbleStop
  /// \sa SDL_HapticRumbleSupported
  int SDL_HapticRumbleInit(
    ffi.Pointer<SDL_Haptic1> haptic,
  ) {
    return _SDL_HapticRumbleInit(
      haptic,
    );
  }

  late final _SDL_HapticRumbleInitPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<SDL_Haptic1>)>>(
          'SDL_HapticRumbleInit');
  late final _SDL_HapticRumbleInit = _SDL_HapticRumbleInitPtr.asFunction<
      int Function(ffi.Pointer<SDL_Haptic1>)>();

  /// Run a simple rumble effect on a haptic device.
  ///
  /// \param haptic the haptic device to play the rumble effect on
  /// \param strength strength of the rumble to play as a 0-1 float value
  /// \param length length of the rumble to play in milliseconds
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_HapticRumbleInit
  /// \sa SDL_HapticRumbleStop
  /// \sa SDL_HapticRumbleSupported
  int SDL_HapticRumblePlay(
    ffi.Pointer<SDL_Haptic1> haptic,
    double strength,
    int length,
  ) {
    return _SDL_HapticRumblePlay(
      haptic,
      strength,
      length,
    );
  }

  late final _SDL_HapticRumblePlayPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_Haptic1>, ffi.Float,
              Uint32)>>('SDL_HapticRumblePlay');
  late final _SDL_HapticRumblePlay = _SDL_HapticRumblePlayPtr.asFunction<
      int Function(ffi.Pointer<SDL_Haptic1>, double, int)>();

  /// Stop the simple rumble on a haptic device.
  ///
  /// \param haptic the haptic device to stop the rumble effect on
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_HapticRumbleInit
  /// \sa SDL_HapticRumblePlay
  /// \sa SDL_HapticRumbleSupported
  int SDL_HapticRumbleStop(
    ffi.Pointer<SDL_Haptic1> haptic,
  ) {
    return _SDL_HapticRumbleStop(
      haptic,
    );
  }

  late final _SDL_HapticRumbleStopPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<SDL_Haptic1>)>>(
          'SDL_HapticRumbleStop');
  late final _SDL_HapticRumbleStop = _SDL_HapticRumbleStopPtr.asFunction<
      int Function(ffi.Pointer<SDL_Haptic1>)>();

  /// Initialize the HIDAPI library.
  ///
  /// This function initializes the HIDAPI library. Calling it is not strictly
  /// necessary, as it will be called automatically by SDL_hid_enumerate() and
  /// any of the SDL_hid_open_*() functions if it is needed. This function should
  /// be called at the beginning of execution however, if there is a chance of
  /// HIDAPI handles being opened by different threads simultaneously.
  ///
  /// Each call to this function should have a matching call to SDL_hid_exit()
  ///
  /// \returns 0 on success and -1 on error.
  ///
  /// \since This function is available since SDL 2.0.18.
  ///
  /// \sa SDL_hid_exit
  int SDL_hid_init() {
    return _SDL_hid_init();
  }

  late final _SDL_hid_initPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function()>>('SDL_hid_init');
  late final _SDL_hid_init = _SDL_hid_initPtr.asFunction<int Function()>();

  /// Finalize the HIDAPI library.
  ///
  /// This function frees all of the static data associated with HIDAPI. It
  /// should be called at the end of execution to avoid memory leaks.
  ///
  /// \returns 0 on success and -1 on error.
  ///
  /// \since This function is available since SDL 2.0.18.
  ///
  /// \sa SDL_hid_init
  int SDL_hid_exit() {
    return _SDL_hid_exit();
  }

  late final _SDL_hid_exitPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function()>>('SDL_hid_exit');
  late final _SDL_hid_exit = _SDL_hid_exitPtr.asFunction<int Function()>();

  /// Check to see if devices may have been added or removed.
  ///
  /// Enumerating the HID devices is an expensive operation, so you can call this
  /// to see if there have been any system device changes since the last call to
  /// this function. A change in the counter returned doesn't necessarily mean
  /// that anything has changed, but you can call SDL_hid_enumerate() to get an
  /// updated device list.
  ///
  /// Calling this function for the first time may cause a thread or other system
  /// resource to be allocated to track device change notifications.
  ///
  /// \returns a change counter that is incremented with each potential device
  /// change, or 0 if device change detection isn't available.
  ///
  /// \since This function is available since SDL 2.0.18.
  ///
  /// \sa SDL_hid_enumerate
  int SDL_hid_device_change_count() {
    return _SDL_hid_device_change_count();
  }

  late final _SDL_hid_device_change_countPtr =
      _lookup<ffi.NativeFunction<Uint32 Function()>>(
          'SDL_hid_device_change_count');
  late final _SDL_hid_device_change_count =
      _SDL_hid_device_change_countPtr.asFunction<int Function()>();

  /// Enumerate the HID Devices.
  ///
  /// This function returns a linked list of all the HID devices attached to the
  /// system which match vendor_id and product_id. If `vendor_id` is set to 0
  /// then any vendor matches. If `product_id` is set to 0 then any product
  /// matches. If `vendor_id` and `product_id` are both set to 0, then all HID
  /// devices will be returned.
  ///
  /// \param vendor_id The Vendor ID (VID) of the types of device to open.
  /// \param product_id The Product ID (PID) of the types of device to open.
  /// \returns a pointer to a linked list of type SDL_hid_device_info, containing
  /// information about the HID devices attached to the system, or NULL
  /// in the case of failure. Free this linked list by calling
  /// SDL_hid_free_enumeration().
  ///
  /// \since This function is available since SDL 2.0.18.
  ///
  /// \sa SDL_hid_device_change_count
  ffi.Pointer<SDL_hid_device_info> SDL_hid_enumerate(
    int vendor_id,
    int product_id,
  ) {
    return _SDL_hid_enumerate(
      vendor_id,
      product_id,
    );
  }

  late final _SDL_hid_enumeratePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<SDL_hid_device_info> Function(
              ffi.Uint16, ffi.Uint16)>>('SDL_hid_enumerate');
  late final _SDL_hid_enumerate = _SDL_hid_enumeratePtr.asFunction<
      ffi.Pointer<SDL_hid_device_info> Function(int, int)>();

  /// Free an enumeration Linked List
  ///
  /// This function frees a linked list created by SDL_hid_enumerate().
  ///
  /// \param devs Pointer to a list of struct_device returned from
  /// SDL_hid_enumerate().
  ///
  /// \since This function is available since SDL 2.0.18.
  void SDL_hid_free_enumeration(
    ffi.Pointer<SDL_hid_device_info> devs,
  ) {
    return _SDL_hid_free_enumeration(
      devs,
    );
  }

  late final _SDL_hid_free_enumerationPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<SDL_hid_device_info>)>>('SDL_hid_free_enumeration');
  late final _SDL_hid_free_enumeration = _SDL_hid_free_enumerationPtr
      .asFunction<void Function(ffi.Pointer<SDL_hid_device_info>)>();

  /// Open a HID device using a Vendor ID (VID), Product ID (PID) and optionally
  /// a serial number.
  ///
  /// If `serial_number` is NULL, the first device with the specified VID and PID
  /// is opened.
  ///
  /// \param vendor_id The Vendor ID (VID) of the device to open.
  /// \param product_id The Product ID (PID) of the device to open.
  /// \param serial_number The Serial Number of the device to open (Optionally
  /// NULL).
  /// \returns a pointer to a SDL_hid_device object on success or NULL on
  /// failure.
  ///
  /// \since This function is available since SDL 2.0.18.
  ffi.Pointer<SDL_hid_device> SDL_hid_open(
    int vendor_id,
    int product_id,
    ffi.Pointer<wchar_t> serial_number,
  ) {
    return _SDL_hid_open(
      vendor_id,
      product_id,
      serial_number,
    );
  }

  late final _SDL_hid_openPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<SDL_hid_device> Function(
              ffi.Uint16, ffi.Uint16, ffi.Pointer<wchar_t>)>>('SDL_hid_open');
  late final _SDL_hid_open = _SDL_hid_openPtr.asFunction<
      ffi.Pointer<SDL_hid_device> Function(int, int, ffi.Pointer<wchar_t>)>();

  /// Open a HID device by its path name.
  ///
  /// The path name be determined by calling SDL_hid_enumerate(), or a
  /// platform-specific path name can be used (eg: /dev/hidraw0 on Linux).
  ///
  /// \param path The path name of the device to open
  /// \returns a pointer to a SDL_hid_device object on success or NULL on
  /// failure.
  ///
  /// \since This function is available since SDL 2.0.18.
  ffi.Pointer<SDL_hid_device> SDL_hid_open_path(
    ffi.Pointer<ffi.Int8> path,
    int bExclusive,
  ) {
    return _SDL_hid_open_path(
      path,
      bExclusive,
    );
  }

  late final _SDL_hid_open_pathPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<SDL_hid_device> Function(
              ffi.Pointer<ffi.Int8>, ffi.Int32)>>('SDL_hid_open_path');
  late final _SDL_hid_open_path = _SDL_hid_open_pathPtr.asFunction<
      ffi.Pointer<SDL_hid_device> Function(ffi.Pointer<ffi.Int8>, int)>();

  /// Write an Output report to a HID device.
  ///
  /// The first byte of `data` must contain the Report ID. For devices which only
  /// support a single report, this must be set to 0x0. The remaining bytes
  /// contain the report data. Since the Report ID is mandatory, calls to
  /// SDL_hid_write() will always contain one more byte than the report contains.
  /// For example, if a hid report is 16 bytes long, 17 bytes must be passed to
  /// SDL_hid_write(), the Report ID (or 0x0, for devices with a single report),
  /// followed by the report data (16 bytes). In this example, the length passed
  /// in would be 17.
  ///
  /// SDL_hid_write() will send the data on the first OUT endpoint, if one
  /// exists. If it does not, it will send the data through the Control Endpoint
  /// (Endpoint 0).
  ///
  /// \param dev A device handle returned from SDL_hid_open().
  /// \param data The data to send, including the report number as the first
  /// byte.
  /// \param length The length in bytes of the data to send.
  /// \returns the actual number of bytes written and -1 on error.
  ///
  /// \since This function is available since SDL 2.0.18.
  int SDL_hid_write(
    ffi.Pointer<SDL_hid_device> dev,
    ffi.Pointer<ffi.Uint8> data,
    int length,
  ) {
    return _SDL_hid_write(
      dev,
      data,
      length,
    );
  }

  late final _SDL_hid_writePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_hid_device>,
              ffi.Pointer<ffi.Uint8>, size_t)>>('SDL_hid_write');
  late final _SDL_hid_write = _SDL_hid_writePtr.asFunction<
      int Function(ffi.Pointer<SDL_hid_device>, ffi.Pointer<ffi.Uint8>, int)>();

  /// Read an Input report from a HID device with timeout.
  ///
  /// Input reports are returned to the host through the INTERRUPT IN endpoint.
  /// The first byte will contain the Report number if the device uses numbered
  /// reports.
  ///
  /// \param dev A device handle returned from SDL_hid_open().
  /// \param data A buffer to put the read data into.
  /// \param length The number of bytes to read. For devices with multiple
  /// reports, make sure to read an extra byte for the report
  /// number.
  /// \param milliseconds timeout in milliseconds or -1 for blocking wait.
  /// \returns the actual number of bytes read and -1 on error. If no packet was
  /// available to be read within the timeout period, this function
  /// returns 0.
  ///
  /// \since This function is available since SDL 2.0.18.
  int SDL_hid_read_timeout(
    ffi.Pointer<SDL_hid_device> dev,
    ffi.Pointer<ffi.Uint8> data,
    int length,
    int milliseconds,
  ) {
    return _SDL_hid_read_timeout(
      dev,
      data,
      length,
      milliseconds,
    );
  }

  late final _SDL_hid_read_timeoutPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<SDL_hid_device>,
              ffi.Pointer<ffi.Uint8>,
              size_t,
              ffi.Int32)>>('SDL_hid_read_timeout');
  late final _SDL_hid_read_timeout = _SDL_hid_read_timeoutPtr.asFunction<
      int Function(
          ffi.Pointer<SDL_hid_device>, ffi.Pointer<ffi.Uint8>, int, int)>();

  /// Read an Input report from a HID device.
  ///
  /// Input reports are returned to the host through the INTERRUPT IN endpoint.
  /// The first byte will contain the Report number if the device uses numbered
  /// reports.
  ///
  /// \param dev A device handle returned from SDL_hid_open().
  /// \param data A buffer to put the read data into.
  /// \param length The number of bytes to read. For devices with multiple
  /// reports, make sure to read an extra byte for the report
  /// number.
  /// \returns the actual number of bytes read and -1 on error. If no packet was
  /// available to be read and the handle is in non-blocking mode, this
  /// function returns 0.
  ///
  /// \since This function is available since SDL 2.0.18.
  int SDL_hid_read(
    ffi.Pointer<SDL_hid_device> dev,
    ffi.Pointer<ffi.Uint8> data,
    int length,
  ) {
    return _SDL_hid_read(
      dev,
      data,
      length,
    );
  }

  late final _SDL_hid_readPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_hid_device>,
              ffi.Pointer<ffi.Uint8>, size_t)>>('SDL_hid_read');
  late final _SDL_hid_read = _SDL_hid_readPtr.asFunction<
      int Function(ffi.Pointer<SDL_hid_device>, ffi.Pointer<ffi.Uint8>, int)>();

  /// Set the device handle to be non-blocking.
  ///
  /// In non-blocking mode calls to SDL_hid_read() will return immediately with a
  /// value of 0 if there is no data to be read. In blocking mode, SDL_hid_read()
  /// will wait (block) until there is data to read before returning.
  ///
  /// Nonblocking can be turned on and off at any time.
  ///
  /// \param dev A device handle returned from SDL_hid_open().
  /// \param nonblock enable or not the nonblocking reads - 1 to enable
  /// nonblocking - 0 to disable nonblocking.
  /// \returns 0 on success and -1 on error.
  ///
  /// \since This function is available since SDL 2.0.18.
  int SDL_hid_set_nonblocking(
    ffi.Pointer<SDL_hid_device> dev,
    int nonblock,
  ) {
    return _SDL_hid_set_nonblocking(
      dev,
      nonblock,
    );
  }

  late final _SDL_hid_set_nonblockingPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_hid_device>,
              ffi.Int32)>>('SDL_hid_set_nonblocking');
  late final _SDL_hid_set_nonblocking = _SDL_hid_set_nonblockingPtr.asFunction<
      int Function(ffi.Pointer<SDL_hid_device>, int)>();

  /// Send a Feature report to the device.
  ///
  /// Feature reports are sent over the Control endpoint as a Set_Report
  /// transfer. The first byte of `data` must contain the Report ID. For devices
  /// which only support a single report, this must be set to 0x0. The remaining
  /// bytes contain the report data. Since the Report ID is mandatory, calls to
  /// SDL_hid_send_feature_report() will always contain one more byte than the
  /// report contains. For example, if a hid report is 16 bytes long, 17 bytes
  /// must be passed to SDL_hid_send_feature_report(): the Report ID (or 0x0, for
  /// devices which do not use numbered reports), followed by the report data (16
  /// bytes). In this example, the length passed in would be 17.
  ///
  /// \param dev A device handle returned from SDL_hid_open().
  /// \param data The data to send, including the report number as the first
  /// byte.
  /// \param length The length in bytes of the data to send, including the report
  /// number.
  /// \returns the actual number of bytes written and -1 on error.
  ///
  /// \since This function is available since SDL 2.0.18.
  int SDL_hid_send_feature_report(
    ffi.Pointer<SDL_hid_device> dev,
    ffi.Pointer<ffi.Uint8> data,
    int length,
  ) {
    return _SDL_hid_send_feature_report(
      dev,
      data,
      length,
    );
  }

  late final _SDL_hid_send_feature_reportPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_hid_device>,
              ffi.Pointer<ffi.Uint8>, size_t)>>('SDL_hid_send_feature_report');
  late final _SDL_hid_send_feature_report =
      _SDL_hid_send_feature_reportPtr.asFunction<
          int Function(
              ffi.Pointer<SDL_hid_device>, ffi.Pointer<ffi.Uint8>, int)>();

  /// Get a feature report from a HID device.
  ///
  /// Set the first byte of `data` to the Report ID of the report to be read.
  /// Make sure to allow space for this extra byte in `data`. Upon return, the
  /// first byte will still contain the Report ID, and the report data will start
  /// in data[1].
  ///
  /// \param dev A device handle returned from SDL_hid_open().
  /// \param data A buffer to put the read data into, including the Report ID.
  /// Set the first byte of `data` to the Report ID of the report to
  /// be read, or set it to zero if your device does not use numbered
  /// reports.
  /// \param length The number of bytes to read, including an extra byte for the
  /// report ID. The buffer can be longer than the actual report.
  /// \returns the number of bytes read plus one for the report ID (which is
  /// still in the first byte), or -1 on error.
  ///
  /// \since This function is available since SDL 2.0.18.
  int SDL_hid_get_feature_report(
    ffi.Pointer<SDL_hid_device> dev,
    ffi.Pointer<ffi.Uint8> data,
    int length,
  ) {
    return _SDL_hid_get_feature_report(
      dev,
      data,
      length,
    );
  }

  late final _SDL_hid_get_feature_reportPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_hid_device>,
              ffi.Pointer<ffi.Uint8>, size_t)>>('SDL_hid_get_feature_report');
  late final _SDL_hid_get_feature_report =
      _SDL_hid_get_feature_reportPtr.asFunction<
          int Function(
              ffi.Pointer<SDL_hid_device>, ffi.Pointer<ffi.Uint8>, int)>();

  /// Close a HID device.
  ///
  /// \param dev A device handle returned from SDL_hid_open().
  ///
  /// \since This function is available since SDL 2.0.18.
  void SDL_hid_close(
    ffi.Pointer<SDL_hid_device> dev,
  ) {
    return _SDL_hid_close(
      dev,
    );
  }

  late final _SDL_hid_closePtr = _lookup<
          ffi.NativeFunction<ffi.Void Function(ffi.Pointer<SDL_hid_device>)>>(
      'SDL_hid_close');
  late final _SDL_hid_close = _SDL_hid_closePtr.asFunction<
      void Function(ffi.Pointer<SDL_hid_device>)>();

  /// Get The Manufacturer String from a HID device.
  ///
  /// \param dev A device handle returned from SDL_hid_open().
  /// \param string A wide string buffer to put the data into.
  /// \param maxlen The length of the buffer in multiples of wchar_t.
  /// \returns 0 on success and -1 on error.
  ///
  /// \since This function is available since SDL 2.0.18.
  int SDL_hid_get_manufacturer_string(
    ffi.Pointer<SDL_hid_device> dev,
    ffi.Pointer<wchar_t> string,
    int maxlen,
  ) {
    return _SDL_hid_get_manufacturer_string(
      dev,
      string,
      maxlen,
    );
  }

  late final _SDL_hid_get_manufacturer_stringPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_hid_device>, ffi.Pointer<wchar_t>,
              size_t)>>('SDL_hid_get_manufacturer_string');
  late final _SDL_hid_get_manufacturer_string =
      _SDL_hid_get_manufacturer_stringPtr.asFunction<
          int Function(
              ffi.Pointer<SDL_hid_device>, ffi.Pointer<wchar_t>, int)>();

  /// Get The Product String from a HID device.
  ///
  /// \param dev A device handle returned from SDL_hid_open().
  /// \param string A wide string buffer to put the data into.
  /// \param maxlen The length of the buffer in multiples of wchar_t.
  /// \returns 0 on success and -1 on error.
  ///
  /// \since This function is available since SDL 2.0.18.
  int SDL_hid_get_product_string(
    ffi.Pointer<SDL_hid_device> dev,
    ffi.Pointer<wchar_t> string,
    int maxlen,
  ) {
    return _SDL_hid_get_product_string(
      dev,
      string,
      maxlen,
    );
  }

  late final _SDL_hid_get_product_stringPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_hid_device>, ffi.Pointer<wchar_t>,
              size_t)>>('SDL_hid_get_product_string');
  late final _SDL_hid_get_product_string =
      _SDL_hid_get_product_stringPtr.asFunction<
          int Function(
              ffi.Pointer<SDL_hid_device>, ffi.Pointer<wchar_t>, int)>();

  /// Get The Serial Number String from a HID device.
  ///
  /// \param dev A device handle returned from SDL_hid_open().
  /// \param string A wide string buffer to put the data into.
  /// \param maxlen The length of the buffer in multiples of wchar_t.
  /// \returns 0 on success and -1 on error.
  ///
  /// \since This function is available since SDL 2.0.18.
  int SDL_hid_get_serial_number_string(
    ffi.Pointer<SDL_hid_device> dev,
    ffi.Pointer<wchar_t> string,
    int maxlen,
  ) {
    return _SDL_hid_get_serial_number_string(
      dev,
      string,
      maxlen,
    );
  }

  late final _SDL_hid_get_serial_number_stringPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_hid_device>, ffi.Pointer<wchar_t>,
              size_t)>>('SDL_hid_get_serial_number_string');
  late final _SDL_hid_get_serial_number_string =
      _SDL_hid_get_serial_number_stringPtr.asFunction<
          int Function(
              ffi.Pointer<SDL_hid_device>, ffi.Pointer<wchar_t>, int)>();

  /// Get a string from a HID device, based on its string index.
  ///
  /// \param dev A device handle returned from SDL_hid_open().
  /// \param string_index The index of the string to get.
  /// \param string A wide string buffer to put the data into.
  /// \param maxlen The length of the buffer in multiples of wchar_t.
  /// \returns 0 on success and -1 on error.
  ///
  /// \since This function is available since SDL 2.0.18.
  int SDL_hid_get_indexed_string(
    ffi.Pointer<SDL_hid_device> dev,
    int string_index,
    ffi.Pointer<wchar_t> string,
    int maxlen,
  ) {
    return _SDL_hid_get_indexed_string(
      dev,
      string_index,
      string,
      maxlen,
    );
  }

  late final _SDL_hid_get_indexed_stringPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_hid_device>, ffi.Int32,
              ffi.Pointer<wchar_t>, size_t)>>('SDL_hid_get_indexed_string');
  late final _SDL_hid_get_indexed_string =
      _SDL_hid_get_indexed_stringPtr.asFunction<
          int Function(
              ffi.Pointer<SDL_hid_device>, int, ffi.Pointer<wchar_t>, int)>();

  /// Start or stop a BLE scan on iOS and tvOS to pair Steam Controllers
  ///
  /// \param active SDL_TRUE to start the scan, SDL_FALSE to stop the scan
  ///
  /// \since This function is available since SDL 2.0.18.
  void SDL_hid_ble_scan(
    int active,
  ) {
    return _SDL_hid_ble_scan(
      active,
    );
  }

  late final _SDL_hid_ble_scanPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Int32)>>(
          'SDL_hid_ble_scan');
  late final _SDL_hid_ble_scan =
      _SDL_hid_ble_scanPtr.asFunction<void Function(int)>();

  /// Set a hint with a specific priority.
  ///
  /// The priority controls the behavior when setting a hint that already has a
  /// value. Hints will replace existing hints of their priority and lower.
  /// Environment variables are considered to have override priority.
  ///
  /// \param name the hint to set
  /// \param value the value of the hint variable
  /// \param priority the SDL_HintPriority level for the hint
  /// \returns SDL_TRUE if the hint was set, SDL_FALSE otherwise.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetHint
  /// \sa SDL_SetHint
  int SDL_SetHintWithPriority(
    ffi.Pointer<ffi.Int8> name,
    ffi.Pointer<ffi.Int8> value,
    int priority,
  ) {
    return _SDL_SetHintWithPriority(
      name,
      value,
      priority,
    );
  }

  late final _SDL_SetHintWithPriorityPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Int8>,
              ffi.Int32)>>('SDL_SetHintWithPriority');
  late final _SDL_SetHintWithPriority = _SDL_SetHintWithPriorityPtr.asFunction<
      int Function(ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Int8>, int)>();

  /// Set a hint with normal priority.
  ///
  /// Hints will not be set if there is an existing override hint or environment
  /// variable that takes precedence. You can use SDL_SetHintWithPriority() to
  /// set the hint with override priority instead.
  ///
  /// \param name the hint to set
  /// \param value the value of the hint variable
  /// \returns SDL_TRUE if the hint was set, SDL_FALSE otherwise.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetHint
  /// \sa SDL_SetHintWithPriority
  int SDL_SetHint(
    ffi.Pointer<ffi.Int8> name,
    ffi.Pointer<ffi.Int8> value,
  ) {
    return _SDL_SetHint(
      name,
      value,
    );
  }

  late final _SDL_SetHintPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Int8>)>>('SDL_SetHint');
  late final _SDL_SetHint = _SDL_SetHintPtr.asFunction<
      int Function(ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Int8>)>();

  /// Get the value of a hint.
  ///
  /// \param name the hint to query
  /// \returns the string value of a hint or NULL if the hint isn't set.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_SetHint
  /// \sa SDL_SetHintWithPriority
  ffi.Pointer<ffi.Int8> SDL_GetHint(
    ffi.Pointer<ffi.Int8> name,
  ) {
    return _SDL_GetHint(
      name,
    );
  }

  late final _SDL_GetHintPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Int8> Function(
              ffi.Pointer<ffi.Int8>)>>('SDL_GetHint');
  late final _SDL_GetHint = _SDL_GetHintPtr.asFunction<
      ffi.Pointer<ffi.Int8> Function(ffi.Pointer<ffi.Int8>)>();

  /// Get the boolean value of a hint variable.
  ///
  /// \param name the name of the hint to get the boolean value from
  /// \param default_value the value to return if the hint does not exist
  /// \returns the boolean value of a hint or the provided default value if the
  /// hint does not exist.
  ///
  /// \since This function is available since SDL 2.0.5.
  ///
  /// \sa SDL_GetHint
  /// \sa SDL_SetHint
  int SDL_GetHintBoolean(
    ffi.Pointer<ffi.Int8> name,
    int default_value,
  ) {
    return _SDL_GetHintBoolean(
      name,
      default_value,
    );
  }

  late final _SDL_GetHintBooleanPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<ffi.Int8>, ffi.Int32)>>('SDL_GetHintBoolean');
  late final _SDL_GetHintBoolean = _SDL_GetHintBooleanPtr.asFunction<
      int Function(ffi.Pointer<ffi.Int8>, int)>();

  /// Add a function to watch a particular hint.
  ///
  /// \param name the hint to watch
  /// \param callback An SDL_HintCallback function that will be called when the
  /// hint value changes
  /// \param userdata a pointer to pass to the callback function
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_DelHintCallback
  void SDL_AddHintCallback(
    ffi.Pointer<ffi.Int8> name,
    SDL_HintCallback callback,
    ffi.Pointer<ffi.Void> userdata,
  ) {
    return _SDL_AddHintCallback(
      name,
      callback,
      userdata,
    );
  }

  late final _SDL_AddHintCallbackPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Int8>, SDL_HintCallback,
              ffi.Pointer<ffi.Void>)>>('SDL_AddHintCallback');
  late final _SDL_AddHintCallback = _SDL_AddHintCallbackPtr.asFunction<
      void Function(
          ffi.Pointer<ffi.Int8>, SDL_HintCallback, ffi.Pointer<ffi.Void>)>();

  /// Remove a function watching a particular hint.
  ///
  /// \param name the hint being watched
  /// \param callback An SDL_HintCallback function that will be called when the
  /// hint value changes
  /// \param userdata a pointer being passed to the callback function
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_AddHintCallback
  void SDL_DelHintCallback(
    ffi.Pointer<ffi.Int8> name,
    SDL_HintCallback callback,
    ffi.Pointer<ffi.Void> userdata,
  ) {
    return _SDL_DelHintCallback(
      name,
      callback,
      userdata,
    );
  }

  late final _SDL_DelHintCallbackPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<ffi.Int8>, SDL_HintCallback,
              ffi.Pointer<ffi.Void>)>>('SDL_DelHintCallback');
  late final _SDL_DelHintCallback = _SDL_DelHintCallbackPtr.asFunction<
      void Function(
          ffi.Pointer<ffi.Int8>, SDL_HintCallback, ffi.Pointer<ffi.Void>)>();

  /// Clear all hints.
  ///
  /// This function is automatically called during SDL_Quit().
  ///
  /// \since This function is available since SDL 2.0.0.
  void SDL_ClearHints() {
    return _SDL_ClearHints();
  }

  late final _SDL_ClearHintsPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('SDL_ClearHints');
  late final _SDL_ClearHints = _SDL_ClearHintsPtr.asFunction<void Function()>();

  /// Dynamically load a shared object.
  ///
  /// \param sofile a system-dependent name of the object file
  /// \returns an opaque pointer to the object handle or NULL if there was an
  /// error; call SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_LoadFunction
  /// \sa SDL_UnloadObject
  ffi.Pointer<ffi.Void> SDL_LoadObject(
    ffi.Pointer<ffi.Int8> sofile,
  ) {
    return _SDL_LoadObject(
      sofile,
    );
  }

  late final _SDL_LoadObjectPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Void> Function(
              ffi.Pointer<ffi.Int8>)>>('SDL_LoadObject');
  late final _SDL_LoadObject = _SDL_LoadObjectPtr.asFunction<
      ffi.Pointer<ffi.Void> Function(ffi.Pointer<ffi.Int8>)>();

  /// Look up the address of the named function in a shared object.
  ///
  /// This function pointer is no longer valid after calling SDL_UnloadObject().
  ///
  /// This function can only look up C function names. Other languages may have
  /// name mangling and intrinsic language support that varies from compiler to
  /// compiler.
  ///
  /// Make sure you declare your function pointers with the same calling
  /// convention as the actual library function. Your code will crash
  /// mysteriously if you do not do this.
  ///
  /// If the requested function doesn't exist, NULL is returned.
  ///
  /// \param handle a valid shared object handle returned by SDL_LoadObject()
  /// \param name the name of the function to look up
  /// \returns a pointer to the function or NULL if there was an error; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_LoadObject
  /// \sa SDL_UnloadObject
  ffi.Pointer<ffi.Void> SDL_LoadFunction(
    ffi.Pointer<ffi.Void> handle,
    ffi.Pointer<ffi.Int8> name,
  ) {
    return _SDL_LoadFunction(
      handle,
      name,
    );
  }

  late final _SDL_LoadFunctionPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Void> Function(ffi.Pointer<ffi.Void>,
              ffi.Pointer<ffi.Int8>)>>('SDL_LoadFunction');
  late final _SDL_LoadFunction = _SDL_LoadFunctionPtr.asFunction<
      ffi.Pointer<ffi.Void> Function(
          ffi.Pointer<ffi.Void>, ffi.Pointer<ffi.Int8>)>();

  /// Unload a shared object from memory.
  ///
  /// \param handle a valid shared object handle returned by SDL_LoadObject()
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_LoadFunction
  /// \sa SDL_LoadObject
  void SDL_UnloadObject(
    ffi.Pointer<ffi.Void> handle,
  ) {
    return _SDL_UnloadObject(
      handle,
    );
  }

  late final _SDL_UnloadObjectPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ffi.Void>)>>(
          'SDL_UnloadObject');
  late final _SDL_UnloadObject =
      _SDL_UnloadObjectPtr.asFunction<void Function(ffi.Pointer<ffi.Void>)>();

  /// Set the priority of all log categories.
  ///
  /// \param priority the SDL_LogPriority to assign
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_LogSetPriority
  void SDL_LogSetAllPriority(
    int priority,
  ) {
    return _SDL_LogSetAllPriority(
      priority,
    );
  }

  late final _SDL_LogSetAllPriorityPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Int32)>>(
          'SDL_LogSetAllPriority');
  late final _SDL_LogSetAllPriority =
      _SDL_LogSetAllPriorityPtr.asFunction<void Function(int)>();

  /// Set the priority of a particular log category.
  ///
  /// \param category the category to assign a priority to
  /// \param priority the SDL_LogPriority to assign
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_LogGetPriority
  /// \sa SDL_LogSetAllPriority
  void SDL_LogSetPriority(
    int category,
    int priority,
  ) {
    return _SDL_LogSetPriority(
      category,
      priority,
    );
  }

  late final _SDL_LogSetPriorityPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Int32, ffi.Int32)>>(
          'SDL_LogSetPriority');
  late final _SDL_LogSetPriority =
      _SDL_LogSetPriorityPtr.asFunction<void Function(int, int)>();

  /// Get the priority of a particular log category.
  ///
  /// \param category the category to query
  /// \returns the SDL_LogPriority for the requested category
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_LogSetPriority
  int SDL_LogGetPriority(
    int category,
  ) {
    return _SDL_LogGetPriority(
      category,
    );
  }

  late final _SDL_LogGetPriorityPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Int32)>>(
          'SDL_LogGetPriority');
  late final _SDL_LogGetPriority =
      _SDL_LogGetPriorityPtr.asFunction<int Function(int)>();

  /// Reset all priorities to default.
  ///
  /// This is called by SDL_Quit().
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_LogSetAllPriority
  /// \sa SDL_LogSetPriority
  void SDL_LogResetPriorities() {
    return _SDL_LogResetPriorities();
  }

  late final _SDL_LogResetPrioritiesPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>(
          'SDL_LogResetPriorities');
  late final _SDL_LogResetPriorities =
      _SDL_LogResetPrioritiesPtr.asFunction<void Function()>();

  /// Log a message with SDL_LOG_CATEGORY_APPLICATION and SDL_LOG_PRIORITY_INFO.
  ///
  /// = * \param fmt a printf() style message format string
  ///
  /// \param ... additional parameters matching % tokens in the `fmt` string, if
  /// any
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_LogCritical
  /// \sa SDL_LogDebug
  /// \sa SDL_LogError
  /// \sa SDL_LogInfo
  /// \sa SDL_LogMessage
  /// \sa SDL_LogMessageV
  /// \sa SDL_LogVerbose
  /// \sa SDL_LogWarn
  void SDL_Log(
    ffi.Pointer<ffi.Int8> fmt,
  ) {
    return _SDL_Log(
      fmt,
    );
  }

  late final _SDL_LogPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ffi.Int8>)>>(
          'SDL_Log');
  late final _SDL_Log =
      _SDL_LogPtr.asFunction<void Function(ffi.Pointer<ffi.Int8>)>();

  /// Log a message with SDL_LOG_PRIORITY_VERBOSE.
  ///
  /// \param category the category of the message
  /// \param fmt a printf() style message format string
  /// \param ... additional parameters matching % tokens in the **fmt** string,
  /// if any
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_Log
  /// \sa SDL_LogCritical
  /// \sa SDL_LogDebug
  /// \sa SDL_LogError
  /// \sa SDL_LogInfo
  /// \sa SDL_LogMessage
  /// \sa SDL_LogMessageV
  /// \sa SDL_LogWarn
  void SDL_LogVerbose(
    int category,
    ffi.Pointer<ffi.Int8> fmt,
  ) {
    return _SDL_LogVerbose(
      category,
      fmt,
    );
  }

  late final _SDL_LogVerbosePtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Int32, ffi.Pointer<ffi.Int8>)>>('SDL_LogVerbose');
  late final _SDL_LogVerbose = _SDL_LogVerbosePtr.asFunction<
      void Function(int, ffi.Pointer<ffi.Int8>)>();

  /// Log a message with SDL_LOG_PRIORITY_DEBUG.
  ///
  /// \param category the category of the message
  /// \param fmt a printf() style message format string
  /// \param ... additional parameters matching % tokens in the **fmt** string,
  /// if any
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_Log
  /// \sa SDL_LogCritical
  /// \sa SDL_LogError
  /// \sa SDL_LogInfo
  /// \sa SDL_LogMessage
  /// \sa SDL_LogMessageV
  /// \sa SDL_LogVerbose
  /// \sa SDL_LogWarn
  void SDL_LogDebug(
    int category,
    ffi.Pointer<ffi.Int8> fmt,
  ) {
    return _SDL_LogDebug(
      category,
      fmt,
    );
  }

  late final _SDL_LogDebugPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Int32, ffi.Pointer<ffi.Int8>)>>('SDL_LogDebug');
  late final _SDL_LogDebug =
      _SDL_LogDebugPtr.asFunction<void Function(int, ffi.Pointer<ffi.Int8>)>();

  /// Log a message with SDL_LOG_PRIORITY_INFO.
  ///
  /// \param category the category of the message
  /// \param fmt a printf() style message format string
  /// \param ... additional parameters matching % tokens in the **fmt** string,
  /// if any
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_Log
  /// \sa SDL_LogCritical
  /// \sa SDL_LogDebug
  /// \sa SDL_LogError
  /// \sa SDL_LogMessage
  /// \sa SDL_LogMessageV
  /// \sa SDL_LogVerbose
  /// \sa SDL_LogWarn
  void SDL_LogInfo(
    int category,
    ffi.Pointer<ffi.Int8> fmt,
  ) {
    return _SDL_LogInfo(
      category,
      fmt,
    );
  }

  late final _SDL_LogInfoPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Int32, ffi.Pointer<ffi.Int8>)>>('SDL_LogInfo');
  late final _SDL_LogInfo =
      _SDL_LogInfoPtr.asFunction<void Function(int, ffi.Pointer<ffi.Int8>)>();

  /// Log a message with SDL_LOG_PRIORITY_WARN.
  ///
  /// \param category the category of the message
  /// \param fmt a printf() style message format string
  /// \param ... additional parameters matching % tokens in the **fmt** string,
  /// if any
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_Log
  /// \sa SDL_LogCritical
  /// \sa SDL_LogDebug
  /// \sa SDL_LogError
  /// \sa SDL_LogInfo
  /// \sa SDL_LogMessage
  /// \sa SDL_LogMessageV
  /// \sa SDL_LogVerbose
  void SDL_LogWarn(
    int category,
    ffi.Pointer<ffi.Int8> fmt,
  ) {
    return _SDL_LogWarn(
      category,
      fmt,
    );
  }

  late final _SDL_LogWarnPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Int32, ffi.Pointer<ffi.Int8>)>>('SDL_LogWarn');
  late final _SDL_LogWarn =
      _SDL_LogWarnPtr.asFunction<void Function(int, ffi.Pointer<ffi.Int8>)>();

  /// Log a message with SDL_LOG_PRIORITY_ERROR.
  ///
  /// \param category the category of the message
  /// \param fmt a printf() style message format string
  /// \param ... additional parameters matching % tokens in the **fmt** string,
  /// if any
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_Log
  /// \sa SDL_LogCritical
  /// \sa SDL_LogDebug
  /// \sa SDL_LogInfo
  /// \sa SDL_LogMessage
  /// \sa SDL_LogMessageV
  /// \sa SDL_LogVerbose
  /// \sa SDL_LogWarn
  void SDL_LogError(
    int category,
    ffi.Pointer<ffi.Int8> fmt,
  ) {
    return _SDL_LogError(
      category,
      fmt,
    );
  }

  late final _SDL_LogErrorPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Int32, ffi.Pointer<ffi.Int8>)>>('SDL_LogError');
  late final _SDL_LogError =
      _SDL_LogErrorPtr.asFunction<void Function(int, ffi.Pointer<ffi.Int8>)>();

  /// Log a message with SDL_LOG_PRIORITY_CRITICAL.
  ///
  /// \param category the category of the message
  /// \param fmt a printf() style message format string
  /// \param ... additional parameters matching % tokens in the **fmt** string,
  /// if any
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_Log
  /// \sa SDL_LogDebug
  /// \sa SDL_LogError
  /// \sa SDL_LogInfo
  /// \sa SDL_LogMessage
  /// \sa SDL_LogMessageV
  /// \sa SDL_LogVerbose
  /// \sa SDL_LogWarn
  void SDL_LogCritical(
    int category,
    ffi.Pointer<ffi.Int8> fmt,
  ) {
    return _SDL_LogCritical(
      category,
      fmt,
    );
  }

  late final _SDL_LogCriticalPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Int32, ffi.Pointer<ffi.Int8>)>>('SDL_LogCritical');
  late final _SDL_LogCritical = _SDL_LogCriticalPtr.asFunction<
      void Function(int, ffi.Pointer<ffi.Int8>)>();

  /// Log a message with the specified category and priority.
  ///
  /// \param category the category of the message
  /// \param priority the priority of the message
  /// \param fmt a printf() style message format string
  /// \param ... additional parameters matching % tokens in the **fmt** string,
  /// if any
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_Log
  /// \sa SDL_LogCritical
  /// \sa SDL_LogDebug
  /// \sa SDL_LogError
  /// \sa SDL_LogInfo
  /// \sa SDL_LogMessageV
  /// \sa SDL_LogVerbose
  /// \sa SDL_LogWarn
  void SDL_LogMessage(
    int category,
    int priority,
    ffi.Pointer<ffi.Int8> fmt,
  ) {
    return _SDL_LogMessage(
      category,
      priority,
      fmt,
    );
  }

  late final _SDL_LogMessagePtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Int32, ffi.Int32, ffi.Pointer<ffi.Int8>)>>('SDL_LogMessage');
  late final _SDL_LogMessage = _SDL_LogMessagePtr.asFunction<
      void Function(int, int, ffi.Pointer<ffi.Int8>)>();

  /// Log a message with the specified category and priority.
  ///
  /// \param category the category of the message
  /// \param priority the priority of the message
  /// \param fmt a printf() style message format string
  /// \param ap a variable argument list
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_Log
  /// \sa SDL_LogCritical
  /// \sa SDL_LogDebug
  /// \sa SDL_LogError
  /// \sa SDL_LogInfo
  /// \sa SDL_LogMessage
  /// \sa SDL_LogVerbose
  /// \sa SDL_LogWarn
  void SDL_LogMessageV(
    int category,
    int priority,
    ffi.Pointer<ffi.Int8> fmt,
    va_list ap,
  ) {
    return _SDL_LogMessageV(
      category,
      priority,
      fmt,
      ap,
    );
  }

  late final _SDL_LogMessageVPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Int32, ffi.Int32, ffi.Pointer<ffi.Int8>,
              va_list)>>('SDL_LogMessageV');
  late final _SDL_LogMessageV = _SDL_LogMessageVPtr.asFunction<
      void Function(int, int, ffi.Pointer<ffi.Int8>, va_list)>();

  /// Get the current log output function.
  ///
  /// \param callback an SDL_LogOutputFunction filled in with the current log
  /// callback
  /// \param userdata a pointer filled in with the pointer that is passed to
  /// `callback`
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_LogSetOutputFunction
  void SDL_LogGetOutputFunction(
    ffi.Pointer<SDL_LogOutputFunction> callback,
    ffi.Pointer<ffi.Pointer<ffi.Void>> userdata,
  ) {
    return _SDL_LogGetOutputFunction(
      callback,
      userdata,
    );
  }

  late final _SDL_LogGetOutputFunctionPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<SDL_LogOutputFunction>,
              ffi.Pointer<ffi.Pointer<ffi.Void>>)>>('SDL_LogGetOutputFunction');
  late final _SDL_LogGetOutputFunction =
      _SDL_LogGetOutputFunctionPtr.asFunction<
          void Function(ffi.Pointer<SDL_LogOutputFunction>,
              ffi.Pointer<ffi.Pointer<ffi.Void>>)>();

  /// Replace the default log output function with one of your own.
  ///
  /// \param callback an SDL_LogOutputFunction to call instead of the default
  /// \param userdata a pointer that is passed to `callback`
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_LogGetOutputFunction
  void SDL_LogSetOutputFunction(
    SDL_LogOutputFunction callback,
    ffi.Pointer<ffi.Void> userdata,
  ) {
    return _SDL_LogSetOutputFunction(
      callback,
      userdata,
    );
  }

  late final _SDL_LogSetOutputFunctionPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(SDL_LogOutputFunction,
              ffi.Pointer<ffi.Void>)>>('SDL_LogSetOutputFunction');
  late final _SDL_LogSetOutputFunction =
      _SDL_LogSetOutputFunctionPtr.asFunction<
          void Function(SDL_LogOutputFunction, ffi.Pointer<ffi.Void>)>();

  /// Create a modal message box.
  ///
  /// If your needs aren't complex, it might be easier to use
  /// SDL_ShowSimpleMessageBox.
  ///
  /// This function should be called on the thread that created the parent
  /// window, or on the main thread if the messagebox has no parent. It will
  /// block execution of that thread until the user clicks a button or closes the
  /// messagebox.
  ///
  /// This function may be called at any time, even before SDL_Init(). This makes
  /// it useful for reporting errors like a failure to create a renderer or
  /// OpenGL context.
  ///
  /// On X11, SDL rolls its own dialog box with X11 primitives instead of a
  /// formal toolkit like GTK+ or Qt.
  ///
  /// Note that if SDL_Init() would fail because there isn't any available video
  /// target, this function is likely to fail for the same reasons. If this is a
  /// concern, check the return value from this function and fall back to writing
  /// to stderr if you can.
  ///
  /// \param messageboxdata the SDL_MessageBoxData structure with title, text and
  /// other options
  /// \param buttonid the pointer to which user id of hit button should be copied
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_ShowSimpleMessageBox
  int SDL_ShowMessageBox(
    ffi.Pointer<SDL_MessageBoxData> messageboxdata,
    ffi.Pointer<ffi.Int32> buttonid,
  ) {
    return _SDL_ShowMessageBox(
      messageboxdata,
      buttonid,
    );
  }

  late final _SDL_ShowMessageBoxPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_MessageBoxData>,
              ffi.Pointer<ffi.Int32>)>>('SDL_ShowMessageBox');
  late final _SDL_ShowMessageBox = _SDL_ShowMessageBoxPtr.asFunction<
      int Function(ffi.Pointer<SDL_MessageBoxData>, ffi.Pointer<ffi.Int32>)>();

  /// Display a simple modal message box.
  ///
  /// If your needs aren't complex, this function is preferred over
  /// SDL_ShowMessageBox.
  ///
  /// `flags` may be any of the following:
  ///
  /// - `SDL_MESSAGEBOX_ERROR`: error dialog
  /// - `SDL_MESSAGEBOX_WARNING`: warning dialog
  /// - `SDL_MESSAGEBOX_INFORMATION`: informational dialog
  ///
  /// This function should be called on the thread that created the parent
  /// window, or on the main thread if the messagebox has no parent. It will
  /// block execution of that thread until the user clicks a button or closes the
  /// messagebox.
  ///
  /// This function may be called at any time, even before SDL_Init(). This makes
  /// it useful for reporting errors like a failure to create a renderer or
  /// OpenGL context.
  ///
  /// On X11, SDL rolls its own dialog box with X11 primitives instead of a
  /// formal toolkit like GTK+ or Qt.
  ///
  /// Note that if SDL_Init() would fail because there isn't any available video
  /// target, this function is likely to fail for the same reasons. If this is a
  /// concern, check the return value from this function and fall back to writing
  /// to stderr if you can.
  ///
  /// \param flags an SDL_MessageBoxFlags value
  /// \param title UTF-8 title text
  /// \param message UTF-8 message text
  /// \param window the parent window, or NULL for no parent
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_ShowMessageBox
  int SDL_ShowSimpleMessageBox(
    int flags,
    ffi.Pointer<ffi.Int8> title,
    ffi.Pointer<ffi.Int8> message,
    ffi.Pointer<SDL_Window> window,
  ) {
    return _SDL_ShowSimpleMessageBox(
      flags,
      title,
      message,
      window,
    );
  }

  late final _SDL_ShowSimpleMessageBoxPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              Uint32,
              ffi.Pointer<ffi.Int8>,
              ffi.Pointer<ffi.Int8>,
              ffi.Pointer<SDL_Window>)>>('SDL_ShowSimpleMessageBox');
  late final _SDL_ShowSimpleMessageBox =
      _SDL_ShowSimpleMessageBoxPtr.asFunction<
          int Function(int, ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Int8>,
              ffi.Pointer<SDL_Window>)>();

  /// Create a CAMetalLayer-backed NSView/UIView and attach it to the specified
  /// window.
  ///
  /// On macOS, this does *not* associate a MTLDevice with the CAMetalLayer on
  /// its own. It is up to user code to do that.
  ///
  /// The returned handle can be casted directly to a NSView or UIView. To access
  /// the backing CAMetalLayer, call SDL_Metal_GetLayer().
  ///
  /// \since This function is available since SDL 2.0.12.
  ///
  /// \sa SDL_Metal_DestroyView
  /// \sa SDL_Metal_GetLayer
  SDL_MetalView SDL_Metal_CreateView(
    ffi.Pointer<SDL_Window> window,
  ) {
    return _SDL_Metal_CreateView(
      window,
    );
  }

  late final _SDL_Metal_CreateViewPtr = _lookup<
          ffi.NativeFunction<SDL_MetalView Function(ffi.Pointer<SDL_Window>)>>(
      'SDL_Metal_CreateView');
  late final _SDL_Metal_CreateView = _SDL_Metal_CreateViewPtr.asFunction<
      SDL_MetalView Function(ffi.Pointer<SDL_Window>)>();

  /// Destroy an existing SDL_MetalView object.
  ///
  /// This should be called before SDL_DestroyWindow, if SDL_Metal_CreateView was
  /// called after SDL_CreateWindow.
  ///
  /// \since This function is available since SDL 2.0.12.
  ///
  /// \sa SDL_Metal_CreateView
  void SDL_Metal_DestroyView(
    SDL_MetalView view,
  ) {
    return _SDL_Metal_DestroyView(
      view,
    );
  }

  late final _SDL_Metal_DestroyViewPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(SDL_MetalView)>>(
          'SDL_Metal_DestroyView');
  late final _SDL_Metal_DestroyView =
      _SDL_Metal_DestroyViewPtr.asFunction<void Function(SDL_MetalView)>();

  /// Get a pointer to the backing CAMetalLayer for the given view.
  ///
  /// \since This function is available since SDL 2.0.14.
  ///
  /// \sa SDL_MetalCreateView
  ffi.Pointer<ffi.Void> SDL_Metal_GetLayer(
    SDL_MetalView view,
  ) {
    return _SDL_Metal_GetLayer(
      view,
    );
  }

  late final _SDL_Metal_GetLayerPtr = _lookup<
          ffi.NativeFunction<ffi.Pointer<ffi.Void> Function(SDL_MetalView)>>(
      'SDL_Metal_GetLayer');
  late final _SDL_Metal_GetLayer = _SDL_Metal_GetLayerPtr.asFunction<
      ffi.Pointer<ffi.Void> Function(SDL_MetalView)>();

  /// Get the size of a window's underlying drawable in pixels (for use with
  /// setting viewport, scissor & etc).
  ///
  /// \param window SDL_Window from which the drawable size should be queried
  /// \param w Pointer to variable for storing the width in pixels, may be NULL
  ///
  /// \since This function is available since SDL 2.0.14.
  ///
  /// \sa SDL_GetWindowSize
  /// \sa SDL_CreateWindow
  void SDL_Metal_GetDrawableSize(
    ffi.Pointer<SDL_Window> window,
    ffi.Pointer<ffi.Int32> w,
    ffi.Pointer<ffi.Int32> h,
  ) {
    return _SDL_Metal_GetDrawableSize(
      window,
      w,
      h,
    );
  }

  late final _SDL_Metal_GetDrawableSizePtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<SDL_Window>, ffi.Pointer<ffi.Int32>,
              ffi.Pointer<ffi.Int32>)>>('SDL_Metal_GetDrawableSize');
  late final _SDL_Metal_GetDrawableSize =
      _SDL_Metal_GetDrawableSizePtr.asFunction<
          void Function(ffi.Pointer<SDL_Window>, ffi.Pointer<ffi.Int32>,
              ffi.Pointer<ffi.Int32>)>();

  /// Get the current power supply details.
  ///
  /// You should never take a battery status as absolute truth. Batteries
  /// (especially failing batteries) are delicate hardware, and the values
  /// reported here are best estimates based on what that hardware reports. It's
  /// not uncommon for older batteries to lose stored power much faster than it
  /// reports, or completely drain when reporting it has 20 percent left, etc.
  ///
  /// Battery status can change at any time; if you are concerned with power
  /// state, you should call this function frequently, and perhaps ignore changes
  /// until they seem to be stable for a few seconds.
  ///
  /// It's possible a platform can only report battery percentage or time left
  /// but not both.
  ///
  /// \param secs seconds of battery life left, you can pass a NULL here if you
  /// don't care, will return -1 if we can't determine a value, or
  /// we're not running on a battery
  /// \param pct percentage of battery life left, between 0 and 100, you can pass
  /// a NULL here if you don't care, will return -1 if we can't
  /// determine a value, or we're not running on a battery
  /// \returns an SDL_PowerState enum representing the current battery state.
  ///
  /// \since This function is available since SDL 2.0.0.
  int SDL_GetPowerInfo(
    ffi.Pointer<ffi.Int32> secs,
    ffi.Pointer<ffi.Int32> pct,
  ) {
    return _SDL_GetPowerInfo(
      secs,
      pct,
    );
  }

  late final _SDL_GetPowerInfoPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<ffi.Int32>,
              ffi.Pointer<ffi.Int32>)>>('SDL_GetPowerInfo');
  late final _SDL_GetPowerInfo = _SDL_GetPowerInfoPtr.asFunction<
      int Function(ffi.Pointer<ffi.Int32>, ffi.Pointer<ffi.Int32>)>();

  /// Get the number of 2D rendering drivers available for the current display.
  ///
  /// A render driver is a set of code that handles rendering and texture
  /// management on a particular display. Normally there is only one, but some
  /// drivers may have several available with different capabilities.
  ///
  /// There may be none if SDL was compiled without render support.
  ///
  /// \returns a number >= 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_CreateRenderer
  /// \sa SDL_GetRenderDriverInfo
  int SDL_GetNumRenderDrivers() {
    return _SDL_GetNumRenderDrivers();
  }

  late final _SDL_GetNumRenderDriversPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function()>>(
          'SDL_GetNumRenderDrivers');
  late final _SDL_GetNumRenderDrivers =
      _SDL_GetNumRenderDriversPtr.asFunction<int Function()>();

  /// Get info about a specific 2D rendering driver for the current display.
  ///
  /// \param index the index of the driver to query information about
  /// \param info an SDL_RendererInfo structure to be filled with information on
  /// the rendering driver
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_CreateRenderer
  /// \sa SDL_GetNumRenderDrivers
  int SDL_GetRenderDriverInfo(
    int index,
    ffi.Pointer<SDL_RendererInfo> info,
  ) {
    return _SDL_GetRenderDriverInfo(
      index,
      info,
    );
  }

  late final _SDL_GetRenderDriverInfoPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Int32,
              ffi.Pointer<SDL_RendererInfo>)>>('SDL_GetRenderDriverInfo');
  late final _SDL_GetRenderDriverInfo = _SDL_GetRenderDriverInfoPtr.asFunction<
      int Function(int, ffi.Pointer<SDL_RendererInfo>)>();

  /// Create a window and default renderer.
  ///
  /// \param width the width of the window
  /// \param height the height of the window
  /// \param window_flags the flags used to create the window (see
  /// SDL_CreateWindow())
  /// \param window a pointer filled with the window, or NULL on error
  /// \param renderer a pointer filled with the renderer, or NULL on error
  /// \returns 0 on success, or -1 on error; call SDL_GetError() for more
  /// information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_CreateRenderer
  /// \sa SDL_CreateWindow
  int SDL_CreateWindowAndRenderer(
    int width,
    int height,
    int window_flags,
    ffi.Pointer<ffi.Pointer<SDL_Window>> window,
    ffi.Pointer<ffi.Pointer<SDL_Renderer>> renderer,
  ) {
    return _SDL_CreateWindowAndRenderer(
      width,
      height,
      window_flags,
      window,
      renderer,
    );
  }

  late final _SDL_CreateWindowAndRendererPtr = _lookup<
          ffi.NativeFunction<
              ffi.Int32 Function(
                  ffi.Int32,
                  ffi.Int32,
                  Uint32,
                  ffi.Pointer<ffi.Pointer<SDL_Window>>,
                  ffi.Pointer<ffi.Pointer<SDL_Renderer>>)>>(
      'SDL_CreateWindowAndRenderer');
  late final _SDL_CreateWindowAndRenderer =
      _SDL_CreateWindowAndRendererPtr.asFunction<
          int Function(int, int, int, ffi.Pointer<ffi.Pointer<SDL_Window>>,
              ffi.Pointer<ffi.Pointer<SDL_Renderer>>)>();

  /// Create a 2D rendering context for a window.
  ///
  /// \param window the window where rendering is displayed
  /// \param index the index of the rendering driver to initialize, or -1 to
  /// initialize the first one supporting the requested flags
  /// \param flags 0, or one or more SDL_RendererFlags OR'd together
  /// \returns a valid rendering context or NULL if there was an error; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_CreateSoftwareRenderer
  /// \sa SDL_DestroyRenderer
  /// \sa SDL_GetNumRenderDrivers
  /// \sa SDL_GetRendererInfo
  ffi.Pointer<SDL_Renderer> SDL_CreateRenderer(
    ffi.Pointer<SDL_Window> window,
    int index,
    int flags,
  ) {
    return _SDL_CreateRenderer(
      window,
      index,
      flags,
    );
  }

  late final _SDL_CreateRendererPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<SDL_Renderer> Function(ffi.Pointer<SDL_Window>, ffi.Int32,
              Uint32)>>('SDL_CreateRenderer');
  late final _SDL_CreateRenderer = _SDL_CreateRendererPtr.asFunction<
      ffi.Pointer<SDL_Renderer> Function(ffi.Pointer<SDL_Window>, int, int)>();

  /// Create a 2D software rendering context for a surface.
  ///
  /// Two other API which can be used to create SDL_Renderer:
  /// SDL_CreateRenderer() and SDL_CreateWindowAndRenderer(). These can _also_
  /// create a software renderer, but they are intended to be used with an
  /// SDL_Window as the final destination and not an SDL_Surface.
  ///
  /// \param surface the SDL_Surface structure representing the surface where
  /// rendering is done
  /// \returns a valid rendering context or NULL if there was an error; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_CreateRenderer
  /// \sa SDL_CreateWindowRenderer
  /// \sa SDL_DestroyRenderer
  ffi.Pointer<SDL_Renderer> SDL_CreateSoftwareRenderer(
    ffi.Pointer<SDL_Surface> surface,
  ) {
    return _SDL_CreateSoftwareRenderer(
      surface,
    );
  }

  late final _SDL_CreateSoftwareRendererPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<SDL_Renderer> Function(
              ffi.Pointer<SDL_Surface>)>>('SDL_CreateSoftwareRenderer');
  late final _SDL_CreateSoftwareRenderer =
      _SDL_CreateSoftwareRendererPtr.asFunction<
          ffi.Pointer<SDL_Renderer> Function(ffi.Pointer<SDL_Surface>)>();

  /// Get the renderer associated with a window.
  ///
  /// \param window the window to query
  /// \returns the rendering context on success or NULL on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_CreateRenderer
  ffi.Pointer<SDL_Renderer> SDL_GetRenderer(
    ffi.Pointer<SDL_Window> window,
  ) {
    return _SDL_GetRenderer(
      window,
    );
  }

  late final _SDL_GetRendererPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<SDL_Renderer> Function(
              ffi.Pointer<SDL_Window>)>>('SDL_GetRenderer');
  late final _SDL_GetRenderer = _SDL_GetRendererPtr.asFunction<
      ffi.Pointer<SDL_Renderer> Function(ffi.Pointer<SDL_Window>)>();

  /// Get information about a rendering context.
  ///
  /// \param renderer the rendering context
  /// \param info an SDL_RendererInfo structure filled with information about the
  /// current renderer
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_CreateRenderer
  int SDL_GetRendererInfo(
    ffi.Pointer<SDL_Renderer> renderer,
    ffi.Pointer<SDL_RendererInfo> info,
  ) {
    return _SDL_GetRendererInfo(
      renderer,
      info,
    );
  }

  late final _SDL_GetRendererInfoPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_Renderer>,
              ffi.Pointer<SDL_RendererInfo>)>>('SDL_GetRendererInfo');
  late final _SDL_GetRendererInfo = _SDL_GetRendererInfoPtr.asFunction<
      int Function(ffi.Pointer<SDL_Renderer>, ffi.Pointer<SDL_RendererInfo>)>();

  /// Get the output size in pixels of a rendering context.
  ///
  /// Due to high-dpi displays, you might end up with a rendering context that
  /// has more pixels than the window that contains it, so use this instead of
  /// SDL_GetWindowSize() to decide how much drawing area you have.
  ///
  /// \param renderer the rendering context
  /// \param w an int filled with the width
  /// \param h an int filled with the height
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetRenderer
  int SDL_GetRendererOutputSize(
    ffi.Pointer<SDL_Renderer> renderer,
    ffi.Pointer<ffi.Int32> w,
    ffi.Pointer<ffi.Int32> h,
  ) {
    return _SDL_GetRendererOutputSize(
      renderer,
      w,
      h,
    );
  }

  late final _SDL_GetRendererOutputSizePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_Renderer>, ffi.Pointer<ffi.Int32>,
              ffi.Pointer<ffi.Int32>)>>('SDL_GetRendererOutputSize');
  late final _SDL_GetRendererOutputSize =
      _SDL_GetRendererOutputSizePtr.asFunction<
          int Function(ffi.Pointer<SDL_Renderer>, ffi.Pointer<ffi.Int32>,
              ffi.Pointer<ffi.Int32>)>();

  /// Create a texture for a rendering context.
  ///
  /// You can set the texture scaling method by setting
  /// `SDL_HINT_RENDER_SCALE_QUALITY` before creating the texture.
  ///
  /// \param renderer the rendering context
  /// \param format one of the enumerated values in SDL_PixelFormatEnum
  /// \param access one of the enumerated values in SDL_TextureAccess
  /// \param w the width of the texture in pixels
  /// \param h the height of the texture in pixels
  /// \returns a pointer to the created texture or NULL if no rendering context
  /// was active, the format was unsupported, or the width or height
  /// were out of range; call SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_CreateTextureFromSurface
  /// \sa SDL_DestroyTexture
  /// \sa SDL_QueryTexture
  /// \sa SDL_UpdateTexture
  ffi.Pointer<SDL_Texture> SDL_CreateTexture(
    ffi.Pointer<SDL_Renderer> renderer,
    int format,
    int access,
    int w,
    int h,
  ) {
    return _SDL_CreateTexture(
      renderer,
      format,
      access,
      w,
      h,
    );
  }

  late final _SDL_CreateTexturePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<SDL_Texture> Function(ffi.Pointer<SDL_Renderer>, Uint32,
              ffi.Int32, ffi.Int32, ffi.Int32)>>('SDL_CreateTexture');
  late final _SDL_CreateTexture = _SDL_CreateTexturePtr.asFunction<
      ffi.Pointer<SDL_Texture> Function(
          ffi.Pointer<SDL_Renderer>, int, int, int, int)>();

  /// Create a texture from an existing surface.
  ///
  /// The surface is not modified or freed by this function.
  ///
  /// The SDL_TextureAccess hint for the created texture is
  /// `SDL_TEXTUREACCESS_STATIC`.
  ///
  /// The pixel format of the created texture may be different from the pixel
  /// format of the surface. Use SDL_QueryTexture() to query the pixel format of
  /// the texture.
  ///
  /// \param renderer the rendering context
  /// \param surface the SDL_Surface structure containing pixel data used to fill
  /// the texture
  /// \returns the created texture or NULL on failure; call SDL_GetError() for
  /// more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_CreateTexture
  /// \sa SDL_DestroyTexture
  /// \sa SDL_QueryTexture
  ffi.Pointer<SDL_Texture> SDL_CreateTextureFromSurface(
    ffi.Pointer<SDL_Renderer> renderer,
    ffi.Pointer<SDL_Surface> surface,
  ) {
    return _SDL_CreateTextureFromSurface(
      renderer,
      surface,
    );
  }

  late final _SDL_CreateTextureFromSurfacePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<SDL_Texture> Function(ffi.Pointer<SDL_Renderer>,
              ffi.Pointer<SDL_Surface>)>>('SDL_CreateTextureFromSurface');
  late final _SDL_CreateTextureFromSurface =
      _SDL_CreateTextureFromSurfacePtr.asFunction<
          ffi.Pointer<SDL_Texture> Function(
              ffi.Pointer<SDL_Renderer>, ffi.Pointer<SDL_Surface>)>();

  /// Query the attributes of a texture.
  ///
  /// \param texture the texture to query
  /// \param format a pointer filled in with the raw format of the texture; the
  /// actual format may differ, but pixel transfers will use this
  /// format (one of the SDL_PixelFormatEnum values)
  /// \param access a pointer filled in with the actual access to the texture
  /// (one of the SDL_TextureAccess values)
  /// \param w a pointer filled in with the width of the texture in pixels
  /// \param h a pointer filled in with the height of the texture in pixels
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_CreateTexture
  int SDL_QueryTexture(
    ffi.Pointer<SDL_Texture> texture,
    ffi.Pointer<Uint32> format,
    ffi.Pointer<ffi.Int32> access,
    ffi.Pointer<ffi.Int32> w,
    ffi.Pointer<ffi.Int32> h,
  ) {
    return _SDL_QueryTexture(
      texture,
      format,
      access,
      w,
      h,
    );
  }

  late final _SDL_QueryTexturePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<SDL_Texture>,
              ffi.Pointer<Uint32>,
              ffi.Pointer<ffi.Int32>,
              ffi.Pointer<ffi.Int32>,
              ffi.Pointer<ffi.Int32>)>>('SDL_QueryTexture');
  late final _SDL_QueryTexture = _SDL_QueryTexturePtr.asFunction<
      int Function(
          ffi.Pointer<SDL_Texture>,
          ffi.Pointer<Uint32>,
          ffi.Pointer<ffi.Int32>,
          ffi.Pointer<ffi.Int32>,
          ffi.Pointer<ffi.Int32>)>();

  /// Set an additional color value multiplied into render copy operations.
  ///
  /// When this texture is rendered, during the copy operation each source color
  /// channel is modulated by the appropriate color value according to the
  /// following formula:
  ///
  /// `srcC = srcC * (color / 255)`
  ///
  /// Color modulation is not always supported by the renderer; it will return -1
  /// if color modulation is not supported.
  ///
  /// \param texture the texture to update
  /// \param r the red color value multiplied into copy operations
  /// \param g the green color value multiplied into copy operations
  /// \param b the blue color value multiplied into copy operations
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetTextureColorMod
  /// \sa SDL_SetTextureAlphaMod
  int SDL_SetTextureColorMod(
    ffi.Pointer<SDL_Texture> texture,
    int r,
    int g,
    int b,
  ) {
    return _SDL_SetTextureColorMod(
      texture,
      r,
      g,
      b,
    );
  }

  late final _SDL_SetTextureColorModPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_Texture>, Uint8, Uint8,
              Uint8)>>('SDL_SetTextureColorMod');
  late final _SDL_SetTextureColorMod = _SDL_SetTextureColorModPtr.asFunction<
      int Function(ffi.Pointer<SDL_Texture>, int, int, int)>();

  /// Get the additional color value multiplied into render copy operations.
  ///
  /// \param texture the texture to query
  /// \param r a pointer filled in with the current red color value
  /// \param g a pointer filled in with the current green color value
  /// \param b a pointer filled in with the current blue color value
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetTextureAlphaMod
  /// \sa SDL_SetTextureColorMod
  int SDL_GetTextureColorMod(
    ffi.Pointer<SDL_Texture> texture,
    ffi.Pointer<Uint8> r,
    ffi.Pointer<Uint8> g,
    ffi.Pointer<Uint8> b,
  ) {
    return _SDL_GetTextureColorMod(
      texture,
      r,
      g,
      b,
    );
  }

  late final _SDL_GetTextureColorModPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<SDL_Texture>,
              ffi.Pointer<Uint8>,
              ffi.Pointer<Uint8>,
              ffi.Pointer<Uint8>)>>('SDL_GetTextureColorMod');
  late final _SDL_GetTextureColorMod = _SDL_GetTextureColorModPtr.asFunction<
      int Function(ffi.Pointer<SDL_Texture>, ffi.Pointer<Uint8>,
          ffi.Pointer<Uint8>, ffi.Pointer<Uint8>)>();

  /// Set an additional alpha value multiplied into render copy operations.
  ///
  /// When this texture is rendered, during the copy operation the source alpha
  /// value is modulated by this alpha value according to the following formula:
  ///
  /// `srcA = srcA * (alpha / 255)`
  ///
  /// Alpha modulation is not always supported by the renderer; it will return -1
  /// if alpha modulation is not supported.
  ///
  /// \param texture the texture to update
  /// \param alpha the source alpha value multiplied into copy operations
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetTextureAlphaMod
  /// \sa SDL_SetTextureColorMod
  int SDL_SetTextureAlphaMod(
    ffi.Pointer<SDL_Texture> texture,
    int alpha,
  ) {
    return _SDL_SetTextureAlphaMod(
      texture,
      alpha,
    );
  }

  late final _SDL_SetTextureAlphaModPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<SDL_Texture>, Uint8)>>('SDL_SetTextureAlphaMod');
  late final _SDL_SetTextureAlphaMod = _SDL_SetTextureAlphaModPtr.asFunction<
      int Function(ffi.Pointer<SDL_Texture>, int)>();

  /// Get the additional alpha value multiplied into render copy operations.
  ///
  /// \param texture the texture to query
  /// \param alpha a pointer filled in with the current alpha value
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetTextureColorMod
  /// \sa SDL_SetTextureAlphaMod
  int SDL_GetTextureAlphaMod(
    ffi.Pointer<SDL_Texture> texture,
    ffi.Pointer<Uint8> alpha,
  ) {
    return _SDL_GetTextureAlphaMod(
      texture,
      alpha,
    );
  }

  late final _SDL_GetTextureAlphaModPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_Texture>,
              ffi.Pointer<Uint8>)>>('SDL_GetTextureAlphaMod');
  late final _SDL_GetTextureAlphaMod = _SDL_GetTextureAlphaModPtr.asFunction<
      int Function(ffi.Pointer<SDL_Texture>, ffi.Pointer<Uint8>)>();

  /// Set the blend mode for a texture, used by SDL_RenderCopy().
  ///
  /// If the blend mode is not supported, the closest supported mode is chosen
  /// and this function returns -1.
  ///
  /// \param texture the texture to update
  /// \param blendMode the SDL_BlendMode to use for texture blending
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetTextureBlendMode
  /// \sa SDL_RenderCopy
  int SDL_SetTextureBlendMode(
    ffi.Pointer<SDL_Texture> texture,
    int blendMode,
  ) {
    return _SDL_SetTextureBlendMode(
      texture,
      blendMode,
    );
  }

  late final _SDL_SetTextureBlendModePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<SDL_Texture>, ffi.Int32)>>('SDL_SetTextureBlendMode');
  late final _SDL_SetTextureBlendMode = _SDL_SetTextureBlendModePtr.asFunction<
      int Function(ffi.Pointer<SDL_Texture>, int)>();

  /// Get the blend mode used for texture copy operations.
  ///
  /// \param texture the texture to query
  /// \param blendMode a pointer filled in with the current SDL_BlendMode
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_SetTextureBlendMode
  int SDL_GetTextureBlendMode(
    ffi.Pointer<SDL_Texture> texture,
    ffi.Pointer<ffi.Int32> blendMode,
  ) {
    return _SDL_GetTextureBlendMode(
      texture,
      blendMode,
    );
  }

  late final _SDL_GetTextureBlendModePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_Texture>,
              ffi.Pointer<ffi.Int32>)>>('SDL_GetTextureBlendMode');
  late final _SDL_GetTextureBlendMode = _SDL_GetTextureBlendModePtr.asFunction<
      int Function(ffi.Pointer<SDL_Texture>, ffi.Pointer<ffi.Int32>)>();

  /// Set the scale mode used for texture scale operations.
  ///
  /// If the scale mode is not supported, the closest supported mode is chosen.
  ///
  /// \param texture The texture to update.
  /// \param scaleMode the SDL_ScaleMode to use for texture scaling.
  /// \returns 0 on success, or -1 if the texture is not valid.
  ///
  /// \since This function is available since SDL 2.0.12.
  ///
  /// \sa SDL_GetTextureScaleMode
  int SDL_SetTextureScaleMode(
    ffi.Pointer<SDL_Texture> texture,
    int scaleMode,
  ) {
    return _SDL_SetTextureScaleMode(
      texture,
      scaleMode,
    );
  }

  late final _SDL_SetTextureScaleModePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<SDL_Texture>, ffi.Int32)>>('SDL_SetTextureScaleMode');
  late final _SDL_SetTextureScaleMode = _SDL_SetTextureScaleModePtr.asFunction<
      int Function(ffi.Pointer<SDL_Texture>, int)>();

  /// Get the scale mode used for texture scale operations.
  ///
  /// \param texture the texture to query.
  /// \param scaleMode a pointer filled in with the current scale mode.
  /// \return 0 on success, or -1 if the texture is not valid.
  ///
  /// \since This function is available since SDL 2.0.12.
  ///
  /// \sa SDL_SetTextureScaleMode
  int SDL_GetTextureScaleMode(
    ffi.Pointer<SDL_Texture> texture,
    ffi.Pointer<ffi.Int32> scaleMode,
  ) {
    return _SDL_GetTextureScaleMode(
      texture,
      scaleMode,
    );
  }

  late final _SDL_GetTextureScaleModePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_Texture>,
              ffi.Pointer<ffi.Int32>)>>('SDL_GetTextureScaleMode');
  late final _SDL_GetTextureScaleMode = _SDL_GetTextureScaleModePtr.asFunction<
      int Function(ffi.Pointer<SDL_Texture>, ffi.Pointer<ffi.Int32>)>();

  /// Associate a user-specified pointer with a texture.
  ///
  /// \param texture the texture to update.
  /// \param userdata the pointer to associate with the texture.
  /// \returns 0 on success, or -1 if the texture is not valid.
  ///
  /// \since This function is available since SDL 2.0.18.
  ///
  /// \sa SDL_GetTextureUserData
  int SDL_SetTextureUserData(
    ffi.Pointer<SDL_Texture> texture,
    ffi.Pointer<ffi.Void> userdata,
  ) {
    return _SDL_SetTextureUserData(
      texture,
      userdata,
    );
  }

  late final _SDL_SetTextureUserDataPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_Texture>,
              ffi.Pointer<ffi.Void>)>>('SDL_SetTextureUserData');
  late final _SDL_SetTextureUserData = _SDL_SetTextureUserDataPtr.asFunction<
      int Function(ffi.Pointer<SDL_Texture>, ffi.Pointer<ffi.Void>)>();

  /// Get the user-specified pointer associated with a texture
  ///
  /// \param texture the texture to query.
  /// \return the pointer associated with the texture, or NULL if the texture is
  /// not valid.
  ///
  /// \since This function is available since SDL 2.0.18.
  ///
  /// \sa SDL_SetTextureUserData
  ffi.Pointer<ffi.Void> SDL_GetTextureUserData(
    ffi.Pointer<SDL_Texture> texture,
  ) {
    return _SDL_GetTextureUserData(
      texture,
    );
  }

  late final _SDL_GetTextureUserDataPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Void> Function(
              ffi.Pointer<SDL_Texture>)>>('SDL_GetTextureUserData');
  late final _SDL_GetTextureUserData = _SDL_GetTextureUserDataPtr.asFunction<
      ffi.Pointer<ffi.Void> Function(ffi.Pointer<SDL_Texture>)>();

  /// Update the given texture rectangle with new pixel data.
  ///
  /// The pixel data must be in the pixel format of the texture. Use
  /// SDL_QueryTexture() to query the pixel format of the texture.
  ///
  /// This is a fairly slow function, intended for use with static textures that
  /// do not change often.
  ///
  /// If the texture is intended to be updated often, it is preferred to create
  /// the texture as streaming and use the locking functions referenced below.
  /// While this function will work with streaming textures, for optimization
  /// reasons you may not get the pixels back if you lock the texture afterward.
  ///
  /// \param texture the texture to update
  /// \param rect an SDL_Rect structure representing the area to update, or NULL
  /// to update the entire texture
  /// \param pixels the raw pixel data in the format of the texture
  /// \param pitch the number of bytes in a row of pixel data, including padding
  /// between lines
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_CreateTexture
  /// \sa SDL_LockTexture
  /// \sa SDL_UnlockTexture
  int SDL_UpdateTexture(
    ffi.Pointer<SDL_Texture> texture,
    ffi.Pointer<SDL_Rect> rect,
    ffi.Pointer<ffi.Void> pixels,
    int pitch,
  ) {
    return _SDL_UpdateTexture(
      texture,
      rect,
      pixels,
      pitch,
    );
  }

  late final _SDL_UpdateTexturePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_Texture>, ffi.Pointer<SDL_Rect>,
              ffi.Pointer<ffi.Void>, ffi.Int32)>>('SDL_UpdateTexture');
  late final _SDL_UpdateTexture = _SDL_UpdateTexturePtr.asFunction<
      int Function(ffi.Pointer<SDL_Texture>, ffi.Pointer<SDL_Rect>,
          ffi.Pointer<ffi.Void>, int)>();

  /// Update a rectangle within a planar YV12 or IYUV texture with new pixel
  /// data.
  ///
  /// You can use SDL_UpdateTexture() as long as your pixel data is a contiguous
  /// block of Y and U/V planes in the proper order, but this function is
  /// available if your pixel data is not contiguous.
  ///
  /// \param texture the texture to update
  /// \param rect a pointer to the rectangle of pixels to update, or NULL to
  /// update the entire texture
  /// \param Yplane the raw pixel data for the Y plane
  /// \param Ypitch the number of bytes between rows of pixel data for the Y
  /// plane
  /// \param Uplane the raw pixel data for the U plane
  /// \param Upitch the number of bytes between rows of pixel data for the U
  /// plane
  /// \param Vplane the raw pixel data for the V plane
  /// \param Vpitch the number of bytes between rows of pixel data for the V
  /// plane
  /// \returns 0 on success or -1 if the texture is not valid; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.1.
  ///
  /// \sa SDL_UpdateTexture
  int SDL_UpdateYUVTexture(
    ffi.Pointer<SDL_Texture> texture,
    ffi.Pointer<SDL_Rect> rect,
    ffi.Pointer<Uint8> Yplane,
    int Ypitch,
    ffi.Pointer<Uint8> Uplane,
    int Upitch,
    ffi.Pointer<Uint8> Vplane,
    int Vpitch,
  ) {
    return _SDL_UpdateYUVTexture(
      texture,
      rect,
      Yplane,
      Ypitch,
      Uplane,
      Upitch,
      Vplane,
      Vpitch,
    );
  }

  late final _SDL_UpdateYUVTexturePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<SDL_Texture>,
              ffi.Pointer<SDL_Rect>,
              ffi.Pointer<Uint8>,
              ffi.Int32,
              ffi.Pointer<Uint8>,
              ffi.Int32,
              ffi.Pointer<Uint8>,
              ffi.Int32)>>('SDL_UpdateYUVTexture');
  late final _SDL_UpdateYUVTexture = _SDL_UpdateYUVTexturePtr.asFunction<
      int Function(
          ffi.Pointer<SDL_Texture>,
          ffi.Pointer<SDL_Rect>,
          ffi.Pointer<Uint8>,
          int,
          ffi.Pointer<Uint8>,
          int,
          ffi.Pointer<Uint8>,
          int)>();

  /// Update a rectangle within a planar NV12 or NV21 texture with new pixels.
  ///
  /// You can use SDL_UpdateTexture() as long as your pixel data is a contiguous
  /// block of NV12/21 planes in the proper order, but this function is available
  /// if your pixel data is not contiguous.
  ///
  /// \param texture the texture to update
  /// \param rect a pointer to the rectangle of pixels to update, or NULL to
  /// update the entire texture.
  /// \param Yplane the raw pixel data for the Y plane.
  /// \param Ypitch the number of bytes between rows of pixel data for the Y
  /// plane.
  /// \param UVplane the raw pixel data for the UV plane.
  /// \param UVpitch the number of bytes between rows of pixel data for the UV
  /// plane.
  /// \return 0 on success, or -1 if the texture is not valid.
  ///
  /// \since This function is available since SDL 2.0.16.
  int SDL_UpdateNVTexture(
    ffi.Pointer<SDL_Texture> texture,
    ffi.Pointer<SDL_Rect> rect,
    ffi.Pointer<Uint8> Yplane,
    int Ypitch,
    ffi.Pointer<Uint8> UVplane,
    int UVpitch,
  ) {
    return _SDL_UpdateNVTexture(
      texture,
      rect,
      Yplane,
      Ypitch,
      UVplane,
      UVpitch,
    );
  }

  late final _SDL_UpdateNVTexturePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<SDL_Texture>,
              ffi.Pointer<SDL_Rect>,
              ffi.Pointer<Uint8>,
              ffi.Int32,
              ffi.Pointer<Uint8>,
              ffi.Int32)>>('SDL_UpdateNVTexture');
  late final _SDL_UpdateNVTexture = _SDL_UpdateNVTexturePtr.asFunction<
      int Function(ffi.Pointer<SDL_Texture>, ffi.Pointer<SDL_Rect>,
          ffi.Pointer<Uint8>, int, ffi.Pointer<Uint8>, int)>();

  /// Lock a portion of the texture for **write-only** pixel access.
  ///
  /// As an optimization, the pixels made available for editing don't necessarily
  /// contain the old texture data. This is a write-only operation, and if you
  /// need to keep a copy of the texture data you should do that at the
  /// application level.
  ///
  /// You must use SDL_UnlockTexture() to unlock the pixels and apply any
  /// changes.
  ///
  /// \param texture the texture to lock for access, which was created with
  /// `SDL_TEXTUREACCESS_STREAMING`
  /// \param rect an SDL_Rect structure representing the area to lock for access;
  /// NULL to lock the entire texture
  /// \param pixels this is filled in with a pointer to the locked pixels,
  /// appropriately offset by the locked area
  /// \param pitch this is filled in with the pitch of the locked pixels; the
  /// pitch is the length of one row in bytes
  /// \returns 0 on success or a negative error code if the texture is not valid
  /// or was not created with `SDL_TEXTUREACCESS_STREAMING`; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_UnlockTexture
  int SDL_LockTexture(
    ffi.Pointer<SDL_Texture> texture,
    ffi.Pointer<SDL_Rect> rect,
    ffi.Pointer<ffi.Pointer<ffi.Void>> pixels,
    ffi.Pointer<ffi.Int32> pitch,
  ) {
    return _SDL_LockTexture(
      texture,
      rect,
      pixels,
      pitch,
    );
  }

  late final _SDL_LockTexturePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<SDL_Texture>,
              ffi.Pointer<SDL_Rect>,
              ffi.Pointer<ffi.Pointer<ffi.Void>>,
              ffi.Pointer<ffi.Int32>)>>('SDL_LockTexture');
  late final _SDL_LockTexture = _SDL_LockTexturePtr.asFunction<
      int Function(ffi.Pointer<SDL_Texture>, ffi.Pointer<SDL_Rect>,
          ffi.Pointer<ffi.Pointer<ffi.Void>>, ffi.Pointer<ffi.Int32>)>();

  /// Lock a portion of the texture for **write-only** pixel access, and expose
  /// it as a SDL surface.
  ///
  /// Besides providing an SDL_Surface instead of raw pixel data, this function
  /// operates like SDL_LockTexture.
  ///
  /// As an optimization, the pixels made available for editing don't necessarily
  /// contain the old texture data. This is a write-only operation, and if you
  /// need to keep a copy of the texture data you should do that at the
  /// application level.
  ///
  /// You must use SDL_UnlockTexture() to unlock the pixels and apply any
  /// changes.
  ///
  /// The returned surface is freed internally after calling SDL_UnlockTexture()
  /// or SDL_DestroyTexture(). The caller should not free it.
  ///
  /// \param texture the texture to lock for access, which was created with
  /// `SDL_TEXTUREACCESS_STREAMING`
  /// \param rect a pointer to the rectangle to lock for access. If the rect is
  /// NULL, the entire texture will be locked
  /// \param surface this is filled in with an SDL surface representing the
  /// locked area
  /// \returns 0 on success, or -1 if the texture is not valid or was not created
  /// with `SDL_TEXTUREACCESS_STREAMING`
  ///
  /// \since This function is available since SDL 2.0.12.
  ///
  /// \sa SDL_LockTexture
  /// \sa SDL_UnlockTexture
  int SDL_LockTextureToSurface(
    ffi.Pointer<SDL_Texture> texture,
    ffi.Pointer<SDL_Rect> rect,
    ffi.Pointer<ffi.Pointer<SDL_Surface>> surface,
  ) {
    return _SDL_LockTextureToSurface(
      texture,
      rect,
      surface,
    );
  }

  late final _SDL_LockTextureToSurfacePtr = _lookup<
          ffi.NativeFunction<
              ffi.Int32 Function(
                  ffi.Pointer<SDL_Texture>,
                  ffi.Pointer<SDL_Rect>,
                  ffi.Pointer<ffi.Pointer<SDL_Surface>>)>>(
      'SDL_LockTextureToSurface');
  late final _SDL_LockTextureToSurface =
      _SDL_LockTextureToSurfacePtr.asFunction<
          int Function(ffi.Pointer<SDL_Texture>, ffi.Pointer<SDL_Rect>,
              ffi.Pointer<ffi.Pointer<SDL_Surface>>)>();

  /// Unlock a texture, uploading the changes to video memory, if needed.
  ///
  /// **Warning**: Please note that SDL_LockTexture() is intended to be
  /// write-only; it will not guarantee the previous contents of the texture will
  /// be provided. You must fully initialize any area of a texture that you lock
  /// before unlocking it, as the pixels might otherwise be uninitialized memory.
  ///
  /// Which is to say: locking and immediately unlocking a texture can result in
  /// corrupted textures, depending on the renderer in use.
  ///
  /// \param texture a texture locked by SDL_LockTexture()
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_LockTexture
  void SDL_UnlockTexture(
    ffi.Pointer<SDL_Texture> texture,
  ) {
    return _SDL_UnlockTexture(
      texture,
    );
  }

  late final _SDL_UnlockTexturePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<SDL_Texture>)>>(
          'SDL_UnlockTexture');
  late final _SDL_UnlockTexture = _SDL_UnlockTexturePtr.asFunction<
      void Function(ffi.Pointer<SDL_Texture>)>();

  /// Determine whether a renderer supports the use of render targets.
  ///
  /// \param renderer the renderer that will be checked
  /// \returns SDL_TRUE if supported or SDL_FALSE if not.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_SetRenderTarget
  int SDL_RenderTargetSupported(
    ffi.Pointer<SDL_Renderer> renderer,
  ) {
    return _SDL_RenderTargetSupported(
      renderer,
    );
  }

  late final _SDL_RenderTargetSupportedPtr = _lookup<
          ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<SDL_Renderer>)>>(
      'SDL_RenderTargetSupported');
  late final _SDL_RenderTargetSupported = _SDL_RenderTargetSupportedPtr
      .asFunction<int Function(ffi.Pointer<SDL_Renderer>)>();

  /// Set a texture as the current rendering target.
  ///
  /// Before using this function, you should check the
  /// `SDL_RENDERER_TARGETTEXTURE` bit in the flags of SDL_RendererInfo to see if
  /// render targets are supported.
  ///
  /// The default render target is the window for which the renderer was created.
  /// To stop rendering to a texture and render to the window again, call this
  /// function with a NULL `texture`.
  ///
  /// \param renderer the rendering context
  /// \param texture the targeted texture, which must be created with the
  /// `SDL_TEXTUREACCESS_TARGET` flag, or NULL to render to the
  /// window instead of a texture.
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetRenderTarget
  int SDL_SetRenderTarget(
    ffi.Pointer<SDL_Renderer> renderer,
    ffi.Pointer<SDL_Texture> texture,
  ) {
    return _SDL_SetRenderTarget(
      renderer,
      texture,
    );
  }

  late final _SDL_SetRenderTargetPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_Renderer>,
              ffi.Pointer<SDL_Texture>)>>('SDL_SetRenderTarget');
  late final _SDL_SetRenderTarget = _SDL_SetRenderTargetPtr.asFunction<
      int Function(ffi.Pointer<SDL_Renderer>, ffi.Pointer<SDL_Texture>)>();

  /// Get the current render target.
  ///
  /// The default render target is the window for which the renderer was created,
  /// and is reported a NULL here.
  ///
  /// \param renderer the rendering context
  /// \returns the current render target or NULL for the default render target.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_SetRenderTarget
  ffi.Pointer<SDL_Texture> SDL_GetRenderTarget(
    ffi.Pointer<SDL_Renderer> renderer,
  ) {
    return _SDL_GetRenderTarget(
      renderer,
    );
  }

  late final _SDL_GetRenderTargetPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<SDL_Texture> Function(
              ffi.Pointer<SDL_Renderer>)>>('SDL_GetRenderTarget');
  late final _SDL_GetRenderTarget = _SDL_GetRenderTargetPtr.asFunction<
      ffi.Pointer<SDL_Texture> Function(ffi.Pointer<SDL_Renderer>)>();

  /// Set a device independent resolution for rendering.
  ///
  /// This function uses the viewport and scaling functionality to allow a fixed
  /// logical resolution for rendering, regardless of the actual output
  /// resolution. If the actual output resolution doesn't have the same aspect
  /// ratio the output rendering will be centered within the output display.
  ///
  /// If the output display is a window, mouse and touch events in the window
  /// will be filtered and scaled so they seem to arrive within the logical
  /// resolution. The SDL_HINT_MOUSE_RELATIVE_SCALING hint controls whether
  /// relative motion events are also scaled.
  ///
  /// If this function results in scaling or subpixel drawing by the rendering
  /// backend, it will be handled using the appropriate quality hints.
  ///
  /// \param renderer the renderer for which resolution should be set
  /// \param w the width of the logical resolution
  /// \param h the height of the logical resolution
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_RenderGetLogicalSize
  int SDL_RenderSetLogicalSize(
    ffi.Pointer<SDL_Renderer> renderer,
    int w,
    int h,
  ) {
    return _SDL_RenderSetLogicalSize(
      renderer,
      w,
      h,
    );
  }

  late final _SDL_RenderSetLogicalSizePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_Renderer>, ffi.Int32,
              ffi.Int32)>>('SDL_RenderSetLogicalSize');
  late final _SDL_RenderSetLogicalSize = _SDL_RenderSetLogicalSizePtr
      .asFunction<int Function(ffi.Pointer<SDL_Renderer>, int, int)>();

  /// Get device independent resolution for rendering.
  ///
  /// This may return 0 for `w` and `h` if the SDL_Renderer has never had its
  /// logical size set by SDL_RenderSetLogicalSize() and never had a render
  /// target set.
  ///
  /// \param renderer a rendering context
  /// \param w an int to be filled with the width
  /// \param h an int to be filled with the height
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_RenderSetLogicalSize
  void SDL_RenderGetLogicalSize(
    ffi.Pointer<SDL_Renderer> renderer,
    ffi.Pointer<ffi.Int32> w,
    ffi.Pointer<ffi.Int32> h,
  ) {
    return _SDL_RenderGetLogicalSize(
      renderer,
      w,
      h,
    );
  }

  late final _SDL_RenderGetLogicalSizePtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<SDL_Renderer>, ffi.Pointer<ffi.Int32>,
              ffi.Pointer<ffi.Int32>)>>('SDL_RenderGetLogicalSize');
  late final _SDL_RenderGetLogicalSize =
      _SDL_RenderGetLogicalSizePtr.asFunction<
          void Function(ffi.Pointer<SDL_Renderer>, ffi.Pointer<ffi.Int32>,
              ffi.Pointer<ffi.Int32>)>();

  /// Set whether to force integer scales for resolution-independent rendering.
  ///
  /// This function restricts the logical viewport to integer values - that is,
  /// when a resolution is between two multiples of a logical size, the viewport
  /// size is rounded down to the lower multiple.
  ///
  /// \param renderer the renderer for which integer scaling should be set
  /// \param enable enable or disable the integer scaling for rendering
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.5.
  ///
  /// \sa SDL_RenderGetIntegerScale
  /// \sa SDL_RenderSetLogicalSize
  int SDL_RenderSetIntegerScale(
    ffi.Pointer<SDL_Renderer> renderer,
    int enable,
  ) {
    return _SDL_RenderSetIntegerScale(
      renderer,
      enable,
    );
  }

  late final _SDL_RenderSetIntegerScalePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_Renderer>,
              ffi.Int32)>>('SDL_RenderSetIntegerScale');
  late final _SDL_RenderSetIntegerScale = _SDL_RenderSetIntegerScalePtr
      .asFunction<int Function(ffi.Pointer<SDL_Renderer>, int)>();

  /// Get whether integer scales are forced for resolution-independent rendering.
  ///
  /// \param renderer the renderer from which integer scaling should be queried
  /// \returns SDL_TRUE if integer scales are forced or SDL_FALSE if not and on
  /// failure; call SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.5.
  ///
  /// \sa SDL_RenderSetIntegerScale
  int SDL_RenderGetIntegerScale(
    ffi.Pointer<SDL_Renderer> renderer,
  ) {
    return _SDL_RenderGetIntegerScale(
      renderer,
    );
  }

  late final _SDL_RenderGetIntegerScalePtr = _lookup<
          ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<SDL_Renderer>)>>(
      'SDL_RenderGetIntegerScale');
  late final _SDL_RenderGetIntegerScale = _SDL_RenderGetIntegerScalePtr
      .asFunction<int Function(ffi.Pointer<SDL_Renderer>)>();

  /// Set the drawing area for rendering on the current target.
  ///
  /// When the window is resized, the viewport is reset to fill the entire new
  /// window size.
  ///
  /// \param renderer the rendering context
  /// \param rect the SDL_Rect structure representing the drawing area, or NULL
  /// to set the viewport to the entire target
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_RenderGetViewport
  int SDL_RenderSetViewport(
    ffi.Pointer<SDL_Renderer> renderer,
    ffi.Pointer<SDL_Rect> rect,
  ) {
    return _SDL_RenderSetViewport(
      renderer,
      rect,
    );
  }

  late final _SDL_RenderSetViewportPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_Renderer>,
              ffi.Pointer<SDL_Rect>)>>('SDL_RenderSetViewport');
  late final _SDL_RenderSetViewport = _SDL_RenderSetViewportPtr.asFunction<
      int Function(ffi.Pointer<SDL_Renderer>, ffi.Pointer<SDL_Rect>)>();

  /// Get the drawing area for the current target.
  ///
  /// \param renderer the rendering context
  /// \param rect an SDL_Rect structure filled in with the current drawing area
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_RenderSetViewport
  void SDL_RenderGetViewport(
    ffi.Pointer<SDL_Renderer> renderer,
    ffi.Pointer<SDL_Rect> rect,
  ) {
    return _SDL_RenderGetViewport(
      renderer,
      rect,
    );
  }

  late final _SDL_RenderGetViewportPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<SDL_Renderer>,
              ffi.Pointer<SDL_Rect>)>>('SDL_RenderGetViewport');
  late final _SDL_RenderGetViewport = _SDL_RenderGetViewportPtr.asFunction<
      void Function(ffi.Pointer<SDL_Renderer>, ffi.Pointer<SDL_Rect>)>();

  /// Set the clip rectangle for rendering on the specified target.
  ///
  /// \param renderer the rendering context for which clip rectangle should be
  /// set
  /// \param rect an SDL_Rect structure representing the clip area, relative to
  /// the viewport, or NULL to disable clipping
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_RenderGetClipRect
  /// \sa SDL_RenderIsClipEnabled
  int SDL_RenderSetClipRect(
    ffi.Pointer<SDL_Renderer> renderer,
    ffi.Pointer<SDL_Rect> rect,
  ) {
    return _SDL_RenderSetClipRect(
      renderer,
      rect,
    );
  }

  late final _SDL_RenderSetClipRectPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_Renderer>,
              ffi.Pointer<SDL_Rect>)>>('SDL_RenderSetClipRect');
  late final _SDL_RenderSetClipRect = _SDL_RenderSetClipRectPtr.asFunction<
      int Function(ffi.Pointer<SDL_Renderer>, ffi.Pointer<SDL_Rect>)>();

  /// Get the clip rectangle for the current target.
  ///
  /// \param renderer the rendering context from which clip rectangle should be
  /// queried
  /// \param rect an SDL_Rect structure filled in with the current clipping area
  /// or an empty rectangle if clipping is disabled
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_RenderIsClipEnabled
  /// \sa SDL_RenderSetClipRect
  void SDL_RenderGetClipRect(
    ffi.Pointer<SDL_Renderer> renderer,
    ffi.Pointer<SDL_Rect> rect,
  ) {
    return _SDL_RenderGetClipRect(
      renderer,
      rect,
    );
  }

  late final _SDL_RenderGetClipRectPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<SDL_Renderer>,
              ffi.Pointer<SDL_Rect>)>>('SDL_RenderGetClipRect');
  late final _SDL_RenderGetClipRect = _SDL_RenderGetClipRectPtr.asFunction<
      void Function(ffi.Pointer<SDL_Renderer>, ffi.Pointer<SDL_Rect>)>();

  /// Get whether clipping is enabled on the given renderer.
  ///
  /// \param renderer the renderer from which clip state should be queried
  /// \returns SDL_TRUE if clipping is enabled or SDL_FALSE if not; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.4.
  ///
  /// \sa SDL_RenderGetClipRect
  /// \sa SDL_RenderSetClipRect
  int SDL_RenderIsClipEnabled(
    ffi.Pointer<SDL_Renderer> renderer,
  ) {
    return _SDL_RenderIsClipEnabled(
      renderer,
    );
  }

  late final _SDL_RenderIsClipEnabledPtr = _lookup<
          ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<SDL_Renderer>)>>(
      'SDL_RenderIsClipEnabled');
  late final _SDL_RenderIsClipEnabled = _SDL_RenderIsClipEnabledPtr.asFunction<
      int Function(ffi.Pointer<SDL_Renderer>)>();

  /// Set the drawing scale for rendering on the current target.
  ///
  /// The drawing coordinates are scaled by the x/y scaling factors before they
  /// are used by the renderer. This allows resolution independent drawing with a
  /// single coordinate system.
  ///
  /// If this results in scaling or subpixel drawing by the rendering backend, it
  /// will be handled using the appropriate quality hints. For best results use
  /// integer scaling factors.
  ///
  /// \param renderer a rendering context
  /// \param scaleX the horizontal scaling factor
  /// \param scaleY the vertical scaling factor
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_RenderGetScale
  /// \sa SDL_RenderSetLogicalSize
  int SDL_RenderSetScale(
    ffi.Pointer<SDL_Renderer> renderer,
    double scaleX,
    double scaleY,
  ) {
    return _SDL_RenderSetScale(
      renderer,
      scaleX,
      scaleY,
    );
  }

  late final _SDL_RenderSetScalePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_Renderer>, ffi.Float,
              ffi.Float)>>('SDL_RenderSetScale');
  late final _SDL_RenderSetScale = _SDL_RenderSetScalePtr.asFunction<
      int Function(ffi.Pointer<SDL_Renderer>, double, double)>();

  /// Get the drawing scale for the current target.
  ///
  /// \param renderer the renderer from which drawing scale should be queried
  /// \param scaleX a pointer filled in with the horizontal scaling factor
  /// \param scaleY a pointer filled in with the vertical scaling factor
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_RenderSetScale
  void SDL_RenderGetScale(
    ffi.Pointer<SDL_Renderer> renderer,
    ffi.Pointer<ffi.Float> scaleX,
    ffi.Pointer<ffi.Float> scaleY,
  ) {
    return _SDL_RenderGetScale(
      renderer,
      scaleX,
      scaleY,
    );
  }

  late final _SDL_RenderGetScalePtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(ffi.Pointer<SDL_Renderer>, ffi.Pointer<ffi.Float>,
              ffi.Pointer<ffi.Float>)>>('SDL_RenderGetScale');
  late final _SDL_RenderGetScale = _SDL_RenderGetScalePtr.asFunction<
      void Function(ffi.Pointer<SDL_Renderer>, ffi.Pointer<ffi.Float>,
          ffi.Pointer<ffi.Float>)>();

  /// Get logical coordinates of point in renderer when given real coordinates of
  /// point in window.
  ///
  /// Logical coordinates will differ from real coordinates when render is scaled
  /// and logical renderer size set
  ///
  /// \param renderer the renderer from which the logical coordinates should be
  /// calcualted
  /// \param windowX the real X coordinate in the window
  /// \param windowY the real Y coordinate in the window
  /// \param logicalX the pointer filled with the logical x coordinate
  /// \param logicalY the pointer filled with the logical y coordinate
  ///
  /// \since This function is available since SDL 2.0.18.
  ///
  /// \sa SDL_RenderGetScale
  /// \sa SDL_RenderSetScale
  /// \sa SDL_RenderGetLogicalSize
  /// \sa SDL_RenderSetLogicalSize
  void SDL_RenderWindowToLogical(
    ffi.Pointer<SDL_Renderer> renderer,
    int windowX,
    int windowY,
    ffi.Pointer<ffi.Float> logicalX,
    ffi.Pointer<ffi.Float> logicalY,
  ) {
    return _SDL_RenderWindowToLogical(
      renderer,
      windowX,
      windowY,
      logicalX,
      logicalY,
    );
  }

  late final _SDL_RenderWindowToLogicalPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<SDL_Renderer>,
              ffi.Int32,
              ffi.Int32,
              ffi.Pointer<ffi.Float>,
              ffi.Pointer<ffi.Float>)>>('SDL_RenderWindowToLogical');
  late final _SDL_RenderWindowToLogical =
      _SDL_RenderWindowToLogicalPtr.asFunction<
          void Function(ffi.Pointer<SDL_Renderer>, int, int,
              ffi.Pointer<ffi.Float>, ffi.Pointer<ffi.Float>)>();

  /// Get real coordinates of point in window when given logical coordinates of point in renderer.
  /// Logical coordinates will differ from real coordinates when render is scaled and logical renderer size set
  ///
  /// \param renderer the renderer from which the window coordinates should be calculated
  /// \param logicalX the logical x coordinate
  /// \param logicalY the logical y coordinate
  /// \param windowX the pointer filled with the real X coordinate in the window
  /// \param windowY the pointer filled with the real Y coordinate in the window
  ///
  ///
  /// \since This function is available since SDL 2.0.18.
  ///
  /// \sa SDL_RenderGetScale
  /// \sa SDL_RenderSetScale
  /// \sa SDL_RenderGetLogicalSize
  /// \sa SDL_RenderSetLogicalSize
  void SDL_RenderLogicalToWindow(
    ffi.Pointer<SDL_Renderer> renderer,
    double logicalX,
    double logicalY,
    ffi.Pointer<ffi.Int32> windowX,
    ffi.Pointer<ffi.Int32> windowY,
  ) {
    return _SDL_RenderLogicalToWindow(
      renderer,
      logicalX,
      logicalY,
      windowX,
      windowY,
    );
  }

  late final _SDL_RenderLogicalToWindowPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(
              ffi.Pointer<SDL_Renderer>,
              ffi.Float,
              ffi.Float,
              ffi.Pointer<ffi.Int32>,
              ffi.Pointer<ffi.Int32>)>>('SDL_RenderLogicalToWindow');
  late final _SDL_RenderLogicalToWindow =
      _SDL_RenderLogicalToWindowPtr.asFunction<
          void Function(ffi.Pointer<SDL_Renderer>, double, double,
              ffi.Pointer<ffi.Int32>, ffi.Pointer<ffi.Int32>)>();

  /// Set the color used for drawing operations (Rect, Line and Clear).
  ///
  /// Set the color for drawing or filling rectangles, lines, and points, and for
  /// SDL_RenderClear().
  ///
  /// \param renderer the rendering context
  /// \param r the red value used to draw on the rendering target
  /// \param g the green value used to draw on the rendering target
  /// \param b the blue value used to draw on the rendering target
  /// \param a the alpha value used to draw on the rendering target; usually
  /// `SDL_ALPHA_OPAQUE` (255). Use SDL_SetRenderDrawBlendMode to
  /// specify how the alpha channel is used
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetRenderDrawColor
  /// \sa SDL_RenderClear
  /// \sa SDL_RenderDrawLine
  /// \sa SDL_RenderDrawLines
  /// \sa SDL_RenderDrawPoint
  /// \sa SDL_RenderDrawPoints
  /// \sa SDL_RenderDrawRect
  /// \sa SDL_RenderDrawRects
  /// \sa SDL_RenderFillRect
  /// \sa SDL_RenderFillRects
  int SDL_SetRenderDrawColor(
    ffi.Pointer<SDL_Renderer> renderer,
    int r,
    int g,
    int b,
    int a,
  ) {
    return _SDL_SetRenderDrawColor(
      renderer,
      r,
      g,
      b,
      a,
    );
  }

  late final _SDL_SetRenderDrawColorPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_Renderer>, Uint8, Uint8, Uint8,
              Uint8)>>('SDL_SetRenderDrawColor');
  late final _SDL_SetRenderDrawColor = _SDL_SetRenderDrawColorPtr.asFunction<
      int Function(ffi.Pointer<SDL_Renderer>, int, int, int, int)>();

  /// Get the color used for drawing operations (Rect, Line and Clear).
  ///
  /// \param renderer the rendering context
  /// \param r a pointer filled in with the red value used to draw on the
  /// rendering target
  /// \param g a pointer filled in with the green value used to draw on the
  /// rendering target
  /// \param b a pointer filled in with the blue value used to draw on the
  /// rendering target
  /// \param a a pointer filled in with the alpha value used to draw on the
  /// rendering target; usually `SDL_ALPHA_OPAQUE` (255)
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_SetRenderDrawColor
  int SDL_GetRenderDrawColor(
    ffi.Pointer<SDL_Renderer> renderer,
    ffi.Pointer<Uint8> r,
    ffi.Pointer<Uint8> g,
    ffi.Pointer<Uint8> b,
    ffi.Pointer<Uint8> a,
  ) {
    return _SDL_GetRenderDrawColor(
      renderer,
      r,
      g,
      b,
      a,
    );
  }

  late final _SDL_GetRenderDrawColorPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<SDL_Renderer>,
              ffi.Pointer<Uint8>,
              ffi.Pointer<Uint8>,
              ffi.Pointer<Uint8>,
              ffi.Pointer<Uint8>)>>('SDL_GetRenderDrawColor');
  late final _SDL_GetRenderDrawColor = _SDL_GetRenderDrawColorPtr.asFunction<
      int Function(ffi.Pointer<SDL_Renderer>, ffi.Pointer<Uint8>,
          ffi.Pointer<Uint8>, ffi.Pointer<Uint8>, ffi.Pointer<Uint8>)>();

  /// Set the blend mode used for drawing operations (Fill and Line).
  ///
  /// If the blend mode is not supported, the closest supported mode is chosen.
  ///
  /// \param renderer the rendering context
  /// \param blendMode the SDL_BlendMode to use for blending
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetRenderDrawBlendMode
  /// \sa SDL_RenderDrawLine
  /// \sa SDL_RenderDrawLines
  /// \sa SDL_RenderDrawPoint
  /// \sa SDL_RenderDrawPoints
  /// \sa SDL_RenderDrawRect
  /// \sa SDL_RenderDrawRects
  /// \sa SDL_RenderFillRect
  /// \sa SDL_RenderFillRects
  int SDL_SetRenderDrawBlendMode(
    ffi.Pointer<SDL_Renderer> renderer,
    int blendMode,
  ) {
    return _SDL_SetRenderDrawBlendMode(
      renderer,
      blendMode,
    );
  }

  late final _SDL_SetRenderDrawBlendModePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_Renderer>,
              ffi.Int32)>>('SDL_SetRenderDrawBlendMode');
  late final _SDL_SetRenderDrawBlendMode = _SDL_SetRenderDrawBlendModePtr
      .asFunction<int Function(ffi.Pointer<SDL_Renderer>, int)>();

  /// Get the blend mode used for drawing operations.
  ///
  /// \param renderer the rendering context
  /// \param blendMode a pointer filled in with the current SDL_BlendMode
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_SetRenderDrawBlendMode
  int SDL_GetRenderDrawBlendMode(
    ffi.Pointer<SDL_Renderer> renderer,
    ffi.Pointer<ffi.Int32> blendMode,
  ) {
    return _SDL_GetRenderDrawBlendMode(
      renderer,
      blendMode,
    );
  }

  late final _SDL_GetRenderDrawBlendModePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_Renderer>,
              ffi.Pointer<ffi.Int32>)>>('SDL_GetRenderDrawBlendMode');
  late final _SDL_GetRenderDrawBlendMode =
      _SDL_GetRenderDrawBlendModePtr.asFunction<
          int Function(ffi.Pointer<SDL_Renderer>, ffi.Pointer<ffi.Int32>)>();

  /// Clear the current rendering target with the drawing color.
  ///
  /// This function clears the entire rendering target, ignoring the viewport and
  /// the clip rectangle.
  ///
  /// \param renderer the rendering context
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_SetRenderDrawColor
  int SDL_RenderClear(
    ffi.Pointer<SDL_Renderer> renderer,
  ) {
    return _SDL_RenderClear(
      renderer,
    );
  }

  late final _SDL_RenderClearPtr = _lookup<
          ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<SDL_Renderer>)>>(
      'SDL_RenderClear');
  late final _SDL_RenderClear =
      _SDL_RenderClearPtr.asFunction<int Function(ffi.Pointer<SDL_Renderer>)>();

  /// Draw a point on the current rendering target.
  ///
  /// SDL_RenderDrawPoint() draws a single point. If you want to draw multiple,
  /// use SDL_RenderDrawPoints() instead.
  ///
  /// \param renderer the rendering context
  /// \param x the x coordinate of the point
  /// \param y the y coordinate of the point
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_RenderDrawLine
  /// \sa SDL_RenderDrawLines
  /// \sa SDL_RenderDrawPoints
  /// \sa SDL_RenderDrawRect
  /// \sa SDL_RenderDrawRects
  /// \sa SDL_RenderFillRect
  /// \sa SDL_RenderFillRects
  /// \sa SDL_RenderPresent
  /// \sa SDL_SetRenderDrawBlendMode
  /// \sa SDL_SetRenderDrawColor
  int SDL_RenderDrawPoint(
    ffi.Pointer<SDL_Renderer> renderer,
    int x,
    int y,
  ) {
    return _SDL_RenderDrawPoint(
      renderer,
      x,
      y,
    );
  }

  late final _SDL_RenderDrawPointPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_Renderer>, ffi.Int32,
              ffi.Int32)>>('SDL_RenderDrawPoint');
  late final _SDL_RenderDrawPoint = _SDL_RenderDrawPointPtr.asFunction<
      int Function(ffi.Pointer<SDL_Renderer>, int, int)>();

  /// Draw multiple points on the current rendering target.
  ///
  /// \param renderer the rendering context
  /// \param points an array of SDL_Point structures that represent the points to
  /// draw
  /// \param count the number of points to draw
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_RenderDrawLine
  /// \sa SDL_RenderDrawLines
  /// \sa SDL_RenderDrawPoint
  /// \sa SDL_RenderDrawRect
  /// \sa SDL_RenderDrawRects
  /// \sa SDL_RenderFillRect
  /// \sa SDL_RenderFillRects
  /// \sa SDL_RenderPresent
  /// \sa SDL_SetRenderDrawBlendMode
  /// \sa SDL_SetRenderDrawColor
  int SDL_RenderDrawPoints(
    ffi.Pointer<SDL_Renderer> renderer,
    ffi.Pointer<SDL_Point> points,
    int count,
  ) {
    return _SDL_RenderDrawPoints(
      renderer,
      points,
      count,
    );
  }

  late final _SDL_RenderDrawPointsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_Renderer>, ffi.Pointer<SDL_Point>,
              ffi.Int32)>>('SDL_RenderDrawPoints');
  late final _SDL_RenderDrawPoints = _SDL_RenderDrawPointsPtr.asFunction<
      int Function(ffi.Pointer<SDL_Renderer>, ffi.Pointer<SDL_Point>, int)>();

  /// Draw a line on the current rendering target.
  ///
  /// SDL_RenderDrawLine() draws the line to include both end points. If you want
  /// to draw multiple, connecting lines use SDL_RenderDrawLines() instead.
  ///
  /// \param renderer the rendering context
  /// \param x1 the x coordinate of the start point
  /// \param y1 the y coordinate of the start point
  /// \param x2 the x coordinate of the end point
  /// \param y2 the y coordinate of the end point
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_RenderDrawLines
  /// \sa SDL_RenderDrawPoint
  /// \sa SDL_RenderDrawPoints
  /// \sa SDL_RenderDrawRect
  /// \sa SDL_RenderDrawRects
  /// \sa SDL_RenderFillRect
  /// \sa SDL_RenderFillRects
  /// \sa SDL_RenderPresent
  /// \sa SDL_SetRenderDrawBlendMode
  /// \sa SDL_SetRenderDrawColor
  int SDL_RenderDrawLine(
    ffi.Pointer<SDL_Renderer> renderer,
    int x1,
    int y1,
    int x2,
    int y2,
  ) {
    return _SDL_RenderDrawLine(
      renderer,
      x1,
      y1,
      x2,
      y2,
    );
  }

  late final _SDL_RenderDrawLinePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_Renderer>, ffi.Int32, ffi.Int32,
              ffi.Int32, ffi.Int32)>>('SDL_RenderDrawLine');
  late final _SDL_RenderDrawLine = _SDL_RenderDrawLinePtr.asFunction<
      int Function(ffi.Pointer<SDL_Renderer>, int, int, int, int)>();

  /// Draw a series of connected lines on the current rendering target.
  ///
  /// \param renderer the rendering context
  /// \param points an array of SDL_Point structures representing points along
  /// the lines
  /// \param count the number of points, drawing count-1 lines
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_RenderDrawLine
  /// \sa SDL_RenderDrawPoint
  /// \sa SDL_RenderDrawPoints
  /// \sa SDL_RenderDrawRect
  /// \sa SDL_RenderDrawRects
  /// \sa SDL_RenderFillRect
  /// \sa SDL_RenderFillRects
  /// \sa SDL_RenderPresent
  /// \sa SDL_SetRenderDrawBlendMode
  /// \sa SDL_SetRenderDrawColor
  int SDL_RenderDrawLines(
    ffi.Pointer<SDL_Renderer> renderer,
    ffi.Pointer<SDL_Point> points,
    int count,
  ) {
    return _SDL_RenderDrawLines(
      renderer,
      points,
      count,
    );
  }

  late final _SDL_RenderDrawLinesPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_Renderer>, ffi.Pointer<SDL_Point>,
              ffi.Int32)>>('SDL_RenderDrawLines');
  late final _SDL_RenderDrawLines = _SDL_RenderDrawLinesPtr.asFunction<
      int Function(ffi.Pointer<SDL_Renderer>, ffi.Pointer<SDL_Point>, int)>();

  /// Draw a rectangle on the current rendering target.
  ///
  /// \param renderer the rendering context
  /// \param rect an SDL_Rect structure representing the rectangle to draw, or
  /// NULL to outline the entire rendering target
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_RenderDrawLine
  /// \sa SDL_RenderDrawLines
  /// \sa SDL_RenderDrawPoint
  /// \sa SDL_RenderDrawPoints
  /// \sa SDL_RenderDrawRects
  /// \sa SDL_RenderFillRect
  /// \sa SDL_RenderFillRects
  /// \sa SDL_RenderPresent
  /// \sa SDL_SetRenderDrawBlendMode
  /// \sa SDL_SetRenderDrawColor
  int SDL_RenderDrawRect(
    ffi.Pointer<SDL_Renderer> renderer,
    ffi.Pointer<SDL_Rect> rect,
  ) {
    return _SDL_RenderDrawRect(
      renderer,
      rect,
    );
  }

  late final _SDL_RenderDrawRectPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_Renderer>,
              ffi.Pointer<SDL_Rect>)>>('SDL_RenderDrawRect');
  late final _SDL_RenderDrawRect = _SDL_RenderDrawRectPtr.asFunction<
      int Function(ffi.Pointer<SDL_Renderer>, ffi.Pointer<SDL_Rect>)>();

  /// Draw some number of rectangles on the current rendering target.
  ///
  /// \param renderer the rendering context
  /// \param rects an array of SDL_Rect structures representing the rectangles to
  /// be drawn
  /// \param count the number of rectangles
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_RenderDrawLine
  /// \sa SDL_RenderDrawLines
  /// \sa SDL_RenderDrawPoint
  /// \sa SDL_RenderDrawPoints
  /// \sa SDL_RenderDrawRect
  /// \sa SDL_RenderFillRect
  /// \sa SDL_RenderFillRects
  /// \sa SDL_RenderPresent
  /// \sa SDL_SetRenderDrawBlendMode
  /// \sa SDL_SetRenderDrawColor
  int SDL_RenderDrawRects(
    ffi.Pointer<SDL_Renderer> renderer,
    ffi.Pointer<SDL_Rect> rects,
    int count,
  ) {
    return _SDL_RenderDrawRects(
      renderer,
      rects,
      count,
    );
  }

  late final _SDL_RenderDrawRectsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_Renderer>, ffi.Pointer<SDL_Rect>,
              ffi.Int32)>>('SDL_RenderDrawRects');
  late final _SDL_RenderDrawRects = _SDL_RenderDrawRectsPtr.asFunction<
      int Function(ffi.Pointer<SDL_Renderer>, ffi.Pointer<SDL_Rect>, int)>();

  /// Fill a rectangle on the current rendering target with the drawing color.
  ///
  /// The current drawing color is set by SDL_SetRenderDrawColor(), and the
  /// color's alpha value is ignored unless blending is enabled with the
  /// appropriate call to SDL_SetRenderDrawBlendMode().
  ///
  /// \param renderer the rendering context
  /// \param rect the SDL_Rect structure representing the rectangle to fill, or
  /// NULL for the entire rendering target
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_RenderDrawLine
  /// \sa SDL_RenderDrawLines
  /// \sa SDL_RenderDrawPoint
  /// \sa SDL_RenderDrawPoints
  /// \sa SDL_RenderDrawRect
  /// \sa SDL_RenderDrawRects
  /// \sa SDL_RenderFillRects
  /// \sa SDL_RenderPresent
  /// \sa SDL_SetRenderDrawBlendMode
  /// \sa SDL_SetRenderDrawColor
  int SDL_RenderFillRect(
    ffi.Pointer<SDL_Renderer> renderer,
    ffi.Pointer<SDL_Rect> rect,
  ) {
    return _SDL_RenderFillRect(
      renderer,
      rect,
    );
  }

  late final _SDL_RenderFillRectPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_Renderer>,
              ffi.Pointer<SDL_Rect>)>>('SDL_RenderFillRect');
  late final _SDL_RenderFillRect = _SDL_RenderFillRectPtr.asFunction<
      int Function(ffi.Pointer<SDL_Renderer>, ffi.Pointer<SDL_Rect>)>();

  /// Fill some number of rectangles on the current rendering target with the
  /// drawing color.
  ///
  /// \param renderer the rendering context
  /// \param rects an array of SDL_Rect structures representing the rectangles to
  /// be filled
  /// \param count the number of rectangles
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_RenderDrawLine
  /// \sa SDL_RenderDrawLines
  /// \sa SDL_RenderDrawPoint
  /// \sa SDL_RenderDrawPoints
  /// \sa SDL_RenderDrawRect
  /// \sa SDL_RenderDrawRects
  /// \sa SDL_RenderFillRect
  /// \sa SDL_RenderPresent
  int SDL_RenderFillRects(
    ffi.Pointer<SDL_Renderer> renderer,
    ffi.Pointer<SDL_Rect> rects,
    int count,
  ) {
    return _SDL_RenderFillRects(
      renderer,
      rects,
      count,
    );
  }

  late final _SDL_RenderFillRectsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_Renderer>, ffi.Pointer<SDL_Rect>,
              ffi.Int32)>>('SDL_RenderFillRects');
  late final _SDL_RenderFillRects = _SDL_RenderFillRectsPtr.asFunction<
      int Function(ffi.Pointer<SDL_Renderer>, ffi.Pointer<SDL_Rect>, int)>();

  /// Copy a portion of the texture to the current rendering target.
  ///
  /// The texture is blended with the destination based on its blend mode set
  /// with SDL_SetTextureBlendMode().
  ///
  /// The texture color is affected based on its color modulation set by
  /// SDL_SetTextureColorMod().
  ///
  /// The texture alpha is affected based on its alpha modulation set by
  /// SDL_SetTextureAlphaMod().
  ///
  /// \param renderer the rendering context
  /// \param texture the source texture
  /// \param srcrect the source SDL_Rect structure or NULL for the entire texture
  /// \param dstrect the destination SDL_Rect structure or NULL for the entire
  /// rendering target; the texture will be stretched to fill the
  /// given rectangle
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_RenderCopyEx
  /// \sa SDL_SetTextureAlphaMod
  /// \sa SDL_SetTextureBlendMode
  /// \sa SDL_SetTextureColorMod
  int SDL_RenderCopy(
    ffi.Pointer<SDL_Renderer> renderer,
    ffi.Pointer<SDL_Texture> texture,
    ffi.Pointer<SDL_Rect> srcrect,
    ffi.Pointer<SDL_Rect> dstrect,
  ) {
    return _SDL_RenderCopy(
      renderer,
      texture,
      srcrect,
      dstrect,
    );
  }

  late final _SDL_RenderCopyPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<SDL_Renderer>,
              ffi.Pointer<SDL_Texture>,
              ffi.Pointer<SDL_Rect>,
              ffi.Pointer<SDL_Rect>)>>('SDL_RenderCopy');
  late final _SDL_RenderCopy = _SDL_RenderCopyPtr.asFunction<
      int Function(ffi.Pointer<SDL_Renderer>, ffi.Pointer<SDL_Texture>,
          ffi.Pointer<SDL_Rect>, ffi.Pointer<SDL_Rect>)>();

  /// Copy a portion of the texture to the current rendering, with optional
  /// rotation and flipping.
  ///
  /// Copy a portion of the texture to the current rendering target, optionally
  /// rotating it by angle around the given center and also flipping it
  /// top-bottom and/or left-right.
  ///
  /// The texture is blended with the destination based on its blend mode set
  /// with SDL_SetTextureBlendMode().
  ///
  /// The texture color is affected based on its color modulation set by
  /// SDL_SetTextureColorMod().
  ///
  /// The texture alpha is affected based on its alpha modulation set by
  /// SDL_SetTextureAlphaMod().
  ///
  /// \param renderer the rendering context
  /// \param texture the source texture
  /// \param srcrect the source SDL_Rect structure or NULL for the entire texture
  /// \param dstrect the destination SDL_Rect structure or NULL for the entire
  /// rendering target
  /// \param angle an angle in degrees that indicates the rotation that will be
  /// applied to dstrect, rotating it in a clockwise direction
  /// \param center a pointer to a point indicating the point around which
  /// dstrect will be rotated (if NULL, rotation will be done
  /// around `dstrect.w / 2`, `dstrect.h / 2`)
  /// \param flip a SDL_RendererFlip value stating which flipping actions should
  /// be performed on the texture
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_RenderCopy
  /// \sa SDL_SetTextureAlphaMod
  /// \sa SDL_SetTextureBlendMode
  /// \sa SDL_SetTextureColorMod
  int SDL_RenderCopyEx(
    ffi.Pointer<SDL_Renderer> renderer,
    ffi.Pointer<SDL_Texture> texture,
    ffi.Pointer<SDL_Rect> srcrect,
    ffi.Pointer<SDL_Rect> dstrect,
    double angle,
    ffi.Pointer<SDL_Point> center,
    int flip,
  ) {
    return _SDL_RenderCopyEx(
      renderer,
      texture,
      srcrect,
      dstrect,
      angle,
      center,
      flip,
    );
  }

  late final _SDL_RenderCopyExPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<SDL_Renderer>,
              ffi.Pointer<SDL_Texture>,
              ffi.Pointer<SDL_Rect>,
              ffi.Pointer<SDL_Rect>,
              ffi.Double,
              ffi.Pointer<SDL_Point>,
              ffi.Int32)>>('SDL_RenderCopyEx');
  late final _SDL_RenderCopyEx = _SDL_RenderCopyExPtr.asFunction<
      int Function(
          ffi.Pointer<SDL_Renderer>,
          ffi.Pointer<SDL_Texture>,
          ffi.Pointer<SDL_Rect>,
          ffi.Pointer<SDL_Rect>,
          double,
          ffi.Pointer<SDL_Point>,
          int)>();

  /// Draw a point on the current rendering target at subpixel precision.
  ///
  /// \param renderer The renderer which should draw a point.
  /// \param x The x coordinate of the point.
  /// \param y The y coordinate of the point.
  /// \return 0 on success, or -1 on error
  ///
  /// \since This function is available since SDL 2.0.10.
  int SDL_RenderDrawPointF(
    ffi.Pointer<SDL_Renderer> renderer,
    double x,
    double y,
  ) {
    return _SDL_RenderDrawPointF(
      renderer,
      x,
      y,
    );
  }

  late final _SDL_RenderDrawPointFPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_Renderer>, ffi.Float,
              ffi.Float)>>('SDL_RenderDrawPointF');
  late final _SDL_RenderDrawPointF = _SDL_RenderDrawPointFPtr.asFunction<
      int Function(ffi.Pointer<SDL_Renderer>, double, double)>();

  /// Draw multiple points on the current rendering target at subpixel precision.
  ///
  /// \param renderer The renderer which should draw multiple points.
  /// \param points The points to draw
  /// \param count The number of points to draw
  /// \return 0 on success, or -1 on error
  ///
  /// \since This function is available since SDL 2.0.10.
  int SDL_RenderDrawPointsF(
    ffi.Pointer<SDL_Renderer> renderer,
    ffi.Pointer<SDL_FPoint> points,
    int count,
  ) {
    return _SDL_RenderDrawPointsF(
      renderer,
      points,
      count,
    );
  }

  late final _SDL_RenderDrawPointsFPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_Renderer>, ffi.Pointer<SDL_FPoint>,
              ffi.Int32)>>('SDL_RenderDrawPointsF');
  late final _SDL_RenderDrawPointsF = _SDL_RenderDrawPointsFPtr.asFunction<
      int Function(ffi.Pointer<SDL_Renderer>, ffi.Pointer<SDL_FPoint>, int)>();

  /// Draw a line on the current rendering target at subpixel precision.
  ///
  /// \param renderer The renderer which should draw a line.
  /// \param x1 The x coordinate of the start point.
  /// \param y1 The y coordinate of the start point.
  /// \param x2 The x coordinate of the end point.
  /// \param y2 The y coordinate of the end point.
  /// \return 0 on success, or -1 on error
  ///
  /// \since This function is available since SDL 2.0.10.
  int SDL_RenderDrawLineF(
    ffi.Pointer<SDL_Renderer> renderer,
    double x1,
    double y1,
    double x2,
    double y2,
  ) {
    return _SDL_RenderDrawLineF(
      renderer,
      x1,
      y1,
      x2,
      y2,
    );
  }

  late final _SDL_RenderDrawLineFPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_Renderer>, ffi.Float, ffi.Float,
              ffi.Float, ffi.Float)>>('SDL_RenderDrawLineF');
  late final _SDL_RenderDrawLineF = _SDL_RenderDrawLineFPtr.asFunction<
      int Function(
          ffi.Pointer<SDL_Renderer>, double, double, double, double)>();

  /// Draw a series of connected lines on the current rendering target at
  /// subpixel precision.
  ///
  /// \param renderer The renderer which should draw multiple lines.
  /// \param points The points along the lines
  /// \param count The number of points, drawing count-1 lines
  /// \return 0 on success, or -1 on error
  ///
  /// \since This function is available since SDL 2.0.10.
  int SDL_RenderDrawLinesF(
    ffi.Pointer<SDL_Renderer> renderer,
    ffi.Pointer<SDL_FPoint> points,
    int count,
  ) {
    return _SDL_RenderDrawLinesF(
      renderer,
      points,
      count,
    );
  }

  late final _SDL_RenderDrawLinesFPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_Renderer>, ffi.Pointer<SDL_FPoint>,
              ffi.Int32)>>('SDL_RenderDrawLinesF');
  late final _SDL_RenderDrawLinesF = _SDL_RenderDrawLinesFPtr.asFunction<
      int Function(ffi.Pointer<SDL_Renderer>, ffi.Pointer<SDL_FPoint>, int)>();

  /// Draw a rectangle on the current rendering target at subpixel precision.
  ///
  /// \param renderer The renderer which should draw a rectangle.
  /// \param rect A pointer to the destination rectangle, or NULL to outline the
  /// entire rendering target.
  /// \return 0 on success, or -1 on error
  ///
  /// \since This function is available since SDL 2.0.10.
  int SDL_RenderDrawRectF(
    ffi.Pointer<SDL_Renderer> renderer,
    ffi.Pointer<SDL_FRect> rect,
  ) {
    return _SDL_RenderDrawRectF(
      renderer,
      rect,
    );
  }

  late final _SDL_RenderDrawRectFPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_Renderer>,
              ffi.Pointer<SDL_FRect>)>>('SDL_RenderDrawRectF');
  late final _SDL_RenderDrawRectF = _SDL_RenderDrawRectFPtr.asFunction<
      int Function(ffi.Pointer<SDL_Renderer>, ffi.Pointer<SDL_FRect>)>();

  /// Draw some number of rectangles on the current rendering target at subpixel
  /// precision.
  ///
  /// \param renderer The renderer which should draw multiple rectangles.
  /// \param rects A pointer to an array of destination rectangles.
  /// \param count The number of rectangles.
  /// \return 0 on success, or -1 on error
  ///
  /// \since This function is available since SDL 2.0.10.
  int SDL_RenderDrawRectsF(
    ffi.Pointer<SDL_Renderer> renderer,
    ffi.Pointer<SDL_FRect> rects,
    int count,
  ) {
    return _SDL_RenderDrawRectsF(
      renderer,
      rects,
      count,
    );
  }

  late final _SDL_RenderDrawRectsFPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_Renderer>, ffi.Pointer<SDL_FRect>,
              ffi.Int32)>>('SDL_RenderDrawRectsF');
  late final _SDL_RenderDrawRectsF = _SDL_RenderDrawRectsFPtr.asFunction<
      int Function(ffi.Pointer<SDL_Renderer>, ffi.Pointer<SDL_FRect>, int)>();

  /// Fill a rectangle on the current rendering target with the drawing color at
  /// subpixel precision.
  ///
  /// \param renderer The renderer which should fill a rectangle.
  /// \param rect A pointer to the destination rectangle, or NULL for the entire
  /// rendering target.
  /// \return 0 on success, or -1 on error
  ///
  /// \since This function is available since SDL 2.0.10.
  int SDL_RenderFillRectF(
    ffi.Pointer<SDL_Renderer> renderer,
    ffi.Pointer<SDL_FRect> rect,
  ) {
    return _SDL_RenderFillRectF(
      renderer,
      rect,
    );
  }

  late final _SDL_RenderFillRectFPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_Renderer>,
              ffi.Pointer<SDL_FRect>)>>('SDL_RenderFillRectF');
  late final _SDL_RenderFillRectF = _SDL_RenderFillRectFPtr.asFunction<
      int Function(ffi.Pointer<SDL_Renderer>, ffi.Pointer<SDL_FRect>)>();

  /// Fill some number of rectangles on the current rendering target with the
  /// drawing color at subpixel precision.
  ///
  /// \param renderer The renderer which should fill multiple rectangles.
  /// \param rects A pointer to an array of destination rectangles.
  /// \param count The number of rectangles.
  /// \return 0 on success, or -1 on error
  ///
  /// \since This function is available since SDL 2.0.10.
  int SDL_RenderFillRectsF(
    ffi.Pointer<SDL_Renderer> renderer,
    ffi.Pointer<SDL_FRect> rects,
    int count,
  ) {
    return _SDL_RenderFillRectsF(
      renderer,
      rects,
      count,
    );
  }

  late final _SDL_RenderFillRectsFPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_Renderer>, ffi.Pointer<SDL_FRect>,
              ffi.Int32)>>('SDL_RenderFillRectsF');
  late final _SDL_RenderFillRectsF = _SDL_RenderFillRectsFPtr.asFunction<
      int Function(ffi.Pointer<SDL_Renderer>, ffi.Pointer<SDL_FRect>, int)>();

  /// Copy a portion of the texture to the current rendering target at subpixel
  /// precision.
  ///
  /// \param renderer The renderer which should copy parts of a texture.
  /// \param texture The source texture.
  /// \param srcrect A pointer to the source rectangle, or NULL for the entire
  /// texture.
  /// \param dstrect A pointer to the destination rectangle, or NULL for the
  /// entire rendering target.
  /// \return 0 on success, or -1 on error
  ///
  /// \since This function is available since SDL 2.0.10.
  int SDL_RenderCopyF(
    ffi.Pointer<SDL_Renderer> renderer,
    ffi.Pointer<SDL_Texture> texture,
    ffi.Pointer<SDL_Rect> srcrect,
    ffi.Pointer<SDL_FRect> dstrect,
  ) {
    return _SDL_RenderCopyF(
      renderer,
      texture,
      srcrect,
      dstrect,
    );
  }

  late final _SDL_RenderCopyFPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<SDL_Renderer>,
              ffi.Pointer<SDL_Texture>,
              ffi.Pointer<SDL_Rect>,
              ffi.Pointer<SDL_FRect>)>>('SDL_RenderCopyF');
  late final _SDL_RenderCopyF = _SDL_RenderCopyFPtr.asFunction<
      int Function(ffi.Pointer<SDL_Renderer>, ffi.Pointer<SDL_Texture>,
          ffi.Pointer<SDL_Rect>, ffi.Pointer<SDL_FRect>)>();

  /// Copy a portion of the source texture to the current rendering target, with
  /// rotation and flipping, at subpixel precision.
  ///
  /// \param renderer The renderer which should copy parts of a texture.
  /// \param texture The source texture.
  /// \param srcrect A pointer to the source rectangle, or NULL for the entire
  /// texture.
  /// \param dstrect A pointer to the destination rectangle, or NULL for the
  /// entire rendering target.
  /// \param angle An angle in degrees that indicates the rotation that will be
  /// applied to dstrect, rotating it in a clockwise direction
  /// \param center A pointer to a point indicating the point around which
  /// dstrect will be rotated (if NULL, rotation will be done
  /// around dstrect.w/2, dstrect.h/2).
  /// \param flip An SDL_RendererFlip value stating which flipping actions should
  /// be performed on the texture
  /// \return 0 on success, or -1 on error
  ///
  /// \since This function is available since SDL 2.0.10.
  int SDL_RenderCopyExF(
    ffi.Pointer<SDL_Renderer> renderer,
    ffi.Pointer<SDL_Texture> texture,
    ffi.Pointer<SDL_Rect> srcrect,
    ffi.Pointer<SDL_FRect> dstrect,
    double angle,
    ffi.Pointer<SDL_FPoint> center,
    int flip,
  ) {
    return _SDL_RenderCopyExF(
      renderer,
      texture,
      srcrect,
      dstrect,
      angle,
      center,
      flip,
    );
  }

  late final _SDL_RenderCopyExFPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<SDL_Renderer>,
              ffi.Pointer<SDL_Texture>,
              ffi.Pointer<SDL_Rect>,
              ffi.Pointer<SDL_FRect>,
              ffi.Double,
              ffi.Pointer<SDL_FPoint>,
              ffi.Int32)>>('SDL_RenderCopyExF');
  late final _SDL_RenderCopyExF = _SDL_RenderCopyExFPtr.asFunction<
      int Function(
          ffi.Pointer<SDL_Renderer>,
          ffi.Pointer<SDL_Texture>,
          ffi.Pointer<SDL_Rect>,
          ffi.Pointer<SDL_FRect>,
          double,
          ffi.Pointer<SDL_FPoint>,
          int)>();

  /// Render a list of triangles, optionally using a texture and indices into the
  /// vertex array Color and alpha modulation is done per vertex
  /// (SDL_SetTextureColorMod and SDL_SetTextureAlphaMod are ignored).
  ///
  /// \param texture (optional) The SDL texture to use.
  /// \param vertices Vertices.
  /// \param num_vertices Number of vertices.
  /// \param indices (optional) An array of integer indices into the 'vertices'
  /// array, if NULL all vertices will be rendered in sequential
  /// order.
  /// \param num_indices Number of indices.
  /// \return 0 on success, or -1 if the operation is not supported
  ///
  /// \since This function is available since SDL 2.0.18.
  ///
  /// \sa SDL_RenderGeometryRaw
  /// \sa SDL_Vertex
  int SDL_RenderGeometry(
    ffi.Pointer<SDL_Renderer> renderer,
    ffi.Pointer<SDL_Texture> texture,
    ffi.Pointer<SDL_Vertex> vertices,
    int num_vertices,
    ffi.Pointer<ffi.Int32> indices,
    int num_indices,
  ) {
    return _SDL_RenderGeometry(
      renderer,
      texture,
      vertices,
      num_vertices,
      indices,
      num_indices,
    );
  }

  late final _SDL_RenderGeometryPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<SDL_Renderer>,
              ffi.Pointer<SDL_Texture>,
              ffi.Pointer<SDL_Vertex>,
              ffi.Int32,
              ffi.Pointer<ffi.Int32>,
              ffi.Int32)>>('SDL_RenderGeometry');
  late final _SDL_RenderGeometry = _SDL_RenderGeometryPtr.asFunction<
      int Function(ffi.Pointer<SDL_Renderer>, ffi.Pointer<SDL_Texture>,
          ffi.Pointer<SDL_Vertex>, int, ffi.Pointer<ffi.Int32>, int)>();

  /// Render a list of triangles, optionally using a texture and indices into the
  /// vertex arrays Color and alpha modulation is done per vertex
  /// (SDL_SetTextureColorMod and SDL_SetTextureAlphaMod are ignored).
  ///
  /// \param texture (optional) The SDL texture to use.
  /// \param xy Vertex positions
  /// \param xy_stride Byte size to move from one element to the next element
  /// \param color Vertex colors (as SDL_Color)
  /// \param color_stride Byte size to move from one element to the next element
  /// \param uv Vertex normalized texture coordinates
  /// \param uv_stride Byte size to move from one element to the next element
  /// \param num_vertices Number of vertices.
  /// \param indices (optional) An array of indices into the 'vertices' arrays,
  /// if NULL all vertices will be rendered in sequential order.
  /// \param num_indices Number of indices.
  /// \param size_indices Index size: 1 (byte), 2 (short), 4 (int)
  /// \return 0 on success, or -1 if the operation is not supported
  ///
  /// \since This function is available since SDL 2.0.18.
  ///
  /// \sa SDL_RenderGeometry
  /// \sa SDL_Vertex
  int SDL_RenderGeometryRaw(
    ffi.Pointer<SDL_Renderer> renderer,
    ffi.Pointer<SDL_Texture> texture,
    ffi.Pointer<ffi.Float> xy,
    int xy_stride,
    ffi.Pointer<SDL_Color> color,
    int color_stride,
    ffi.Pointer<ffi.Float> uv,
    int uv_stride,
    int num_vertices,
    ffi.Pointer<ffi.Void> indices,
    int num_indices,
    int size_indices,
  ) {
    return _SDL_RenderGeometryRaw(
      renderer,
      texture,
      xy,
      xy_stride,
      color,
      color_stride,
      uv,
      uv_stride,
      num_vertices,
      indices,
      num_indices,
      size_indices,
    );
  }

  late final _SDL_RenderGeometryRawPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<SDL_Renderer>,
              ffi.Pointer<SDL_Texture>,
              ffi.Pointer<ffi.Float>,
              ffi.Int32,
              ffi.Pointer<SDL_Color>,
              ffi.Int32,
              ffi.Pointer<ffi.Float>,
              ffi.Int32,
              ffi.Int32,
              ffi.Pointer<ffi.Void>,
              ffi.Int32,
              ffi.Int32)>>('SDL_RenderGeometryRaw');
  late final _SDL_RenderGeometryRaw = _SDL_RenderGeometryRawPtr.asFunction<
      int Function(
          ffi.Pointer<SDL_Renderer>,
          ffi.Pointer<SDL_Texture>,
          ffi.Pointer<ffi.Float>,
          int,
          ffi.Pointer<SDL_Color>,
          int,
          ffi.Pointer<ffi.Float>,
          int,
          int,
          ffi.Pointer<ffi.Void>,
          int,
          int)>();

  /// Read pixels from the current rendering target to an array of pixels.
  ///
  /// **WARNING**: This is a very slow operation, and should not be used
  /// frequently.
  ///
  /// `pitch` specifies the number of bytes between rows in the destination
  /// `pixels` data. This allows you to write to a subrectangle or have padded
  /// rows in the destination. Generally, `pitch` should equal the number of
  /// pixels per row in the `pixels` data times the number of bytes per pixel,
  /// but it might contain additional padding (for example, 24bit RGB Windows
  /// Bitmap data pads all rows to multiples of 4 bytes).
  ///
  /// \param renderer the rendering context
  /// \param rect an SDL_Rect structure representing the area to read, or NULL
  /// for the entire render target
  /// \param format an SDL_PixelFormatEnum value of the desired format of the
  /// pixel data, or 0 to use the format of the rendering target
  /// \param pixels a pointer to the pixel data to copy into
  /// \param pitch the pitch of the `pixels` parameter
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  int SDL_RenderReadPixels(
    ffi.Pointer<SDL_Renderer> renderer,
    ffi.Pointer<SDL_Rect> rect,
    int format,
    ffi.Pointer<ffi.Void> pixels,
    int pitch,
  ) {
    return _SDL_RenderReadPixels(
      renderer,
      rect,
      format,
      pixels,
      pitch,
    );
  }

  late final _SDL_RenderReadPixelsPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<SDL_Renderer>,
              ffi.Pointer<SDL_Rect>,
              Uint32,
              ffi.Pointer<ffi.Void>,
              ffi.Int32)>>('SDL_RenderReadPixels');
  late final _SDL_RenderReadPixels = _SDL_RenderReadPixelsPtr.asFunction<
      int Function(ffi.Pointer<SDL_Renderer>, ffi.Pointer<SDL_Rect>, int,
          ffi.Pointer<ffi.Void>, int)>();

  /// Update the screen with any rendering performed since the previous call.
  ///
  /// SDL's rendering functions operate on a backbuffer; that is, calling a
  /// rendering function such as SDL_RenderDrawLine() does not directly put a
  /// line on the screen, but rather updates the backbuffer. As such, you compose
  /// your entire scene and *present* the composed backbuffer to the screen as a
  /// complete picture.
  ///
  /// Therefore, when using SDL's rendering API, one does all drawing intended
  /// for the frame, and then calls this function once per frame to present the
  /// final drawing to the user.
  ///
  /// The backbuffer should be considered invalidated after each present; do not
  /// assume that previous contents will exist between frames. You are strongly
  /// encouraged to call SDL_RenderClear() to initialize the backbuffer before
  /// starting each new frame's drawing, even if you plan to overwrite every
  /// pixel.
  ///
  /// \param renderer the rendering context
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_RenderClear
  /// \sa SDL_RenderDrawLine
  /// \sa SDL_RenderDrawLines
  /// \sa SDL_RenderDrawPoint
  /// \sa SDL_RenderDrawPoints
  /// \sa SDL_RenderDrawRect
  /// \sa SDL_RenderDrawRects
  /// \sa SDL_RenderFillRect
  /// \sa SDL_RenderFillRects
  /// \sa SDL_SetRenderDrawBlendMode
  /// \sa SDL_SetRenderDrawColor
  void SDL_RenderPresent(
    ffi.Pointer<SDL_Renderer> renderer,
  ) {
    return _SDL_RenderPresent(
      renderer,
    );
  }

  late final _SDL_RenderPresentPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<SDL_Renderer>)>>(
          'SDL_RenderPresent');
  late final _SDL_RenderPresent = _SDL_RenderPresentPtr.asFunction<
      void Function(ffi.Pointer<SDL_Renderer>)>();

  /// Destroy the specified texture.
  ///
  /// Passing NULL or an otherwise invalid texture will set the SDL error message
  /// to "Invalid texture".
  ///
  /// \param texture the texture to destroy
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_CreateTexture
  /// \sa SDL_CreateTextureFromSurface
  void SDL_DestroyTexture(
    ffi.Pointer<SDL_Texture> texture,
  ) {
    return _SDL_DestroyTexture(
      texture,
    );
  }

  late final _SDL_DestroyTexturePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<SDL_Texture>)>>(
          'SDL_DestroyTexture');
  late final _SDL_DestroyTexture = _SDL_DestroyTexturePtr.asFunction<
      void Function(ffi.Pointer<SDL_Texture>)>();

  /// Destroy the rendering context for a window and free associated textures.
  ///
  /// \param renderer the rendering context
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_CreateRenderer
  void SDL_DestroyRenderer(
    ffi.Pointer<SDL_Renderer> renderer,
  ) {
    return _SDL_DestroyRenderer(
      renderer,
    );
  }

  late final _SDL_DestroyRendererPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<SDL_Renderer>)>>(
          'SDL_DestroyRenderer');
  late final _SDL_DestroyRenderer = _SDL_DestroyRendererPtr.asFunction<
      void Function(ffi.Pointer<SDL_Renderer>)>();

  /// Force the rendering context to flush any pending commands to the underlying
  /// rendering API.
  ///
  /// You do not need to (and in fact, shouldn't) call this function unless you
  /// are planning to call into OpenGL/Direct3D/Metal/whatever directly in
  /// addition to using an SDL_Renderer.
  ///
  /// This is for a very-specific case: if you are using SDL's render API, you
  /// asked for a specific renderer backend (OpenGL, Direct3D, etc), you set
  /// SDL_HINT_RENDER_BATCHING to "1", and you plan to make OpenGL/D3D/whatever
  /// calls in addition to SDL render API calls. If all of this applies, you
  /// should call SDL_RenderFlush() between calls to SDL's render API and the
  /// low-level API you're using in cooperation.
  ///
  /// In all other cases, you can ignore this function. This is only here to get
  /// maximum performance out of a specific situation. In all other cases, SDL
  /// will do the right thing, perhaps at a performance loss.
  ///
  /// This function is first available in SDL 2.0.10, and is not needed in 2.0.9
  /// and earlier, as earlier versions did not queue rendering commands at all,
  /// instead flushing them to the OS immediately.
  ///
  /// \param renderer the rendering context
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.10.
  int SDL_RenderFlush(
    ffi.Pointer<SDL_Renderer> renderer,
  ) {
    return _SDL_RenderFlush(
      renderer,
    );
  }

  late final _SDL_RenderFlushPtr = _lookup<
          ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<SDL_Renderer>)>>(
      'SDL_RenderFlush');
  late final _SDL_RenderFlush =
      _SDL_RenderFlushPtr.asFunction<int Function(ffi.Pointer<SDL_Renderer>)>();

  /// Bind an OpenGL/ES/ES2 texture to the current context.
  ///
  /// This is for use with OpenGL instructions when rendering OpenGL primitives
  /// directly.
  ///
  /// If not NULL, `texw` and `texh` will be filled with the width and height
  /// values suitable for the provided texture. In most cases, both will be 1.0,
  /// however, on systems that support the GL_ARB_texture_rectangle extension,
  /// these values will actually be the pixel width and height used to create the
  /// texture, so this factor needs to be taken into account when providing
  /// texture coordinates to OpenGL.
  ///
  /// You need a renderer to create an SDL_Texture, therefore you can only use
  /// this function with an implicit OpenGL context from SDL_CreateRenderer(),
  /// not with your own OpenGL context. If you need control over your OpenGL
  /// context, you need to write your own texture-loading methods.
  ///
  /// Also note that SDL may upload RGB textures as BGR (or vice-versa), and
  /// re-order the color channels in the shaders phase, so the uploaded texture
  /// may have swapped color channels.
  ///
  /// \param texture the texture to bind to the current OpenGL/ES/ES2 context
  /// \param texw a pointer to a float value which will be filled with the
  /// texture width or NULL if you don't need that value
  /// \param texh a pointer to a float value which will be filled with the
  /// texture height or NULL if you don't need that value
  /// \returns 0 on success, or -1 if the operation is not supported; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GL_MakeCurrent
  /// \sa SDL_GL_UnbindTexture
  int SDL_GL_BindTexture(
    ffi.Pointer<SDL_Texture> texture,
    ffi.Pointer<ffi.Float> texw,
    ffi.Pointer<ffi.Float> texh,
  ) {
    return _SDL_GL_BindTexture(
      texture,
      texw,
      texh,
    );
  }

  late final _SDL_GL_BindTexturePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_Texture>, ffi.Pointer<ffi.Float>,
              ffi.Pointer<ffi.Float>)>>('SDL_GL_BindTexture');
  late final _SDL_GL_BindTexture = _SDL_GL_BindTexturePtr.asFunction<
      int Function(ffi.Pointer<SDL_Texture>, ffi.Pointer<ffi.Float>,
          ffi.Pointer<ffi.Float>)>();

  /// Unbind an OpenGL/ES/ES2 texture from the current context.
  ///
  /// See SDL_GL_BindTexture() for examples on how to use these functions
  ///
  /// \param texture the texture to unbind from the current OpenGL/ES/ES2 context
  /// \returns 0 on success, or -1 if the operation is not supported
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GL_BindTexture
  /// \sa SDL_GL_MakeCurrent
  int SDL_GL_UnbindTexture(
    ffi.Pointer<SDL_Texture> texture,
  ) {
    return _SDL_GL_UnbindTexture(
      texture,
    );
  }

  late final _SDL_GL_UnbindTexturePtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<SDL_Texture>)>>(
          'SDL_GL_UnbindTexture');
  late final _SDL_GL_UnbindTexture = _SDL_GL_UnbindTexturePtr.asFunction<
      int Function(ffi.Pointer<SDL_Texture>)>();

  /// Get the CAMetalLayer associated with the given Metal renderer.
  ///
  /// This function returns `void *`, so SDL doesn't have to include Metal's
  /// headers, but it can be safely cast to a `CAMetalLayer *`.
  ///
  /// \param renderer The renderer to query
  /// \returns a `CAMetalLayer *` on success, or NULL if the renderer isn't a
  /// Metal renderer
  ///
  /// \since This function is available since SDL 2.0.8.
  ///
  /// \sa SDL_RenderGetMetalCommandEncoder
  ffi.Pointer<ffi.Void> SDL_RenderGetMetalLayer(
    ffi.Pointer<SDL_Renderer> renderer,
  ) {
    return _SDL_RenderGetMetalLayer(
      renderer,
    );
  }

  late final _SDL_RenderGetMetalLayerPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Void> Function(
              ffi.Pointer<SDL_Renderer>)>>('SDL_RenderGetMetalLayer');
  late final _SDL_RenderGetMetalLayer = _SDL_RenderGetMetalLayerPtr.asFunction<
      ffi.Pointer<ffi.Void> Function(ffi.Pointer<SDL_Renderer>)>();

  /// Get the Metal command encoder for the current frame
  ///
  /// This function returns `void *`, so SDL doesn't have to include Metal's
  /// headers, but it can be safely cast to an `id<MTLRenderCommandEncoder>`.
  ///
  /// Note that as of SDL 2.0.18, this will return NULL if Metal refuses to give
  /// SDL a drawable to render to, which might happen if the window is
  /// hidden/minimized/offscreen. This doesn't apply to command encoders for
  /// render targets, just the window's backbacker. Check your return values!
  ///
  /// \param renderer The renderer to query
  /// \returns an `id<MTLRenderCommandEncoder>` on success, or NULL if the
  /// renderer isn't a Metal renderer or there was an error.
  ///
  /// \since This function is available since SDL 2.0.8.
  ///
  /// \sa SDL_RenderGetMetalLayer
  ffi.Pointer<ffi.Void> SDL_RenderGetMetalCommandEncoder(
    ffi.Pointer<SDL_Renderer> renderer,
  ) {
    return _SDL_RenderGetMetalCommandEncoder(
      renderer,
    );
  }

  late final _SDL_RenderGetMetalCommandEncoderPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Void> Function(
              ffi.Pointer<SDL_Renderer>)>>('SDL_RenderGetMetalCommandEncoder');
  late final _SDL_RenderGetMetalCommandEncoder =
      _SDL_RenderGetMetalCommandEncoderPtr.asFunction<
          ffi.Pointer<ffi.Void> Function(ffi.Pointer<SDL_Renderer>)>();

  /// Toggle VSync of the given renderer.
  ///
  /// \param renderer The renderer to toggle
  /// \param vsync 1 for on, 0 for off. All other values are reserved
  /// \returns a 0 int on success, or non-zero on failure
  ///
  /// \since This function is available since SDL 2.0.18.
  int SDL_RenderSetVSync(
    ffi.Pointer<SDL_Renderer> renderer,
    int vsync,
  ) {
    return _SDL_RenderSetVSync(
      renderer,
      vsync,
    );
  }

  late final _SDL_RenderSetVSyncPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(
              ffi.Pointer<SDL_Renderer>, ffi.Int32)>>('SDL_RenderSetVSync');
  late final _SDL_RenderSetVSync = _SDL_RenderSetVSyncPtr.asFunction<
      int Function(ffi.Pointer<SDL_Renderer>, int)>();

  /// Create a window that can be shaped with the specified position, dimensions,
  /// and flags.
  ///
  /// \param title The title of the window, in UTF-8 encoding.
  /// \param x The x position of the window, ::SDL_WINDOWPOS_CENTERED, or
  /// ::SDL_WINDOWPOS_UNDEFINED.
  /// \param y The y position of the window, ::SDL_WINDOWPOS_CENTERED, or
  /// ::SDL_WINDOWPOS_UNDEFINED.
  /// \param w The width of the window.
  /// \param h The height of the window.
  /// \param flags The flags for the window, a mask of SDL_WINDOW_BORDERLESS with
  /// any of the following: ::SDL_WINDOW_OPENGL,
  /// ::SDL_WINDOW_INPUT_GRABBED, ::SDL_WINDOW_HIDDEN,
  /// ::SDL_WINDOW_RESIZABLE, ::SDL_WINDOW_MAXIMIZED,
  /// ::SDL_WINDOW_MINIMIZED, ::SDL_WINDOW_BORDERLESS is always set,
  /// and ::SDL_WINDOW_FULLSCREEN is always unset.
  /// \return the window created, or NULL if window creation failed.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_DestroyWindow
  ffi.Pointer<SDL_Window> SDL_CreateShapedWindow(
    ffi.Pointer<ffi.Int8> title,
    int x,
    int y,
    int w,
    int h,
    int flags,
  ) {
    return _SDL_CreateShapedWindow(
      title,
      x,
      y,
      w,
      h,
      flags,
    );
  }

  late final _SDL_CreateShapedWindowPtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<SDL_Window> Function(
              ffi.Pointer<ffi.Int8>,
              ffi.Uint32,
              ffi.Uint32,
              ffi.Uint32,
              ffi.Uint32,
              Uint32)>>('SDL_CreateShapedWindow');
  late final _SDL_CreateShapedWindow = _SDL_CreateShapedWindowPtr.asFunction<
      ffi.Pointer<SDL_Window> Function(
          ffi.Pointer<ffi.Int8>, int, int, int, int, int)>();

  /// Return whether the given window is a shaped window.
  ///
  /// \param window The window to query for being shaped.
  /// \return SDL_TRUE if the window is a window that can be shaped, SDL_FALSE if
  /// the window is unshaped or NULL.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_CreateShapedWindow
  int SDL_IsShapedWindow(
    ffi.Pointer<SDL_Window> window,
  ) {
    return _SDL_IsShapedWindow(
      window,
    );
  }

  late final _SDL_IsShapedWindowPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<SDL_Window>)>>(
          'SDL_IsShapedWindow');
  late final _SDL_IsShapedWindow = _SDL_IsShapedWindowPtr.asFunction<
      int Function(ffi.Pointer<SDL_Window>)>();

  /// Set the shape and parameters of a shaped window.
  ///
  /// \param window The shaped window whose parameters should be set.
  /// \param shape A surface encoding the desired shape for the window.
  /// \param shape_mode The parameters to set for the shaped window.
  /// \return 0 on success, SDL_INVALID_SHAPE_ARGUMENT on an invalid shape
  /// argument, or SDL_NONSHAPEABLE_WINDOW if the SDL_Window given does
  /// not reference a valid shaped window.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_WindowShapeMode
  /// \sa SDL_GetShapedWindowMode
  int SDL_SetWindowShape(
    ffi.Pointer<SDL_Window> window,
    ffi.Pointer<SDL_Surface> shape,
    ffi.Pointer<SDL_WindowShapeMode> shape_mode,
  ) {
    return _SDL_SetWindowShape(
      window,
      shape,
      shape_mode,
    );
  }

  late final _SDL_SetWindowShapePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_Window>, ffi.Pointer<SDL_Surface>,
              ffi.Pointer<SDL_WindowShapeMode>)>>('SDL_SetWindowShape');
  late final _SDL_SetWindowShape = _SDL_SetWindowShapePtr.asFunction<
      int Function(ffi.Pointer<SDL_Window>, ffi.Pointer<SDL_Surface>,
          ffi.Pointer<SDL_WindowShapeMode>)>();

  /// Get the shape parameters of a shaped window.
  ///
  /// \param window The shaped window whose parameters should be retrieved.
  /// \param shape_mode An empty shape-mode structure to fill, or NULL to check
  /// whether the window has a shape.
  /// \return 0 if the window has a shape and, provided shape_mode was not NULL,
  /// shape_mode has been filled with the mode data,
  /// SDL_NONSHAPEABLE_WINDOW if the SDL_Window given is not a shaped
  /// window, or SDL_WINDOW_LACKS_SHAPE if the SDL_Window given is a
  /// shapeable window currently lacking a shape.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_WindowShapeMode
  /// \sa SDL_SetWindowShape
  int SDL_GetShapedWindowMode(
    ffi.Pointer<SDL_Window> window,
    ffi.Pointer<SDL_WindowShapeMode> shape_mode,
  ) {
    return _SDL_GetShapedWindowMode(
      window,
      shape_mode,
    );
  }

  late final _SDL_GetShapedWindowModePtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Pointer<SDL_Window>,
              ffi.Pointer<SDL_WindowShapeMode>)>>('SDL_GetShapedWindowMode');
  late final _SDL_GetShapedWindowMode = _SDL_GetShapedWindowModePtr.asFunction<
      int Function(
          ffi.Pointer<SDL_Window>, ffi.Pointer<SDL_WindowShapeMode>)>();

  /// Set a callback for every Windows message, run before TranslateMessage().
  ///
  /// \param callback The SDL_WindowsMessageHook function to call.
  /// \param userdata a pointer to pass to every iteration of `callback`
  ///
  /// \since This function is available since SDL 2.0.4.
  void SDL_SetWindowsMessageHook(
    SDL_WindowsMessageHook callback,
    ffi.Pointer<ffi.Void> userdata,
  ) {
    return _SDL_SetWindowsMessageHook(
      callback,
      userdata,
    );
  }

  late final _SDL_SetWindowsMessageHookPtr = _lookup<
      ffi.NativeFunction<
          ffi.Void Function(SDL_WindowsMessageHook,
              ffi.Pointer<ffi.Void>)>>('SDL_SetWindowsMessageHook');
  late final _SDL_SetWindowsMessageHook =
      _SDL_SetWindowsMessageHookPtr.asFunction<
          void Function(SDL_WindowsMessageHook, ffi.Pointer<ffi.Void>)>();

  /// Get the D3D9 adapter index that matches the specified display index.
  ///
  /// The returned adapter index can be passed to `IDirect3D9::CreateDevice` and
  /// controls on which monitor a full screen application will appear.
  ///
  /// \param displayIndex the display index for which to get the D3D9 adapter
  /// index
  /// \returns the D3D9 adapter index on success or a negative error code on
  /// failure; call SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.1.
  int SDL_Direct3D9GetAdapterIndex(
    int displayIndex,
  ) {
    return _SDL_Direct3D9GetAdapterIndex(
      displayIndex,
    );
  }

  late final _SDL_Direct3D9GetAdapterIndexPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Int32)>>(
          'SDL_Direct3D9GetAdapterIndex');
  late final _SDL_Direct3D9GetAdapterIndex =
      _SDL_Direct3D9GetAdapterIndexPtr.asFunction<int Function(int)>();

  /// Get the D3D9 device associated with a renderer.
  ///
  /// Once you are done using the device, you should release it to avoid a
  /// resource leak.
  ///
  /// \param renderer the renderer from which to get the associated D3D device
  /// \returns the D3D9 device associated with given renderer or NULL if it is
  /// not a D3D9 renderer; call SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.1.
  ffi.Pointer<IDirect3DDevice9> SDL_RenderGetD3D9Device(
    ffi.Pointer<SDL_Renderer> renderer,
  ) {
    return _SDL_RenderGetD3D9Device(
      renderer,
    );
  }

  late final _SDL_RenderGetD3D9DevicePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<IDirect3DDevice9> Function(
              ffi.Pointer<SDL_Renderer>)>>('SDL_RenderGetD3D9Device');
  late final _SDL_RenderGetD3D9Device = _SDL_RenderGetD3D9DevicePtr.asFunction<
      ffi.Pointer<IDirect3DDevice9> Function(ffi.Pointer<SDL_Renderer>)>();

  /// Get the D3D11 device associated with a renderer.
  ///
  /// Once you are done using the device, you should release it to avoid a
  /// resource leak.
  ///
  /// \param renderer the renderer from which to get the associated D3D11 device
  /// \returns the D3D11 device associated with given renderer or NULL if it is
  /// not a D3D11 renderer; call SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.16.
  ffi.Pointer<ID3D11Device> SDL_RenderGetD3D11Device(
    ffi.Pointer<SDL_Renderer> renderer,
  ) {
    return _SDL_RenderGetD3D11Device(
      renderer,
    );
  }

  late final _SDL_RenderGetD3D11DevicePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ID3D11Device> Function(
              ffi.Pointer<SDL_Renderer>)>>('SDL_RenderGetD3D11Device');
  late final _SDL_RenderGetD3D11Device =
      _SDL_RenderGetD3D11DevicePtr.asFunction<
          ffi.Pointer<ID3D11Device> Function(ffi.Pointer<SDL_Renderer>)>();

  /// Get the DXGI Adapter and Output indices for the specified display index.
  ///
  /// The DXGI Adapter and Output indices can be passed to `EnumAdapters` and
  /// `EnumOutputs` respectively to get the objects required to create a DX10 or
  /// DX11 device and swap chain.
  ///
  /// Before SDL 2.0.4 this function did not return a value. Since SDL 2.0.4 it
  /// returns an SDL_bool.
  ///
  /// \param displayIndex the display index for which to get both indices
  /// \param adapterIndex a pointer to be filled in with the adapter index
  /// \param outputIndex a pointer to be filled in with the output index
  /// \returns SDL_TRUE on success or SDL_FALSE on failure; call SDL_GetError()
  /// for more information.
  ///
  /// \since This function is available since SDL 2.0.2.
  int SDL_DXGIGetOutputInfo(
    int displayIndex,
    ffi.Pointer<ffi.Int32> adapterIndex,
    ffi.Pointer<ffi.Int32> outputIndex,
  ) {
    return _SDL_DXGIGetOutputInfo(
      displayIndex,
      adapterIndex,
      outputIndex,
    );
  }

  late final _SDL_DXGIGetOutputInfoPtr = _lookup<
      ffi.NativeFunction<
          ffi.Int32 Function(ffi.Int32, ffi.Pointer<ffi.Int32>,
              ffi.Pointer<ffi.Int32>)>>('SDL_DXGIGetOutputInfo');
  late final _SDL_DXGIGetOutputInfo = _SDL_DXGIGetOutputInfoPtr.asFunction<
      int Function(int, ffi.Pointer<ffi.Int32>, ffi.Pointer<ffi.Int32>)>();

  /// Query if the current device is a tablet.
  ///
  /// If SDL can't determine this, it will return SDL_FALSE.
  ///
  /// \returns SDL_TRUE if the device is a tablet, SDL_FALSE otherwise.
  ///
  /// \since This function is available since SDL 2.0.9.
  int SDL_IsTablet() {
    return _SDL_IsTablet();
  }

  late final _SDL_IsTabletPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function()>>('SDL_IsTablet');
  late final _SDL_IsTablet = _SDL_IsTabletPtr.asFunction<int Function()>();

  void SDL_OnApplicationWillTerminate() {
    return _SDL_OnApplicationWillTerminate();
  }

  late final _SDL_OnApplicationWillTerminatePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>(
          'SDL_OnApplicationWillTerminate');
  late final _SDL_OnApplicationWillTerminate =
      _SDL_OnApplicationWillTerminatePtr.asFunction<void Function()>();

  void SDL_OnApplicationDidReceiveMemoryWarning() {
    return _SDL_OnApplicationDidReceiveMemoryWarning();
  }

  late final _SDL_OnApplicationDidReceiveMemoryWarningPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>(
          'SDL_OnApplicationDidReceiveMemoryWarning');
  late final _SDL_OnApplicationDidReceiveMemoryWarning =
      _SDL_OnApplicationDidReceiveMemoryWarningPtr.asFunction<
          void Function()>();

  void SDL_OnApplicationWillResignActive() {
    return _SDL_OnApplicationWillResignActive();
  }

  late final _SDL_OnApplicationWillResignActivePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>(
          'SDL_OnApplicationWillResignActive');
  late final _SDL_OnApplicationWillResignActive =
      _SDL_OnApplicationWillResignActivePtr.asFunction<void Function()>();

  void SDL_OnApplicationDidEnterBackground() {
    return _SDL_OnApplicationDidEnterBackground();
  }

  late final _SDL_OnApplicationDidEnterBackgroundPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>(
          'SDL_OnApplicationDidEnterBackground');
  late final _SDL_OnApplicationDidEnterBackground =
      _SDL_OnApplicationDidEnterBackgroundPtr.asFunction<void Function()>();

  void SDL_OnApplicationWillEnterForeground() {
    return _SDL_OnApplicationWillEnterForeground();
  }

  late final _SDL_OnApplicationWillEnterForegroundPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>(
          'SDL_OnApplicationWillEnterForeground');
  late final _SDL_OnApplicationWillEnterForeground =
      _SDL_OnApplicationWillEnterForegroundPtr.asFunction<void Function()>();

  void SDL_OnApplicationDidBecomeActive() {
    return _SDL_OnApplicationDidBecomeActive();
  }

  late final _SDL_OnApplicationDidBecomeActivePtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>(
          'SDL_OnApplicationDidBecomeActive');
  late final _SDL_OnApplicationDidBecomeActive =
      _SDL_OnApplicationDidBecomeActivePtr.asFunction<void Function()>();

  /// Get the number of milliseconds since SDL library initialization.
  ///
  /// This value wraps if the program runs for more than ~49 days.
  ///
  /// This function is not recommended as of SDL 2.0.18; use SDL_GetTicks64()
  /// instead, where the value doesn't wrap every ~49 days. There are places in
  /// SDL where we provide a 32-bit timestamp that can not change without
  /// breaking binary compatibility, though, so this function isn't officially
  /// deprecated.
  ///
  /// \returns an unsigned 32-bit value representing the number of milliseconds
  /// since the SDL library initialized.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_TICKS_PASSED
  int SDL_GetTicks() {
    return _SDL_GetTicks();
  }

  late final _SDL_GetTicksPtr =
      _lookup<ffi.NativeFunction<Uint32 Function()>>('SDL_GetTicks');
  late final _SDL_GetTicks = _SDL_GetTicksPtr.asFunction<int Function()>();

  /// Get the number of milliseconds since SDL library initialization.
  ///
  /// Note that you should not use the SDL_TICKS_PASSED macro with values
  /// returned by this function, as that macro does clever math to compensate for
  /// the 32-bit overflow every ~49 days that SDL_GetTicks() suffers from. 64-bit
  /// values from this function can be safely compared directly.
  ///
  /// For example, if you want to wait 100 ms, you could do this:
  ///
  /// ```c
  /// const Uint64 timeout = SDL_GetTicks64() + 100;
  /// while (SDL_GetTicks64() < timeout) {
  /// // ... do work until timeout has elapsed
  /// }
  /// ```
  ///
  /// \returns an unsigned 64-bit value representing the number of milliseconds
  /// since the SDL library initialized.
  ///
  /// \since This function is available since SDL 2.0.18.
  int SDL_GetTicks64() {
    return _SDL_GetTicks64();
  }

  late final _SDL_GetTicks64Ptr =
      _lookup<ffi.NativeFunction<Uint64 Function()>>('SDL_GetTicks64');
  late final _SDL_GetTicks64 = _SDL_GetTicks64Ptr.asFunction<int Function()>();

  /// Get the current value of the high resolution counter.
  ///
  /// This function is typically used for profiling.
  ///
  /// The counter values are only meaningful relative to each other. Differences
  /// between values can be converted to times by using
  /// SDL_GetPerformanceFrequency().
  ///
  /// \returns the current counter value.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetPerformanceFrequency
  int SDL_GetPerformanceCounter() {
    return _SDL_GetPerformanceCounter();
  }

  late final _SDL_GetPerformanceCounterPtr =
      _lookup<ffi.NativeFunction<Uint64 Function()>>(
          'SDL_GetPerformanceCounter');
  late final _SDL_GetPerformanceCounter =
      _SDL_GetPerformanceCounterPtr.asFunction<int Function()>();

  /// Get the count per second of the high resolution counter.
  ///
  /// \returns a platform-specific count per second.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetPerformanceCounter
  int SDL_GetPerformanceFrequency() {
    return _SDL_GetPerformanceFrequency();
  }

  late final _SDL_GetPerformanceFrequencyPtr =
      _lookup<ffi.NativeFunction<Uint64 Function()>>(
          'SDL_GetPerformanceFrequency');
  late final _SDL_GetPerformanceFrequency =
      _SDL_GetPerformanceFrequencyPtr.asFunction<int Function()>();

  /// Wait a specified number of milliseconds before returning.
  ///
  /// This function waits a specified number of milliseconds before returning. It
  /// waits at least the specified time, but possibly longer due to OS
  /// scheduling.
  ///
  /// \param ms the number of milliseconds to delay
  ///
  /// \since This function is available since SDL 2.0.0.
  void SDL_Delay(
    int ms,
  ) {
    return _SDL_Delay(
      ms,
    );
  }

  late final _SDL_DelayPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(Uint32)>>('SDL_Delay');
  late final _SDL_Delay = _SDL_DelayPtr.asFunction<void Function(int)>();

  /// Call a callback function at a future time.
  ///
  /// If you use this function, you must pass `SDL_INIT_TIMER` to SDL_Init().
  ///
  /// The callback function is passed the current timer interval and the user
  /// supplied parameter from the SDL_AddTimer() call and should return the next
  /// timer interval. If the value returned from the callback is 0, the timer is
  /// canceled.
  ///
  /// The callback is run on a separate thread.
  ///
  /// Timers take into account the amount of time it took to execute the
  /// callback. For example, if the callback took 250 ms to execute and returned
  /// 1000 (ms), the timer would only wait another 750 ms before its next
  /// iteration.
  ///
  /// Timing may be inexact due to OS scheduling. Be sure to note the current
  /// time with SDL_GetTicks() or SDL_GetPerformanceCounter() in case your
  /// callback needs to adjust for variances.
  ///
  /// \param interval the timer delay, in milliseconds, passed to `callback`
  /// \param callback the SDL_TimerCallback function to call when the specified
  /// `interval` elapses
  /// \param param a pointer that is passed to `callback`
  /// \returns a timer ID or 0 if an error occurs; call SDL_GetError() for more
  /// information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_RemoveTimer
  int SDL_AddTimer(
    int interval,
    SDL_TimerCallback callback,
    ffi.Pointer<ffi.Void> param,
  ) {
    return _SDL_AddTimer(
      interval,
      callback,
      param,
    );
  }

  late final _SDL_AddTimerPtr = _lookup<
      ffi.NativeFunction<
          SDL_TimerID Function(Uint32, SDL_TimerCallback,
              ffi.Pointer<ffi.Void>)>>('SDL_AddTimer');
  late final _SDL_AddTimer = _SDL_AddTimerPtr.asFunction<
      int Function(int, SDL_TimerCallback, ffi.Pointer<ffi.Void>)>();

  /// Remove a timer created with SDL_AddTimer().
  ///
  /// \param id the ID of the timer to remove
  /// \returns SDL_TRUE if the timer is removed or SDL_FALSE if the timer wasn't
  /// found.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_AddTimer
  int SDL_RemoveTimer(
    int id,
  ) {
    return _SDL_RemoveTimer(
      id,
    );
  }

  late final _SDL_RemoveTimerPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(SDL_TimerID)>>(
          'SDL_RemoveTimer');
  late final _SDL_RemoveTimer =
      _SDL_RemoveTimerPtr.asFunction<int Function(int)>();

  /// Get the version of SDL that is linked against your program.
  ///
  /// If you are linking to SDL dynamically, then it is possible that the current
  /// version will be different than the version you compiled against. This
  /// function returns the current version, while SDL_VERSION() is a macro that
  /// tells you what version you compiled with.
  ///
  /// This function may be called safely at any time, even before SDL_Init().
  ///
  /// \param ver the SDL_version structure that contains the version information
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetRevision
  void SDL_GetVersion(
    ffi.Pointer<SDL_version> ver,
  ) {
    return _SDL_GetVersion(
      ver,
    );
  }

  late final _SDL_GetVersionPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<SDL_version>)>>(
          'SDL_GetVersion');
  late final _SDL_GetVersion =
      _SDL_GetVersionPtr.asFunction<void Function(ffi.Pointer<SDL_version>)>();

  /// Get the code revision of SDL that is linked against your program.
  ///
  /// This value is the revision of the code you are linked with and may be
  /// different from the code you are compiling with, which is found in the
  /// constant SDL_REVISION.
  ///
  /// The revision is arbitrary string (a hash value) uniquely identifying the
  /// exact revision of the SDL library in use, and is only useful in comparing
  /// against other revisions. It is NOT an incrementing number.
  ///
  /// If SDL wasn't built from a git repository with the appropriate tools, this
  /// will return an empty string.
  ///
  /// Prior to SDL 2.0.16, before development moved to GitHub, this returned a
  /// hash for a Mercurial repository.
  ///
  /// You shouldn't use this function for anything but logging it for debugging
  /// purposes. The string is not intended to be reliable in any way.
  ///
  /// \returns an arbitrary string, uniquely identifying the exact revision of
  /// the SDL library in use.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetVersion
  ffi.Pointer<ffi.Int8> SDL_GetRevision() {
    return _SDL_GetRevision();
  }

  late final _SDL_GetRevisionPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<ffi.Int8> Function()>>(
          'SDL_GetRevision');
  late final _SDL_GetRevision =
      _SDL_GetRevisionPtr.asFunction<ffi.Pointer<ffi.Int8> Function()>();

  /// Obsolete function, do not use.
  ///
  /// When SDL was hosted in a Mercurial repository, and was built carefully,
  /// this would return the revision number that the build was created from. This
  /// number was not reliable for several reasons, but more importantly, SDL is
  /// now hosted in a git repository, which does not offer numbers at all, only
  /// hashes. This function only ever returns zero now. Don't use it.
  ///
  /// Before SDL 2.0.16, this might have returned an unreliable, but non-zero
  /// number.
  ///
  /// \deprecated Use SDL_GetRevision() instead; if SDL was carefully built, it
  /// will return a git hash.
  ///
  /// \returns zero, always, in modern SDL releases.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_GetRevision
  int SDL_GetRevisionNumber() {
    return _SDL_GetRevisionNumber();
  }

  late final _SDL_GetRevisionNumberPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function()>>(
          'SDL_GetRevisionNumber');
  late final _SDL_GetRevisionNumber =
      _SDL_GetRevisionNumberPtr.asFunction<int Function()>();

  /// Report the user's preferred locale.
  ///
  /// This returns an array of SDL_Locale structs, the final item zeroed out.
  /// When the caller is done with this array, it should call SDL_free() on the
  /// returned value; all the memory involved is allocated in a single block, so
  /// a single SDL_free() will suffice.
  ///
  /// Returned language strings are in the format xx, where 'xx' is an ISO-639
  /// language specifier (such as "en" for English, "de" for German, etc).
  /// Country strings are in the format YY, where "YY" is an ISO-3166 country
  /// code (such as "US" for the United States, "CA" for Canada, etc). Country
  /// might be NULL if there's no specific guidance on them (so you might get {
  /// "en", "US" } for American English, but { "en", NULL } means "English
  /// language, generically"). Language strings are never NULL, except to
  /// terminate the array.
  ///
  /// Please note that not all of these strings are 2 characters; some are three
  /// or more.
  ///
  /// The returned list of locales are in the order of the user's preference. For
  /// example, a German citizen that is fluent in US English and knows enough
  /// Japanese to navigate around Tokyo might have a list like: { "de", "en_US",
  /// "jp", NULL }. Someone from England might prefer British English (where
  /// "color" is spelled "colour", etc), but will settle for anything like it: {
  /// "en_GB", "en", NULL }.
  ///
  /// This function returns NULL on error, including when the platform does not
  /// supply this information at all.
  ///
  /// This might be a "slow" call that has to query the operating system. It's
  /// best to ask for this once and save the results. However, this list can
  /// change, usually because the user has changed a system preference outside of
  /// your program; SDL will send an SDL_LOCALECHANGED event in this case, if
  /// possible, and you can call this function again to get an updated copy of
  /// preferred locales.
  ///
  /// \return array of locales, terminated with a locale with a NULL language
  /// field. Will return NULL on error.
  ///
  /// \since This function is available since SDL 2.0.14.
  ffi.Pointer<SDL_Locale> SDL_GetPreferredLocales() {
    return _SDL_GetPreferredLocales();
  }

  late final _SDL_GetPreferredLocalesPtr =
      _lookup<ffi.NativeFunction<ffi.Pointer<SDL_Locale> Function()>>(
          'SDL_GetPreferredLocales');
  late final _SDL_GetPreferredLocales = _SDL_GetPreferredLocalesPtr.asFunction<
      ffi.Pointer<SDL_Locale> Function()>();

  /// Open a URL/URI in the browser or other appropriate external application.
  ///
  /// Open a URL in a separate, system-provided application. How this works will
  /// vary wildly depending on the platform. This will likely launch what makes
  /// sense to handle a specific URL's protocol (a web browser for `http://`,
  /// etc), but it might also be able to launch file managers for directories and
  /// other things.
  ///
  /// What happens when you open a URL varies wildly as well: your game window
  /// may lose focus (and may or may not lose focus if your game was fullscreen
  /// or grabbing input at the time). On mobile devices, your app will likely
  /// move to the background or your process might be paused. Any given platform
  /// may or may not handle a given URL.
  ///
  /// If this is unimplemented (or simply unavailable) for a platform, this will
  /// fail with an error. A successful result does not mean the URL loaded, just
  /// that we launched _something_ to handle it (or at least believe we did).
  ///
  /// All this to say: this function can be useful, but you should definitely
  /// test it on every platform you target.
  ///
  /// \param url A valid URL/URI to open. Use `file:///full/path/to/file` for
  /// local files, if supported.
  /// \returns 0 on success, or -1 on error; call SDL_GetError() for more
  /// information.
  ///
  /// \since This function is available since SDL 2.0.14.
  int SDL_OpenURL(
    ffi.Pointer<ffi.Int8> url,
  ) {
    return _SDL_OpenURL(
      url,
    );
  }

  late final _SDL_OpenURLPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<ffi.Int8>)>>(
          'SDL_OpenURL');
  late final _SDL_OpenURL =
      _SDL_OpenURLPtr.asFunction<int Function(ffi.Pointer<ffi.Int8>)>();

  /// Initialize the SDL library.
  ///
  /// SDL_Init() simply forwards to calling SDL_InitSubSystem(). Therefore, the
  /// two may be used interchangeably. Though for readability of your code
  /// SDL_InitSubSystem() might be preferred.
  ///
  /// The file I/O (for example: SDL_RWFromFile) and threading (SDL_CreateThread)
  /// subsystems are initialized by default. Message boxes
  /// (SDL_ShowSimpleMessageBox) also attempt to work without initializing the
  /// video subsystem, in hopes of being useful in showing an error dialog when
  /// SDL_Init fails. You must specifically initialize other subsystems if you
  /// use them in your application.
  ///
  /// Logging (such as SDL_Log) works without initialization, too.
  ///
  /// `flags` may be any of the following OR'd together:
  ///
  /// - `SDL_INIT_TIMER`: timer subsystem
  /// - `SDL_INIT_AUDIO`: audio subsystem
  /// - `SDL_INIT_VIDEO`: video subsystem; automatically initializes the events
  /// subsystem
  /// - `SDL_INIT_JOYSTICK`: joystick subsystem; automatically initializes the
  /// events subsystem
  /// - `SDL_INIT_HAPTIC`: haptic (force feedback) subsystem
  /// - `SDL_INIT_GAMECONTROLLER`: controller subsystem; automatically
  /// initializes the joystick subsystem
  /// - `SDL_INIT_EVENTS`: events subsystem
  /// - `SDL_INIT_EVERYTHING`: all of the above subsystems
  /// - `SDL_INIT_NOPARACHUTE`: compatibility; this flag is ignored
  ///
  /// Subsystem initialization is ref-counted, you must call SDL_QuitSubSystem()
  /// for each SDL_InitSubSystem() to correctly shutdown a subsystem manually (or
  /// call SDL_Quit() to force shutdown). If a subsystem is already loaded then
  /// this call will increase the ref-count and return.
  ///
  /// \param flags subsystem initialization flags
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_InitSubSystem
  /// \sa SDL_Quit
  /// \sa SDL_SetMainReady
  /// \sa SDL_WasInit
  int SDL_Init(
    int flags,
  ) {
    return _SDL_Init(
      flags,
    );
  }

  late final _SDL_InitPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(Uint32)>>('SDL_Init');
  late final _SDL_Init = _SDL_InitPtr.asFunction<int Function(int)>();

  /// Compatibility function to initialize the SDL library.
  ///
  /// In SDL2, this function and SDL_Init() are interchangeable.
  ///
  /// \param flags any of the flags used by SDL_Init(); see SDL_Init for details.
  /// \returns 0 on success or a negative error code on failure; call
  /// SDL_GetError() for more information.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_Init
  /// \sa SDL_Quit
  /// \sa SDL_QuitSubSystem
  int SDL_InitSubSystem(
    int flags,
  ) {
    return _SDL_InitSubSystem(
      flags,
    );
  }

  late final _SDL_InitSubSystemPtr =
      _lookup<ffi.NativeFunction<ffi.Int32 Function(Uint32)>>(
          'SDL_InitSubSystem');
  late final _SDL_InitSubSystem =
      _SDL_InitSubSystemPtr.asFunction<int Function(int)>();

  /// Shut down specific SDL subsystems.
  ///
  /// If you start a subsystem using a call to that subsystem's init function
  /// (for example SDL_VideoInit()) instead of SDL_Init() or SDL_InitSubSystem(),
  /// SDL_QuitSubSystem() and SDL_WasInit() will not work. You will need to use
  /// that subsystem's quit function (SDL_VideoQuit()) directly instead. But
  /// generally, you should not be using those functions directly anyhow; use
  /// SDL_Init() instead.
  ///
  /// You still need to call SDL_Quit() even if you close all open subsystems
  /// with SDL_QuitSubSystem().
  ///
  /// \param flags any of the flags used by SDL_Init(); see SDL_Init for details.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_InitSubSystem
  /// \sa SDL_Quit
  void SDL_QuitSubSystem(
    int flags,
  ) {
    return _SDL_QuitSubSystem(
      flags,
    );
  }

  late final _SDL_QuitSubSystemPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function(Uint32)>>(
          'SDL_QuitSubSystem');
  late final _SDL_QuitSubSystem =
      _SDL_QuitSubSystemPtr.asFunction<void Function(int)>();

  /// Get a mask of the specified subsystems which are currently initialized.
  ///
  /// \param flags any of the flags used by SDL_Init(); see SDL_Init for details.
  /// \returns a mask of all initialized subsystems if `flags` is 0, otherwise it
  /// returns the initialization status of the specified subsystems.
  ///
  /// The return value does not include SDL_INIT_NOPARACHUTE.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_Init
  /// \sa SDL_InitSubSystem
  int SDL_WasInit(
    int flags,
  ) {
    return _SDL_WasInit(
      flags,
    );
  }

  late final _SDL_WasInitPtr =
      _lookup<ffi.NativeFunction<Uint32 Function(Uint32)>>('SDL_WasInit');
  late final _SDL_WasInit = _SDL_WasInitPtr.asFunction<int Function(int)>();

  /// Clean up all initialized subsystems.
  ///
  /// You should call this function even if you have already shutdown each
  /// initialized subsystem with SDL_QuitSubSystem(). It is safe to call this
  /// function even in the case of errors in initialization.
  ///
  /// If you start a subsystem using a call to that subsystem's init function
  /// (for example SDL_VideoInit()) instead of SDL_Init() or SDL_InitSubSystem(),
  /// then you must use that subsystem's quit function (SDL_VideoQuit()) to shut
  /// it down before calling SDL_Quit(). But generally, you should not be using
  /// those functions directly anyhow; use SDL_Init() instead.
  ///
  /// You can use this function with atexit() to ensure that it is run when your
  /// application is shutdown, but it is not wise to do this from a library or
  /// other dynamically loaded code.
  ///
  /// \since This function is available since SDL 2.0.0.
  ///
  /// \sa SDL_Init
  /// \sa SDL_QuitSubSystem
  void SDL_Quit() {
    return _SDL_Quit();
  }

  late final _SDL_QuitPtr =
      _lookup<ffi.NativeFunction<ffi.Void Function()>>('SDL_Quit');
  late final _SDL_Quit = _SDL_QuitPtr.asFunction<void Function()>();
}

typedef va_list = ffi.Pointer<ffi.Int8>;
typedef uintptr_t = ffi.Uint64;
typedef wchar_t = ffi.Uint16;

class _crt_locale_data_public extends ffi.Struct {
  external ffi.Pointer<ffi.Uint16> locale_pctype;

  @ffi.Int32()
  external int locale_mb_cur_max;

  @ffi.Uint32()
  external int locale_lc_codepage;
}

class _crt_locale_pointers extends ffi.Struct {
  external ffi.Pointer<_crt_locale_data> locinfo;

  external ffi.Pointer<_crt_multibyte_data> mbcinfo;
}

class _crt_locale_data extends ffi.Opaque {}

class _crt_multibyte_data extends ffi.Opaque {}

class Mbstatet extends ffi.Struct {
  @ffi.Uint64()
  external int Wchar;

  @ffi.Uint16()
  external int Byte;

  @ffi.Uint16()
  external int State;
}

typedef errno_t = ffi.Int32;

abstract class SDL_bool {
  static const int SDL_FALSE = 0;
  static const int SDL_TRUE = 1;
}

abstract class SDL_DUMMY_ENUM {
  static const int DUMMY_ENUM_VALUE = 0;
}

typedef size_t = ffi.Uint64;
typedef SDL_malloc_func
    = ffi.Pointer<ffi.NativeFunction<ffi.Pointer<ffi.Void> Function(size_t)>>;
typedef SDL_calloc_func = ffi.Pointer<
    ffi.NativeFunction<ffi.Pointer<ffi.Void> Function(size_t, size_t)>>;
typedef SDL_realloc_func = ffi.Pointer<
    ffi.NativeFunction<
        ffi.Pointer<ffi.Void> Function(ffi.Pointer<ffi.Void>, size_t)>>;
typedef SDL_free_func
    = ffi.Pointer<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ffi.Void>)>>;
typedef Uint32 = ffi.Uint32;
typedef Sint64 = ffi.Int64;
typedef Uint64 = ffi.Uint64;

class SDL_iconv_t extends ffi.Opaque {}

typedef SDL_iconv_t1 = ffi.Pointer<SDL_iconv_t>;

abstract class SDL_AssertState {
  /// < Retry the assert immediately.
  static const int SDL_ASSERTION_RETRY = 0;

  /// < Make the debugger trigger a breakpoint.
  static const int SDL_ASSERTION_BREAK = 1;

  /// < Terminate the program.
  static const int SDL_ASSERTION_ABORT = 2;

  /// < Ignore the assert.
  static const int SDL_ASSERTION_IGNORE = 3;

  /// < Ignore the assert from now on.
  static const int SDL_ASSERTION_ALWAYS_IGNORE = 4;
}

class SDL_AssertData extends ffi.Struct {
  @ffi.Int32()
  external int always_ignore;

  @ffi.Uint32()
  external int trigger_count;

  external ffi.Pointer<ffi.Int8> condition;

  external ffi.Pointer<ffi.Int8> filename;

  @ffi.Int32()
  external int linenum;

  external ffi.Pointer<ffi.Int8> function;

  external ffi.Pointer<SDL_AssertData> next;
}

/// A callback that fires when an SDL assertion fails.
///
/// \param data a pointer to the SDL_AssertData structure corresponding to the
/// current assertion
/// \param userdata what was passed as `userdata` to SDL_SetAssertionHandler()
/// \returns an SDL_AssertState value indicating how to handle the failure.
typedef SDL_AssertionHandler = ffi.Pointer<
    ffi.NativeFunction<
        ffi.Int32 Function(
            ffi.Pointer<SDL_AssertData>, ffi.Pointer<ffi.Void>)>>;
typedef SDL_SpinLock = ffi.Int32;

/// \brief A type representing an atomic integer value.  It is a struct
/// so people don't accidentally use numeric operations on it.
class SDL_atomic_t extends ffi.Struct {
  @ffi.Int32()
  external int value;
}

abstract class SDL_errorcode {
  static const int SDL_ENOMEM = 0;
  static const int SDL_EFREAD = 1;
  static const int SDL_EFWRITE = 2;
  static const int SDL_EFSEEK = 3;
  static const int SDL_UNSUPPORTED = 4;
  static const int SDL_LASTERROR = 5;
}

class SETJMP_FLOAT128 extends ffi.Struct {
  @ffi.Array.multi([2])
  external ffi.Array<ffi.Uint64> Part;
}

class JUMP_BUFFER extends ffi.Struct {
  @ffi.Uint64()
  external int Frame;

  @ffi.Uint64()
  external int Rbx;

  @ffi.Uint64()
  external int Rsp;

  @ffi.Uint64()
  external int Rbp;

  @ffi.Uint64()
  external int Rsi;

  @ffi.Uint64()
  external int Rdi;

  @ffi.Uint64()
  external int R12;

  @ffi.Uint64()
  external int R13;

  @ffi.Uint64()
  external int R14;

  @ffi.Uint64()
  external int R15;

  @ffi.Uint64()
  external int Rip;

  @ffi.Uint64()
  external int MxCsr;

  @ffi.Uint16()
  external int FpCsr;

  @ffi.Uint16()
  external int Spare;

  external SETJMP_FLOAT1281 Xmm6;

  external SETJMP_FLOAT1281 Xmm7;

  external SETJMP_FLOAT1281 Xmm8;

  external SETJMP_FLOAT1281 Xmm9;

  external SETJMP_FLOAT1281 Xmm10;

  external SETJMP_FLOAT1281 Xmm11;

  external SETJMP_FLOAT1281 Xmm12;

  external SETJMP_FLOAT1281 Xmm13;

  external SETJMP_FLOAT1281 Xmm14;

  external SETJMP_FLOAT1281 Xmm15;
}

typedef SETJMP_FLOAT1281 = SETJMP_FLOAT128;
typedef _JBTYPE = SETJMP_FLOAT1281;

class __m64 extends ffi.Union {
  @ffi.Uint64()
  external int m64_u64;

  @ffi.Array.multi([2])
  external ffi.Array<ffi.Float> m64_f32;

  @ffi.Array.multi([8])
  external ffi.Array<ffi.Int8> m64_i8;

  @ffi.Array.multi([4])
  external ffi.Array<ffi.Int16> m64_i16;

  @ffi.Array.multi([2])
  external ffi.Array<ffi.Int32> m64_i32;

  @ffi.Int64()
  external int m64_i64;

  @ffi.Array.multi([8])
  external ffi.Array<ffi.Uint8> m64_u8;

  @ffi.Array.multi([4])
  external ffi.Array<ffi.Uint16> m64_u16;

  @ffi.Array.multi([2])
  external ffi.Array<ffi.Uint32> m64_u32;
}

class __m128 extends ffi.Union {
  @ffi.Array.multi([4])
  external ffi.Array<ffi.Float> m128_f32;

  @ffi.Array.multi([2])
  external ffi.Array<ffi.Uint64> m128_u64;

  @ffi.Array.multi([16])
  external ffi.Array<ffi.Int8> m128_i8;

  @ffi.Array.multi([8])
  external ffi.Array<ffi.Int16> m128_i16;

  @ffi.Array.multi([4])
  external ffi.Array<ffi.Int32> m128_i32;

  @ffi.Array.multi([2])
  external ffi.Array<ffi.Int64> m128_i64;

  @ffi.Array.multi([16])
  external ffi.Array<ffi.Uint8> m128_u8;

  @ffi.Array.multi([8])
  external ffi.Array<ffi.Uint16> m128_u16;

  @ffi.Array.multi([4])
  external ffi.Array<ffi.Uint32> m128_u32;
}

class heapinfo extends ffi.Struct {
  external ffi.Pointer<ffi.Int32> pentry;

  @size_t()
  external int size;

  @ffi.Int32()
  external int useflag;
}

typedef _HEAPINFO = heapinfo;

class __m128i extends ffi.Union {
  @ffi.Array.multi([16])
  external ffi.Array<ffi.Int8> m128i_i8;

  @ffi.Array.multi([8])
  external ffi.Array<ffi.Int16> m128i_i16;

  @ffi.Array.multi([4])
  external ffi.Array<ffi.Int32> m128i_i32;

  @ffi.Array.multi([2])
  external ffi.Array<ffi.Int64> m128i_i64;

  @ffi.Array.multi([16])
  external ffi.Array<ffi.Uint8> m128i_u8;

  @ffi.Array.multi([8])
  external ffi.Array<ffi.Uint16> m128i_u16;

  @ffi.Array.multi([4])
  external ffi.Array<ffi.Uint32> m128i_u32;

  @ffi.Array.multi([2])
  external ffi.Array<ffi.Uint64> m128i_u64;
}

class _m128d extends ffi.Struct {
  @ffi.Array.multi([2])
  external ffi.Array<ffi.Double> m128d_f64;
}

class __m256 extends ffi.Union {
  @ffi.Array.multi([8])
  external ffi.Array<ffi.Float> m256_f32;
}

class _m256d extends ffi.Struct {
  @ffi.Array.multi([4])
  external ffi.Array<ffi.Double> m256d_f64;
}

class __m256i extends ffi.Union {
  @ffi.Array.multi([32])
  external ffi.Array<ffi.Int8> m256i_i8;

  @ffi.Array.multi([16])
  external ffi.Array<ffi.Int16> m256i_i16;

  @ffi.Array.multi([8])
  external ffi.Array<ffi.Int32> m256i_i32;

  @ffi.Array.multi([4])
  external ffi.Array<ffi.Int64> m256i_i64;

  @ffi.Array.multi([32])
  external ffi.Array<ffi.Uint8> m256i_u8;

  @ffi.Array.multi([16])
  external ffi.Array<ffi.Uint16> m256i_u16;

  @ffi.Array.multi([8])
  external ffi.Array<ffi.Uint32> m256i_u32;

  @ffi.Array.multi([4])
  external ffi.Array<ffi.Uint64> m256i_u64;
}

class __m512 extends ffi.Union {
  @ffi.Array.multi([16])
  external ffi.Array<ffi.Float> m512_f32;
}

class _m512d extends ffi.Struct {
  @ffi.Array.multi([8])
  external ffi.Array<ffi.Double> m512d_f64;
}

class __m512i extends ffi.Union {
  @ffi.Array.multi([64])
  external ffi.Array<ffi.Int8> m512i_i8;

  @ffi.Array.multi([32])
  external ffi.Array<ffi.Int16> m512i_i16;

  @ffi.Array.multi([16])
  external ffi.Array<ffi.Int32> m512i_i32;

  @ffi.Array.multi([8])
  external ffi.Array<ffi.Int64> m512i_i64;

  @ffi.Array.multi([64])
  external ffi.Array<ffi.Uint8> m512i_u8;

  @ffi.Array.multi([32])
  external ffi.Array<ffi.Uint16> m512i_u16;

  @ffi.Array.multi([16])
  external ffi.Array<ffi.Uint32> m512i_u32;

  @ffi.Array.multi([8])
  external ffi.Array<ffi.Uint64> m512i_u64;
}

abstract class _MM_BROADCAST32_ENUM {
  static const int _MM_BROADCAST32_NONE = 0;
  static const int _MM_BROADCAST_1X16 = 1;
  static const int _MM_BROADCAST_4X16 = 2;
}

abstract class _MM_BROADCAST64_ENUM {
  static const int _MM_BROADCAST64_NONE = 0;
  static const int _MM_BROADCAST_1X8 = 1;
  static const int _MM_BROADCAST_4X8 = 2;
}

abstract class _MM_ROUND_MODE_ENUM {
  static const int _MM_ROUND_MODE_NEAREST = 0;
  static const int _MM_ROUND_MODE_DOWN = 1;
  static const int _MM_ROUND_MODE_UP = 2;
  static const int _MM_ROUND_MODE_TOWARD_ZERO = 3;
  static const int _MM_ROUND_MODE_DEFAULT = 4;
  static const int _MM_ROUND_MODE_NO_EXC = 8;
}

abstract class _MM_EXP_ADJ_ENUM {
  static const int _MM_EXPADJ_NONE = 0;
  static const int _MM_EXPADJ_4 = 1;
  static const int _MM_EXPADJ_5 = 2;
  static const int _MM_EXPADJ_8 = 3;
  static const int _MM_EXPADJ_16 = 4;
  static const int _MM_EXPADJ_24 = 5;
  static const int _MM_EXPADJ_31 = 6;
  static const int _MM_EXPADJ_32 = 7;
}

abstract class _MM_INDEX_SCALE_ENUM {
  static const int _MM_SCALE_1 = 1;
  static const int _MM_SCALE_2 = 2;
  static const int _MM_SCALE_4 = 4;
  static const int _MM_SCALE_8 = 8;
}

abstract class _MM_PERM_ENUM {
  static const int _MM_PERM_AAAA = 0;
  static const int _MM_PERM_AAAB = 1;
  static const int _MM_PERM_AAAC = 2;
  static const int _MM_PERM_AAAD = 3;
  static const int _MM_PERM_AABA = 4;
  static const int _MM_PERM_AABB = 5;
  static const int _MM_PERM_AABC = 6;
  static const int _MM_PERM_AABD = 7;
  static const int _MM_PERM_AACA = 8;
  static const int _MM_PERM_AACB = 9;
  static const int _MM_PERM_AACC = 10;
  static const int _MM_PERM_AACD = 11;
  static const int _MM_PERM_AADA = 12;
  static const int _MM_PERM_AADB = 13;
  static const int _MM_PERM_AADC = 14;
  static const int _MM_PERM_AADD = 15;
  static const int _MM_PERM_ABAA = 16;
  static const int _MM_PERM_ABAB = 17;
  static const int _MM_PERM_ABAC = 18;
  static const int _MM_PERM_ABAD = 19;
  static const int _MM_PERM_ABBA = 20;
  static const int _MM_PERM_ABBB = 21;
  static const int _MM_PERM_ABBC = 22;
  static const int _MM_PERM_ABBD = 23;
  static const int _MM_PERM_ABCA = 24;
  static const int _MM_PERM_ABCB = 25;
  static const int _MM_PERM_ABCC = 26;
  static const int _MM_PERM_ABCD = 27;
  static const int _MM_PERM_ABDA = 28;
  static const int _MM_PERM_ABDB = 29;
  static const int _MM_PERM_ABDC = 30;
  static const int _MM_PERM_ABDD = 31;
  static const int _MM_PERM_ACAA = 32;
  static const int _MM_PERM_ACAB = 33;
  static const int _MM_PERM_ACAC = 34;
  static const int _MM_PERM_ACAD = 35;
  static const int _MM_PERM_ACBA = 36;
  static const int _MM_PERM_ACBB = 37;
  static const int _MM_PERM_ACBC = 38;
  static const int _MM_PERM_ACBD = 39;
  static const int _MM_PERM_ACCA = 40;
  static const int _MM_PERM_ACCB = 41;
  static const int _MM_PERM_ACCC = 42;
  static const int _MM_PERM_ACCD = 43;
  static const int _MM_PERM_ACDA = 44;
  static const int _MM_PERM_ACDB = 45;
  static const int _MM_PERM_ACDC = 46;
  static const int _MM_PERM_ACDD = 47;
  static const int _MM_PERM_ADAA = 48;
  static const int _MM_PERM_ADAB = 49;
  static const int _MM_PERM_ADAC = 50;
  static const int _MM_PERM_ADAD = 51;
  static const int _MM_PERM_ADBA = 52;
  static const int _MM_PERM_ADBB = 53;
  static const int _MM_PERM_ADBC = 54;
  static const int _MM_PERM_ADBD = 55;
  static const int _MM_PERM_ADCA = 56;
  static const int _MM_PERM_ADCB = 57;
  static const int _MM_PERM_ADCC = 58;
  static const int _MM_PERM_ADCD = 59;
  static const int _MM_PERM_ADDA = 60;
  static const int _MM_PERM_ADDB = 61;
  static const int _MM_PERM_ADDC = 62;
  static const int _MM_PERM_ADDD = 63;
  static const int _MM_PERM_BAAA = 64;
  static const int _MM_PERM_BAAB = 65;
  static const int _MM_PERM_BAAC = 66;
  static const int _MM_PERM_BAAD = 67;
  static const int _MM_PERM_BABA = 68;
  static const int _MM_PERM_BABB = 69;
  static const int _MM_PERM_BABC = 70;
  static const int _MM_PERM_BABD = 71;
  static const int _MM_PERM_BACA = 72;
  static const int _MM_PERM_BACB = 73;
  static const int _MM_PERM_BACC = 74;
  static const int _MM_PERM_BACD = 75;
  static const int _MM_PERM_BADA = 76;
  static const int _MM_PERM_BADB = 77;
  static const int _MM_PERM_BADC = 78;
  static const int _MM_PERM_BADD = 79;
  static const int _MM_PERM_BBAA = 80;
  static const int _MM_PERM_BBAB = 81;
  static const int _MM_PERM_BBAC = 82;
  static const int _MM_PERM_BBAD = 83;
  static const int _MM_PERM_BBBA = 84;
  static const int _MM_PERM_BBBB = 85;
  static const int _MM_PERM_BBBC = 86;
  static const int _MM_PERM_BBBD = 87;
  static const int _MM_PERM_BBCA = 88;
  static const int _MM_PERM_BBCB = 89;
  static const int _MM_PERM_BBCC = 90;
  static const int _MM_PERM_BBCD = 91;
  static const int _MM_PERM_BBDA = 92;
  static const int _MM_PERM_BBDB = 93;
  static const int _MM_PERM_BBDC = 94;
  static const int _MM_PERM_BBDD = 95;
  static const int _MM_PERM_BCAA = 96;
  static const int _MM_PERM_BCAB = 97;
  static const int _MM_PERM_BCAC = 98;
  static const int _MM_PERM_BCAD = 99;
  static const int _MM_PERM_BCBA = 100;
  static const int _MM_PERM_BCBB = 101;
  static const int _MM_PERM_BCBC = 102;
  static const int _MM_PERM_BCBD = 103;
  static const int _MM_PERM_BCCA = 104;
  static const int _MM_PERM_BCCB = 105;
  static const int _MM_PERM_BCCC = 106;
  static const int _MM_PERM_BCCD = 107;
  static const int _MM_PERM_BCDA = 108;
  static const int _MM_PERM_BCDB = 109;
  static const int _MM_PERM_BCDC = 110;
  static const int _MM_PERM_BCDD = 111;
  static const int _MM_PERM_BDAA = 112;
  static const int _MM_PERM_BDAB = 113;
  static const int _MM_PERM_BDAC = 114;
  static const int _MM_PERM_BDAD = 115;
  static const int _MM_PERM_BDBA = 116;
  static const int _MM_PERM_BDBB = 117;
  static const int _MM_PERM_BDBC = 118;
  static const int _MM_PERM_BDBD = 119;
  static const int _MM_PERM_BDCA = 120;
  static const int _MM_PERM_BDCB = 121;
  static const int _MM_PERM_BDCC = 122;
  static const int _MM_PERM_BDCD = 123;
  static const int _MM_PERM_BDDA = 124;
  static const int _MM_PERM_BDDB = 125;
  static const int _MM_PERM_BDDC = 126;
  static const int _MM_PERM_BDDD = 127;
  static const int _MM_PERM_CAAA = 128;
  static const int _MM_PERM_CAAB = 129;
  static const int _MM_PERM_CAAC = 130;
  static const int _MM_PERM_CAAD = 131;
  static const int _MM_PERM_CABA = 132;
  static const int _MM_PERM_CABB = 133;
  static const int _MM_PERM_CABC = 134;
  static const int _MM_PERM_CABD = 135;
  static const int _MM_PERM_CACA = 136;
  static const int _MM_PERM_CACB = 137;
  static const int _MM_PERM_CACC = 138;
  static const int _MM_PERM_CACD = 139;
  static const int _MM_PERM_CADA = 140;
  static const int _MM_PERM_CADB = 141;
  static const int _MM_PERM_CADC = 142;
  static const int _MM_PERM_CADD = 143;
  static const int _MM_PERM_CBAA = 144;
  static const int _MM_PERM_CBAB = 145;
  static const int _MM_PERM_CBAC = 146;
  static const int _MM_PERM_CBAD = 147;
  static const int _MM_PERM_CBBA = 148;
  static const int _MM_PERM_CBBB = 149;
  static const int _MM_PERM_CBBC = 150;
  static const int _MM_PERM_CBBD = 151;
  static const int _MM_PERM_CBCA = 152;
  static const int _MM_PERM_CBCB = 153;
  static const int _MM_PERM_CBCC = 154;
  static const int _MM_PERM_CBCD = 155;
  static const int _MM_PERM_CBDA = 156;
  static const int _MM_PERM_CBDB = 157;
  static const int _MM_PERM_CBDC = 158;
  static const int _MM_PERM_CBDD = 159;
  static const int _MM_PERM_CCAA = 160;
  static const int _MM_PERM_CCAB = 161;
  static const int _MM_PERM_CCAC = 162;
  static const int _MM_PERM_CCAD = 163;
  static const int _MM_PERM_CCBA = 164;
  static const int _MM_PERM_CCBB = 165;
  static const int _MM_PERM_CCBC = 166;
  static const int _MM_PERM_CCBD = 167;
  static const int _MM_PERM_CCCA = 168;
  static const int _MM_PERM_CCCB = 169;
  static const int _MM_PERM_CCCC = 170;
  static const int _MM_PERM_CCCD = 171;
  static const int _MM_PERM_CCDA = 172;
  static const int _MM_PERM_CCDB = 173;
  static const int _MM_PERM_CCDC = 174;
  static const int _MM_PERM_CCDD = 175;
  static const int _MM_PERM_CDAA = 176;
  static const int _MM_PERM_CDAB = 177;
  static const int _MM_PERM_CDAC = 178;
  static const int _MM_PERM_CDAD = 179;
  static const int _MM_PERM_CDBA = 180;
  static const int _MM_PERM_CDBB = 181;
  static const int _MM_PERM_CDBC = 182;
  static const int _MM_PERM_CDBD = 183;
  static const int _MM_PERM_CDCA = 184;
  static const int _MM_PERM_CDCB = 185;
  static const int _MM_PERM_CDCC = 186;
  static const int _MM_PERM_CDCD = 187;
  static const int _MM_PERM_CDDA = 188;
  static const int _MM_PERM_CDDB = 189;
  static const int _MM_PERM_CDDC = 190;
  static const int _MM_PERM_CDDD = 191;
  static const int _MM_PERM_DAAA = 192;
  static const int _MM_PERM_DAAB = 193;
  static const int _MM_PERM_DAAC = 194;
  static const int _MM_PERM_DAAD = 195;
  static const int _MM_PERM_DABA = 196;
  static const int _MM_PERM_DABB = 197;
  static const int _MM_PERM_DABC = 198;
  static const int _MM_PERM_DABD = 199;
  static const int _MM_PERM_DACA = 200;
  static const int _MM_PERM_DACB = 201;
  static const int _MM_PERM_DACC = 202;
  static const int _MM_PERM_DACD = 203;
  static const int _MM_PERM_DADA = 204;
  static const int _MM_PERM_DADB = 205;
  static const int _MM_PERM_DADC = 206;
  static const int _MM_PERM_DADD = 207;
  static const int _MM_PERM_DBAA = 208;
  static const int _MM_PERM_DBAB = 209;
  static const int _MM_PERM_DBAC = 210;
  static const int _MM_PERM_DBAD = 211;
  static const int _MM_PERM_DBBA = 212;
  static const int _MM_PERM_DBBB = 213;
  static const int _MM_PERM_DBBC = 214;
  static const int _MM_PERM_DBBD = 215;
  static const int _MM_PERM_DBCA = 216;
  static const int _MM_PERM_DBCB = 217;
  static const int _MM_PERM_DBCC = 218;
  static const int _MM_PERM_DBCD = 219;
  static const int _MM_PERM_DBDA = 220;
  static const int _MM_PERM_DBDB = 221;
  static const int _MM_PERM_DBDC = 222;
  static const int _MM_PERM_DBDD = 223;
  static const int _MM_PERM_DCAA = 224;
  static const int _MM_PERM_DCAB = 225;
  static const int _MM_PERM_DCAC = 226;
  static const int _MM_PERM_DCAD = 227;
  static const int _MM_PERM_DCBA = 228;
  static const int _MM_PERM_DCBB = 229;
  static const int _MM_PERM_DCBC = 230;
  static const int _MM_PERM_DCBD = 231;
  static const int _MM_PERM_DCCA = 232;
  static const int _MM_PERM_DCCB = 233;
  static const int _MM_PERM_DCCC = 234;
  static const int _MM_PERM_DCCD = 235;
  static const int _MM_PERM_DCDA = 236;
  static const int _MM_PERM_DCDB = 237;
  static const int _MM_PERM_DCDC = 238;
  static const int _MM_PERM_DCDD = 239;
  static const int _MM_PERM_DDAA = 240;
  static const int _MM_PERM_DDAB = 241;
  static const int _MM_PERM_DDAC = 242;
  static const int _MM_PERM_DDAD = 243;
  static const int _MM_PERM_DDBA = 244;
  static const int _MM_PERM_DDBB = 245;
  static const int _MM_PERM_DDBC = 246;
  static const int _MM_PERM_DDBD = 247;
  static const int _MM_PERM_DDCA = 248;
  static const int _MM_PERM_DDCB = 249;
  static const int _MM_PERM_DDCC = 250;
  static const int _MM_PERM_DDCD = 251;
  static const int _MM_PERM_DDDA = 252;
  static const int _MM_PERM_DDDB = 253;
  static const int _MM_PERM_DDDC = 254;
  static const int _MM_PERM_DDDD = 255;
}

abstract class _MM_FIXUPRESULT_ENUM {
  static const int _MM_FIXUP_NO_CHANGE = 0;
  static const int _MM_FIXUP_NEG_INF = 1;
  static const int _MM_FIXUP_NEG_ZERO = 2;
  static const int _MM_FIXUP_POS_ZERO = 3;
  static const int _MM_FIXUP_POS_INF = 4;
  static const int _MM_FIXUP_NAN = 5;
  static const int _MM_FIXUP_MAX_FLOAT = 6;
  static const int _MM_FIXUP_MIN_FLOAT = 7;
}

abstract class _MM_MANTISSA_NORM_ENUM {
  static const int _MM_MANT_NORM_1_2 = 0;
  static const int _MM_MANT_NORM_p5_2 = 1;
  static const int _MM_MANT_NORM_p5_1 = 2;
  static const int _MM_MANT_NORM_p75_1p5 = 3;
}

abstract class _MM_MANTISSA_SIGN_ENUM {
  static const int _MM_MANT_SIGN_src = 0;
  static const int _MM_MANT_SIGN_zero = 1;
  static const int _MM_MANT_SIGN_nan = 2;
}

abstract class _MM_CMPINT_ENUM {
  static const int _MM_CMPINT_EQ = 0;
  static const int _MM_CMPINT_LT = 1;
  static const int _MM_CMPINT_LE = 2;
  static const int _MM_CMPINT_UNUSED = 3;
  static const int _MM_CMPINT_NE = 4;
  static const int _MM_CMPINT_NLT = 5;
  static const int _MM_CMPINT_NLE = 6;
}

typedef __mmask16 = ffi.Uint16;
typedef __mmask8 = ffi.Uint8;
typedef __mmask64 = ffi.Uint64;
typedef __mmask32 = ffi.Uint32;
typedef __m128bh = __m128i;
typedef __m256bh = __m256i;
typedef __m512bh = __m512i;
typedef __tile = ffi.Int32;
typedef __m128h = __m128i;
typedef __m256h = __m256i;
typedef __m512h = __m512i;

class rmp_seg extends ffi.Struct {
  @ffi.Uint64()
  external int rmp_gpa;

  @ffi.Int8()
  external int rmp_entry;

  @ffi.Int8()
  external int rmp_pageSize;

  @ffi.Int8()
  external int rmp_pageMark;

  @ffi.Int8()
  external int rmp_reserved;

  @ffi.Int32()
  external int rmp_ASID;
}

class SDL_mutex extends ffi.Opaque {}

class SDL_semaphore extends ffi.Opaque {}

typedef SDL_sem = SDL_semaphore;

class SDL_cond extends ffi.Opaque {}

class exception extends ffi.Struct {
  @ffi.Int32()
  external int type;

  external ffi.Pointer<ffi.Int8> name;

  @ffi.Double()
  external double arg1;

  @ffi.Double()
  external double arg2;

  @ffi.Double()
  external double retval;
}

class complex extends ffi.Struct {
  @ffi.Double()
  external double x;

  @ffi.Double()
  external double y;
}

class _double_val extends ffi.Union {
  @ffi.Array.multi([4])
  external ffi.Array<ffi.Uint16> Sh;

  @ffi.Double()
  external double Val;
}

class _float_val extends ffi.Union {
  @ffi.Array.multi([2])
  external ffi.Array<ffi.Uint16> Sh;

  @ffi.Float()
  external double Val;
}

class _ldouble_val extends ffi.Opaque {}

class _float_const extends ffi.Opaque {}

typedef _locale_t = ffi.Pointer<_crt_locale_pointers>;

abstract class _crt_argv_mode {
  static const int _crt_argv_no_arguments = 0;
  static const int _crt_argv_unexpanded_arguments = 1;
  static const int _crt_argv_expanded_arguments = 2;
}

abstract class _crt_exit_return_mode {
  static const int _crt_exit_terminate_process = 0;
  static const int _crt_exit_return_to_caller = 1;
}

abstract class _crt_exit_cleanup_mode {
  static const int _crt_exit_full_cleanup = 0;
  static const int _crt_exit_quick_cleanup = 1;
  static const int _crt_exit_no_cleanup = 2;
}

class EXCEPTION_POINTERS extends ffi.Opaque {}

abstract class _crt_app_type {
  static const int _crt_unknown_app = 0;
  static const int _crt_console_app = 1;
  static const int _crt_gui_app = 2;
}

typedef _UserMathErrorFunctionPointer = ffi
    .Pointer<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<exception>)>>;
typedef _PVFV = ffi.Pointer<ffi.NativeFunction<ffi.Void Function()>>;
typedef _PIFV = ffi.Pointer<ffi.NativeFunction<ffi.Int32 Function()>>;

class onexit_table_t extends ffi.Struct {
  external ffi.Pointer<_PVFV> first;

  external ffi.Pointer<_PVFV> last;

  external ffi.Pointer<_PVFV> end;
}

typedef _onexit_t = ffi.Pointer<ffi.NativeFunction<ffi.Int32 Function()>>;
typedef _tls_callback_type = ffi.Pointer<
    ffi.NativeFunction<
        ffi.Void Function(
            ffi.Pointer<ffi.Void>, ffi.Uint64, ffi.Pointer<ffi.Void>)>>;
typedef _beginthread_proc_type
    = ffi.Pointer<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ffi.Void>)>>;
typedef _beginthreadex_proc_type = ffi
    .Pointer<ffi.NativeFunction<ffi.Uint32 Function(ffi.Pointer<ffi.Void>)>>;
typedef _GetDllProcAddrProcType
    = ffi.Pointer<ffi.NativeFunction<ffi.Int32 Function()>>;

class SDL_Thread extends ffi.Opaque {}

/// The SDL thread priority.
///
/// SDL will make system changes as necessary in order to apply the thread priority.
/// Code which attempts to control thread state related to priority should be aware
/// that calling SDL_SetThreadPriority may alter such state.
/// SDL_HINT_THREAD_PRIORITY_POLICY can be used to control aspects of this behavior.
///
/// \note On many systems you require special privileges to set high or time critical priority.
abstract class SDL_ThreadPriority {
  static const int SDL_THREAD_PRIORITY_LOW = 0;
  static const int SDL_THREAD_PRIORITY_NORMAL = 1;
  static const int SDL_THREAD_PRIORITY_HIGH = 2;
  static const int SDL_THREAD_PRIORITY_TIME_CRITICAL = 3;
}

/// The function passed to SDL_CreateThread().
///
/// \param data what was passed as `data` to SDL_CreateThread()
/// \returns a value that can be reported through SDL_WaitThread().
typedef SDL_ThreadFunction = ffi
    .Pointer<ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<ffi.Void>)>>;
typedef pfnSDL_CurrentBeginThread = ffi.Pointer<
    ffi.NativeFunction<
        uintptr_t Function(
            ffi.Pointer<ffi.Void>,
            ffi.Uint32,
            ffi.Pointer<
                ffi.NativeFunction<ffi.Uint32 Function(ffi.Pointer<ffi.Void>)>>,
            ffi.Pointer<ffi.Void>,
            ffi.Uint32,
            ffi.Pointer<ffi.Uint32>)>>;
typedef pfnSDL_CurrentEndThread
    = ffi.Pointer<ffi.NativeFunction<ffi.Void Function(ffi.Uint32)>>;
typedef SDL_threadID = ffi.Uint64;
typedef SDL_TLSID = ffi.Uint32;

/// This is the read/write operation structure -- very basic.
class SDL_RWops extends ffi.Struct {
  /// Return the size of the file in this rwops, or -1 if unknown
  external ffi
          .Pointer<ffi.NativeFunction<Sint64 Function(ffi.Pointer<SDL_RWops>)>>
      size;

  /// Seek to \c offset relative to \c whence, one of stdio's whence values:
  /// RW_SEEK_SET, RW_SEEK_CUR, RW_SEEK_END
  ///
  /// \return the final offset in the data stream, or -1 on error.
  external ffi.Pointer<
      ffi.NativeFunction<
          Sint64 Function(ffi.Pointer<SDL_RWops>, Sint64, ffi.Int32)>> seek;

  /// Read up to \c maxnum objects each of size \c size from the data
  /// stream to the area pointed at by \c ptr.
  ///
  /// \return the number of objects read, or 0 at error or end of file.
  external ffi.Pointer<
      ffi.NativeFunction<
          size_t Function(ffi.Pointer<SDL_RWops>, ffi.Pointer<ffi.Void>, size_t,
              size_t)>> read;

  /// Write exactly \c num objects each of size \c size from the area
  /// pointed at by \c ptr to data stream.
  ///
  /// \return the number of objects written, or 0 at error or end of file.
  external ffi.Pointer<
      ffi.NativeFunction<
          size_t Function(ffi.Pointer<SDL_RWops>, ffi.Pointer<ffi.Void>, size_t,
              size_t)>> write;

  /// Close and free an allocated SDL_RWops structure.
  ///
  /// \return 0 if successful or -1 on write error when flushing data.
  external ffi.Pointer<
      ffi.NativeFunction<ffi.Int32 Function(ffi.Pointer<SDL_RWops>)>> close;

  @Uint32()
  external int type;

  external UnnamedUnion1 hidden;
}

class UnnamedUnion1 extends ffi.Union {
  external UnnamedStruct1 windowsio;

  external UnnamedStruct3 mem;

  external UnnamedStruct4 unknown;
}

class UnnamedStruct1 extends ffi.Struct {
  @ffi.Int32()
  external int append;

  external ffi.Pointer<ffi.Void> h;

  external UnnamedStruct2 buffer;
}

class UnnamedStruct2 extends ffi.Struct {
  external ffi.Pointer<ffi.Void> data;

  @size_t()
  external int size;

  @size_t()
  external int left;
}

class UnnamedStruct3 extends ffi.Struct {
  external ffi.Pointer<Uint8> base;

  external ffi.Pointer<Uint8> here;

  external ffi.Pointer<Uint8> stop;
}

typedef Uint8 = ffi.Uint8;

class UnnamedStruct4 extends ffi.Struct {
  external ffi.Pointer<ffi.Void> data1;

  external ffi.Pointer<ffi.Void> data2;
}

typedef Uint16 = ffi.Uint16;

/// The calculated values in this structure are calculated by SDL_OpenAudio().
///
/// For multi-channel audio, the default SDL channel mapping is:
/// 2:  FL FR                       (stereo)
/// 3:  FL FR LFE                   (2.1 surround)
/// 4:  FL FR BL BR                 (quad)
/// 5:  FL FR FC BL BR              (quad + center)
/// 6:  FL FR FC LFE SL SR          (5.1 surround - last two can also be BL BR)
/// 7:  FL FR FC LFE BC SL SR       (6.1 surround)
/// 8:  FL FR FC LFE BL BR SL SR    (7.1 surround)
class SDL_AudioSpec extends ffi.Struct {
  /// < DSP frequency -- samples per second
  @ffi.Int32()
  external int freq;

  /// < Audio data format
  @SDL_AudioFormat()
  external int format;

  /// < Number of channels: 1 mono, 2 stereo
  @Uint8()
  external int channels;

  /// < Audio buffer silence value (calculated)
  @Uint8()
  external int silence;

  /// < Audio buffer size in sample FRAMES (total samples divided by channel count)
  @Uint16()
  external int samples;

  /// < Necessary for some compile environments
  @Uint16()
  external int padding;

  /// < Audio buffer size in bytes (calculated)
  @Uint32()
  external int size;

  /// < Callback that feeds the audio device (NULL to use SDL_QueueAudio()).
  external SDL_AudioCallback callback;

  /// < Userdata passed to callback (ignored for NULL callbacks).
  external ffi.Pointer<ffi.Void> userdata;
}

/// \brief Audio format flags.
///
/// These are what the 16 bits in SDL_AudioFormat currently mean...
/// (Unspecified bits are always zero).
///
/// \verbatim
/// ++-----------------------sample is signed if set
/// ||
/// ||       ++-----------sample is bigendian if set
/// ||       ||
/// ||       ||          ++---sample is float if set
/// ||       ||          ||
/// ||       ||          || +---sample bit size---+
/// ||       ||          || |                     |
/// 15 14 13 12 11 10 09 08 07 06 05 04 03 02 01 00
/// \endverbatim
///
/// There are macros in SDL 2.0 and later to query these bits.
typedef SDL_AudioFormat = Uint16;

/// This function is called when the audio device needs more data.
///
/// \param userdata An application-specific parameter saved in
/// the SDL_AudioSpec structure
/// \param stream A pointer to the audio data buffer.
/// \param len    The length of that buffer in bytes.
///
/// Once the callback returns, the buffer will no longer be valid.
/// Stereo samples are stored in a LRLRLR ordering.
///
/// You can choose to avoid callbacks and use SDL_QueueAudio() instead, if
/// you like. Just open your audio device with a NULL callback.
typedef SDL_AudioCallback = ffi.Pointer<
    ffi.NativeFunction<
        ffi.Void Function(
            ffi.Pointer<ffi.Void>, ffi.Pointer<Uint8>, ffi.Int32)>>;

class SDL_AudioCVT extends ffi.Struct {
  /// < Set to 1 if conversion possible
  @ffi.Int32()
  external int needed;

  /// < Source audio format
  @SDL_AudioFormat()
  external int src_format;

  /// < Target audio format
  @SDL_AudioFormat()
  external int dst_format;

  /// < Rate conversion increment
  @ffi.Double()
  external double rate_incr;

  /// < Buffer to hold entire audio data
  external ffi.Pointer<Uint8> buf;

  /// < Length of original audio buffer
  @ffi.Int32()
  external int len;

  /// < Length of converted audio buffer
  @ffi.Int32()
  external int len_cvt;

  /// < buffer must be len*len_mult big
  @ffi.Int32()
  external int len_mult;

  /// < Given len, final size is len*len_ratio
  @ffi.Double()
  external double len_ratio;

  @ffi.Array.multi([10])
  external ffi.Array<SDL_AudioFilter> filters;

  /// < Current audio conversion function
  @ffi.Int32()
  external int filter_index;
}

typedef SDL_AudioFilter = ffi.Pointer<
    ffi.NativeFunction<
        ffi.Void Function(ffi.Pointer<SDL_AudioCVT>, SDL_AudioFormat)>>;

/// SDL Audio Device IDs.
///
/// A successful call to SDL_OpenAudio() is always device id 1, and legacy
/// SDL audio APIs assume you want this device ID. SDL_OpenAudioDevice() calls
/// always returns devices >= 2 on success. The legacy calls are good both
/// for backwards compatibility and when you don't care about multiple,
/// specific, or capture devices.
typedef SDL_AudioDeviceID = Uint32;

abstract class SDL_AudioStatus {
  static const int SDL_AUDIO_STOPPED = 0;
  static const int SDL_AUDIO_PLAYING = 1;
  static const int SDL_AUDIO_PAUSED = 2;
}

class SDL_AudioStream extends ffi.Opaque {}

typedef SDL_AudioStream1 = SDL_AudioStream;

/// Pixel type.
abstract class SDL_PixelType {
  static const int SDL_PIXELTYPE_UNKNOWN = 0;
  static const int SDL_PIXELTYPE_INDEX1 = 1;
  static const int SDL_PIXELTYPE_INDEX4 = 2;
  static const int SDL_PIXELTYPE_INDEX8 = 3;
  static const int SDL_PIXELTYPE_PACKED8 = 4;
  static const int SDL_PIXELTYPE_PACKED16 = 5;
  static const int SDL_PIXELTYPE_PACKED32 = 6;
  static const int SDL_PIXELTYPE_ARRAYU8 = 7;
  static const int SDL_PIXELTYPE_ARRAYU16 = 8;
  static const int SDL_PIXELTYPE_ARRAYU32 = 9;
  static const int SDL_PIXELTYPE_ARRAYF16 = 10;
  static const int SDL_PIXELTYPE_ARRAYF32 = 11;
}

/// Bitmap pixel order, high bit -> low bit.
abstract class SDL_BitmapOrder {
  static const int SDL_BITMAPORDER_NONE = 0;
  static const int SDL_BITMAPORDER_4321 = 1;
  static const int SDL_BITMAPORDER_1234 = 2;
}

/// Packed component order, high bit -> low bit.
abstract class SDL_PackedOrder {
  static const int SDL_PACKEDORDER_NONE = 0;
  static const int SDL_PACKEDORDER_XRGB = 1;
  static const int SDL_PACKEDORDER_RGBX = 2;
  static const int SDL_PACKEDORDER_ARGB = 3;
  static const int SDL_PACKEDORDER_RGBA = 4;
  static const int SDL_PACKEDORDER_XBGR = 5;
  static const int SDL_PACKEDORDER_BGRX = 6;
  static const int SDL_PACKEDORDER_ABGR = 7;
  static const int SDL_PACKEDORDER_BGRA = 8;
}

/// Array component order, low byte -> high byte.
abstract class SDL_ArrayOrder {
  static const int SDL_ARRAYORDER_NONE = 0;
  static const int SDL_ARRAYORDER_RGB = 1;
  static const int SDL_ARRAYORDER_RGBA = 2;
  static const int SDL_ARRAYORDER_ARGB = 3;
  static const int SDL_ARRAYORDER_BGR = 4;
  static const int SDL_ARRAYORDER_BGRA = 5;
  static const int SDL_ARRAYORDER_ABGR = 6;
}

/// Packed component layout.
abstract class SDL_PackedLayout {
  static const int SDL_PACKEDLAYOUT_NONE = 0;
  static const int SDL_PACKEDLAYOUT_332 = 1;
  static const int SDL_PACKEDLAYOUT_4444 = 2;
  static const int SDL_PACKEDLAYOUT_1555 = 3;
  static const int SDL_PACKEDLAYOUT_5551 = 4;
  static const int SDL_PACKEDLAYOUT_565 = 5;
  static const int SDL_PACKEDLAYOUT_8888 = 6;
  static const int SDL_PACKEDLAYOUT_2101010 = 7;
  static const int SDL_PACKEDLAYOUT_1010102 = 8;
}

abstract class SDL_PixelFormatEnum {
  static const int SDL_PIXELFORMAT_UNKNOWN = 0;
  static const int SDL_PIXELFORMAT_INDEX1LSB = 286261504;
  static const int SDL_PIXELFORMAT_INDEX1MSB = 287310080;
  static const int SDL_PIXELFORMAT_INDEX4LSB = 303039488;
  static const int SDL_PIXELFORMAT_INDEX4MSB = 304088064;
  static const int SDL_PIXELFORMAT_INDEX8 = 318769153;
  static const int SDL_PIXELFORMAT_RGB332 = 336660481;
  static const int SDL_PIXELFORMAT_XRGB4444 = 353504258;
  static const int SDL_PIXELFORMAT_RGB444 = 353504258;
  static const int SDL_PIXELFORMAT_XBGR4444 = 357698562;
  static const int SDL_PIXELFORMAT_BGR444 = 357698562;
  static const int SDL_PIXELFORMAT_XRGB1555 = 353570562;
  static const int SDL_PIXELFORMAT_RGB555 = 353570562;
  static const int SDL_PIXELFORMAT_XBGR1555 = 357764866;
  static const int SDL_PIXELFORMAT_BGR555 = 357764866;
  static const int SDL_PIXELFORMAT_ARGB4444 = 355602434;
  static const int SDL_PIXELFORMAT_RGBA4444 = 356651010;
  static const int SDL_PIXELFORMAT_ABGR4444 = 359796738;
  static const int SDL_PIXELFORMAT_BGRA4444 = 360845314;
  static const int SDL_PIXELFORMAT_ARGB1555 = 355667970;
  static const int SDL_PIXELFORMAT_RGBA5551 = 356782082;
  static const int SDL_PIXELFORMAT_ABGR1555 = 359862274;
  static const int SDL_PIXELFORMAT_BGRA5551 = 360976386;
  static const int SDL_PIXELFORMAT_RGB565 = 353701890;
  static const int SDL_PIXELFORMAT_BGR565 = 357896194;
  static const int SDL_PIXELFORMAT_RGB24 = 386930691;
  static const int SDL_PIXELFORMAT_BGR24 = 390076419;
  static const int SDL_PIXELFORMAT_XRGB8888 = 370546692;
  static const int SDL_PIXELFORMAT_RGB888 = 370546692;
  static const int SDL_PIXELFORMAT_RGBX8888 = 371595268;
  static const int SDL_PIXELFORMAT_XBGR8888 = 374740996;
  static const int SDL_PIXELFORMAT_BGR888 = 374740996;
  static const int SDL_PIXELFORMAT_BGRX8888 = 375789572;
  static const int SDL_PIXELFORMAT_ARGB8888 = 372645892;
  static const int SDL_PIXELFORMAT_RGBA8888 = 373694468;
  static const int SDL_PIXELFORMAT_ABGR8888 = 376840196;
  static const int SDL_PIXELFORMAT_BGRA8888 = 377888772;
  static const int SDL_PIXELFORMAT_ARGB2101010 = 372711428;
  static const int SDL_PIXELFORMAT_RGBA32 = 376840196;
  static const int SDL_PIXELFORMAT_ARGB32 = 377888772;
  static const int SDL_PIXELFORMAT_BGRA32 = 372645892;
  static const int SDL_PIXELFORMAT_ABGR32 = 373694468;

  /// < Planar mode: Y + V + U  (3 planes)
  static const int SDL_PIXELFORMAT_YV12 = 842094169;

  /// < Planar mode: Y + U + V  (3 planes)
  static const int SDL_PIXELFORMAT_IYUV = 1448433993;

  /// < Packed mode: Y0+U0+Y1+V0 (1 plane)
  static const int SDL_PIXELFORMAT_YUY2 = 844715353;

  /// < Packed mode: U0+Y0+V0+Y1 (1 plane)
  static const int SDL_PIXELFORMAT_UYVY = 1498831189;

  /// < Packed mode: Y0+V0+Y1+U0 (1 plane)
  static const int SDL_PIXELFORMAT_YVYU = 1431918169;

  /// < Planar mode: Y + U/V interleaved  (2 planes)
  static const int SDL_PIXELFORMAT_NV12 = 842094158;

  /// < Planar mode: Y + V/U interleaved  (2 planes)
  static const int SDL_PIXELFORMAT_NV21 = 825382478;

  /// < Android video texture format
  static const int SDL_PIXELFORMAT_EXTERNAL_OES = 542328143;
}

/// The bits of this structure can be directly reinterpreted as an integer-packed
/// color which uses the SDL_PIXELFORMAT_RGBA32 format (SDL_PIXELFORMAT_ABGR8888
/// on little-endian systems and SDL_PIXELFORMAT_RGBA8888 on big-endian systems).
class SDL_Color extends ffi.Struct {
  @Uint8()
  external int r;

  @Uint8()
  external int g;

  @Uint8()
  external int b;

  @Uint8()
  external int a;
}

class SDL_Palette extends ffi.Struct {
  @ffi.Int32()
  external int ncolors;

  external ffi.Pointer<SDL_Color> colors;

  @Uint32()
  external int version;

  @ffi.Int32()
  external int refcount;
}

/// \note Everything in the pixel format structure is read-only.
class SDL_PixelFormat extends ffi.Struct {
  @Uint32()
  external int format;

  external ffi.Pointer<SDL_Palette> palette;

  @Uint8()
  external int BitsPerPixel;

  @Uint8()
  external int BytesPerPixel;

  @ffi.Array.multi([2])
  external ffi.Array<Uint8> padding;

  @Uint32()
  external int Rmask;

  @Uint32()
  external int Gmask;

  @Uint32()
  external int Bmask;

  @Uint32()
  external int Amask;

  @Uint8()
  external int Rloss;

  @Uint8()
  external int Gloss;

  @Uint8()
  external int Bloss;

  @Uint8()
  external int Aloss;

  @Uint8()
  external int Rshift;

  @Uint8()
  external int Gshift;

  @Uint8()
  external int Bshift;

  @Uint8()
  external int Ashift;

  @ffi.Int32()
  external int refcount;

  external ffi.Pointer<SDL_PixelFormat> next;
}

/// The structure that defines a point (integer)
///
/// \sa SDL_EnclosePoints
/// \sa SDL_PointInRect
class SDL_Point extends ffi.Struct {
  @ffi.Int32()
  external int x;

  @ffi.Int32()
  external int y;
}

/// The structure that defines a point (floating point)
///
/// \sa SDL_EnclosePoints
/// \sa SDL_PointInRect
class SDL_FPoint extends ffi.Struct {
  @ffi.Float()
  external double x;

  @ffi.Float()
  external double y;
}

/// A rectangle, with the origin at the upper left (integer).
///
/// \sa SDL_RectEmpty
/// \sa SDL_RectEquals
/// \sa SDL_HasIntersection
/// \sa SDL_IntersectRect
/// \sa SDL_UnionRect
/// \sa SDL_EnclosePoints
class SDL_Rect extends ffi.Struct {
  @ffi.Int32()
  external int x;

  @ffi.Int32()
  external int y;

  @ffi.Int32()
  external int w;

  @ffi.Int32()
  external int h;
}

/// A rectangle, with the origin at the upper left (floating point).
class SDL_FRect extends ffi.Struct {
  @ffi.Float()
  external double x;

  @ffi.Float()
  external double y;

  @ffi.Float()
  external double w;

  @ffi.Float()
  external double h;
}

/// \brief The blend mode used in SDL_RenderCopy() and drawing operations.
abstract class SDL_BlendMode {
  /// < no blending
  /// dstRGBA = srcRGBA
  static const int SDL_BLENDMODE_NONE = 0;

  /// < alpha blending
  /// dstRGB = (srcRGB * srcA) + (dstRGB * (1-srcA))
  /// dstA = srcA + (dstA * (1-srcA))
  static const int SDL_BLENDMODE_BLEND = 1;

  /// < additive blending
  /// dstRGB = (srcRGB * srcA) + dstRGB
  /// dstA = dstA
  static const int SDL_BLENDMODE_ADD = 2;

  /// < color modulate
  /// dstRGB = srcRGB * dstRGB
  /// dstA = dstA
  static const int SDL_BLENDMODE_MOD = 4;

  /// < color multiply
  /// dstRGB = (srcRGB * dstRGB) + (dstRGB * (1-srcA))
  /// dstA = (srcA * dstA) + (dstA * (1-srcA))
  static const int SDL_BLENDMODE_MUL = 8;
  static const int SDL_BLENDMODE_INVALID = 2147483647;
}

/// \brief The blend operation used when combining source and destination pixel components
abstract class SDL_BlendOperation {
  /// < dst + src: supported by all renderers
  static const int SDL_BLENDOPERATION_ADD = 1;

  /// < dst - src : supported by D3D9, D3D11, OpenGL, OpenGLES
  static const int SDL_BLENDOPERATION_SUBTRACT = 2;

  /// < src - dst : supported by D3D9, D3D11, OpenGL, OpenGLES
  static const int SDL_BLENDOPERATION_REV_SUBTRACT = 3;

  /// < min(dst, src) : supported by D3D11
  static const int SDL_BLENDOPERATION_MINIMUM = 4;

  /// < max(dst, src) : supported by D3D11
  static const int SDL_BLENDOPERATION_MAXIMUM = 5;
}

/// \brief The normalized factor used to multiply pixel components
abstract class SDL_BlendFactor {
  /// < 0, 0, 0, 0
  static const int SDL_BLENDFACTOR_ZERO = 1;

  /// < 1, 1, 1, 1
  static const int SDL_BLENDFACTOR_ONE = 2;

  /// < srcR, srcG, srcB, srcA
  static const int SDL_BLENDFACTOR_SRC_COLOR = 3;

  /// < 1-srcR, 1-srcG, 1-srcB, 1-srcA
  static const int SDL_BLENDFACTOR_ONE_MINUS_SRC_COLOR = 4;

  /// < srcA, srcA, srcA, srcA
  static const int SDL_BLENDFACTOR_SRC_ALPHA = 5;

  /// < 1-srcA, 1-srcA, 1-srcA, 1-srcA
  static const int SDL_BLENDFACTOR_ONE_MINUS_SRC_ALPHA = 6;

  /// < dstR, dstG, dstB, dstA
  static const int SDL_BLENDFACTOR_DST_COLOR = 7;

  /// < 1-dstR, 1-dstG, 1-dstB, 1-dstA
  static const int SDL_BLENDFACTOR_ONE_MINUS_DST_COLOR = 8;

  /// < dstA, dstA, dstA, dstA
  static const int SDL_BLENDFACTOR_DST_ALPHA = 9;

  /// < 1-dstA, 1-dstA, 1-dstA, 1-dstA
  static const int SDL_BLENDFACTOR_ONE_MINUS_DST_ALPHA = 10;
}

/// \brief A collection of pixels used in software blitting.
///
/// \note  This structure should be treated as read-only, except for \c pixels,
/// which, if not NULL, contains the raw pixel data for the surface.
class SDL_Surface extends ffi.Struct {
  /// < Read-only
  @Uint32()
  external int flags;

  /// < Read-only
  external ffi.Pointer<SDL_PixelFormat> format;

  /// < Read-only
  @ffi.Int32()
  external int w;

  @ffi.Int32()
  external int h;

  /// < Read-only
  @ffi.Int32()
  external int pitch;

  /// < Read-write
  external ffi.Pointer<ffi.Void> pixels;

  /// < Read-write
  external ffi.Pointer<ffi.Void> userdata;

  /// < Read-only
  @ffi.Int32()
  external int locked;

  /// < Private
  external ffi.Pointer<ffi.Void> list_blitmap;

  /// < Read-only
  external SDL_Rect clip_rect;

  /// < Private
  external ffi.Pointer<SDL_BlitMap> map;

  /// < Read-mostly
  @ffi.Int32()
  external int refcount;
}

class SDL_BlitMap extends ffi.Opaque {}

/// \brief The formula used for converting between YUV and RGB
abstract class SDL_YUV_CONVERSION_MODE {
  /// < Full range JPEG
  static const int SDL_YUV_CONVERSION_JPEG = 0;

  /// < BT.601 (the default)
  static const int SDL_YUV_CONVERSION_BT601 = 1;

  /// < BT.709
  static const int SDL_YUV_CONVERSION_BT709 = 2;

  /// < BT.601 for SD content, BT.709 for HD content
  static const int SDL_YUV_CONVERSION_AUTOMATIC = 3;
}

/// \brief  The structure that defines a display mode
///
/// \sa SDL_GetNumDisplayModes()
/// \sa SDL_GetDisplayMode()
/// \sa SDL_GetDesktopDisplayMode()
/// \sa SDL_GetCurrentDisplayMode()
/// \sa SDL_GetClosestDisplayMode()
/// \sa SDL_SetWindowDisplayMode()
/// \sa SDL_GetWindowDisplayMode()
class SDL_DisplayMode extends ffi.Struct {
  /// < pixel format
  @Uint32()
  external int format;

  /// < width, in screen coordinates
  @ffi.Int32()
  external int w;

  /// < height, in screen coordinates
  @ffi.Int32()
  external int h;

  /// < refresh rate (or zero for unspecified)
  @ffi.Int32()
  external int refresh_rate;

  /// < driver-specific data, initialize to 0
  external ffi.Pointer<ffi.Void> driverdata;
}

class SDL_Window extends ffi.Opaque {}

/// \brief The flags on a window
///
/// \sa SDL_GetWindowFlags()
abstract class SDL_WindowFlags {
  /// < fullscreen window
  static const int SDL_WINDOW_FULLSCREEN = 1;

  /// < window usable with OpenGL context
  static const int SDL_WINDOW_OPENGL = 2;

  /// < window is visible
  static const int SDL_WINDOW_SHOWN = 4;

  /// < window is not visible
  static const int SDL_WINDOW_HIDDEN = 8;

  /// < no window decoration
  static const int SDL_WINDOW_BORDERLESS = 16;

  /// < window can be resized
  static const int SDL_WINDOW_RESIZABLE = 32;

  /// < window is minimized
  static const int SDL_WINDOW_MINIMIZED = 64;

  /// < window is maximized
  static const int SDL_WINDOW_MAXIMIZED = 128;

  /// < window has grabbed mouse input
  static const int SDL_WINDOW_MOUSE_GRABBED = 256;

  /// < window has input focus
  static const int SDL_WINDOW_INPUT_FOCUS = 512;

  /// < window has mouse focus
  static const int SDL_WINDOW_MOUSE_FOCUS = 1024;
  static const int SDL_WINDOW_FULLSCREEN_DESKTOP = 4097;

  /// < window not created by SDL
  static const int SDL_WINDOW_FOREIGN = 2048;

  /// < window should be created in high-DPI mode if supported.
  /// On macOS NSHighResolutionCapable must be set true in the
  /// application's Info.plist for this to have any effect.
  static const int SDL_WINDOW_ALLOW_HIGHDPI = 8192;

  /// < window has mouse captured (unrelated to MOUSE_GRABBED)
  static const int SDL_WINDOW_MOUSE_CAPTURE = 16384;

  /// < window should always be above others
  static const int SDL_WINDOW_ALWAYS_ON_TOP = 32768;

  /// < window should not be added to the taskbar
  static const int SDL_WINDOW_SKIP_TASKBAR = 65536;

  /// < window should be treated as a utility window
  static const int SDL_WINDOW_UTILITY = 131072;

  /// < window should be treated as a tooltip
  static const int SDL_WINDOW_TOOLTIP = 262144;

  /// < window should be treated as a popup menu
  static const int SDL_WINDOW_POPUP_MENU = 524288;

  /// < window has grabbed keyboard input
  static const int SDL_WINDOW_KEYBOARD_GRABBED = 1048576;

  /// < window usable for Vulkan surface
  static const int SDL_WINDOW_VULKAN = 268435456;

  /// < window usable for Metal view
  static const int SDL_WINDOW_METAL = 536870912;

  /// < equivalent to SDL_WINDOW_MOUSE_GRABBED for compatibility
  static const int SDL_WINDOW_INPUT_GRABBED = 256;
}

/// \brief Event subtype for window events
abstract class SDL_WindowEventID {
  /// < Never used
  static const int SDL_WINDOWEVENT_NONE = 0;

  /// < Window has been shown
  static const int SDL_WINDOWEVENT_SHOWN = 1;

  /// < Window has been hidden
  static const int SDL_WINDOWEVENT_HIDDEN = 2;

  /// < Window has been exposed and should be
  /// redrawn
  static const int SDL_WINDOWEVENT_EXPOSED = 3;

  /// < Window has been moved to data1, data2
  static const int SDL_WINDOWEVENT_MOVED = 4;

  /// < Window has been resized to data1xdata2
  static const int SDL_WINDOWEVENT_RESIZED = 5;

  /// < The window size has changed, either as
  /// a result of an API call or through the
  /// system or user changing the window size.
  static const int SDL_WINDOWEVENT_SIZE_CHANGED = 6;

  /// < Window has been minimized
  static const int SDL_WINDOWEVENT_MINIMIZED = 7;

  /// < Window has been maximized
  static const int SDL_WINDOWEVENT_MAXIMIZED = 8;

  /// < Window has been restored to normal size
  /// and position
  static const int SDL_WINDOWEVENT_RESTORED = 9;

  /// < Window has gained mouse focus
  static const int SDL_WINDOWEVENT_ENTER = 10;

  /// < Window has lost mouse focus
  static const int SDL_WINDOWEVENT_LEAVE = 11;

  /// < Window has gained keyboard focus
  static const int SDL_WINDOWEVENT_FOCUS_GAINED = 12;

  /// < Window has lost keyboard focus
  static const int SDL_WINDOWEVENT_FOCUS_LOST = 13;

  /// < The window manager requests that the window be closed
  static const int SDL_WINDOWEVENT_CLOSE = 14;

  /// < Window is being offered a focus (should SetWindowInputFocus() on itself or a subwindow, or ignore)
  static const int SDL_WINDOWEVENT_TAKE_FOCUS = 15;

  /// < Window had a hit test that wasn't SDL_HITTEST_NORMAL.
  static const int SDL_WINDOWEVENT_HIT_TEST = 16;

  /// < The ICC profile of the window's display has changed.
  static const int SDL_WINDOWEVENT_ICCPROF_CHANGED = 17;

  /// < Window has been moved to display data1.
  static const int SDL_WINDOWEVENT_DISPLAY_CHANGED = 18;
}

/// \brief Event subtype for display events
abstract class SDL_DisplayEventID {
  /// < Never used
  static const int SDL_DISPLAYEVENT_NONE = 0;

  /// < Display orientation has changed to data1
  static const int SDL_DISPLAYEVENT_ORIENTATION = 1;

  /// < Display has been added to the system
  static const int SDL_DISPLAYEVENT_CONNECTED = 2;

  /// < Display has been removed from the system
  static const int SDL_DISPLAYEVENT_DISCONNECTED = 3;
}

/// \brief Display orientation
abstract class SDL_DisplayOrientation {
  /// < The display orientation can't be determined
  static const int SDL_ORIENTATION_UNKNOWN = 0;

  /// < The display is in landscape mode, with the right side up, relative to portrait mode
  static const int SDL_ORIENTATION_LANDSCAPE = 1;

  /// < The display is in landscape mode, with the left side up, relative to portrait mode
  static const int SDL_ORIENTATION_LANDSCAPE_FLIPPED = 2;

  /// < The display is in portrait mode
  static const int SDL_ORIENTATION_PORTRAIT = 3;

  /// < The display is in portrait mode, upside down
  static const int SDL_ORIENTATION_PORTRAIT_FLIPPED = 4;
}

/// \brief Window flash operation
abstract class SDL_FlashOperation {
  /// < Cancel any window flash state
  static const int SDL_FLASH_CANCEL = 0;

  /// < Flash the window briefly to get attention
  static const int SDL_FLASH_BRIEFLY = 1;

  /// < Flash the window until it gets focus
  static const int SDL_FLASH_UNTIL_FOCUSED = 2;
}

/// \brief OpenGL configuration attributes
abstract class SDL_GLattr {
  static const int SDL_GL_RED_SIZE = 0;
  static const int SDL_GL_GREEN_SIZE = 1;
  static const int SDL_GL_BLUE_SIZE = 2;
  static const int SDL_GL_ALPHA_SIZE = 3;
  static const int SDL_GL_BUFFER_SIZE = 4;
  static const int SDL_GL_DOUBLEBUFFER = 5;
  static const int SDL_GL_DEPTH_SIZE = 6;
  static const int SDL_GL_STENCIL_SIZE = 7;
  static const int SDL_GL_ACCUM_RED_SIZE = 8;
  static const int SDL_GL_ACCUM_GREEN_SIZE = 9;
  static const int SDL_GL_ACCUM_BLUE_SIZE = 10;
  static const int SDL_GL_ACCUM_ALPHA_SIZE = 11;
  static const int SDL_GL_STEREO = 12;
  static const int SDL_GL_MULTISAMPLEBUFFERS = 13;
  static const int SDL_GL_MULTISAMPLESAMPLES = 14;
  static const int SDL_GL_ACCELERATED_VISUAL = 15;
  static const int SDL_GL_RETAINED_BACKING = 16;
  static const int SDL_GL_CONTEXT_MAJOR_VERSION = 17;
  static const int SDL_GL_CONTEXT_MINOR_VERSION = 18;
  static const int SDL_GL_CONTEXT_EGL = 19;
  static const int SDL_GL_CONTEXT_FLAGS = 20;
  static const int SDL_GL_CONTEXT_PROFILE_MASK = 21;
  static const int SDL_GL_SHARE_WITH_CURRENT_CONTEXT = 22;
  static const int SDL_GL_FRAMEBUFFER_SRGB_CAPABLE = 23;
  static const int SDL_GL_CONTEXT_RELEASE_BEHAVIOR = 24;
  static const int SDL_GL_CONTEXT_RESET_NOTIFICATION = 25;
  static const int SDL_GL_CONTEXT_NO_ERROR = 26;
}

abstract class SDL_GLprofile {
  static const int SDL_GL_CONTEXT_PROFILE_CORE = 1;
  static const int SDL_GL_CONTEXT_PROFILE_COMPATIBILITY = 2;

  /// < GLX_CONTEXT_ES2_PROFILE_BIT_EXT
  static const int SDL_GL_CONTEXT_PROFILE_ES = 4;
}

abstract class SDL_GLcontextFlag {
  static const int SDL_GL_CONTEXT_DEBUG_FLAG = 1;
  static const int SDL_GL_CONTEXT_FORWARD_COMPATIBLE_FLAG = 2;
  static const int SDL_GL_CONTEXT_ROBUST_ACCESS_FLAG = 4;
  static const int SDL_GL_CONTEXT_RESET_ISOLATION_FLAG = 8;
}

abstract class SDL_GLcontextReleaseFlag {
  static const int SDL_GL_CONTEXT_RELEASE_BEHAVIOR_NONE = 0;
  static const int SDL_GL_CONTEXT_RELEASE_BEHAVIOR_FLUSH = 1;
}

abstract class SDL_GLContextResetNotification {
  static const int SDL_GL_CONTEXT_RESET_NO_NOTIFICATION = 0;
  static const int SDL_GL_CONTEXT_RESET_LOSE_CONTEXT = 1;
}

/// Possible return values from the SDL_HitTest callback.
///
/// \sa SDL_HitTest
abstract class SDL_HitTestResult {
  /// < Region is normal. No special properties.
  static const int SDL_HITTEST_NORMAL = 0;

  /// < Region can drag entire window.
  static const int SDL_HITTEST_DRAGGABLE = 1;
  static const int SDL_HITTEST_RESIZE_TOPLEFT = 2;
  static const int SDL_HITTEST_RESIZE_TOP = 3;
  static const int SDL_HITTEST_RESIZE_TOPRIGHT = 4;
  static const int SDL_HITTEST_RESIZE_RIGHT = 5;
  static const int SDL_HITTEST_RESIZE_BOTTOMRIGHT = 6;
  static const int SDL_HITTEST_RESIZE_BOTTOM = 7;
  static const int SDL_HITTEST_RESIZE_BOTTOMLEFT = 8;
  static const int SDL_HITTEST_RESIZE_LEFT = 9;
}

/// Callback used for hit-testing.
///
/// \param win the SDL_Window where hit-testing was set on
/// \param area an SDL_Point which should be hit-tested
/// \param data what was passed as `callback_data` to SDL_SetWindowHitTest()
/// \return an SDL_HitTestResult value.
///
/// \sa SDL_SetWindowHitTest
typedef SDL_HitTest = ffi.Pointer<
    ffi.NativeFunction<
        ffi.Int32 Function(ffi.Pointer<SDL_Window>, ffi.Pointer<SDL_Point>,
            ffi.Pointer<ffi.Void>)>>;

/// \brief An opaque handle to an OpenGL context.
typedef SDL_GLContext = ffi.Pointer<ffi.Void>;

/// \brief The SDL keyboard scancode representation.
///
/// Values of this type are used to represent keyboard keys, among other places
/// in the \link SDL_Keysym::scancode key.keysym.scancode \endlink field of the
/// SDL_Event structure.
///
/// The values in this enumeration are based on the USB usage page standard:
/// https://www.usb.org/sites/default/files/documents/hut1_12v2.pdf
abstract class SDL_Scancode {
  static const int SDL_SCANCODE_UNKNOWN = 0;
  static const int SDL_SCANCODE_A = 4;
  static const int SDL_SCANCODE_B = 5;
  static const int SDL_SCANCODE_C = 6;
  static const int SDL_SCANCODE_D = 7;
  static const int SDL_SCANCODE_E = 8;
  static const int SDL_SCANCODE_F = 9;
  static const int SDL_SCANCODE_G = 10;
  static const int SDL_SCANCODE_H = 11;
  static const int SDL_SCANCODE_I = 12;
  static const int SDL_SCANCODE_J = 13;
  static const int SDL_SCANCODE_K = 14;
  static const int SDL_SCANCODE_L = 15;
  static const int SDL_SCANCODE_M = 16;
  static const int SDL_SCANCODE_N = 17;
  static const int SDL_SCANCODE_O = 18;
  static const int SDL_SCANCODE_P = 19;
  static const int SDL_SCANCODE_Q = 20;
  static const int SDL_SCANCODE_R = 21;
  static const int SDL_SCANCODE_S = 22;
  static const int SDL_SCANCODE_T = 23;
  static const int SDL_SCANCODE_U = 24;
  static const int SDL_SCANCODE_V = 25;
  static const int SDL_SCANCODE_W = 26;
  static const int SDL_SCANCODE_X = 27;
  static const int SDL_SCANCODE_Y = 28;
  static const int SDL_SCANCODE_Z = 29;
  static const int SDL_SCANCODE_1 = 30;
  static const int SDL_SCANCODE_2 = 31;
  static const int SDL_SCANCODE_3 = 32;
  static const int SDL_SCANCODE_4 = 33;
  static const int SDL_SCANCODE_5 = 34;
  static const int SDL_SCANCODE_6 = 35;
  static const int SDL_SCANCODE_7 = 36;
  static const int SDL_SCANCODE_8 = 37;
  static const int SDL_SCANCODE_9 = 38;
  static const int SDL_SCANCODE_0 = 39;
  static const int SDL_SCANCODE_RETURN = 40;
  static const int SDL_SCANCODE_ESCAPE = 41;
  static const int SDL_SCANCODE_BACKSPACE = 42;
  static const int SDL_SCANCODE_TAB = 43;
  static const int SDL_SCANCODE_SPACE = 44;
  static const int SDL_SCANCODE_MINUS = 45;
  static const int SDL_SCANCODE_EQUALS = 46;
  static const int SDL_SCANCODE_LEFTBRACKET = 47;
  static const int SDL_SCANCODE_RIGHTBRACKET = 48;

  /// < Located at the lower left of the return
  /// key on ISO keyboards and at the right end
  /// of the QWERTY row on ANSI keyboards.
  /// Produces REVERSE SOLIDUS (backslash) and
  /// VERTICAL LINE in a US layout, REVERSE
  /// SOLIDUS and VERTICAL LINE in a UK Mac
  /// layout, NUMBER SIGN and TILDE in a UK
  /// Windows layout, DOLLAR SIGN and POUND SIGN
  /// in a Swiss German layout, NUMBER SIGN and
  /// APOSTROPHE in a German layout, GRAVE
  /// ACCENT and POUND SIGN in a French Mac
  /// layout, and ASTERISK and MICRO SIGN in a
  /// French Windows layout.
  static const int SDL_SCANCODE_BACKSLASH = 49;

  /// < ISO USB keyboards actually use this code
  /// instead of 49 for the same key, but all
  /// OSes I've seen treat the two codes
  /// identically. So, as an implementor, unless
  /// your keyboard generates both of those
  /// codes and your OS treats them differently,
  /// you should generate SDL_SCANCODE_BACKSLASH
  /// instead of this code. As a user, you
  /// should not rely on this code because SDL
  /// will never generate it with most (all?)
  /// keyboards.
  static const int SDL_SCANCODE_NONUSHASH = 50;
  static const int SDL_SCANCODE_SEMICOLON = 51;
  static const int SDL_SCANCODE_APOSTROPHE = 52;

  /// < Located in the top left corner (on both ANSI
  /// and ISO keyboards). Produces GRAVE ACCENT and
  /// TILDE in a US Windows layout and in US and UK
  /// Mac layouts on ANSI keyboards, GRAVE ACCENT
  /// and NOT SIGN in a UK Windows layout, SECTION
  /// SIGN and PLUS-MINUS SIGN in US and UK Mac
  /// layouts on ISO keyboards, SECTION SIGN and
  /// DEGREE SIGN in a Swiss German layout (Mac:
  /// only on ISO keyboards), CIRCUMFLEX ACCENT and
  /// DEGREE SIGN in a German layout (Mac: only on
  /// ISO keyboards), SUPERSCRIPT TWO and TILDE in a
  /// French Windows layout, COMMERCIAL AT and
  /// NUMBER SIGN in a French Mac layout on ISO
  /// keyboards, and LESS-THAN SIGN and GREATER-THAN
  /// SIGN in a Swiss German, German, or French Mac
  /// layout on ANSI keyboards.
  static const int SDL_SCANCODE_GRAVE = 53;
  static const int SDL_SCANCODE_COMMA = 54;
  static const int SDL_SCANCODE_PERIOD = 55;
  static const int SDL_SCANCODE_SLASH = 56;
  static const int SDL_SCANCODE_CAPSLOCK = 57;
  static const int SDL_SCANCODE_F1 = 58;
  static const int SDL_SCANCODE_F2 = 59;
  static const int SDL_SCANCODE_F3 = 60;
  static const int SDL_SCANCODE_F4 = 61;
  static const int SDL_SCANCODE_F5 = 62;
  static const int SDL_SCANCODE_F6 = 63;
  static const int SDL_SCANCODE_F7 = 64;
  static const int SDL_SCANCODE_F8 = 65;
  static const int SDL_SCANCODE_F9 = 66;
  static const int SDL_SCANCODE_F10 = 67;
  static const int SDL_SCANCODE_F11 = 68;
  static const int SDL_SCANCODE_F12 = 69;
  static const int SDL_SCANCODE_PRINTSCREEN = 70;
  static const int SDL_SCANCODE_SCROLLLOCK = 71;
  static const int SDL_SCANCODE_PAUSE = 72;

  /// < insert on PC, help on some Mac keyboards (but
  /// does send code 73, not 117)
  static const int SDL_SCANCODE_INSERT = 73;
  static const int SDL_SCANCODE_HOME = 74;
  static const int SDL_SCANCODE_PAGEUP = 75;
  static const int SDL_SCANCODE_DELETE = 76;
  static const int SDL_SCANCODE_END = 77;
  static const int SDL_SCANCODE_PAGEDOWN = 78;
  static const int SDL_SCANCODE_RIGHT = 79;
  static const int SDL_SCANCODE_LEFT = 80;
  static const int SDL_SCANCODE_DOWN = 81;
  static const int SDL_SCANCODE_UP = 82;

  /// < num lock on PC, clear on Mac keyboards
  static const int SDL_SCANCODE_NUMLOCKCLEAR = 83;
  static const int SDL_SCANCODE_KP_DIVIDE = 84;
  static const int SDL_SCANCODE_KP_MULTIPLY = 85;
  static const int SDL_SCANCODE_KP_MINUS = 86;
  static const int SDL_SCANCODE_KP_PLUS = 87;
  static const int SDL_SCANCODE_KP_ENTER = 88;
  static const int SDL_SCANCODE_KP_1 = 89;
  static const int SDL_SCANCODE_KP_2 = 90;
  static const int SDL_SCANCODE_KP_3 = 91;
  static const int SDL_SCANCODE_KP_4 = 92;
  static const int SDL_SCANCODE_KP_5 = 93;
  static const int SDL_SCANCODE_KP_6 = 94;
  static const int SDL_SCANCODE_KP_7 = 95;
  static const int SDL_SCANCODE_KP_8 = 96;
  static const int SDL_SCANCODE_KP_9 = 97;
  static const int SDL_SCANCODE_KP_0 = 98;
  static const int SDL_SCANCODE_KP_PERIOD = 99;

  /// < This is the additional key that ISO
  /// keyboards have over ANSI ones,
  /// located between left shift and Y.
  /// Produces GRAVE ACCENT and TILDE in a
  /// US or UK Mac layout, REVERSE SOLIDUS
  /// (backslash) and VERTICAL LINE in a
  /// US or UK Windows layout, and
  /// LESS-THAN SIGN and GREATER-THAN SIGN
  /// in a Swiss German, German, or French
  /// layout.
  static const int SDL_SCANCODE_NONUSBACKSLASH = 100;

  /// < windows contextual menu, compose
  static const int SDL_SCANCODE_APPLICATION = 101;

  /// < The USB document says this is a status flag,
  /// not a physical key - but some Mac keyboards
  /// do have a power key.
  static const int SDL_SCANCODE_POWER = 102;
  static const int SDL_SCANCODE_KP_EQUALS = 103;
  static const int SDL_SCANCODE_F13 = 104;
  static const int SDL_SCANCODE_F14 = 105;
  static const int SDL_SCANCODE_F15 = 106;
  static const int SDL_SCANCODE_F16 = 107;
  static const int SDL_SCANCODE_F17 = 108;
  static const int SDL_SCANCODE_F18 = 109;
  static const int SDL_SCANCODE_F19 = 110;
  static const int SDL_SCANCODE_F20 = 111;
  static const int SDL_SCANCODE_F21 = 112;
  static const int SDL_SCANCODE_F22 = 113;
  static const int SDL_SCANCODE_F23 = 114;
  static const int SDL_SCANCODE_F24 = 115;
  static const int SDL_SCANCODE_EXECUTE = 116;
  static const int SDL_SCANCODE_HELP = 117;
  static const int SDL_SCANCODE_MENU = 118;
  static const int SDL_SCANCODE_SELECT = 119;
  static const int SDL_SCANCODE_STOP = 120;

  /// < redo
  static const int SDL_SCANCODE_AGAIN = 121;
  static const int SDL_SCANCODE_UNDO = 122;
  static const int SDL_SCANCODE_CUT = 123;
  static const int SDL_SCANCODE_COPY = 124;
  static const int SDL_SCANCODE_PASTE = 125;
  static const int SDL_SCANCODE_FIND = 126;
  static const int SDL_SCANCODE_MUTE = 127;
  static const int SDL_SCANCODE_VOLUMEUP = 128;
  static const int SDL_SCANCODE_VOLUMEDOWN = 129;
  static const int SDL_SCANCODE_KP_COMMA = 133;
  static const int SDL_SCANCODE_KP_EQUALSAS400 = 134;

  /// < used on Asian keyboards, see
  /// footnotes in USB doc
  static const int SDL_SCANCODE_INTERNATIONAL1 = 135;
  static const int SDL_SCANCODE_INTERNATIONAL2 = 136;

  /// < Yen
  static const int SDL_SCANCODE_INTERNATIONAL3 = 137;
  static const int SDL_SCANCODE_INTERNATIONAL4 = 138;
  static const int SDL_SCANCODE_INTERNATIONAL5 = 139;
  static const int SDL_SCANCODE_INTERNATIONAL6 = 140;
  static const int SDL_SCANCODE_INTERNATIONAL7 = 141;
  static const int SDL_SCANCODE_INTERNATIONAL8 = 142;
  static const int SDL_SCANCODE_INTERNATIONAL9 = 143;

  /// < Hangul/English toggle
  static const int SDL_SCANCODE_LANG1 = 144;

  /// < Hanja conversion
  static const int SDL_SCANCODE_LANG2 = 145;

  /// < Katakana
  static const int SDL_SCANCODE_LANG3 = 146;

  /// < Hiragana
  static const int SDL_SCANCODE_LANG4 = 147;

  /// < Zenkaku/Hankaku
  static const int SDL_SCANCODE_LANG5 = 148;

  /// < reserved
  static const int SDL_SCANCODE_LANG6 = 149;

  /// < reserved
  static const int SDL_SCANCODE_LANG7 = 150;

  /// < reserved
  static const int SDL_SCANCODE_LANG8 = 151;

  /// < reserved
  static const int SDL_SCANCODE_LANG9 = 152;

  /// < Erase-Eaze
  static const int SDL_SCANCODE_ALTERASE = 153;
  static const int SDL_SCANCODE_SYSREQ = 154;
  static const int SDL_SCANCODE_CANCEL = 155;
  static const int SDL_SCANCODE_CLEAR = 156;
  static const int SDL_SCANCODE_PRIOR = 157;
  static const int SDL_SCANCODE_RETURN2 = 158;
  static const int SDL_SCANCODE_SEPARATOR = 159;
  static const int SDL_SCANCODE_OUT = 160;
  static const int SDL_SCANCODE_OPER = 161;
  static const int SDL_SCANCODE_CLEARAGAIN = 162;
  static const int SDL_SCANCODE_CRSEL = 163;
  static const int SDL_SCANCODE_EXSEL = 164;
  static const int SDL_SCANCODE_KP_00 = 176;
  static const int SDL_SCANCODE_KP_000 = 177;
  static const int SDL_SCANCODE_THOUSANDSSEPARATOR = 178;
  static const int SDL_SCANCODE_DECIMALSEPARATOR = 179;
  static const int SDL_SCANCODE_CURRENCYUNIT = 180;
  static const int SDL_SCANCODE_CURRENCYSUBUNIT = 181;
  static const int SDL_SCANCODE_KP_LEFTPAREN = 182;
  static const int SDL_SCANCODE_KP_RIGHTPAREN = 183;
  static const int SDL_SCANCODE_KP_LEFTBRACE = 184;
  static const int SDL_SCANCODE_KP_RIGHTBRACE = 185;
  static const int SDL_SCANCODE_KP_TAB = 186;
  static const int SDL_SCANCODE_KP_BACKSPACE = 187;
  static const int SDL_SCANCODE_KP_A = 188;
  static const int SDL_SCANCODE_KP_B = 189;
  static const int SDL_SCANCODE_KP_C = 190;
  static const int SDL_SCANCODE_KP_D = 191;
  static const int SDL_SCANCODE_KP_E = 192;
  static const int SDL_SCANCODE_KP_F = 193;
  static const int SDL_SCANCODE_KP_XOR = 194;
  static const int SDL_SCANCODE_KP_POWER = 195;
  static const int SDL_SCANCODE_KP_PERCENT = 196;
  static const int SDL_SCANCODE_KP_LESS = 197;
  static const int SDL_SCANCODE_KP_GREATER = 198;
  static const int SDL_SCANCODE_KP_AMPERSAND = 199;
  static const int SDL_SCANCODE_KP_DBLAMPERSAND = 200;
  static const int SDL_SCANCODE_KP_VERTICALBAR = 201;
  static const int SDL_SCANCODE_KP_DBLVERTICALBAR = 202;
  static const int SDL_SCANCODE_KP_COLON = 203;
  static const int SDL_SCANCODE_KP_HASH = 204;
  static const int SDL_SCANCODE_KP_SPACE = 205;
  static const int SDL_SCANCODE_KP_AT = 206;
  static const int SDL_SCANCODE_KP_EXCLAM = 207;
  static const int SDL_SCANCODE_KP_MEMSTORE = 208;
  static const int SDL_SCANCODE_KP_MEMRECALL = 209;
  static const int SDL_SCANCODE_KP_MEMCLEAR = 210;
  static const int SDL_SCANCODE_KP_MEMADD = 211;
  static const int SDL_SCANCODE_KP_MEMSUBTRACT = 212;
  static const int SDL_SCANCODE_KP_MEMMULTIPLY = 213;
  static const int SDL_SCANCODE_KP_MEMDIVIDE = 214;
  static const int SDL_SCANCODE_KP_PLUSMINUS = 215;
  static const int SDL_SCANCODE_KP_CLEAR = 216;
  static const int SDL_SCANCODE_KP_CLEARENTRY = 217;
  static const int SDL_SCANCODE_KP_BINARY = 218;
  static const int SDL_SCANCODE_KP_OCTAL = 219;
  static const int SDL_SCANCODE_KP_DECIMAL = 220;
  static const int SDL_SCANCODE_KP_HEXADECIMAL = 221;
  static const int SDL_SCANCODE_LCTRL = 224;
  static const int SDL_SCANCODE_LSHIFT = 225;

  /// < alt, option
  static const int SDL_SCANCODE_LALT = 226;

  /// < windows, command (apple), meta
  static const int SDL_SCANCODE_LGUI = 227;
  static const int SDL_SCANCODE_RCTRL = 228;
  static const int SDL_SCANCODE_RSHIFT = 229;

  /// < alt gr, option
  static const int SDL_SCANCODE_RALT = 230;

  /// < windows, command (apple), meta
  static const int SDL_SCANCODE_RGUI = 231;

  /// < I'm not sure if this is really not covered
  /// by any of the above, but since there's a
  /// special KMOD_MODE for it I'm adding it here
  static const int SDL_SCANCODE_MODE = 257;
  static const int SDL_SCANCODE_AUDIONEXT = 258;
  static const int SDL_SCANCODE_AUDIOPREV = 259;
  static const int SDL_SCANCODE_AUDIOSTOP = 260;
  static const int SDL_SCANCODE_AUDIOPLAY = 261;
  static const int SDL_SCANCODE_AUDIOMUTE = 262;
  static const int SDL_SCANCODE_MEDIASELECT = 263;
  static const int SDL_SCANCODE_WWW = 264;
  static const int SDL_SCANCODE_MAIL = 265;
  static const int SDL_SCANCODE_CALCULATOR = 266;
  static const int SDL_SCANCODE_COMPUTER = 267;
  static const int SDL_SCANCODE_AC_SEARCH = 268;
  static const int SDL_SCANCODE_AC_HOME = 269;
  static const int SDL_SCANCODE_AC_BACK = 270;
  static const int SDL_SCANCODE_AC_FORWARD = 271;
  static const int SDL_SCANCODE_AC_STOP = 272;
  static const int SDL_SCANCODE_AC_REFRESH = 273;
  static const int SDL_SCANCODE_AC_BOOKMARKS = 274;
  static const int SDL_SCANCODE_BRIGHTNESSDOWN = 275;
  static const int SDL_SCANCODE_BRIGHTNESSUP = 276;

  /// < display mirroring/dual display
  /// switch, video mode switch
  static const int SDL_SCANCODE_DISPLAYSWITCH = 277;
  static const int SDL_SCANCODE_KBDILLUMTOGGLE = 278;
  static const int SDL_SCANCODE_KBDILLUMDOWN = 279;
  static const int SDL_SCANCODE_KBDILLUMUP = 280;
  static const int SDL_SCANCODE_EJECT = 281;
  static const int SDL_SCANCODE_SLEEP = 282;
  static const int SDL_SCANCODE_APP1 = 283;
  static const int SDL_SCANCODE_APP2 = 284;
  static const int SDL_SCANCODE_AUDIOREWIND = 285;
  static const int SDL_SCANCODE_AUDIOFASTFORWARD = 286;

  /// < not a key, just marks the number of scancodes
  /// for array bounds
  static const int SDL_NUM_SCANCODES = 512;
}

abstract class SDL_KeyCode {
  static const int SDLK_UNKNOWN = 0;
  static const int SDLK_RETURN = 13;
  static const int SDLK_ESCAPE = 27;
  static const int SDLK_BACKSPACE = 8;
  static const int SDLK_TAB = 9;
  static const int SDLK_SPACE = 32;
  static const int SDLK_EXCLAIM = 33;
  static const int SDLK_QUOTEDBL = 34;
  static const int SDLK_HASH = 35;
  static const int SDLK_PERCENT = 37;
  static const int SDLK_DOLLAR = 36;
  static const int SDLK_AMPERSAND = 38;
  static const int SDLK_QUOTE = 39;
  static const int SDLK_LEFTPAREN = 40;
  static const int SDLK_RIGHTPAREN = 41;
  static const int SDLK_ASTERISK = 42;
  static const int SDLK_PLUS = 43;
  static const int SDLK_COMMA = 44;
  static const int SDLK_MINUS = 45;
  static const int SDLK_PERIOD = 46;
  static const int SDLK_SLASH = 47;
  static const int SDLK_0 = 48;
  static const int SDLK_1 = 49;
  static const int SDLK_2 = 50;
  static const int SDLK_3 = 51;
  static const int SDLK_4 = 52;
  static const int SDLK_5 = 53;
  static const int SDLK_6 = 54;
  static const int SDLK_7 = 55;
  static const int SDLK_8 = 56;
  static const int SDLK_9 = 57;
  static const int SDLK_COLON = 58;
  static const int SDLK_SEMICOLON = 59;
  static const int SDLK_LESS = 60;
  static const int SDLK_EQUALS = 61;
  static const int SDLK_GREATER = 62;
  static const int SDLK_QUESTION = 63;
  static const int SDLK_AT = 64;
  static const int SDLK_LEFTBRACKET = 91;
  static const int SDLK_BACKSLASH = 92;
  static const int SDLK_RIGHTBRACKET = 93;
  static const int SDLK_CARET = 94;
  static const int SDLK_UNDERSCORE = 95;
  static const int SDLK_BACKQUOTE = 96;
  static const int SDLK_a = 97;
  static const int SDLK_b = 98;
  static const int SDLK_c = 99;
  static const int SDLK_d = 100;
  static const int SDLK_e = 101;
  static const int SDLK_f = 102;
  static const int SDLK_g = 103;
  static const int SDLK_h = 104;
  static const int SDLK_i = 105;
  static const int SDLK_j = 106;
  static const int SDLK_k = 107;
  static const int SDLK_l = 108;
  static const int SDLK_m = 109;
  static const int SDLK_n = 110;
  static const int SDLK_o = 111;
  static const int SDLK_p = 112;
  static const int SDLK_q = 113;
  static const int SDLK_r = 114;
  static const int SDLK_s = 115;
  static const int SDLK_t = 116;
  static const int SDLK_u = 117;
  static const int SDLK_v = 118;
  static const int SDLK_w = 119;
  static const int SDLK_x = 120;
  static const int SDLK_y = 121;
  static const int SDLK_z = 122;
  static const int SDLK_CAPSLOCK = 1073741881;
  static const int SDLK_F1 = 1073741882;
  static const int SDLK_F2 = 1073741883;
  static const int SDLK_F3 = 1073741884;
  static const int SDLK_F4 = 1073741885;
  static const int SDLK_F5 = 1073741886;
  static const int SDLK_F6 = 1073741887;
  static const int SDLK_F7 = 1073741888;
  static const int SDLK_F8 = 1073741889;
  static const int SDLK_F9 = 1073741890;
  static const int SDLK_F10 = 1073741891;
  static const int SDLK_F11 = 1073741892;
  static const int SDLK_F12 = 1073741893;
  static const int SDLK_PRINTSCREEN = 1073741894;
  static const int SDLK_SCROLLLOCK = 1073741895;
  static const int SDLK_PAUSE = 1073741896;
  static const int SDLK_INSERT = 1073741897;
  static const int SDLK_HOME = 1073741898;
  static const int SDLK_PAGEUP = 1073741899;
  static const int SDLK_DELETE = 127;
  static const int SDLK_END = 1073741901;
  static const int SDLK_PAGEDOWN = 1073741902;
  static const int SDLK_RIGHT = 1073741903;
  static const int SDLK_LEFT = 1073741904;
  static const int SDLK_DOWN = 1073741905;
  static const int SDLK_UP = 1073741906;
  static const int SDLK_NUMLOCKCLEAR = 1073741907;
  static const int SDLK_KP_DIVIDE = 1073741908;
  static const int SDLK_KP_MULTIPLY = 1073741909;
  static const int SDLK_KP_MINUS = 1073741910;
  static const int SDLK_KP_PLUS = 1073741911;
  static const int SDLK_KP_ENTER = 1073741912;
  static const int SDLK_KP_1 = 1073741913;
  static const int SDLK_KP_2 = 1073741914;
  static const int SDLK_KP_3 = 1073741915;
  static const int SDLK_KP_4 = 1073741916;
  static const int SDLK_KP_5 = 1073741917;
  static const int SDLK_KP_6 = 1073741918;
  static const int SDLK_KP_7 = 1073741919;
  static const int SDLK_KP_8 = 1073741920;
  static const int SDLK_KP_9 = 1073741921;
  static const int SDLK_KP_0 = 1073741922;
  static const int SDLK_KP_PERIOD = 1073741923;
  static const int SDLK_APPLICATION = 1073741925;
  static const int SDLK_POWER = 1073741926;
  static const int SDLK_KP_EQUALS = 1073741927;
  static const int SDLK_F13 = 1073741928;
  static const int SDLK_F14 = 1073741929;
  static const int SDLK_F15 = 1073741930;
  static const int SDLK_F16 = 1073741931;
  static const int SDLK_F17 = 1073741932;
  static const int SDLK_F18 = 1073741933;
  static const int SDLK_F19 = 1073741934;
  static const int SDLK_F20 = 1073741935;
  static const int SDLK_F21 = 1073741936;
  static const int SDLK_F22 = 1073741937;
  static const int SDLK_F23 = 1073741938;
  static const int SDLK_F24 = 1073741939;
  static const int SDLK_EXECUTE = 1073741940;
  static const int SDLK_HELP = 1073741941;
  static const int SDLK_MENU = 1073741942;
  static const int SDLK_SELECT = 1073741943;
  static const int SDLK_STOP = 1073741944;
  static const int SDLK_AGAIN = 1073741945;
  static const int SDLK_UNDO = 1073741946;
  static const int SDLK_CUT = 1073741947;
  static const int SDLK_COPY = 1073741948;
  static const int SDLK_PASTE = 1073741949;
  static const int SDLK_FIND = 1073741950;
  static const int SDLK_MUTE = 1073741951;
  static const int SDLK_VOLUMEUP = 1073741952;
  static const int SDLK_VOLUMEDOWN = 1073741953;
  static const int SDLK_KP_COMMA = 1073741957;
  static const int SDLK_KP_EQUALSAS400 = 1073741958;
  static const int SDLK_ALTERASE = 1073741977;
  static const int SDLK_SYSREQ = 1073741978;
  static const int SDLK_CANCEL = 1073741979;
  static const int SDLK_CLEAR = 1073741980;
  static const int SDLK_PRIOR = 1073741981;
  static const int SDLK_RETURN2 = 1073741982;
  static const int SDLK_SEPARATOR = 1073741983;
  static const int SDLK_OUT = 1073741984;
  static const int SDLK_OPER = 1073741985;
  static const int SDLK_CLEARAGAIN = 1073741986;
  static const int SDLK_CRSEL = 1073741987;
  static const int SDLK_EXSEL = 1073741988;
  static const int SDLK_KP_00 = 1073742000;
  static const int SDLK_KP_000 = 1073742001;
  static const int SDLK_THOUSANDSSEPARATOR = 1073742002;
  static const int SDLK_DECIMALSEPARATOR = 1073742003;
  static const int SDLK_CURRENCYUNIT = 1073742004;
  static const int SDLK_CURRENCYSUBUNIT = 1073742005;
  static const int SDLK_KP_LEFTPAREN = 1073742006;
  static const int SDLK_KP_RIGHTPAREN = 1073742007;
  static const int SDLK_KP_LEFTBRACE = 1073742008;
  static const int SDLK_KP_RIGHTBRACE = 1073742009;
  static const int SDLK_KP_TAB = 1073742010;
  static const int SDLK_KP_BACKSPACE = 1073742011;
  static const int SDLK_KP_A = 1073742012;
  static const int SDLK_KP_B = 1073742013;
  static const int SDLK_KP_C = 1073742014;
  static const int SDLK_KP_D = 1073742015;
  static const int SDLK_KP_E = 1073742016;
  static const int SDLK_KP_F = 1073742017;
  static const int SDLK_KP_XOR = 1073742018;
  static const int SDLK_KP_POWER = 1073742019;
  static const int SDLK_KP_PERCENT = 1073742020;
  static const int SDLK_KP_LESS = 1073742021;
  static const int SDLK_KP_GREATER = 1073742022;
  static const int SDLK_KP_AMPERSAND = 1073742023;
  static const int SDLK_KP_DBLAMPERSAND = 1073742024;
  static const int SDLK_KP_VERTICALBAR = 1073742025;
  static const int SDLK_KP_DBLVERTICALBAR = 1073742026;
  static const int SDLK_KP_COLON = 1073742027;
  static const int SDLK_KP_HASH = 1073742028;
  static const int SDLK_KP_SPACE = 1073742029;
  static const int SDLK_KP_AT = 1073742030;
  static const int SDLK_KP_EXCLAM = 1073742031;
  static const int SDLK_KP_MEMSTORE = 1073742032;
  static const int SDLK_KP_MEMRECALL = 1073742033;
  static const int SDLK_KP_MEMCLEAR = 1073742034;
  static const int SDLK_KP_MEMADD = 1073742035;
  static const int SDLK_KP_MEMSUBTRACT = 1073742036;
  static const int SDLK_KP_MEMMULTIPLY = 1073742037;
  static const int SDLK_KP_MEMDIVIDE = 1073742038;
  static const int SDLK_KP_PLUSMINUS = 1073742039;
  static const int SDLK_KP_CLEAR = 1073742040;
  static const int SDLK_KP_CLEARENTRY = 1073742041;
  static const int SDLK_KP_BINARY = 1073742042;
  static const int SDLK_KP_OCTAL = 1073742043;
  static const int SDLK_KP_DECIMAL = 1073742044;
  static const int SDLK_KP_HEXADECIMAL = 1073742045;
  static const int SDLK_LCTRL = 1073742048;
  static const int SDLK_LSHIFT = 1073742049;
  static const int SDLK_LALT = 1073742050;
  static const int SDLK_LGUI = 1073742051;
  static const int SDLK_RCTRL = 1073742052;
  static const int SDLK_RSHIFT = 1073742053;
  static const int SDLK_RALT = 1073742054;
  static const int SDLK_RGUI = 1073742055;
  static const int SDLK_MODE = 1073742081;
  static const int SDLK_AUDIONEXT = 1073742082;
  static const int SDLK_AUDIOPREV = 1073742083;
  static const int SDLK_AUDIOSTOP = 1073742084;
  static const int SDLK_AUDIOPLAY = 1073742085;
  static const int SDLK_AUDIOMUTE = 1073742086;
  static const int SDLK_MEDIASELECT = 1073742087;
  static const int SDLK_WWW = 1073742088;
  static const int SDLK_MAIL = 1073742089;
  static const int SDLK_CALCULATOR = 1073742090;
  static const int SDLK_COMPUTER = 1073742091;
  static const int SDLK_AC_SEARCH = 1073742092;
  static const int SDLK_AC_HOME = 1073742093;
  static const int SDLK_AC_BACK = 1073742094;
  static const int SDLK_AC_FORWARD = 1073742095;
  static const int SDLK_AC_STOP = 1073742096;
  static const int SDLK_AC_REFRESH = 1073742097;
  static const int SDLK_AC_BOOKMARKS = 1073742098;
  static const int SDLK_BRIGHTNESSDOWN = 1073742099;
  static const int SDLK_BRIGHTNESSUP = 1073742100;
  static const int SDLK_DISPLAYSWITCH = 1073742101;
  static const int SDLK_KBDILLUMTOGGLE = 1073742102;
  static const int SDLK_KBDILLUMDOWN = 1073742103;
  static const int SDLK_KBDILLUMUP = 1073742104;
  static const int SDLK_EJECT = 1073742105;
  static const int SDLK_SLEEP = 1073742106;
  static const int SDLK_APP1 = 1073742107;
  static const int SDLK_APP2 = 1073742108;
  static const int SDLK_AUDIOREWIND = 1073742109;
  static const int SDLK_AUDIOFASTFORWARD = 1073742110;
}

/// \brief Enumeration of valid key mods (possibly OR'd together).
abstract class SDL_Keymod {
  static const int KMOD_NONE = 0;
  static const int KMOD_LSHIFT = 1;
  static const int KMOD_RSHIFT = 2;
  static const int KMOD_LCTRL = 64;
  static const int KMOD_RCTRL = 128;
  static const int KMOD_LALT = 256;
  static const int KMOD_RALT = 512;
  static const int KMOD_LGUI = 1024;
  static const int KMOD_RGUI = 2048;
  static const int KMOD_NUM = 4096;
  static const int KMOD_CAPS = 8192;
  static const int KMOD_MODE = 16384;
  static const int KMOD_SCROLL = 32768;
  static const int KMOD_CTRL = 192;
  static const int KMOD_SHIFT = 3;
  static const int KMOD_ALT = 768;
  static const int KMOD_GUI = 3072;
  static const int KMOD_RESERVED = 32768;
}

/// \brief The SDL keysym structure, used in key events.
///
/// \note  If you are looking for translated character input, see the ::SDL_TEXTINPUT event.
class SDL_Keysym extends ffi.Struct {
  /// < SDL physical key code - see ::SDL_Scancode for details
  @ffi.Int32()
  external int scancode;

  /// < SDL virtual key code - see ::SDL_Keycode for details
  @SDL_Keycode()
  external int sym;

  /// < current key modifiers
  @Uint16()
  external int mod;

  @Uint32()
  external int unused;
}

/// \brief The SDL virtual key representation.
///
/// Values of this type are used to represent keyboard keys using the current
/// layout of the keyboard.  These values include Unicode values representing
/// the unmodified character that would be generated by pressing the key, or
/// an SDLK_* constant for those keys that do not generate characters.
///
/// A special exception is the number keys at the top of the keyboard which
/// always map to SDLK_0...SDLK_9, regardless of layout.
typedef SDL_Keycode = Sint32;
typedef Sint32 = ffi.Int32;

class SDL_Cursor extends ffi.Opaque {}

/// \brief Cursor types for SDL_CreateSystemCursor().
abstract class SDL_SystemCursor {
  /// < Arrow
  static const int SDL_SYSTEM_CURSOR_ARROW = 0;

  /// < I-beam
  static const int SDL_SYSTEM_CURSOR_IBEAM = 1;

  /// < Wait
  static const int SDL_SYSTEM_CURSOR_WAIT = 2;

  /// < Crosshair
  static const int SDL_SYSTEM_CURSOR_CROSSHAIR = 3;

  /// < Small wait cursor (or Wait if not available)
  static const int SDL_SYSTEM_CURSOR_WAITARROW = 4;

  /// < Double arrow pointing northwest and southeast
  static const int SDL_SYSTEM_CURSOR_SIZENWSE = 5;

  /// < Double arrow pointing northeast and southwest
  static const int SDL_SYSTEM_CURSOR_SIZENESW = 6;

  /// < Double arrow pointing west and east
  static const int SDL_SYSTEM_CURSOR_SIZEWE = 7;

  /// < Double arrow pointing north and south
  static const int SDL_SYSTEM_CURSOR_SIZENS = 8;

  /// < Four pointed arrow pointing north, south, east, and west
  static const int SDL_SYSTEM_CURSOR_SIZEALL = 9;

  /// < Slashed circle or crossbones
  static const int SDL_SYSTEM_CURSOR_NO = 10;

  /// < Hand
  static const int SDL_SYSTEM_CURSOR_HAND = 11;
  static const int SDL_NUM_SYSTEM_CURSORS = 12;
}

/// \brief Scroll direction types for the Scroll event
abstract class SDL_MouseWheelDirection {
  /// < The scroll direction is normal
  static const int SDL_MOUSEWHEEL_NORMAL = 0;

  /// < The scroll direction is flipped / natural
  static const int SDL_MOUSEWHEEL_FLIPPED = 1;
}

/// The joystick structure used to identify an SDL joystick
class SDL_Joystick extends ffi.Opaque {}

class SDL_JoystickGUID extends ffi.Struct {
  @ffi.Array.multi([16])
  external ffi.Array<Uint8> data;
}

abstract class SDL_JoystickType {
  static const int SDL_JOYSTICK_TYPE_UNKNOWN = 0;
  static const int SDL_JOYSTICK_TYPE_GAMECONTROLLER = 1;
  static const int SDL_JOYSTICK_TYPE_WHEEL = 2;
  static const int SDL_JOYSTICK_TYPE_ARCADE_STICK = 3;
  static const int SDL_JOYSTICK_TYPE_FLIGHT_STICK = 4;
  static const int SDL_JOYSTICK_TYPE_DANCE_PAD = 5;
  static const int SDL_JOYSTICK_TYPE_GUITAR = 6;
  static const int SDL_JOYSTICK_TYPE_DRUM_KIT = 7;
  static const int SDL_JOYSTICK_TYPE_ARCADE_PAD = 8;
  static const int SDL_JOYSTICK_TYPE_THROTTLE = 9;
}

abstract class SDL_JoystickPowerLevel {
  static const int SDL_JOYSTICK_POWER_UNKNOWN = -1;
  static const int SDL_JOYSTICK_POWER_EMPTY = 0;
  static const int SDL_JOYSTICK_POWER_LOW = 1;
  static const int SDL_JOYSTICK_POWER_MEDIUM = 2;
  static const int SDL_JOYSTICK_POWER_FULL = 3;
  static const int SDL_JOYSTICK_POWER_WIRED = 4;
  static const int SDL_JOYSTICK_POWER_MAX = 5;
}

/// This is a unique ID for a joystick for the time it is connected to the system,
/// and is never reused for the lifetime of the application. If the joystick is
/// disconnected and reconnected, it will get a new ID.
///
/// The ID value starts at 0 and increments from there. The value -1 is an invalid ID.
typedef SDL_JoystickID = Sint32;
typedef SDL_Joystick1 = SDL_Joystick;
typedef Sint16 = ffi.Int16;

/// \brief SDL_sensor.h
///
/// In order to use these functions, SDL_Init() must have been called
/// with the ::SDL_INIT_SENSOR flag.  This causes SDL to scan the system
/// for sensors, and load appropriate drivers.
class SDL_Sensor extends ffi.Opaque {}

abstract class SDL_SensorType {
  /// < Returned for an invalid sensor
  static const int SDL_SENSOR_INVALID = -1;

  /// < Unknown sensor type
  static const int SDL_SENSOR_UNKNOWN = 0;

  /// < Accelerometer
  static const int SDL_SENSOR_ACCEL = 1;

  /// < Gyroscope
  static const int SDL_SENSOR_GYRO = 2;
}

/// This is a unique ID for a sensor for the time it is connected to the system,
/// and is never reused for the lifetime of the application.
///
/// The ID value starts at 0 and increments from there. The value -1 is an invalid ID.
typedef SDL_SensorID = Sint32;
typedef SDL_Sensor1 = SDL_Sensor;

/// The gamecontroller structure used to identify an SDL game controller
class SDL_GameController extends ffi.Opaque {}

abstract class SDL_GameControllerType {
  static const int SDL_CONTROLLER_TYPE_UNKNOWN = 0;
  static const int SDL_CONTROLLER_TYPE_XBOX360 = 1;
  static const int SDL_CONTROLLER_TYPE_XBOXONE = 2;
  static const int SDL_CONTROLLER_TYPE_PS3 = 3;
  static const int SDL_CONTROLLER_TYPE_PS4 = 4;
  static const int SDL_CONTROLLER_TYPE_NINTENDO_SWITCH_PRO = 5;
  static const int SDL_CONTROLLER_TYPE_VIRTUAL = 6;
  static const int SDL_CONTROLLER_TYPE_PS5 = 7;
  static const int SDL_CONTROLLER_TYPE_AMAZON_LUNA = 8;
  static const int SDL_CONTROLLER_TYPE_GOOGLE_STADIA = 9;
}

abstract class SDL_GameControllerBindType {
  static const int SDL_CONTROLLER_BINDTYPE_NONE = 0;
  static const int SDL_CONTROLLER_BINDTYPE_BUTTON = 1;
  static const int SDL_CONTROLLER_BINDTYPE_AXIS = 2;
  static const int SDL_CONTROLLER_BINDTYPE_HAT = 3;
}

/// Get the SDL joystick layer binding for this controller button/axis mapping
class SDL_GameControllerButtonBind extends ffi.Struct {
  @ffi.Int32()
  external int bindType;

  external UnnamedUnion2 value;
}

class UnnamedUnion2 extends ffi.Union {
  @ffi.Int32()
  external int button;

  @ffi.Int32()
  external int axis;

  external UnnamedStruct5 hat;
}

class UnnamedStruct5 extends ffi.Struct {
  @ffi.Int32()
  external int hat;

  @ffi.Int32()
  external int hat_mask;
}

typedef SDL_GameController1 = SDL_GameController;

/// The list of axes available from a controller
///
/// Thumbstick axis values range from SDL_JOYSTICK_AXIS_MIN to SDL_JOYSTICK_AXIS_MAX,
/// and are centered within ~8000 of zero, though advanced UI will allow users to set
/// or autodetect the dead zone, which varies between controllers.
///
/// Trigger axis values range from 0 to SDL_JOYSTICK_AXIS_MAX.
abstract class SDL_GameControllerAxis {
  static const int SDL_CONTROLLER_AXIS_INVALID = -1;
  static const int SDL_CONTROLLER_AXIS_LEFTX = 0;
  static const int SDL_CONTROLLER_AXIS_LEFTY = 1;
  static const int SDL_CONTROLLER_AXIS_RIGHTX = 2;
  static const int SDL_CONTROLLER_AXIS_RIGHTY = 3;
  static const int SDL_CONTROLLER_AXIS_TRIGGERLEFT = 4;
  static const int SDL_CONTROLLER_AXIS_TRIGGERRIGHT = 5;
  static const int SDL_CONTROLLER_AXIS_MAX = 6;
}

/// The list of buttons available from a controller
abstract class SDL_GameControllerButton {
  static const int SDL_CONTROLLER_BUTTON_INVALID = -1;
  static const int SDL_CONTROLLER_BUTTON_A = 0;
  static const int SDL_CONTROLLER_BUTTON_B = 1;
  static const int SDL_CONTROLLER_BUTTON_X = 2;
  static const int SDL_CONTROLLER_BUTTON_Y = 3;
  static const int SDL_CONTROLLER_BUTTON_BACK = 4;
  static const int SDL_CONTROLLER_BUTTON_GUIDE = 5;
  static const int SDL_CONTROLLER_BUTTON_START = 6;
  static const int SDL_CONTROLLER_BUTTON_LEFTSTICK = 7;
  static const int SDL_CONTROLLER_BUTTON_RIGHTSTICK = 8;
  static const int SDL_CONTROLLER_BUTTON_LEFTSHOULDER = 9;
  static const int SDL_CONTROLLER_BUTTON_RIGHTSHOULDER = 10;
  static const int SDL_CONTROLLER_BUTTON_DPAD_UP = 11;
  static const int SDL_CONTROLLER_BUTTON_DPAD_DOWN = 12;
  static const int SDL_CONTROLLER_BUTTON_DPAD_LEFT = 13;
  static const int SDL_CONTROLLER_BUTTON_DPAD_RIGHT = 14;
  static const int SDL_CONTROLLER_BUTTON_MISC1 = 15;
  static const int SDL_CONTROLLER_BUTTON_PADDLE1 = 16;
  static const int SDL_CONTROLLER_BUTTON_PADDLE2 = 17;
  static const int SDL_CONTROLLER_BUTTON_PADDLE3 = 18;
  static const int SDL_CONTROLLER_BUTTON_PADDLE4 = 19;
  static const int SDL_CONTROLLER_BUTTON_TOUCHPAD = 20;
  static const int SDL_CONTROLLER_BUTTON_MAX = 21;
}

abstract class SDL_TouchDeviceType {
  static const int SDL_TOUCH_DEVICE_INVALID = -1;
  static const int SDL_TOUCH_DEVICE_DIRECT = 0;
  static const int SDL_TOUCH_DEVICE_INDIRECT_ABSOLUTE = 1;
  static const int SDL_TOUCH_DEVICE_INDIRECT_RELATIVE = 2;
}

class SDL_Finger extends ffi.Struct {
  @SDL_FingerID()
  external int id;

  @ffi.Float()
  external double x;

  @ffi.Float()
  external double y;

  @ffi.Float()
  external double pressure;
}

typedef SDL_FingerID = Sint64;
typedef SDL_TouchID = Sint64;
typedef SDL_GestureID = Sint64;

/// The types of events that can be delivered.
abstract class SDL_EventType {
  /// < Unused (do not remove)
  static const int SDL_FIRSTEVENT = 0;

  /// < User-requested quit
  static const int SDL_QUIT = 256;

  /// < The application is being terminated by the OS
  /// Called on iOS in applicationWillTerminate()
  /// Called on Android in onDestroy()
  static const int SDL_APP_TERMINATING = 257;

  /// < The application is low on memory, free memory if possible.
  /// Called on iOS in applicationDidReceiveMemoryWarning()
  /// Called on Android in onLowMemory()
  static const int SDL_APP_LOWMEMORY = 258;

  /// < The application is about to enter the background
  /// Called on iOS in applicationWillResignActive()
  /// Called on Android in onPause()
  static const int SDL_APP_WILLENTERBACKGROUND = 259;

  /// < The application did enter the background and may not get CPU for some time
  /// Called on iOS in applicationDidEnterBackground()
  /// Called on Android in onPause()
  static const int SDL_APP_DIDENTERBACKGROUND = 260;

  /// < The application is about to enter the foreground
  /// Called on iOS in applicationWillEnterForeground()
  /// Called on Android in onResume()
  static const int SDL_APP_WILLENTERFOREGROUND = 261;

  /// < The application is now interactive
  /// Called on iOS in applicationDidBecomeActive()
  /// Called on Android in onResume()
  static const int SDL_APP_DIDENTERFOREGROUND = 262;

  /// < The user's locale preferences have changed.
  static const int SDL_LOCALECHANGED = 263;

  /// < Display state change
  static const int SDL_DISPLAYEVENT = 336;

  /// < Window state change
  static const int SDL_WINDOWEVENT = 512;

  /// < System specific event
  static const int SDL_SYSWMEVENT = 513;

  /// < Key pressed
  static const int SDL_KEYDOWN = 768;

  /// < Key released
  static const int SDL_KEYUP = 769;

  /// < Keyboard text editing (composition)
  static const int SDL_TEXTEDITING = 770;

  /// < Keyboard text input
  static const int SDL_TEXTINPUT = 771;

  /// < Keymap changed due to a system event such as an
  /// input language or keyboard layout change.
  static const int SDL_KEYMAPCHANGED = 772;

  /// < Mouse moved
  static const int SDL_MOUSEMOTION = 1024;

  /// < Mouse button pressed
  static const int SDL_MOUSEBUTTONDOWN = 1025;

  /// < Mouse button released
  static const int SDL_MOUSEBUTTONUP = 1026;

  /// < Mouse wheel motion
  static const int SDL_MOUSEWHEEL = 1027;

  /// < Joystick axis motion
  static const int SDL_JOYAXISMOTION = 1536;

  /// < Joystick trackball motion
  static const int SDL_JOYBALLMOTION = 1537;

  /// < Joystick hat position change
  static const int SDL_JOYHATMOTION = 1538;

  /// < Joystick button pressed
  static const int SDL_JOYBUTTONDOWN = 1539;

  /// < Joystick button released
  static const int SDL_JOYBUTTONUP = 1540;

  /// < A new joystick has been inserted into the system
  static const int SDL_JOYDEVICEADDED = 1541;

  /// < An opened joystick has been removed
  static const int SDL_JOYDEVICEREMOVED = 1542;

  /// < Game controller axis motion
  static const int SDL_CONTROLLERAXISMOTION = 1616;

  /// < Game controller button pressed
  static const int SDL_CONTROLLERBUTTONDOWN = 1617;

  /// < Game controller button released
  static const int SDL_CONTROLLERBUTTONUP = 1618;

  /// < A new Game controller has been inserted into the system
  static const int SDL_CONTROLLERDEVICEADDED = 1619;

  /// < An opened Game controller has been removed
  static const int SDL_CONTROLLERDEVICEREMOVED = 1620;

  /// < The controller mapping was updated
  static const int SDL_CONTROLLERDEVICEREMAPPED = 1621;

  /// < Game controller touchpad was touched
  static const int SDL_CONTROLLERTOUCHPADDOWN = 1622;

  /// < Game controller touchpad finger was moved
  static const int SDL_CONTROLLERTOUCHPADMOTION = 1623;

  /// < Game controller touchpad finger was lifted
  static const int SDL_CONTROLLERTOUCHPADUP = 1624;

  /// < Game controller sensor was updated
  static const int SDL_CONTROLLERSENSORUPDATE = 1625;
  static const int SDL_FINGERDOWN = 1792;
  static const int SDL_FINGERUP = 1793;
  static const int SDL_FINGERMOTION = 1794;
  static const int SDL_DOLLARGESTURE = 2048;
  static const int SDL_DOLLARRECORD = 2049;
  static const int SDL_MULTIGESTURE = 2050;

  /// < The clipboard changed
  static const int SDL_CLIPBOARDUPDATE = 2304;

  /// < The system requests a file open
  static const int SDL_DROPFILE = 4096;

  /// < text/plain drag-and-drop event
  static const int SDL_DROPTEXT = 4097;

  /// < A new set of drops is beginning (NULL filename)
  static const int SDL_DROPBEGIN = 4098;

  /// < Current set of drops is now complete (NULL filename)
  static const int SDL_DROPCOMPLETE = 4099;

  /// < A new audio device is available
  static const int SDL_AUDIODEVICEADDED = 4352;

  /// < An audio device has been removed.
  static const int SDL_AUDIODEVICEREMOVED = 4353;

  /// < A sensor was updated
  static const int SDL_SENSORUPDATE = 4608;

  /// < The render targets have been reset and their contents need to be updated
  static const int SDL_RENDER_TARGETS_RESET = 8192;

  /// < The device has been reset and all textures need to be recreated
  static const int SDL_RENDER_DEVICE_RESET = 8193;

  /// < Signals the end of an event poll cycle
  static const int SDL_POLLSENTINEL = 32512;

  /// Events ::SDL_USEREVENT through ::SDL_LASTEVENT are for your use,
  /// and should be allocated with SDL_RegisterEvents()
  static const int SDL_USEREVENT = 32768;

  /// This last event is only for bounding internal arrays
  static const int SDL_LASTEVENT = 65535;
}

/// \brief Fields shared by every event
class SDL_CommonEvent extends ffi.Struct {
  @Uint32()
  external int type;

  /// < In milliseconds, populated using SDL_GetTicks()
  @Uint32()
  external int timestamp;
}

/// \brief Display state change event data (event.display.*)
class SDL_DisplayEvent extends ffi.Struct {
  /// < ::SDL_DISPLAYEVENT
  @Uint32()
  external int type;

  /// < In milliseconds, populated using SDL_GetTicks()
  @Uint32()
  external int timestamp;

  /// < The associated display index
  @Uint32()
  external int display;

  /// < ::SDL_DisplayEventID
  @Uint8()
  external int event;

  @Uint8()
  external int padding1;

  @Uint8()
  external int padding2;

  @Uint8()
  external int padding3;

  /// < event dependent data
  @Sint32()
  external int data1;
}

/// \brief Window state change event data (event.window.*)
class SDL_WindowEvent extends ffi.Struct {
  /// < ::SDL_WINDOWEVENT
  @Uint32()
  external int type;

  /// < In milliseconds, populated using SDL_GetTicks()
  @Uint32()
  external int timestamp;

  /// < The associated window
  @Uint32()
  external int windowID;

  /// < ::SDL_WindowEventID
  @Uint8()
  external int event;

  @Uint8()
  external int padding1;

  @Uint8()
  external int padding2;

  @Uint8()
  external int padding3;

  /// < event dependent data
  @Sint32()
  external int data1;

  /// < event dependent data
  @Sint32()
  external int data2;
}

/// \brief Keyboard button event structure (event.key.*)
class SDL_KeyboardEvent extends ffi.Struct {
  /// < ::SDL_KEYDOWN or ::SDL_KEYUP
  @Uint32()
  external int type;

  /// < In milliseconds, populated using SDL_GetTicks()
  @Uint32()
  external int timestamp;

  /// < The window with keyboard focus, if any
  @Uint32()
  external int windowID;

  /// < ::SDL_PRESSED or ::SDL_RELEASED
  @Uint8()
  external int state;

  /// < Non-zero if this is a key repeat
  @Uint8()
  external int repeat;

  @Uint8()
  external int padding2;

  @Uint8()
  external int padding3;

  /// < The key that was pressed or released
  external SDL_Keysym keysym;
}

/// \brief Keyboard text editing event structure (event.edit.*)
class SDL_TextEditingEvent extends ffi.Struct {
  /// < ::SDL_TEXTEDITING
  @Uint32()
  external int type;

  /// < In milliseconds, populated using SDL_GetTicks()
  @Uint32()
  external int timestamp;

  /// < The window with keyboard focus, if any
  @Uint32()
  external int windowID;

  @ffi.Array.multi([32])
  external ffi.Array<ffi.Int8> text;

  /// < The start cursor of selected editing text
  @Sint32()
  external int start;

  /// < The length of selected editing text
  @Sint32()
  external int length;
}

/// \brief Keyboard text input event structure (event.text.*)
class SDL_TextInputEvent extends ffi.Struct {
  /// < ::SDL_TEXTINPUT
  @Uint32()
  external int type;

  /// < In milliseconds, populated using SDL_GetTicks()
  @Uint32()
  external int timestamp;

  /// < The window with keyboard focus, if any
  @Uint32()
  external int windowID;

  @ffi.Array.multi([32])
  external ffi.Array<ffi.Int8> text;
}

/// \brief Mouse motion event structure (event.motion.*)
class SDL_MouseMotionEvent extends ffi.Struct {
  /// < ::SDL_MOUSEMOTION
  @Uint32()
  external int type;

  /// < In milliseconds, populated using SDL_GetTicks()
  @Uint32()
  external int timestamp;

  /// < The window with mouse focus, if any
  @Uint32()
  external int windowID;

  /// < The mouse instance id, or SDL_TOUCH_MOUSEID
  @Uint32()
  external int which;

  /// < The current button state
  @Uint32()
  external int state;

  /// < X coordinate, relative to window
  @Sint32()
  external int x;

  /// < Y coordinate, relative to window
  @Sint32()
  external int y;

  /// < The relative motion in the X direction
  @Sint32()
  external int xrel;

  /// < The relative motion in the Y direction
  @Sint32()
  external int yrel;
}

/// \brief Mouse button event structure (event.button.*)
class SDL_MouseButtonEvent extends ffi.Struct {
  /// < ::SDL_MOUSEBUTTONDOWN or ::SDL_MOUSEBUTTONUP
  @Uint32()
  external int type;

  /// < In milliseconds, populated using SDL_GetTicks()
  @Uint32()
  external int timestamp;

  /// < The window with mouse focus, if any
  @Uint32()
  external int windowID;

  /// < The mouse instance id, or SDL_TOUCH_MOUSEID
  @Uint32()
  external int which;

  /// < The mouse button index
  @Uint8()
  external int button;

  /// < ::SDL_PRESSED or ::SDL_RELEASED
  @Uint8()
  external int state;

  /// < 1 for single-click, 2 for double-click, etc.
  @Uint8()
  external int clicks;

  @Uint8()
  external int padding1;

  /// < X coordinate, relative to window
  @Sint32()
  external int x;

  /// < Y coordinate, relative to window
  @Sint32()
  external int y;
}

/// \brief Mouse wheel event structure (event.wheel.*)
class SDL_MouseWheelEvent extends ffi.Struct {
  /// < ::SDL_MOUSEWHEEL
  @Uint32()
  external int type;

  /// < In milliseconds, populated using SDL_GetTicks()
  @Uint32()
  external int timestamp;

  /// < The window with mouse focus, if any
  @Uint32()
  external int windowID;

  /// < The mouse instance id, or SDL_TOUCH_MOUSEID
  @Uint32()
  external int which;

  /// < The amount scrolled horizontally, positive to the right and negative to the left
  @Sint32()
  external int x;

  /// < The amount scrolled vertically, positive away from the user and negative toward the user
  @Sint32()
  external int y;

  /// < Set to one of the SDL_MOUSEWHEEL_* defines. When FLIPPED the values in X and Y will be opposite. Multiply by -1 to change them back
  @Uint32()
  external int direction;

  /// < The amount scrolled horizontally, positive to the right and negative to the left, with float precision (added in 2.0.18)
  @ffi.Float()
  external double preciseX;

  /// < The amount scrolled vertically, positive away from the user and negative toward the user, with float precision (added in 2.0.18)
  @ffi.Float()
  external double preciseY;
}

/// \brief Joystick axis motion event structure (event.jaxis.*)
class SDL_JoyAxisEvent extends ffi.Struct {
  /// < ::SDL_JOYAXISMOTION
  @Uint32()
  external int type;

  /// < In milliseconds, populated using SDL_GetTicks()
  @Uint32()
  external int timestamp;

  /// < The joystick instance id
  @SDL_JoystickID()
  external int which;

  /// < The joystick axis index
  @Uint8()
  external int axis;

  @Uint8()
  external int padding1;

  @Uint8()
  external int padding2;

  @Uint8()
  external int padding3;

  /// < The axis value (range: -32768 to 32767)
  @Sint16()
  external int value;

  @Uint16()
  external int padding4;
}

/// \brief Joystick trackball motion event structure (event.jball.*)
class SDL_JoyBallEvent extends ffi.Struct {
  /// < ::SDL_JOYBALLMOTION
  @Uint32()
  external int type;

  /// < In milliseconds, populated using SDL_GetTicks()
  @Uint32()
  external int timestamp;

  /// < The joystick instance id
  @SDL_JoystickID()
  external int which;

  /// < The joystick trackball index
  @Uint8()
  external int ball;

  @Uint8()
  external int padding1;

  @Uint8()
  external int padding2;

  @Uint8()
  external int padding3;

  /// < The relative motion in the X direction
  @Sint16()
  external int xrel;

  /// < The relative motion in the Y direction
  @Sint16()
  external int yrel;
}

/// \brief Joystick hat position change event structure (event.jhat.*)
class SDL_JoyHatEvent extends ffi.Struct {
  /// < ::SDL_JOYHATMOTION
  @Uint32()
  external int type;

  /// < In milliseconds, populated using SDL_GetTicks()
  @Uint32()
  external int timestamp;

  /// < The joystick instance id
  @SDL_JoystickID()
  external int which;

  /// < The joystick hat index
  @Uint8()
  external int hat;

  /// < The hat position value.
  /// \sa ::SDL_HAT_LEFTUP ::SDL_HAT_UP ::SDL_HAT_RIGHTUP
  /// \sa ::SDL_HAT_LEFT ::SDL_HAT_CENTERED ::SDL_HAT_RIGHT
  /// \sa ::SDL_HAT_LEFTDOWN ::SDL_HAT_DOWN ::SDL_HAT_RIGHTDOWN
  ///
  /// Note that zero means the POV is centered.
  @Uint8()
  external int value;

  @Uint8()
  external int padding1;

  @Uint8()
  external int padding2;
}

/// \brief Joystick button event structure (event.jbutton.*)
class SDL_JoyButtonEvent extends ffi.Struct {
  /// < ::SDL_JOYBUTTONDOWN or ::SDL_JOYBUTTONUP
  @Uint32()
  external int type;

  /// < In milliseconds, populated using SDL_GetTicks()
  @Uint32()
  external int timestamp;

  /// < The joystick instance id
  @SDL_JoystickID()
  external int which;

  /// < The joystick button index
  @Uint8()
  external int button;

  /// < ::SDL_PRESSED or ::SDL_RELEASED
  @Uint8()
  external int state;

  @Uint8()
  external int padding1;

  @Uint8()
  external int padding2;
}

/// \brief Joystick device event structure (event.jdevice.*)
class SDL_JoyDeviceEvent extends ffi.Struct {
  /// < ::SDL_JOYDEVICEADDED or ::SDL_JOYDEVICEREMOVED
  @Uint32()
  external int type;

  /// < In milliseconds, populated using SDL_GetTicks()
  @Uint32()
  external int timestamp;

  /// < The joystick device index for the ADDED event, instance id for the REMOVED event
  @Sint32()
  external int which;
}

/// \brief Game controller axis motion event structure (event.caxis.*)
class SDL_ControllerAxisEvent extends ffi.Struct {
  /// < ::SDL_CONTROLLERAXISMOTION
  @Uint32()
  external int type;

  /// < In milliseconds, populated using SDL_GetTicks()
  @Uint32()
  external int timestamp;

  /// < The joystick instance id
  @SDL_JoystickID()
  external int which;

  /// < The controller axis (SDL_GameControllerAxis)
  @Uint8()
  external int axis;

  @Uint8()
  external int padding1;

  @Uint8()
  external int padding2;

  @Uint8()
  external int padding3;

  /// < The axis value (range: -32768 to 32767)
  @Sint16()
  external int value;

  @Uint16()
  external int padding4;
}

/// \brief Game controller button event structure (event.cbutton.*)
class SDL_ControllerButtonEvent extends ffi.Struct {
  /// < ::SDL_CONTROLLERBUTTONDOWN or ::SDL_CONTROLLERBUTTONUP
  @Uint32()
  external int type;

  /// < In milliseconds, populated using SDL_GetTicks()
  @Uint32()
  external int timestamp;

  /// < The joystick instance id
  @SDL_JoystickID()
  external int which;

  /// < The controller button (SDL_GameControllerButton)
  @Uint8()
  external int button;

  /// < ::SDL_PRESSED or ::SDL_RELEASED
  @Uint8()
  external int state;

  @Uint8()
  external int padding1;

  @Uint8()
  external int padding2;
}

/// \brief Controller device event structure (event.cdevice.*)
class SDL_ControllerDeviceEvent extends ffi.Struct {
  /// < ::SDL_CONTROLLERDEVICEADDED, ::SDL_CONTROLLERDEVICEREMOVED, or ::SDL_CONTROLLERDEVICEREMAPPED
  @Uint32()
  external int type;

  /// < In milliseconds, populated using SDL_GetTicks()
  @Uint32()
  external int timestamp;

  /// < The joystick device index for the ADDED event, instance id for the REMOVED or REMAPPED event
  @Sint32()
  external int which;
}

/// \brief Game controller touchpad event structure (event.ctouchpad.*)
class SDL_ControllerTouchpadEvent extends ffi.Struct {
  /// < ::SDL_CONTROLLERTOUCHPADDOWN or ::SDL_CONTROLLERTOUCHPADMOTION or ::SDL_CONTROLLERTOUCHPADUP
  @Uint32()
  external int type;

  /// < In milliseconds, populated using SDL_GetTicks()
  @Uint32()
  external int timestamp;

  /// < The joystick instance id
  @SDL_JoystickID()
  external int which;

  /// < The index of the touchpad
  @Sint32()
  external int touchpad;

  /// < The index of the finger on the touchpad
  @Sint32()
  external int finger;

  /// < Normalized in the range 0...1 with 0 being on the left
  @ffi.Float()
  external double x;

  /// < Normalized in the range 0...1 with 0 being at the top
  @ffi.Float()
  external double y;

  /// < Normalized in the range 0...1
  @ffi.Float()
  external double pressure;
}

/// \brief Game controller sensor event structure (event.csensor.*)
class SDL_ControllerSensorEvent extends ffi.Struct {
  /// < ::SDL_CONTROLLERSENSORUPDATE
  @Uint32()
  external int type;

  /// < In milliseconds, populated using SDL_GetTicks()
  @Uint32()
  external int timestamp;

  /// < The joystick instance id
  @SDL_JoystickID()
  external int which;

  /// < The type of the sensor, one of the values of ::SDL_SensorType
  @Sint32()
  external int sensor;

  @ffi.Array.multi([3])
  external ffi.Array<ffi.Float> data;
}

/// \brief Audio device event structure (event.adevice.*)
class SDL_AudioDeviceEvent extends ffi.Struct {
  /// < ::SDL_AUDIODEVICEADDED, or ::SDL_AUDIODEVICEREMOVED
  @Uint32()
  external int type;

  /// < In milliseconds, populated using SDL_GetTicks()
  @Uint32()
  external int timestamp;

  /// < The audio device index for the ADDED event (valid until next SDL_GetNumAudioDevices() call), SDL_AudioDeviceID for the REMOVED event
  @Uint32()
  external int which;

  /// < zero if an output device, non-zero if a capture device.
  @Uint8()
  external int iscapture;

  @Uint8()
  external int padding1;

  @Uint8()
  external int padding2;

  @Uint8()
  external int padding3;
}

/// \brief Touch finger event structure (event.tfinger.*)
class SDL_TouchFingerEvent extends ffi.Struct {
  /// < ::SDL_FINGERMOTION or ::SDL_FINGERDOWN or ::SDL_FINGERUP
  @Uint32()
  external int type;

  /// < In milliseconds, populated using SDL_GetTicks()
  @Uint32()
  external int timestamp;

  /// < The touch device id
  @SDL_TouchID()
  external int touchId;

  @SDL_FingerID()
  external int fingerId;

  /// < Normalized in the range 0...1
  @ffi.Float()
  external double x;

  /// < Normalized in the range 0...1
  @ffi.Float()
  external double y;

  /// < Normalized in the range -1...1
  @ffi.Float()
  external double dx;

  /// < Normalized in the range -1...1
  @ffi.Float()
  external double dy;

  /// < Normalized in the range 0...1
  @ffi.Float()
  external double pressure;

  /// < The window underneath the finger, if any
  @Uint32()
  external int windowID;
}

/// \brief Multiple Finger Gesture Event (event.mgesture.*)
class SDL_MultiGestureEvent extends ffi.Struct {
  /// < ::SDL_MULTIGESTURE
  @Uint32()
  external int type;

  /// < In milliseconds, populated using SDL_GetTicks()
  @Uint32()
  external int timestamp;

  /// < The touch device id
  @SDL_TouchID()
  external int touchId;

  @ffi.Float()
  external double dTheta;

  @ffi.Float()
  external double dDist;

  @ffi.Float()
  external double x;

  @ffi.Float()
  external double y;

  @Uint16()
  external int numFingers;

  @Uint16()
  external int padding;
}

/// \brief Dollar Gesture Event (event.dgesture.*)
class SDL_DollarGestureEvent extends ffi.Struct {
  /// < ::SDL_DOLLARGESTURE or ::SDL_DOLLARRECORD
  @Uint32()
  external int type;

  /// < In milliseconds, populated using SDL_GetTicks()
  @Uint32()
  external int timestamp;

  /// < The touch device id
  @SDL_TouchID()
  external int touchId;

  @SDL_GestureID()
  external int gestureId;

  @Uint32()
  external int numFingers;

  @ffi.Float()
  external double error;

  /// < Normalized center of gesture
  @ffi.Float()
  external double x;

  /// < Normalized center of gesture
  @ffi.Float()
  external double y;
}

/// \brief An event used to request a file open by the system (event.drop.*)
/// This event is enabled by default, you can disable it with SDL_EventState().
/// \note If this event is enabled, you must free the filename in the event.
class SDL_DropEvent extends ffi.Struct {
  /// < ::SDL_DROPBEGIN or ::SDL_DROPFILE or ::SDL_DROPTEXT or ::SDL_DROPCOMPLETE
  @Uint32()
  external int type;

  /// < In milliseconds, populated using SDL_GetTicks()
  @Uint32()
  external int timestamp;

  /// < The file name, which should be freed with SDL_free(), is NULL on begin/complete
  external ffi.Pointer<ffi.Int8> file;

  /// < The window that was dropped on, if any
  @Uint32()
  external int windowID;
}

/// \brief Sensor event structure (event.sensor.*)
class SDL_SensorEvent extends ffi.Struct {
  /// < ::SDL_SENSORUPDATE
  @Uint32()
  external int type;

  /// < In milliseconds, populated using SDL_GetTicks()
  @Uint32()
  external int timestamp;

  /// < The instance ID of the sensor
  @Sint32()
  external int which;

  @ffi.Array.multi([6])
  external ffi.Array<ffi.Float> data;
}

/// \brief The "quit requested" event
class SDL_QuitEvent extends ffi.Struct {
  /// < ::SDL_QUIT
  @Uint32()
  external int type;

  /// < In milliseconds, populated using SDL_GetTicks()
  @Uint32()
  external int timestamp;
}

/// \brief OS Specific event
class SDL_OSEvent extends ffi.Struct {
  /// < ::SDL_QUIT
  @Uint32()
  external int type;

  /// < In milliseconds, populated using SDL_GetTicks()
  @Uint32()
  external int timestamp;
}

/// \brief A user-defined event type (event.user.*)
class SDL_UserEvent extends ffi.Struct {
  /// < ::SDL_USEREVENT through ::SDL_LASTEVENT-1
  @Uint32()
  external int type;

  /// < In milliseconds, populated using SDL_GetTicks()
  @Uint32()
  external int timestamp;

  /// < The associated window if any
  @Uint32()
  external int windowID;

  /// < User defined event code
  @Sint32()
  external int code;

  /// < User defined data pointer
  external ffi.Pointer<ffi.Void> data1;

  /// < User defined data pointer
  external ffi.Pointer<ffi.Void> data2;
}

class SDL_SysWMmsg extends ffi.Opaque {}

/// \brief A video driver dependent system event (event.syswm.*)
/// This event is disabled by default, you can enable it with SDL_EventState()
///
/// \note If you want to use this event, you should include SDL_syswm.h.
class SDL_SysWMEvent extends ffi.Struct {
  /// < ::SDL_SYSWMEVENT
  @Uint32()
  external int type;

  /// < In milliseconds, populated using SDL_GetTicks()
  @Uint32()
  external int timestamp;

  /// < driver dependent data, defined in SDL_syswm.h
  external ffi.Pointer<SDL_SysWMmsg> msg;
}

/// \brief General event structure
class SDL_Event extends ffi.Union {
  /// < Event type, shared with all events
  @Uint32()
  external int type;

  /// < Common event data
  external SDL_CommonEvent common;

  /// < Display event data
  external SDL_DisplayEvent display;

  /// < Window event data
  external SDL_WindowEvent window;

  /// < Keyboard event data
  external SDL_KeyboardEvent key;

  /// < Text editing event data
  external SDL_TextEditingEvent edit;

  /// < Text input event data
  external SDL_TextInputEvent text;

  /// < Mouse motion event data
  external SDL_MouseMotionEvent motion;

  /// < Mouse button event data
  external SDL_MouseButtonEvent button;

  /// < Mouse wheel event data
  external SDL_MouseWheelEvent wheel;

  /// < Joystick axis event data
  external SDL_JoyAxisEvent jaxis;

  /// < Joystick ball event data
  external SDL_JoyBallEvent jball;

  /// < Joystick hat event data
  external SDL_JoyHatEvent jhat;

  /// < Joystick button event data
  external SDL_JoyButtonEvent jbutton;

  /// < Joystick device change event data
  external SDL_JoyDeviceEvent jdevice;

  /// < Game Controller axis event data
  external SDL_ControllerAxisEvent caxis;

  /// < Game Controller button event data
  external SDL_ControllerButtonEvent cbutton;

  /// < Game Controller device event data
  external SDL_ControllerDeviceEvent cdevice;

  /// < Game Controller touchpad event data
  external SDL_ControllerTouchpadEvent ctouchpad;

  /// < Game Controller sensor event data
  external SDL_ControllerSensorEvent csensor;

  /// < Audio device event data
  external SDL_AudioDeviceEvent adevice;

  /// < Sensor event data
  external SDL_SensorEvent sensor;

  /// < Quit request event data
  external SDL_QuitEvent quit;

  /// < Custom event data
  external SDL_UserEvent user;

  /// < System dependent window event data
  external SDL_SysWMEvent syswm;

  /// < Touch finger event data
  external SDL_TouchFingerEvent tfinger;

  /// < Gesture event data
  external SDL_MultiGestureEvent mgesture;

  /// < Gesture event data
  external SDL_DollarGestureEvent dgesture;

  /// < Drag and drop event data
  external SDL_DropEvent drop;

  @ffi.Array.multi([56])
  external ffi.Array<Uint8> padding;
}

abstract class SDL_eventaction {
  static const int SDL_ADDEVENT = 0;
  static const int SDL_PEEKEVENT = 1;
  static const int SDL_GETEVENT = 2;
}

/// A function pointer used for callbacks that watch the event queue.
///
/// \param userdata what was passed as `userdata` to SDL_SetEventFilter()
/// or SDL_AddEventWatch, etc
/// \param event the event that triggered the callback
/// \returns 1 to permit event to be added to the queue, and 0 to disallow
/// it. When used with SDL_AddEventWatch, the return value is ignored.
///
/// \sa SDL_SetEventFilter
/// \sa SDL_AddEventWatch
typedef SDL_EventFilter = ffi.Pointer<
    ffi.NativeFunction<
        ffi.Int32 Function(ffi.Pointer<ffi.Void>, ffi.Pointer<SDL_Event>)>>;

/// \typedef SDL_Haptic
///
/// \brief The haptic structure used to identify an SDL haptic.
///
/// \sa SDL_HapticOpen
/// \sa SDL_HapticOpenFromJoystick
/// \sa SDL_HapticClose
class SDL_Haptic extends ffi.Opaque {}

/// \brief Structure that represents a haptic direction.
///
/// This is the direction where the force comes from,
/// instead of the direction in which the force is exerted.
///
/// Directions can be specified by:
/// - ::SDL_HAPTIC_POLAR : Specified by polar coordinates.
/// - ::SDL_HAPTIC_CARTESIAN : Specified by cartesian coordinates.
/// - ::SDL_HAPTIC_SPHERICAL : Specified by spherical coordinates.
///
/// Cardinal directions of the haptic device are relative to the positioning
/// of the device.  North is considered to be away from the user.
///
/// The following diagram represents the cardinal directions:
/// \verbatim
/// .--.
/// |__| .-------.
/// |=.| |.-----.|
/// |--| ||     ||
/// |  | |'-----'|
/// |__|~')_____('
/// [ COMPUTER ]
///
///
/// North (0,-1)
/// ^
/// |
/// |
/// (-1,0)  West <----[ HAPTIC ]----> East (1,0)
/// |
/// |
/// v
/// South (0,1)
///
///
/// [ USER ]
/// \|||/
/// (o o)
/// ---ooO-(_)-Ooo---
/// \endverbatim
///
/// If type is ::SDL_HAPTIC_POLAR, direction is encoded by hundredths of a
/// degree starting north and turning clockwise.  ::SDL_HAPTIC_POLAR only uses
/// the first \c dir parameter.  The cardinal directions would be:
/// - North: 0 (0 degrees)
/// - East: 9000 (90 degrees)
/// - South: 18000 (180 degrees)
/// - West: 27000 (270 degrees)
///
/// If type is ::SDL_HAPTIC_CARTESIAN, direction is encoded by three positions
/// (X axis, Y axis and Z axis (with 3 axes)).  ::SDL_HAPTIC_CARTESIAN uses
/// the first three \c dir parameters.  The cardinal directions would be:
/// - North:  0,-1, 0
/// - East:   1, 0, 0
/// - South:  0, 1, 0
/// - West:  -1, 0, 0
///
/// The Z axis represents the height of the effect if supported, otherwise
/// it's unused.  In cartesian encoding (1, 2) would be the same as (2, 4), you
/// can use any multiple you want, only the direction matters.
///
/// If type is ::SDL_HAPTIC_SPHERICAL, direction is encoded by two rotations.
/// The first two \c dir parameters are used.  The \c dir parameters are as
/// follows (all values are in hundredths of degrees):
/// - Degrees from (1, 0) rotated towards (0, 1).
/// - Degrees towards (0, 0, 1) (device needs at least 3 axes).
///
///
/// Example of force coming from the south with all encodings (force coming
/// from the south means the user will have to pull the stick to counteract):
/// \code
/// SDL_HapticDirection direction;
///
/// // Cartesian directions
/// direction.type = SDL_HAPTIC_CARTESIAN; // Using cartesian direction encoding.
/// direction.dir[0] = 0; // X position
/// direction.dir[1] = 1; // Y position
/// // Assuming the device has 2 axes, we don't need to specify third parameter.
///
/// // Polar directions
/// direction.type = SDL_HAPTIC_POLAR; // We'll be using polar direction encoding.
/// direction.dir[0] = 18000; // Polar only uses first parameter
///
/// // Spherical coordinates
/// direction.type = SDL_HAPTIC_SPHERICAL; // Spherical encoding
/// direction.dir[0] = 9000; // Since we only have two axes we don't need more parameters.
/// \endcode
///
/// \sa SDL_HAPTIC_POLAR
/// \sa SDL_HAPTIC_CARTESIAN
/// \sa SDL_HAPTIC_SPHERICAL
/// \sa SDL_HAPTIC_STEERING_AXIS
/// \sa SDL_HapticEffect
/// \sa SDL_HapticNumAxes
class SDL_HapticDirection extends ffi.Struct {
  /// < The type of encoding.
  @Uint8()
  external int type;

  @ffi.Array.multi([3])
  external ffi.Array<Sint32> dir;
}

/// \brief A structure containing a template for a Constant effect.
///
/// This struct is exclusively for the ::SDL_HAPTIC_CONSTANT effect.
///
/// A constant effect applies a constant force in the specified direction
/// to the joystick.
///
/// \sa SDL_HAPTIC_CONSTANT
/// \sa SDL_HapticEffect
class SDL_HapticConstant extends ffi.Struct {
  /// < ::SDL_HAPTIC_CONSTANT
  @Uint16()
  external int type;

  /// < Direction of the effect.
  external SDL_HapticDirection direction;

  /// < Duration of the effect.
  @Uint32()
  external int length;

  /// < Delay before starting the effect.
  @Uint16()
  external int delay;

  /// < Button that triggers the effect.
  @Uint16()
  external int button;

  /// < How soon it can be triggered again after button.
  @Uint16()
  external int interval;

  /// < Strength of the constant effect.
  @Sint16()
  external int level;

  /// < Duration of the attack.
  @Uint16()
  external int attack_length;

  /// < Level at the start of the attack.
  @Uint16()
  external int attack_level;

  /// < Duration of the fade.
  @Uint16()
  external int fade_length;

  /// < Level at the end of the fade.
  @Uint16()
  external int fade_level;
}

/// \brief A structure containing a template for a Periodic effect.
///
/// The struct handles the following effects:
/// - ::SDL_HAPTIC_SINE
/// - ::SDL_HAPTIC_LEFTRIGHT
/// - ::SDL_HAPTIC_TRIANGLE
/// - ::SDL_HAPTIC_SAWTOOTHUP
/// - ::SDL_HAPTIC_SAWTOOTHDOWN
///
/// A periodic effect consists in a wave-shaped effect that repeats itself
/// over time.  The type determines the shape of the wave and the parameters
/// determine the dimensions of the wave.
///
/// Phase is given by hundredth of a degree meaning that giving the phase a value
/// of 9000 will displace it 25% of its period.  Here are sample values:
/// -     0: No phase displacement.
/// -  9000: Displaced 25% of its period.
/// - 18000: Displaced 50% of its period.
/// - 27000: Displaced 75% of its period.
/// - 36000: Displaced 100% of its period, same as 0, but 0 is preferred.
///
/// Examples:
/// \verbatim
/// SDL_HAPTIC_SINE
/// __      __      __      __
/// /  \    /  \    /  \    /
/// /    \__/    \__/    \__/
///
/// SDL_HAPTIC_SQUARE
/// __    __    __    __    __
/// |  |  |  |  |  |  |  |  |  |
/// |  |__|  |__|  |__|  |__|  |
///
/// SDL_HAPTIC_TRIANGLE
/// /\    /\    /\    /\    /\
/// /  \  /  \  /  \  /  \  /
/// /    \/    \/    \/    \/
///
/// SDL_HAPTIC_SAWTOOTHUP
/// /|  /|  /|  /|  /|  /|  /|
/// / | / | / | / | / | / | / |
/// /  |/  |/  |/  |/  |/  |/  |
///
/// SDL_HAPTIC_SAWTOOTHDOWN
/// \  |\  |\  |\  |\  |\  |\  |
/// \ | \ | \ | \ | \ | \ | \ |
/// \|  \|  \|  \|  \|  \|  \|
/// \endverbatim
///
/// \sa SDL_HAPTIC_SINE
/// \sa SDL_HAPTIC_LEFTRIGHT
/// \sa SDL_HAPTIC_TRIANGLE
/// \sa SDL_HAPTIC_SAWTOOTHUP
/// \sa SDL_HAPTIC_SAWTOOTHDOWN
/// \sa SDL_HapticEffect
class SDL_HapticPeriodic extends ffi.Struct {
  /// < ::SDL_HAPTIC_SINE, ::SDL_HAPTIC_LEFTRIGHT,
  /// ::SDL_HAPTIC_TRIANGLE, ::SDL_HAPTIC_SAWTOOTHUP or
  /// ::SDL_HAPTIC_SAWTOOTHDOWN
  @Uint16()
  external int type;

  /// < Direction of the effect.
  external SDL_HapticDirection direction;

  /// < Duration of the effect.
  @Uint32()
  external int length;

  /// < Delay before starting the effect.
  @Uint16()
  external int delay;

  /// < Button that triggers the effect.
  @Uint16()
  external int button;

  /// < How soon it can be triggered again after button.
  @Uint16()
  external int interval;

  /// < Period of the wave.
  @Uint16()
  external int period;

  /// < Peak value; if negative, equivalent to 180 degrees extra phase shift.
  @Sint16()
  external int magnitude;

  /// < Mean value of the wave.
  @Sint16()
  external int offset;

  /// < Positive phase shift given by hundredth of a degree.
  @Uint16()
  external int phase;

  /// < Duration of the attack.
  @Uint16()
  external int attack_length;

  /// < Level at the start of the attack.
  @Uint16()
  external int attack_level;

  /// < Duration of the fade.
  @Uint16()
  external int fade_length;

  /// < Level at the end of the fade.
  @Uint16()
  external int fade_level;
}

/// \brief A structure containing a template for a Condition effect.
///
/// The struct handles the following effects:
/// - ::SDL_HAPTIC_SPRING: Effect based on axes position.
/// - ::SDL_HAPTIC_DAMPER: Effect based on axes velocity.
/// - ::SDL_HAPTIC_INERTIA: Effect based on axes acceleration.
/// - ::SDL_HAPTIC_FRICTION: Effect based on axes movement.
///
/// Direction is handled by condition internals instead of a direction member.
/// The condition effect specific members have three parameters.  The first
/// refers to the X axis, the second refers to the Y axis and the third
/// refers to the Z axis.  The right terms refer to the positive side of the
/// axis and the left terms refer to the negative side of the axis.  Please
/// refer to the ::SDL_HapticDirection diagram for which side is positive and
/// which is negative.
///
/// \sa SDL_HapticDirection
/// \sa SDL_HAPTIC_SPRING
/// \sa SDL_HAPTIC_DAMPER
/// \sa SDL_HAPTIC_INERTIA
/// \sa SDL_HAPTIC_FRICTION
/// \sa SDL_HapticEffect
class SDL_HapticCondition extends ffi.Struct {
  /// < ::SDL_HAPTIC_SPRING, ::SDL_HAPTIC_DAMPER,
  /// ::SDL_HAPTIC_INERTIA or ::SDL_HAPTIC_FRICTION
  @Uint16()
  external int type;

  /// < Direction of the effect - Not used ATM.
  external SDL_HapticDirection direction;

  /// < Duration of the effect.
  @Uint32()
  external int length;

  /// < Delay before starting the effect.
  @Uint16()
  external int delay;

  /// < Button that triggers the effect.
  @Uint16()
  external int button;

  /// < How soon it can be triggered again after button.
  @Uint16()
  external int interval;

  @ffi.Array.multi([3])
  external ffi.Array<Uint16> right_sat;

  @ffi.Array.multi([3])
  external ffi.Array<Uint16> left_sat;

  @ffi.Array.multi([3])
  external ffi.Array<Sint16> right_coeff;

  @ffi.Array.multi([3])
  external ffi.Array<Sint16> left_coeff;

  @ffi.Array.multi([3])
  external ffi.Array<Uint16> deadband;

  @ffi.Array.multi([3])
  external ffi.Array<Sint16> center;
}

/// \brief A structure containing a template for a Ramp effect.
///
/// This struct is exclusively for the ::SDL_HAPTIC_RAMP effect.
///
/// The ramp effect starts at start strength and ends at end strength.
/// It augments in linear fashion.  If you use attack and fade with a ramp
/// the effects get added to the ramp effect making the effect become
/// quadratic instead of linear.
///
/// \sa SDL_HAPTIC_RAMP
/// \sa SDL_HapticEffect
class SDL_HapticRamp extends ffi.Struct {
  /// < ::SDL_HAPTIC_RAMP
  @Uint16()
  external int type;

  /// < Direction of the effect.
  external SDL_HapticDirection direction;

  /// < Duration of the effect.
  @Uint32()
  external int length;

  /// < Delay before starting the effect.
  @Uint16()
  external int delay;

  /// < Button that triggers the effect.
  @Uint16()
  external int button;

  /// < How soon it can be triggered again after button.
  @Uint16()
  external int interval;

  /// < Beginning strength level.
  @Sint16()
  external int start;

  /// < Ending strength level.
  @Sint16()
  external int end;

  /// < Duration of the attack.
  @Uint16()
  external int attack_length;

  /// < Level at the start of the attack.
  @Uint16()
  external int attack_level;

  /// < Duration of the fade.
  @Uint16()
  external int fade_length;

  /// < Level at the end of the fade.
  @Uint16()
  external int fade_level;
}

/// \brief A structure containing a template for a Left/Right effect.
///
/// This struct is exclusively for the ::SDL_HAPTIC_LEFTRIGHT effect.
///
/// The Left/Right effect is used to explicitly control the large and small
/// motors, commonly found in modern game controllers. The small (right) motor
/// is high frequency, and the large (left) motor is low frequency.
///
/// \sa SDL_HAPTIC_LEFTRIGHT
/// \sa SDL_HapticEffect
class SDL_HapticLeftRight extends ffi.Struct {
  /// < ::SDL_HAPTIC_LEFTRIGHT
  @Uint16()
  external int type;

  /// < Duration of the effect in milliseconds.
  @Uint32()
  external int length;

  /// < Control of the large controller motor.
  @Uint16()
  external int large_magnitude;

  /// < Control of the small controller motor.
  @Uint16()
  external int small_magnitude;
}

/// \brief A structure containing a template for the ::SDL_HAPTIC_CUSTOM effect.
///
/// This struct is exclusively for the ::SDL_HAPTIC_CUSTOM effect.
///
/// A custom force feedback effect is much like a periodic effect, where the
/// application can define its exact shape.  You will have to allocate the
/// data yourself.  Data should consist of channels * samples Uint16 samples.
///
/// If channels is one, the effect is rotated using the defined direction.
/// Otherwise it uses the samples in data for the different axes.
///
/// \sa SDL_HAPTIC_CUSTOM
/// \sa SDL_HapticEffect
class SDL_HapticCustom extends ffi.Struct {
  /// < ::SDL_HAPTIC_CUSTOM
  @Uint16()
  external int type;

  /// < Direction of the effect.
  external SDL_HapticDirection direction;

  /// < Duration of the effect.
  @Uint32()
  external int length;

  /// < Delay before starting the effect.
  @Uint16()
  external int delay;

  /// < Button that triggers the effect.
  @Uint16()
  external int button;

  /// < How soon it can be triggered again after button.
  @Uint16()
  external int interval;

  /// < Axes to use, minimum of one.
  @Uint8()
  external int channels;

  /// < Sample periods.
  @Uint16()
  external int period;

  /// < Amount of samples.
  @Uint16()
  external int samples;

  /// < Should contain channels*samples items.
  external ffi.Pointer<Uint16> data;

  /// < Duration of the attack.
  @Uint16()
  external int attack_length;

  /// < Level at the start of the attack.
  @Uint16()
  external int attack_level;

  /// < Duration of the fade.
  @Uint16()
  external int fade_length;

  /// < Level at the end of the fade.
  @Uint16()
  external int fade_level;
}

/// \brief The generic template for any haptic effect.
///
/// All values max at 32767 (0x7FFF).  Signed values also can be negative.
/// Time values unless specified otherwise are in milliseconds.
///
/// You can also pass ::SDL_HAPTIC_INFINITY to length instead of a 0-32767
/// value.  Neither delay, interval, attack_length nor fade_length support
/// ::SDL_HAPTIC_INFINITY.  Fade will also not be used since effect never ends.
///
/// Additionally, the ::SDL_HAPTIC_RAMP effect does not support a duration of
/// ::SDL_HAPTIC_INFINITY.
///
/// Button triggers may not be supported on all devices, it is advised to not
/// use them if possible.  Buttons start at index 1 instead of index 0 like
/// the joystick.
///
/// If both attack_length and fade_level are 0, the envelope is not used,
/// otherwise both values are used.
///
/// Common parts:
/// \code
/// // Replay - All effects have this
/// Uint32 length;        // Duration of effect (ms).
/// Uint16 delay;         // Delay before starting effect.
///
/// // Trigger - All effects have this
/// Uint16 button;        // Button that triggers effect.
/// Uint16 interval;      // How soon before effect can be triggered again.
///
/// // Envelope - All effects except condition effects have this
/// Uint16 attack_length; // Duration of the attack (ms).
/// Uint16 attack_level;  // Level at the start of the attack.
/// Uint16 fade_length;   // Duration of the fade out (ms).
/// Uint16 fade_level;    // Level at the end of the fade.
/// \endcode
///
///
/// Here we have an example of a constant effect evolution in time:
/// \verbatim
/// Strength
/// ^
/// |
/// |    effect level -->  _________________
/// |                     /                 \
/// |                    /                   \
/// |                   /                     \
/// |                  /                       \
/// | attack_level --> |                        \
/// |                  |                        |  <---  fade_level
/// |
/// +--------------------------------------------------> Time
/// [--]                 [---]
/// attack_length        fade_length
///
/// [------------------][-----------------------]
/// delay               length
/// \endverbatim
///
/// Note either the attack_level or the fade_level may be above the actual
/// effect level.
///
/// \sa SDL_HapticConstant
/// \sa SDL_HapticPeriodic
/// \sa SDL_HapticCondition
/// \sa SDL_HapticRamp
/// \sa SDL_HapticLeftRight
/// \sa SDL_HapticCustom
class SDL_HapticEffect extends ffi.Union {
  /// < Effect type.
  @Uint16()
  external int type;

  /// < Constant effect.
  external SDL_HapticConstant constant;

  /// < Periodic effect.
  external SDL_HapticPeriodic periodic;

  /// < Condition effect.
  external SDL_HapticCondition condition;

  /// < Ramp effect.
  external SDL_HapticRamp ramp;

  /// < Left/Right effect.
  external SDL_HapticLeftRight leftright;

  /// < Custom effect.
  external SDL_HapticCustom custom;
}

typedef SDL_Haptic1 = SDL_Haptic;

/// \brief  A handle representing an open HID device
class SDL_hid_device_ extends ffi.Opaque {}

/// hidapi info structure */
/// /**
/// \brief  Information about a connected HID device
class SDL_hid_device_info extends ffi.Struct {
  /// Platform-specific device path
  external ffi.Pointer<ffi.Int8> path;

  /// Device Vendor ID
  @ffi.Uint16()
  external int vendor_id;

  /// Device Product ID
  @ffi.Uint16()
  external int product_id;

  /// Serial Number
  external ffi.Pointer<wchar_t> serial_number;

  /// Device Release Number in binary-coded decimal,
  /// also known as Device Version Number
  @ffi.Uint16()
  external int release_number;

  /// Manufacturer String
  external ffi.Pointer<wchar_t> manufacturer_string;

  /// Product string
  external ffi.Pointer<wchar_t> product_string;

  /// Usage Page for this Device/Interface
  /// (Windows/Mac only).
  @ffi.Uint16()
  external int usage_page;

  /// Usage for this Device/Interface
  /// (Windows/Mac only).
  @ffi.Uint16()
  external int usage;

  /// The USB interface which this logical device
  /// represents.
  ///
  /// Valid on both Linux implementations in all cases.
  /// Valid on the Windows implementation only if the device
  /// contains more than one interface.
  @ffi.Int32()
  external int interface_number;

  /// Additional information about the USB interface.
  /// Valid on libusb and Android implementations.
  @ffi.Int32()
  external int interface_class;

  @ffi.Int32()
  external int interface_subclass;

  @ffi.Int32()
  external int interface_protocol;

  /// Pointer to the next device
  external ffi.Pointer<SDL_hid_device_info> next;
}

typedef SDL_hid_device = SDL_hid_device_;

/// \brief  An enumeration of hint priorities
abstract class SDL_HintPriority {
  static const int SDL_HINT_DEFAULT = 0;
  static const int SDL_HINT_NORMAL = 1;
  static const int SDL_HINT_OVERRIDE = 2;
}

/// Type definition of the hint callback function.
///
/// \param userdata what was passed as `userdata` to SDL_AddHintCallback()
/// \param name what was passed as `name` to SDL_AddHintCallback()
/// \param oldValue the previous hint value
/// \param newValue the new value hint is to be set to
typedef SDL_HintCallback = ffi.Pointer<
    ffi.NativeFunction<
        ffi.Void Function(ffi.Pointer<ffi.Void>, ffi.Pointer<ffi.Int8>,
            ffi.Pointer<ffi.Int8>, ffi.Pointer<ffi.Int8>)>>;

/// \brief The predefined log categories
///
/// By default the application category is enabled at the INFO level,
/// the assert category is enabled at the WARN level, test is enabled
/// at the VERBOSE level and all other categories are enabled at the
/// CRITICAL level.
abstract class SDL_LogCategory {
  static const int SDL_LOG_CATEGORY_APPLICATION = 0;
  static const int SDL_LOG_CATEGORY_ERROR = 1;
  static const int SDL_LOG_CATEGORY_ASSERT = 2;
  static const int SDL_LOG_CATEGORY_SYSTEM = 3;
  static const int SDL_LOG_CATEGORY_AUDIO = 4;
  static const int SDL_LOG_CATEGORY_VIDEO = 5;
  static const int SDL_LOG_CATEGORY_RENDER = 6;
  static const int SDL_LOG_CATEGORY_INPUT = 7;
  static const int SDL_LOG_CATEGORY_TEST = 8;
  static const int SDL_LOG_CATEGORY_RESERVED1 = 9;
  static const int SDL_LOG_CATEGORY_RESERVED2 = 10;
  static const int SDL_LOG_CATEGORY_RESERVED3 = 11;
  static const int SDL_LOG_CATEGORY_RESERVED4 = 12;
  static const int SDL_LOG_CATEGORY_RESERVED5 = 13;
  static const int SDL_LOG_CATEGORY_RESERVED6 = 14;
  static const int SDL_LOG_CATEGORY_RESERVED7 = 15;
  static const int SDL_LOG_CATEGORY_RESERVED8 = 16;
  static const int SDL_LOG_CATEGORY_RESERVED9 = 17;
  static const int SDL_LOG_CATEGORY_RESERVED10 = 18;
  static const int SDL_LOG_CATEGORY_CUSTOM = 19;
}

/// \brief The predefined log priorities
abstract class SDL_LogPriority {
  static const int SDL_LOG_PRIORITY_VERBOSE = 1;
  static const int SDL_LOG_PRIORITY_DEBUG = 2;
  static const int SDL_LOG_PRIORITY_INFO = 3;
  static const int SDL_LOG_PRIORITY_WARN = 4;
  static const int SDL_LOG_PRIORITY_ERROR = 5;
  static const int SDL_LOG_PRIORITY_CRITICAL = 6;
  static const int SDL_NUM_LOG_PRIORITIES = 7;
}

/// The prototype for the log output callback function.
///
/// This function is called by SDL when there is new text to be logged.
///
/// \param userdata what was passed as `userdata` to SDL_LogSetOutputFunction()
/// \param category the category of the message
/// \param priority the priority of the message
/// \param message the message being output
typedef SDL_LogOutputFunction = ffi.Pointer<
    ffi.NativeFunction<
        ffi.Void Function(ffi.Pointer<ffi.Void>, ffi.Int32, ffi.Int32,
            ffi.Pointer<ffi.Int8>)>>;

/// SDL_MessageBox flags. If supported will display warning icon, etc.
abstract class SDL_MessageBoxFlags {
  /// < error dialog
  static const int SDL_MESSAGEBOX_ERROR = 16;

  /// < warning dialog
  static const int SDL_MESSAGEBOX_WARNING = 32;

  /// < informational dialog
  static const int SDL_MESSAGEBOX_INFORMATION = 64;

  /// < buttons placed left to right
  static const int SDL_MESSAGEBOX_BUTTONS_LEFT_TO_RIGHT = 128;

  /// < buttons placed right to left
  static const int SDL_MESSAGEBOX_BUTTONS_RIGHT_TO_LEFT = 256;
}

/// Flags for SDL_MessageBoxButtonData.
abstract class SDL_MessageBoxButtonFlags {
  /// < Marks the default button when return is hit
  static const int SDL_MESSAGEBOX_BUTTON_RETURNKEY_DEFAULT = 1;

  /// < Marks the default button when escape is hit
  static const int SDL_MESSAGEBOX_BUTTON_ESCAPEKEY_DEFAULT = 2;
}

/// Individual button data.
class SDL_MessageBoxButtonData extends ffi.Struct {
  /// < ::SDL_MessageBoxButtonFlags
  @Uint32()
  external int flags;

  /// < User defined button id (value returned via SDL_ShowMessageBox)
  @ffi.Int32()
  external int buttonid;

  /// < The UTF-8 button text
  external ffi.Pointer<ffi.Int8> text;
}

/// RGB value used in a message box color scheme
class SDL_MessageBoxColor extends ffi.Struct {
  @Uint8()
  external int r;

  @Uint8()
  external int g;

  @Uint8()
  external int b;
}

abstract class SDL_MessageBoxColorType {
  static const int SDL_MESSAGEBOX_COLOR_BACKGROUND = 0;
  static const int SDL_MESSAGEBOX_COLOR_TEXT = 1;
  static const int SDL_MESSAGEBOX_COLOR_BUTTON_BORDER = 2;
  static const int SDL_MESSAGEBOX_COLOR_BUTTON_BACKGROUND = 3;
  static const int SDL_MESSAGEBOX_COLOR_BUTTON_SELECTED = 4;
  static const int SDL_MESSAGEBOX_COLOR_MAX = 5;
}

/// A set of colors to use for message box dialogs
class SDL_MessageBoxColorScheme extends ffi.Struct {
  @ffi.Array.multi([5])
  external ffi.Array<SDL_MessageBoxColor> colors;
}

/// MessageBox structure containing title, text, window, etc.
class SDL_MessageBoxData extends ffi.Struct {
  /// < ::SDL_MessageBoxFlags
  @Uint32()
  external int flags;

  /// < Parent window, can be NULL
  external ffi.Pointer<SDL_Window> window;

  /// < UTF-8 title
  external ffi.Pointer<ffi.Int8> title;

  /// < UTF-8 message text
  external ffi.Pointer<ffi.Int8> message;

  @ffi.Int32()
  external int numbuttons;

  external ffi.Pointer<SDL_MessageBoxButtonData> buttons;

  /// < ::SDL_MessageBoxColorScheme, can be NULL to use system settings
  external ffi.Pointer<SDL_MessageBoxColorScheme> colorScheme;
}

/// \brief A handle to a CAMetalLayer-backed NSView (macOS) or UIView (iOS/tvOS).
///
/// \note This can be cast directly to an NSView or UIView.
typedef SDL_MetalView = ffi.Pointer<ffi.Void>;

/// The basic state for the system's power supply.
abstract class SDL_PowerState {
  /// < cannot determine power status
  static const int SDL_POWERSTATE_UNKNOWN = 0;

  /// < Not plugged in, running on the battery
  static const int SDL_POWERSTATE_ON_BATTERY = 1;

  /// < Plugged in, no battery available
  static const int SDL_POWERSTATE_NO_BATTERY = 2;

  /// < Plugged in, charging battery
  static const int SDL_POWERSTATE_CHARGING = 3;

  /// < Plugged in, battery charged
  static const int SDL_POWERSTATE_CHARGED = 4;
}

/// Flags used when creating a rendering context
abstract class SDL_RendererFlags {
  /// < The renderer is a software fallback
  static const int SDL_RENDERER_SOFTWARE = 1;

  /// < The renderer uses hardware
  /// acceleration
  static const int SDL_RENDERER_ACCELERATED = 2;

  /// < Present is synchronized
  /// with the refresh rate
  static const int SDL_RENDERER_PRESENTVSYNC = 4;

  /// < The renderer supports
  /// rendering to texture
  static const int SDL_RENDERER_TARGETTEXTURE = 8;
}

/// Information on the capabilities of a render driver or context.
class SDL_RendererInfo extends ffi.Struct {
  /// < The name of the renderer
  external ffi.Pointer<ffi.Int8> name;

  /// < Supported ::SDL_RendererFlags
  @Uint32()
  external int flags;

  /// < The number of available texture formats
  @Uint32()
  external int num_texture_formats;

  @ffi.Array.multi([16])
  external ffi.Array<Uint32> texture_formats;

  /// < The maximum texture width
  @ffi.Int32()
  external int max_texture_width;

  /// < The maximum texture height
  @ffi.Int32()
  external int max_texture_height;
}

/// Vertex structure
class SDL_Vertex extends ffi.Struct {
  /// < Vertex position, in SDL_Renderer coordinates
  external SDL_FPoint position;

  /// < Vertex color
  external SDL_Color color;

  /// < Normalized texture coordinates, if needed
  external SDL_FPoint tex_coord;
}

/// The scaling mode for a texture.
abstract class SDL_ScaleMode {
  /// < nearest pixel sampling
  static const int SDL_ScaleModeNearest = 0;

  /// < linear filtering
  static const int SDL_ScaleModeLinear = 1;

  /// < anisotropic filtering
  static const int SDL_ScaleModeBest = 2;
}

/// The access pattern allowed for a texture.
abstract class SDL_TextureAccess {
  /// < Changes rarely, not lockable
  static const int SDL_TEXTUREACCESS_STATIC = 0;

  /// < Changes frequently, lockable
  static const int SDL_TEXTUREACCESS_STREAMING = 1;

  /// < Texture can be used as a render target
  static const int SDL_TEXTUREACCESS_TARGET = 2;
}

/// The texture channel modulation used in SDL_RenderCopy().
abstract class SDL_TextureModulate {
  /// < No modulation
  static const int SDL_TEXTUREMODULATE_NONE = 0;

  /// < srcC = srcC * color
  static const int SDL_TEXTUREMODULATE_COLOR = 1;

  /// < srcA = srcA * alpha
  static const int SDL_TEXTUREMODULATE_ALPHA = 2;
}

/// Flip constants for SDL_RenderCopyEx
abstract class SDL_RendererFlip {
  /// < Do not flip
  static const int SDL_FLIP_NONE = 0;

  /// < flip horizontally
  static const int SDL_FLIP_HORIZONTAL = 1;

  /// < flip vertically
  static const int SDL_FLIP_VERTICAL = 2;
}

/// A structure representing rendering state
class SDL_Renderer extends ffi.Opaque {}

/// An efficient driver-specific representation of pixel data
class SDL_Texture extends ffi.Opaque {}

/// \brief An enum denoting the specific type of contents present in an SDL_WindowShapeParams union.
abstract class WindowShapeMode {
  /// \brief The default mode, a binarized alpha cutoff of 1.
  static const int ShapeModeDefault = 0;

  /// \brief A binarized alpha cutoff with a given integer value.
  static const int ShapeModeBinarizeAlpha = 1;

  /// \brief A binarized alpha cutoff with a given integer value, but with the opposite comparison.
  static const int ShapeModeReverseBinarizeAlpha = 2;

  /// \brief A color key is applied.
  static const int ShapeModeColorKey = 3;
}

/// \brief A union containing parameters for shaped windows.
class SDL_WindowShapeParams extends ffi.Union {
  /// \brief A cutoff alpha value for binarization of the window shape's alpha channel.
  @Uint8()
  external int binarizationCutoff;

  external SDL_Color colorKey;
}

/// \brief A struct that tags the SDL_WindowShapeParams union with an enum describing the type of its contents.
class SDL_WindowShapeMode extends ffi.Struct {
  /// \brief The mode of these window-shape parameters.
  @ffi.Int32()
  external int mode;

  /// \brief Window-shape parameters.
  external SDL_WindowShapeParams parameters;
}

typedef SDL_WindowsMessageHook = ffi.Pointer<
    ffi.NativeFunction<
        ffi.Void Function(ffi.Pointer<ffi.Void>, ffi.Pointer<ffi.Void>,
            ffi.Uint32, Uint64, Sint64)>>;

class IDirect3DDevice9 extends ffi.Opaque {}

class ID3D11Device extends ffi.Opaque {}

/// Definition of the timer ID type.
typedef SDL_TimerID = ffi.Int32;

/// Function prototype for the timer callback function.
///
/// The callback function is passed the current timer interval and returns
/// the next timer interval. If the returned value is the same as the one
/// passed in, the periodic alarm continues, otherwise a new alarm is
/// scheduled. If the callback returns 0, the periodic alarm is cancelled.
typedef SDL_TimerCallback = ffi.Pointer<
    ffi.NativeFunction<Uint32 Function(Uint32, ffi.Pointer<ffi.Void>)>>;

/// Information about the version of SDL in use.
///
/// Represents the library's version as three levels: major revision
/// (increments with massive changes, additions, and enhancements),
/// minor revision (increments with backwards-compatible changes to the
/// major revision), and patchlevel (increments with fixes to the minor
/// revision).
///
/// \sa SDL_VERSION
/// \sa SDL_GetVersion
class SDL_version extends ffi.Struct {
  /// < major version
  @Uint8()
  external int major;

  /// < minor version
  @Uint8()
  external int minor;

  /// < update version
  @Uint8()
  external int patch;
}

class SDL_Locale extends ffi.Struct {
  /// < A language name, like "en" for English.
  external ffi.Pointer<ffi.Int8> language;

  /// < A country, like "US" for America. Can be NULL.
  external ffi.Pointer<ffi.Int8> country;
}

const int HAVE_WINAPIFAMILY_H = 1;

const int WINAPI_PARTITION_SERVER = 0;

const int WINAPI_PARTITION_PKG_WINTRUST = 0;

const int WINAPI_PARTITION_PKG_WEBSERVICES = 0;

const int WINAPI_PARTITION_PKG_EVENTLOGSERVICE = 0;

const int WINAPI_PARTITION_PKG_VHD = 0;

const int WINAPI_PARTITION_PKG_PERFCOUNTER = 0;

const int WINAPI_PARTITION_PKG_SECURESTARTUP = 0;

const int WINAPI_PARTITION_PKG_REMOTEFS = 0;

const int WINAPI_PARTITION_PKG_BOOTABLESKU = 0;

const int WINAPI_PARTITION_PKG_CMDTOOLS = 0;

const int WINAPI_PARTITION_PKG_DISM = 0;

const int WINAPI_PARTITION_PKG_CORESETUP = 0;

const int WINAPI_PARTITION_PKG_APPRUNTIME = 0;

const int WINAPI_PARTITION_PKG_ESENT = 0;

const int WINAPI_PARTITION_PKG_WINMGMT = 0;

const int WINAPI_PARTITION_PKG_WNV = 0;

const int WINAPI_PARTITION_PKG_CLUSTER = 0;

const int WINAPI_PARTITION_PKG_VSS = 0;

const int WINAPI_PARTITION_PKG_TRAFFIC = 0;

const int WINAPI_PARTITION_PKG_ISCSI = 0;

const int WINAPI_PARTITION_PKG_STORAGE = 0;

const int WINAPI_PARTITION_PKG_MPSSVC = 0;

const int WINAPI_PARTITION_PKG_APPXDEPLOYMENT = 0;

const int WINAPI_PARTITION_PKG_WER = 0;

const int WINAPI_FAMILY_PC_APP = 2;

const int WINAPI_FAMILY_PHONE_APP = 3;

const int WINAPI_FAMILY_SYSTEM = 4;

const int WINAPI_FAMILY_SERVER = 5;

const int WINAPI_FAMILY_GAMES = 6;

const int WINAPI_FAMILY_DESKTOP_APP = 100;

const int WINAPI_FAMILY_APP = 2;

const int WINAPI_FAMILY = 100;

const int WINAPI_PARTITION_DESKTOP = 1;

const int WINAPI_PARTITION_APP = 1;

const int WINAPI_PARTITION_PC_APP = 1;

const int WINAPI_PARTITION_PHONE_APP = 0;

const int WINAPI_PARTITION_GAMES = 1;

const int WINAPI_PARTITION_SYSTEM = 0;

const int WINAPI_PARTITION_PHONE = 0;

const int WINAPI_FAMILY_WINRT = 0;

const int __WINDOWS__ = 1;

const int __WIN32__ = 1;

const int NULL = 0;

const int HAVE_WINSDKVER_H = 1;

const int _WIN32_MAXVER = 2560;

const int _WIN32_WINDOWS_MAXVER = 2560;

const int NTDDI_MAXVER = 2560;

const int _WIN32_IE_MAXVER = 2560;

const int _WIN32_WINNT_MAXVER = 2560;

const int WINVER_MAXVER = 2560;

const int HAVE_STDINT_H = 1;

const int SIZEOF_VOIDP = 8;

const int HAVE_DDRAW_H = 1;

const int HAVE_DINPUT_H = 1;

const int HAVE_DSOUND_H = 1;

const int HAVE_DXGI_H = 1;

const int HAVE_XINPUT_H = 1;

const int HAVE_WINDOWS_GAMING_INPUT_H = 1;

const int HAVE_D3D11_H = 1;

const int HAVE_MMDEVICEAPI_H = 1;

const int HAVE_AUDIOCLIENT_H = 1;

const int HAVE_TPCSHRD_H = 1;

const int HAVE_SENSORSAPI_H = 1;

const int HAVE_IMMINTRIN_H = 1;

const int HAVE_STDARG_H = 1;

const int HAVE_STDDEF_H = 1;

const int SDL_AUDIO_DRIVER_WASAPI = 1;

const int SDL_AUDIO_DRIVER_DSOUND = 1;

const int SDL_AUDIO_DRIVER_WINMM = 1;

const int SDL_AUDIO_DRIVER_DISK = 1;

const int SDL_AUDIO_DRIVER_DUMMY = 1;

const int SDL_JOYSTICK_DINPUT = 1;

const int SDL_JOYSTICK_HIDAPI = 1;

const int SDL_JOYSTICK_RAWINPUT = 1;

const int SDL_JOYSTICK_VIRTUAL = 1;

const int SDL_JOYSTICK_WGI = 1;

const int SDL_JOYSTICK_XINPUT = 1;

const int SDL_HAPTIC_DINPUT = 1;

const int SDL_HAPTIC_XINPUT = 1;

const int SDL_SENSOR_WINDOWS = 1;

const int SDL_LOADSO_WINDOWS = 1;

const int SDL_THREAD_GENERIC_COND_SUFFIX = 1;

const int SDL_THREAD_WINDOWS = 1;

const int SDL_TIMER_WINDOWS = 1;

const int SDL_VIDEO_DRIVER_DUMMY = 1;

const int SDL_VIDEO_DRIVER_WINDOWS = 1;

const int SDL_VIDEO_RENDER_D3D = 1;

const int SDL_VIDEO_RENDER_D3D11 = 1;

const int SDL_VIDEO_OPENGL = 1;

const int SDL_VIDEO_OPENGL_WGL = 1;

const int SDL_VIDEO_RENDER_OGL = 1;

const int SDL_VIDEO_RENDER_OGL_ES2 = 1;

const int SDL_VIDEO_OPENGL_ES2 = 1;

const int SDL_VIDEO_OPENGL_EGL = 1;

const int SDL_VIDEO_VULKAN = 1;

const int SDL_POWER_WINDOWS = 1;

const int SDL_FILESYSTEM_WINDOWS = 1;

const int _VCRT_COMPILER_PREPROCESSOR = 1;

const int _SAL_VERSION = 20;

const int __SAL_H_VERSION = 180000000;

const int _USE_DECLSPECS_FOR_SAL = 0;

const int _USE_ATTRIBUTES_FOR_SAL = 0;

const int _CRT_PACKING = 8;

const int _VCRUNTIME_DISABLED_WARNINGS = 4514;

const int _HAS_EXCEPTIONS = 1;

const int _WCHAR_T_DEFINED = 1;

const int _HAS_CXX17 = 0;

const int _HAS_CXX20 = 0;

const int _HAS_CXX23 = 0;

const int _HAS_NODISCARD = 1;

const int _ARM_WINAPI_PARTITION_DESKTOP_SDK_AVAILABLE = 1;

const int _CRT_BUILD_DESKTOP_APP = 1;

const int _UCRT_DISABLED_WARNINGS = 4324;

const int _ARGMAX = 100;

const int _TRUNCATE = -1;

const int _CRT_INT_MAX = 2147483647;

const int _CRT_SIZE_MAX = -1;

const String __FILEW__ = 't';

const int _CRT_FUNCTIONS_REQUIRED = 1;

const int _CRT_HAS_CXX17 = 0;

const int _CRT_HAS_C11 = 0;

const int _CRT_INTERNAL_NONSTDC_NAMES = 1;

const int __STDC_SECURE_LIB__ = 200411;

const int __GOT_SECURE_LIB__ = 200411;

const int __STDC_WANT_SECURE_LIB__ = 1;

const int _SECURECRT_FILL_BUFFER_PATTERN = 254;

const int _CRT_SECURE_CPP_OVERLOAD_STANDARD_NAMES = 0;

const int _CRT_SECURE_CPP_OVERLOAD_STANDARD_NAMES_COUNT = 0;

const int _CRT_SECURE_CPP_OVERLOAD_SECURE_NAMES = 1;

const int _CRT_SECURE_CPP_OVERLOAD_STANDARD_NAMES_MEMORY = 0;

const int _CRT_SECURE_CPP_OVERLOAD_SECURE_NAMES_MEMORY = 0;

const int INT8_MIN = -128;

const int INT16_MIN = -32768;

const int INT32_MIN = -2147483648;

const int INT64_MIN = -9223372036854775808;

const int INT8_MAX = 127;

const int INT16_MAX = 32767;

const int INT32_MAX = 2147483647;

const int INT64_MAX = 9223372036854775807;

const int UINT8_MAX = 255;

const int UINT16_MAX = 65535;

const int UINT32_MAX = 4294967295;

const int UINT64_MAX = -1;

const int INT_LEAST8_MIN = -128;

const int INT_LEAST16_MIN = -32768;

const int INT_LEAST32_MIN = -2147483648;

const int INT_LEAST64_MIN = -9223372036854775808;

const int INT_LEAST8_MAX = 127;

const int INT_LEAST16_MAX = 32767;

const int INT_LEAST32_MAX = 2147483647;

const int INT_LEAST64_MAX = 9223372036854775807;

const int UINT_LEAST8_MAX = 255;

const int UINT_LEAST16_MAX = 65535;

const int UINT_LEAST32_MAX = 4294967295;

const int UINT_LEAST64_MAX = -1;

const int INT_FAST8_MIN = -128;

const int INT_FAST16_MIN = -2147483648;

const int INT_FAST32_MIN = -2147483648;

const int INT_FAST64_MIN = -9223372036854775808;

const int INT_FAST8_MAX = 127;

const int INT_FAST16_MAX = 2147483647;

const int INT_FAST32_MAX = 2147483647;

const int INT_FAST64_MAX = 9223372036854775807;

const int UINT_FAST8_MAX = 255;

const int UINT_FAST16_MAX = 4294967295;

const int UINT_FAST32_MAX = 4294967295;

const int UINT_FAST64_MAX = -1;

const int INTPTR_MIN = -9223372036854775808;

const int INTPTR_MAX = 9223372036854775807;

const int UINTPTR_MAX = -1;

const int INTMAX_MIN = -9223372036854775808;

const int INTMAX_MAX = 9223372036854775807;

const int UINTMAX_MAX = -1;

const int PTRDIFF_MIN = -9223372036854775808;

const int PTRDIFF_MAX = 9223372036854775807;

const int SIZE_MAX = -1;

const int SIG_ATOMIC_MIN = -2147483648;

const int SIG_ATOMIC_MAX = 2147483647;

const int WCHAR_MIN = 0;

const int WCHAR_MAX = 65535;

const int WINT_MIN = 0;

const int WINT_MAX = 65535;

const int SDL_MAX_SINT8 = 127;

const int SDL_MIN_SINT8 = -128;

const int SDL_MAX_UINT8 = 255;

const int SDL_MIN_UINT8 = 0;

const int SDL_MAX_SINT16 = 32767;

const int SDL_MIN_SINT16 = -32768;

const int SDL_MAX_UINT16 = 65535;

const int SDL_MIN_UINT16 = 0;

const int SDL_MAX_SINT32 = 2147483647;

const int SDL_MIN_SINT32 = -2147483648;

const int SDL_MAX_UINT32 = 4294967295;

const int SDL_MIN_UINT32 = 0;

const int SDL_MAX_SINT64 = 9223372036854775807;

const int SDL_MIN_SINT64 = -9223372036854775808;

const int SDL_MAX_UINT64 = -1;

const int SDL_MIN_UINT64 = 0;

const String SDL_PRIs64 = 'I64d';

const String SDL_PRIu64 = 'I64u';

const String SDL_PRIx64 = 'I64x';

const String SDL_PRIX64 = 'I64X';

const String SDL_PRIs32 = 'd';

const String SDL_PRIu32 = 'u';

const String SDL_PRIx32 = 'x';

const String SDL_PRIX32 = 'X';

const double M_PI = 3.141592653589793;

const int SDL_ICONV_ERROR = -1;

const int SDL_ICONV_E2BIG = -2;

const int SDL_ICONV_EILSEQ = -3;

const int SDL_ICONV_EINVAL = -4;

const int SDL_ASSERT_LEVEL = 1;

const String SDL_FILE = 'temp_for_macros.hpp';

const int SDL_LINE = 592;

const int SDL_NULL_WHILE_LOOP_CONDITION = 0;

const int _JBLEN = 16;

const int _HEAP_MAXREQ = -32;

const int _HEAPEMPTY = -1;

const int _HEAPOK = -2;

const int _HEAPBADBEGIN = -3;

const int _HEAPBADNODE = -4;

const int _HEAPEND = -5;

const int _HEAPBADPTR = -6;

const int _FREEENTRY = 0;

const int _USEDENTRY = 1;

const int _ALLOCA_S_THRESHOLD = 1024;

const int _ALLOCA_S_STACK_MARKER = 52428;

const int _ALLOCA_S_HEAP_MARKER = 56797;

const int _ALLOCA_S_MARKER_SIZE = 16;

const int _MM_HINT_NTA = 0;

const int _MM_HINT_T0 = 1;

const int _MM_HINT_T1 = 2;

const int _MM_HINT_T2 = 3;

const int _MM_HINT_ENTA = 4;

const int _MM_EXCEPT_MASK = 63;

const int _MM_EXCEPT_INVALID = 1;

const int _MM_EXCEPT_DENORM = 2;

const int _MM_EXCEPT_DIV_ZERO = 4;

const int _MM_EXCEPT_OVERFLOW = 8;

const int _MM_EXCEPT_UNDERFLOW = 16;

const int _MM_EXCEPT_INEXACT = 32;

const int _MM_MASK_MASK = 8064;

const int _MM_MASK_INVALID = 128;

const int _MM_MASK_DENORM = 256;

const int _MM_MASK_DIV_ZERO = 512;

const int _MM_MASK_OVERFLOW = 1024;

const int _MM_MASK_UNDERFLOW = 2048;

const int _MM_MASK_INEXACT = 4096;

const int _MM_ROUND_MASK = 24576;

const int _MM_ROUND_NEAREST = 0;

const int _MM_ROUND_DOWN = 8192;

const int _MM_ROUND_UP = 16384;

const int _MM_ROUND_TOWARD_ZERO = 24576;

const int _MM_FLUSH_ZERO_MASK = 32768;

const int _MM_FLUSH_ZERO_ON = 32768;

const int _MM_FLUSH_ZERO_OFF = 0;

const int _MM_DENORMALS_ZERO_MASK = 64;

const int _MM_DENORMALS_ZERO_ON = 64;

const int _MM_DENORMALS_ZERO_OFF = 0;

const int _MM_FROUND_TO_NEAREST_INT = 0;

const int _MM_FROUND_TO_NEG_INF = 1;

const int _MM_FROUND_TO_POS_INF = 2;

const int _MM_FROUND_TO_ZERO = 3;

const int _MM_FROUND_CUR_DIRECTION = 4;

const int _MM_FROUND_RAISE_EXC = 0;

const int _MM_FROUND_NO_EXC = 8;

const int _MM_FROUND_NINT = 0;

const int _MM_FROUND_FLOOR = 1;

const int _MM_FROUND_CEIL = 2;

const int _MM_FROUND_TRUNC = 3;

const int _MM_FROUND_RINT = 4;

const int _MM_FROUND_NEARBYINT = 12;

const int _SIDD_UBYTE_OPS = 0;

const int _SIDD_UWORD_OPS = 1;

const int _SIDD_SBYTE_OPS = 2;

const int _SIDD_SWORD_OPS = 3;

const int _SIDD_CMP_EQUAL_ANY = 0;

const int _SIDD_CMP_RANGES = 4;

const int _SIDD_CMP_EQUAL_EACH = 8;

const int _SIDD_CMP_EQUAL_ORDERED = 12;

const int _SIDD_POSITIVE_POLARITY = 0;

const int _SIDD_NEGATIVE_POLARITY = 16;

const int _SIDD_MASKED_POSITIVE_POLARITY = 32;

const int _SIDD_MASKED_NEGATIVE_POLARITY = 48;

const int _SIDD_LEAST_SIGNIFICANT = 0;

const int _SIDD_MOST_SIGNIFICANT = 64;

const int _SIDD_BIT_MASK = 0;

const int _SIDD_UNIT_MASK = 64;

const int _CMP_EQ_OQ = 0;

const int _CMP_LT_OS = 1;

const int _CMP_LE_OS = 2;

const int _CMP_UNORD_Q = 3;

const int _CMP_NEQ_UQ = 4;

const int _CMP_NLT_US = 5;

const int _CMP_NLE_US = 6;

const int _CMP_ORD_Q = 7;

const int _CMP_EQ_UQ = 8;

const int _CMP_NGE_US = 9;

const int _CMP_NGT_US = 10;

const int _CMP_FALSE_OQ = 11;

const int _CMP_NEQ_OQ = 12;

const int _CMP_GE_OS = 13;

const int _CMP_GT_OS = 14;

const int _CMP_TRUE_UQ = 15;

const int _CMP_EQ_OS = 16;

const int _CMP_LT_OQ = 17;

const int _CMP_LE_OQ = 18;

const int _CMP_UNORD_S = 19;

const int _CMP_NEQ_US = 20;

const int _CMP_NLT_UQ = 21;

const int _CMP_NLE_UQ = 22;

const int _CMP_ORD_S = 23;

const int _CMP_EQ_US = 24;

const int _CMP_NGE_UQ = 25;

const int _CMP_NGT_UQ = 26;

const int _CMP_FALSE_OS = 27;

const int _CMP_NEQ_OS = 28;

const int _CMP_GE_OQ = 29;

const int _CMP_GT_OQ = 30;

const int _CMP_TRUE_US = 31;

const int _XCR_XFEATURE_ENABLED_MASK = 0;

const int _XBEGIN_STARTED = 4294967295;

const int _XABORT_EXPLICIT = 1;

const int _XABORT_RETRY = 2;

const int _XABORT_CONFLICT = 4;

const int _XABORT_CAPACITY = 8;

const int _XABORT_DEBUG = 16;

const int _XABORT_NESTED = 32;

const int _MM_K0_REG8 = 255;

const int _MM_K0_REG16 = 65535;

const int _MM_K0_REG32 = 4294967295;

const int _MM_K0_REG64 = -1;

const int _MM_BROADCAST_16X16 = 0;

const int _MM_BROADCAST_8X8 = 0;

const int _MM_CMPINT_GE = 5;

const int _MM_CMPINT_GT = 6;

const int _MM_PCOMCTRL_LT = 0;

const int _MM_PCOMCTRL_LE = 1;

const int _MM_PCOMCTRL_GT = 2;

const int _MM_PCOMCTRL_GE = 3;

const int _MM_PCOMCTRL_EQ = 4;

const int _MM_PCOMCTRL_NEQ = 5;

const int _MM_PCOMCTRL_FALSE = 6;

const int _MM_PCOMCTRL_TRUE = 7;

const int _MM_PERMUTE2_COPY = 0;

const int _MM_PERMUTE2_ZEROIF1 = 2;

const int _MM_PERMUTE2_ZEROIF0 = 3;

const int SDL_LIL_ENDIAN = 1234;

const int SDL_BIG_ENDIAN = 4321;

const int SDL_BYTEORDER = 1234;

const int SDL_MUTEX_TIMEDOUT = 1;

const int SDL_MUTEX_MAXWAIT = 4294967295;

const int _DOMAIN = 1;

const int _SING = 2;

const int _OVERFLOW = 3;

const int _UNDERFLOW = 4;

const int _TLOSS = 5;

const int _PLOSS = 6;

const double _HUGE_ENUF = 1e+300;

const double INFINITY = double.infinity;

const double HUGE_VAL = double.infinity;

const double HUGE_VALF = double.infinity;

const double HUGE_VALL = double.infinity;

const double NAN = double.nan;

const int _DENORM = -2;

const int _FINITE = -1;

const int _INFCODE = 1;

const int _NANCODE = 2;

const int FP_INFINITE = 1;

const int FP_NAN = 2;

const int FP_NORMAL = -1;

const int FP_SUBNORMAL = -2;

const int FP_ZERO = 0;

const int _C2 = 1;

const int FP_ILOGB0 = -2147483648;

const int FP_ILOGBNAN = 2147483647;

const int MATH_ERRNO = 1;

const int MATH_ERREXCEPT = 2;

const int math_errhandling = 3;

const int _FE_DIVBYZERO = 4;

const int _FE_INEXACT = 32;

const int _FE_INVALID = 1;

const int _FE_OVERFLOW = 8;

const int _FE_UNDERFLOW = 16;

const int _D0_C = 3;

const int _D1_C = 2;

const int _D2_C = 1;

const int _D3_C = 0;

const int _DBIAS = 1022;

const int _DOFF = 4;

const int _F0_C = 1;

const int _F1_C = 0;

const int _FBIAS = 126;

const int _FOFF = 7;

const int _FRND = 1;

const int _L0_C = 3;

const int _L1_C = 2;

const int _L2_C = 1;

const int _L3_C = 0;

const int _LBIAS = 1022;

const int _LOFF = 4;

const int _DFRAC = 15;

const int _DMASK = 32752;

const int _DMAX = 2047;

const int _DSIGN = 32768;

const int _FFRAC = 127;

const int _FMASK = 32640;

const int _FMAX = 255;

const int _FSIGN = 32768;

const int _LFRAC = 65535;

const int _LMASK = 32767;

const int _LMAX = 32767;

const int _LSIGN = 32768;

const int _DHUGE_EXP = 1842;

const int _FHUGE_EXP = 229;

const int _LHUGE_EXP = 29490;

const int _FP_LT = 1;

const int _FP_EQ = 2;

const int _FP_GT = 4;

const int DOMAIN = 1;

const int SING = 2;

const int OVERFLOW = 3;

const int UNDERFLOW = 4;

const int TLOSS = 5;

const int PLOSS = 6;

const int _P_WAIT = 0;

const int _P_NOWAIT = 1;

const int _OLD_P_OVERLAY = 2;

const int _P_NOWAITO = 3;

const int _P_DETACH = 4;

const int _P_OVERLAY = 2;

const int _WAIT_CHILD = 0;

const int _WAIT_GRANDCHILD = 1;

const int P_WAIT = 0;

const int P_NOWAIT = 1;

const int P_OVERLAY = 2;

const int OLD_P_OVERLAY = 2;

const int P_NOWAITO = 3;

const int P_DETACH = 4;

const int WAIT_CHILD = 0;

const int WAIT_GRANDCHILD = 1;

const int SDL_RWOPS_UNKNOWN = 0;

const int SDL_RWOPS_WINFILE = 1;

const int SDL_RWOPS_STDFILE = 2;

const int SDL_RWOPS_JNIFILE = 3;

const int SDL_RWOPS_MEMORY = 4;

const int SDL_RWOPS_MEMORY_RO = 5;

const int RW_SEEK_SET = 0;

const int RW_SEEK_CUR = 1;

const int RW_SEEK_END = 2;

const int SDL_AUDIO_MASK_BITSIZE = 255;

const int SDL_AUDIO_MASK_DATATYPE = 256;

const int SDL_AUDIO_MASK_ENDIAN = 4096;

const int SDL_AUDIO_MASK_SIGNED = 32768;

const int AUDIO_U8 = 8;

const int AUDIO_S8 = 32776;

const int AUDIO_U16LSB = 16;

const int AUDIO_S16LSB = 32784;

const int AUDIO_U16MSB = 4112;

const int AUDIO_S16MSB = 36880;

const int AUDIO_U16 = 16;

const int AUDIO_S16 = 32784;

const int AUDIO_S32LSB = 32800;

const int AUDIO_S32MSB = 36896;

const int AUDIO_S32 = 32800;

const int AUDIO_F32LSB = 33056;

const int AUDIO_F32MSB = 37152;

const int AUDIO_F32 = 33056;

const int AUDIO_U16SYS = 16;

const int AUDIO_S16SYS = 32784;

const int AUDIO_S32SYS = 32800;

const int AUDIO_F32SYS = 33056;

const int SDL_AUDIO_ALLOW_FREQUENCY_CHANGE = 1;

const int SDL_AUDIO_ALLOW_FORMAT_CHANGE = 2;

const int SDL_AUDIO_ALLOW_CHANNELS_CHANGE = 4;

const int SDL_AUDIO_ALLOW_SAMPLES_CHANGE = 8;

const int SDL_AUDIO_ALLOW_ANY_CHANGE = 15;

const int SDL_AUDIOCVT_MAX_FILTERS = 9;

const int SDL_MIX_MAXVOLUME = 128;

const int SDL_CACHELINE_SIZE = 128;

const int SDL_ALPHA_OPAQUE = 255;

const int SDL_ALPHA_TRANSPARENT = 0;

const int SDL_SWSURFACE = 0;

const int SDL_PREALLOC = 1;

const int SDL_RLEACCEL = 2;

const int SDL_DONTFREE = 4;

const int SDL_SIMD_ALIGNED = 8;

const int SDL_WINDOWPOS_UNDEFINED_MASK = 536805376;

const int SDL_WINDOWPOS_UNDEFINED = 536805376;

const int SDL_WINDOWPOS_CENTERED_MASK = 805240832;

const int SDL_WINDOWPOS_CENTERED = 805240832;

const int SDLK_SCANCODE_MASK = 1073741824;

const int SDL_BUTTON_LEFT = 1;

const int SDL_BUTTON_MIDDLE = 2;

const int SDL_BUTTON_RIGHT = 3;

const int SDL_BUTTON_X1 = 4;

const int SDL_BUTTON_X2 = 5;

const int SDL_BUTTON_LMASK = 1;

const int SDL_BUTTON_MMASK = 2;

const int SDL_BUTTON_RMASK = 4;

const int SDL_BUTTON_X1MASK = 8;

const int SDL_BUTTON_X2MASK = 16;

const double SDL_IPHONE_MAX_GFORCE = 5.0;

const int SDL_JOYSTICK_AXIS_MAX = 32767;

const int SDL_JOYSTICK_AXIS_MIN = -32768;

const int SDL_HAT_CENTERED = 0;

const int SDL_HAT_UP = 1;

const int SDL_HAT_RIGHT = 2;

const int SDL_HAT_DOWN = 4;

const int SDL_HAT_LEFT = 8;

const int SDL_HAT_RIGHTUP = 3;

const int SDL_HAT_RIGHTDOWN = 6;

const int SDL_HAT_LEFTUP = 9;

const int SDL_HAT_LEFTDOWN = 12;

const double SDL_STANDARD_GRAVITY = 9.806650161743164;

const int SDL_TOUCH_MOUSEID = 4294967295;

const int SDL_MOUSE_TOUCHID = -1;

const int SDL_RELEASED = 0;

const int SDL_PRESSED = 1;

const int SDL_TEXTEDITINGEVENT_TEXT_SIZE = 32;

const int SDL_TEXTINPUTEVENT_TEXT_SIZE = 32;

const int SDL_QUERY = -1;

const int SDL_IGNORE = 0;

const int SDL_DISABLE = 0;

const int SDL_ENABLE = 1;

const int SDL_HAPTIC_CONSTANT = 1;

const int SDL_HAPTIC_SINE = 2;

const int SDL_HAPTIC_LEFTRIGHT = 4;

const int SDL_HAPTIC_TRIANGLE = 8;

const int SDL_HAPTIC_SAWTOOTHUP = 16;

const int SDL_HAPTIC_SAWTOOTHDOWN = 32;

const int SDL_HAPTIC_RAMP = 64;

const int SDL_HAPTIC_SPRING = 128;

const int SDL_HAPTIC_DAMPER = 256;

const int SDL_HAPTIC_INERTIA = 512;

const int SDL_HAPTIC_FRICTION = 1024;

const int SDL_HAPTIC_CUSTOM = 2048;

const int SDL_HAPTIC_GAIN = 4096;

const int SDL_HAPTIC_AUTOCENTER = 8192;

const int SDL_HAPTIC_STATUS = 16384;

const int SDL_HAPTIC_PAUSE = 32768;

const int SDL_HAPTIC_POLAR = 0;

const int SDL_HAPTIC_CARTESIAN = 1;

const int SDL_HAPTIC_SPHERICAL = 2;

const int SDL_HAPTIC_STEERING_AXIS = 3;

const int SDL_HAPTIC_INFINITY = 4294967295;

const String SDL_HINT_ACCELEROMETER_AS_JOYSTICK =
    'SDL_ACCELEROMETER_AS_JOYSTICK';

const String SDL_HINT_ALLOW_ALT_TAB_WHILE_GRABBED =
    'SDL_ALLOW_ALT_TAB_WHILE_GRABBED';

const String SDL_HINT_ALLOW_TOPMOST = 'SDL_ALLOW_TOPMOST';

const String SDL_HINT_ANDROID_APK_EXPANSION_MAIN_FILE_VERSION =
    'SDL_ANDROID_APK_EXPANSION_MAIN_FILE_VERSION';

const String SDL_HINT_ANDROID_APK_EXPANSION_PATCH_FILE_VERSION =
    'SDL_ANDROID_APK_EXPANSION_PATCH_FILE_VERSION';

const String SDL_HINT_ANDROID_BLOCK_ON_PAUSE = 'SDL_ANDROID_BLOCK_ON_PAUSE';

const String SDL_HINT_ANDROID_BLOCK_ON_PAUSE_PAUSEAUDIO =
    'SDL_ANDROID_BLOCK_ON_PAUSE_PAUSEAUDIO';

const String SDL_HINT_ANDROID_TRAP_BACK_BUTTON = 'SDL_ANDROID_TRAP_BACK_BUTTON';

const String SDL_HINT_APP_NAME = 'SDL_APP_NAME';

const String SDL_HINT_APPLE_TV_CONTROLLER_UI_EVENTS =
    'SDL_APPLE_TV_CONTROLLER_UI_EVENTS';

const String SDL_HINT_APPLE_TV_REMOTE_ALLOW_ROTATION =
    'SDL_APPLE_TV_REMOTE_ALLOW_ROTATION';

const String SDL_HINT_AUDIO_CATEGORY = 'SDL_AUDIO_CATEGORY';

const String SDL_HINT_AUDIO_DEVICE_APP_NAME = 'SDL_AUDIO_DEVICE_APP_NAME';

const String SDL_HINT_AUDIO_DEVICE_STREAM_NAME = 'SDL_AUDIO_DEVICE_STREAM_NAME';

const String SDL_HINT_AUDIO_DEVICE_STREAM_ROLE = 'SDL_AUDIO_DEVICE_STREAM_ROLE';

const String SDL_HINT_AUDIO_RESAMPLING_MODE = 'SDL_AUDIO_RESAMPLING_MODE';

const String SDL_HINT_AUTO_UPDATE_JOYSTICKS = 'SDL_AUTO_UPDATE_JOYSTICKS';

const String SDL_HINT_AUTO_UPDATE_SENSORS = 'SDL_AUTO_UPDATE_SENSORS';

const String SDL_HINT_BMP_SAVE_LEGACY_FORMAT = 'SDL_BMP_SAVE_LEGACY_FORMAT';

const String SDL_HINT_DISPLAY_USABLE_BOUNDS = 'SDL_DISPLAY_USABLE_BOUNDS';

const String SDL_HINT_EMSCRIPTEN_ASYNCIFY = 'SDL_EMSCRIPTEN_ASYNCIFY';

const String SDL_HINT_EMSCRIPTEN_KEYBOARD_ELEMENT =
    'SDL_EMSCRIPTEN_KEYBOARD_ELEMENT';

const String SDL_HINT_ENABLE_STEAM_CONTROLLERS = 'SDL_ENABLE_STEAM_CONTROLLERS';

const String SDL_HINT_EVENT_LOGGING = 'SDL_EVENT_LOGGING';

const String SDL_HINT_FRAMEBUFFER_ACCELERATION = 'SDL_FRAMEBUFFER_ACCELERATION';

const String SDL_HINT_GAMECONTROLLERCONFIG = 'SDL_GAMECONTROLLERCONFIG';

const String SDL_HINT_GAMECONTROLLERCONFIG_FILE =
    'SDL_GAMECONTROLLERCONFIG_FILE';

const String SDL_HINT_GAMECONTROLLERTYPE = 'SDL_GAMECONTROLLERTYPE';

const String SDL_HINT_GAMECONTROLLER_IGNORE_DEVICES =
    'SDL_GAMECONTROLLER_IGNORE_DEVICES';

const String SDL_HINT_GAMECONTROLLER_IGNORE_DEVICES_EXCEPT =
    'SDL_GAMECONTROLLER_IGNORE_DEVICES_EXCEPT';

const String SDL_HINT_GAMECONTROLLER_USE_BUTTON_LABELS =
    'SDL_GAMECONTROLLER_USE_BUTTON_LABELS';

const String SDL_HINT_GRAB_KEYBOARD = 'SDL_GRAB_KEYBOARD';

const String SDL_HINT_IDLE_TIMER_DISABLED = 'SDL_IOS_IDLE_TIMER_DISABLED';

const String SDL_HINT_IME_INTERNAL_EDITING = 'SDL_IME_INTERNAL_EDITING';

const String SDL_HINT_IME_SHOW_UI = 'SDL_IME_SHOW_UI';

const String SDL_HINT_IOS_HIDE_HOME_INDICATOR = 'SDL_IOS_HIDE_HOME_INDICATOR';

const String SDL_HINT_JOYSTICK_ALLOW_BACKGROUND_EVENTS =
    'SDL_JOYSTICK_ALLOW_BACKGROUND_EVENTS';

const String SDL_HINT_JOYSTICK_HIDAPI = 'SDL_JOYSTICK_HIDAPI';

const String SDL_HINT_JOYSTICK_HIDAPI_GAMECUBE = 'SDL_JOYSTICK_HIDAPI_GAMECUBE';

const String SDL_HINT_JOYSTICK_HIDAPI_JOY_CONS = 'SDL_JOYSTICK_HIDAPI_JOY_CONS';

const String SDL_HINT_JOYSTICK_HIDAPI_LUNA = 'SDL_JOYSTICK_HIDAPI_LUNA';

const String SDL_HINT_JOYSTICK_HIDAPI_PS4 = 'SDL_JOYSTICK_HIDAPI_PS4';

const String SDL_HINT_JOYSTICK_HIDAPI_PS4_RUMBLE =
    'SDL_JOYSTICK_HIDAPI_PS4_RUMBLE';

const String SDL_HINT_JOYSTICK_HIDAPI_PS5 = 'SDL_JOYSTICK_HIDAPI_PS5';

const String SDL_HINT_JOYSTICK_HIDAPI_PS5_PLAYER_LED =
    'SDL_JOYSTICK_HIDAPI_PS5_PLAYER_LED';

const String SDL_HINT_JOYSTICK_HIDAPI_PS5_RUMBLE =
    'SDL_JOYSTICK_HIDAPI_PS5_RUMBLE';

const String SDL_HINT_JOYSTICK_HIDAPI_STADIA = 'SDL_JOYSTICK_HIDAPI_STADIA';

const String SDL_HINT_JOYSTICK_HIDAPI_STEAM = 'SDL_JOYSTICK_HIDAPI_STEAM';

const String SDL_HINT_JOYSTICK_HIDAPI_SWITCH = 'SDL_JOYSTICK_HIDAPI_SWITCH';

const String SDL_HINT_JOYSTICK_HIDAPI_SWITCH_HOME_LED =
    'SDL_JOYSTICK_HIDAPI_SWITCH_HOME_LED';

const String SDL_HINT_JOYSTICK_HIDAPI_XBOX = 'SDL_JOYSTICK_HIDAPI_XBOX';

const String SDL_HINT_JOYSTICK_RAWINPUT = 'SDL_JOYSTICK_RAWINPUT';

const String SDL_HINT_JOYSTICK_RAWINPUT_CORRELATE_XINPUT =
    'SDL_JOYSTICK_RAWINPUT_CORRELATE_XINPUT';

const String SDL_HINT_JOYSTICK_THREAD = 'SDL_JOYSTICK_THREAD';

const String SDL_HINT_KMSDRM_REQUIRE_DRM_MASTER =
    'SDL_KMSDRM_REQUIRE_DRM_MASTER';

const String SDL_HINT_JOYSTICK_DEVICE = 'SDL_JOYSTICK_DEVICE';

const String SDL_HINT_LINUX_JOYSTICK_CLASSIC = 'SDL_LINUX_JOYSTICK_CLASSIC';

const String SDL_HINT_LINUX_JOYSTICK_DEADZONES = 'SDL_LINUX_JOYSTICK_DEADZONES';

const String SDL_HINT_MAC_BACKGROUND_APP = 'SDL_MAC_BACKGROUND_APP';

const String SDL_HINT_MAC_CTRL_CLICK_EMULATE_RIGHT_CLICK =
    'SDL_MAC_CTRL_CLICK_EMULATE_RIGHT_CLICK';

const String SDL_HINT_MOUSE_DOUBLE_CLICK_RADIUS =
    'SDL_MOUSE_DOUBLE_CLICK_RADIUS';

const String SDL_HINT_MOUSE_DOUBLE_CLICK_TIME = 'SDL_MOUSE_DOUBLE_CLICK_TIME';

const String SDL_HINT_MOUSE_FOCUS_CLICKTHROUGH = 'SDL_MOUSE_FOCUS_CLICKTHROUGH';

const String SDL_HINT_MOUSE_NORMAL_SPEED_SCALE = 'SDL_MOUSE_NORMAL_SPEED_SCALE';

const String SDL_HINT_MOUSE_RELATIVE_MODE_WARP = 'SDL_MOUSE_RELATIVE_MODE_WARP';

const String SDL_HINT_MOUSE_RELATIVE_SCALING = 'SDL_MOUSE_RELATIVE_SCALING';

const String SDL_HINT_MOUSE_RELATIVE_SPEED_SCALE =
    'SDL_MOUSE_RELATIVE_SPEED_SCALE';

const String SDL_HINT_MOUSE_TOUCH_EVENTS = 'SDL_MOUSE_TOUCH_EVENTS';

const String SDL_HINT_NO_SIGNAL_HANDLERS = 'SDL_NO_SIGNAL_HANDLERS';

const String SDL_HINT_OPENGL_ES_DRIVER = 'SDL_OPENGL_ES_DRIVER';

const String SDL_HINT_ORIENTATIONS = 'SDL_IOS_ORIENTATIONS';

const String SDL_HINT_POLL_SENTINEL = 'SDL_POLL_SENTINEL';

const String SDL_HINT_PREFERRED_LOCALES = 'SDL_PREFERRED_LOCALES';

const String SDL_HINT_QTWAYLAND_CONTENT_ORIENTATION =
    'SDL_QTWAYLAND_CONTENT_ORIENTATION';

const String SDL_HINT_QTWAYLAND_WINDOW_FLAGS = 'SDL_QTWAYLAND_WINDOW_FLAGS';

const String SDL_HINT_RENDER_BATCHING = 'SDL_RENDER_BATCHING';

const String SDL_HINT_RENDER_LINE_METHOD = 'SDL_RENDER_LINE_METHOD';

const String SDL_HINT_RENDER_DIRECT3D11_DEBUG = 'SDL_RENDER_DIRECT3D11_DEBUG';

const String SDL_HINT_RENDER_DIRECT3D_THREADSAFE =
    'SDL_RENDER_DIRECT3D_THREADSAFE';

const String SDL_HINT_RENDER_DRIVER = 'SDL_RENDER_DRIVER';

const String SDL_HINT_RENDER_LOGICAL_SIZE_MODE = 'SDL_RENDER_LOGICAL_SIZE_MODE';

const String SDL_HINT_RENDER_OPENGL_SHADERS = 'SDL_RENDER_OPENGL_SHADERS';

const String SDL_HINT_RENDER_SCALE_QUALITY = 'SDL_RENDER_SCALE_QUALITY';

const String SDL_HINT_RENDER_VSYNC = 'SDL_RENDER_VSYNC';

const String SDL_HINT_RETURN_KEY_HIDES_IME = 'SDL_RETURN_KEY_HIDES_IME';

const String SDL_HINT_RPI_VIDEO_LAYER = 'SDL_RPI_VIDEO_LAYER';

const String SDL_HINT_SCREENSAVER_INHIBIT_ACTIVITY_NAME =
    'SDL_SCREENSAVER_INHIBIT_ACTIVITY_NAME';

const String SDL_HINT_THREAD_FORCE_REALTIME_TIME_CRITICAL =
    'SDL_THREAD_FORCE_REALTIME_TIME_CRITICAL';

const String SDL_HINT_THREAD_PRIORITY_POLICY = 'SDL_THREAD_PRIORITY_POLICY';

const String SDL_HINT_THREAD_STACK_SIZE = 'SDL_THREAD_STACK_SIZE';

const String SDL_HINT_TIMER_RESOLUTION = 'SDL_TIMER_RESOLUTION';

const String SDL_HINT_TOUCH_MOUSE_EVENTS = 'SDL_TOUCH_MOUSE_EVENTS';

const String SDL_HINT_TV_REMOTE_AS_JOYSTICK = 'SDL_TV_REMOTE_AS_JOYSTICK';

const String SDL_HINT_VIDEO_ALLOW_SCREENSAVER = 'SDL_VIDEO_ALLOW_SCREENSAVER';

const String SDL_HINT_VIDEO_DOUBLE_BUFFER = 'SDL_VIDEO_DOUBLE_BUFFER';

const String SDL_HINT_VIDEO_EGL_ALLOW_TRANSPARENCY =
    'SDL_VIDEO_EGL_ALLOW_TRANSPARENCY';

const String SDL_HINT_VIDEO_EXTERNAL_CONTEXT = 'SDL_VIDEO_EXTERNAL_CONTEXT';

const String SDL_HINT_VIDEO_HIGHDPI_DISABLED = 'SDL_VIDEO_HIGHDPI_DISABLED';

const String SDL_HINT_VIDEO_MAC_FULLSCREEN_SPACES =
    'SDL_VIDEO_MAC_FULLSCREEN_SPACES';

const String SDL_HINT_VIDEO_MINIMIZE_ON_FOCUS_LOSS =
    'SDL_VIDEO_MINIMIZE_ON_FOCUS_LOSS';

const String SDL_HINT_VIDEO_WAYLAND_ALLOW_LIBDECOR =
    'SDL_VIDEO_WAYLAND_ALLOW_LIBDECOR';

const String SDL_HINT_VIDEO_WINDOW_SHARE_PIXEL_FORMAT =
    'SDL_VIDEO_WINDOW_SHARE_PIXEL_FORMAT';

const String SDL_HINT_VIDEO_WIN_D3DCOMPILER = 'SDL_VIDEO_WIN_D3DCOMPILER';

const String SDL_HINT_VIDEO_X11_FORCE_EGL = 'SDL_VIDEO_X11_FORCE_EGL';

const String SDL_HINT_VIDEO_X11_NET_WM_BYPASS_COMPOSITOR =
    'SDL_VIDEO_X11_NET_WM_BYPASS_COMPOSITOR';

const String SDL_HINT_VIDEO_X11_NET_WM_PING = 'SDL_VIDEO_X11_NET_WM_PING';

const String SDL_HINT_VIDEO_X11_WINDOW_VISUALID =
    'SDL_VIDEO_X11_WINDOW_VISUALID';

const String SDL_HINT_VIDEO_X11_XINERAMA = 'SDL_VIDEO_X11_XINERAMA';

const String SDL_HINT_VIDEO_X11_XRANDR = 'SDL_VIDEO_X11_XRANDR';

const String SDL_HINT_VIDEO_X11_XVIDMODE = 'SDL_VIDEO_X11_XVIDMODE';

const String SDL_HINT_WAVE_FACT_CHUNK = 'SDL_WAVE_FACT_CHUNK';

const String SDL_HINT_WAVE_RIFF_CHUNK_SIZE = 'SDL_WAVE_RIFF_CHUNK_SIZE';

const String SDL_HINT_WAVE_TRUNCATION = 'SDL_WAVE_TRUNCATION';

const String SDL_HINT_WINDOWS_DISABLE_THREAD_NAMING =
    'SDL_WINDOWS_DISABLE_THREAD_NAMING';

const String SDL_HINT_WINDOWS_ENABLE_MESSAGELOOP =
    'SDL_WINDOWS_ENABLE_MESSAGELOOP';

const String SDL_HINT_WINDOWS_FORCE_MUTEX_CRITICAL_SECTIONS =
    'SDL_WINDOWS_FORCE_MUTEX_CRITICAL_SECTIONS';

const String SDL_HINT_WINDOWS_FORCE_SEMAPHORE_KERNEL =
    'SDL_WINDOWS_FORCE_SEMAPHORE_KERNEL';

const String SDL_HINT_WINDOWS_INTRESOURCE_ICON = 'SDL_WINDOWS_INTRESOURCE_ICON';

const String SDL_HINT_WINDOWS_INTRESOURCE_ICON_SMALL =
    'SDL_WINDOWS_INTRESOURCE_ICON_SMALL';

const String SDL_HINT_WINDOWS_NO_CLOSE_ON_ALT_F4 =
    'SDL_WINDOWS_NO_CLOSE_ON_ALT_F4';

const String SDL_HINT_WINDOWS_USE_D3D9EX = 'SDL_WINDOWS_USE_D3D9EX';

const String SDL_HINT_WINDOW_FRAME_USABLE_WHILE_CURSOR_HIDDEN =
    'SDL_WINDOW_FRAME_USABLE_WHILE_CURSOR_HIDDEN';

const String SDL_HINT_WINDOW_NO_ACTIVATION_WHEN_SHOWN =
    'SDL_WINDOW_NO_ACTIVATION_WHEN_SHOWN';

const String SDL_HINT_WINRT_HANDLE_BACK_BUTTON = 'SDL_WINRT_HANDLE_BACK_BUTTON';

const String SDL_HINT_WINRT_PRIVACY_POLICY_LABEL =
    'SDL_WINRT_PRIVACY_POLICY_LABEL';

const String SDL_HINT_WINRT_PRIVACY_POLICY_URL = 'SDL_WINRT_PRIVACY_POLICY_URL';

const String SDL_HINT_X11_FORCE_OVERRIDE_REDIRECT =
    'SDL_X11_FORCE_OVERRIDE_REDIRECT';

const String SDL_HINT_XINPUT_ENABLED = 'SDL_XINPUT_ENABLED';

const String SDL_HINT_XINPUT_USE_OLD_JOYSTICK_MAPPING =
    'SDL_XINPUT_USE_OLD_JOYSTICK_MAPPING';

const String SDL_HINT_AUDIO_INCLUDE_MONITORS = 'SDL_AUDIO_INCLUDE_MONITORS';

const int SDL_MAX_LOG_MESSAGE = 4096;

const int SDL_NONSHAPEABLE_WINDOW = -1;

const int SDL_INVALID_SHAPE_ARGUMENT = -2;

const int SDL_WINDOW_LACKS_SHAPE = -3;

const int SDL_MAJOR_VERSION = 2;

const int SDL_MINOR_VERSION = 0;

const int SDL_PATCHLEVEL = 20;

const int SDL_COMPILEDVERSION = 2020;

const int SDL_INIT_TIMER = 1;

const int SDL_INIT_AUDIO = 16;

const int SDL_INIT_VIDEO = 32;

const int SDL_INIT_JOYSTICK = 512;

const int SDL_INIT_HAPTIC = 4096;

const int SDL_INIT_GAMECONTROLLER = 8192;

const int SDL_INIT_EVENTS = 16384;

const int SDL_INIT_SENSOR = 32768;

const int SDL_INIT_NOPARACHUTE = 1048576;

const int SDL_INIT_EVERYTHING = 62001;

const String SDL_REVISION =
    'https://github.com/libsdl-org/SDL.git@b424665e0899769b200231ba943353a5fee1b6b6';

const int SDL_REVISION_NUMBER = 0;
